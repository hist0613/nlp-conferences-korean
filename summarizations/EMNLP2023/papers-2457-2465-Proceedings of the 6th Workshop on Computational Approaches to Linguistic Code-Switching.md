# Korean Three-Line Summarizations of Papers 2457-2465 in Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching
###### Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching (https://aclanthology.org/2023.calcs-1.0/)
- Anthology ID: 2023.calcs-1.0 
- Volume: Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching 
- Summary: 
    요약문을 생성할 수 없습니다.

###### TongueSwitcher: Fine-Grained Identification of German-English Code-Switching (https://aclanthology.org/2023.calcs-1.1/)
- Anthology ID: 2023.calcs-1.1 
- Volume: Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching 
- Summary: 
    1. 이 연구는 독일어-영어 코드 스위칭 연구에 기여한다. 우리는 독일어 텍스트에 영어가 포함된 자연스러운 독일어-영어 코드 스위칭 코퍼스를 제공하며 코드 스위칭 식별을 위한 두 가지 방법을 제시한다.
    2. 첫 번째 방법은 규칙 기반으로, 단어 목록과 형태학적 처리를 활용한다. 이 방법을 사용하여 독일어-영어 코드 스위칭을 적용한 2,560만 개의 트윗 코퍼스를 작성한다.
    3. 두 번째 방법에서는 이 코퍼스에서 신경 언어 모델의 사전 학습을 이어서 진행하고 해당 언어 모델의 임베딩을 기반으로 토큰을 분류한다. 우리의 시스템은 새로운 코퍼스와 기존 독일어-영어 코드 스위칭 벤치마크에서 소타(SoTA)를 성립한다. 특히, 문맥에서만 해결할 수 있는 언어-모호 단어와 영어와 독일어 형태소가 혼합된 단어에 대해 체계적으로 코드 스위칭을 연구하였다.

###### Towards Real-World Streaming Speech Translation for Code-Switched Speech (https://aclanthology.org/2023.calcs-1.2/)
- Anthology ID: 2023.calcs-1.2 
- Volume: Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching 
- Summary: 
    1. code-switching (CS), 즉 한 문장에서 여러 언어를 섞는 현상은 많은 자연어 처리(NLP) 상황에서 도전적일 수 있으며, 이에 대한 연구는 오프라인 시나리오에 제한되어 왔다.
    2. 우리는 실제 세계의 CS 음성 번역을 위해 두 가지 핵심적이고 탐구되지 않은 영역에 초점을 맞추고자 한다: 스트리밍 설정 및 소스에 포함되지 않은 제3 언어로의 번역.
    3. 이를 위해 Fisher와 Miami 테스트 및 검증 데이터셋을 확장하여 스페인어와 독일어로 변환하는 모델을 학습하고, 오프라인 및 스트리밍 ST의 기준 결과를 수립한다.

###### Language Preference for Expression of Sentiment for Nepali-English Bilingual Speakers on Social Media (https://aclanthology.org/2023.calcs-1.3/)
- Anthology ID: 2023.calcs-1.3 
- Volume: Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching 
- Summary: 
    1. 네팔-영어 코드 스위칭은 특히 소셜 미디어에서 네팔 사회에서 확장되고 있는 현상이다. 코드 스위칭 텍스트는 다중 언어 사용자의 사회 언어 행동을 이해하는 데 활용될 수 있다.
    2. 본 논문에서는 이러한 다중 언어 사용자의 감정 표현에 대한 언어 선호도를 연구한다. 나쁜 감정을 표현하는 데 동종 언어 사용의 선호도가 높은 것으로 나타났다.
    3. 기계 학습 및 트랜스포머 기반 모델을 사용하여 해당 데이터셋에 대해 기준 모델로서 감성 분류를 수행하였고, 이 데이터셋은 공개되었다.

###### Text-Derived Language Identity Incorporation for End-to-End Code-Switching Speech Recognition (https://aclanthology.org/2023.calcs-1.4/)
- Anthology ID: 2023.calcs-1.4 
- Volume: Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching 
- Summary: 
    1. CS(speech의 code-switching) 인식은 짧은 단일 언어 세그먼트에서의 제한된 언어적 맥락으로 인해 자동 음성인식 시스템에 어려움을 줄 수 있는데, LID(language identity)는 이러한 문제를 완화하기 위해 음성인식 시스템에 통합된다. 
    2. 이전 연구는 주로 음성 신호에서 LID를 추출하는데 초점을 맞추었지만 본 논문은 순수한 텍스트 데이터에서 LID를 학습하는 새로운 접근법을 소개한다. 
    3. 텍스트 기반 LID를 통합하는 두 가지 전략인 LID 상태 퓨전과 언어 사후 편향을 탐구하여 LID를 엔드 투 엔드 ASR(음성인식) 시스템에 통합한다.

###### Prompting Multilingual Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages (https://aclanthology.org/2023.calcs-1.5/)
- Anthology ID: 2023.calcs-1.5 
- Volume: Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching 
- Summary: 
    1. 음성 인터페이스의 행동 모델의 의사결정 차이를 기존의 절대 성능 측정 지표로는 정확히 파악하기 어렵다.
    2. 이 논문에서는 두 대화 행동 모델의 유사도를 계산하는 일반적인 방법론을 제안하고, 의미 및 텍스트 수준에서 점수를 계산하는 다양한 방식을 조사한다.
    3. 절대 성능 측정 기준을 보완하기 위해, 우리는 이러한 점수를 세 가지 다른 작업에 적용하고 측정 방법의 실용성을 보여준다.

###### CONFLATOR: Incorporating Switching Point based Rotatory Positional Encodings for Code-Mixed Language Modeling (https://aclanthology.org/2023.calcs-1.6/)
- Anthology ID: 2023.calcs-1.6 
- Volume: Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching 
- Summary: 
    1. 코드믹스(CM)는 두 개 이상의 언어를 혼용하는 것으로, 트랜스포머와 같은 NLP 모델은 많은 태스크에서 효과적이었으나, CM에 대해서는 아직 잘 연구되지 않은 분야이다.
    2. 이 논문에서는 트랜스포머의 비결정적인 특성으로 인해 위치 정보를 항상 인코딩할 수 없다는 문제점을 제시하고, 위치 인코딩을 통해 단어 정보를 풍부하게 만들고 위치 정보를 결합하여 CM 언어 모델링에 특히 switching points에 주의를 기울인다.
    3. 실험 결과, rotatory positional encoding과 switching point 정보를 결합한 방법이 가장 좋은 결과를 얻는 것을 보여주었다. CONFLATOR은 코드믹스된 힌디어와 영어 (힌글리쉬)를 기반으로 하는 두 가지 태스크인 감성 분석 및 기계 번역에서 최신 기술을 능가한다.

###### Unified Model for Code-Switching Speech Recognition and Language Identification Based on Concatenated Tokenizer (https://aclanthology.org/2023.calcs-1.7/)
- Anthology ID: 2023.calcs-1.7 
- Volume: Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching 
- Summary: 
    1. Code-Switching (CS) 다중 언어 자동음성인식(ASR) 모델은 대화 중에 두 개 이상의 번갈아가며 사용되는 언어를 변환할 수 있다. 
    2. 본 논문에서는 (1) 완전히 단일 언어 데이터 소스에서 code-switching ASR 데이터셋을 생성하는 새로운 방법과 (2) 기존의 단일 언어 토크나이저를 재사용하면서 ASR 모델이 각 발행된 텍스트 토큰에 대한 언어 ID를 생성할 수 있는 새로운 Concatenated Tokenizer를 제안한다. 
    3. 제안된 방법들은 영어-힌디어 및 영어-스페인어 두 언어 쌍에 대해 CS ASR 모델을 구축하는 데 효과적이며, Miami Bangor CS 평가 말뭉치에서 새로운 최첨단 결과를 달성한다. 또한, 제안된 Concatenated Tokenizer 모델은 경쟁력 있는 ASR 성능과 함께, FLEURS 데이터셋에서 98% 이상의 언어 식별 정확도를 달성한다.

###### Multilingual self-supervised speech representations improve the speech recognition of low-resource African languages with codeswitching (https://aclanthology.org/2023.calcs-1.8/)
- Anthology ID: 2023.calcs-1.8 
- Volume: Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching 
- Summary: 
    1. 저 자원 언어를 구사하는 많은 사용자들이 다른 지역 언어나 영어로 코드 스위칭(code-switching)을 자주하는 반면, 코드스위치된 음성 데이터셋은 맞춤형 음향 모델을 처음부터 훈련하거나 언어 모델 재스코어링을 할 만큼 충분하지 않다.
    2. 우리는 self-supervised speech representations (wav2vec 2.0 XLSR)을 코드스위치 데이터 인식에 fine-tuning 하는 방법을 제안한다.
    3. 실험 결과, 유한한 훈련 데이터 상황에서 self-supervised 표현의 fine-tuning이 성능 면에서 더 좋은 결과를 보여주는 것으로 나타나며, 유망한 대안이 될 수 있다.


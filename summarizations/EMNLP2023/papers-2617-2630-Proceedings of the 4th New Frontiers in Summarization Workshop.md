# Korean Three-Line Summarizations of Papers 2617-2630 in Proceedings of the 4th New Frontiers in Summarization Workshop
###### Proceedings of the 4th New Frontiers in Summarization Workshop (https://aclanthology.org/2023.newsum-1.0/)
- Anthology ID: 2023.newsum-1.0 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Authors:  
- Summary: 
    요약문을 생성할 수 없습니다.

###### Is ChatGPT a Good NLG Evaluator? A Preliminary Study (https://aclanthology.org/2023.newsum-1.1/)
- Anthology ID: 2023.newsum-1.1 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Authors: Yue Dong | Wen Xiao | Lu Wang | Fei Liu | Giuseppe Carenini 
- Summary: 
    1. 최근에는 ChatGPT의 등장으로 컴퓨터 언어학 커뮤니티에서 많은 관심을 받고 있다. 하지만 ChatGPT가 평가 지표로 사용될 수 있는 능력은 아직 탐구되지 않았다. 이 논문에서는 ChatGPT를 자연어 생성 모델(NLG)의 평가 지표로 사용하기 위한 메타-평가를 수행하였다. 
    2. ChatGPT를 사람의 판단자로 간주하여 NLG 모델의 생성 결과를 평가하도록 유도하고, NLG 메타-평가 데이터셋에 대한 실험 결과를 보여준다. 결과는 이전의 자동 평가 메트릭과 비교하여 대부분에서 사람의 판단과 상당한 상관관계를 가지고 있음을 보여준다.
    3. 그러나 ChatGPT 평가자의 효과는 메타-평가 데이터셋의 생성 방법에 따라 영향을 받을 수 있다. 레퍼런스에 크게 의존하여 편향된 메타-평가 데이터셋의 경우에는 ChatGPT 평가자의 효과가 떨어질 수 있다.

###### Zero-Shot Cross-Lingual Summarization via Large Language Models (https://aclanthology.org/2023.newsum-1.2/)
- Anthology ID: 2023.newsum-1.2 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Authors: Yue Dong | Wen Xiao | Lu Wang | Fei Liu | Giuseppe Carenini 
- Summary: 
    1. 소스 언어로 된 문서가 주어졌을 때, 크로스-리지널 요약(CLS)은 다른 대상 언어로 요약문을 생성하는 것을 목표로 한다. 
    2. 이 논문에서는 다양한 프롬프트를 사용하여 대형 언어 모델 (LLM)이 다른 패러다임 (end-to-end 및 pipeline)으로 제로샷 CLS를 수행하는 데 어떻게 활용될 수 있는지를 실험적으로 평가한다.
    3. 실험 결과, ChatGPT와 GPT-4는 원래 자세한 정보가 포함된 긴 요약문을 생성하는 경향이 있지만, 상호작용적인 프롬프트의 도움으로 정보성과 간결성을 균형있게 조절하여 CLS 성능을 크게 향상시킬 수 있다는 것을 보여준다.

###### SimCSum: Joint Learning of Simplification and Cross-lingual Summarization for Cross-lingual Science Journalism (https://aclanthology.org/2023.newsum-1.3/)
- Anthology ID: 2023.newsum-1.3 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Authors: Yue Dong | Wen Xiao | Lu Wang | Fei Liu | Giuseppe Carenini 
- Summary: 
    1. 최근에 소개된 Cross-lingual science journalism은 비전문가 독자를 위해 원본 언어와 다른 언어로 과학 기사를 요약하는 작업이다.
    2. 기존의 파이프라인 모델은 텍스트 간략화와 크로스-리지날 summarization을 결합하여 이 작업을 수행했으나, 우리는 멀티 태스크 학습 아키텍처를 도입하여 이 작업을 확장한다.
    3. 우리의 접근 방식은 우리가 제안한 SimCSum에서 크로스-리지날 popular science summary를 생성하기 위해 두 가지 NLP tasks를 공동으로 훈련하는 것이다.

###### Extract, Select and Rewrite: A Modular Sentence Summarization Method (https://aclanthology.org/2023.newsum-1.4/)
- Anthology ID: 2023.newsum-1.4 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Authors: Yue Dong | Wen Xiao | Lu Wang | Fei Liu | Giuseppe Carenini 
- Summary: 
    1. 모듈식 접근법은 대부분의 end-to-end 모델과 비교했을 때 합성 가능성과 제어 가능성이 있다는 장점을 가지고 있다.
    2. 본 논문에서는 Extract-Select-Rewrite (ESR)라는 세 단계의 추상적 문장 요약 방법을 제안한다.
    3. ESR은 요약을 세 단계로 분해하여 지식 추출, 내용 선택, 그리고 재작성으로 나누고, 최고 수준의 end-to-end 모델과 비교하여 경쟁력을 보이면서 보다 충실한 결과를 얻을 수 있다.

###### Summarization-based Data Augmentation for Document Classification (https://aclanthology.org/2023.newsum-1.5/)
- Anthology ID: 2023.newsum-1.5 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Authors: Yue Dong | Wen Xiao | Lu Wang | Fei Liu | Giuseppe Carenini 
- Summary: 
    1. 사전학습 언어 모델은 일반적인 자연어 이해 작업에서 널리 쓰이지만, 긴 글 (document)과 같은 텍스트를 이해하는 것은 데이터 희소성의 문제로 여전히 어렵다고 할 수 있다.
    2. 우리는 사람들이 짧은 텍스트를 읽고 긴 텍스트를 이해하는 능력을 개발하는 것에서 영감을 받아, document 분류를 위한 간단하고 효과적인 요약 기반 데이터 증강 (data augmentation)인 SUMMaug를 제안한다.
    3. 우리는 우리의 방법이 강건성과 정확성 측면에서 기존 기준선 방법들과 비교하여 이점을 확인하기 위해 두 데이터셋에서의 실험 결과를 발표하며, 코드와 데이터를 공개한다.

###### In-context Learning of Large Language Models for Controlled Dialogue Summarization: A Holistic Benchmark and Empirical Analysis (https://aclanthology.org/2023.newsum-1.6/)
- Anthology ID: 2023.newsum-1.6 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Authors: Yue Dong | Wen Xiao | Lu Wang | Fei Liu | Giuseppe Carenini 
- Summary: 
    1. 대규모 언어 모델 (LLM)은 요약 및 제어 텍스트 생성을 포함한 다양한 NLP 작업에서 뛰어난 성능을 보였다. 그 중 하나인 in-context learning (ICL)은 모델이 파라미터 업데이트 없이 prompt의 입력-출력 쌍을 사용하여 새로운 작업을 학습하는 기능이다.
    2. 그러나 LLM의 few-shot 요약 대화 요약에서의 성능은 아직 충분히 탐구되지 않았다. 이 연구는 SAMSum 데이터셋을 기반으로 다양한 최신 LLM 모델을 few-shot framework에서 평가한다.
    3. 우리는 제어된 설정 (엔티티 제어, 길이 제어, 인물 중심 계획)과 제어되지 않은 설정에서 이러한 모델을 평가하고, few-shot 대화 요약에 대한 포괄적인 벤치마크를 제시한다.

###### From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting (https://aclanthology.org/2023.newsum-1.7/)
- Anthology ID: 2023.newsum-1.7 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Authors: Yue Dong | Wen Xiao | Lu Wang | Fei Liu | Giuseppe Carenini 
- Summary: 
    1. 요약문 작성에서 적절한 정보의 양을 선택하는 것은 어려운 일이다. 좋은 요약문은 세부적이고 개체 중심적인데 너무 밀집되어 이해하기 어렵지 않아야 한다. 
    2. 이 논문에서는 "밀도 체인"(CoD) 프롬프트를 사용하여 GPT-4 요약문의 밀도 변화에 대해 더 잘 이해하고자 한다. GPT-4는 길이를 늘리지 않고 빠진 중요한 개체를 점차 포함시키는 과정을 통해 요약문을 생성한다.
    3. 100개의 뉴스 기사에 대한 인간 선호도 조사 결과, GPT-4 요약문 중 CoD를 사용한 요약문이 기존 요약문보다 더 밀집되며, 사람이 작성한 요약문과 거의 비슷한 선호도를 보였다. 인과관계 및 가독성 사이에는 트레이드오프가 존재한다는 것을 질적 분석을 통해 확인하였다.

###### Generating Extractive and Abstractive Summaries in Parallel from Scientific Articles Incorporating Citing Statements (https://aclanthology.org/2023.newsum-1.8/)
- Anthology ID: 2023.newsum-1.8 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Authors: Yue Dong | Wen Xiao | Lu Wang | Fei Liu | Giuseppe Carenini 
- Summary: 
    1. 모든 과학 논문에 대한 요약은 문서의 내용에만 초점을 맞추고, 인용 논문의 통찰력을 간과하기 쉽다. 
    2. 우리는 소스 및 인용 문서의 정보를 활용하여 과학 문서를 요약하는 모델을 개발했다. 
    3. 이 모델은 추상적 및 추출적 요약을 동시에 생성하며, 각각이 다른 요약 기법을 보완하여 고품질 요약을 만든다.

###### Supervising the Centroid Baseline for Extractive Multi-Document Summarization (https://aclanthology.org/2023.newsum-1.9/)
- Anthology ID: 2023.newsum-1.9 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Authors: Yue Dong | Wen Xiao | Lu Wang | Fei Liu | Giuseppe Carenini 
- Summary: 
    1. Centroid 방법은 extractive multi-document summarization을 위한 간단한 접근 방식이지만, 문장 선택에 beam search 과정을 추가하고 centroid estimation attention 모델을 도입하여 결과를 향상시켰다.
    2. 이를 여러 개의 multi-document summarization 데이터셋에서 증명하였고, 다국어 시나리오에서도 적용할 수 있는 것을 보였다.

###### DebateKG – Automatic Policy Debate Case Creation with Semantic Knowledge Graphs (https://aclanthology.org/2023.newsum-1.10/)
- Anthology ID: 2023.newsum-1.10 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Authors: Yue Dong | Wen Xiao | Lu Wang | Fei Liu | Giuseppe Carenini 
- Summary: 
    1. 최근 연구에서는 논쟁 분야에서 발견된 문제를 해결하기 위해 자연어처리 시스템의 적용 가능성을 보여주고 있다. 이 연구에서는 "Policy Debate"라는 유형의 경쟁 토론에서 경쟁자들이 고품질 토론 주제를 만드는 작업에 대해 조사하고 있다.
    2. 우리는 인수적 의미 지식 그래프를 사용하여 제약 최단 경로 탐색을 통해 효과적인 토론 주제를 구축할 수 있다는 것을 보여주었다.
    3. 또한, 우리는 "DebateSum"이라고 불리는 대규모 데이터셋을 보완하여 53180개의 새로운 예제와 각각의 예제에 대한 추가적인 메타데이터를 도입하였다.

###### Unsupervised Opinion Summarization Using Approximate Geodesics (https://aclanthology.org/2023.newsum-1.11/)
- Anthology ID: 2023.newsum-1.11 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Authors: Yue Dong | Wen Xiao | Lu Wang | Fei Liu | Giuseppe Carenini 
- Summary: 
    1. 의견 요약은 사용자 리뷰에서 인기있는 의견을 요약하는 작업이며, 이 논문에서는 GeoSumm이라는 새로운 시스템을 소개한다. GeoSumm은 의견 요약을 수행하기 위한 encoder-decoder 기반의 표현 학습 모델로, 토피컬 표현을 생성하여 텍스트의 기저 의미를 포착한다.
    2. GeoSumm은 사전 훈련된 텍스트 표현의 여러 계층에서 사전 학습을 통해 토피컬 표현을 생성하고, 이를 사용하여 신규 거리 기반 점수화 메커니즘을 통해 리뷰 문장의 중요성을 측정한다.
    3. GeoSumm은 일반적이고 측면별 요약을 구성하기 위해 중요도 점수를 사용하며, 3개의 의견 요약 데이터셋에서 강력한 성능을 달성한다. 추가 실험을 통해 모델의 기능을 분석하고, GeoSumm의 도메인 간 일반화 능력을 보여준다.

###### Analyzing Multi-Sentence Aggregation in Abstractive Summarization via the Shapley Value (https://aclanthology.org/2023.newsum-1.12/)
- Anthology ID: 2023.newsum-1.12 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Authors: Yue Dong | Wen Xiao | Lu Wang | Fei Liu | Giuseppe Carenini 
- Summary: 
    1. 개요 요약 시스템은 입력 문서의 가장 핵심적인 정보를 자기 말로 간결하게 요약하는 것을 목표로 한다. 이를 위해 여러 정보 조각을 모아 결합하는 과정, aggregation이 필요하다. 그러나 기존에는 벤치마크 데이터셋의 참조 요약과 시스템 생성 요약이 얼마나 aggregation을 필요로 하는지 알 수 없다.
    2. 이 논문에서는 AggSHAP라는 aggregation 정도를 측정하기 위한 지표를 제안한다. 그리고 자동 및 인간 평가를 통해 AggSHAP가 여러 문장을 모으는 작업을 단문 추출이나 단문 재구성과 구분할 수 있다는 것을 보여준다. 
    3. 참조나 모델 생성 요약에서 AggSHAP에 기반한 aggregation 정도가 높은 문장은 매우 적다는 것을 발견했으며, 또한 AggSHAP와 다른 요약 품질 점수와의 음의 상관관계도 보였다. 이러한 결과는 요약에서 여러 문장 aggregation을 촉진하는 새로운 작업과 데이터셋을 개발해야 한다는 필요성을 시사한다.

###### Improving Multi-Stage Long Document Summarization with Enhanced Coarse Summarizer (https://aclanthology.org/2023.newsum-1.13/)
- Anthology ID: 2023.newsum-1.13 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Authors: Yue Dong | Wen Xiao | Lu Wang | Fei Liu | Giuseppe Carenini 
- Summary: 
    1. "다단계 장문 요약은 긴 문서를 여러 세그먼트로 나누고 각 세그먼트를 사용하여 다단계로 일반적인 요약을 생성하는 유연한 접근 방식이다." 
    2. "기존의 다단계 요약에서 코스 요약기는 최종 요약을 생성하는 데 유용하지 않은 데이터 세그먼트로 미세하게 훈련된다." 
    3. "본 논문에서는 최종 요약 생성에 필요한 관련 세그먼트로만 새로운 세그먼트 쌍을 생성하고 대조 학습을 통해 미세 요약 모델을 훈련하는 새로운 다단계 장문 요약 방법을 제안한다."


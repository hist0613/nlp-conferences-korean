# Korean Three-Line Summarizations of Papers 401-500 in Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing
###### Pre-Trained Language Models Augmented with Synthetic Scanpaths for Natural Language Understanding (https://aclanthology.org/2023.emnlp-main.400/)
- Anthology ID: 2023.emnlp-main.400 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인간 시선 데이터는 자연어 이해를 반영하는 인지적 정보를 제공한다. 
    2. 이 논문에서 제안한 모델은 synthetic scanpath generation을 활용하여 인간 시선 데이터 없이도 scanpath를 증강된 언어 모델에 통합시키는 모델을 개발하였다. 
    3. 실험 결과, proposed model은 원래 언어 모델보다 우수한 성능을 보이며, 실제 인간 시선 데이터로 증강된 언어 모델과 비교 가능한 성능을 달성하였다.

###### Counting the Bugs in ChatGPT’s Wugs: A Multilingual Investigation into the Morphological Capabilities of a Large Language Model (https://aclanthology.org/2023.emnlp-main.401/)
- Anthology ID: 2023.emnlp-main.401 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근엔 LLMs가 인간의 언어 능력과 비교되며 놀라운 언어 능력을 갖추게 되었지만, 최신 LLMs의 언어 능력에 대한 체계적인 조사는 상대적으로 적었으며, 대부분은 (i) 인간의 일반화능력을 고려하지 않고, (ii) 영어만을 중점적으로 다루며, (iii) 문법이나 의미론을 조사하며 단어형태로부터 발생하는 다른 능력은 무시되었다.
    2. 우리는 오히려 사람과 인과관계를 맺어 사물을 이해하지 못하는 능력을 갖추고 있음을 증명하는 ChatGPT의 형태론 능력에 대해 최초로 철저한 분석을 실시하였다. 
    3. 우리는 ChatGPT의 형태론 능력은 특히 영어에서 효과적인 시스템보다 현저히 낮은 성능을 보이는 것을 발견하였으며, 전반적으로, 우리의 결과는 형태론적인 측면에서 ChatGPT의 언어 능력에 대한 새로운 시각을 제공하며, 인간과 유사한 언어 능력이라는 주장은 이르고도 오도하는 것이라고 주장한다.

###### Adapt in Contexts: Retrieval-Augmented Domain Adaptation via In-Context Learning (https://aclanthology.org/2023.emnlp-main.402/)
- Anthology ID: 2023.emnlp-main.402 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. LLM은 few-shot 추론의 in-context 학습력을 갖추었으나, 실제 상황에서는 in-domain 데이터가 항상 이용 가능치 않아 cross-domain in-context 학습이 필요하다.
    2. 이 논문에서는 unsupervised domain adaptation 문제를 in-context 학습 방식으로 다루며, target 라벨을 사용하지 않고 source domain에서 target domain으로 언어 모델을 적응시킨다.
    3. 쿼리에 가장 유사한 cross-domain 요소들의 하위 집합을 검색하여 augmented cross-domain in-context 예제와 함께 대상 도메인 분포와 식별적 특징을 동시에 학습하여 언어 모델을 적응시킨다.

###### Understanding the Inner-workings of Language Models Through Representation Dissimilarity (https://aclanthology.org/2023.emnlp-main.403/)
- Anthology ID: 2023.emnlp-main.403 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 실제 응용에서 언어 모델을 적용함에 따라 모델의 신뢰도, 해석 가능성 및 투명성에 대한 이해는 중요한 문제로 대두되고 있다.
    2. 이 연구에서는 두 모델 내부 표현의 차이를 측정하는 기능인 representation dissimilarity measures가 언어 모델의 작동 원리를 이해하는 데 유용한 도구일 수 있다는 것을 보여준다.
    3. 우리의 결과는 차이 측정이 언어 모델의 내부 작동에 대한 통찰력을 제공하는 유망한 도구 집합이라는 것을 시사한다.

###### Efficient Classification of Long Documents via State-Space Models (https://aclanthology.org/2023.emnlp-main.404/)
- Anthology ID: 2023.emnlp-main.404 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 실제 상황에서 많이 나오는 긴 문서는 변환기 모델들의 기본적인 self-attention 모듈로 효율적으로 처리할 수 없는데, 이 논문에서는 이러한 문제를 해결하기 위해 상태 공간 모델(State-Space Models, SSMs)을 사용하여 처리하였다. 
    2. SSM을 사용한 모델과 self-attention 기반 모델을 비교하여, 이 논문에서는 이러한 모델들이 binary, multi-class, multi-label classification 등 다양한 긴 문서 분류 작업에서 효과적임을 실험적으로 보여주었다.
    3. 또한, SSM-pooler 모델을 소개하고 평균적으로 36% 더 효율적인 성능을 보이면서 입력 noise에 대해 더 강한 안정성을 나타내었다.

###### Dual-Feedback Knowledge Retrieval for Task-Oriented Dialogue Systems (https://aclanthology.org/2023.emnlp-main.405/)
- Anthology ID: 2023.emnlp-main.405 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 역할을 완수하기 위해 사용자 요청을 충족시키기 위해 필요한 관련 정보를 선택하기 위해 효과적인 지식 검색은 end-to-end task-oriented 대화 시스템의 성공을 보장하는 데 중요한 역할을 한다. 
    2. 현재의 접근법은 지식 검색과 응답 생성을 일반적으로 통합하는데, 이는 광범위한 지식 베이스를 다룰 때 확장성에 도전을 제기한다.
    3. 이 논문에서는 오픈 도메인 질의응답에서 영감을 받은 retriever-generator 구조를 제안하고, retriever를 사용하여 관련 지식을 검색하고 generator를 활용하여 시스템 응답을 생성한다.

###### Construction Artifacts in Metaphor Identification Datasets (https://aclanthology.org/2023.emnlp-main.406/)
- Anthology ID: 2023.emnlp-main.406 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 여러 암시적 비유 식별 데이터셋은 비유 표현이나 문맥을 완전히 무시함으로써 게임으로 조작될 수 있다는 것을 보여준다.
    2. 우리는 여러 데이터셋과 설정에서 이 가설을 검증하고, 완전한 정보 없이 언어 모델에 기반한 비유 식별 시스템이 완전한 문맥을 사용하는 시스템과 경쟁력을 갖을 수 있다고 보여준다.
    3. 이러한 결과는 데이터셋 구축 절차 때문에 긍정 및 부정 클래스에 원치 않는 편향을 도입하기 때문이다.

###### MAF: Multi-Aspect Feedback for Improving Reasoning in Large Language Models (https://aclanthology.org/2023.emnlp-main.407/)
- Anthology ID: 2023.emnlp-main.407 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어 모델은 다양한 자연어 태스크에서 높은 성능을 보여주지만, 자연어 추론과 같은 경우 잘못된 중간 추론 단계 생성, 수학적 오류 등의 문제가 있다. 
    2. 이 논문에서는 여러 종류의 오류에 대한 다양한 피드백 모듈을 통합하여 언어 모델의 성능을 향상시키는 **Multi-Aspect Feedback** 프레임워크를 제안한다. 
    3. 실험 결과, 이 방법을 사용하면 언어 모델의 추론 체인에서 발생하는 여러 오류를 해결하고, 수학 추론에서 최대 20%와 논리 함의에서 최대 18%의 성능 향상을 보였다.

###### Granularity Matters: Pathological Graph-driven Cross-modal Alignment for Brain CT Report Generation (https://aclanthology.org/2023.emnlp-main.408/)
- Anthology ID: 2023.emnlp-main.408 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자동 뇌 CT 보고서 생성은 두뇌 질환의 진단 효율과 정확성을 향상시킬 수 있다. 하지만 현재의 방법은 1) 세부적인 비정상성 인식을 위한 상세한 지도 정보가 부족한 이미지-텍스트 형식의 훈련 데이터에 의해 제한되고, 2) 시각-텍스트 정렬이 거칠게 결합되어 보고서 생성을 위한 복잡한 피처 표현을 초래하는 문제가 있다. 
    2. 우리는 정확하고 견고한 뇌 CT 보고서 생성을 위한 신규 경로 그래프 기반 교모달 정렬 (PGCA) 모델을 제안한다. 저희 방법은 섬세한 조직과 병변에 대한 시각적 단서를 배우고 텍스트 단어와 일치시키기 위해 병태 그래프를 구성하여 교모달 정렬을 효과적으로 해제한다.
    3. 그래프 내에서 핵심적인 병태 속성을 나타내는 이질적인 노드들을 도메인 지식과의 사전 정보를 통해 연결하고, 그래프 임베딩과 업데이트 모듈을 통해 시각적 피처를 섬세하게 정제하여 텍스트 단어와 일치시킨다. 방대한 실험 결과는 우리 방법의 타당성을 확인한다. 우리의 PGCA 모델은 뇌 CT 보고서의 자동 생성을 크게 향상시키고 최종적으로 두뇌 질환 진단에 기여할 것으로 기대한다.

###### Enhancing Structured Evidence Extraction for Fact Verification (https://aclanthology.org/2023.emnlp-main.409/)
- Anthology ID: 2023.emnlp-main.409 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 오픈 도메인 사실 검증은 청구 사실을 추출된 증거와 대조하여 확인하는 작업이다.
    2. 이전 모델들은 테이블 추출과 셀 선택의 단계에서 구조화된 증거의 재현율이 낮은 문제를 겪고 있다.
    3. 이 연구에서는 테이블의 행과 열 의미를 활용하여 구조화된 증거 추출의 정확도를 향상시키는 간단하면서도 효과적인 방법을 제안한다.

###### Rethinking Model Selection and Decoding for Keyphrase Generation with Pre-trained Sequence-to-Sequence Models (https://aclanthology.org/2023.emnlp-main.410/)
- Anthology ID: 2023.emnlp-main.410 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 키워드 생성(KPG)은 NLP에서 오래된 작업으로 널리 활용되고 있다. 그러나, 모델 선택과 디코딩 전략의 영향에 대한 체계적인 분석이 이루어지지 않아 임의로 결정되기도 한다.
    2. 이 논문에서는 seq2seq 기반 언어 모델의 선택과 디코딩 전략이 KPG에 미치는 영향을 체계적으로 분석하였다.
    3. 그 결과, 기본적으로 큰 모델 크기나 과제 특화적 adaptation은 매개 변수 효율성이 떨어지며, 도메인 내 사전 훈련과 과제 적응 결합은 일부적으로 일반화를 방해할 수 있음을 보여준다. 또한, DeSel 디코딩 알고리즘을 제안하여 greedy search보다 우수한 성능을 얻을 수 있다.

###### A Fair and In-Depth Evaluation of Existing End-to-End Entity Linking Systems (https://aclanthology.org/2023.emnlp-main.411/)
- Anthology ID: 2023.emnlp-main.411 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존 entity linking 시스템들의 평가는 특정 응용 분야에서 성능을 어떻게 발휘할지에 대해 거의 설명하지 않는다.
    2. 이 논문은 다양한 기존 end-to-end entity linker들을 의미 있는 방식으로 깊이 있는 평가하고 강점과 약점을 성격화하며, 재현성 측면에 대해서도 보고한다.
    3. 우리의 평가는 위에서 언급한 문제들을 다루는 데 어느 정도 애로사항이 있는 여러 유명한 벤치마크와 두 개의 새로운 벤치마크를 기반으로 한다.

###### A Multi-Task Dataset for Assessing Discourse Coherence in Chinese Essays: Structure, Theme, and Logic Analysis (https://aclanthology.org/2023.emnlp-main.412/)
- Anthology ID: 2023.emnlp-main.412 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "중국어 에세이 담론 일관성 코퍼스 (CEDCC)"는 담론 일관성을 평가하기 위한 다중 작업 데이터셋으로, 기존 연구는 담론 일관성의 고립된 측면에 초점을 맞추었다. CEDCC는 일관성 평가, 주제 연속성, 담론 관계를 통합하여 이러한 빈 공간을 채우는 데 기여하며, 상세한 주석을 통해 현실적인 텍스트의 세세한 면을 포착하여 중국어 담론 일관성 분석의 진전을 촉진한다.
    2. 우리의 기여는 CEDCC의 개발, 추가 연구를 위한 기준선의 확립, 그리고 일관성이 담론 관계 인식과 자동 에세이 점수에 미치는 영향을 시연하는 것이다.
    3. 이 데이터셋과 관련 코드는 https://github.com/cubenlp/CEDCC_corpus에서 이용할 수 있습니다.

###### SKD-NER: Continual Named Entity Recognition via Span-based Knowledge Distillation with Reinforcement Learning (https://aclanthology.org/2023.emnlp-main.413/)
- Anthology ID: 2023.emnlp-main.413 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. '지속적인 학습을 위한 개체명 인식(CL-NER)'은 모델이 이전에 학습한 개체 유형을 인식하는 능력을 유지하면서 새로운 개체 유형을 계속 학습할 수 있도록 하는 것을 목표로 한다. 하지만 이전에 학습한 개체 유형의 catastrophic forgetting 문제를 효과적으로 해결하는 현재의 전략은 실패하고 있다.
    2. 이 문제를 해결하기 위해 우리는 SKD-NER 모델을 제안한다. 이 모델은 개체기반 접근 방식을 기반으로 하며, 강화학습 전략을 혁신적으로 포함시켜 catastrophic forgetting에 대한 모델의 능력을 향상시킨다.
    3. 우리의 실험 결과는 우리의 모델이 CL-NER 작업의 성능을 현저하게 향상시키며, 최첨단 방법들을 앞지른다는 것을 보여준다.

###### Lifelong Sequence Generation with Dynamic Module Expansion and Adaptation (https://aclanthology.org/2023.emnlp-main.414/)
- Anthology ID: 2023.emnlp-main.414 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. lifelong sequence generation(LSG)은 지속적인 학습에서 모델을 일련의 생성 작업에 지속적으로 훈련시키는 것을 목표로 하며, 새로운 생성 패턴을 지속적으로 학습하면서도 이전 지식을 잊지 않는 것이다.
    2. 기존 LSG 방법들은 이전 지식 유지에 중점을 두고 있으며 과업간 지식 전이에 관심을 덜 가지고 있다. 
    3. DMEA는 과업 상관관계에 기초하여 새로운 지식을 습득하기 위한 동적 아키텍처 결정 및 새로운 과업에 대한 적응을 용이하게 하는 가장 유사한 이전 과업을 선택하는 기능을 제공한다.

###### When the Majority is Wrong: Modeling Annotator Disagreement for Subjective Tasks (https://aclanthology.org/2023.emnlp-main.415/)
- Anthology ID: 2023.emnlp-main.415 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기계 학습에서 전체 투표는 hate speech 탐지와 같은 작업에서 annotator 간의 의견 차이는 노이즈가 아닌 의견의 체계적 차이를 반영할 수 있다. 이에, 작은 그룹으로부터의 공격적인 문장인지를 판단하는 것이 중요하다. 
    2. 우리는 잠재적으로 공격적인 텍스트에 대한 개별 annotator의 등급을 예측하고, 이 정보를 텍스트의 예측된 대상 그룹과 결합하여 대상 그룹 구성원의 등급을 예측하는 모델을 구성한다. 
    3. 우리는 다양한 메트릭에서 성능을 향상시키며, 개별 annotator 등급 예측에서 22%의 기준선을 높이고, annotator 간 분산 예측에서는 33%의 성능 향상을 보였으며, 이는 모델의 불확실성 메트릭을 제공한다. 또한, annotator의 의견은 온라인 콘텐츠의 의견과 함께 demograhic 정보를 사용하여 예측할 수 있으며, invasive하지 않은 질문을 통해 annotator의 온라인 경험을 최소화하여 demograhic 정보 수집의 필요성을 줄일 수 있다.

###### Lazy-k Decoding: Constrained Decoding for Information Extraction (https://aclanthology.org/2023.emnlp-main.416/)
- Anthology ID: 2023.emnlp-main.416 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 본 논문은 구조화된 예측에서 확률적 모델을 개선하는 가능성을 탐구한다. 특히, 정보 추출을 위한 토큰 분류의 맥락에서 제약 조건 디코딩 방법과 모델을 결합한다.
    2. 디코딩 방법들은 제약 조건을 만족하는 라벨 할당을 찾으면서 전체 확률을 최대화한다.
    3. 실험 결과, 작은 모델을 사용할 때 특히 제약 조건 디코딩 방법이 모델의 성능을 크게 개선할 수 있음을 보여주었다.

###### Personalized Distillation: Empowering Open-Sourced LLMs with Adaptive Learning for Code Generation (https://aclanthology.org/2023.emnlp-main.417/)
- Anthology ID: 2023.emnlp-main.417 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 강력한 닫힌 소스 LLMs (ChatGPT, GPT-4)의 등장으로 닫힌 소스 LLMs의 능력을 작은 오픈 소스 LLMs에 전달하는 데 관심이 높아졌습니다.
    2. 기존의 전수 지식 추출 방법은 학생 모델이 배울 수 있도록 ChatGPT에게 명령과 답변 집합을 생성하도록 하는 것이었습니다.
    3. 그러나 이 논문에서는 학생 모델의 장점과 조건을 간과하지 않도록 개인화된 전수 과정을 설계하여 학생 모델에 대한 개인화된 학습을 가능하게 함으로써 표준적인 전수 방법을 능가하였습니다.

###### Do Language Models Have a Common Sense regarding Time? Revisiting Temporal Commonsense Reasoning in the Era of Large Language Models (https://aclanthology.org/2023.emnlp-main.418/)
- Anthology ID: 2023.emnlp-main.418 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 시계열 추론은 인간의 의사 소통과 이해에 있어 중요한 요소이지만, 큰 언어 모델에서는 아직까지 미개척된 분야이다. 이 논문에서는 큰 언어 모델 (LLM)의 시계열 추론 능력에 대한 첫 번째로 광범위한 벤치마킹을 제공한다. 
    2. 6개의 데이터셋에서 8개의 다른 언어 모델을 사용하여 3가지 서로 다른 프롬프팅 전략을 통해 본 모델을 평가했다.
    3. 시계열 작업의 다양한 범주에서의 성능을 세분화 조사하고, 이를 통해 모델의 시간적 측면에서 이벤트의 연속성, 순서, 진행을 이해하고 예측하는 능력을 분석하였다. 이를 통해 모델의 능력과 한계에 대한 포괄적인 참고 자료를 제공한다.

###### Comparing Styles across Languages (https://aclanthology.org/2023.emnlp-main.419/)
- Anthology ID: 2023.emnlp-main.419 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어 간 스타일 차이를 이해하는 것은 문화적으로 적절한 텍스트를 생성하기 위해 사람과 컴퓨터를 훈련하는데 유리하다.
    2. 이 논문에서는 다국어 언어 모델로부터 스타일적 차이를 추출하는 설명 프레임워크를 소개하고, 언어 간 스타일을 비교한다.
    3. 이 프레임워크는 언어별로 포괄적인 스타일 렉시콘을 생성하고, 언어 모델의 피처 중요도를 비교 가능한 어휘 범주로 통합하는 기능을 제공한다.

###### Event Causality Extraction via Implicit Cause-Effect Interactions (https://aclanthology.org/2023.emnlp-main.420/)
- Anthology ID: 2023.emnlp-main.420 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이벤트 인과관계 추출 (ECE)은 모델이 이벤트 간 인과관계를 캡처하기 위해 강력한 추론 능력을 가져야 하는데, 기존 연구는 인과성 추론에 중요한 단서를 제공할 수 있는 인과이벤트 사이의 상호작용을 충분히 활용하지 못했다.
    2. 우리는 이를 위해 Implicit Cause-Effect interaction (ICE) 프레임워크를 제안하여 ECE를 템플릿 기반의 조건부 생성 문제로 정의한다. 우리의 방법은 개념 추론에 관한 특권 정보 (ground truth event types and arguments)를 활용하여 암묵적인 이벤트 간 상호작용을 캡처하며, 테스트 단계에서 특권 정보의 부재를 완화하기 위해 지식 전달 기계를 도입한다.
    3. 또한, 선생님으로부터 학생으로의 지식 전이를 용이하게 하기 위해 Cause-Effect Optimal Transport (CEOT)라는 이벤트 수준의 정렬 전략을 설계하여 인과성 이벤트 유형과 인수의 의미적 상호작용을 강화한다. 실험 결과는 ICE가 ECE-CCKS 데이터셋에서 최고 수준의 성능을 달성한다는 것을 보여준다.

###### Evaluation of African American Language Bias in Natural Language Generation (https://aclanthology.org/2023.emnlp-main.421/)
- Anthology ID: 2023.emnlp-main.421 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 그동안, 음성인식이나 독성 감지와 같은 작업에서 African American Language (AAL)을 불리하게 하는 편향이 모델에서 발견되었지만, ChatGPT와 같은 언어 생성 모델에 대한 이러한 편향에 대해 조사된 바가 거의 없었습니다.
    2. 우리는 미국 교실에서 권장되는 "표준" 영어인 White Mainstream English (WME)와 비교하여 대규모 언어 모델의 AAL 이해도를 평가했습니다.
    3. 우리는 AAL 텍스트의 새로운 데이터셋을 기반으로 하여, 전처리된 LLMs 6개의 작업 성능 차이를 통해 방언적 편향에 대한 증거를 제시합니다.

###### A Systematic Study of Performance Disparities in Multilingual Task-Oriented Dialogue Systems (https://aclanthology.org/2023.emnlp-main.422/)
- Anthology ID: 2023.emnlp-main.422 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다국어 NLP의 핵심 목표는 세계의 다양한 언어에서 잘 작동하는 강건한 언어 기술을 달성하는 것이다. 이 논문에서는 다양한 다국어 task-oriented dialogue (ToD) 시스템 간의 성능 격차를 정량적으로 측정하고 분석한다.
    2. ToD task, pretrained 언어 모델, 대상 언어, ToD 주석 데이터 양 등 여러 요소에 따라 성능 격차가 발생하는 것을 실험을 통해 입증한다.
    3. 또한 현재의 ToD 시스템에서 적응 (adaptation) 및 내재적 편향 (intrinsic biases)이 존재함을 증명하고, 다양한 언어에서 ToD 데이터 수집 및 시스템 개발에 대한 실용적인 팁을 제공한다.

###### Cognate Transformer for Automated Phonological Reconstruction and Cognate Reflex Prediction (https://aclanthology.org/2023.emnlp-main.423/)
- Anthology ID: 2023.emnlp-main.423 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 역사적 언어학의 중심적인 문제 중 하나인 음운 복원은 자식 언어의 관찰된 공동어로부터 조상 언어의 원어를 결정하는 문제입니다.이 논문에서는 단백질 언어 모델인 MSA Transformer를 음운 복원 문제에 적용하여 모델의 성능을 향상시켰습니다.
    2. MSA Transformer는 다중 시퀀스 정렬을 입력으로 사용하여 여러 개의 관련된 언어 데이터에 적합한 모델입니다. 이 모델을 Cognate Transformer라고 명명하고, 연관된 과제 중 하나인 관련어 반영 예측에도 적용하였습니다.
    3. 실험 결과, Cognate Transformer는 기존 모델보다 음운 복원과 관련어 반영 예측 두 가지 과제에서 우수한 성능을 보였으며, 특히 마스킹된 단어 예측 작업에서 사전 훈련된 경우에 더 효과적인 것으로 나타났습니다.

###### Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning (https://aclanthology.org/2023.emnlp-main.424/)
- Anthology ID: 2023.emnlp-main.424 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 극단적 규모의 언어 모델들은 다양한 언어 태스크에서 탁월한 성능을 보이지만, 순수한 프롬프팅을 통해 이러한 언어 모델을 제어하는 정도는 제한적일 수 있다.
    2. IPA는 fine-tuning 없이도 GPT-3와 같은 언어 모델을 효율적으로 개선하는 방법으로, 경량의 정책 어댑터를 사용하여 임의의 사용자 목적을 최적화하기 위해 강화학습으로 훈련된 대규모 기본 모델을 디코딩 시간에 안내한다.
    3. 텍스트 생성과 같은 다섯 가지 어려운 태스크에서 IPA는 기본 언어 모델보다 지속적인 개선을 가져와 경쟁적인 베이스라인 방법들보다 우월한 결과를 보여준다. 또한, IPA를 사용하여 GPT-2를 개선할 경우 GPT-3를 능가할 수 있으며, GPT-3에서 IPA를 사용하는 경우 GPT-3보다 훨씬 높은 성능 향상을 보여준다. 이러한 유망한 결과는 IPA가 극단적 규모의 언어 모델에 대한 경량 대안으로서의 잠재력을 강조한다.

###### Weakly Supervised Semantic Parsing with Execution-based Spurious Program Filtering (https://aclanthology.org/2023.emnlp-main.425/)
- Anthology ID: 2023.emnlp-main.425 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 약한 지도로 시맨틱 파서를 훈련시킬 때의 오류 프로그램은 오랜 동안 도전 과업이었다. 
    2. 이 논문에서는 프로그램 실행 결과를 기반으로 한 도메인에 구애받지 않는 필터링 메커니즘을 제안한다. 
    3. 기존 약한 지도 시맨틱 파싱 프레임워크에 용이하게 적용할 수 있으며, Empirical evaluations을 통해 향상된 성능을 보였다.

###### Taxonomy Expansion for Named Entity Recognition (https://aclanthology.org/2023.emnlp-main.426/)
- Anthology ID: 2023.emnlp-main.426 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. NER(명명된 개체 인식) 모델을 학습하는 것은 주로 개체 유형의 분류 체계를 고정하는 것을 포함한다. 그러나 요구 사항이 변화하고 추가 개체 유형을 인식할 필요가 있는 경우가 발생할 수 있다.
    2. 기존의 방법은 기존과 추가 개체 유형을 포함하여 전체 데이터셋을 다시 주석을 달고 모델을 학습하는 것이다. 그러나 이 작업은 매우 수고롭다.
    3. 이 논문에서는 부분적으로 주석이 달린 데이터셋만 사용하는 새로운 접근 방식인 PLM(부분 레이블 모델)을 제안하고, 이 방법이 이전 연구에서 고려되지 않은 분류 체계 확장에도 일관되게 더 나은 성능을 보인다는 것을 실험을 통해 보여준다.

###### Rather a Nurse than a Physician - Contrastive Explanations under Investigation (https://aclanthology.org/2023.emnlp-main.427/)
- Anthology ID: 2023.emnlp-main.427 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. '*대비적 설명 (contrastive explanations)*'은 어떤 결정을 '*다른 결정과 대조하여*' 설명하는 것으로, 비대비적 설명보다 인간이 결정을 설명하는 방식과 더 비슷하다고 주장되었으나, 이 주장은 아직 실험적으로 검증되지 않았다.
    2. 본 논문에서는 SST2, DynaSent, BIOS, DBpedia-Animals라는 영어 텍스트 분류 데이터셋을 분석하고, RoBERTa, GPT-2, T5라는 세 가지 다른 모델에서 세 가지 다른 크기로 fine-tuning 및 설명을 추출한다. 또한, LRP, GradientxInput, GradNorm과 같은 세 가지 사후 설명가능성 방법을 적용한다.
    3. 결론적으로, 모델 기반 설명과 인간의 주관적 설명이 모두 대비적/비대비적 설정에서 높은 일치도를 보이며, 두 경우의 모델 기반 설명 모두 인간의 이유를 충분히 잘 설명한다는 결과를 실험적으로 발견하였다. 따라서, 인간이 대비적인 방식으로 결정을 설명하지 않을 수도 있다는 것을 밝혀냈다.

###### EtiCor: Corpus for Analyzing LLMs for Etiquettes (https://aclanthology.org/2023.emnlp-main.428/)
- Anthology ID: 2023.emnlp-main.428 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 일상 소통에서 etiquettes는 굉장히 중요한 부분이다. 이 논문에서는 5개의 지역에서 텍스트들을 모은 Etiquettes Corpus를 제안한다.
    2. Etiquettes Corpus는 지역별 social norms에 대한 LLM 지식과 이해를 평가하기 위한 실험 환경을 제공한다.
    3. 실험 결과, 최신 LLM들은 주로 양서권이 아닌 지역의 etiquettes를 이해하지 못하는 것으로 나타나고 있다.

###### An Investigation of LLMs’ Inefficacy in Understanding Converse Relations (https://aclanthology.org/2023.emnlp-main.429/)
- Anthology ID: 2023.emnlp-main.429 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델(LLM)은 구조적인 데이터-텍스트 변환과 의미 파싱과 같은 형식 언어 지향적인 작업에서 주목할만한 성과를 이루었다. 그러나 현재 벤치마크는 대부분 LLM의 사전 훈련 데이터 분포를 따르기 때문에, LLM이 실제로 형식 언어의 구조적 의미를 이해하는지에 대한 의문이 제기된다.
    2. 본 논문에서는 특정 사례인 반대 이진 관계(converse binary relation)에 대해 이 문제를 조사한다. 우리는 반대 관계에 초점을 맞춘 ConvRe라는 새로운 벤치마크를 소개하며, 이 벤치마크는 인기 있는 지식 그래프 완성 데이터셋에서 추출된 17개 관계와 1240개 트리플을 포함한다.
    3. 실험 결과는 LLM이 종종 단축학습을 하고 여전히 우리가 제안한 벤치마크에 대한 도전을 직면하고 있다는 것을 시사한다.

###### Towards Low-Resource Automatic Program Repair with Meta-Learning and Pretrained Language Models (https://aclanthology.org/2023.emnlp-main.430/)
- Anthology ID: 2023.emnlp-main.430 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자동 프로그램 수정(APR)은 수작업 디버깅 작업을 줄이고 개발자의 생산성을 향상시키기 위한 소프트웨어 개발에서 핵심적인 기술로 주목받고 있다. 그러나 실질적인 상황에서 소프트웨어 버그는 불균형 분포를 가지고 있고, APR 모델이 학습한 수정 지식은 주로 빈번한 오류 유형의 패턴만 포착하므로 드물게 발생하는 오류 유형을 다루기에 적합하지 않다.
    2. 우리는 이 한계를 해결하기 위해 저자원 APR의 새로운 과제를 조사하고, 코드 사전 훈련 언어 모델과 통합된 새로운 메타 학습 프레임워크인 Meta-APR을 제안한다. Meta-APR은 효율적인 일급 메타 학습 최적화를 통해 고자원 버그로부터 더 나은 오류별 지식을 학습함으로써 대상 저자원 버그에 대한 빠른 적응을 가능케 한다.
    3. CodeT5를 Meta-APR의 백본 모델로 채택하였지만, 어떤 신경망 모델에도 통합될 수 있는 모델 태환적인 프레임워크이다. 다양한 프로그래밍 언어에서 세 가지 벤치마크에 대한 실험 결과는 우리의 방법이 기존 DL 기반 APR 접근 방식보다 우수함을 검증하고 있다.

###### ZGUL: Zero-shot Generalization to Unseen Languages using Multi-source Ensembling of Language Adapters (https://aclanthology.org/2023.emnlp-main.431/)
- Anthology ID: 2023.emnlp-main.431 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. NLP 태스크에서의 제로샷 크로스-리질 전송 문제를 언어 어댑터 (LAs)를 사용하여 해결한다. 그러나 대부분의 이전 연구들은 단일 소스 (보통 영어)의 어댑터로 학습한 뒤, 대상 LA 또는 다른 관련 언어의 LA를 사용하여 테스트한다. 모델의 robustness를 높이기 위해 여러 언어 (언어적 또는 지리적으로 관련된)의 어댑터를 요구한다.
    2. LAs를 이용한 훈련은 unlabelled data를 필요로 하는데, 이는 저자들이 언급한 low resource unseen languages에서 바로 사용할 수 없는 문제를 발생시킨다. 
    3. ZGUL(Zero-shot Geographical and Unseen Languages)라는 새로운 신경 구조를 사용하여 여러 소스 언어의 어댑터를 이용해 효과적인 크로스-리질 전송을 실현하였고, 15개의 unseen target 언어에 대해 POS 태깅 및 NER 태스크에 대해 3.2 average F1 point의 성능 향상을 얻었음을 실험으로 입증하였다.

###### Log-FGAER: Logic-Guided Fine-Grained Address Entity Recognition from Multi-Turn Spoken Dialogue (https://aclanthology.org/2023.emnlp-main.432/)
- Anthology ID: 2023.emnlp-main.432 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다중 턴의 대화에서 세부 주소 엔터티 인식은 특히 어렵다. 주소의 다른 부분들은 여러 턴의 대화를 통해 분산되고, 이를 턴별로 추출하여 결합하는 것은 어렵다.
    2. 이 논문에서는 주소의 계층 구조 관계를 논리 규칙으로 정의하고, 확률적인 방식으로 적용하여 FGAER (Fine-grained address entity recognition)의 정확도를 향상시키는 로직 가이드 fine-grained address recognition(Log-FGAER) 방법을 제안한다.
    3. 또한, 우리는 라벨이 지정된 주소 엔터티로 말뭉치 대화 데이터셋을 ChatGPT를 사용하여 온톨로지 기반 데이터 증강 방법론을 제시한다. 실험 결과는 우리의 제안의 효과를 입증한다.

###### Unified Low-Resource Sequence Labeling by Sample-Aware Dynamic Sparse Finetuning (https://aclanthology.org/2023.emnlp-main.433/)
- Anthology ID: 2023.emnlp-main.433 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Named Entity Recognition, Relation Extraction, Semantic Role Labeling 등 다양한 sequence labeling 문제를 통합된 시퀀스-대-시퀀스 형식으로 정의하는 Unified Sequence Labeling은 대규모 언어 모델 지식을 구조화된 예측에 최대한 활용할 수 있는 기회를 제공한다.
    2. 그러나 이를 위해서는 베이스 pretrained 언어 모델에 알려지지 않은 특수한 형식에 맞게 포맷팅해야 하므로 타겟 포맷에 충분히 적용될 수 없는 데이터 제한 상황에서 사용성이 제한된다.
    3. 이 논문에서는 FISH-DIP라는 샘플-의존성을 고려한 동적 sparse 파일 튜닝 전략을 제안하여, 대량의 모델 파라미터 대신에 고품질 예측을 위한 적은 파라미터에 초점을 맞추는 동안 모델을 최적화하는 방법을 제시한다. 이 방법은 저자와 저성능 인스턴스를 우선적으로 개선함으로써 일련의 작업에서 최대 40%의 성능 향상을 보여준다.

###### On the Representational Capacity of Recurrent Neural Language Models (https://aclanthology.org/2023.emnlp-main.434/)
- Anthology ID: 2023.emnlp-main.434 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 연구는 시계열 신경망(RNN)을 기반으로 하는 언어 모델의 계산 표현력을 조사한다. 
    2. 제안된 방법은 실시간 계산을 수행하는 실제 RNN 언어 모델을 이용하여 결정론적인 확률적 튜링 머신(PTM)을 재현할 수 있다는 것을 보여준다. 
    3. 이 연구에서는 실제 시간 제한 하에서 RNN 언어 모델의 계산능력을 상한값과 하한값으로 제시한다.

###### A Mechanistic Interpretation of Arithmetic Reasoning in Language Models using Causal Mediation Analysis (https://aclanthology.org/2023.emnlp-main.435/)
- Anthology ID: 2023.emnlp-main.435 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 연구에서는 많은 언어 모델 (LMs) 에서의 수학적 추론에 관심을 가지고 있으나, 이러한 모델이 산술 과제와 관련된 정보를 어떻게 처리하고 저장하는지에 대한 이해는 제한적이다.
    2. 이 논문에서는 인과 중재 분석 프레임워크를 사용하여 산술 문제에 대한 Transformer 기반 LMs 의 기계적 해석을 제시하고, 특정 모델 구성 요소의 활성화에 개입함으로써 예측된 확률의 변화를 측정함으로써 특정 예측에 책임 있는 파라미터의 하위 집합을 식별한다.
    3. 실험 결과에 따르면 LMs는 중간 레이어에서 최종 토큰까지의 유의미한 정보를 어텐션 메커니즘을 통해 전달하여 입력을 처리하며, 그 정보는 MLP 모듈의 세트에 의해 처리되어 결과와 관련된 정보를 생성하고 잔류 데이터 스트림에 통합된다.

###### Benchmarking and Improving Text-to-SQL Generation under Ambiguity (https://aclanthology.org/2023.emnlp-main.436/)
- Anthology ID: 2023.emnlp-main.436 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 지금까지의 Text-to-SQL 변환 연구는 텍스트 쿼리마다 하나의 올바른 SQL이 있는 데이터셋을 기반으로 진행되었으나, 실제로 발생하는 자연어 쿼리는 겹치는 스키마 이름과 혼동스러운 관계 경로로 인해 의도한 SQL에 대한 중대한 모호함을 포함한다.
    2. 이 연구에서는 LexicalBeam이라는 새로운 디코딩 알고리즘을 제안하여 SQL 논리 공간을 탐색하는 데에 효과적이며, 관련된 인터페이스를 통해 사용자가 다른 해석에 대한 고려를 할 수 있는 환경을 제공한다.
    3. 이미지와 자연어 생성에서 많은 성과를 거둔 beam search 알고리즘들은 SQL 쿼리 생성에 있어서 유용하지 않은 토큰 수준의 다양성을 제공하여 원하는 결과를 얻지 못하게 한다는 것이다.

###### Non-autoregressive Text Editing with Copy-aware Latent Alignments (https://aclanthology.org/2023.emnlp-main.437/)
- Anthology ID: 2023.emnlp-main.437 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 텍스트 편집 분야에서는 Seq2Seq에서 Seq2Edit로의 패러다임 전환을 목표로 한다. 하지만 Seq2Edit 방법은 여전히 단어 생성의 유연성과 다른 언어로의 일반화와 같은 몇 가지 문제에 직면한다.
    2. 이 논문에서는 CTC 정렬을 통해 텍스트 편집 과정을 모델링하는 새로운 비자기방적 텍스트 편집 방법을 제안한다. 복사 작업을 편집 공간에 도입함으로써 텍스트 중첩을 효율적으로 관리할 수 있는 기능을 제공한다.
    3. GEC 및 문장 퓨전 작업에서의 실험 결과를 통해 제안한 방법이 기존의 Seq2Edit 모델보다 우수한 성능을 보이며, 4배 이상의 속도 개선을 달성한다는 것을 보여준다. 또한, 독일어와 러시아어에서의 일반화 능력을 잘 보여준다.

###### Translating away Translationese without Parallel Data (https://aclanthology.org/2023.emnlp-main.438/)
- Anthology ID: 2023.emnlp-main.438 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존 평가 메트릭은 MCQ의 교육적 가치를 고려하지 못하고 데이터셋에 있는 단어만 비교하여 평가하는데, 이 논문에서는 솔루션을 제안하여 실제 강의실에서 사용할 수 있는 자동 평가 메트릭인 KDA를 사용한다.
    2. 기존 augmentation 방법들은 spurious correlation에 영향을 받지만, 이 논문에서는 collective decision과 contrastive learning을 이용하여 counterfactual augmentation의 robustness를 향상시켰다.
    3. 번역된 텍스트는 원래 텍스트와는 다른 언어적 차이를 보이는데, 이 논문에서는 번역되어진 텍스트의 translationese를 줄이기 위해 translation-based style transfer를 사용한다.

###### Prompt-Based Monte-Carlo Tree Search for Goal-oriented Dialogue Policy Planning (https://aclanthology.org/2023.emnlp-main.439/)
- Anthology ID: 2023.emnlp-main.439 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 목표 지향형 대화를 위한 계획은 미래 대화 상호작용을 시뮬레이션하고 과업 진행을 추정하는 것을 필요로 한다. 
    2. 이 논문에서는 GDP-Zero라는 방법을 소개하여 모델 훈련 없이 목표 지향형 대화 정책 계획을 수행하는 방법을 제안한다. 
    3. GDP-Zero는 대화 과정에서 다양한 역할을 하는 큰 언어 모델을 활용하여 대화 정책을 설정하고 성능을 평가한 결과, ChatGPT보다 더 낮은 시간 동안 응답을 선호하고 상호작용 평가에서 더 설득력 있게 평가되었다.

###### UniMath: A Foundational and Multimodal Mathematical Reasoner (https://aclanthology.org/2023.emnlp-main.440/)
- Anthology ID: 2023.emnlp-main.440 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "자연어 처리(NLP) 분야에서는 상당한 진전이 있었지만, 기존 방법들은 다양한 수학 모드를 효과적으로 해석하고 처리하는 데 제한이 있다. 따라서 이 논문에서는 다중 모달 수학 추론 작업에 적합하고 통합된 UniMath 시스템을 소개한다."
    2. "UniMath는 산술, 기하학, 테이블 기반 수학의 복잡한 문제 해결에 대한 다중 모달 지원을 위해, fine-tuned T5 모델에 변분 오토인코더(VAE) 기반 이미지 토크나이저를 도입한다."
    3. "SVAMP, GeoQA, TableMWP의 다양한 데이터셋에서 모델을 공동으로 훈련하고 평가함으로써 UniMath는 최고 수준의 성능을 달성한다. 또한, MathQA와 Geo-Proving의 두 개의 추가 데이터셋에 적용하여 모델의 일반화 능력을 확인하였다."

###### CaseEncoder: A Knowledge-enhanced Pre-trained Model for Legal Case Encoding (https://aclanthology.org/2023.emnlp-main.441/)
- Anthology ID: 2023.emnlp-main.441 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 법적인 사례를 찾는 것은 현대 법률 정보 시스템에서 중요한 과정이다. 최근의 연구는 법적 사례 검색을 위해 일반 도메인에서 미리 학습한 언어 모델을 사용해왔지만, 일반 도메인 PLM을 사용하는 것에는 제한이 있다. 특히 이러한 모델은 법적 사례 문서에서의 법적 속성을 충분히 포착하지 못할 수 있다. 
    2. 이 문제를 해결하기 위해 우리는 CaseEncoder라는 법적 문서 인코더를 제안한다. CaseEncoder는 데이터 샘플링 및 사전 학습 단계에서 세밀한 법적 지식을 활용한다. 세밀한 법 조항 정보를 활용하여 양성 및 음성 예시를 선택하는 것으로 학습 데이터의 품질을 향상시킨다.
    3. 실험 결과, CaseEncoder는 일반 사전 학습 모델과 법적 사전 학습 모델을 모두 능가하여 zero-shot 법적 사례 검색에서 상당한 성능 향상을 이룩한다. CaseEncoder의 소스 코드는 https://github.com/Anonymous-EMNLP2023/CaseEncoder에서 찾을 수 있다.

###### HiddenTables and PyQTax: A Cooperative Game and Dataset For TableQA to Ensure Scale and Data Privacy Across a Myriad of Taxonomies (https://aclanthology.org/2023.emnlp-main.442/)
- Anthology ID: 2023.emnlp-main.442 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Large Language Models (LLMs)는 테이블 기반 질문-답변 작업에서 한계를 가지고 있으며, 이를 해결하기 위해 "HiddenTables"이라는 협력 게임을 제안한다.
    2. 이 게임은 LLM 에이전트의 능력을 평가하는 Oracle과 코드 생성 LLM Solver 사이에서 진행되며, 자연어 스키마를 기반으로 한다는 점에서 중요하다. 이 게임은 백엔드 데이터의 보안을 보장하고 있다.
    3. "HiddenTables"의 인프라를 사용하여 새로운 데이터셋 "PyQTax"를 만들었으며, 이는 116,671개의 질문-테이블-답변 쌍에 대한 세분화된 분석 및 다양한 질문 분류에 대한 레이블을 제공한다.

###### Causal Document-Grounded Dialogue Pre-training (https://aclanthology.org/2023.emnlp-main.443/)
- Anthology ID: 2023.emnlp-main.443 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 문서기반 대화 (DocGD)의 목표는 대화 맥락에 따라 지원 문서에서 근거를 제시하여 응답을 생성하는 것이다. 
    2. 기존의 DocGD 방법들은 인과관계를 명시적으로 포착하는 특별히 맞춤형 사전훈련 접근 방식 없이 일반적인 사전훈련 언어 모델에 의존하고 있는 것으로 나타났다.
    3. 이 논문에서는 인과 관계를 명확하게 포착하는 데 적합한 사전훈련 접근 방식을 제안하고 대규모 DocGD 사전훈련 말뭉치 구축을 위한 첫 번째 완전한 인과관계 데이터셋 구축 전략을 제시한다.

###### Accented Speech Recognition With Accent-specific Codebooks (https://aclanthology.org/2023.emnlp-main.444/)
- Anthology ID: 2023.emnlp-main.444 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 스피치 악센트는 최신 자동 음성 인식 (ASR) 시스템에 대한 중요한 도전 과제입니다. 소수 악센트에 대한 성능 저하는 ASR의 포용적인 적용을 방해하는 심각한 문제입니다.
    2. 이 논문에서는 훈련 가능한 코드북 집합을 사용하여 end-to-end ASR 시스템을 위한 독특한 악센트 적응 방법을 제안합니다. 이러한 코드북은 악센트별 정보를 포착하고 ASR 인코더 레이어에서 통합됩니다.
    3. 실험 결과, 우리의 제안된 방법은 훈련 중 본적이 있는 영어 악센트뿐만 아니라 훈련 중보지 않은 악센트에 대해서도 유의한 성능 향상을 보입니다.

###### Linking Surface Facts to Large-Scale Knowledge Graphs (https://aclanthology.org/2023.emnlp-main.445/)
- Anthology ID: 2023.emnlp-main.445 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 오픈 정보 추출(OIE) 방법은 ("주어", "관계", "목적어") 삼중체 형식으로 자연어 텍스트에서 사실을 추출한다. 그러나 이러한 사실들은 단순한 표면 형태에 불과하며, 그 모호함으로 인해 하위 작업에서의 사용이 어렵다. 
    2. 이 논문에서는 OIE의 높은 커버리지와 지식 그래프의 의미정밀도를 결합하기 위해 새로운 벤치마크와 평가 프로토콜을 제안한다. 
    3. 여러 가지 기준에서의 벤치마크 실험 결과, 기존 지식 그래프에 링크되지 않은 entities 및 predicates의 탐지가 정확한 링킹보다 어렵다는 것을 보여주었다. 이로써 이 어려운 작업에 대한 추가 연구 노력이 요구된다는 결론을 내렸다.

###### Sentiment Analysis on Streaming User Reviews via Dual-Channel Dynamic Graph Neural Network (https://aclanthology.org/2023.emnlp-main.446/)
- Anthology ID: 2023.emnlp-main.446 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 딥러닝 기술의 빠른 발전으로 사용자 리뷰의 감성 분석이 큰 성과를 이뤄냈으나, 기존 방법은 사용자와 제품에 대한 정적인 가정을 하고 시간에 따라 변하는 특성을 간과하고 있다.
    2. 본 논문에서는 시간에 따라 변하는 사용자와 제품의 특성을 모델링하기 위해 동적 그래프 신경망(DGNN)을 기반으로 한 이중 채널 프레임워크인 DC-DGNN을 제안한다.
    3. 실험 결과를 통해 제안된 방법의 우수성을 입증하였다.

###### DUMB: A Benchmark for Smart Evaluation of Dutch Models (https://aclanthology.org/2023.emnlp-main.447/)
- Anthology ID: 2023.emnlp-main.447 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. DUMB (Dutch Model Benchmark)는 저-규모, 중-규모 및 고-규모 작업에 대한 다양한 데이터셋을 포함한 언어 모델의 성능을 비교하는 벤치마크를 제시한다. 
    2. RER (상대적 에러 감소)은 DUMB의 언어 모델 성능을 강력한 기준선과 비교하여 다른 언어 모델을 평가할 때도 참조할 수 있도록 평가 지표를 제안하였다. 
    3. 실험 결과, 현재의 네덜란드어 모노링구얼 모델들은 성능이 낮으며, 더 큰 규모의 다른 아키텍처와 사전 학습 목적을 가진 네덜란드어 모델을 훈련시키는 것이 좋다는 것을 보여주었다.

###### OssCSE: Overcoming Surface Structure Bias in Contrastive Learning for Unsupervised Sentence Embedding (https://aclanthology.org/2023.emnlp-main.448/)
- Anthology ID: 2023.emnlp-main.448 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Contrastive learning은 비지도 문장 표현 학습에서 효과적인 방법으로 입증되었으나, 기존 방법은 표면 구조 편향(surface structure bias)에 취약하다. 
    2. 이 논문에서는 표면 구조와 의미론적 유사성을 기반으로 새로운 데이터셋을 제안하여 기존 모델을 체계적으로 조사하였다. 
    3. 또한, biased를 극복하기 위해 두 가지 측면에서 대응하였는데, 하나는 bias에 반대하는 데이터로 augmentation하는 것이고, 다른 하나는 catastrophic forgetting을 방지하기 위해 recall loss를 활용하여 단어 의미를 보존하는 것이다.

###### End-to-End Single-Channel Speaker-Turn Aware Conversational Speech Translation (https://aclanthology.org/2023.emnlp-main.449/)
- Anthology ID: 2023.emnlp-main.449 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 음성-텍스트 번역(ST) 시스템은 한 명의 화자의 발화를 훈련시키고, 여러 명의 화자가 대화하는 실제 시나리오에서는 일반화되지 않을 수 있다.
    2. 이 논문에서는 여러 화자 간의 대화가 포함된 단일 채널 멀티스피커 대화 ST를 다루는데, 이를 위해 자동 음성 인식, 음성 번역 및 화자 차례 감지를 결합하는 다중작업 훈련 모델을 제안한다.
    3. 실험 결과에서 다중 화자 조건에서 기존 ST 시스템에 비해 우수한 성능을 보여주는 반면, 싱글 스피커 조건에서는 유사한 성능을 달성한다. (scripts for data processing and model training도 공개한다)

###### A Fine-Grained Taxonomy of Replies to Hate Speech (https://aclanthology.org/2023.emnlp-main.450/)
- Anthology ID: 2023.emnlp-main.450 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 극을 멸시하는 것보다는 대대적인 카운터스피치가 적나라한 증가 방법으로 강조되고 있는데, 그런 대화에는 극혐하는 내용 혹은 대화의 창시자, 일반적인 요청, 이치에 맞는 반박, 욕설 등 다양한 유형이 있다.
    2. 카운터스피치의 효과, 즉 적대를 받아들일 확률은 이러한 유형에 달려있다. 
    3. 이 논문에서는 극혐하는 내용과 그에 대한 답변들에 대한 이론적으로 기초된 분류법과 새로운 말뭉치를 제시한다.

###### JointMatch: A Unified Approach for Diverse and Collaborative Pseudo-Labeling to Semi-Supervised Text Classification (https://aclanthology.org/2023.emnlp-main.451/)
- Anthology ID: 2023.emnlp-main.451 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "쓰지 않은 데이터를 사용할 수 있는 반지도 학습 텍스트 분류(SSTC)는 라벨 편향과 오류 누적 문제로 인해 관심을 받고 있다. 논문에서는 최근 반지도 학습과 노이즈를 학습하는 작업에서 영감을 얻어 이러한 도전에 대응하기 위한 종합적인 접근 방식인 JointMatch를 제안한다."
    2. "JointMatch는 현재 쉬운 클래스로의 모델 편향을 완화시키기 위해 다른 클래스의 학습 상태에 따라 클래스별 임계값을 적응적으로 조정하는 것과 상호 교육적 방식으로 서로 다르게 초기화된 두 네트워크를 활용하여 오류 누적 문제를 완화하는 것에 초점을 두고 있다."
    3. "벤치마크 데이터셋에서 수행한 실험 결과, JointMatch의 성능이 우수하며 평균적으로 5.13%의 향상을 달성한다. 특히, 5개 라벨 당 86%의 정확도로 극히 희소한 라벨 설정에서도 탁월한 결과를 보인다."

###### Simple Temporal Adaptation to Changing Label Sets: Hashtag Prediction via Dense KNN (https://aclanthology.org/2023.emnlp-main.452/)
- Anthology ID: 2023.emnlp-main.452 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사용자 생성 소셜 미디어 데이터는 온라인 토론에 영향을 미치는 새로운 트렌드와 개인 정보 삭제로 인해 지속적으로 변화한다. 그러나 전통적인 NLP 모델은 고정된 훈련 데이터에 의존하기 때문에 빈번하고 비용이 많이 드는 재훈련 없이는 시간적 변화에 대응할 수 없다.
    2. 본 논문에서는 hashtag 예측을 통해 장기간 변동성에 대한 연구를 수행하고, 재훈련이 필요없는 비매개변수적 밀집 검색 기술을 간단하면서도 효과적인 해결책으로 제안한다.
    3. 실험 결과, 우리의 방법은 시간적 분포 변화가 있는 최신 트위터 데이터셋에서 최고의 정적 매개변수 기준과 비교하여 64% 향상되었으며, 비용이 많이 드는 그래디언트 기반 재훈련을 회피할 수 있다. 또한, 데이터의 개인정보 보호 법에 따라 동적으로 삭제되는 사용자 데이터에도 적합하며 계산 비용과 성능 손실이 거의 없다.

###### Speak, Memory: An Archaeology of Books Known to ChatGPT/GPT-4 (https://aclanthology.org/2023.emnlp-main.453/)
- Anthology ID: 2023.emnlp-main.453 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 연구에서는 이름 채우기 맴버쉽 추론 질의를 통해 ChatGPT와 GPT-4가 알고 있는 책을 추론하기 위해 데이터 고려사항을 수행한다. 그 결과, OpenAI 모델은 다양한 저작권이 있는 자료들을 기억하고 있으며, 이 기억의 정도는 해당 책의 단락이 웹에서 얼마나 자주 나타나는지와 관련이 있다.
    2. 이러한 모델의 기억 능력은 문화 분석의 측정 타당성을 복잡하게 만들며, 테스트 데이터를 오염시켜 문제가 된다. 우리는 모델이 기억하는 책에 비해 기억하지 않은 책에서 다음 작업의 결과가 훨씬 좋은 것을 보여주며, 이는 훈련 데이터가 이미 알려져 있는 개방 모델에 대한 필요성을 뒷받침한다.
    3. 따라서 우리는 훈련 데이터가 알려진 개방 모델에 대한 지지를 제공하는 것이 타당하다 주장한다.

###### A Study on Accessing Linguistic Information in Pre-Trained Language Models by Using Prompts (https://aclanthology.org/2023.emnlp-main.454/)
- Anthology ID: 2023.emnlp-main.454 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 다중언어 언어 모델에서 언어적 정보에 접근할 수 있는지 연구하였으며, explicit한 문법 원리에 대한 인사이트를 얻기 위한 쉬운 방법이 없었다. 
    2. 이 논문에서는 prompting 기술을 사용하여 언어 모델이 명시적인 문법 원리에 접근할 수 있는지 테스트하고, 언어적 특징에 대한 접근 방법의 효과를 연구하였다. 
    3. 독일어, 아이슬란드어, 스페인어에 대한 실험결과, 어떤 언어적 속성은 prompting을 통해 접근할 수 있으며, 다른 언어적 속성은 더 어렵게 파악된다는 것을 보였다.

###### CiteBench: A Benchmark for Scientific Citation Text Generation (https://aclanthology.org/2023.emnlp-main.455/)
- Anthology ID: 2023.emnlp-main.455 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 과학은 이전 과학 논문에 기초하여 진전한다. 연구의 가속화로 인해 최근 개발 동향을 따라가고 이전 연구의 규모가 계속해서 증가하는 것은 어렵다. 이를 해결하기 위해, citation 텍스트 생성 작업은 인용할 논문들과 인용문맥이 주어졌을 때 정확한 텍스트 요약을 생성하기 위한 작업이다.
    2. citation 텍스트 생성은 인용된 문헌이 인용하는 논문에서 드물게 자주 나오는 텍스트의 개략적인 표현을 제공하므로, 여러 데이터를 통합하여 표준화된 평가를 가능하게 하는 CiteBench라는 벤치마크를 제안한다.
    3. 새로운 벤치마크를 활용하여 강력한 기준 선언들의 성능을 조사하고, 데이터 간의 전이 가능성을 테스트하며, 향후 연구를 지원하기 위해 citation 텍스트 생성 작업에 대한 새로운 통찰력을 제공한다.

###### From Heuristic to Analytic: Cognitively Motivated Strategies for Coherent Physical Commonsense Reasoning (https://aclanthology.org/2023.emnlp-main.456/)
- Anthology ID: 2023.emnlp-main.456 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Pre-trained language models (PLMs)는 언어 작업에서 훌륭한 성능을 보여주었지만, spurious correlations에 취약하며 가공된 정보를 생성하기도 한다. 이 연구에서는 과제와 무관한 정보를 줄이기 위해 사람과 유사한 숙고적인 추론체인을 사용하여 PLMs를 fine-tuning하고 in-context learning에 적용한다.
    2. Heuristic-Analytic Reasoning (HAR) 전략은 인간과 유사한 추론 전략을 모델에 적용하여 발전시켰으며, 정합성 있는 모델 판단을 위한 설명을 크게 개선시켰다. 
    3. 우리의 결과는 인간과 유사한 추론 전략이 PLM의 모델 판단의 일관성과 신뢰성을 개선하는 데 효과적일 수 있음을 시사한다.

###### A Challenging Multimodal Video Summary: Simultaneously Extracting and Generating Keyframe-Caption Pairs from Video (https://aclanthology.org/2023.emnlp-main.457/)
- Anthology ID: 2023.emnlp-main.457 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 본 논문은 사용 가능한 형태의 목록으로 영상의 핵심 씬을 요약하기 위한 모달 동영상 요약 과제 설정과 데이터셋을 제안한다.
    2. 이 과제는 영상에서 중요한 장면을 이미지(키프레임) 형태로 추출하고 각 키프레임의 상황을 설명하는 캡션을 생성하는 것을 목표로 한다.
    3. 이 작업은 실용적인 응용 프로그램으로 유용하며, 동시에 키프레임 선택 성능과 캡션 품질의 동시 최적화를 달성하기 위해 이전 키프레임과 이후 키프레임 및 캡션에 상호 종속성을 신중히 고려해야 하는 도전적인 문제이다.

###### Copyright Violations and Large Language Models (https://aclanthology.org/2023.emnlp-main.458/)
- Anthology ID: 2023.emnlp-main.458 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어 모델은 단순히 사실 뿐만 아니라 훈련 중에 본 텍스트의 장문을 기억할 수도 있다. 본 연구는 저작권 침해와 대규모 언어 모델 간의 문제를 verbatim memorization의 측면에서 탐색하며, 저작권을 가진 텍스트의 재배포 가능성에 초점을 맞춘다.
    2. 인기 있는 책과 코딩 문제 컬렉션을 대상으로 여러 언어 모델에 대한 실험을 진행하여, 언어 모델이 이러한 자료들을 얼마나 재배포하는지 보수적으로 확인한다.
    3. 본 연구는 저작권 규정을 준수하기 위해 자연어 처리 분야의 미래 개발에 대한 추가적인 검토와 잠재적인 영향에 대한 필요성을 강조한다.

###### Effects of sub-word segmentation on performance of transformer language models (https://aclanthology.org/2023.emnlp-main.459/)
- Anthology ID: 2023.emnlp-main.459 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자동 생성된 Multiple Choice Questions (MCQ)의 교육적 가치를 평가하기 위한 새로운 평가 메트릭인 Knowledge Dependent Answerability (KDA)가 제안되었다.
    2. KDA는 사람 조사를 기반으로 구축되며, 사후 학습 된 언어 모델을 사용하여 KDA_disc와 KDA_cont로 근사화된다.
    3. KDA_disc와 KDA_cont는 MCQ의 품질 측정에 강한 예측력을 가지며, 실제 교실 환경에서의 사용성과 강한 상관 관계를 가지고 있다.

###### Symbolic Planning and Code Generation for Grounded Dialogue (https://aclanthology.org/2023.emnlp-main.460/)
- Anthology ID: 2023.emnlp-main.460 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 큰 언어 모델 (LLMs)은 텍스트와 코드 처리 및 생성에서 우수한 성능을 보이지만, 목표에 대한 모델의 제어가 어려워 테스크 지향적인 다이얼로그에는 제한적으로 적용되고 새로운 grounding을 처리하는 데 실패한다. 
    2. 우리는 LLMs와 상징적인 계획 및 grounding 코드 실행을 결합한 모듈식이며 명확하게 설명 가능한 다이얼로그 시스템을 제안한다.
    3. 우리의 시스템은 LLM을 사용하여 대화 상대의 발언을 실행 가능한 코드로 전환하고 grounding을 수행하는 함수를 호출하는 역할을 하는 reader와 symbolic planner로 구성되어 있다. 이를 통해 우리의 시스템은 기존의 최첨단 기법을 크게 개선하였다고 평가받았다.

###### Universal Self-Adaptive Prompting (https://aclanthology.org/2023.emnlp-main.461/)
- Anthology ID: 2023.emnlp-main.461 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 현대의 대형 언어 모델(Large Language Model, LLM)은 인상적인 zero-shot과 few-shot 능력을 가지고 있으며 이러한 능력은 자주 불러내지만 실제로는 도움을 받지 못하고 있는 경우 일반적인 과제에서 기존 자동 프롬프트 설계 방법을 적용하기가 어렵기 때문에 여전히 보다 약한 성능을 보이고 있다.
    2. 본 연구에서는 Universal Self-Adaptive Prompting (USP)라는 zero-shot 학습에 특화된 자동 프롬프트 설계 접근 방식을 제시한다. USP는 라벨이 없는 일반적인 과제에서 작동하며 작은 양의 미표시 된 데이터와 추론만 가능한 LLM만으로도 사용할 수 있다.
    3. 실험 결과 USP는 다양한 자연어 이해, 생성 및 추론 작업에서 표준 zero-shot 베이스라인과 비교해 상당한 성능 향상을 보이며 종종 few-shot 베이스라인과 비교해 비슷하거나 우수한 성능을 보였다.

###### Somali Information Retrieval Corpus: Bridging the Gap between Query Translation and Dedicated Language Resources (https://aclanthology.org/2023.emnlp-main.462/)
- Anthology ID: 2023.emnlp-main.462 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 소말리아어 정보 검색에 대한 연구는 특화된 말뭉치의 부족으로 인해 조회 번역에 의존하고있다. 그러나 이 논문에서는 언어 전문가와 NLP 연구자와 협력하여 소말리아어 정보 검색을 위한 주석이 달린 말뭉치를 생성한다.
    2. 이 말뭉치는 다양한 온라인 사이트에서 수집된 2335개 문서로 구성되어 있으며, 이 말뭉치를 사용하여 의사-중요도 피드백 (PRF) 질의 확장 기법을 사용한 소말리아어 정보 검색 시스템을 개발한다.
    3. 이러한 소말리아어 데이터셋은 낮은 자원의 소말리아어에 대한 NLP 장벽을 극복할 수 있으며, 질문-답변 및 텍스트 분류와 같은 다양한 NLP 도구 및 응용 프로그램을 개발하는 데 도움이 될 뿐만 아니라 연구자들에게 새로운 기술과 접근법을 연구하고 개발할 수 있는 귀중한 자료를 제공합니다.

###### Beat LLMs at Their Own Game: Zero-Shot LLM-Generated Text Detection via Querying ChatGPT (https://aclanthology.org/2023.emnlp-main.463/)
- Anthology ID: 2023.emnlp-main.463 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 NLP 태스크에서 deep model의 정확성이 사람을 능가했지만 spurious pattern에 의존함으로써 robustness가 제한되고 있다. 
    2. 이 논문에서는 contrastive learning과 counterfactual augmentation을 활용하여 robustness를 향상시키는 방법을 제안하는데, "여러 개의" counterfactual을 생성하고, 집합적 의사 결정을 통해 각 단어의 인과관계를 robust하게 파악한다.
    3. LLM (Large Language Model)에 대한 우려에도 불구하고, 이 논문에서는 LLM이 생성한 텍스트를 탐지하기 위한 zero-shot black-box 방법을 제안하고, 다양한 데이터셋과 태스크에서 효과적으로 LLM이 생성한 텍스트를 감지할 수 있는 것을 실험적으로 보여준다.

###### Faithful Model Evaluation for Model-Based Metrics (https://aclanthology.org/2023.emnlp-main.464/)
- Anthology ID: 2023.emnlp-main.464 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 처리(NLP)에서는 통계적 유의성 검정을 통해 연구나 실험 결과가 우연히 발생한 것인지, 실제 관계를 나타내는 것인지를 판단한다.
    2. 유의성 검정 단계에서 핵심은 표본 분산에 따른 신뢰 구간을 추정하는 것인데, 기존 작업에서는 경험적인 모델을 사용하기 때문에 지표 모델 오차로 인한 분산 변화를 고려하지 않아 잘못된 결론을 낼 수 있다.
    3. 이 논문에서는 모델 기반 지표의 표본 분산을 계산할 때 지표 모델 오차를 고려하는 수학적 기반을 제시하고, 공개된 벤치마크 데이터셋과 제품 시스템에서의 실험을 통해 특정 실험에서 결론이 변경됨을 보여준다.

###### Content- and Topology-Aware Representation Learning for Scientific Multi-Literature (https://aclanthology.org/2023.emnlp-main.465/)
- Anthology ID: 2023.emnlp-main.465 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 처리 아키텍처 개발에서 representation learning은 중요한 요소인데, 기존 접근 방법들은 문장이나 문서 수준에서의 텍스트 정보 학습에 초점을 맞추었다. 이로인해 다중 문서 설정에서의 하류 응용 프로그램의 성능이 저하되는 문제가 생겼다.
    2. 이 논문에서는 다중 문서 수준으로 표현 학습을 확장한 SMRC2를 제안한다. 이 모델은 콘텐츠로부터의 잠재적 의미 정보와 토폴로지 네트워크로부터의 다양한 관련성 정보를 동시에 학습한다.
    3. 우리의 실험은 우리의 방법의 우수성과 효과를 입증하며, 과학적 다중 문헌 표현 학습에 대한 추가 연구를 촉진하기 위해 코드와 생물 의학 분야의 새로운 데이터 세트를 공개할 것이다.

###### Language Model Quality Correlates with Psychometric Predictive Power in Multiple Languages (https://aclanthology.org/2023.emnlp-main.466/)
- Anthology ID: 2023.emnlp-main.466 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 지식 기반 답변 가능성(KDA)이라는 새로운 자동 평가 메트릭을 제안하여 MCQ 생성의 교육적 가치를 평가한다.
    2. 공간적인 인과관계를 인지하기 위해 대체설적 augmentation과 대조적인 학습을 활용한 NLP 모델의 robustness를 개선하는 방법을 제안한다.
    3. 크로스언어적인 실험을 통해 대용량 LMs의 예측력과 사람의 독해 패턴 간에 유의미한 상관관계를 발견하였다.

###### Joint Entity and Relation Extraction with Span Pruning and Hypergraph Neural Networks (https://aclanthology.org/2023.emnlp-main.467/)
- Anthology ID: 2023.emnlp-main.467 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 정보 추출에서 중요한 작업인 Entity and Relation Extraction (ERE)은 최근 marker-based 파이프라인 모델이 최고 성능을 보이지만, 오류 전파 문제로 여전히 제약을 받는다.
    2. HGERE라는 Hypergraph neural network를 제안하여 오류 전파 문제를 완화하고 다중 entity와 relations간의 상호작용을 고려한다. 
    3. ACE2004, ACE2005, SciERC와 같은 벤치마크에서 수행된 실험 결과, HGERE가 이전의 최고 성능인 PL-marker보다 상당한 개선을 이루었다.

###### Have LLMs Advanced Enough? A Challenging Problem Solving Benchmark For Large Language Models (https://aclanthology.org/2023.emnlp-main.468/)
- Anthology ID: 2023.emnlp-main.468 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최신 언어 모델의 성능이 이전보다 더욱 향상되었지만, 본 논문에서는 LLM의 문제 해결 능력을 평가하기 위한 더욱 어려운 벤치마크 데이터셋인 JEEBench를 제시한다.
    2. JEEBench는 과학적인 지식이 필요한 515개의 고난도 수학, 물리학, 화학 문제를 포함하고 있으며, 이 문제를 해결하기 위해서는 깊은 도메인 지식 위에 기반한 장기적인 추리가 필요하다.
    3. 실험 결과에 따르면, 다양한 오픈소스와 사유 모델의 성능이 최대 40%에 불과하며, 가장 좋은 모델인 GPT-4의 실패 원인은 대수적 조작 오류, 추상적인 개념을 정확하게 수학적 식으로 전환하는 난이도 및 관련 도메인 특정 개념을 검색하는 데 실패하는 것이었다.

###### StrAE: Autoencoding for Pre-Trained Embeddings using Explicit Structure (https://aclanthology.org/2023.emnlp-main.469/)
- Anthology ID: 2023.emnlp-main.469 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 explicit structure을 엄격하게 따르고 tree-structured 표현에서 새로운 contrastive objective를 사용하여 multi-level representations을 효과적으로 학습하는 StrAE (Structured Autoencoder) framework을 제안한다.
    2. 다양한 형태의 구조에 대한 비교를 통해, 결과가 입력된 구조의 정보성(informativeness)에 직접적으로 기인함을 확인하고, 기존의 트리 모델의 경우 이러한 사실이 아니라는 것을 보여준다.
    3. StrAE를 개선하여 모델이 간단한 지역 병합 알고리즘을 사용하여 자체 구성 정의할 수 있도록 확장한 Self-StrAE는 명시적인 계층 구조와 유사한 성능을 보이고, explicit hierarchical compositions와 관련이 없는 기준선들보다 우수한 성능을 보인다.

###### WiCE: Real-World Entailment for Claims in Wikipedia (https://aclanthology.org/2023.emnlp-main.470/)
- Anthology ID: 2023.emnlp-main.470 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 파트-문장(support) 단위로 이루어진 fine-grained 텍스트 entailment 데이터셋인 WiCE를 제안하였다. GPT-3.5를 사용하여 claim을 아래 파트-문장으로 자동 분해하는 전략을 제안하고, 해당 전략이 다른 데이터셋에서도 entailment 모델의 성능을 향상시키는 것을 보였다.
    2. 기존 entailment 데이터셋으로부터 추출한 자연스러운 claim과 evidence 쌍을 사용하여 WiCE 데이터셋을 구축하였다.
    3. WiCE 데이터셋에 있는 진짜 claim들은 기존 모델이 다루기 어려운 검증 및 검색 문제를 포함하고 있음을 보였다.

###### Natural Disaster Tweets Classification Using Multimodal Data (https://aclanthology.org/2023.emnlp-main.471/)
- Anthology ID: 2023.emnlp-main.471 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 소셜 미디어 플랫폼은 의견 표명이나 정보 전달에 널리 이용되며, 재난 관련 작업에도 사용될 수 있다. 그러나 기존의 작업은 이미지나 텍스트와 같은 단일 모달리티에만 초점을 맞춘 것이 일반적이다. 
    2. 본 논문에서는 다중 모달 데이터셋을 다룰 수 있는 시스템을 개발하기 위해 다양한 모델을 탐구한다. 
    3. 다중 모달 트윗을 분류하는데 우수한 계산 효율성과 평가 성능을 가진 시스템을 개발하여 재난 관리를 지원하고 인도주의적 재앙의 상황을 파악하고 피해의 심각성과 유형을 평가하는 것을 목표로 한다.

###### On the Challenges of Using Black-Box APIs for Toxicity Evaluation in Research (https://aclanthology.org/2023.emnlp-main.472/)
- Anthology ID: 2023.emnlp-main.472 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 독성에 대한 인식은 시간이 지남에 따라 변화하며 지리 및 문화적 배경에 따라 다를 수 있다. 따라서 Perspective API와 같은 상용 블랙박스 독성 감지 API는 정적이 아니라 지속적으로 리트레이닝되어 약점과 바이어스를 해결한다.
    2. 이 논문에서는 독성을 억제하는 모델과 방법을 비교하는 연구 결과의 재현 가능성에 대한 영향을 평가한다. 논문은 상속된 자동 독성 점수에 의존한 연구는 부정확한 결과로 이어질 수 있다는 결과를 제시한다.
    3. Perspective API의 최신 버전으로 HELM의 모든 모델을 독성에 대해 점수를 다시 매기면 널리 사용되는 기반 모델들의 순위가 달라지는 것을 밝혀냈다. 연구들 간에 사과-사과 비교를 적용할 때 주의가 필요하며, 시간이 지남에 따른 독성 평가에 더 구조적인 접근이 필요하다는 주장이다.

###### RoBoCoP: A Comprehensive ROmance BOrrowing COgnate Package and Benchmark for Multilingual Cognate Identification (https://aclanthology.org/2023.emnlp-main.473/)
- Anthology ID: 2023.emnlp-main.473 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 고유어의 식별은 역사 언어학에서 기반적인 과정이며, 추가 연구의 기반이 된다. 로망스 언어를 위한 여러 cognate 데이터베이스가 있지만, 그들은 흩어져 있거나 불완전하며, 불확실한 정보를 가지고 있거나 가용성이 불확실하다.
    2. 본 논문에서는 로망스 언어의 고유어와 차용어에 기반한 포괄적인 데이터베이스를 제안한다. 우리는 루마니아어, 이탈리아어, 스페인어, 포르투갈어, 프랑스어의 전자 사전을 구문 분석하여 어떤 두 개의 로망스 언어 간에 고유어 쌍을 추출한다.
    3. 이 자원을 기반으로 우리는 머신러닝과 딥러닝 기반 방법을 적용하여 로망스 언어의 어떤 두 쌍에 대해서도 고유어를 자동으로 감지하는 강력한 벤치마크를 제안한다. 우리는 고유어의 자동 식별이 어려운 과제에 대해서 약 94% 정확도로 가능하다는 것을 발견했다.

###### Instructive Dialogue Summarization with Query Aggregations (https://aclanthology.org/2023.emnlp-main.474/)
- Anthology ID: 2023.emnlp-main.474 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존 대화 요약 방법들은 사용자의 특정 관심사를 고려하지 않고 요약을 생성하는데, 이는 사용자가 특정 주제나 측면에 집중하는 경우에 문제가 될 수 있다. 
    2. 이 논문에서는 instruction-finetuned 언어 모델의 발전을 통해 요약 방법을 향상시키기 위해 instruction-tuning을 대화에 도입하는 방법을 제안한다. 
    3. 실험 결과는 우리의 모델이 기존의 성능 경쟁 모델을 능가하며, 더 큰 모델보다도 좋은 통사성과 일반화 능력을 가진다는 것을 보여준다.

###### Semantic matching for text classification with complex class descriptions (https://aclanthology.org/2023.emnlp-main.475/)
- Anthology ID: 2023.emnlp-main.475 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 텍스트 분류기를 새로운 클래스에 적응시키는 것은 비용이 많이 드는 작업이다. 이전 연구들은 기존 클래스의 클래스 설명이나 라벨을 활용하여 이 문제를 해결해왔으나, 부족한 점이 여전히 존재한다.
    2. 이 논문은 텍스트 분류를 매칭 문제로 바라보고, 모델이 관련된 클래스 설명과 예제를 매칭시키는 방식으로 새로운 클래스에 대한 zero-shot과 few-shot 학습을 수행하는 방법을 제안한다.
    3. 실험 결과, 이 접근 방법은 복잡한 클래스 설명을 가진 텍스트 분류 작업에서 강력한 zero-shot 성능과 few-shot 샘플에 대한 확장성을 보여주며, 강력한 베이스라인 모델을 10-shot 설정에서 22.48% (평균 정밀도) 능가한다. 또한, Model-Agnostic Meta-Learning (MAML) 알고리즘을 zero-shot 매칭 설정으로 확장하여 zero-shot 성능을 4.29% 향상시킨다.

###### MADNet: Maximizing Addressee Deduction Expectation for Multi-Party Conversation Generation (https://aclanthology.org/2023.emnlp-main.476/)
- Anthology ID: 2023.emnlp-main.476 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다자간 대화(MPC)를 그래프 신경망을 사용하여 모델링하는 기존 방법은 대상자 레이블에 강한 의존성이 있으며, 각 발언이 반드시 "@" 또는 동등한 대상자 레이블과 함께 표시되어야 하는 이상적인 상황에만 적용할 수 있다.
    2. 우리는 MPC에서 흔한 대상자 레이블의 부족이라는 문제를 연구하기 위해, MPC 생성을 위한 이질적 그래프 신경망에서 대상자 연역 기대값을 극대화하는 MADNet을 제안한다.
    3. 실험 결과, 우분투 IRC 채널 벤치마크에서 MADNet이 MPC 생성 과제에서 다양한 기준선 모델보다 더 좋은 성능을 보여주며, 특히 일부 대상자 레이블이 누락된 더 일반적이고 어려운 설정에서 유용하게 사용됨을 보여준다.

###### GLEN: Generative Retrieval via Lexical Index Learning (https://aclanthology.org/2023.emnlp-main.477/)
- Anthology ID: 2023.emnlp-main.477 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Generative retrieval은 질의에 관련된 문서의 식별자를 직접 생성하는 문서 검색의 새로운 패러다임을 제시하며, 보조 색인 구조를 구축하지 않으면서 이점을 취한다."
    2. 기존 연구는 사전 훈련된 언어 모델과 식별자의 지식 간의 불일치와 학습과 추론 간의 차이라는 두 가지 주요 도전에 직면한다.
    3. 새로운 generative retrieval 방법인 GLEN은 동적 어휘 식별자를 효과적으로 활용하여 의미 있는 어휘 식별자와 질의와 문서 간의 관련 신호를 학습하고, 증가하지 않는 추가적인 오버헤드 없이 문서를 순위 매기는 데 식별자 가중치를 사용하는 충돌 방지 추론을 활용한다. NQ320k, MS MARCO 및 BEIR와 같은 다양한 기준 데이터셋에서 GLEN이 기존 generative retrieval 방법에 비해 최고 수준 또는 경쟁력 있는 성능을 달성하는 것을 실험 결과로 증명하였다.

###### Turn-Level Active Learning for Dialogue State Tracking (https://aclanthology.org/2023.emnlp-main.478/)
- Anthology ID: 2023.emnlp-main.478 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화 상태 추적(DST)은 과제 지향 대화 시스템에서 중요한 역할을 한다. 그러나 turn-by-turn으로 주석이 달린 대화 데이터를 수집하는 것은 비용이 많이 들고 비효율적이다. 
    2. 이 논문에서는 DST를 위한 새로운 turn-level active learning 프레임워크를 제안하여 주석을 달기 위해 대화에서 턴을 선택한다. 
    3. 제한된 레이블 예산을 고려한 실험 결과, 대화 턴의 선택적 주석이 효과적임을 보여준다. 또한, 우리의 접근 방식은 훨씬 적은 주석 데이터로 전통적인 훈련 접근 방식과 비교할 수 있는 DST 성능을 효과적으로 달성하며, 새로운 대화 데이터에 주석을 달기 위한 보다 효율적인 방법을 제공한다.

###### ReSee: Responding through Seeing Fine-grained Visual Knowledge in Open-domain Dialogue (https://aclanthology.org/2023.emnlp-main.479/)
- Anthology ID: 2023.emnlp-main.479 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 텍스트 기반 대화 시스템에 시각적 지식을 포함하는 것은 인간의 사고, 상상, 의사 소통 방식을 모방하는 잠재적인 방향이 되었다. 
    2. 그러나 기존의 다중모달 대화 시스템은 제한된 데이터셋의 규모와 품질 또는 시각적 지식의 대략적인 개념에 제한된다.
    3. 이 논문에서는 시각적 지식을 "턴-레벨"과 "개체-레벨"로 더 잘게 분리하고, 인터넷이나 대규모 이미지 데이터셋에서 향상된 시각 정보를 검색하여 정확성과 다양성을 높이는 새로운 패러다임을 제안한다.

###### Modeling Conceptual Attribute Likeness and Domain Inconsistency for Metaphor Detection (https://aclanthology.org/2023.emnlp-main.480/)
- Anthology ID: 2023.emnlp-main.480 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 유사한 속성의 공유가 메타포 표현에서 암시적 의미를 유추하는 데 중요하다는 것에 기반하여 메타포 탐지를 위한 Attribute Likeness and Domain Inconsistency Learning (AIDIL) 프레임워크를 제안한다.
    2. 속성 계층 구조 네트워크를 활용하여 원본과 대사 개념 사이의 유사한 속성을 찾고, 도메인 대조 학습 전략을 통해 원본과 대사 도메인의 의미적 불일치를 학습한다.
    3. 네 개의 데이터셋을 사용한 실험 결과, 제안하는 방법이 이전 최첨단 방법보다 우수한 성능을 보이며, 일반화 능력을 입증한다.

###### Referring Image Segmentation via Joint Mask Contextual Embedding Learning and Progressive Alignment Network (https://aclanthology.org/2023.emnlp-main.481/)
- Anthology ID: 2023.emnlp-main.481 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1.   referring image segmentation은 자연어 표현에 해당하는 이미지의 객체에 대한 픽셀 단위 마스크를 예측하는 작업이다. 기존의 cascade framework를 사용한 방법에서는 복잡한 문제를 여러 단계로 나누어 처리하지만, 특정 단계에서 가장 관련성이 높은 정보에 집중하며 이른 단계에서 전파된 오류를 수정하는 과제를 해결하지 못하는 한계가 있다.
    2. 이 논문에서는 JMCELN을 제안하였는데, 이는 Learnable Contextual Embedding과 Progressive Alignment Network (PAN)을 통합하여 Cascade Framework를 강화한 것이다. Learnable Contextual Embedding 모듈은 현재 마스크 예측 결과를 기반으로 추론 정보를 동적으로 저장하고 활용하여 더 나은 마스크 예측 정확도를 위해 관련 정보를 적응적으로 잡아내고 개선한다.
    3. 또한, Progressive Alignment Network (PAN)은 JMCELN의 핵심 부분으로 도입되었는데, 이는 이전 레이어의 출력을 현재 출력의 필터로 사용하여 서로 다른 단계에서의 예측 차이를 줄이는 역할을 한다. PAN은 예측을 반복적으로 정렬함으로써 Learnable Contextual Embedding이 추론에 더 구별력 있는 정보를 통합하도록 안내하여 예측 품질을 향상시키고 오류 전파를 줄인다.

###### Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study (https://aclanthology.org/2023.emnlp-main.482/)
- Anthology ID: 2023.emnlp-main.482 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 큰 디코더만 있는 언어 모델은 RETRO와 같은 retrieval을 사용하여 perplexity 면에서 크게 향상될 수 있으나, 텍스트 생성 품질과 downstream task 정확성에 대한 영향은 불분명하다. 
    2. 이 연구에서는 RETRO와 일반 GPT, 검색 향상 GPT를 fine-tuning 또는 inference 단계에서 비교하여 포괄적인 연구를 수행하였으며, 다음과 같은 새로운 결과를 얻었다. 
    3. RETRO는 degeneration (반복)이 훨씬 적고 신뢰할만한 데이터베이스를 사용할 경우에는 독성이 약간 낮으면서 사실적인 정확성이 더 높으며, 지식-집중적인 작업에서 GPT보다 우월한 결과를 보여준다.

###### SCITAB: A Challenging Benchmark for Compositional Reasoning and Claim Verification on Scientific Tables (https://aclanthology.org/2023.emnlp-main.483/)
- Anthology ID: 2023.emnlp-main.483 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 과학적 사실 검증 벤치마크는 크라우드소싱된 주장으로 인한 편향과 텍스트 기반 증거에 대한 지나친 의존 등의 문제점이 있다. 
    2. 이 연구에서는 진짜 과학 논문에서 왔으며, 구성적 추론이 필요한 1.2K개의 전문가 검증된 과학적 주장과 증거를 포함하는 과학적 테이블로 구성된 SCITAB라는 도전적인 평가 데이터셋을 제시한다.
    3. 우리의 분석은 테이블의 기반, 주장의 모호성 및 구성적 추론과 같은 SCITAB에 의해 제기된 독특한 문제들을 밝혀냈다.

###### Training Simultaneous Speech Translation with Robust and Random Wait-k-Tokens Strategy (https://aclanthology.org/2023.emnlp-main.484/)
- Anthology ID: 2023.emnlp-main.484 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 로우 레이턴시 상황에서 말 번역의 고품질 번역을 보장하기 위한 simultaneous speech translation (SimulST)은 오디오와 텍스트 간의 모달리티 차이로 인해 어려움을 겪고 있다.
    2. 이 논문에서는 Modality 간의 차이를 해결하기 위해 Montreal Forced Aligner (MFA)를 활용하여 acoustic encoder의 사전 학습을 하고, token-level 크로스-모달 정렬을 통해 SimulMT의 wait-k 정책이 SimulST에 적합하게 적응할 수 있도록 한다.
    3. 논문에서 제안하는 robust and random wait-k-tokens 전략을 사용하여, 단일 모델이 다양한 레이턴시 요구에 부합하고 추론 중에 발생하는 경계 정렬의 오류 누적을 최소화할 수 있는 것으로 실험 결과를 보여준다.

###### SCENE: Self-Labeled Counterfactuals for Extrapolating to Negative Examples (https://aclanthology.org/2023.emnlp-main.485/)
- Anthology ID: 2023.emnlp-main.485 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 부정 사례 (예를들어 부언 관계, 답을 할 수 없는 질문, 거짓된 주장 등)를 탐지하는 것은 많은 자연어 이해 문제에서 중요하고 어려운 측면이다. 그러나 도메인 특정성과 비용 문제로 인해 도전적인 부정 사례를 수동으로 수집하는 것은 어렵고 비용이 많이 든다. 이 논문에서는 SCENE(Self-labeled Counterfactuals for Extrapolating to Negative Examples)라는 자동 방법을 제안하여 모델이 도전적인 부정 사례를 감지하는 능력을 크게 향상시키는 훈련 데이터를 합성한다.
    2. 기존의 데이터 증강은 기존의 레이블에 대해 새로운 예제를 합성하지만, SCENE은 양성 예제만으로부터 부정 예제를 생성할 수 있다. SCENE은 양성 예제를 마스킹 인풀링 모델로 변형한 후, 자체 학습 휴리스틱에 따라 결과 예제가 부정인지 여부를 판단한다.
    3. SCENE은 답변 가능한 훈련 예제에만 접근하여 SQuAD 2.0와 같은 데이터셋에서 모델의 성능 차이 69.6%를 닫을 수 있으며, boolean 질문 응답과 텍스트 함의 인식으로 확장될 수 있으며, SQuAD에서 ACE-whQA로의 일반화를 향상시킨다.

###### Enhancing Code-Switching for Cross-lingual SLU: A Unified View of Semantic and Grammatical Coherence (https://aclanthology.org/2023.emnlp-main.486/)
- Anthology ID: 2023.emnlp-main.486 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 고-리소스 언어에서의 언어 이해(SLU)의 성공에도 불구하고, zero-shot 상황과 같은 저-리소스 환경에서 유사한 성능을 달성하는 것은 제한된 레이블된 훈련 데이터 때문에 현실적인 어려움이 남아있다.
    2. 우리는 zero-shot 크로스-언어 SLU를 향상시키기 위해 최근에 나온 방법들을 다루고 있으며, 고려하지 못한 토큰 수준의 의존성과 문맥 유사성을 고려한 새로운 메소드인 SoGo를 제안한다.
    3. 실험과 분석을 통해 SoGo가 MultiATIS++의 9개 언어에서 우수한 성능을 보인다는 것을 확인했다.

###### Task-Agnostic Low-Rank Adapters for Unseen English Dialects (https://aclanthology.org/2023.emnlp-main.487/)
- Anthology ID: 2023.emnlp-main.487 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델 (LLM)은 표준 미국 영어를 우위에 두고 균형이 맞지 않는 말뭉치로 훈련되었다. 그 결과, 다른 방언의 사용자는 이러한 기술과 상호 작용할 때 더 많은 실패를 경험한다. 이 연구는 언어 기술이 다양한 영어 방언을 수용하도록 설계되어야 하며 그 반대로 되어서는 안된다는 믿음을 공유한다.
    2. 기존의 방언 연구는 발전하고 새로운 방언들에 대해서 일관되게 확장할 수 있는 방법이 없다. 따라서 이 논문은 HyperLoRA라는 방법을 제안한다.
    3. HyperLoRA는 전문 언어학적 지식을 활용하여 하이퍼네트워크를 통해 리소스 효율적인 적응을 가능하게 한다. 방언별와 방언 간의 정보를 분리함으로써 HyperLoRA는 과제에 대한 일반화 능력을 향상시키고, 더 많은 파라미터 수에 대해 확장성이 높으며, 예측치가 없는 방언의 성능에서 가장 우수하거나 경쟁력 있는 성과를 달성한다.

###### Federated Learning of Large Language Models with Parameter-Efficient Prompt Tuning and Adaptive Optimization (https://aclanthology.org/2023.emnlp-main.488/)
- Anthology ID: 2023.emnlp-main.488 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Federation learning (FL)은 분산 데이터로 협업하는 모델 훈련을 가능하게 하는 유망한 패러다임이지만, 대규모 언어 모델의 훈련 과정은 주요 파라미터의 업데이트를 필요로 하므로 실제 상황에서 LLMs를 다루기 위한 FL 기술의 적용이 제한되고 있다. 
    2. 이 논문에서는 FedPepTAO라는 효율적이고 효과적인 FL을 위한 Parameter-efficient prompt Tuning 접근 방식을 제안한다. 
    3. Partial prompt tuning 및 adaptive optimization 기법을 통해 속도와 성능을 개선하고 비독립, 동일 분포가 아닌 분산 데이터로 발생하는 클라이언트 drift 문제를 해결한다.

###### TheoremQA: A Theorem-driven Question Answering Dataset (https://aclanthology.org/2023.emnlp-main.489/)
- Anthology ID: 2023.emnlp-main.489 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. GPT-4와 PaLM-2와 같은 최근의 LLMs는 GSM8K와 같은 기본 수학 문제를 90% 이상의 정확도로 해결하는 데 엄청난 발전을 이루었지만, 수학적 정리를 필요로 하는 더 어려운 수학 문제를 해결하는 능력은 아직 조사되지 않았다.
    2. 이 논문에서는 AI 모델이 과학 문제를 해결하기 위해 정리를 적용하는 능력을 평가하기 위해 설계된 첫 번째 정리 기반 질문-응답 데이터 세트인 TheoremQA를 소개한다.
    3. TheoremQA는 전문가들에 의해 담당 분야인 수학, 물리학, 전기 및 컴퓨터 공학, 금융에서 350개의 정리를 다루는 800개의 고품질 문제를 포함하고 있으며, 다양한 프롬프팅 전략(Chain-of-Thoughts, Program-of-Thoughts 등)으로 16개의 대형 언어 및 코드 모델의 평가를 수행하였다.

###### Scalable-DSC: A Structural Template Prompt Approach to Scalable Dialogue State Correction (https://aclanthology.org/2023.emnlp-main.490/)
- Anthology ID: 2023.emnlp-main.490 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Dialogue state error correction"은 대화 상태 추적(DST)의 오류 전파 문제를 완화하기 위해 제안된 방법인데, 이러한 접근 방식은 특정 DST 모델과 강하게 얽혀 있어 다른 DST 모델에 적용하기가 제한된다.
    2. 이를 해결하기 위해, 우리는 Scalable-DSC라는 방법을 제안하는데, 이는 잘못된 슬롯 값들을 어떤 DST 모델이 예측한 대화 상태에서 수정할 수 있다.
    3. 이를 위해 우리는 Structural Template Prompt (STP)를 제안하고, 미리 정의된 템플릿 옵션을 기반으로 정규화된 자연어 시퀀스로 예측된 대화 상태를 변환하여 수정된 대화 상태 시퀀스를 생성한다. 이러한 방법을 통해 우리의 모델은 MultiWOZ 2.0-2.4에서 최고의 결과를 얻었다.

###### Don’t Trust ChatGPT when your Question is not in English: A Study of Multilingual Abilities and Types of LLMs (https://aclanthology.org/2023.emnlp-main.491/)
- Anthology ID: 2023.emnlp-main.491 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델은 다양한 자연어 처리 (NLP) 태스크에서 뛰어난 자연어 이해 능력을 보여주었으며, 여러 언어에서의 능력도 입증되었다. 그러나 LLM의 다중 언어 능력 획득 방법과 언어별 성능의 차이에 대한 기본적인 질문들은 여전히 존재한다.
    2. 이 논문에서는 LLM의 다중 언어 능력을 질적과 양적 방식으로 평가하기 위한 체계적인 방법을 제안한다. 실험 결과는 GPT와 같은 LLM들이 다양한 언어 간에 배운 지식을 효과적으로 전달할 수 있으며, 번역 불변 (translation-equivariant) 태스크에서 일관된 결과를 보여준다는 것을 입증하였다. 
    3. 그러나 번역 변동 (translation-variant) 태스크에서 정확한 결과를 제공하기 어려우며, 이러한 경우 사용자의 신중한 판단이 요구된다.

###### M3Seg: A Maximum-Minimum Mutual Information Paradigm for Unsupervised Topic Segmentation in ASR Transcripts (https://aclanthology.org/2023.emnlp-main.492/)
- Anthology ID: 2023.emnlp-main.492 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 주제 분할(M3Seg)은 주제 경계를 탐지하고, 자동 음성 인식 변환(transcriptions)을 주제 의미에 의해 제한된 세그먼트로 분할한다. 
    2. 이 논문에서는 M3Seg라는 새로운 Maximum-Minimum Mutual information 패러다임을 제안하며, 양방향 데이터를 사용하지 않고 선형 주제 분할 수행한다.
    3. 실험 결과는 M3Seg의 효과를 입증하며, 다른 최신 방법보다 상당한 개선(18%-37%)을 보인다.

###### Empirical Study of Zero-Shot NER with ChatGPT (https://aclanthology.org/2023.emnlp-main.493/)
- Anthology ID: 2023.emnlp-main.493 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "이 논문은 ChatGPT와 명명된 entity 인식(NER) 태스크에 대한 zero-shot 정보 추출에서 LLM의 성능을 탐구한다. 논문에서는 LLM의 주목할만한 추론 능력에서 영감을 받아 NER에 맞게 맞춤형 추론 전략을 제안한다."
    2. "논문에서는 NER 태스크를 레이블별로 간단한 하위 문제로 분해하는 분해형 질문-응답 패러다임과, 구문적 augmentation을 제안한다. 제안된 메서드는 zero-shot NER에서 중요한 개선을 이루며, 중국어와 영어 데이터셋, 특정 도메인과 일반 도메인 시나리오를 포함한 7개의 벤치마크에서 효과적으로 작동한다."
    3. "또한 논문은 오류 유형에 대한 포괄적인 분석과 최적화 방향에 대한 제안을 제시하며, few-shot 환경과 다른 LLMs에서도 제안된 방법의 효과를 검증한다."

###### Automatic Prompt Optimization with “Gradient Descent” and Beam Search (https://aclanthology.org/2023.emnlp-main.494/)
- Anthology ID: 2023.emnlp-main.494 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델은 일반적인 목적의 에이전트로서 놀라운 성능을 보여주었지만, 그 성능은 번거로운 시행착오 노력을 통해 수작업으로 작성된 프롬프트에 매우 의존적이다.
    2. 우리는 ProTeGi라는 간단하고 비매개 변수적인 솔루션을 제안하여 이 문제를 해결한다. 이 알고리즘은 LLM API와 학습 데이터에 접근 가능한 것을 전제로 하여 프롬프트를 자동으로 개선하는데, 훈련 데이터를 미니배치로 사용하여 현재 프롬프트에 비판을 표현하는 자연어 "기울기"를 생성한다.
    3. 프롬프트의 개선은 그래디언트 강하 방법을 따르며, 빔 서치와 밴딧 선택 프로세스에 의해 안내된다. 이를 통해 ProTeGi 알고리즘은 기존의 프롬프트 편집 기법보다 우수한 성능을 보여주며, 데이터를 사용하여 모호한 작업 설명을 보다 정확한 주석 지침으로 재작성하여 초기 프롬프트의 성능을 최대 31% 개선할 수 있다.

###### Active Retrieval Augmented Generation (https://aclanthology.org/2023.emnlp-main.495/)
- Anthology ID: 2023.emnlp-main.495 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 큰 언어 모델은 언어를 이해하고 생성하는 능력이 뛰어나지만, 사실적이지 않은 결과물을 만들어내거나 환각을 일으킬 가능성이 있다. 
    2. 외부 지식 자원에서 정보를 검색하여 언어 모델을 보강하는 방법이 있는데, 이 논문에서는 지속적으로 정보를 수집하는 일반적인 시나리오에서 활용 가능한 메서드를 제안한다. 
    3. 제안된 FLARE 방법은 다음 문장의 예측을 사용하여 미래 내용을 예측하고, 이를 쿼리로 사용하여 신뢰도가 낮은 토큰을 포함하는 문장을 대체하기 위해 관련 문서를 검색한다. FLARE은 4개의 장문 기반 지식 생성 작업/데이터셋에서 우수한 결과를 보여주며, 우리 방법의 효과를 입증한다.

###### GD-COMET: A Geo-Diverse Commonsense Inference Model (https://aclanthology.org/2023.emnlp-main.496/)
- Anthology ID: 2023.emnlp-main.496 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. AI 시스템이 다양한 배경의 사용자를 위해 문화적으로 인식하도록 설계하는 것이 중요해지고 있다. 
    2. 이 논문에서는 GD-COMET이라는 지리적으로 다양한 문화를 고려한 공통 감각 추론 모델을 제안한다. 
    3. GD-COMET은 다양한 문화에 관련된 추론을 생성할 수 있으며, 인간 평가와 임무 평가를 통해 효과적임을 입증하고 있다.

###### Multi-level Adaptive Contrastive Learning for Knowledge Internalization in Dialogue Generation (https://aclanthology.org/2023.emnlp-main.497/)
- Anthology ID: 2023.emnlp-main.497 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "지식 기반 대화 생성은 외부 지식을 활용하여 문맥을 보완함으로써 텍스트 쇠퇴 문제를 완화하는 것을 목표로 한다. 그러나 모델은 종종 이러한 정보를 인간과 같은 방식으로 응답에 내재시키는 데 실패한다."
    2. "복사 스타일의 쇠퇴는 모델이 지식 세그먼트를 단순히 일반적인 응답에 삽입하기 때문에 발생하며, 이로 인해 생성된 응답은 지루하고 일관성이 없으며 상호 작용이 부족하다."
    3. "이 논문에서는 약한 가능성 목적의 주된 원인으로서의 복사 스타일의 쇠퇴를 파악하고, MACL (Multi-level Adaptive Contrastive Learning) 프레임워크를 제안하여 토큰 수준과 시퀀스 수준에서 쇠퇴 행동을 패널티로 부과하는 동적으로 부정적인 예시를 샘플링한다."

###### Enhancing Biomedical Lay Summarisation with External Knowledge Graphs (https://aclanthology.org/2023.emnlp-main.498/)
- Anthology ID: 2023.emnlp-main.498 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이전의 자동 요약 접근법들은 기술적인 독자를 위해 작성된 출처 기사에 완전히 의존하며, 모든 기술적 개념을 명시적으로 정의하거나 일반인 대상의 필요한 배경 정보를 모두 제공하지는 않는다.
    2. 우리는 바이오의학 요약 데이터셋인 eLife를 article-specific knowledge graph로 보강함으로써 이 문제를 해결한다.
    3. 우리의 결과는 그래프 기반의 도메인 지식을 통합하는 것이 요약 문장의 가독성을 크게 향상시키고 기술적 개념의 설명을 개선하여 요약에 상당한 이점을 제공할 수 있다는 것을 확인한다.

###### A Diffusion Weighted Graph Framework for New Intent Discovery (https://aclanthology.org/2023.emnlp-main.499/)
- Anthology ID: 2023.emnlp-main.499 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "새로운 의도 발견 (NID)은 알려진 의도와 함께 라벨이 없는 데이터에서 새로운 의도를 인식하는 것을 목표로 한다. 하지만 기존 방법들은 샘플들 간의 구조적 관계를 고려하지 않고 있어서, 품질과 수량 사이의 균형을 이루지 못하게 되어 새로운 의도 클러스터의 형성과 사전 학습 지식의 효과적인 전달을 방해한다."
    2. "우리는 데이터에 내재된 의미적 유사성과 구조적 관계를 포착하기 위해 새롭게 Diffusion Weighted Graph Framework (DWGF)을 제안한다. 이를 통해 더 충분하고 신뢰성 있는 지도 신호를 생성할 수 있다."
    3. "실험 결과, 우리의 방법은 여러 벤치마크 데이터셋에서 모든 평가 메트릭을 기준으로 최신 모델을 능가하는 것을 확인했다. 코드와 데이터는 공개될 예정이다."


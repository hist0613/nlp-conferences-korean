# Korean Three-Line Summarizations of Papers 2340-2366 in Proceedings of the 10th Workshop on Argument Mining
###### Proceedings of the 10th Workshop on Argument Mining (https://aclanthology.org/2023.argmining-1.0/)
- Anthology ID: 2023.argmining-1.0 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Detecting Argumentative Fallacies in the Wild: Problems and Limitations of Large Language Models (https://aclanthology.org/2023.argmining-1.1/)
- Anthology ID: 2023.argmining-1.1 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 기존의 자연어 텍스트에서 오류를 식별하는 방법은 실험 환경을 국한시키기 때문에 실제 상황에서의 적용성과 유용성을 이해하기 어렵다. 본 논문에서는 자연어 텍스트에서의 오류 식별에 대한 데이터 기반 방법의 한계를 분석한다.
    2. 이를 위해 우리는 첫째로 자연어 논증 체계로 이루어진 검증용 말뭉치를 생성하였으며, 둘째로 자연어 텍스트에서의 오류 식별 작업에 대한 새로운 경험적 결과를 제공한다.
    3. 또한 새로운 검증용 말뭉치를 고려하여 테스트 데이터 도메인 외부에서 관찰된 오류들을 분석하고, 이에 대한 중요한 한계점을 지적하며 향후 연구에 반영해야 할 사항들을 제시한다. 특히, 우리가 이러한 시스템을 실제 현장에 도입하려면.

###### Using Masked Language Model Probabilities of Connectives for Stance Detection in English Discourse (https://aclanthology.org/2023.argmining-1.2/)
- Anthology ID: 2023.argmining-1.2 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 이 연구는 주장의 입장을 탐지하기 위해 담화 연결어의 역할을 operation하는 접근법을 소개한다. 
    2. 이 연구는 주장과 그를 지지하거나 반대하는 전제 사이에 삽입된 담화 연결어의 확률을 이용하여 그 유틸리티를 조사한다. 
    3. LightGBM 분류기를 사용하여 영어 담화에서 주장 탐지를 위한 유망한 결과를 보여주며, 이러한 특징들이 주장 탐지를 포함한 논거 분석 작업을 향상시키는 잠재력을 강조한다.

###### Teach Me How to Argue: A Survey on NLP Feedback Systems in Argumentation (https://aclanthology.org/2023.argmining-1.3/)
- Anthology ID: 2023.argmining-1.3 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 교육에서 논증을 사용하는 것은 학생들의 비판적 사고 기술을 향상시키는 데 도움이되었고, 논증을 위한 컴퓨터 모델도 개발되어이 프로세스를 더 지원하고 있다. 
    2. 그러나 이러한 모델은 논증의 특정 점수를 예측한 이유, 즉 왜 논쟁이 좋거나 나쁜지 설명할 수 없기 때문에, 사용자에게 건설적인 피드백을 제공하여 비판적 사고 기술을 강화하기가 어렵다.
    3. 이 논문에서는 NLP 피드백 시스템을 탐색하고 각각의 피드백을 "풍부성, 시각화, 상호 작용 및 개인화"라는 네 가지 중요한 피드백 차원으로 분류한다.

###### Constituency Tree Representation for Argument Unit Recognition (https://aclanthology.org/2023.argmining-1.4/)
- Anthology ID: 2023.argmining-1.4 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 기존의 문장에서 주제를 추출하는 방법은 단어의 근접성에만 의존하기 때문에 문장의 통사구조를 고려하지 않는다. 우리는 문장의 구성성 트리 표현을 활용하여 토큰 수준에서 주장 단위(ADU)를 예측하는 이점을 조사한다.
    2. 우리는 문장 내의 주장의 구조 특성을 포착하기 위해 구성성 트리 표현을 사용하는 효과를 평가한다. 우리는 근접한 단어 간의 단순한 선형 의존성보다 구성성 구조가 더 효과적임을 경험적으로 보여준다.
    3. 우리의 접근 방식은 구성성 트리와 함께 그래프 신경망을 활용하여 주장 단위 인식을 위해 특정하게 적용한다. 우리의 모델은 토큰 수준에서 주장 단위를 인식하는 기존의 방법보다 우수한 결과를 보여준다.

###### Stance-Aware Re-Ranking for Non-factual Comparative Queries (https://aclanthology.org/2023.argmining-1.5/)
- Anthology ID: 2023.argmining-1.5 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 비팩티브 비교 쿼리를 기반으로 랭킹을 재정렬하는 방식을 제안하고, 비교 대상에 대한 태도를 표현하는 결과를 고려하여 검색 효과를 향상시킨다. 
    2. Touché 2022에서 비교적인 인수 검색에 대해 제출된 26개의 결과에 적용하여, 완벽한 오라클 스탠스 레이블이 사용 가능할 때 우리의 스탠스-의식적 재랭킹은 모든 결과에 대해 검색 효과를 크게 향상시킨다. 
    3. GPT-3.5를 기반으로 한 실용적인 스탠스 탐지기를 사용할 때 우리의 재랭킹은 모든 결과에 대해 효과를 향상시키지만, 유의한 향상은 단 6개뿐이다.

###### Legal Argument Extraction from Court Judgements using Integer Linear Programming (https://aclanthology.org/2023.argmining-1.6/)
- Anthology ID: 2023.argmining-1.6 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 법적 주장은 법적 지식의 핵심 요소 중 하나이며, 법원 판결의 비구조적인 텍스트에서 다양한 방식으로 표현된다. 법원 판결에서 주장을 추출하여 범주화하고 구조화된 형식으로 저장하여 과거 주장의 대량 데이터베이스를 생성할 수 있다. 이러한 데이터베이스는 새로운 사건에 적합한 주장을 제안하는 데 유용할 것이다.
    2. 이 논문에서는 minimal supervision을 사용하여 인도의 최고 법원 판결에서 주장을 추출하는 것에 초점을 맞추었다. 
    3. 우리는 먼저 주장 추출에 유용한 일부 문장 수준의 주장 표식을 식별하고, Integer Linear Programming (ILP)를 사용하여 여러 개의 약한 증거를 결합하여 전체 문서 수준의 최적 법적 주장을 얻는 유연한 텍스트 분할 문제로 법적 주장 추출 문제를 모델링했다.

###### Argument Detection in Student Essays under Resource Constraints (https://aclanthology.org/2023.argmining-1.7/)
- Anthology ID: 2023.argmining-1.7 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 비교적 변덕스러운 패턴에 의존하는 딥 모델의 robustness 한계로 인해, 대조 학습과 반사적 augmentation을 활용하여 robustness를 향상시키려고 한다.
    2. 여러 counterfactual들을 종합하여 예측 분포를 공동 결정하여 각 용어의 인과관계를 강하게 지도하는 새로운 augmentation을 제안한다.
    3. 실험 결과는 집합적 의사 결정 기반 새로운 방법을 사용하여 task model 이펙트(bias)에 덜 민감하며, 다양한 차원에서 효과적으로 개선되었음을 보여준다.
    
    1. 학생들의 비판적 사고 발달과 교육, 직업 발전에 있어서 효과적인 주장력은 중요하다. 주장 요소를 탐지하는 것은 학생들의 주장력 평가 시스템 개발에 중요하다.
    2. 기존의 지도 학습 방법은 대량의 신뢰할 수 있는 학습 예제가 필요하지만, 학생 작문에 대해서는 사용하기 어려울 수 있다.
    3. low-resource argument detection을 위한 intrinsic entailment 관계와 prompt-tuning 전략을 결합하여 데이터 및 계산 요구를 줄이는 low-resource classification 접근 방법을 제안한다. 실험 결과는 예측 정확도를 저해하지 않으면서도 argument detection 모델의 훈련에 필요한 데이터와 계산 요구를 줄이는 우리의 방법의 효과적임을 보여준다.

###### Towards Fine-Grained Argumentation Strategy Analysis in Persuasive Essays (https://aclanthology.org/2023.argmining-1.8/)
- Anthology ID: 2023.argmining-1.8 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 우리는 argumentation 전략을 효과적이고 설득력 있는 텍스트를 작성하는 데 사용되는 수단으로 정의하였다. 이전 연구들은 상대적으로 대략적인 분석을 수행했으나, 우리는 더 상세한 분석을 위해 더 나아갈 것이다.
    2. 우리는 Argument Annotated Essays corpus의 주장과 전제의 특정 유형에 대한 주석을 확장하고, 이들을 자동으로 식별하기 위한 모델을 제안하고 첫 번째 결과를 제시한다.
    3. 또한, 에세이 구조, argument 구성 요소의 "흐름", 주장-전제 구성 요소의 형성 방식, 에세이 종류 및 개별 작성자의 역할과 관련하여 나타나는 사용 패턴에 대해 논의한다.

###### Dimensionality Reduction for Machine Learning-based Argument Mining (https://aclanthology.org/2023.argmining-1.9/)
- Anthology ID: 2023.argmining-1.9 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 기계 학습 알고리즘을 훈련시키는 데 사용되는 고차원 언어 기능 벡터 대신에, 입력 데이터의 차원을 줄이는 것의 잠재적 이점을 조사하였고, argument mining 작업에서 효과적인 결과를 보여주었다.
    2. 새로운 argumentative corpus(논문에서는 e-participation)에 SVD, PCA, LDA 기법을 적용하여 차원을 줄이는 실험을 실시하여, 계산 효율성과 논증 정보 추출 효과에 긍정적인 결과를 얻었다.
    3. argumentative fragment detection, argument component classification, argumentative relation recognition 등의 주요 argument mining 작업에서, 입력 기능 수의 3-4% 정도의 차원에서도 전체 corpus를 사용한 경우와 비교할 때 약 95-97%의 성능을 얻을 수 있었다.

###### On the Impact of Reconstruction and Context for Argument Prediction in Natural Debate (https://aclanthology.org/2023.argmining-1.10/)
- Anthology ID: 2023.argmining-1.10 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 토론 자연성은 작고 구조화된 주제 중심의 상황에서 크고 자발적이며 제약이 적은 환경까지 다양하게 범위가 있다.
    2. 우리는 대화 기여를 복원하여 대화 구문 분석이 인과관계 예측에 어떤 영향을 미치는지 연구하고, 문맥 정보를 결합하는 효과를 조사한다.
    3. 우리의 초기 가정과는 달리 복원은 예측을 향상시키지 않으며, 문맥은 제안과 결합해서만 사용할 때만 예측을 향상시킨다는 것을 발견했다.

###### Unsupervised argument reframing with a counterfactual-based approach (https://aclanthology.org/2023.argmining-1.11/)
- Anthology ID: 2023.argmining-1.11 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. "프레이밍은 토론에 참여하는 참가자들이 자신의 견해를 지원하는 측면이나 차원을 강조하는 중요한 메커니즘이다. 
    2. 우리는 eXplainable AI (XAI) 분야에서 카운터팩투얼 설명 생성 방법으로부터 영감을 받아 인자 재프레이밍의 비지도 학습 방법을 제안한다. 
    3. 우리의 방법은 프레임을 제거하고 대상 프레임과 관련된 다른 토큰으로 바꾸는 마스크-앤-리플레이스 접근 방식으로 공식화되며, XAI에서 사용되는 여러 메트릭과 유사한 지표를 기반으로 재프레임에 적합한 카운터팩투얼을 찾기 위한 재판정 기법을 사용한다."

###### Overview of ImageArg-2023: The First Shared Task in Multimodal Argument Mining (https://aclanthology.org/2023.argmining-1.12/)
- Anthology ID: 2023.argmining-1.12 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. ImageArg 공유 작업은 Argument Mining 워크샵과 함께 열린 최초의 다중모달 (multimodal) Argument Mining 공유 작업 자세한 개요를 제공한다.
    2. Subtask-A는 토론 대상에 대한 이미지와 텍스트를 포함한 트윗의 입장 (stance) 판별을 수행하며, Subtask-B는 이미지가 트윗 텍스트를 더 설득력있게 만드는지를 분류한다.
    3. 이 공유 작업은 6개 국가에서 9개의 다른 팀으로부터 Subtask-A에는 31개 제출, Subtask-B에는 21개의 제출을 받았으며, 각각 최고의 성능을 보인 F1-score는 각각 0.8647과 0.5561이다.

###### IUST at ImageArg: The First Shared Task in Multimodal Argument Mining (https://aclanthology.org/2023.argmining-1.13/)
- Anthology ID: 2023.argmining-1.13 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. ImageArg는 다중 모달 설득 기술을 발전시키기 위한 10th ArgMining Workshop에서의 공유 과제로, ImageArg 데이터셋을 활용한다.
    2. 이 도전은 두 가지 다른 하위 과제로 구성되는데, 1) 주장적 입장 (AS) 분류: 주어진 트윗이 주장적인 입장을 취하는지를 평가한다. 2) 이미지 설득력 (IP) 분류 : 트윗 이미지가 트윗의 설득력을 향상시키는지 여부를 결정한다.
    3. 우리는 두 하위과제에서 다양한 실험을 진행하였으며, 9개 팀 중 6위를 차지했다.

###### TILFA: A Unified Framework for Text, Image, and Layout Fusion in Argument Mining (https://aclanthology.org/2023.argmining-1.14/)
- Anthology ID: 2023.argmining-1.14 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. Argument Mining (AM)은 작가의 입장을 분석하는 것이 주요 목표인데, 이 논문에서는 텍스트뿐만 아니라 이미지도 포함하는 AM 데이터셋을 소개한다.
    2. 본 논문에서는 TILFA라는 새로운 프레임워크를 제안하여 텍스트 이해 뿐만 아니라 이미지의 광학 문자와 레이아웃 세부사항을 감지할 수 있다.
    3. KnowComp 팀의 모델은 이미지 및 텍스트 퓨전에 우수한 성능을 보여 기존 베이스라인보다 훨씬 뛰어나며, 이번 대회의 Argumentative Stance Classification 하위태스크에서 1위를 차지했다.

###### A General Framework for Multimodal Argument Persuasiveness Classification of Tweets (https://aclanthology.org/2023.argmining-1.15/)
- Anthology ID: 2023.argmining-1.15 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 텍스트에 이미지를 첨부하여 텍스트의 설득력을 높이는 것이 중요한데, ImageArg 싱글 테스크에서는 텍스트와 이미지에 대한 분류와 이미지가 텍스트의 설득력에 미치는 영향을 예측하였다.
    2. 이 논문에서는 사전 훈련된 모델을 사용하여 텍스트와 이미지 특징을 추출하고 이를 과제별 분류 모델에 사용하는 방법을 제안하였다.
    3. 실험 결과, CLIP 모델이 특히 과제 A에서의 특징 추출에 중요한 역할을 하는 것으로 확인되었다.

###### Webis @ ImageArg 2023: Embedding-based Stance and Persuasiveness Classification (https://aclanthology.org/2023.argmining-1.16/)
- Anthology ID: 2023.argmining-1.16 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. Webis는 ImageArg 2023의 두 가지 subtask에 참여했으며, argumentative stance classification subtask에서는 BERT 모델을 사용하여 F1 스코어 0.84를 달성했다.
    2. image persuasiveness classification subtask에서는 CLIP 임베딩과 신경망 모델을 사용하여 F1 스코어 0.56을 달성하여 이 대회에서 이 subtask에서 최고의 성능을 보였다.
    3. 우리의 분석 결과, "I support gun control"와 같이 분명한 문장도 우리의 경쟁력 있는 stance classifier에 여전히 문제가 있으며, 트윗 텍스트를 무시한 이미지 설득력 예측 모델은 최고 성능 모델과 유사한 효과를 갖는다는 것을 보여준다.

###### GC-Hunter at ImageArg Shared Task: Multi-Modal Stance and Persuasiveness Learning (https://aclanthology.org/2023.argmining-1.17/)
- Anthology ID: 2023.argmining-1.17 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 소셜 미디어의 중요성이 증가함에 따라 사용자들은 글에 이미지를 삽입하는 경우가 많아졌다. 이러한 트렌드로 인해 소셜 미디어 메시지의 자동 처리에 새로운 도전이 발생하고 있다.
    2. 본 논문에서는 ImageArg 공유 작업의 두 가지 주요 목표에 대해 다루고 있다. 첫째로, 다중모달 트윗에 대한 태도(stance)를 결정하는 것이다. 우리는 트윗 텍스트와 이미지 텍스트를 연결(concatenation)하여 transformer 기반 모델을 fine-tuning 하는 강력한 베이스라인을 제시한다.
    3. 둘째로, 다중모달 트윗에서 이미지의 설득력에 대한 예상을 하는 것이다. 우리는 데이터에 대해 비전 모델과 언어 모델을 훈련시키고, 다른 특징 집합을 모델과 병합하여 예측력을 향상시켜 이미지의 설득력을 캡처한다. 이러한 목표들은 결국 소셜 미디어에서의 다중모달 메시지와 이미지와 텍스트의 관계를 이해하는 더 큰 목표에 기여한다.

###### Argumentative Stance Prediction: An Exploratory Study on Multimodality and Few-Shot Learning (https://aclanthology.org/2023.argmining-1.18/)
- Anthology ID: 2023.argmining-1.18 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 다중 모달 문제로서의 주장 의견 예측을 진전시키기 위해, 다중 모달 주장 분석의 첫번째 공유 작업은 gun control과 abortion과 같은 중요한 사회적 주제에서 주장 의견 예측을 진행했다.
    2. 우리의 실험적 연구는 트윗에서 주장 의견 예측에 대한 이미지의 필요성을 평가하고, out-of-the-box 텍스트 기반 큰 언어 모델을 적은 양의 데이터에서 세부 조정된 유니모달 및 다중 모달 모델과 비교한다.
    3. 결과로서 텍스트 기반 언어 모델의 앙상블 (0.817 F1-score)이 다중 모달 (0.677 F1-score) 및 최신의 상위 성능을 내는 텍스트 기반 적은 양의 데이터 예측 (0.550 F1-score)보다 우수함을 나타내고, 이미지 내용을 자연어로 요약하는 것이 다중 모달 모델의 성능 향상에 도움이 된다는 것을 보여준다.

###### SPLIT: Stance and Persuasion Prediction with Multi-modal on Image and Textual Information (https://aclanthology.org/2023.argmining-1.19/)
- Anthology ID: 2023.argmining-1.19 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. "설득력은 연설자가 청중의 신념, 태도, 의지, 동기 및 행동에 영향을 끼칠 수 있는 두드러진 성격 특성이다."
    2. "ImageArg 과제는 EMNLP 2023의 10번째 ArgMining 워크샵에서 다중모달 설득 기술을 발전시키기 위해 ImageArg 데이터셋의 잠재력을 활용하는데 초점을 맞추고 있다."
    3. "우리는 이 연구에서 양두모달 데이터셋의 활용과 세 가지 다른 다중모달 모델을 평가한다. 최첨단 모델의 장점과 제약을 보여주기 위해 다중모달 데이터셋을 개선한다."

###### Semantists at ImageArg-2023: Exploring Cross-modal Contrastive and Ensemble Models for Multimodal Stance and Persuasiveness Classification (https://aclanthology.org/2023.argmining-1.20/)
- Anthology ID: 2023.argmining-1.20 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 해당 논문은 이미지에 대한 트윗의 태도를 식별하고, 특정 주제에 대한 설득력 점수를 결정하는 ImageArg-2023 공유 작업에 대한 시스템을 설명합니다.
    2. 텍스트 기반의 접근 방식을 사용하여 트윗의 논쟁적 태도를 분류하기 위해 여러 개의 변형 모델을 사용합니다.
    3. 놀랍게도, 트윗의 텍스트 기반 접근 방식이 다중 모달 접근 방식보다 성능이 더 우수함을 보였습니다.

###### Overview of PragTag-2023: Low-Resource Multi-Domain Pragmatic Tagging of Peer Reviews (https://aclanthology.org/2023.argmining-1.21/)
- Anthology ID: 2023.argmining-1.21 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. Peer review는 과학에서 핵심 품질 통제 메커니즘이다. Peer review의 핵심 요소는 리뷰 보고서로, 리뷰어가 작업을 평가하고 저자에게 제안을 하는 논쟁적인 텍스트이다.
    2. 기존 NLP 연구는 주로 기계 학습 컨퍼런스의 리뷰에 집중해 왔으나, NLP 모델은 도메인 변화에 취약하며, 새로운 연구 커뮤니티의 리뷰에 적용할 때 성능이 저하될 수 있다.
    3. 피어 리뷰 데이터는 일반적으로 입수하기 어렵고 비싸게 라벨링해야 하는 어려움이 있다. 따라서 피어 리뷰의 저자별 문장 분류 작업에서 도메인 강인성을 높이고 데이터 부족 문제를 해결하기 위한 방법을 탐구하는 PragTag-2023 Shared Task가 소개되었다.

###### CATALPA_EduNLP at PragTag-2023 (https://aclanthology.org/2023.argmining-1.22/)
- Anthology ID: 2023.argmining-1.22 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 이 논문은 PragTag-2023 Shared Task에 대한 기여를 설명한다. 문장 분류, 문장 유사도 및 시퀀스 태깅을 기반으로 한 다양한 접근 방식을 설명하고 비교한다.
    2. 문장 분류 기반의 BERT를 사용한 접근 방식이 시퀀스 태깅 및 SBERT를 기반으로 한 문장 분류보다 우수한 성능을 보인다.
    3. 또한, 다른 접근 방식을 결합하는 것의 잠재력을 강조하는 분석 결과를 제시한다.

###### DeepBlueAI at PragTag-2023:Ensemble-based Text Classification Approaches under Limited Data Resources (https://aclanthology.org/2023.argmining-1.23/)
- Anthology ID: 2023.argmining-1.23 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 리뷰 데이터의 부족과 주석 작업의 고비용으로 인해, 이 논문에서는 한정된 데이터를 사용하여 사전 훈련된 모델의 규모 조정에 중점을 두고 있다.
    2. 모델의 강건성을 향상시키기 위해 적대적 훈련 기법을 사용한다.
    3. 약간의 변형을 도입하여 모델이 적대적 공격과 능숙하게 대응하고 입력 데이터의 안정성을 향상시키도록 한다.

###### MILAB at PragTag-2023: Enhancing Cross-Domain Generalization through Data Augmentation with Reduced Uncertainty (https://aclanthology.org/2023.argmining-1.24/)
- Anthology ID: 2023.argmining-1.24 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. PragTag task에 대한 논문에서는 동료 리뷰의 각 문장을 6가지 유형의 pragmatic 태그 중 하나로 분류하기 위한 접근 방식을 설명한다. 
    2. 도메인의 불일치로 인해 어렵기 때문에, pseudo-labeling과 synonym generation과 같은 데이터 증강 기술을 사용하여 데이터 불균형과 부족 문제를 해결하려고 한다. 
    3. 실험 결과, zero 조건에서는 첫 번째 순위, full과 low 조건에서는 세 번째 순위를 달성하며 우리의 접근법이 효과적임을 입증하였다.

###### NUS-IDS at PragTag-2023: Improving Pragmatic Tagging of Peer Reviews through Unlabeled Data (https://aclanthology.org/2023.argmining-1.25/)
- Anthology ID: 2023.argmining-1.25 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. "우리는 EMNLP-2023에서의 Pragmatic Tagging of Peer Reviews Shared Task를 위한 모델에 대해 설명한다. 우리는 위의 대회 과제에 대해 다양한 최신 transformer 모델을 사용하여 다중 문장 분류 모델을 훈련시켰다."
    2. "무감독 데이터에 대한 여러 모델의 예측을 결합하여 미분류 인스턴스를 임시로 라벨을 지정하고 예측 과제에서의 성능 향상을 위해 데이터셋을 증강했다."
    3. "특히, F1000RD corpus에서는 전체 훈련 데이터의 10%만 사용하면서도 100% 훈련 데이터로 훈련된 모델과 비슷한 성능을 내었다. 대회 데이터셋 전체에서 다양한 데이터 조건에 대해 상위 2위 중에 속한다."

###### SuryaKiran at PragTag 2023 - Benchmarking Domain Adaptation using Masked Language Modeling in Natural Language Processing For Specialized Data (https://aclanthology.org/2023.argmining-1.26/)
- Anthology ID: 2023.argmining-1.26 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 대부분의 transformer 모델은 Wikipedia와 Reddit와 같은 포럼에서 얻은 영어 언어 말뭉치로 학습되는데, 이러한 모델은 과학적 피어 리뷰, 법률 및 의료와 같은 특수 분야에서 사용되지만, 이러한 특화된 도메인과 관련된 데이터에 포함된 정보가 없기 때문에 성능이 좋지 않다. 
    2. 이러한 모델이 특화된 도메인에서 최대한 좋은 성능을 내기 위한 방법 중 하나는 해당 도메인의 레이블이 지정된 데이터를 수집하여 선택한 transformer 모델에 대해 fine-tuning하는 것이다. 
    3. 그러나 이는 많은 레이블이 지정된 데이터를 수집해야 하고, 상당한 수작업이 필요하다는 어려움이 있다. 따라서 레이블이 지정되지 않은 도메인 특정 데이터를 사용하여 transformer 모델을 사전 학습하고 이 모델을 레이블이 지정된 데이터로 fine-tuning하는 방법도 있다.


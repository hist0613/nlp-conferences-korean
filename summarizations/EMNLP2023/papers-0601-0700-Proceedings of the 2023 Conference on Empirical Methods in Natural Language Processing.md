# Korean Three-Line Summarizations of Papers 601-700 in Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing
###### SummEdits: Measuring LLM Ability at Factual Reasoning Through The Lens of Summarization (https://aclanthology.org/2023.emnlp-main.600/)
- Anthology ID: 2023.emnlp-main.600 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 LLMs (Large Language Models)를 실제 환경에서 사용하면, 사실적인 불일치(factual inconsistencies)를 효과적으로 감지할 수 있는 방법이 사실 정보의 확산을 줄이고 모델의 결과에 대한 신뢰를 향상시키는 데 중요하다. 
    2. 우리는 기존 평가 척도의 문제점을 발견하여 inconsistency detection benchmark에 대한 새로운 프로토콜을 제안하였고, 이를 10개 도메인에 대해 구현한 SummEdits 벤치마크에 적용하였다. 
    3. 대부분의 LLM은 SummEdits에서 성능이 무작위 수준에 가까우며, 최고의 모델인 GPT-4도 인간의 성능 추정치보다 8% 낮은 성능을 보여주고 있어 LLM의 사실 추론 능력과 불일치 감지 능력의 한계를 보여준다.

###### DIVE: Towards Descriptive and Diverse Visual Commonsense Generation (https://aclanthology.org/2023.emnlp-main.601/)
- Anthology ID: 2023.emnlp-main.601 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "인간 수준의 시각적 이해를 위해, 시각적 공통 감각 생성은 이미지를 넘어서는 시각적 추론을 생성하는 데 도입되었다. 그러나 현재의 시각적 공통 감각 생성 연구는 기술적이고 다양한 추론 생성을 생각해내는 중요한 인지 능력을 간과하고 있다."
    2. "이 논문에서는 생성된 추론의 기술성과 다양성을 향상시키기 위한 새로운 시각적 공통 감각 생성 프레임워크인 DIVE를 제안한다."
    3. "실험 결과는 DIVE가 기존 모델들에 비해 기술성과 다양성 측면에서 뛰어나며, 독특하고 새로운 추론 생성에 우수한 품질을 보인다는 것을 확인하였다. 또한, 인간 평가를 통해 DIVE가 기술성과 다양성에서 인간 판단과 일치하는 것을 확인하였다."

###### Towards Conceptualization of “Fair Explanation”: Disparate Impacts of anti-Asian Hate Speech Explanations on Content Moderators (https://aclanthology.org/2023.emnlp-main.602/)
- Anthology ID: 2023.emnlp-main.602 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 AI 설명 가능성과 공정성의 교차점에서의 연구는 설명이 공정성 지표에 의해 측정된 사람과 AI의 작업 성능을 향상시킬 수 있는지에 초점을 맞추고 있다. 
    2. 우리는 "공정성"을 가진 설명이 무엇인지를 정의하고, 특정 인구에 부정적인 영향을 미치지 않는 설명을 제시한다. 
    3. 우리는 정확성과 라벨링 시간뿐만 아니라 설명이 다른 사용자 그룹에 미치는 심리적 영향(metal discomfort, stereotype activation, 그리고 perceived workload)을 포함한 여러 메트릭을 사용하여 "공정한 설명"의 새로운 평가 방법을 제안한다.

###### Bridging Background Knowledge Gaps in Translation with Automatic Explicitation (https://aclanthology.org/2023.emnlp-main.603/)
- Anthology ID: 2023.emnlp-main.603 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 번역은 사람들이 다른 언어로 작성된 콘텐츠를 이해하는 데 도움이 된다. 그러나 필요한 배경 지식이 없는 사람들에게는 정확한 문장 번역만으로는 충분하지 않을 수 있다.
    2. 본 논문에서는 언어 간 질문-응답 프레임워크에서 질문에 더 정확한 답변을 할 수 있도록 도와줄 수 있는 explicitation을 자동으로 생성하는 기술을 소개한다.
    3. 이를 위해, Wikipedia에서 수집한 데이터셋인 WikiExpl을 사용하여 인간 번역자들에 의해 명확하게 표시된 explicitation을 자동으로 생성하는 기술을 소개한다.

###### A Quality-based Syntactic Template Retriever for Syntactically-Controlled Paraphrase Generation (https://aclanthology.org/2023.emnlp-main.604/)
- Anthology ID: 2023.emnlp-main.604 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 SPG 모델들은 인간이 주석을 달거나 잘 선택된 문법 템플릿과 함께 사용될 때 유리한 성과를 보이지만, 이런 템플릿을 얻는 것은 실제 적용을 방해하는 어려움이 있다.
    2. 이 논문에서는 생성될 패러프레이즈의 품질에 기반하여 템플릿을 검색하는 Quality-based Syntactic Template Retriever(QSTR)를 제안한다. 또한, 한 문장에 대해 여러 개의 패러프레이즈가 필요한 상황에서 동질성을 희생시키지 않고 다양성을 높일 수 있는 Diverse Templates Search(DTS) 알고리즘도 제안한다.
    3. 실험 결과, QSTR은 고품질 패러프레이즈를 생성하는 기존의 검색 방법을 크게 능가하며, reference-free 지표에서에서는 인간 주석과 비교 가능한 성과를 보인다. 또한, 데이터 증강을 위해 생성된 패러프레이즈를 사용한 인간 평가 및 하위 태스크 성능은 QSTR과 DTS 알고리즘의 잠재력을 실제 상황에서도 보여준다.

###### Beyond Shared Vocabulary: Increasing Representational Word Similarities across Languages for Multilingual Machine Translation (https://aclanthology.org/2023.emnlp-main.605/)
- Anthology ID: 2023.emnlp-main.605 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다국어 신경 기계 번역 (MNMT)에서 공유 어휘를 사용하는 것은 일반적인 방법이다. 공유 어휘는 간단한 설계에 더해, 일치하는 의미를 가지는 경우 지식을 전달하는데 중요한 역할을 한다. 그러나 서로 다른 문자 체계를 사용할 때 같은 단어가 적으면 transfer가 억제된다.
    2. 이 논문에서는 이 문제를 완화하기 위해 임베딩을 구축하기 위한 다시 매개화된 방법을 제안한다. 구체적으로, 우리는 단어 등급 동치류를 통해 단어 수준의 정보 전달 경로를 정의하고, 그래프 네트워크를 사용하여 언어 간에 단어 임베딩을 통합한다.
    3. 실험 결과, 우리의 방법은 임베딩의 의미가 다국어로 잘 맞아 떨어지고, 고저 리소스 MNMT에서 확실한 BLEU 개선을 달성하며, 추가적인 학습 가능한 매개 변수는 1.0% 미만이며 계산 비용은 제한적으로 증가하나 추론 시간은 기준선과 동일하다.

###### Quantifying the redundancy between prosody and text (https://aclanthology.org/2023.emnlp-main.606/)
- Anthology ID: 2023.emnlp-main.606 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 회화의 중요한 측면을 전달하는 운율(prosody)과 단어 사이의 정보 관계는 아직 잘 알려져 있지 않다.
    2. 이 연구에서는 큰 언어 모델(Large Language Models, LLMs)을 사용하여, 운율과 단어 사이의 중복된 정보량을 추정한다.
    3. 연구 결과, "intensity, duration, pauses, and pitch contours"와 같은 여러 운율적 특징들이 단어와 중복된 정보를 가지고 있음을 보여준다.

###### CRoW: Benchmarking Commonsense Reasoning in Real-World Tasks (https://aclanthology.org/2023.emnlp-main.607/)
- Anthology ID: 2023.emnlp-main.607 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 자연어처리(NLP) 공감 판단 연구에서는 많은 새로운 데이터셋과 벤치마크가 생성되었지만, 대부분의 데이터셋은 실제 NLP 시스템이 해결하는 실제 과제와 관련이 없는 인공적인 시나리오에서 공감 판단 도전 과제를 구성한다.
    2. 이 연구에서는 CRoW라고 불리는 수동으로 정리된 다중 작업 벤치마크를 제공하여 모델이 실제 세계의 NLP 작업에 공감 판단을 적용하는 능력을 평가한다.
    3. CRoW를 사용하여 물리적, 시간적, 사회적 추론과 같은 다양한 차원의 공감지식에서 NLP 시스템의 성능을 연구하였으며, 인간과 비교했을 때 NLP 시스템의 성능 차이가 크며, 공감 판단은 실제 과제 설정에서 해결되어야 할 문제임을 보여주었다.

###### A Video Is Worth 4096 Tokens: Verbalize Story Videos To Understand Them In Zero Shot (https://aclanthology.org/2023.emnlp-main.608/)
- Anthology ID: 2023.emnlp-main.608 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 광고 및 스토리 비디오와 같은 멀티미디어 콘텐츠는 창의성과 여러 가지 모드의 풍부한 결합을 보여줍니다. 이 논문에서는 이러한 모델링 결합을 위해 장문 비디오를 자연어로 표현하여 생성하고, 생성된 이야기에 대한 비디오 이해 작업을 원본 비디오가 아닌 이야기에 적용하는 방법을 제안합니다.
    2. 이 연구는 제로샷 학습만으로도 만족스러운 성능을 가진 감독 학습 모델을 개발하기 어려운 멀티미디어 도메인의 문제를 해결하기 위해, 대규모 언어 모델(Large Language Models, LLMs)를 활용합니다.
    3. 연구 결과 제로샷 방법을 사용하더라도, 동영상 이해 작업에서 감독된 기준선 대비 크게 향상된 결과를 얻을 수 있으며, 컴퓨팅 사회과학에서 중요한 심리 전략 식별에 대한 첫 번째 데이터 세트를 공개합니다.

###### Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning (https://aclanthology.org/2023.emnlp-main.609/)
- Anthology ID: 2023.emnlp-main.609 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 큰 언어 모델(Large Language Models)은 다양한 작업을 수행하기 위해 자기 학습을 하는 것이라는 연구 결과를 통해 자신이 주어진 context에서 학습하는 방법의 작동 메커니즘을 조사했다. 
    2. 탐색 결과로, 레이블 단어는 앵커로 작용하며, 레이블 단어의 의미 정보가 얕은 계산 레이어의 처리 중에 결합되고 레이블 단어에서 합쳐진 정보가 최종 예측의 참고로 작용한다는 것을 밝혀냈다.
    3. 이 연구를 바탕으로, 앵커 가중치 조정 방법을 소개하여 ICL 성능을 향상시키고, 추론 과정을 가속화하기 위한 예시 압축 기법 및 GPT2-XL에서 ICL 오류를 진단하기 위한 분석 프레임워크를 제안한다.

###### Prompting Scientific Names for Zero-Shot Species Recognition (https://aclanthology.org/2023.emnlp-main.610/)
- Anthology ID: 2023.emnlp-main.610 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 교육적 가치를 고려하지 않은 기존 평가 메트릭은 MCQ 생성의 학습 평가에 제약이 있다.
    2. 우리는 지식 종속 가능성(KDA)이라는 새로운 메트릭을 제안하여 MCQ의 대답 가능성을 측정하고 대상 사실의 학생 지식을 평가한다.
    3. 실험 결과, KDA_disc와 KDA_cont는 실제 강의 세팅에서의 사용성과 강한 상관관계가 있음을 보여준다.
    
    1. 최근의 NLP 모델은 높은 정확성을 보이지만, spurious pattern에 의존하여 robustness가 제한되는 문제가 있다.
    2. 기존 augmentation 방법들은 spurious correlation에 영향을 받는데, 이 논문에서는 "여러 개의" counterfactual을 생성하여 robust하게 인과관계를 파악하는 방법을 제안한다.
    3. 실험 결과, 집합적 의사 결정 방법을 통해 기존 방법에 비해 더 robust한 성능과 다양한 차원에서 향상된 성능을 얻을 수 있다.
    
    1. 일반적인 대상 사물인 이미지를 zero-shot 방식으로 인식하는 CLIP과 같은 VLM의 특화된 개념, 예를 들어, 새, 식물, 동물의 종을 고유하게 인식하는 방법에 대한 연구는 적다.
    2. 이 논문에서는 CLIP을 통한 zero-shot 종 인식에서 라틴어나 그리스어로 된 과학 이름을 사용한 프롬프트의 성능이 낮다고 보고한다.
    3. 대신에, 우리는 과학 이름을 영어로 번역하여 프롬프트에 사용함으로써 성능을 향상시킬 수 있음을 보고한다.

###### Active Learning for Natural Language Generation (https://aclanthology.org/2023.emnlp-main.611/)
- Anthology ID: 2023.emnlp-main.611 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 생성(NLG) 분야는 수작업 주석이 매우 비싸고 시간이 많이 소요되므로 레이블이 지정된 데이터의 심각한 부족으로 고통받고 있다.
    2. 이 논문에서는 NLG에 대한 active learning (AL)을 첫 번째 체계적인 연구로 제안하며, 다양한 작업과 여러 가지 선도적인 선택 전략을 고려한 강력한 instruction-tuned 모델을 활용한다.
    3. 기존의 AL 전략의 성능은 일관성이 없으며, 일부 경우에서는 무작위 예제 선택의 기준선을 뛰어넘을 수 있지만, 다른 경우에는 그렇지 않다는 사실을 발견하였다. 그리고 분류와 생성 시나리오 간에 몇 가지 주목할만한 차이점을 강조하고, 기존의 AL 전략의 선택 동작을 분석한다. 이러한 연구 결과는 생성 작업에 AL을 적용하기 위한 새로운 접근 방식을 탐구하는 동기를 부여한다.

###### Re3Dial: Retrieve, Reorganize and Rescale Conversations for Long-Turn Open-Domain Dialogue Pre-training (https://aclanthology.org/2023.emnlp-main.612/)
- Anthology ID: 2023.emnlp-main.612 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화 모델의 장거리 맥락 활용 능력이 한계가 있다. 이를 해결하기 위해 우리는 기존의 짧은 대화를 재구성하여 수십억 개의 장대화를 자동으로 구축할 수 있는 Retrieve, Reorganize and Rescale framework (Re3Dial)을 제안한다. 
    2. Re3Dial은 세션 리트리버를 사용하여 의미론적 및 담화적 관계를 통해 멀티턴 대화를 포착하고, 이를 바탕으로 응답 생성에 활용한다. 
    3. 여러 개의 대화를 재구성하여 장거리 대화를 구축하는 Re3Dial은 대화 모델의 맥락 파악 능력을 크게 향상시키며 동시에 보다 합리적이고 유익한 응답을 생성할 수 있다. 이를 위해 우리는 Re3Dial을 위한 툴킷과 데이터를 공개할 것이다.

###### MultiTurnCleanup: A Benchmark for Multi-Turn Spoken Conversational Transcript Cleanup (https://aclanthology.org/2023.emnlp-main.613/)
- Anthology ID: 2023.emnlp-main.613 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 불플루언시 검출 모델은 한 명의 화자로부터 나오는 각각의 말투에 초점을 맞추고 있다. 그러나 실제 회화 텍스트에서는 여러 턴에 걸쳐 발생하는 다양한 불연속 현상이 있기 때문에, 기존의 모델로는 식별할 수 없다. 
    2. 이 연구는 회화 텍스트를 위한 혁신적인 다중 턴 청소 작업과 새로운 데이터셋인 MultiTurnCleanup을 제안함으로써 이러한 현상에 대응한다. 
    3. 고품질 데이터셋을 수집하기 위해 데이터 라벨링 스키마를 설계하고, 실험적 평가를 위해 미래 연구의 벤치마크로 두 가지 모델링 접근 방식을 활용한다.

###### Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models (https://aclanthology.org/2023.emnlp-main.614/)
- Anthology ID: 2023.emnlp-main.614 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어 모델 API는 최근 연구 프로토타입에서 상용 제품으로 진화하여 다국어 기능을 갖춘 제품으로 제공되고 있다. 그러나 토큰 처리량에 따라 API 사용자에게 요금이 부과되는데, 토큰이란 것은 훈련 데이터와 모델에 따라 다르며, 다른 언어로 동일한 정보를 전달하기 위해서는 토큰 수에 큰 차이가 있다.
    2. 이 논문에서는 다양한 언어로 구성된 다국어 벤치마크에서 OpenAI 언어 모델 API의 비용과 유틸리티에 대한 체계적인 분석을 실시하였다.
    3. 분석 결과, API가 지원하는 많은 언어 사용자들이 비싼 가격을 지불하면서도 좋지 않은 결과를 얻고 있다는 것을 보여주었다. 이들 사용자들은 원래 API가 접근성이 떨어지는 지역에 살고 있다. 이러한 분석을 통해 언어 모델 API의 가격 정책에 대한 투명성을 높이고, 공정하게 만들기 위해 API 제공 업체들을 독려하고자 한다.

###### Characterizing Mechanisms for Factual Recall in Language Models (https://aclanthology.org/2023.emnlp-main.615/)
- Anthology ID: 2023.emnlp-main.615 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어 모델은 사전 훈련된 기억한 사실들과 주어진 문맥에서 나타나는 새로운 정보를 통합해야 하는데, 이 두 소스는 일치하지 않을 수 있으며 어떻게 모델이 이러한 충돌을 해소할지 불확실하다.
    2. 이 연구에서는 세계 수도에 대한 정보를 질의하는 데이터셋을 사용하여, 분포적인 결정 요소와 메커니즘적인 결정 요소를 조사하였다.
    3. 표현적 결정 요소인 head attribution을 사용하여, 모델이 메모리스한 답변 또는 문맥 속 답변을 사용하는 attention head를 식별하고, 이러한 head의 값을 조절하여 모델의 동작을 제어할 수 있다는 것을 입증하였다.

###### MULTITuDE: Large-Scale Multilingual Machine-Generated Text Detection Benchmark (https://aclanthology.org/2023.emnlp-main.616/)
- Anthology ID: 2023.emnlp-main.616 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 LLMs가 영어 이외의 언어로 납득할만한 텍스트를 생성하는 능력과 다국어 환경에서 기계 생성 텍스트 감지기의 성능에 대한 연구가 부족하다.
    2. 우리는 MULTITuDE라는 새로운 벤치마킹 데이터셋을 소개하여 11개 언어 (ar, ca, cs, de, en, es, nl, pt, ru, uk, and zh)에서 생성된 74,081개의 인증 및 기계 생성 텍스트로 구성되어 있다. 이 벤치마크를 통해 우리는 제로샷(통계적 및 블랙박스)와 파인튜닝된 감지기의 성능을 비교한다.
    3. 이 연구에서는 다국어성을 고려하여 이 감지기들이 보지 않은 언어 (언어적으로 유사한 언어 및 다른 언어)와 보지 않은 LLMs에 얼마나 일반화되는지 그리고 여러 언어에서 훈련되었을 때 감지기의 성능이 향상되는지를 평가한다.

###### Revisiting Block-based Quantisation: What is Important for Sub-8-bit LLM Inference? (https://aclanthology.org/2023.emnlp-main.617/)
- Anthology ID: 2023.emnlp-main.617 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델 (LLMs)의 추론은 많은 계산 및 메모리 자원이 필요하다. 본 논문에서는 8비트에 중점을 둔 기존 LLM 양자화와는 달리, LLM 레이어의 통계 및 학습 특성을 탐구하고 LLM 양자화의 병목 현상을 숫자 스케일링 오프셋에 돌려놓는다고 주장한다.
    2. 그래서 우리는 LLMs에 대한 블록 양자화 방법을 적용하여 계산 경로에 대한 추가적인 처리 없이 단순히 산술적으로 숫자 스케일링 오프셋을 감소시킴으로써 이 문제에 대처합니다. 
    3. 우리의 실험 결과는 기존 8비트 양자화보다 산술 밀도에서 2.5배, 메모리 밀도에서 1.2배 우수한 성능을 보여주며, 다운스트림 작업에서 거의 손실이 없는 4비트 LLM의 성능을 구현하는 것과 같은 하위-8비트 LLM 양자화에 대한 인사이트를 제공한다.

###### Whispering LLaMA: A Cross-Modal Generative Error Correction Framework for Speech Recognition (https://aclanthology.org/2023.emnlp-main.618/)
- Anthology ID: 2023.emnlp-main.618 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 자동 음성 인식에서 생성적 오류 교정을 위한 새로운 교차 모달 융합 기술을 소개한다. 
    2. 우리의 방법론은 음향 정보와 외부 언어 표현을 함께 사용하여 정확한 음성 전사 맥락을 생성한다.
    3. ASR 성능을 향상시키기 위해 초기화 기술과 파라미터 효율적 알고리즘을 사용하는 우리의 접근 방식은 n-best Oracle 대비 37.66%의 단어 오류율(WER) 성능 향상을 보여준다.

###### Reducing Sequence Length by Predicting Edit Spans with Large Language Models (https://aclanthology.org/2023.emnlp-main.619/)
- Anthology ID: 2023.emnlp-main.619 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 대규모 언어 모델(Large Language Models)은 다양한 작업에서 놀라운 성능을 보여주며 큰 관심을 받고 있다. 하지만 이러한 모델들은 문법 오류 교정이나 형식성 스타일 변환과 같은 지역 시퀀스 전이 작업에서는 입력 텍스트와 출력 텍스트의 차이가 최소하기 때문에 변화 없이 입력 텍스트를 단순히 복사하는 경향이 있다. 이 논문에서는 이러한 문제를 해결하기 위해 원본 텍스트에 대한 편집 범위를 예측하여 대상 시퀀스의 길이와 계산 비용을 줄일 수 있는 방법을 제안한다. 
    2. 제안된 방법은 LLM(Large Language Models)에 대한 instruction tuning을 적용하여 편집 범위의 감독 데이터를 사용한다. 실험 결과, 제안된 방법은 줄어든 대상 텍스트 길이에도 불구하고, 요약, 형식성 스타일 변환, 문법 오류 교정, 텍스트 단순화와 같은 4가지 작업에서 기준 모델과 비교할 만한 성능을 달성한다. 
    3. 또한, 제안된 방법과 함께 작업별 세부 튜닝을 수행한 결과, 이 4가지 작업에서 최고 성능을 달성한 것을 보고하였다.

###### Instruct and Extract: Instruction Tuning for On-Demand Information Extraction (https://aclanthology.org/2023.emnlp-main.620/)
- Anthology ID: 2023.emnlp-main.620 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대용량 언어 모델은 지시 따르기 능력로 더 많은 사용자에게 오픈되었으나, 대부분의 작업 특정 시스템은 비전문가 사용자를 위한 long-tail ad hoc 추출 사용 사례에 잘 맞지 않는다. 
    2. 이 논문에서는 On-Demand Information Extraction이라는 새로운 패러다임을 제안하여 실제 사용자의 개인화된 요구를 충족시키기 위한 작업을 소개한다. 
    3. 우리의 벤치마크인 InstructIE에서 ODIE를 개발하여 umaple-size의 기존 오픈소스 모델보다 상당히 우수한 성능을 보여준다는 평가 결과를 보여주었다.

###### Rethinking the Evaluation for Conversational Recommendation in the Era of Large Language Models (https://aclanthology.org/2023.emnlp-main.621/)
- Anthology ID: 2023.emnlp-main.621 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 대형 언어 모델 (LLM)의 성공은 사용자 요구를 충족하기 위해 자연어 대화에 의존하는 강력한 대화식 추천 시스템 (CRS)을 개발하는 데 많은 잠재력을 보여주었습니다. 이 논문에서는 CRS에 ChatGPT를 활용하는 연구에 착수하며, 기존의 평가 프로토콜의 부족함을 밝혀냅니다. 이는 인간이 주석으로 표시한 ground-truth 항목과의 일치를 지나치게 강조하고 CRS의 상호작용적 성격을 간과할 수 있습니다.
    2. 이러한 제한을 극복하기 위해 우리는 LLM 기반 사용자 시뮬레이터를 활용한 대화형 평가 접근법인 iEvaLM을 제안합니다. 우리의 평가 접근법은 다양한 시스템-사용자 상호작용 시나리오를 시뮬레이션할 수 있습니다.
    3. 두 개의 공개 CRS 데이터셋을 사용한 실험을 통해 우리는 기존의 평가 프로토콜에 비해 상당한 개선을 보여줍니다. 또한, 설명 가능성의 평가를 강조하며, ChatGPT는 추천에 대한 설득력 있는 설명 생성을 보여줍니다. 우리의 연구는 CRS에 LLM의 미개척된 잠재력에 대한 깊은 이해에 기여하며, LLM 기반 CRS에 대한 보다 유연하고 현실적인 평가 접근법을 제공합니다.

###### ReCEval: Evaluating Reasoning Chains via Correctness and Informativeness (https://aclanthology.org/2023.emnlp-main.622/)
- Anthology ID: 2023.emnlp-main.622 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 태스크에서 다단계 추론 능력은 매우 중요하지만, 좋은 추론 체인이 무엇이고 이를 어떻게 평가해야 하는지는 여전히 불확실하다.
    2. 기존 방법들은 추론 체인이 올바른 결론으로 이어질 수 있는지만 확인하는데 초점을 맞추고 있는데, 이러한 답변 중심의 접근은 추론의 품질과 답을 예측하기 위한 부적절한 바이어스를 혼동시킬 수 있다.
    3. 따라서 본 논문에서는 이러한 문제를 해결하기 위해 추론 체인을 최종 답변으로의 의미론적 증명으로 평가하는 ReCEval (Reasoning Chain Evaluation) 방법을 제안하고, 이를 통해 기존 방법들보다 향상된 성능을 얻을 수 있다는 것을 실험적으로 입증하였다.

###### Expand, Highlight, Generate: RL-driven Document Generation for Passage Reranking (https://aclanthology.org/2023.emnlp-main.623/)
- Anthology ID: 2023.emnlp-main.623 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에는 랭킹 모델을 위해 대규모 언어 모델(LLMs)을 기반으로 가상 훈련 데이터를 생성하는 것이 주목받고 있다. 이 논문에서는 데이터 증강의 새로운 관점을 제안하여 쿼리로부터 가상 문서를 생성하는 방법을 소개한다.
    2. DocGen 파이프라인은 LLMs의 few-shot 기능을 활용하여 가상 문서 생성을 수행한다. 이를 위해 (i) 쿼리 확장, (ii) 원래 쿼리 강조, (iii) 쿼리와 관련성이 높을 것으로 예상되는 가상 문서 생성 순서로 진행된다.
    3. DocGen-RL은 가상 문서의 쿼리와의 관련성을 보상으로 여기고 강화학습(RL)을 활용하여 DocGen 파이프라인을 최적화하는 방법을 제안한다. DocGen 파이프라인과 DocGen-RL은 기존의 InPars와 같은 데이터 증강 방법을 크게 능가하는 것을 실험적으로 입증하였다.

###### Transformer-based Live Update Generation for Soccer Matches from Microblog Posts (https://aclanthology.org/2023.emnlp-main.624/)
- Anthology ID: 2023.emnlp-main.624 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 수 많은 다양한 라이브 트윗들의 시퀀스에서 적절한 스포츠 업데이트를 생성하는 것은 어려웠으나, 트윗과 함께하는 생중계 스포츠 시청 경험이 인기를 얻고 있다. 
    2. 본 논문에서는 축구 경기에 초점을 맞추어, 사용자가 원 raw 트윗들로부터 경기 진행 상황을 실시간으로 파악하고 경기의 흥미를 즐길 수 있는 시스템을 구축하는 것에 초점을 두고 있다. 
    3. 우리의 제안된 시스템은 대규모 사전 학습된 언어 모델을 기반으로 하며, 업데이트 수를 제어하는 메커니즘과 중복 및 유사한 업데이트의 중복성을 줄이는 메커니즘을 포함하고 있다.

###### Make Every Example Count: On the Stability and Utility of Self-Influence for Learning from Noisy NLP Datasets (https://aclanthology.org/2023.emnlp-main.625/)
- Anthology ID: 2023.emnlp-main.625 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 현재 NLP에서 데이터셋의 크기가 점점 커지면서 성과 향상에 있어 데이터의 품질이 병목이 되는 경우가 많다. 
    2. 이 논문에서는 태스크에 대해 독립인 (task-agnostic) self-influence 점수를 이용하여 데이터 정제를 수행하고, 이 방법이 자연스러운 이상값을 잡아내는 데 얼마나 효과적인지 연구하였다. 
    3. 자기 영향에 기반한 데이터 정제가 기계 번역, 질문 응답, 텍스트 분류 등에서 성능 향상을 얼마나 가져오는지를 연구하였다.

###### Appraising the Potential Uses and Harms of LLMs for Medical Systematic Reviews (https://aclanthology.org/2023.emnlp-main.626/)
- Anthology ID: 2023.emnlp-main.626 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 의료 체계적 문헌고찰(Medical systematic reviews)은 건강 관련 결정과 정책 결정에 핵심적인 역할을 한다. 그러나 이러한 문헌고찰 작성은 시간이 많이 소요되어 고품질이고 최신의 증거 요약이 제한된다.
    2. 최근 LLMs의 발전은 이 문제를 해결하기 위해 필요한 문헌고찰들을 필요에 따라 자동으로 생성할 수 있는 잠재력을 제공한다. 그러나, LLMs는 man. hallucination(환각)이나 omission(생략)에 의해 정확하지 않고 잘못된 텍스트를 생성하기도 한다.
    3. 이 연구에서는 국제적인 체계적 문헌고찰 전문가들과의 16번의 인터뷰를 통해 의료 증거분석 문맥에서 LLMs의 유용성과 위험을 규명하고, 이에 따라 생물의학적 LLMs의 엄격한 평가 기준을 제시한다.

###### PromptST: Abstract Prompt Learning for End-to-End Speech Translation (https://aclanthology.org/2023.emnlp-main.627/)
- Anthology ID: 2023.emnlp-main.627 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 음성-텍스트 번역 (S2T) 모델에서 음성과 텍스트 특징을 어떻게 통합하는지에 대한 이해에 첫걸음을 내딛었다.
    2. S2T 모델의 상단 인코더 층이 언어 지식을 효율적으로 학습하지 못하여 번역 정확성에 중요한 영향을 미친다는 것을 밝혀냈다.
    3. 이를 바탕으로 우리는 S2T 모델의 상위 인코더 층에 간단한 플러그인 프롬프트 학습 전략을 제안하여 보다 추상적인 표현력을 갖춘 PromptST 모델을 개발하였다.

###### Text Rendering Strategies for Pixel Language Models (https://aclanthology.org/2023.emnlp-main.628/)
- Anthology ID: 2023.emnlp-main.628 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 픽셀 기반 언어 모델은 이미지로 렌더링된 텍스트를 처리하여 어떤 스크립트든 다룰 수 있기 때문에, 여는 어휘 언어 모델링에 유망한 접근법이다. 그러나 최근의 접근법은 거의 동일한 입력 패치를 생성하는 텍스트 렌더러를 사용하는데, 이는 입력 표현에서 중복이 발생하여 다운스트림 작업에 부적합할 수 있다.
    2. 본 논문에서는 PIXEL 모델(Rust et al., 2023)에서 텍스트를 렌더링하는 네 가지 접근법을 조사하고, 단순한 문자 바이그램 렌더링이 문장 수준 작업에서 성능을 향상시키면서도 토큰 수준이나 다국어 작업에서의 성능을 희생시키지 않는 것을 발견하였다.
    3. 이 새로운 렌더링 전략은 또한 원래의 86M 파라미터 모델과 동등한 성능을 발휘하는 22M 파라미터로 더 컴팩트한 모델을 훈련할 수 있게 한다. 문자 바이그램 렌더링은 일관된 개선된 모델을 제공하지만, 패치 빈도 편향에 의해 주도되는 이방성적인 패치 임베딩 공간을 보여주며, 이미지 패치 기반 및 토큰화 기반 언어 모델 사이의 연결을 강조한다.

###### APoLLo : Unified Adapter and Prompt Learning for Vision Language Models (https://aclanthology.org/2023.emnlp-main.629/)
- Anthology ID: 2023.emnlp-main.629 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Vision-Language Pretrained (VLP) 모델의 성능에 있어 입력 텍스트 프롬프트의 선택은 매우 중요하며, 이 논문에서는 Adapter와 Prompt 학습을 결합한 APoLLo라는 통합된 다중 모달 접근 방법을 제안한다.
    2. 우리의 방법은 VLP 모델이 소수의 데이터로 fine-tuning 될 때 일반화 능력을 크게 향상시킬 수 있다. 양 모달리티 간의 정렬을 강화하기 위해 학습 가능한 cross-attention 기반의 어댑터 레이어를 도입하고, 데이터 증가를 위해 증가된 입력을 받는 각 인코더 브랜치 간의 일관성을 강조한다.
    3. 우리의 방법은 새로운 클래스에 대한 일반화, 데이터셋 간 평가, 보이지 않는 도메인 변화에 대한 평가 등 세 가지 대표적인 작업에서 향상된 성능을 보여준다. 실제로, APoLLo는 10 개의 다양한 이미지 인식 데이터셋에 대해 MaPLe (SOTA) 대비 최대 6.03%의 상대적 이득을 얻는다.

###### SAMRank: Unsupervised Keyphrase Extraction using Self-Attention Map in BERT and GPT-2 (https://aclanthology.org/2023.emnlp-main.630/)
- Anthology ID: 2023.emnlp-main.630 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. SAMRank는 사전 훈련된 언어 모델의 self-attention 맵 만을 사용하여 구 어구의 중요도를 결정하는 새로운 비지도 키워드 추출 방법을 제안한다. 
    2. 이전의 방법들은 문맥화 임베딩을 사용하여 단어, 문장 및 문서 간의 의미적 유사성을 포착하였으나, 이러한 방법은 임베딩의 이방성 특성으로 인해 의미적 유사성 측정에 최적화되지 않을 수 있다.
    3. 이 논문에서는 BERT와 GPT-2와 같은 사전 훈련된 언어 모델의 self-attention 맵을 활용하여 구 어구의 중요도를 산출하고, 이를 통해 키워드 추출을 수행하는 SAMRank는 임베딩에 의존하지 않고도 키워드 추출이 가능한 것을 실험적으로 입증하였다.

###### Contrastive Learning for Inference in Dialogue (https://aclanthology.org/2023.emnlp-main.631/)
- Anthology ID: 2023.emnlp-main.631 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인퍼런스, 특히 포함되지 않은 정보를 컴플리먼트로 전달하기 위한 추론 과정은 대화에서 중요하다. 
    2. 최근 대형 언어 모델들은 추론 작업에서 굉장한 진전을 보이고 있으나 모든 정보가 대화 맥락에 포함되지 않은 추론에서는 논리적 추론에 비해 성능이 뒤쳐진다.
    3. 이 논문에서 작성자들은 모델의 동작을 시맨틱 정보 갭에 의해 정의된 작업 난이도에 따라 분석하였다. 우리는 의사결정 트리 기반의 대화 데이터셋을 이용하여 언어 모델의 성능을 분석하고, 모델이 어떻게 추론을 수행하는지 자세히 살펴 보았다.

###### Editing Large Language Models: Problems, Methods, and Opportunities (https://aclanthology.org/2023.emnlp-main.632/)
- Anthology ID: 2023.emnlp-main.632 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. trainable한 LLM을 구축하는 것은 가능하지만, 그들의 relevancy를 유지하고 에러를 수정하는 방법론은 난해하다. 
    2. 해당 논문에서는 LLM을 효율적으로 특정 도메인 내에서 수정하면서 다른 input에 대한 성능을 저하시키지 않는 방법에 대해 깊이 있는 탐구를 제공한다. 
    3. 또한, 효과성과 실용성에 대한 소중한 통찰력을 제공하여 특정 작업이나 문맥에 가장 적합한 방법을 선택하는 데에 도움을 주기 위해 새로운 벤치마크 데이터셋을 구축하였다.

###### MarkQA: A large scale KBQA dataset with numerical reasoning (https://aclanthology.org/2023.emnlp-main.633/)
- Anthology ID: 2023.emnlp-main.633 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 지식 베이스로부터의 질문 응답에 있어서 연속된 숫자형 질문들은 아직 다뤄지지 않은 분야다. 논문에서는 복잡한 숫자 판단을 필요로 하는 NR-KBQA라는 새로운 과제를 제안한다.
    2. Numerical reasoning 질문들의 추론 과정을 파이썬 형식인 PyQL로 표현하는 통합형식을 디자인했다. NR-KBQA 개발을 촉진하기 위해 작은 시드 집합을 통해 자동으로 생성된 MarkQA라는 대규모 데이터셋을 제공한다.
    3. MarkQA 데이터셋에서 수행되는 최신 QA 방법의 실험 결과는 KBQA에서의 복잡한 숫자 판단이 큰 어려움을 겪고 있다는 것을 보여준다.

###### Comparing Biases and the Impact of Multilingual Training across Multiple Languages (https://aclanthology.org/2023.emnlp-main.634/)
- Anthology ID: 2023.emnlp-main.634 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 바이어스 및 공평성 연구는 한 언어 안에서 사회적 바이어스를 주로 다루고 있으며, 몇 가지 속성 (예: 성별, 인종)에 대해 분석하고 있다. 
    2. 그러나 바이어스는 각 언어마다 다르게 나타날 수 있다. 그래서 각 언어와 속성 내에서의 바이어스를 분석하는 것이 중요하다. 
    3. 본 논문에서는 이탈리아어, 중국어, 영어, 히브리어, 스페인어를 대상으로 전반적인 센티먼트 분석 작업에 대한 바이어스 분석을 제시하고, 다국어 데이터와 단일 언어 데이터로 모델을 훈련시킬 때 바이어스가 어떻게 영향을 받는지 조사한다.

###### HutCRS: Hierarchical User-Interest Tracking for Conversational Recommender System (https://aclanthology.org/2023.emnlp-main.635/)
- Anthology ID: 2023.emnlp-main.635 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 대화형 추천 시스템은 사용자로부터 모든 속성에 대한 명시적인 답변 (예/아니오)을 요구하여 사용자의 지식이나 관심에 상관없이 사용자 경험과 의미 일관성을 저하시킬 수 있다. 
    2. 본 논문에서는 실용적이고 사용자 친화적이며 설명 가능한 대화형 추천 시스템 프레임워크인 HutCRS를 제안한다. HutCRS는 대화를 계층적 관심 트리로 표현하며, 사용자가 선호하는 측면을 식별하여 관련 속성에 대해 물어보거나 아이템을 추천한다.
    3. 또한, 우리는 결정 과정을 통합하는 Hierarchical-Interest Policy Learning (HIPL) 모듈을 개발하여 어떤 측면에 대해 질문하고 언제 속성을 물어보거나 아이템을 추천할지 결정한다. 더 나아가, 속성 수준의 피드백 결과를 분류하여 사용자의 상호작용 데이터에 제시되지 않은 특정 정보 (예 : 사용자가 수락하지만 과거 데이터에 나타나지 않은 속성 인스턴스)를 포착하는 시스템 능력을 향상시킨다.

###### Large Language Models Meet Open-World Intent Discovery and Recognition: An Evaluation of ChatGPT (https://aclanthology.org/2023.emnlp-main.636/)
- Anthology ID: 2023.emnlp-main.636 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. OOD intent discovery와 GID (일반화된 인텐트 탐지) 작업은 task-oriented dialogue (TOD) 시스템에 매우 중요한 역할을 하는데, 이러한 작업들을 fine-tuning 기반의 모델로 다루는 기존의 방법들이 있다. 이 논문에서는 ChatGPT의 OOD intent discovery와 GID 능력에 대해 종합적으로 평가하고, ChatGPT의 장단점을 요약하고 설명한다.
    2. ChatGPT는 zero-shot settings에서 일관된 이점을 보이지만, fine-tuned 모델과 비교했을 때 아직도 불리한 면이 있다는 것을 알 수 있다.
    3. 여러 가지 분석 실험을 통해 LLMs(대형 언어 모델)이 직면한 도메인 특화 이해, 군집화, 상황 속 교차 도메인 학습과 같은 과제들에 대해 정리하고 논의하며, 이러한 도전과제를 해결하기 위한 미래 방향에 대한 경험적인 안내를 제공한다.

###### The Distributional Hypothesis Does Not Fully Explain the Benefits of Masked Language Model Pretraining (https://aclanthology.org/2023.emnlp-main.637/)
- Anthology ID: 2023.emnlp-main.637 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 본 논문은 masked language modeling의 사전학습 목적함수를 Distributional Hypothesis의 관점에서 분석한다.
    2. 작은 데이터로부터의 효율성 향상과, 사전학습된 모델의 일반화 능력이 pretraining 데이터의 distributional 속성에 부여될 수 있는지를 조사한다.
    3. 합성 데이터셋을 통해, distributional property가 masked language models의 효율성을 개선시키지만, 일반화 능력에 완벽하게 설명할 수는 없다는 것을 보여준다.

###### Simple and Effective Input Reformulations for Translation (https://aclanthology.org/2023.emnlp-main.638/)
- Anthology ID: 2023.emnlp-main.638 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존 언어 모델은 미세조정 입력 컨텍스트로부터 학습하는데, 이 연구에서는 언어 모델을 미세조정할 때 입력 형태를 변경하여 언어 모델의 강점을 활용하여 성능을 향상시키는 방법을 제안한다.
    2. 이 방법은 데이터 수준의 수정으로 진행되며, 추가적인 학습 데이터 수집이나 추론 시간에 데이터 수정이 필요하지 않는다.
    3. 이 방법은 단일 언어 쌍 번역 작업 또는 다국어 번역 작업에도 적용될 수 있으며, 실험 결과로는 3.5 chrF++까지의 성능 향상을 보였다.

###### Pointwise Mutual Information Based Metric and Decoding Strategy for Faithful Generation in Document Grounded Dialogs (https://aclanthology.org/2023.emnlp-main.639/)
- Anthology ID: 2023.emnlp-main.639 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 문서에 기반한 대화에 사용되는 딥러닝 기반 생성 모델에서 주요한 우려사항은 생성된 응답이 기초 문서에 충실하지 않을 수 있다는 것이다.
    2. 기존의 자동 메트릭은 생성된 응답과 문서의 내용 사이의 유사도를 측정하지만, 이러한 자동 메트릭은 사람의 판단과 일치하지 않는다.
    3. 이 논문에서는 응답의 충실성을 측정하기 위해 새로운 메트릭을 제안하고, 이 메트릭을 응답 생성 과정에 적용하여 더 충실한 응답을 예측하는 새로운 디코딩 기술을 제안한다.

###### The ACL OCL Corpus: Advancing Open Science in Computational Linguistics (https://aclanthology.org/2023.emnlp-main.640/)
- Anthology ID: 2023.emnlp-main.640 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. ACL OCL은 ACL Anthology에서 파생된 학술 코퍼스로, 계산언어학 분야의 오픈 과학 연구를 돕기 위해 제공된다.
    2. 이 코퍼스는 메타데이터, PDF 파일, 인용문 그래프 및 추가적인 구조화된 전체 텍스트를 제공하며, 더 큰 지식 자원 (Semantic Scholar)에 섹션, 그림 및 링크가 있는 형태로 이전 버전의 ACL Anthology를 통합 및 개선한다.
    3. ACL OCL은 7개의 연대를 아우르고, 73,000개의 논문과 210,000개의 그림을 포함하며, 컴퓨터 언어학에서의 추세를 관찰하는 데 적용된다. 예를 들어, "구문 분석, 태깅 및 청킹"에 대한 관심이 줄고 있고, "자연어 생성"에 대한 관심이 소리댄다는 사실을 발견할 수 있다.

###### Using Artificial French Data to Understand the Emergence of Gender Bias in Transformer Language Models (https://aclanthology.org/2023.emnlp-main.641/)
- Anthology ID: 2023.emnlp-main.641 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 많은 연구는 신경 언어 모델이 직접 감독 없이도 다양한 언어적 속성을 학습할 수 있는 능력을 보여주고 있다.
    2. 본 연구는 신경 모델이 단어의 성별과 사용 규칙과 같은 언어적 속성을 어떻게 발견하는지라는 덜 연구된 주제를 탐색하기 위한 초석을 제공한다.
    3. 우리는 프랑스어를 기반으로 한 PCFG로 생성된 인공 말뭉치를 사용하여 훈련 데이터에서 성별 분포를 정확하게 제어하고, 언제 모델이 성별 정보를 올바르게 포착하거나 그와 반대로 성별 편향이 나타나는지를 결정하는 것을 제안한다.

###### Learning to Rank Context for Named Entity Recognition Using a Synthetic Dataset (https://aclanthology.org/2023.emnlp-main.642/)
- Anthology ID: 2023.emnlp-main.642 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 pre-trained transformer 기반 모델들은 명명된 개체 인식 (NER)을 매우 높은 정확도로 수행할 수 있지만, 전체 소설과 같은 긴 문서에 적용할 때 범위가 제한되는 문제가 남아 있다. 
    2. 이 문제를 완화하기 위한 해결책은 문서 수준에서 관련된 맥락을 검색하는 것이다. 그러나 이러한 과업에 대한 감독이 존재하지 않기 때문에 비감독 방식에 안주해야 한다.
    3. 대신에, 우리는 Alpaca라는 instruction-tuned large language model (LLM)을 사용하여 합성된 맥락 검색 훈련 데이터셋을 생성하기를 제안한다. 이 데이터셋을 사용하여 NER에 대한 관련 맥락을 찾을 수 있는 BERT 기반의 신경망 맥락 검색 모델을 훈련시킨다. 우리는 우리의 방법이 40권의 소설의 첫 장으로 구성된 영어 문학 데이터셋에서 NER 과업의 검색 베이스라인보다 우수한 성과를 보여준다.

###### Improving Diversity of Demographic Representation in Large Language Models via Collective-Critiques and Self-Voting (https://aclanthology.org/2023.emnlp-main.643/)
- Anthology ID: 2023.emnlp-main.643 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델의 다양성은 중요한 과제인데, 사용자의 prompt가 명확하지 않을 때 모델이 암묵적인 가정을 따르거나 특정 인종이나 문화의 그룹이 생성된 응답에서 보이지 않거나 사라질 수 있다. 
    2. 본 논문에서 언어 모델 세대에서 다양성의 문제를 형식화하고, 다양성을 측정하는 메트릭을 제안한다. 
    3. 실험 결과에서, 새로운 CCVS 프롬프팅 기술이 다양성을 향상시키는데 효과적이며 기존 기법들보다 큰 효율을 보인다는 것을 확인했다.

###### Hidding the Ghostwriters: An Adversarial Evaluation of AI-Generated Student Essay Detection (https://aclanthology.org/2023.emnlp-main.644/)
- Anthology ID: 2023.emnlp-main.644 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델들이 텍스트 생성 과제에서 놀라운 능력을 발휘하고 있지만, 이러한 모델들의 활용은 표절, 가짜 뉴스의 확산, 교육 과정에서의 문제 등과 같은 내재적인 위험을 수반한다. 
    2. 이 논문은 주로 학생의 글쓰기에 대한 문맥에서 적대적인 왜곡에 대한 효과적인 탐지기의 효과에 대해 연구한다. 
    3. 실험 결과, 기존의 탐지기들은 간단한 자동 적대적 공격을 우회하면서도 검출 가능성을 크게 낮출 수 있는 단어 대체 및 문장 대체 왜곡 방법을 탐구하였다.

###### Contextual Interaction for Argument Post Quality Assessment (https://aclanthology.org/2023.emnlp-main.645/)
- Anthology ID: 2023.emnlp-main.645 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에는 자연어 논쟁의 질을 평가하는 것에 대한 관심이 높아졌다. 기존 접근 방식은 개별 논쟁 포스트의 질을 평가하는 데에 중점을 두었지만, 질 차이가 미묘한 논쟁을 효과적으로 구별하기에는 부족한 경우가 많다.
    2. 이 논문은 상대적 질을 모델링하기 위한 두 가지 대체 방법을 다룬다. 이 방법들은 1) argument들 간의 복잡한 상호작용을 포착하는 감독된 대조학습과 2) in-context 예제로 LLMs를 더욱 풍부하게 만드는 방법이다.
    3. IBM-Rank-30k 데이터셋을 통해 광범위한 평가와 분석을 거쳐, 대조적인 논쟁 품질 평가 방법이 최첨단 기준 모델들보다 우수함을 입증한다. 그러나 in-context 예제를 사용한 LLMs는 높은 품질의 논쟁 포스트를 식별하는 데에 탁월한 능력을 보여주지만, 품질 차이가 미묘한 논쟁 포스트간 구별 능력은 제한적이다.

###### Pre-training Intent-Aware Encoders for Zero- and Few-Shot Intent Classification (https://aclanthology.org/2023.emnlp-main.646/)
- Anthology ID: 2023.emnlp-main.646 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 과제 지향형 대화 시스템에서 IC(Intent classification)은 중요한 역할을 한다. 하지만 충분한 어노테이션(example) 없이 IC 모델을 훈련시키면 일반적으로 일반화 능력이 부족하다. 
    2. 이 논문에서는 IC 작업에 적합한 임베딩을 생성하기 위해 의도의 pseudo label로 대조 학습(contrastive learning)을 사용하는 텍스트 인코더의 신규 사전학습(pre-training) 방법을 제안한다.
    3. 이러한 사전학습 전략을 적용함으로써, PIE 모델은 네 개의 IC 데이터셋에서 zero-shot 및 one-shot 설정에서 이전 최고 성능의 사전학습 텍스트 인코더 대비 최대 5.4%와 4.0% 높은 정확도를 달성한다.

###### Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations (https://aclanthology.org/2023.emnlp-main.647/)
- Anthology ID: 2023.emnlp-main.647 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 고품질 training data의 수집과 정리는 우수한 성능을 가진 텍스트 분류 모델을 개발하는 데 매우 중요하지만, 그것은 종종 상당한 비용과 시간 투자를 동반한다. 
    2. 최근에는 대용으로 LLM (Large Language Model)이 생성한 합성 데이터를 사용하는 것을 탐구한 연구자들도 있다. 
    3. 하지만 LLM이 생성한 합성 데이터의 효과는 서로 다른 분류 작업에 따라 일관되지 않다.

###### GazeVQA: A Video Question Answering Dataset for Multiview Eye-Gaze Task-Oriented Collaborations (https://aclanthology.org/2023.emnlp-main.648/)
- Anthology ID: 2023.emnlp-main.648 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 엑소센트릭과 에고센트릭 비디오를 사용한 비디오 질의 응답 (VQA)은 인간-로봇 상호작용 및 협업 연구에서의 새로운 시도이다. 
    2. 특히 에고센트릭 비디오의 경우 눈동자 동선 정보를 활용하여 사용자의 의도를 이해하는데 도움이 될 수 있다.
    3. 본 논문에서는 사용자들이 질문을 할 때 눈동자 동선 정보가 캡처된 GazeVQA라는 이름의 새로운 테스크 지향 VQA 데이터셋을 구축하였고, 이 데이터셋을 활용해 AssistGaze라고 불리는 AI 모델을 제안하였다.

###### People Make Better Edits: Measuring the Efficacy of LLM-Generated Counterfactually Augmented Data for Harmful Language Detection (https://aclanthology.org/2023.emnlp-main.649/)
- Anthology ID: 2023.emnlp-main.649 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. NLP 모델의 robustness는 사회적 컴퓨팅 작업에서 중요하며, spurious feature에 강건해야 한다. 
    2. 이전 연구들은 counterfactual data augmentation을 사용하여 spurious feature에 대한 의존성을 줄이기 위해 노력했다. 
    3. 이 논문에서는 Polyjuice, ChatGPT, Flan-T5를 사용하여 자동으로 CADs를 생성하고, 수동으로 생성된 CADs와 비교하여 모델의 robustness를 향상시키는지 평가한다.

###### Unraveling Feature Extraction Mechanisms in Neural Networks (https://aclanthology.org/2023.emnlp-main.650/)
- Anthology ID: 2023.emnlp-main.650 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 신경망의 학습 매커니즘을 이해하기 위해 Neural Tangent Kernels (NTKs)를 기반으로 한 이론적 접근법을 제안하였다. 이를 통해 그들의 내부 메커니즘에 대한 통찰을 더 깊게 파악할 수 있다.
    2. 우리는 이 방법을 여러 기본 모델에 적용하여 그들이 gradient descent 과정에서 훈련 데이터로부터 획득한 통계적 특징과 최종 결정에 어떻게 이를 적용하는지를 밝혀냈다.
    3. 또한, 우리는 활성화 함수의 선택이 특징 추출에 영향을 줄 수 있음을 발견하였으며, self-attention과 CNN 모델은 n-gram 학습에 제약이 있을 수 있지만 곱셈 기반 모델은 이 영역에서 뛰어나다는 것을 알 수 있었다.

###### CAPSTONE: Curriculum Sampling for Dense Retrieval with Document Expansion (https://aclanthology.org/2023.emnlp-main.651/)
- Anthology ID: 2023.emnlp-main.651 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 디얼 인코더는 밀집 검색에서 주로 사용되는 구조이지만, 쿼리와 문서 간의 상호작용을 완전히 포착하지 못해 두고 있다.
    2. 우리는 교육 중 가짜 쿼리를 사용하여 생성된 쿼리와 진짜 쿼리 간의 관련성을 진화하도록 가중치를 점점 더 주는 커리큘럼 샘플링 전략을 제안한다.
    3. 이를 통해 밀집 검색 모델은 문서뿐만 아니라 쿼리에도 관심을 기울여 고품질의 쿼리-인포메이션 문서 표현을 얻을 수 있으며, 관련성에 기초한 기존 모델보다 우수한 성능을 보여줍니다.

###### Balance Act: Mitigating Hubness in Cross-Modal Retrieval with Query and Gallery Banks (https://aclanthology.org/2023.emnlp-main.652/)
- Anthology ID: 2023.emnlp-main.652 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다중 모달 검색에서 나타나는 중심성 문제(hubness problem)를 해결하기 위한 후처리 솔루션을 제안한다. 이 논문에서는 검색 성능을 저하시키는 동안 일부 갤러리 데이터 포인트가 빈번하게 검색되는 현상인 hubness 문제를 이론적으로 설명하고, 이를 해결하기 위해 역동적 절편 인발 softmax와 유사성 정규화 방법을 제안한다.
    2. 기존의 연구는 쿼리 샘플만 활용하여 중심성 문제를 완화하기 위한 시도를 했으나, 이 논문에서는 쿼리와 갤러리 샘플을 모두 활용하여 중심성의 발생 빈도를 줄이는 새로운 Dual Bank Normalization (DBNorm) 프레임워크를 제안한다.
    3. 실험 결과, 이 방법은 다양한 언어 기반 벤치마크에서 우수한 성능을 보여 주어진 hubness 문제와 검색 성능 향상에 이전 방법들보다 우월한 성능을 보인다.

###### E-CORE: Emotion Correlation Enhanced Empathetic Dialogue Generation (https://aclanthology.org/2023.emnlp-main.653/)
- Anthology ID: 2023.emnlp-main.653 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 감정적인 대화 시스템 구현을 위해서는 공감 심리를 이끌어내는 것이 중요하다. 하지만 기존의 방법은 감정 레이블을 독립적으로 다루기 때문에 대화 속 감정의 상호관계를 무시하고 정확한 감정 인지와 적절한 응답 생성에 어려움이 있다. 
    2. 이 논문에서는 감정 상호관계를 강화시킨 공감 대화 생성 프레임워크를 제안한다. 다양한 해상도에서 문맥 기반 감정 상호작용을 포착하기 위해 다중 해상도 감정 그래프를 고안하고 감정 상호관계를 모델링한다.
    3. 실험 결과, 우리의 모델이 공감 인지와 표현에서 우수한 성능을 보여줌을 보여준다.

###### What do Deck Chairs and Sun Hats Have in Common? Uncovering Shared Properties in Large Concept Vocabularies (https://aclanthology.org/2023.emnlp-main.654/)
- Anthology ID: 2023.emnlp-main.654 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "개념은 다양한 응용분야에서 중요한 역할을 한다. 문맥 없이 개념을 모델링해야 하는 경우, 이전 연구는 language model에서 문맥을 제거한 개념 임베딩을 요약하여 사용했다. 그러나 개념은 다양한 관점에서 모델링될 수 있으며, 개념 임베딩은 주로 계층 구조를 포착한다. 이 문제를 해결하기 위해, 우리는 잠재적으로 큰 개념 어휘 사전에서 서로 공통점을 가진 다른 개념을 식별하는 전략을 제안한다."
    2. "우리는 다른 개념들과 공유하는 속성을 기반으로 개념을 표현한다. 이 개념 모델링 방법의 실용성을 보이기 위해, 우리는 어려운 다중 라벨 분류 문제인 ultra-fine entity typing 작업을 고려한다. 우리는 공유 속성을 라벨 집합에 추가함으로써 이 작업에 대한 최첨단 모델의 성능을 향상시킬 수 있음을 보여준다."
    3. "라벨 셋을 공유 속성으로 보강함으로써 ultra-fine entity typing 작업에 대한 최첨단 모델의 성능을 향상시킬 수 있다."

###### ALDi: Quantifying the Arabic Level of Dialectness of Text (https://aclanthology.org/2023.emnlp-main.655/)
- Anthology ID: 2023.emnlp-main.655 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 아랍어 텍스트는 현대 표준 아랍어(MSA)와 일상 소통에 사용되는 아랍어다이아렉트(DA)의 혼합체로 이루어져 있으며, 이러한 다양성을 처리하기 위해 이전 연구는 문장 또는 토큰 수준에서 어법 식별(DI)에 초점을 맞추어왔다.
    2. 그러나 DI는 과제를 이진형으로 처리하지만, 우리는 아랍어 사용자들이 어법의 다양성을 지각하기 때문에 이를 문장 수준에서 진행하며 연속된 언어 변수로 처리해야 한다고 주장한다.
    3. 우리는 글 수준에서 데이터셋을 만들었고, 해당 데이터셋으로 학습된 모델이 일련의 다언어와 다양한 장르에 대해 신뢰성 있게 다이어릭트 수준을 파악할 수 있으며, 이는 기존의 DI 시스템보다 세분화된 인식을 제공한다는 것을 자세한 분석을 통해 보여준다.

###### 3DRP-Net: 3D Relative Position-aware Network for 3D Visual Grounding (https://aclanthology.org/2023.emnlp-main.656/)
- Anthology ID: 2023.emnlp-main.656 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "3D visual grounding은 자유형태의 언어로 된 설명을 통해 3D 포인트 클라우드에서 대상 객체를 지역화하는 것을 목표로 한다. 본 논문에서는 상대적인 공간 관계를 효과적으로 포착하고 객체 속성을 강화하는 3D Relative Position-aware Network (3DRP-Net)라는 관계 인식 원스테이지 프레임워크를 제안한다."
    2. "3DRP-Net은 3D 상대적 위치 Multi-head Attention (3DRP-MA) 모듈을 제안하여 객체 쌍의 문맥에서 다른 방향으로부터 상대적 관계를 분석하고, 문장에서 언급된 특정한 객체 관계에 집중할 수 있다."
    3. "ScanRefer, Nr3D/Sr3D 세 가지 벤치마크에서 수행된 광범위한 실험 결과, 우리의 방법이 일반적으로 모든 최첨단 방법을 능가함을 보여준다."

###### Goal-Driven Explainable Clustering via Language Descriptions (https://aclanthology.org/2023.emnlp-main.657/)
- Anthology ID: 2023.emnlp-main.657 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 unsupervised clustering은 사용자의 목표를 고려하지 않고 클러스터의 의미를 설명하지 않습니다.
    2. 본 논문에서는 "목표 지향적 설명과 함께하는 클러스터링" (GoalEx) 이라는 새로운 방법을 제안합니다. 이 방법은 목표와 설명을 자유 형식의 언어로 표현하며, 목표와 관련된 설명을 정확하게 제공합니다.
    3. GoalEx는 기존 방법보다 더 정확하고 목표 관련된 설명을 생성하며, 자동 및 인간 평가에서 좋은 성능을 보입니다.

###### Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models (https://aclanthology.org/2023.emnlp-main.658/)
- Anthology ID: 2023.emnlp-main.658 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최종 목표가 다른 언어 배경을 가진 사용자들이 동일한 모델에서 일관된 피드백을 받을 수 있게 하는 것인데, 다양한 다국어 Pretrained Language Models (PLMs)에서 사실적인 지식의 cross-lingual 일관성(CLK)을 연구한다.
    2. 저자들은 RankC(Ranking-based Consistency) 메트릭을 제안하여 정확도와는 독립적으로 언어 간 지식 일관성을 평가한다.
    3. 모델 크기가 증가하면 대부분의 언어에서 사실적인 probing accuracy가 높아지지만, cross-lingual 일관성은 향상되지 않는다는 결론을 도출하였으며, 새로운 사실적인 연관이 PLMs에 삽입될 때, 이는 영어와 고 RankC 점수를 가진 언어로만 전달된다는 결과를 발견하였다.

###### Learning from Mistakes via Cooperative Study Assistant for Large Language Models (https://aclanthology.org/2023.emnlp-main.659/)
- Anthology ID: 2023.emnlp-main.659 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델 (LLM)은 자체 피드백을 바탕으로 생성을 개선하는 잠재력을 보여줬지만, LLM 자체의 피드백이 정확하지 않아 이점을 제한하고 있다.
    2. "Study Assistant for Large LAnguage Model (SALAM)"이라는 새로운 프레임워크를 제안하여 보조 에이전트를 통해 주요 LLM이 상호작용적 협력을 통해 실수로부터 배울 수 있도록 돕는다.
    3. 실험 결과, SALAM은 세 가지 LLM에서 높은 난이도의 프레임워크를 사용하여 BBH에서 최대 6.6의 정확도 향상 및 BBQ에서 최대 12.6의 정확도 향상을 이끌어냈다.

###### Bridging the Digital Divide: Performance Variation across Socio-Economic Factors in Vision-Language Models (https://aclanthology.org/2023.emnlp-main.660/)
- Anthology ID: 2023.emnlp-main.660 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 현재 AI 모델들의 놀라운 성능에도 불구하고, 이러한 모델들이 실제로 영향을 받을 특정 그룹에서 어떻게 수행되는지에 대한 평가는 종종 제공되지 않는다.
    2. 소수의 그룹 중에서도 저소득 가구의 데이터는 데이터 수집과 모델 평가에서 종종 간과된다.
    3. 우리는 최신 비전-언어 모델(CLIP)의 성능을 수입 수준에 따라 다른 가구 이미지 데이터셋(DollarStreet)에서 평가하고 결과로서 다양한 주제와 국가에 걸쳐 가난한 그룹의 성능이 부유한 그룹보다 일관되게 낮다는 것을 보여준다.

###### Conceptor-Aided Debiasing of Large Language Models (https://aclanthology.org/2023.emnlp-main.661/)
- Anthology ID: 2023.emnlp-main.661 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사전 교육된 대형 언어 모델은 사회적 편견을 반영하는데, 우리는 conceptors를 사용하여 이러한 편견을 제거하는 방법을 제안한다. conceptor 후처리는 GLUE 벤치마크에서 이전 방법들보다 우수한 debiasing 성과를 보여주며, 성능 저하 없이 편견을 줄일 수 있다.
    2. 또한, conceptor-intervened BERT (CI-BERT)라는 새로운 아키텍처를 제안하였는데, 과거 방식에 비해 bias를 효과적으로 제거하지만, 언어 모델의 정확도를 낮춘다.
    3. 우리는 편견 서브스페이스를 신중하게 구성하는 것의 중요성도 보여주었는데, 편견이 있는 단어 목록에서 이상값을 제거하고, OR 연산을 통해 결합한 후 보다 깔끔한 문장에서의 임베딩을 계산하여 가장 좋은 결과를 얻었다.

###### AMR Parsing is Far from Solved: GrAPES, the Granular AMR Parsing Evaluation Suite (https://aclanthology.org/2023.emnlp-main.662/)
- Anthology ID: 2023.emnlp-main.662 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. AMR parsing에 대한 챌린지 세트인 GrAPES와 함께 제시된 평가 메트릭을 소개한다. 기존 AMR 평가 메트릭인 Smatch에서 AMR 파서는 높은 점수를 얻고 있지만, 이는 AMR 파싱이 해결된 것을 의미하지 않는다. 이 연구에서는 GrAPES를 통해 AMR 파서를 다양한 문제에 대해 평가하고 기존 파서의 능력과 한계를 상세히 드러내었다.
    2. GrAPES는 관심 있는 실용적, 기술적, 언어적 현상 등 다양한 현상에 대해 AMR 파서를 테스트하는 평가 세트를 제공한다. 36개의 카테고리는 본적이 있는 라벨부터 구조적 일반화, 상호 참조까지 다양한 현상을 포함하고 있다.
    3. GrAPES를 통해 현재 AMR 파서의 능력과 부족한 점을 깊이 있게 드러내었다고 말한다.

###### Rethinking and Improving Multi-task Learning for End-to-end Speech Translation (https://aclanthology.org/2023.emnlp-main.663/)
- Anthology ID: 2023.emnlp-main.663 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다중작업 학습에 의해 ST(음성 번역)의 끝-끝 성능을 크게 향상시켰지만, 보조 작업들이 ST 작업과 얼마나 일관성이 있는지, 이 접근법이 얼마나 도움이 되는지는 철저히 연구되지 않았다. 
    2. 이 논문에서는 다른 시간과 모듈을 고려하여 다른 작업들간의 일관성을 조사한다. 텍스트 인코더는 주로 cross-modal 변환을 돕지만, 음성에서의 노이즈는 텍스트와 음성 표현 간의 일관성을 저해한다.
    3. 또한, 길이와 표현의 차이를 완화하여 모달 간 격차를 줄이는 개량된 다중작업 학습 (IMTL) 접근법을 ST 작업에 제안한다. MuST-C 데이터셋에서 실험을 진행한 결과, 우리의 방법이 최신 기법과 비교했을 때 최고 성능을 달성함을 보여주었다. 또한, 추가 데이터를 사용하면 MuST-C의 영어-스페인어 작업에서 현재 최고 성능 기법의 20.8%의 학습 시간으로 새로운 최고 성능을 달성하였다.

###### AD-NLP: A Benchmark for Anomaly Detection in Natural Language Processing (https://aclanthology.org/2023.emnlp-main.664/)
- Anthology ID: 2023.emnlp-main.664 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 딥러닝 모델은 이상 탐지 연구에 대한 관심을 불러일으켰다. 텍스트 이상 탐지에 대한 방법들은 흔히 레이블된 데이터셋에서 일부 클래스를 다운샘플링하여 만든 아드혹한 이상 설정에 대해 강력한 실험 결과를 보였다. 
    2. 하지만 이로 인해 재현성 문제와 특정 이상을 검출하는 데에는 성공하지만 더 복잡한 상황에서는 인식하지 못하는 바이어스가 있는 모델이 만들어진다. 
    3. 이 논문에서는 텍스트 이상 탐지로 자연스럽게 표현될 수 있는 종류의 다양한 이상을 검출하기 위한 통합 벤치마크를 제공하고, 얕은 기준선과 최신 신경망 접근법 2가지를 평가하고 분석하여 신경망 모델이 이상 탐지 작업을 수행할 때 배우는 지식에 대한 통찰력을 제공한다.

###### Enhancing the Ranking Context of Dense Retrieval through Reciprocal Nearest Neighbors (https://aclanthology.org/2023.emnlp-main.665/)
- Anthology ID: 2023.emnlp-main.665 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 희소 주석은 밀집 검색 모델의 훈련에 지속적인 도전을 제기한다. 이 논문에서는 이러한 문제를 완화하기 위해 evidence-based label smoothing이라는 새로운 방법을 소개한다. 
    2. 이 방법은 훈련 과정에서 가짜 음성(negatives)으로 사용되는 미분류된 관련 문서에 높은 관련성을 할당함으로써 모델에 패널티를 주지 않고 잘못된 음성에 높은 관련성을 할당하는 문제를 완화한다. 
    3. 실험 결과, 이 방법은 밀집 검색 모델의 랭킹 효과를 향상시키는 데 효과적이며, 레이블 스무딩 및 후처리에서도 사용할 수 있다는 것을 보여준다.

###### Cross-Lingual Cross-Target Stance Detection with Dual Knowledge Distillation Framework (https://aclanthology.org/2023.emnlp-main.666/)
- Anthology ID: 2023.emnlp-main.666 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Stance detection은 텍스트에서 사용자의 태도를 특정 대상에 대해 파악하는 것이며, 영어로 진행된 과거 연구들이 대부분이었다. 그러나 대부분의 비-영어 언어에서는 데이터 저조 문제(low-resource)로 인해 cross-lingual stance detection이 제안되었다.
    2. 이 논문에서는 cross-lingual cross-target stance detection이라는 새로운 과제를 제안하고, dual knowledge distillation을 사용한 최초의 연구를 개발한다.
    3. 실험결과, 우리의 방법은 경쟁력 있는 기준들에 비해 훨씬 효과적임을 보여준다.

###### PRESTO: A Multilingual Dataset for Parsing Realistic Task-Oriented Dialogs (https://aclanthology.org/2023.emnlp-main.667/)
- Anthology ID: 2023.emnlp-main.667 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Google Assistant, Alexa, Siri와 같은 시스템이 일상생활에서 널리 사용되면서 과제 지향 대화에 대한 연구 관심이 증가했지만, 사용자의 다양한 문제점을 현실적으로 포착한 데이터셋의 부족으로 연구 영향력이 제한되었다. 
    2. 우리는 PRESTO라는 공개 데이터셋을 소개하여 현실적인 대화를 파싱하는 데 어려움을 제공한다. PRESTO는 불안정성, 코드 스위칭, 개정과 같은 실제 NLU 과제에서 발생하는 다양한 도전 요소를 포함하고 있다. 
    3. 저자들은 mT5 모델 기반의 기준선 결과를 통해 PRESTO에 존재하는 대화 현상이 모델링하기 어려움을 보여주었고, 특히 low-resource 설정에서 그 난이도가 더 두드러진다는 것을 입증했다.

###### An Iteratively Parallel Generation Method with the Pre-Filling Strategy for Document-level Event Extraction (https://aclanthology.org/2023.emnlp-main.668/)
- Anthology ID: 2023.emnlp-main.668 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 문서 수준 이벤트 추출(DEE) 태스크에서는 문서에 여러 이벤트 레코드와 역할이 포함되므로, 이벤트 레코드들을 정확하게 추출하는 것은 큰 도전이다. 
    2. 기존 방법은 역할을 auto-regressively (자기회귀적) 생성하기 때문에 주어진 생성 순서가 필요한 EDAG(엔티티 기반 방향성 비순환 그래프) 생성 방법을 제시한다.
    3. 본 논문에서는 역할들을 병렬로 생성하여 순서 선택을 피하고, 이전 결과를 활용하기 위해 이벤트 레코드들을 반복적으로 생성하는 IPGPF(Pre-Filling 전략이 있는 반복적 병렬 생성 방법)을 제안한다.

###### CoMPosT: Characterizing and Evaluating Caricature in LLM Simulations (https://aclanthology.org/2023.emnlp-main.669/)
- Anthology ID: 2023.emnlp-main.669 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근엔 사회과학 실험이나 대중 의견 조사와 같은 상황에서 LLM을 사용하여 특정 인구군의 응답을 모방하는데 인간 행동의 세세한 면을 잡아내기 위해 노력해 왔습니다. 그러나 이러한 LLM 시뮬레이션의 품질을 논의하거나 평가할 수 있는 방법이 현재까지는 없습니다.
    2. 또한, 이러한 LLM 시뮬레이션들이 모션을 잘 반영하지 못하고 다양한 차원의 사람을 포착하지 못하여 고정 관념을 유지시키는 우려가 커지고 있습니다.
    3. 따라서 우리는 CoMPosT라는 프레임워크를 제시하며, LLM 시뮬레이션의 네 가지 차원인 Context, Model, Persona, Topic을 빠짐없이 분석하는데 사용합니다. 우리는 이 프레임워크를 통해 기존 LLM 시뮬레이션 작업에서의 '개별화'와 '과장표현'이라는 두 가지 기준을 사용하여 시뮬레이션의 카리커처 수준을 평가합니다. 우리는 GPT-4에서 일부 인구군(정치적 및 억압 받는 그룹) 및 주제에 대한 시뮬레이션의 카리커처 정도를 평가하였습니다.

###### Reduce Human Labor On Evaluating Conversational Information Retrieval System: A Human-Machine Collaboration Approach (https://aclanthology.org/2023.emnlp-main.670/)
- Anthology ID: 2023.emnlp-main.670 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화형 정보 검색 (CIR) 시스템의 평가는 주석 작업에 상당한 인적 노동을 필요로 하는 어려운 작업이다. CIR 시스템의 평가를 위해 인력을 효율적으로 활용하는 방법을 연구하는 데 많은 노력을 기울여야 한다.
    2. 우리는 CIR 평가에 활성 테스팅을 도입하여 HomCoE라는 새로운 방법을 제안한다. 이 방법은 일부 데이터를 인간의 주석 작업에 전략적으로 선택하고, 평가 결과를 보정하여 평가 편향을 제거한다. 이로써 CIR 시스템을 적은 인적 노동으로 정확하게 평가할 수 있다.
    3. 우리의 방법은 인적 노동의 1% 미만을 소비하며, 95%에서 99%의 일치율과 인간 평가 결과를 달성한다는 실험 결과를 보여준다. 이는 다른 기준과 비교하여 우리의 방법의 우수성을 강조한다.

###### BERTie Bott’s Every Flavor Labels: A Tasty Introduction to Semantic Role Labeling for Galician (https://aclanthology.org/2023.emnlp-main.671/)
- Anthology ID: 2023.emnlp-main.671 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문에서는 기존의 말뭉치, WordNet 및 종속 구문 분석을 활용하여 수동 통사 역할 지정 시스템을 훈련하기 위한 첫 번째 개신어 데이터셋을 구축하여 NLP 자원을 확장하는 노력을한다.
    2. 우리는 고도로 복잡한 문장을 의미론적으로 파싱할 때 성능을 향상시키는 새로운 전처리 방법인 동사 인덱싱을 도입한다.
    3. 전이 학습을 사용하여 자원과 동사 인덱싱 방법을 테스트하고, 결과는 동사 인덱싱 효과가 사전 훈련 및 세부조정이 되는 경우에 더 크게 나타났지만, 세부조정 중에만 사용하는 경우에도 개선이 눈에 띄게 있음을 보여준다.

###### Program Translation via Code Distillation (https://aclanthology.org/2023.emnlp-main.672/)
- Anthology ID: 2023.emnlp-main.672 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 소프트웨어 버전 이전 및 프로그램 번역은 대형 코드베이스의 수명주기에서 중요하고 비용이 많이 드는 부분이다. 그러나 프로그램 번역을 위해 병렬 코퍼스를 사용하는 기존의 기계 번역은 맞춰진 데이터가 없기 때문에 실현 가능하지 않다.
    2. 이 연구에서 우리는 Code Distillation (CoDist)이라는 새로운 모델을 제안하여 언어에 중립적인 중간 표현에서 코드의 의미적 및 구조적 동등성을 포착한다.
    3. 우리의 방법은 CodeXGLUE 및 TransCoder GeeksForGeeks 번역 벤치마크에서 최첨단 성능을 달성하며, TransCoder-ST와 비교하여 평균 절대 증가율이 12.7%이다.

###### FaMeSumm: Investigating and Improving Faithfulness of Medical Summarization (https://aclanthology.org/2023.emnlp-main.673/)
- Anthology ID: 2023.emnlp-main.673 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 의료 텍스트의 요약은 충실성을 유지하며 소스 입력과 일치하도록 되어야 하는데, 이는 의료 분야에서의 안전성과 효율성에 있어 중요하지만 연구가 부족한 주제이다.
    2. 현재의 요약 모델은 의료 입력 텍스트에 대해 종종 충실하지 않은 결과물을 생성한다는 사실을 밝혀냄.
    3. 의료 지식을 기반으로 사전 훈련된 언어 모델을 미세 조정함으로써 충실성을 개선하는 FaMeSumm 프레임워크를 소개한다. FaMeSumm은 충실한 요약과 충실하지 않은 요약의 디자인된 집합에 대해 대조적 학습을 수행하고, 의료 용어와 그 문맥을 포함하여 충실한 의료 용어의 생성을 촉진한다.

###### Grammar-Constrained Decoding for Structured NLP Tasks without Finetuning (https://aclanthology.org/2023.emnlp-main.674/)
- Anthology ID: 2023.emnlp-main.674 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델(LMs)은 높은 성능을 보이지만 원하는 출력 형식을 정확하게 따르지 않을 때 복잡한 출력 구조를 신뢰성 있게 생성하는 데 어려움이 있다. 
    2. 본 논문에서는 의미 추출, entity disambiguation, constituency parsing 등 다양한 task에서 Grammar Constrained Decoding (GCD)을 사용하여 LMs의 성능을 향상시키고 유연성을 제공하는 방법을 제안한다. 
    3. 결과적으로 grammar 제약이 있는 LMs는 기존의 LMs보다 성능이 우수하며 task별로 fine-tuning된 모델을 능가한다고 한다.

###### Systematic word meta-sense extension (https://aclanthology.org/2023.emnlp-main.675/)
- Anthology ID: 2023.emnlp-main.675 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 동의어의 의미는 예측 가능하고 생산적인 방식으로 자주 변하기 때문에, 기존 의미 사이의 규칙성을 일반화하여 새로운 의미를 파생시키는 것은 비격상 표현과 같은 비문학 언어 사용의 자동 처리에 중요하다. 
    2. 우리는 SWORME라는 새로운 과제를 소개하여 언어 모델이 기존 의미와 규칙적인 의미 관계를 가지는 새로운 의미를 확장하는 능력을 평가하고 개선한다. 
    3. 우리는 단어 의미 확장을 위한 새로운 유추 기반 방법을 제안하고, 이 방법은 점진적인 의미 변경부터 비문학적인 의미 확장에 이르기까지 언어 모델의 체계성을 향상시키는 데 효과적임을 보여준다.

###### Evaluating Evaluation Metrics: A Framework for Analyzing NLG Evaluation Metrics using Measurement Theory (https://aclanthology.org/2023.emnlp-main.676/)
- Anthology ID: 2023.emnlp-main.676 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 생성(NLG) 모델 평가에서 주요 도전 과제로서, 평가 메트릭의 설계와 평가에 대한 문제를 다루고 있다. 기존의 자동 평가 메트릭의 한계와 현재의 인간 평가 방법에서 발생하는 잡음을 인식하고, 교육 테스트 설계의 기초인 측정 이론을 기반으로 한 MetricEval이라는 프레임워크를 제안한다.
    2. 이 프레임워크는 측정 오차의 원인을 형식화하고, 경험적 데이터를 기반으로 평가 메트릭을 평가하기 위한 통계 도구를 제공한다. 이를 통해 메트릭의 불확실성을 측정하여 결과를 더 잘 해석할 수 있다.
    3. MetricEval을 통해 요약을 위한 평가 메트릭 세트를 분석하고, 인간 평가에서 혼합된 타당성 구조와 LLM 기반 메트릭의 신뢰성과 관련된 문제를 파악하는 사용 사례를 제시하고자 한다. 이를 통해 견고하고 효과적인 NLG 모델의 발전을 위해 타당하고 신뢰할 수 있는 메트릭의 설계, 평가, 해석을 촉진하고자 한다.

###### Revisiting the Knowledge Injection Frameworks (https://aclanthology.org/2023.emnlp-main.677/)
- Anthology ID: 2023.emnlp-main.677 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에는 GPT와 같은 대형 언어 모델이 큰 영향력을 갖게 되었지만, 외부 지식을 활용하여 도메인별 작업에 더 적합하게 조정하는 방법에 대한 문제를 완전히 해결하지 못했다. 
    2. 선행 연구들 중 많은 연구들이 해당 지식을 텍스트 샘플에 주입하기 위해 구축된 정렬 휴리스틱에 의존하지만, 무작위로 선택된 지식을 주입하는 것이 정렬된 지식과 비교했을 때 비슷하거나 더 좋은 결과를 보인다는 문제가 있다. 
    3. 이 논문에서는 다양한 이전 작업들에서 발견된 이 문제를 철저히 조사하고, 가장 중요한 해결 방법 중 하나로 LLM에 주입할 외부 지식의 가지치기와 정제에 대한 기초적인 강조를 제안한다. 이 기법을 지식 주입 프레임워크와 최신 LLM에 통합함으로써 도메인 적응형 LLM의 성능을 향상시킬 수 있다는 것을 보여준다.

###### We Are What We Repeatedly Do: Inducing and Deploying Habitual Schemas in Persona-Based Responses (https://aclanthology.org/2023.emnlp-main.678/)
- Anthology ID: 2023.emnlp-main.678 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화 기술의 많은 실제 응용에서는 특정 개발자 지정 페르소나에 따라 응답을 생성해야 하는데, 최근의 대형 언어 모델에서 다양한 페르소나를 추출할 수 있지만, 이러한 모델의 가시성과 예측 불가능성으로 인해 명시적 형태로 페르소나를 지정할 수 있는 것이 바람직하다. 
    2. 이전 연구에서는 페르소나를 일회성의 자기지식 조각 집합으로 표현하고, 대화 시스템이 생성에 사용하기 위해 검색해왔다. 
    3. 하지만 실제 인간 대화에서는 페르소나가 풍부한 스토리 형태의 내러티브를 통해 드러나는 경우가 많은데, 이러한 주관적인 지식은 일상적인 지식을 포함한다. 이 논문에서는 명시적 스키마 표현을 사용하여 이러한 일상적인 지식을 포착하고, 대화 생성에 relevant한 스키마를 검색하여 대형 언어 모델이 페르소나 기반의 응답을 생성하도록 조건을 제공하는 접근 방식을 제안한다.

###### Zero-shot Faithfulness Evaluation for Text Summarization with Foundation Language Model (https://aclanthology.org/2023.emnlp-main.679/)
- Anthology ID: 2023.emnlp-main.679 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 생성 모델의 요약 정확도가 크게 향상되었지만, 여전히 충실성 문제가 있다. 
    2. 이 논문에서는 중간 규모의 foundation 언어 모델을 사용하여 zero-shot 충실성 평가를 진행한다. 
    3. 실험 결과, FFLM (Faithfulness based on Language Model)은 ChatGPT보다 약 24배 적은 파라미터로 모순 감지 및 충실성 평가에서 경쟁력 있는 결과를 보이고 있다.

###### TaskWeb: Selecting Better Source Tasks for Multi-task NLP (https://aclanthology.org/2023.emnlp-main.680/)
- Anthology ID: 2023.emnlp-main.680 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 NLP 분야에서는 다양한 task를 대량으로 학습시킬 때 더 좋은 일반화 성능을 보이는 모델들이 많이 개발되었지만, task간의 관계와 새로운 task에 도움이 되는 훈련 task를 선택하는 방법에 대해서는 잘 이해되지 않았다.
    2. 본 논문에서는 task 간의 관계를 알아내는 것이 pair-wise task transfer를 통해 새로운 task를 학습하는데 도움이 되는 source task를 선택하는데 어떻게 도움이 될 수 있는지 조사하였다.
    3. TaskWeb이라는 큰 규모의 벤치마크를 제공하고, TaskWeb을 활용하여 source task를 선택하고 multi-task 학습을 위한 유용한 훈련 task의 부분 집합을 선택하는 TaskShop이라는 새로운 방법을 제안한다.

###### Improving Bias Mitigation through Bias Experts in Natural Language Understanding (https://aclanthology.org/2023.emnlp-main.681/)
- Anthology ID: 2023.emnlp-main.681 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 데이터셋 내에 있는 편향성은 모델이 in-distribution 데이터에서 높은 성능을 보이지만 out-of-distribution 데이터에서는 성능이 저하되는 원인이 됩니다. 
    2. 우리는 bias experts라고 불리는 이진 분류기를 도입한 새로운 debiasing 프레임워크를 제안하여 이 문제를 해결합니다. 
    3. 실험 결과, 우리의 방법은 auxiliary 모델의 편향성 파악 능력을 향상시키며, 결과적으로 다양한 challenge 데이터셋에서 최첨단 모델을 능가하는 성과를 보였습니다.

###### Semi-supervised multimodal coreference resolution in image narrations (https://aclanthology.org/2023.emnlp-main.682/)
- Anthology ID: 2023.emnlp-main.682 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 본 논문에서는 이미지와 긴 설명 텍스트가 짝 지어진 다중 모달 코레퍼런스 해결에 대해 연구하였다. 다중 모달 콜레퍼런스 해결은 세부적인 이미지-텍스트 매칭 문제, 설명 언어의 내재적인 모호성, 대규모 주석화된 훈련 세트의 부족으로 인해 중요한 도전 요소를 가지고 있다.
    2. 본 논문에서는 이미지-설명 쌍을 활용하여 다중 모달 문맥에서 코레퍼런스와 설명 지지를 해결하는 데이터 효율적인 반지도 학습 접근 방식을 제시한다.
    3. 실험 결과, 제안된 접근 방식이 코레퍼런스 해결과 설명 지지의 과제에서 강력한 기준선보다 양적, 질적으로 더 우수한 성능을 보여주었다.

###### A Predictive Factor Analysis of Social Biases and Task-Performance in Pretrained Masked Language Models (https://aclanthology.org/2023.emnlp-main.683/)
- Anthology ID: 2023.emnlp-main.683 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 pretrained Masked Language Models(MLM)의 사회적 편향성과 관련되는 여러 가지 요소들을 연구한다.
    2. 모델의 크기, 훈련 데이터의 크기, 훈련 과제, 훈련 데이터의 도메인, 토큰화, 프리트레인 데이터에 포함된 언어 등 여러 요소가 사회적 편향성에 영향을 미치는지에 대한 연구이다.
    3. 연구 결과는 토큰화나 모델의 목표 등 이전 연구에서 간과되었던 중요한 요소들에 대한 정보를 제공한다.

###### Argument-based Detection and Classification of Fallacies in Political Debates (https://aclanthology.org/2023.emnlp-main.684/)
- Anthology ID: 2023.emnlp-main.684 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 잘못된 추론을 사용하는 허위 논증인 Fallacies는 때로는 정치적인 논의에서 사용되며, 공공 의견과 정책 결정에 부정확한 결론과 무효한 추론을 야기할 수 있다. 
    2. 이 논문에서는 허위 논증을 자동으로 감지하고 분류하는 두 가지 기여를 제안한다. 첫째, U.S. 대통령 토론의 최신 Trump-Biden 토론을 포함하여 Fallacies로 주석 달린 ElecDeb60To16 데이터셋을 확장한다. 둘째, Transformers 모델을 기반으로 한 신경망 아키텍처를 정의함으로써 허위 논증 감지 및 분류 작업을 수행한다. 
    3. 실험 결과는 텍스트 표현에 transformer 생성 기법을 비텍스트 기능과 결합함으로써 이점을 보여준다.

###### Collaborative Generative AI: Integrating GPT-k for Efficient Editing in Text-to-Image Generation (https://aclanthology.org/2023.emnlp-main.685/)
- Anthology ID: 2023.emnlp-main.685 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최신 T2I 모델의 발전에도 불구하고, 사용자가 만족할 만한 이미지를 받으려면 반복적으로 입력 프롬프트를 편집해야 하는 문제가 있어 시간과 노력이 많이 소요된다.
    2. 본 논문에서는 GPT-k와 같은 대규모 언어 모델의 문장 생성 능력을 활용하여 T2I 생성을 위한 프롬프트 편집 과정을 개선하기 위한 가능성을 탐구한다. 
    3. 실험 결과, GPT-k 모델은 수정자를 추가하는 데 보다 집중하고 사람들은 단어와 구문을 대체하는 경향이 있으며, 주제에 대한 변경도 포함된다는 것을 확인했다. GPT-k 모델이 제안하는 수정사항을 받아들이면 남아 있는 편집 비율이 20-30% 감소할 수 있다는 것을 실험결과로 보였다.

###### SpEL: Structured Prediction for Entity Linking (https://aclanthology.org/2023.emnlp-main.686/)
- Anthology ID: 2023.emnlp-main.686 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Entity linking은 텍스트 일부를 온톨로지나 지식 소스에 연결하여 구조화된 데이터를 생성하는 연구 분야인데, 이 논문에서는 각각의 토큰을 entity로 분류하고, 토큰 예측을 종합하는 structured prediction을 entity linking에 다시 적용하는 방법을 제안한다.
    2. SpEL (Structured prediction for Entity Linking)은 entity linking 작업에 structured prediction을 적용하기 위해 새로운 아이디어인 정제된 fine-tuning 단계, 컨텍스트에 민감한 예측 종합 전략, 모델의 출력 어휘 크기 축소 및 훈련과 추론 과정에서의 토큰화 불일치 문제를 해결하는 솔루션으로 성능이 뛰어나다고 결과를 보여준다.
    3. AIDA benchmark 데이터셋에 대해 SpEL이 Wikipedia entity linking에서 state-of-the-art를 능가하는 성능을 보이며, 파라미터 수와 추론 속도면에서 계산 효율성이 매우 높다.

###### Architectural Sweet Spots for Modeling Human Label Variation by the Example of Argument Quality: It’s Best to Relate Perspectives! (https://aclanthology.org/2023.emnlp-main.687/)
- Anthology ID: 2023.emnlp-main.687 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 처리에서 많은 주석 작업들은 객관적인 레이블에 대한 서로 다른 유효하고 정당한 관점이 있을 수 있는 주관적인 특성을 가지고 있다. 이러한 특성은 판단 예측에서도 적용되며, 단일 실제 값의 부여가 의심스러울 수 있다. 동시에, 주장의 뒷받침되는 일반적으로 인정되는 개념들이 존재한다. 
    2. 각 주석 작업자별로 레이블을 예측하지만 서로 다른 주석 작업자 사이의 관계를 모델링하는 레이어를 포함하는 모델 아키텍처는 장점이 있다.
    3. 주관성에 대한 접근 방식에서 개별적 관점을 관련시키는 것이 유익할 수 있음을 보여준다.

###### Explicit Planning Helps Language Models in Logical Reasoning (https://aclanthology.org/2023.emnlp-main.688/)
- Anthology ID: 2023.emnlp-main.688 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다양한 자연어 처리 작업에서 언어 모델은 놀라운 성능을 보여 왔으나, 이 논문에서는 LEAP이라는 새로운 시스템을 제안한다. 이 시스템은 논리적 추론을 수행하고 추론 과정에 명시적인 계획을 통합하여 미래 결과를 고려한 이익 추론을 할 수 있다. 또한 희미한 특징으로부터 시스템을 보호하기 위한 교육 전략을 제안한다.
    2. 작은 T5 모델을 사용한 LEAP 시스템은 GPT-3와 비교했을 때 약 1B의 인자 수로 GPT-3의 175 배 작은 반면에 경쟁력 있는 성능을 보인다. GPT-3.5를 사용한 경우에는 PrOntoQA 데이터셋에서도 chain-of-thought 접근법보다 더 나은 성능을 보인다.
    3. 명시적 계획은 시스템의 성능에 중요한 역할을 하는 것을 보이기 위해 포괄적인 실험을 수행했다.

###### clembench: Using Game Play to Evaluate Chat-Optimized Language Models as Conversational Agents (https://aclanthology.org/2023.emnlp-main.689/)
- Anthology ID: 2023.emnlp-main.689 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최신 작업에서는 "Situated Language Understanding Agents"의 체계적 평가 방법론을 제안하였으며, "상황에 맞는 언어 이해 에이전트"는 언어 및 비언어적 맥락에서 작동하는 에이전트들을 의미한다.
    2. 이 논문에서는 LLMs (Large Language Models)이 (시뮬레이터로) 이러한 에이전트들로 이해될 수 있다는 주장을 하고 있는데, 이 연결을 통해 LLMs의 평가를 게임 형태의 제약된 설정에서 수행함으로써 의미있게 할 수 있을지에 대해 탐구한다.
    3. 실제 채팅에 최적화된 LLMs는 게임 플레이 지시를 일정 수준의 성공으로 따를 수 있는 능력을 가지며, 게임의 목표를 얼마나 잘 달성하는지에 따라게임 플레이의 질도 개발 주기에 따라 향상되는 것을 확인하였다. 비교적 단순한 예시 게임들에 대해서도 측정 지표들은 아직 포화되지 않았으며, 이 제안된 도구가 여전히 진단적 가치를 가질 것으로 추측된다.

###### Explaining with Contrastive Phrasal Highlighting: A Case Study in Assisting Humans to Detect Translation Differences (https://aclanthology.org/2023.emnlp-main.690/)
- Anthology ID: 2023.emnlp-main.690 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 NLP 모델의 예측을 설명하는 방법으로 "어떤 토큰이 이 예측에 기여한 것인가?" 에 대답하는 것보다 "두 입력 사이의 어떤 차이가 이 예측을 설명하는가?" 에 대답하는 것이 더 유용하다고 주장한다.
    2. 저자들은 phrase alignment guided erasure를 통해 시맨틱 분기 모델의 예측을 설명하는 contrastive phrasal highlights 생성 기법을 소개한다.
    3. 실험 결과, 이 방법은 유명한 사후 주목 기법보다 크로스-언어적 시맨틱 차이에 대한 인간의 이유와 더 일치하며, 사람들이 인간 번역과 중요한 기계 번역 오류에서 세밀한 의미 차이를 잘 감지하는 데 도움이 되었다.

###### Polyglot or Not? Measuring Multilingual Encyclopedic Knowledge in Foundation Models (https://aclanthology.org/2023.emnlp-main.691/)
- Anthology ID: 2023.emnlp-main.691 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 연구에서는 foundation model들이 다양한 언어적 맥락에서 백과사전적 지식을 회상할 수 있는 능력을 평가하였다.
    2. 20개 언어로 이루어진 303k개의 사실적 연결과 대조적 사실들을 포함한 데이터셋을 구축하고, 다국어 테스트에서 5개의 모델을 평가하였다.
    3. LLaMA 모델이 다국어와 영어 전용 테스트에서 가장 높은 점수를 달성하였으나, LLaMA의 에러 분석에서는 영어 이외의 언어에서의 사실 회상 능력의 제한과 사실 대상의 위치와 성별과 관련된 어려움이 나타났다. 이러한 결과로 현재의 foundation 모델들은 다국어에는 아직 멀었다는 것을 시사한다.

###### Anchoring Fine-tuning of Sentence Transformer with Semantic Label Information for Efficient Truly Few-shot Classification (https://aclanthology.org/2023.emnlp-main.692/)
- Anthology ID: 2023.emnlp-main.692 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Few-shot 분류는 강력한 기술이지만, 훈련에는 상당한 계산 능력과 데이터가 필요하다. 이 논문에서는 AncSetFit이라는 효율적인 방법을 제안하며, 작은 모델 크기와 클래스 당 2-8개의 훈련 인스턴스만으로도 적은 데이터 상황에서 좋은 성능을 얻을 수 있다.
    2. AncSetFit은 fine-tuning에 Sentence Transformer 모델을 사용하며, 문장 임베딩을 통해 작업과 레이블 정보를 가지고 앵커링한다. 이를 통해 contrastive learning과 triplet loss를 사용하여 같은 클래스의 훈련 인스턴스가 임베딩 공간에서 자신의 텍스트 의미 레이블 정보와 가장 가까워지도록 하여 서로 다른 클래스의 인스턴스를 더 강하게 임베딩 한다.
    3. AncSetFit은 SST-5, 감정 탐지, AG News 데이터에서 적은 데이터 상황에서 기존 방법들과 비교하여 강한 성능을 얻었으며, 한 클래스 당 단 두 개의 예제만으로도 좋은 성능을 보였다.

###### UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and Distillation of Rerankers (https://aclanthology.org/2023.emnlp-main.693/)
- Anthology ID: 2023.emnlp-main.693 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 많은 정보 검색 작업들에서 fine-tuning을 위해 큰 양의 라벨링된 데이터셋이 필요하지만, 이러한 데이터셋은 종종 이용 불가하고, 도메인 변화로 인해 실제 응용에 대한 유효성이 빠르게 감소할 수 있다. 
    2. 이 논문에서는 대규모 언어 모델 (LLM)을 사용하여 저렴하게 많은 수의 합성 쿼리를 생성하는 방법을 개발하고 제시한다. 
    3. 제안된 기법은 zero-shot 정확도를 향상시키며, 표준 재순위 메서드보다 매우 낮은 대기 시간을 달성한다.

###### TATA: Stance Detection via Topic-Agnostic and Topic-Aware Embeddings (https://aclanthology.org/2023.emnlp-main.694/)
- Anthology ID: 2023.emnlp-main.694 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 패시지의 태도 감지는 인터넷에서 다양한 태도와 믿음을 이해하는 데 중요하다. 그러나 주어진 주제에 대한 패시지의 태도는 종종 해당 주제에 달려 있기 때문에 보이지 않은 주제에 일반화되는 태도 감지 모델을 만드는 것은 어렵다. 
    2. 우리는 contrastive learning과 뉴스 기사로 구성된 라벨이 없는 데이터셋을 사용하여 일반적인 주제를 위한 임베딩과 특정 주제를 위한 임베딩을 학습하여 하향식 태도 감지에 사용하는 방법을 제안한다. 
    3. 전체 TATA 모델에서 이러한 임베딩을 결합하여 여러 공개적인 태도 감지 데이터셋에서 최고 수준의 성능을 달성한다.

###### Data Similarity is Not Enough to Explain Language Model Performance (https://aclanthology.org/2023.emnlp-main.695/)
- Anthology ID: 2023.emnlp-main.695 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델은 많은 다운스트림 태스크에서 높은 성능을 보이지만 모든 태스크에는 아니다. 이 논문에서는 다운스트림 태스크의 성능과 사전 학습 데이터의 유사성과의 상관관계를 확인하기 위해 Pile과 C4 사전 학습 데이터셋을 사용하여 대규모 비교를 실시하였다.
    2. 유사성과 성능은 멀티링귀얼 데이터셋에서 상관관계를 보이지만, 다른 벤치마크에서는 유사성 측정 지표들에 해당하는 정확도나 서로의 상관관계와 상관없다는 의외의 결과를 얻었다.
    3. 이는 사전 학습 데이터와 다운스트림 태스크 사이의 관계가 흔히 예상되는 것보다 더 복잡할 수 있다는 것을 시사한다.

###### Zero-shot Sharpness-Aware Quantization for Pre-trained Language Models (https://aclanthology.org/2023.emnlp-main.696/)
- Anthology ID: 2023.emnlp-main.696 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 메모리 오버헤드를 줄이고 추론을 가속화하기 위한 양자화는 특히 대규모 사전 훈련 언어 모델 (PLM) 시나리오에서 유망한 접근 방법입니다. 그러나 보안 및 개인 정보 보호 문제로 인해 원래의 훈련 데이터에 액세스 할 수 없으므로 zero-shot 양자화의 수요가 나타났습니다.
    2. 최신 zero-shot 양자화 방법 중 대부분은 주로 컴퓨터 비전 작업에만 적용되며, 생성적 적대적 학습 과정에서의 과적합 문제를 간과하여 부적절한 성능을 보입니다.
    3. 이 논문에서는 ZSAQ 프레임워크를 제안하여 다양한 PLM의 zero-shot 양자화를 위한 새로운 zero-shot sharpness-aware quantization (ZSAQ) 알고리즘을 제안합니다. 이 알고리즘은 양자화 정확성과 모델 일반화를 개선하기 위해 minimax 문제를 최적화하는 것을 목표로합니다.

###### Deciphering Stereotypes in Pre-Trained Language Models (https://aclanthology.org/2023.emnlp-main.697/)
- Anthology ID: 2023.emnlp-main.697 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 Transformer 기반의 사전 학습 언어 모델에 존재하는 인종/민족적 스테레오 타입들을 다루고, 해당 편향이 어떻게 인코딩되는지에 대한 이해를 깊게 하기 위한 목적을 가지고 있다.
    2. 이를 위해, 우리는 모델 프로빙과 텍스트 분석을 결합한 방법으로 PLM의 스테레오타입 인코딩 행동을 조사하기 위한 쉽게 사용할 수 있는 프레임워크를 제시한다.
    3. 우리의 연구 결과는 PLM 내의 일부 어텐션 헤드가 스테레오타입을 인코딩하는 데 주로 관여하며, 이러한 어텐션 헤드에 대한 어텐션 맵을 통해 특정 소수 집단에 대한 스테레오타입을 식별할 수 있음을 보여준다. 이러한 통찰력을 활용하여, 우리는 PLM의 편향을 없애기 위한 어텐션 헤드 가지치기 방법을 제안한다.

###### An “Integrative Survey on Mental Health Conversational Agents to Bridge Computer Science and Medical Perspectives” (https://aclanthology.org/2023.emnlp-main.698/)
- Anthology ID: 2023.emnlp-main.698 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 정신 건강 대화 에이전트(a.k.a. 챗봇)는 정신 건강 문제를 겪는 사람들에게 접근 가능한 지원을 제공할 수 있는 잠재력을 가지고 있어 널리 연구되고 있다.
    2. 이전에 진행된 설문 조사는 주로 컴퓨터 과학이나 의학 분야에서 발표된 논문들을 고려하여 이분화를 초래하고 두 분야 간 유익한 지식 공유를 어렵게 만들었다.
    3. 이 연구에서는 PRISMA 프레임워크를 사용하여 컴퓨터 과학과 의학 분야에서 발표된 534편의 논문을 검토하고 관련된 특징과 실험적 설계 기법을 가진 136개의 주요 논문을 밝혀냈다.

###### Do LLMs Understand Social Knowledge? Evaluating the Sociability of Large Language Models with SocKET Benchmark (https://aclanthology.org/2023.emnlp-main.699/)
- Anthology ID: 2023.emnlp-main.699 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. LLM은 구어, 문맥, 추론과 같은 다양한 NLP 태스크에서 잘 수행되었으나, 사회적 언어 이해를 어떻게 측정할지에 대한 기준이 부족하다. SocKET은 사회적 지식을 테스트하는 58개의 NLP 태스크로 구성된 신뢰할 수 있는 벤치마크이다.
    2. 해당 벤치마크를 사용하여 현재 모델들은 중간 성능을 달성하지만, 다른 유형과 카테고리의 태스크 간에 업무 이전이 가능하며, 이는 이론에서 예측되었다.
    3. zero-shot 평가를 통해 사전 훈련된 모델이 이미 사회적 언어 이해의 일부 기능을 가지고 있으며, 한 카테고리의 태스크에 대한 학습은 다른 카테고리에서의 zero-shot 테스트 성능을 향상시킬 수 있음을 보여준다.


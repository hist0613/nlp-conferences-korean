# Korean Three-Line Summarizations of Papers 2248-2339 in Proceedings of ArabicNLP 2023
###### Proceedings of ArabicNLP 2023 (https://aclanthology.org/2023.arabicnlp-1.0/)
- Anthology ID: 2023.arabicnlp-1.0 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Violet: A Vision-Language Model for Arabic Image Captioning with Gemini Decoder (https://aclanthology.org/2023.arabicnlp-1.1/)
- Anthology ID: 2023.arabicnlp-1.1 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이미지 캡셔닝은 다양한 응용 분야에서 사용될 수 있으나, 영어 이외의 언어에서는 아직까지 충분한 발전을 이루지 못했다. 특히, 아랍어 같은 경우 4억 명 이상의 사용자가 사용하는 모국어임에도 불구하고 이 분야에서 크게 무시되었다. 
    2. 이 논문에서는 아랍어에 특화된 새로운 비전-언어 모델인 Violet을 제안한다. Violet은 비전 인코더와 Gemini 텍스트 디코더로 구성되어 있으며, 비전과 언어 구성 요소 사이의 융합을 허용하면서도 캡션 생성의 유창성을 유지한다.
    3. Violet은 기존의 베이스 라인보다 모든 평가 데이터셋에서 큰 개선을 보이며, 수동 주석 달린 데이터셋에서 61.2의 CIDEr 점수를 달성하며 Flickr8k에서 13점의 개선을 이뤄냈다.

###### Nâbra: Syrian Arabic Dialects with Morphological Annotations (https://aclanthology.org/2023.arabicnlp-1.2/)
- Anthology ID: 2023.arabicnlp-1.2 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문은 스와이어 아라비아 (Syrian Arabic) 방언의 형태학적 주석이 달린 다양한 코퍼스 (corpora)인 Nâbra를 제시한다.
    2. Nâbra는 여러 소스 (소셜 미디어 게시글, 영화 및 시리즈 대본, 노래 가사, 지역 속담 등)에서 수집된 6,000개 이상의 문장과 약 60,000개의 단어로 이루어져 있다.
    3. 9명의 주석가들이 문맥에 따른 완전한 형태학적 주석을 통해 60,000개의 토큰을 주석 처리하였고, F1과 𝜅 일치도 점수가 74%에서 98%까지 다양한 기능들에서 나타나며, Nâbra 주석의 높은 품질을 보여준다.

###### HICMA: The Handwriting Identification for Calligraphy and Manuscripts in Arabic Dataset (https://aclanthology.org/2023.arabicnlp-1.3/)
- Anthology ID: 2023.arabicnlp-1.3 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 약 3억 1,300만 명 이상의 사용자를 보유하고 있는 아라비아어는 전 세계에서 가장 많이 사용되는 언어 중 하나이다. 아라비아어 필기체는 서예 및 다양한 스타일의 필기체가 사용되는 특징이 있다. 본 논문에서는 아라비아어 필기체와 콜리그라피 텍스트에 대한 실제 데이터셋인 Handwriting Identification of Manuscripts and Calligraphy in Arabic (HICMA)를 공개적으로 첫 번째로 제안하고 있다.
    2. HICMA 데이터셋은 다양한 스타일의 실제 아라비아어 필기체 텍스트를 포함하며, 각 이미지에는 이미지-텍스트 쌍과 스타일 레이블이 포함되어 있다.
    3. HICMA 데이터셋은 현재 최고 수준의 아라비아어 광학 문자 인식 모델들과의 성능 비교를 제시하며, 앞으로의 연구에 대한 기준으로 사용될 수 있다. 이 데이터셋과 평가 도구는 CC BY-NC 4.0 라이선스로 공개되었으며, 이를 통해 복잡한 아라비아어 텍스트 인식의 향상을 위한 문을 열 수 있는 기회가 되길 바란다.

###### Automated De-Identification of Arabic Medical Records (https://aclanthology.org/2023.arabicnlp-1.4/)
- Anthology ID: 2023.arabicnlp-1.4 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 전자 의료 기록 (EHR)이 전 세계적으로 퍼지면서 (아랍어권 국가를 포함하여) 환자의 개인정보 보호와 데이터를 연구와 질적 향상에 활용하기 위한 이중 요구가 늘고 있다. 
    2. 본 논문은 아랍어에 특화된 의료 텍스트를 위한 자동 디-식별 파이프라인을 소개한다. 이는 개인 정보를 식별하기 위한 정확한 의료명 사전 인식(NER), 민감한 entities를 가짜 entities로 대체하는 데이터 은닉 모델 및 대형 데이터셋에서도 네이티브로 확장할 수 있는 구현을 포함한다. 
    3. 실험 결과, 이 파이프라인은 17가지 민감한 entities에서 테스트 데이터셋에 대해 0.94에서 0.98까지 미세 F1 스코어를 보여주어, 전문가에 의한 수동 디-식별과 비슷한 정확도를 달성함을 보여준다. 이는 자동 및 확장 가능한 프로세스가 가능해졌다는 것을 시사한다.

###### ArTST: Arabic Text and Speech Transformer (https://aclanthology.org/2023.arabicnlp-1.5/)
- Anthology ID: 2023.arabicnlp-1.5 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. ArTST는 아랍어 텍스트 및 음성 변환기로, 오픈 소스 아랍어 음성 기술을 지원하기 위해 개발되었다. 
    2. 이 모델은 통합된 모델의 구조를 따르며, Modern Standard Arabic(MSA)에 중점을 두고 있으며, 향후에는 사투리 및 코드 스위치된 아랍어를 위한 확장된 버전도 제공할 예정이다.
    3. 실험 결과, ArTST는 SpeechT5와 기존의 결과와 비교하여 세 가지 작업에서 현재 최고 수준과 동등하거나 그 이상의 성능을 보였으며, 특히 저자원 환경에서의 TTS 작업에는 일반화가 쉽게 이루어진다는 것을 확인하였다.

###### TARJAMAT: Evaluation of Bard and ChatGPT on Machine Translation of Ten Arabic Varieties (https://aclanthology.org/2023.arabicnlp-1.6/)
- Anthology ID: 2023.arabicnlp-1.6 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. ChatGPT와 Bard와 같은 instruction-finetuned large language model (LLM)은 다국어 능력이 있다고 주장되었지만, 이러한 모델의 언어 포용력은 부족하게 연구되고 있다.
    2. 본 연구에서는 Bard와 ChatGPT (GPT-3.5와 GPT-4 모두 포함)의 기계 번역 능력을 아랍어의 10가지 다양한 변형들에 대해 철저히 평가한다.
    3. 연구 결과, LLMs는 공개 데이터셋이 제한적인 방언에 대해서는 어려움을 겪을 수 있지만, 평균적으로는 기존 상용 시스템보다 우수한 번역자로 나타났다. 그러나 Classical Arabic (CA)와 Modern Standard Arabic (MSA)에 대해서는 Google Translate와 같은 상용 시스템보다 뒤쳐지는 결과를 나타냈다.

###### Leveraging Domain Adaptation and Data Augmentation to Improve Qur’anic IR in English and Arabic (https://aclanthology.org/2023.arabicnlp-1.7/)
- Anthology ID: 2023.arabicnlp-1.7 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 본 연구에서는 neural IR에서 콰란 관련 정보 검색 문제를 다룬다. domain-specific 데이터 부족 문제를 해결하기 위해 큰 양의 일반 domain 데이터로 학습한 후 in-domain 데이터로 추가 학습한다. 데이터 증강 기술을 사용하여 MRR@10 및 NDCG@5 지표에서 뚜렷한 개선을 이루어 분야 최첨단 수준의 콰란 정보 검색 결과를 얻었다.
    2. 영어와 아랍어 모두에서 콰란 정보 검색을 위한 Islamic corpus 및 domain-specific model이 구축되지 않은 상황에서, 이러한 리소스의 부족 문제에 대응하기 위해 Islamic corpus 컴파일 및 domain-specific language model (LM) 사전 학습을 수행하였다.
    3. 콰란 정보 검색 작업에서 공유하는 공통 백본으로 domain-specific LM을 사용하는 검색 모델의 성능을 향상시키기 위해, 효과적으로 콰란 정보 검색 작업을 수행하는 Arabic 언어 모델을 선택하기 위한 실험들을 수행하였다. 또한, Arabic 검색 작업에 대한 부족한 일반 domain 데이터를 학습에 활용하기 위해 영어에서 성공적인 실험을 아랍어로 확장한 실험들을 수행하였다.

###### LANS: Large-scale Arabic News Summarization Corpus (https://aclanthology.org/2023.arabicnlp-1.8/)
- Anthology ID: 2023.arabicnlp-1.8 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 텍스트 요약은 여러 언어에서 꾸준히 연구되어 왔지만, 아랍어 텍스트 요약은 아직 초기 단계에 있다. 기존의 ATS 데이터셋은 작거나 다양성이 부족하다. 
    2. 우리는 LANS라는 대규모이며 다양성이 있는 아랍어 텍스트 요약 데이터셋을 구축했다. LANS는 1999년부터 2019년까지 신문 사이트의 메타데이터에서 추출한 840만 건의 기사와 요약을 제공한다. 
    3. LANS의 내재적 평가를 자동 및 인간 평가로 수행하였고, 1,000개의 랜덤 샘플의 인간 평가는 수집한 요약문에 대해 95.4%의 정확도를 보고하였으며, 자동 평가는 요약문의 다양성과 추상성을 측정하였다.

###### Beyond English: Evaluating LLMs for Arabic Grammatical Error Correction (https://aclanthology.org/2023.arabicnlp-1.9/)
- Anthology ID: 2023.arabicnlp-1.9 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 최근에는 인간의 지침을 따르도록 조정된 대형 언어 모델 (LLM)이 다양한 영어 NLP 태스크에서 상당한 능력을 보이고 있으나, 문법 오류 수정 (GEC)에서의 성능은 아직 충분히 탐구되지 않았다. 
    2. 본 연구에서는 풍부한 형태론 때문에 어려운 작업인 아라비아어 GEC에서 지시사 전달된 LLM의 능력을 평가했다. 
    3. 여러 가지 프롬프트 방법과 (in-context) few-shot learning을 결합한 결과, GPT-4는 전문가 프롬프트에서 65.49 F1 점수를 달성하며 (기존 베이스라인 대비 약 5점 높음), 양질의 결과를 보였다.

###### Aswat: Arabic Audio Dataset for Automatic Speech Recognition Using Speech-Representation Learning (https://aclanthology.org/2023.arabicnlp-1.10/)
- Anthology ID: 2023.arabicnlp-1.10 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 최근의 자기 지도 음성 표현 학습을 통한 자동 음성 인식 (ASR) 접근법은 저렴한 데이터 라벨링으로 많은 벤치마크 결과를 크게 개선시켰다. 
    2. 본 논문에서는 wav2vec 및 data2vec라는 두 개의 자기 지도 프레임워크를 ASR에 대해 훈련시키고, 결과를 분석함으로써 여러 가지 실험을 수행한다. 
    3. 또한, 아랍어 ASR에서 낮은 단어 오류율(WER)을 달성하기 위해 사전 훈련 작업에 사용할 수 있는 732시간의 아랍어 발화가 포함된 Aswat 데이터셋을 소개한다.

###### Analyzing Multilingual Competency of LLMs in Multi-Turn Instruction Following: A Case Study of Arabic (https://aclanthology.org/2023.arabicnlp-1.11/)
- Anthology ID: 2023.arabicnlp-1.11 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 다양한 작업에 대한 대형 언어 모델의 평가는 상당한 진전이 이루어져 왔으나, 아라비아어와 같이 적게 테스트된 언어로 여러 단계의 지시에 대한 응답 능력은 체계적으로 평가되지 않았다.
    2. 본 논문은 아라비아어에서의 이러한 시나리오에서 오픈 LLM의 능력을 상세히 조사한다. 
    3. 우리는 다양한 개방형 작업에서 LLM의 성능을 평가하고 비교하기 위해 MT-Bench 벤치마크 스위트의 아라비아어 버전을 사용하여 GPT-4를 사용한다는 것을 밝혀냈다.

###### Cross-Dialectal Named Entity Recognition in Arabic (https://aclanthology.org/2023.arabicnlp-1.12/)
- Anthology ID: 2023.arabicnlp-1.12 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 본 논문에서는 아랍 언어 사이의 Named Entity Recognition (NER) 모델의 전이성에 대해 연구하였다. MSA와 같이 풍부한 데이터셋이 없는 다른 아랍 언어 사이에서 MSA에서 훈련된 NER 모델이 어떻게 수행되는가에 대한 질문이 중요하다.
    2. 연구자들은 MSA 데이터셋에서 미리 훈련된 언어 모델의 위에 span-based NER 모델을 훈련시켜 다른 데이터셋에서의 성능을 zero-shot 설정에서 연구하였다.
    3. 여러 프리트레인된 언어 모델 인코더들의 성능을 연구한 결과, 주석 작업 없이도 허용 가능한 수준의 성능을 달성함을 보였다.

###### Enhancing Arabic Machine Translation for E-commerce Product Information: Data Quality Challenges and Innovative Selection Approaches (https://aclanthology.org/2023.arabicnlp-1.13/)
- Anthology ID: 2023.arabicnlp-1.13 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 전자 상거래에서 제품 정보는 보통 기계 번역(MT) 시스템을 사용하여 현지화된다. 
    2. 이 논문에서는 아라비아어 MT의 품질 문제를 해결하기 위해 수집한 데이터의 품질을 주기적으로 확인하기 위한 방법을 제안한다. 
    3. 제안된 방법은 온라인 및 오프라인 실험에서 효과적으로 작동하며, 고객들에게 더 나은 쇼핑 경험을 제공한다.

###### IDRISI-D: Arabic and English Datasets and Benchmarks for Location Mention Disambiguation over Disaster Microblogs (https://aclanthology.org/2023.arabicnlp-1.14/)
- Anthology ID: 2023.arabicnlp-1.14 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 소셜 미디어 데이터에서 지리 정보를 추출하고 해석하는 것은 재난 관리에 효과적으로 도움을 준다. 그러나 자원과 도구의 부족으로 인해 재난 관리 영역에서 Location Mention Disambiguation (LMD) 모델의 개발과 평가가 어려워진다.
    2. 이 논문은 최대 규모의 영어 및 처음으로 아라비아어 공개 LMD 데이터셋인 IDRISI-D를 소개한다. 또한, LMD 시스템의 효과적인 평가를 위한 수정된 계층적 평가 프레임워크도 제안한다.
    3. 우리는 대표적인 기준선을 활용하여 IDRISI-D 데이터셋을 평가하고 BERT 기반 모델의 경쟁력을 입증한다.

###### CamelParser2.0: A State-of-the-Art Dependency Parser for Arabic (https://aclanthology.org/2023.arabicnlp-1.15/)
- Anthology ID: 2023.arabicnlp-1.15 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. "CamelParser2.0은 오픈소스 파이썬 기반의 아랍어 의존 구문 분석기로서 Columbia Arabic Treebank (CATiB)와 Universal Dependencies (UD)라는 두 가지 인기 있는 아랍어 의존 구문 형식을 대상으로 한다."
    2. "CamelParser2.0은 raw 텍스트 처리와 토큰화, 형태소 분석 기능 등을 제공한다."
    3. "CamelParser2.0의 개발 과정에서 파싱 모델 아키텍처와 사전 훈련 언어 모델 선택과 같은 시스템 디자인 하이퍼파라미터를 탐구하면서, 골드 및 예측 토큰화 설정에서 다양한 아랍어 장르에서 최고의 성능을 달성하였다."

###### GARI: Graph Attention for Relative Isomorphism of Arabic Word Embeddings (https://aclanthology.org/2023.arabicnlp-1.16/)
- Anthology ID: 2023.arabicnlp-1.16 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. "언어처리에서 한 언어로 훈련된 단어 임베딩 공간을 다른 언어의 임베딩 공간과 밀접하게 연결시켜주는 BLI는 NLP에서 주요한 도전과제 중 하나이다. 기존의 방법들은 서로 다른 임베딩 공간의 상대적 동형성을 조절하기 위해 시도되었지만, 모델 훈련 목적에 의미적으로 관련된 단어들의 영향을 포함시키지 못했다."
    2. "이를 해결하기 위해, 우리는 GARI를 제안한다. GARI는 분포적인 훈련 목적과 그래프 어텐션 네트워크에 의해 도움을 받는 다중 동형성 손실을 결합한다. GARI는 단어의 의미적 변이의 영향을 고려하여 임베딩 공간의 상대적 동형성을 정의한다."
    3. "아라비아어 데이터셋을 사용한 실험적 평가에서 GARI는 기존 연구와 비교하여 도메인 일치 및 일치하지 않는 설정에서 평균 P@1을 증가시켜 상대적인 점수로 최대 40.95%와 76.80%까지 향상시킨다."

###### ArTrivia: Harvesting Arabic Wikipedia to Build A New Arabic Question Answering Dataset (https://aclanthology.org/2023.arabicnlp-1.17/)
- Anthology ID: 2023.arabicnlp-1.17 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 우리는 다양한 주제를 다루는 18,000개 이상의 아라비아어 질문-답변 쌍과 관련 텍스트를 포함하는 아라비아어 질문-답변 데이터셋인 ArTrivia를 제안한다. 
    2. 우리는 아라비아어 위키피디아에서 다양한 구조화된 데이터 소스를 활용하여 데이터셋을 생성했으며, 각 구성 요소의 성능을 평가하기 위해 포괄적인 통계 분석도 수행했다.
    3. 우리의 평가 결과는 답변 정규화와 같은 데이터셋 생성에서 자주 간과되는 측면이 QA 데이터셋의 품질을 향상시키는 데 중요하다는 점을 강조하며, ArTrivia가 TyDi로부터 더 도전적이고 분포와 다른 질문을 제시하여 TyDi의 보완 데이터셋으로 사용하는 것의 타당성에 대해 의문을 제기한다.

###### ArSarcasMoji Dataset: The Emoji Sentiment Roles in Arabic Ironic Contexts (https://aclanthology.org/2023.arabicnlp-1.18/)
- Anthology ID: 2023.arabicnlp-1.18 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문은 아랍어 자연어 처리(NLP)에서의 이모지 이용이 아랍어의 복잡성 때문에 조심스럽게 다뤄진다는 이유로 주의를 기울이는데, 이 맥락에서 이 논문은 24,630개의 이모지가 포함된 텍스트 데이터셋 ArSarcasMoji를 소개한다.
    2. 연구 결과, 우리는 아랍어 텍스트에서 일상화된 특정 이모지 패턴들이 우아크론(irony)을 나타내며, 그들이 갖는 감정 역할에 주의를 기울이는 것이 우아크 텍스트 이해에 이모지의 중요성을 보여주며, 아랍어 디지털 콘텐츠에서 정확한 우아크 탐지의 잠재력을 시사한다.
    3. 이 논문은 아랍어 텍스트에서 이모지가 아이러니를 이해하는 데 있어 중요한 역할을 하는 것을 강조하며, 이모지의 아랍어 디지털 콘텐츠에서의 우아크 감지 정확성의 잠재력에 대해 논한다.

###### Performance Implications of Using Unrepresentative Corpora in Arabic Natural Language Processing (https://aclanthology.org/2023.arabicnlp-1.19/)
- Anthology ID: 2023.arabicnlp-1.19 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 위키피디아 문서는 아랍어와 같은 저자원 언어들을 위한 NLP 연구에서 널리 사용되는 학습 데이터 소스이다. 그러나, 특히 주어진 언어의 많은 항목들이 다른 언어로 직접 번역되거나 자동으로 생성될 때, 이러한 데이터가 원어민의 대표적인 기여를 얼마나 반영하는지 이해하는 것이 중요하다.
    2. 이 논문에서는 위키피디아의 '유기적이지 않은' 데이터가 언어 모델링과 단어 표현과 같은 두 가지 NLP upstream task의 성능에 미치는 영향을 연구한다.
    3. 실험 결과, 좋은 NLP 성능을 위해서는 크고 유기적인 코퍼스가 필요하며, 이 둘 중 하나만으로는 충분하지 않음을 보여준다.

###### Octopus: A Multitask Model and Toolkit for Arabic Natural Language Generation (https://aclanthology.org/2023.arabicnlp-1.20/)
- Anthology ID: 2023.arabicnlp-1.20 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 아라비아어 텍스트의 이해와 인간과 유사한 응답 생성은 어려운 작업이다. 여러가지 연구자들은 개별적인 문제를 위한 모델과 솔루션을 제안했지만, 다양한 작업을 처리할 수 있는 포괄적인 아라비아어 자연어 생성 툴킷의 부족이 있다.
    2. 본 연구에서는 AraT5v2라고 불리는 강력한 아라비아어 텍스트-텍스트 Transformer 모델을 제안한다. 이 모델은 다양하고 폭넓은 데이터로 체계적으로 학습되었으며, 2,048 토큰의 확장된 시퀀스 길이를 사용한다.
    3. 또한, 우리는 새로운 Python 기반의 패키지 및 명령 줄 툴킷인 OCTOPUS를 개발하고 공개하였는데, 이는 하나의 모델을 활용하여 여덟 가지 아라비아어 생성 작업에 대응할 수 있다.

###### AlGhafa Evaluation Benchmark for Arabic Language Models (https://aclanthology.org/2023.arabicnlp-1.21/)
- Anthology ID: 2023.arabicnlp-1.21 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 최근 아라비아어 대용량 언어 모델의 발전으로 실용적인 응용 분야가 많이 개발되었으나, 아라비아어 대용량 언어 모델의 훈련 데이터 부족과 평가 자원의 한정성으로 인해 영어와 비교했을 때 여전히 어려움이 있는 상황이다.
    2. 우리는 이 계속 성장하는 분야에 기여하기 위해 아라비아어 대용량 언어 모델에 대한 새로운 다중 선택지 평가 벤치마크인 AlGhafa를 소개한다. 우리는 공개된 데이터셋과 80억 개의 토큰으로 이루어진 새로운 HandMade 데이터셋을 사용하여 다양한 모델을 훈련시키고, 여러 아라비아어 모델의 독선적 디코더 모델 중 최대인 140억 개의 매개변수 모델을 개발했다.
    3. 마지막으로, 여러 아라비아어 모델의 정량적, 정성적 독성을 탐색하고, 우리 모델을 기존의 공개 아라비아어 대용량 언어 모델과 비교한다.

###### ArBanking77: Intent Detection Neural Model and a New Dataset in Modern and Dialectical Arabic (https://aclanthology.org/2023.arabicnlp-1.22/)
- Anthology ID: 2023.arabicnlp-1.22 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. ArBanking77은 은행 도메인에서 의도 탐지를 위한 큰 규모의 아라비아어 데이터셋이다.
    2. ArBanking77 데이터셋은 원래 영어 Banking77 데이터셋을 아랍어로 번역하여 로컬라이즈하였으며, 77개의 클래스(의도)로 분류된 31,404개의 Modern Standard Arabic (MSA)와 Palestinian dialect의 쿼리가 포함되어 있다.
    3. ArBanking77을 기반으로 fine-tuning된 AraBERT 기반의 신경망 모델은 MSA에서 0.9209, Palestinan dialect에서 0.8995의 F1-score를 달성하였으며, 저자들은 낮은 리소스 환경에서 모델을 실험하였으며, 해당 데이터셋과 모델은 공개적으로 사용할 수 있다고 밝혔다.

###### ArabIcros: AI-Powered Arabic Crossword Puzzle Generation for Educational Applications (https://aclanthology.org/2023.arabicnlp-1.23/)
- Anthology ID: 2023.arabicnlp-1.23 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문은 고급 AI 기술에 의해 구동되는 최초의 아라비아 십자말 퍼즐 생성기를 소개한다. 
    2. GPT4, GPT3-Davinci, GPT3-Curie, GPT3-Babbage, GPT3-Ada, 그리고 BERT와 같은 첨단 언어 모델들을 활용하여 생성기는 독특하고 도전적인 단서들을 만든다.
    3. 교육적인 십자말 퍼즐은 기억력을 향상시키고 어휘력을 확장시키며 문제 해결 능력을 촉진시키는 데 기여하여, 재미있고 매력적인 방식으로 학습 경험을 증진시키며 전통적인 학습 방법의 풍경을 재구성한다.

###### Machine Translation of Omani Arabic Dialect from Social Media (https://aclanthology.org/2023.arabicnlp-1.24/)
- Anthology ID: 2023.arabicnlp-1.24 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. "현대 표준 아랍어(MSA)와 영어 간의 기계 번역(MT)에 대한 연구는 많지만, 오마니 아랍어(OA) 방언과 영어 간의 MT에 대한 연구는 매우 희박하다."
    2. 오만 방언에 대한 병렬 데이터셋의 부족과 OA에서 영어로의 MT에 초점을 맞추는 연구로, 소셜 미디어 데이터를 사용하여 오만 방언의 실제 병렬 텍스트를 구축한다.
    3. 구글 번역, 마이크로소프트 번역 및 Marian NMT를 사용하여 이 데이터셋에 대한 베이스라인 결과를 제시하며, 가장 일반적인 언어적 오류의 분류를 사용하여 NMT 시스템이 번역한 결과를 분석하여 향후 개선 방향을 제시한다. 마지막으로, 오만 방언에 대한 Marian NMT의 전이 학습을 사용하여 BLEU 점수에서 9.88 포인트 향상을 이룩했다.

###### Arabic Fine-Grained Entity Recognition (https://aclanthology.org/2023.arabicnlp-1.25/)
- Anthology ID: 2023.arabicnlp-1.25 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 기존 NER 시스템은 개략적인 entity의 카테고리를 인식하는 데 중점을 두고 있고, 미세한 하위 유형의 entity들에 대한 분류에는 관심이 적다.
    2. 이 논문은 미세한 entity를 고려한 아라비아어 NER를 개선하기 위해 Wojood 데이터셋을 확장한다.
    3. WojoodFine은 Wojood의 GPE, LOC, ORG, FAC 4개의 entity 유형에 31개의 하위 유형을 추가하여 만들어진 도구로, Cohen의 Kappa와 F1 점수를 사용하여 높은 IAA(Inter-Annotator Agreement)를 보였다.

###### Investigating Zero-shot Cross-lingual Language Understanding for Arabic (https://aclanthology.org/2023.arabicnlp-1.26/)
- Anthology ID: 2023.arabicnlp-1.26 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 다양한 언어 배경 사이에서 언어 이해력을 전이(transfer)할 수 있는 가능성을 연구했다. 
    2. 다른 언어들을 훈련시킨 언어 모델들이 아랍어 이해력을 향상시킬 수 있는 것을 실험으로 보였다. 
    3. 특히, 문제 해결과 자연어 추론 같은 과제에서, 러시아어와 같은 풍성한 형태적 특징을 가진 언어들이 아랍어와 유사한 특성을 보였다.

###### Evaluating ChatGPT and Bard AI on Arabic Sentiment Analysis (https://aclanthology.org/2023.arabicnlp-1.27/)
- Anthology ID: 2023.arabicnlp-1.27 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. ChatGPT와 Bard AI와 같은 대형 언어 모델이 다양한 NLP 태스크에서 뛰어난 성능을 발휘하여 큰 관심을 받았다. 그러나 저자들은 이러한 모델들이 저자원 언어와 방언 (예: 영어와 아랍어 방언)에서의 성능을 알아보지 못했다고 말하며, 이 논문에서는 아랍어 방언에 대한 sentiment analysis를 위해 세 가지 LLM을 평가한다.
    2. 저자들은 Saudi dialect Twitter 데이터셋을 사용하여 LLM의 감성 텍스트 분류 및 생성 능력을 평가한다. 그들은 fully fine-tuned Arabic BERT 기반 모델의 분류 성능을 few-shot 설정에서 LLM과 비교하고, 생성된 새로운 감성 샘플의 품질을 인간 및 자동 평가 방법을 사용하여 평가한다.
    3. 실험 결과, GPT-4는 감성 분석 분류에서 GPT-3.5와 Bard AI를 앞지르며, 최고의 fully supervised BERT 기반 언어 모델과 견줄만한 성능을 보였다. 그러나 데이터 생성 측면에서는 수작업으로 주석이 달린 정통 아랍어 텍스트와 비교했을 때 생성 모델이 감성 분석에 적합한 고품질 아랍어 방언 텍스트를 생성하는 데 어려움이 있는 것으로 나타났다.

###### In-Context Meta-Learning vs. Semantic Score-Based Similarity: A Comparative Study in Arabic Short Answer Grading (https://aclanthology.org/2023.arabicnlp-1.28/)
- Anthology ID: 2023.arabicnlp-1.28 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 짧은 답변 평가를 자동화 시스템에 위임함으로써 교사는 핵심적인 비인간 중심 교육 측면에 더 많은 시간을 할애할 수 있으며, 자동 답변 평가 (ASAG)의 연구는 인스턴스 기반 또는 참고 기반 관점에서 문제에 접근하고 있다.
    2. 이 연구에서는 아랍어 ASAG 데이터셋을 사용하여 두 가지 접근 방식을 비교한다. 인스턴스 기반 방법에는 in-context 메타-러닝을 적용하고, 참고 기반 방법에는 시맨틱 점수 기반 유사도를 활용한다.
    3. 결과적으로 두 가지 방법 모두 기준 선을 능가하여 기준점 이상의 성능을 보이지만, 특히 시맨틱 점수 기반 유사도 방법은 제로샷 환경에서 뛰어난 성능을 보여준다.

###### SALMA: Arabic Sense-Annotated Corpus and WSD Benchmarks (https://aclanthology.org/2023.arabicnlp-1.29/)
- Anthology ID: 2023.arabicnlp-1.29 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. SALMA는 국소 자원이 없었던 아라비아어에 대한 첫 번째 의미주석된 말뭉치로, 각 토큰이 의미주석이 되어 있다. 
    2. SALMA는 하나의 토큰이 하나의 의도된 의미에만 연결되는 대신 여러 개의 의미에 연결하고 각 의미마다 점수를 부여하는 형식으로 구성되어 있다. 
    3. SALMA 코퍼스와 주석 도구는 오픈 소스로 제공되며, Word Sense Disambiguation 시스템을 구축하고 성능을 평가하는 데 활용될 수 있다.

###### Arabic dialect identification: An in-depth error analysis on the MADAR parallel corpus (https://aclanthology.org/2023.arabicnlp-1.30/)
- Anthology ID: 2023.arabicnlp-1.30 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 본 논문은 MADAR 병렬 말뭉치를 사용하여 아라비아 사투리 인식 작업에서 최첨단 모델의 성능을 체계적으로 분석하고 비교한다. 사전 훈련된 transformer 언어 모델과 다양한 특성을 갖춘 Naive Bayes 모델 기반 접근 방식을 테스트하였다. 데이터와 오류 분석을 통해 두 가지 접근 방식의 강점과 약점에 대해 유용한 통찰력을 제공한다.
    2. 논문에서는 어떤 사투리가 구별하기 어려운지, 그리고 오류의 잠재적인 원인을 분석하였다. 또한, MADAR-26 말뭉치의 테스트 세트에서 사투리 클래스별로 동일한 문장이 있는 중요한 문제를 발견하였는데, 이는 모든 분류기를 혼동시킬 수 있다. 
    3. 이 연구는 또한 테스트된 접근 방식들이 밀접한 관련이 있는 사투리들 사이의 미묘한 차이를 포착하지 못한다는 것을 보여준다.

###### Arabic Dialect Identification under Scrutiny: Limitations of Single-label Classification (https://aclanthology.org/2023.arabicnlp-1.31/)
- Anthology ID: 2023.arabicnlp-1.31 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 자동 아랍어 방언 식별(ADI) 시스템은 아랍어 마이크로 방언을 구분하기 어렵다고 보고되고 있다. 
    2. 이 논문은 ADI 작업을 단일 레이블 분류 문제로 접근하는 한계를 지적하고, 이것이 ADI 시스템의 평가에 어떻게 영향을 미치는지를 보여준다. 
    3. 따라서, 우리는 ADI를 여러 개의 레이블 분류 작업으로 접근하도록 제안하고, 새로운 ADI 데이터셋을 설계하기 위한 권장 사항을 제시한다.

###### Arabic Topic Classification in the Generative and AutoML Era (https://aclanthology.org/2023.arabicnlp-1.32/)
- Anthology ID: 2023.arabicnlp-1.32 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 최근 아라비아어 주제 분류 모델은 기존의 사전 훈련된 transformer 모델을 활용하고 제한된 수의 카테고리를 대상으로 한다. 
    2. 본 논문에서는 AraboNeClass라는 새로운 아라비아어 데이터셋과 그를 바탕으로한 주제 분류기를 제안한다. 
    3. ArGTClass는 다른 모델들 (Vertex AI, AutoML, AutoTrain) 보다 우수한 성능을 보여주었다.

###### On Enhancing Fine-Tuning for Pre-trained Language Models (https://aclanthology.org/2023.arabicnlp-1.33/)
- Anthology ID: 2023.arabicnlp-1.33 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 자연어 모델의 놀라운 능력은 그들이 다양한 분야에서 널리 사용되는 발판을 마련했으나, 특정 작업에 적용하기 위해서는 시간이 많이 소요되는 미세 조정 과정을 거쳐야 한다.
    2. 우리는 레이어 선택에 대한 매개변수 조작 만으로 제한된 접근법을 제안하여 함께 시간 최적화와 성능 보존 사이의 최적의 균형을 제공하는 레이어를 식별하였다.
    3. 다양한 하위 작업에서 이 접근법을 검증한 결과, 성능을 5% 미만의 무시할 수 있는 편차로 유지하면서 미세 조정 시간을 최대 50%까지 감소시킬 수 있는 잠재성을 보였다.

###### Multi-Parallel Corpus of North Levantine Arabic (https://aclanthology.org/2023.arabicnlp-1.34/)
- Anthology ID: 2023.arabicnlp-1.34 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 저 자원은 Indo-European 언어로 된 문장 120,600개를 다국어로 번역한 것으로, 저자들은 이 자원이 Arabic Machine Translation 연구에 어떻게 기여할 수 있는지 살펴본다.
    2. 이 자료는 Dialectal Arabic에 대한 연구에서 MSA와 dialects을 커버하고 있으며, English, French, German, Greek, Spanish의 여러 언어로 번역되었다.
    3. 훈련 및 세밀한 튜닝 실험을 통해 이 자원이 Arabic MT 연구에 어떻게 기여할 수 있는지 탐색한다.

###### Simplify: Automatic Arabic Sentence Simplification using Word Embeddings (https://aclanthology.org/2023.arabicnlp-1.35/)
- Anthology ID: 2023.arabicnlp-1.35 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 자동 텍스트 단순화는 원래 의미를 보존하면서 언어 복잡성을 단순화하는 것을 의미한다. 이 연구는 아라비아어에 대한 어휘 단순화 시스템을 개발하는데 초점을 맞추고 있다.
    2. FastText와 Arabert 사전 학습된 임베딩 모델을 이용하여 다양한 단순화 모델을 생성했다. 어려운 단어를 식별하고, 대체어들을 생성하며, 문장 내에서 어려운 단어를 대체하기 위한 선택 작업이 이루어졌다.
    3. 우리는 이러한 모델들이 실제로 어려운 단어를 정확하게 식별하고 선택하는데 효과적인지를 BERTScore를 사용하여 평가하였다.

###### Offensive Language Detection in Arabizi (https://aclanthology.org/2023.arabicnlp-1.36/)
- Anthology ID: 2023.arabicnlp-1.36 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. "저해성 언어를 리소스가 제한된 언어에서 탐지하는 것은 소셜 미디어 플랫폼에게 실제적인 도전입니다."
    2. "이 논문은 아라비츠어에서의 저해성 언어 탐지에 초점을 맞춘 첫 번째 연구입니다."
    3. "우리는 다양한 BERT 모델을 사용하여 아라비츠어에서의 저해성 언어 탐지의 가능성을 고도로 정확하게 보였습니다."

###### Yet Another Model for Arabic Dialect Identification (https://aclanthology.org/2023.arabicnlp-1.37/)
- Anthology ID: 2023.arabicnlp-1.37 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문에서는 ADI-5와 ADI-17 이라는 두 가지 벤치마크 데이터셋에서 이전에 발표된 결과를 일관되게 능가하는 아랍어 방언 식별 (ADI) 모델을 설명한다.
    2. ResNet과 ECAPA-TDNN 두 가지 아키텍처 변형과 MFCC와 UniSpeech-SAT Large에서 추출된 기능, 그리고 네 가지 변형을 결합한 퓨전을 탐색한다.
    3. 개별적으로 ECAPA-TDNN 네트워크가 ResNet보다 우수하며, UniSpeech-SAT 기능을 사용한 모델이 MFCC 기능을 사용한 모델을 큰 폭으로 능가하는 것을 발견한다. 또한, 네 가지 변형의 퓨전은 일관되게 개별 모델보다 우수한 성능을 보여준다. 최상의 모델들은 ADI-5와 ADI-17에서 각각 84.7%와 96.9%의 정확도로 이전에 보고된 결과를 능가한다.

###### VoxArabica: A Robust Dialect-Aware Arabic Speech Recognition System (https://aclanthology.org/2023.arabicnlp-1.38/)
- Anthology ID: 2023.arabicnlp-1.38 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 아랍어는 세계적으로 약 4억 5천만 명이 사용하는 많은 다양한 다이얼렉트와 변형이 있는 언어이다. 언어적 다양성 때문에 아랍어에 대한 강력하고 일반화된 자동 음성 인식 (ASR) 시스템을 구축하는 것은 어렵다. 
    2. 이 논문에서는 아랍어의 다이얼렉트 인식 (DID)과 ASR을 위한 VoxArabica 시스템을 개발하고 시연한다. DID 모델은 MSA를 포함한 17개의 다이얼렉트를 식별하기 위해 훈련되었고, ASR 모델은 MSA, 이집트어, 모로코어 및 혼합 데이터로 미세조정되었다.
    3. VoxArabica는 다양한 기능을 갖춘 단일 웹 인터페이스로 통합되어 있으며, 오디오 녹음, 파일 업로드, 모델 선택 및 잘못된 출력에 대한 깃발을 올릴 수 있는 옵션 등의 기능을 제공한다. 이 시스템은 아랍어 연구에 관심있는 다양한 사용자에게 유용할 것으로 기대된다.

###### KSAA-RD Shared Task: Arabic Reverse Dictionary (https://aclanthology.org/2023.arabicnlp-1.39/)
- Anthology ID: 2023.arabicnlp-1.39 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문은 아랍어를 위한 Reverse Dictionary(RD) 시스템을 개발하기 위한 KSAA-RD 공유 작업에 대해 개요를 제시한다. 
    2. RD는 사용자가 의미나 정의를 기반으로 단어를 찾을 수 있게 해준다.
    3. 이 공유 작업에는 아랍어 RD와 다국어 반대 사전(CLDR) 두 가지 하위 작업이 포함되어 있으며, 각 팀은 대응하는 단어의 가장 유사한 단어 임베딩을 찾기 위해 경쟁한다.

###### UWB at Arabic Reverse Dictionary shared task: Computing the meaning of a gloss (https://aclanthology.org/2023.arabicnlp-1.40/)
- Anthology ID: 2023.arabicnlp-1.40 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. MCQ 생성에 대한 기존 평가 메트릭은 교육적 가치를 고려하지 않으며, 새로운 평가 메트릭 KDA는 대답 가능성과 대상 사실에 대한 학생의 지식을 평가하고 이들과의 강한 상관관계를 보여줍니다.
    2. 최근의 deep model은 NLP 태스크에서 뛰어난 정확성을 보이지만, spurious pattern에 의존하고 있다는 문제가 있습니다. 이 논문에서는 counterfactual augmentation과 contrastive learning을 통해 robustness를 향상시키고 다양한 차원에서 개선되었습니다.
    3. 단어들의 인과관계를 파악하기 위해 여러 개의 counterfactual을 생성하고, 집합적 의사 결정을 통해 더 robust한 방법을 제안합니다.

###### Qamosy at Arabic Reverse Dictionary shared task: Semi Decoder Architecture for Reverse Dictionary with SBERT Encoder (https://aclanthology.org/2023.arabicnlp-1.41/)
- Anthology ID: 2023.arabicnlp-1.41 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 역사전은 특정 개념에 대한 설명 문구를 입력하면 해당 문구와 일치하는 단어와 정의를 반환한다. 많은 역사전이 영어와 같은 언어에 맞춰져 있고 온라인에서 쉽게 이용할 수 있지만 아랍어에 대한 비슷한 자원은 부족하다. 
    2. 이 논문은 아랍어 역사전에 대한 공유 작업에 참여한 내용을 소개한다. 제안된 방법은 두 가지 주요 단계로 구성되며, 첫 번째로 단어 정의를 다차원 벡터로 변환한다. 그런 다음 이러한 인코딩된 벡터를 목표 작업에 대해 Semi-Decoder 모델로 학습시킨다.
    3. Electra와 Sgns의 임베딩에 기반한 요소 검색 기준에 따라 우리의 시스템은 2위를 차지했다.

###### Abed at KSAA-RD Shared Task: Enhancing Arabic Word Embedding with Modified BERT Multilingual (https://aclanthology.org/2023.arabicnlp-1.42/)
- Anthology ID: 2023.arabicnlp-1.42 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 본 논문에서는 BERT Multilingual 모델과 수정된 augmentation, multi attention head를 활용하여 WANLP 2023의 Arabic Reverse Dictionary 공유 작업에 대한 새로운 접근 방법을 제안한다.
    2. 제안된 방법은 모노링구얼 및 크로스링구얼 상황에서 아라비아어 정의에 대한 단어 임베딩 이해와 생성의 성능을 향상시키기 위해 개발되었다.
    3. 제안된 방법은 공유 작업 1과 2에서 벤치마크 및 다른 모델과 비교하여 좋은 결과를 얻었다.

###### Rosetta Stone at KSAA-RD Shared Task: A Hop From Language Modeling To Word–Definition Alignment (https://aclanthology.org/2023.arabicnlp-1.43/)
- Anthology ID: 2023.arabicnlp-1.43 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 역사전은 사용자가 단어의 정의 또는 의미를 제공하면 해당 단어를 찾을 수 있는 도구입니다. 이 논문에서는 아랍어 역사전 작업에서 우승한 솔루션을 제시합니다.
    2. 첫 번째 하위 작업에서는 아랍어 정의를 입력으로 사용하며, 우리의 접근법은 파인튜닝된 아랍어 BERT 기반 모델 앙상블을 활용하여 주어진 정의에 대한 단어 임베딩을 예측합니다.
    3. 두 번째 하위 작업에서는 영어 테스트 정의를 아랍어로 번역하여 첫 번째 하위 작업에 사용된 모델에 적용하는 것이 가장 효과적인 해결책입니다. 이 간단한 방법은 두 하위 작업 모두에서 가장 높은 점수를 달성합니다.

###### ArAIEval Shared Task: Persuasion Techniques and Disinformation Detection in Arabic Text (https://aclanthology.org/2023.arabicnlp-1.44/)
- Anthology ID: 2023.arabicnlp-1.44 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문은 ArabicNLP 2023 회의의 일환으로 진행된 ArAIEval 공유 작업에 대한 개요를 제공한다. ArAIEval은 아라비아어 텍스트에 대해 두 가지 작업을 제공한다: (1) 설득 기법 감지는 트윗과 뉴스 기사에서 설득 기법을 식별하는 데 중점을 둔다. (2) 트윗에서 이변 정보 탐지는 이변 정보를 이진 및 다중 클래스 설정에서 식별한다. 
    2. 총 20개의 팀이 최종 평가 단계에 참여했으며, Task 1과 Task 2에 각각 14개와 16개의 팀이 참여했다. 두 작업 모두 AraBERT와 같은 transformer 모델의 fine-tuning이 대부분의 참가 시스템의 핵심인 것으로 관찰되었다. 
    3. 데이터셋 구축 및 평가 설치에 대한 설명과 참가 시스템에 대한 간략한 개요를 제공한다. 이 공유 작업의 모든 데이터셋과 평가 스크립트는 연구 커뮤니티에 공개되었으며, 아라비아어 NLP 커뮤니티에서 이러한 중요한 작업에 대한 추가적인 연구를 가능하게 할 것이다.

###### DetectiveRedasers at ArAIEval Shared Task: Leveraging Transformer Ensembles for Arabic Deception Detection (https://aclanthology.org/2023.arabicnlp-1.45/)
- Anthology ID: 2023.arabicnlp-1.45 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문은 아랍 소셜 미디어에서의 가짜 정보 대응을 위한 방법론을 제시하고 있으며, 해당 전략은 ArabicNLP 2023 컨퍼런스의 ArAIEval 공유 작업에서 2A 및 2B 과제에서 1위를 차지했습니다.
    2. DetectiveRedasers 팀은 아랍어를 위한 BERT 기반 모델을 중심으로 하고 soft-voting 앙상블 전략을 개선하여 하이퍼파라미터를 최적화한 파이프라인을 개발하였습니다.
    3. 테스트 데이터셋에서의 평가 결과, 앙상블은 일반적으로 견고하지만 항상 개별 모델을 능가하지는 못한다는 것을 확인하였으며, 본 논문의 주요 기여는 2A와 2B의 가짜 정보 분류 과제에서 우승 솔루션을 찾기 위한 다양한 전략입니다.

###### HTE at ArAIEval Shared Task: Integrating Content Type Information in Binary Persuasive Technique Detection (https://aclanthology.org/2023.arabicnlp-1.46/)
- Anthology ID: 2023.arabicnlp-1.46 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 광고는 대중 의견에 영향을 주고 인식을 조작하기 위해 많은 설득 전략을 사용하는데, 이 논문은 이러한 설득 기법을 탐지하기 위해 컨텐츠 유형 정보를 추가 기능으로 포함시키거나 멀티태스크 학습 설정에서 추가 학습 목적으로 변환기 기반 모델을 제안한다.
    2. 최고의 모델은 텍스트에서 설득 기법의 존재를 탐지하는 것뿐만 아니라, 부가적인 작업으로 텍스트 장르 (유형)에 기반하여 사용되는 구문적 및 어휘적 단서를 학습한다.
    3. 이 모델은 ArabicNLP2023-ArAIEval 공유 작업의 일부로 공식 결과에 따르면 13개 참가자 중 1A 공유 작업에서 가장 높은 점수를 달성하였으며, 매크로-F1은 73.21%, 마이크로-F1은 76.34%이다.

###### USTHB at ArAIEval’23 Shared Task: Disinformation Detection System based on Linguistic Feature Concatenation (https://aclanthology.org/2023.arabicnlp-1.47/)
- Anthology ID: 2023.arabicnlp-1.47 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 연구 논문에서는 surface preprocessing, morphological preprocessing, FastText 벡터 모델, TF-IDF 기능의 가중 퓨전 등 여러 가지 요인이 ArAIEval'2023 공유 작업에서 아라비아 디스인포메이션 탐지의 성능에 영향을 미치는지에 대해 종합적인 조사를 수행한다.
    2. 선형 서포트 벡터 분류 (LSVC) 모델을 사용하여 분류 작업을 수행한다. 
    3. 우리의 시스템은 이 작업의 두 번째 하위 작업에 제출된 다른 시스템들이 얻은 평균 F1 micro 점수와 유사하게 바이너리 및 다중 분류 시나리오에서 각각 76.70%와 50.46%의 F1 micro 점수를 달성하여 상당한 결과를 보여준다.

###### Mavericks at ArAIEval Shared Task: Towards a Safer Digital Space - Transformer Ensemble Models Tackling Deception and Persuasion (https://aclanthology.org/2023.arabicnlp-1.48/)
- Anthology ID: 2023.arabicnlp-1.48 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문은 "Arabic AI Tasks Evaluation (ArAiEval) Shared Task 2023"에서의 우리의 접근 방식을 강조한다. 
    2. 우리는 해당 공유 작업의 task 1-A와 task 2-A에 대한 접근 방식을 제시한다. 
    3. 위 과제는 설득 기법 감지와 잘못된 정보 감지에 초점을 맞추고, 아라비아어로 작성된 트윗과 뉴스 기사의 다양한 장르 스니펫을 이진 분류 문제로 제공한다.

###### KnowTellConvince at ArAIEval Shared Task: Disinformation and Persuasion Detection in Arabic using Similar and Contrastive Representation Alignment (https://aclanthology.org/2023.arabicnlp-1.49/)
- Anthology ID: 2023.arabicnlp-1.49 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 디지털 커뮤니케이션 시대에서 허위정보를 식별하고 대응하는 것은 매우 중요한 과제가 되었다. 그러나, 영어와 비교했을 때 아랍어로 이 다중 측면 문제를 해결하기 위한 자원과 전략은 상대적으로 희박하다.
    2. 이 논문은 ArAIEval 2023의 과제에 대한 솔루션을 제시한다. 태스크 1은 설득 기법을 탐지하는데 초점을 맞추고, 태스크 2는 아랍어 텍스트 내에서 허위정보를 탐지하는 것에 중점을 둔다.
    3. 다중 헤드 모델 아키텍처, 파인튜닝 기술, 순차 학습, 혁신적인 활성화 함수를 활용하여, 이 논문의 기여는 설득 기법과 허위정보 탐지 정확도를 크게 향상시켰다. 이를 통해 아랍어 콘텐츠 분석에 대한 공백을 채우고 아랍어권의 정보 소스 신뢰성을 유지하고자 하는 개인, 커뮤니티, 디지털 플랫폼을 지원한다.

###### PTUK-HULAT at ArAIEval Shared Task Fine-tuned Distilbert to Predict Disinformative Tweets (https://aclanthology.org/2023.arabicnlp-1.50/)
- Anthology ID: 2023.arabicnlp-1.50 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 디지털 세상에서 disinformation이 퍼짐에 따라, 소셜 미디어에서 disinformative한 정보를 식별하기 위한 자동 분류 모델이 필요하다. 
    2. 이 논문에서는 DistilBERT multilingual model을 fine-tune하여 Twitter 상에서 dis-informative 여부를 분류하는 것에 성공하였고, 기존의 베이스라인보다 우수한 결과를 달성했다. 
    3. 이 시스템은 전체 참가자 중 11위를 기록하며, F1 micro 87%와 F1 macro 80%로 잘 분류하였음을 보여주었다.

###### AraDetector at ArAIEval Shared Task: An Ensemble of Arabic-specific pre-trained BERT and GPT-4 for Arabic Disinformation Detection (https://aclanthology.org/2023.arabicnlp-1.51/)
- Anthology ID: 2023.arabicnlp-1.51 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 소셜 미디어를 통한 disinformation의 신속한 번성은, 빠른 접근성, 낮은 비용 및 사용 편의성과 같은 소셜 미디어의 기능 덕분에 사람들의 사고, 시각, 행동에 영향을 미치고 속일 위험성으로 인해 가장 위험한 방법 중 하나가 되었다. 
    2. 따라서 disinformation을 탐지하는 것은 어려워지고 있다. 이 논문에서는 disinformation 탐지에 대한 ArAIEval 대회의 일환으로 4가지 모델 (MARBERT, 제안된 앙상블 모델, GPT-4의 제로샷과 Few-shot)을 평가하였고, GPT-4는 79.01%이고 앙상블 모델은 76.83%의 micro-F1 score를 달성했다.
    3. 개발 데이터셋에서 앙상블로 수행한 micro-F1 점수 향상은 없었지만, 테스트 데이터셋에 대한 예측을 위해 여전히 앙상블 접근 방식을 사용했다. 다른 분류기들을 결합하는 것이 시스템의 예측 정확도를 향상시킬 수 있을 것으로 기대하였다.

###### rematchka at ArAIEval Shared Task: Prefix-Tuning & Prompt-tuning for Improved Detection of Propaganda and Disinformation in Arabic Social Media Content (https://aclanthology.org/2023.arabicnlp-1.52/)
- Anthology ID: 2023.arabicnlp-1.52 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 디지털 시대에 프로파간다와 잘못된 정보의 증가로 인해 기만적 정보의 확산을 막기 위해 효과적인 탐지 방법을 개발하는 것이 필요하다.
    2. 이 논문에서는 ArAIEval 공유 작업에 대한 정보 전파와 잘못된 정보 탐지를 위한 우리의 접근 방식을 소개하고 있다.
    3. 우리의 제안된 접근 방식은 prompt-learning 기반의 지식 확장과 prefix-tuning을 활용한 다양한 사전 학습된 BERT 기반 모델을 사용하여 성능을 향상시켰으며, 일반적인 fine-tuning 방법보다 prompt-tuning 기반과 prefix-tuning 기반 모델이 더 우수한 결과를 보였다.

###### Itri Amigos at ArAIEval Shared Task: Transformer vs. Compression-Based Models for Persuasion Techniques and Disinformation Detection (https://aclanthology.org/2023.arabicnlp-1.53/)
- Anthology ID: 2023.arabicnlp-1.53 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 소셜 미디어는 미신이 퍼지는 것을 크게 증폭시켰고, 자연어 처리와 머신러닝 기술을 사용하여 해당 플랫폼에서 거짓 정보를 식별하고 분류하는 데 이용되었다. 그러나 아라비아어 거짓 뉴스 감지에 대한 연구는 아직 많이 이루어지지 않았다.
    2. 본 논문은 2023 ArAIEval 공유 작업의 어려움을 해결하기 위해 사용된 방법을 설명한다. 모노링구얼 아라비아어와 다중 언어 사전훈련 언어 모델을 사용하여 실험을 진행했다. 모노링구얼 아라비아어 모델이 모든 4개 하위 작업에서 뛰어난 성과를 보였다.
    3. 또한 우리는 손실 없는 압축 방법을 사용하여 신경망 성능을 능가하지 못하였지만, 향후 실험에서 비슷한 결과를 더 효율적이고 신속하게 달성하기 위한 흥미로운 가능성을 제시하였다.

###### ReDASPersuasion at ArAIEval Shared Task: Multilingual and Monolingual Models For Arabic Persuasion Detection (https://aclanthology.org/2023.arabicnlp-1.54/)
- Anthology ID: 2023.arabicnlp-1.54 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 본 논문은 다국어 시스템을 사용하여 아라비아어 데이터에서 설득 감지(persuasion detection)를 향상시키기 위한 연구를 수행하였다.
    2. 본 연구는 다양한 시스템을 종합적으로 평가하여 그들의 성능을 비교하고 가장 효과적인 방법을 식별하기 위한 목표로 22개의 실험을 실시하였다. 
    3. 실험 결과, *ReDASPersuasion* 시스템이 다국어 "XLM-RoBERTa"와 모노링구얼 pre-trained transformer를 결합할 때 아라비아어 사투리("CAMeLBERT-DA SA")에서 NLP 분류 작업에 가장 우수한 성능을 보였다.

###### UL & UM6P at ArAIEval Shared Task: Transformer-based model for Persuasion Techniques and Disinformation detection in Arabic (https://aclanthology.org/2023.arabicnlp-1.55/)
- Anthology ID: 2023.arabicnlp-1.55 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문에서는 피설등 문제와 디스인포메이션 과제의 감지를 위한 참가 시스템을 소개한다. 
    2. 논문에서 제안된 시스템은 사전 훈련된 transformer-based 언어 모델과 분류기를 사용하여 성능을 검증했다.
    3. 실제 테스트 세트에서 시스템은 Sub-Task 1A, 1B, 2A 및 2B에 대해 각각 4위, 1위, 3위 및 2위의 순위를 기록하였다.

###### AAST-NLP at ArAIEval Shared Task: Tackling Persuasion technique and Disinformation Detection using Pre-Trained Language Models On Imbalanced Datasets (https://aclanthology.org/2023.arabicnlp-1.56/)
- Anthology ID: 2023.arabicnlp-1.56 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. AAST-NLP 팀은 설득 기법 탐지 및 거짓정보 탐지 공유 작업을 처리하기 위해 개발한 파이프라인을 제안하였다. 
    2. 이 논문에서는 주어진 데이터셋에서 AraBERT를 finetuning하고 각 subtask에 대해 적합한 몇 가지 절차를 수행하는 시스템을 제안한다. 
    3. 실험 결과로, 각 sub-task에서 좋은 성능을 보이며, 특히 sub-task 1B에서 3등을 차지하였다.

###### PD-AR at ArAIEval Shared Task: A BERT-Centric Approach to Tackle Arabic Disinformation (https://aclanthology.org/2023.arabicnlp-1.57/)
- Anthology ID: 2023.arabicnlp-1.57 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 본 연구는 최신 NLP 모델을 사용하여 중요한 자연어 처리 과제인 아라비아어 허위 정보 식별에 대해 탐구한다.
    2. 우리는 다국어와 아라비아어 특화된 기준 모델을 포함한 기준 모델들과의 시스템 모델의 성능을 강조하고, 도메인 특화 사전 훈련 모델의 효과를 보여준다.
    3. 이 연구는 NLP에서 맞춤형 사전 훈련 모델의 채택을 주장하며, 다양한 언어를 이해하는 데 그들의 중요성을 강조한다. 고급 NLP 기법을 도메인 특화 사전 훈련과 결합함으로써 아라비아어 허위 정보 식별을 발전시킨다.

###### Nexus at ArAIEval Shared Task: Fine-Tuning Arabic Language Models for Propaganda and Disinformation Detection (https://aclanthology.org/2023.arabicnlp-1.58/)
- Anthology ID: 2023.arabicnlp-1.58 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. "허구 정보와 선전적 콘텐츠의 확산은 사회적 조화를 위협하고, 정확한 의사결정과 신뢰할 수 있는 소식원에 대한 신뢰를 약화시킨다. 온라인 플랫폼은 종종 이러한 콘텐츠의 번식지로 작용하며, 악의적인 주체들은 대중의 취약점을 이용하여 대중 의견을 조작한다."
    2. "소셜미디어 콘텐츠에서 허위 정보와 선전을 자동으로 식별하기 위한 연구 노력이 있었지만, 성능 관점에서 여전히 어려움이 남아있다."
    3. "이 논문에서는 ArAIEval 공유과제에 우리가 참여한 것에 대해 논의한다. 우리는 1A 서브태스크와 2A 서브태스크에 참가하여 각각 9위와 10위의 위치를 차지하였다. 우리는 transformer 모델을 세밀하게 조정하고 GPT-4와 zero-shot 및 few-shot 학습을 활용한 실험을 진행하였다."

###### Frank at ArAIEval Shared Task: Arabic Persuasion and Disinformation: The Power of Pretrained Models (https://aclanthology.org/2023.arabicnlp-1.59/)
- Anthology ID: 2023.arabicnlp-1.59 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 우리는 ArAIEval 공유 과제의 일환으로, 아랍어 트윗에서 설득력을 탐지하기 위해 mBERT transformer를 사용했고, 아랍어 트윗에서의 허위정보를 식별하기 위해 MARBERT transformer를 사용했다. 설득력 탐지 시스템은 13.2%의 성능 향상으로 마이크로-F1 값이 0.745를 기록하였으며, 전체 점수로 측정한 매크로-F1 값은 0.717이었다.
    2. 마찬가지로, 허위정보 탐지 시스템은 6.7%의 성능 향상으로 마이크로-F1 값이 0.816를 기록하였으며, 매크로-F1 값은 0.637였다. 
    3. 또한, 우리는 다양한 사전 훈련 모델에 대한 예비 결과를 제시한다. 총 순위에서 우리의 시스템은 Subtask 1A에서 16개 팀 중 7위, 2A에서 17개 팀 중 12위에 해당한다.

###### Raphael at ArAIEval Shared Task: Understanding Persuasive Language and Tone, an LLM Approach (https://aclanthology.org/2023.arabicnlp-1.60/)
- Anthology ID: 2023.arabicnlp-1.60 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 사회적 미디어와 주류 미디어 플랫폼에서의 선전 및 비판 정보의 광범위한 전파는 정부기관과 사회적 미디어 기업과 같은 다양한 이해 관계자들의 관심을 받으며 긴급한 문제가 되었다. 이 논문에서는 아랍어와 같은 연구되지 않은 언어로의 속이기 기술 탐지 방법에 대한 접근 방식을 개요로 설명한다.  
    2. 우리는 텍스트에서 톤과 잠재적 설득 기술을 구분하기 위해 GPT-3를 활용하고, 다양한 기본 언어 모델을 탐구하며, 지정된 하위 작업들에 대해 다중 작업 학습 접근법을 사용하는 주요 기여를 하였다.
    3. 우리는 ArAIEval 2023의 공유 작업 1에 우리의 시스템을 제출하였으며, 이는 아랍어 트윗과 뉴스 기사 문단에서의 설득 기술 탐지를 다루고 있다.

###### Legend at ArAIEval Shared Task: Persuasion Technique Detection using a Language-Agnostic Text Representation Model (https://aclanthology.org/2023.arabicnlp-1.61/)
- Anthology ID: 2023.arabicnlp-1.61 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문은 Task 1에 초점을 맞춰, 트윗과 뉴스 기사에서 설득 기술을 식별하는 것을 다룬다. 
    2. XLM-RoBERTa를 사용하여 언어에 구애받지 않는 텍스트 표현 모델을 학습하여, 아라비아어 텍스트에서 설득 기술을 감지한다. 
    3. 의사 결정이나 dialog system 등 다양한 NLP 작업에 유용한 이 방법으로, 대회의 서브태스크 A에서 0.64의 높은 F1 스코어를 달성하였다.

###### NADI 2023: The Fourth Nuanced Arabic Dialect Identification Shared Task (https://aclanthology.org/2023.arabicnlp-1.62/)
- Anthology ID: 2023.arabicnlp-1.62 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. "Nuanced Arabic Dialect Identification Shared Task (NADI 2023)"는 표준화된 조건 하에서 협업 경쟁을 위해 연구팀들에게 기회를 제공함으로써 아랍어 NLP의 최신 기술을 발전시키기 위한 목적을 가지고 있다. 
    2. NADI 2023는 아랍어 방언 인식(Subtask 1)과 방언-MSA 기계 번역(Subtask 2 및 Subtask 3)에 초점을 맞춘다. 
    3. 결과적으로, 세 가지 subtask 모두 도전적이며, 앞으로의 연구에 동기를 부여한다.

###### DialectNLU at NADI 2023 Shared Task: Transformer Based Multitask Approach Jointly Integrating Dialect and Machine Translation Tasks in Arabic (https://aclanthology.org/2023.arabicnlp-1.63/)
- Anthology ID: 2023.arabicnlp-1.63 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 약 4억 명의 사용자를 가진 아라비아어는 세계적으로 5번째로 많이 사용되는 언어로, 자연어 처리 분야에서의 발전이 필요하다. 
    2. 이 논문에서는 EMNLP 2023의 Nuanced Arabic Dialect Identification (NADI) 과제의 하위 과제에 사용된 접근 방법에 대한 시스템 설명을 제공한다. 
    3. Closed country-level dialect identification 분류에는 두 개의 아라비아어 언어 모델 앙상블을 사용하고, closed dialect to Modern Standard Arabic (MSA) 기계 번역에는 아라비아어 특화 데이터셋에서 훈련된 sequence-to-sequence 모델을 결합한 접근 방법을 사용하였다.

###### UoT at NADI 2023 shared task: Automatic Arabic Dialect Identification is Made Possible (https://aclanthology.org/2023.arabicnlp-1.64/)
- Anthology ID: 2023.arabicnlp-1.64 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문에서는 우리가 아랍 사투리 식별을 위해 사용한 접근 방식을 제시한다. 사투리 식별을 위해 여러 기법들을 시도해보고, 수정된 학습 데이터셋으로 사전 학습된 MARBERTv2 모델을 세밀하게 조정함으로써 최상의 결과를 얻었다.
    2. 학습 데이터셋을 사투리 기준으로 정렬하고, 인접한 두 개의 트윗을 연결하여 새로운 트윗으로 추가함으로써 학습 데이터셋을 확장했다.
    3. 우리는 F1 점수 82.87을 달성하였고, 16개 참가자 중 일곱 번째로 성과를 얻었다.

###### SANA at NADI 2023 shared task: Ensemble of Layer-Wise BERT-based models for Dialectal Arabic Identification (https://aclanthology.org/2023.arabicnlp-1.65/)
- Anthology ID: 2023.arabicnlp-1.65 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. NADI-23에서 제출된 우리 시스템은 닫힌 계층별 방식으로 세밀한 아라비아 방언 식별 문제를 처리한다.
    2. 우리는 BERT 기반 모델의 layer-wise fine-tuning 앙상블을 기반으로 하는 모델을 제안한다.
    3. 제안된 모델은 16개 제출 중 네 번째로 랭킹되며 F1-macro 점수는 85.43이다.

###### ISL-AAST at NADI 2023 shared task: Enhancing Arabic Dialect Identification in the Era of Globalization and Technological Progress (https://aclanthology.org/2023.arabicnlp-1.66/)
- Anthology ID: 2023.arabicnlp-1.66 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 아랍어 방언은 중요성과 많은 사용자를 가지고 있지만, 기술적 진보와 세계화로 인해 중요한 변화가 일어나고 있다. 이 연구는 18개 국가의 방언을 카테고리화하고 있는데, 이를 위해 MARABERT와 MARABERT v2 모델을 활용하여 감정 분석을 수행하고 있다.
    2. MARABERT v2의 은닉층에 평균 앙상블과 연결을 적용하고, 결과 출력을 합성곱층에 투입함으로써 가장 효과적인 모델을 얻을 수 있었다.
    3. 다양한 방법에 대해 앙상블 기법을 적용함으로써 모델의 성능을 향상시킬 수 있었고, 연구 결과는 First subtask에서 상위 성과 중 6위를 차지하며 F1 점수 83.73%를 달성하였다.

###### Frank at NADI 2023 Shared Task: Trio-Based Ensemble Approach for Arabic Dialect Identification (https://aclanthology.org/2023.arabicnlp-1.67/)
- Anthology ID: 2023.arabicnlp-1.67 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 본 연구에서는 NADI의 Subtask 1을 위해 고안된 시스템을 소개하는데, 이는 ArabicNLP 2023의 일환이다. 
    2. 저희 접근 방식에서는 MARBERT, MARBERTv2 (A), MARBERTv2 (B)와 같은 모델을 활용하였다. 
    3. 이를 토대로 majority voting ensemble을 만들어 전체적인 성능을 향상시켰으며, 16개 팀 중 5위를 차지했다.

###### NLPeople at NADI 2023 Shared Task: Arabic Dialect Identification with Augmented Context and Multi-Stage Tuning (https://aclanthology.org/2023.arabicnlp-1.68/)
- Anthology ID: 2023.arabicnlp-1.68 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문은 팀의 접근 방식을 설명하고 나무지기 아랍어 방언 식별(NADI) 2023 공유 작업의 세부적인 작업에 대해 다룬다.
    2. 아랍어 특정 언어 모델, 클러스터링 및 검색 방법을 활용한 추가 문맥 제공, 2020년과 2021년 공유 작업에서 제공된 데이터를 사용한 fine-tuning 전략, 그리고 여러 모델의 예측을 앙상블하는 방법으로 Subtask 1에 접근한다.
    3. 제출한 결과는 매크로 평균 F1 점수가 87.27로, 이 작업의 다른 참가자들 중에서 1등을 차지했다.

###### USTHB at NADI 2023 shared task: Exploring Preprocessing and Feature Engineering Strategies for Arabic Dialect Identification (https://aclanthology.org/2023.arabicnlp-1.69/)
- Anthology ID: 2023.arabicnlp-1.69 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 본 논문에서는 NADI'2023의 아라비아 방언 식별에 영향을 미치는 여러 요소들을 깊이 있는 분석을 통해 조사하였으며, 특히 국가 수준의 방언 식별 부분에 초점을 맞추었다.
    2. 표면 전처리, 형태학적 전처리, FastText 벡터 모델, TF-IDF 특징의 가중된 연결 등 여러 요소가 성능에 미치는 영향을 조사하였다.
    3. 평가 단계에서는 Linear Support Vector Classification (LSVC) 모델을 사용하여 뛰어난 결과를 보였으며, F1 점수가 62.51%로, 이는 첫 번째 서브태스크에 제출된 다른 시스템의 평균 F1 점수인 72.91%와 유사한 결과를 보였다.

###### rematchka at NADI 2023 shared task: Parameter Efficient tuning for Dialect Identification and Dialect Machine Translation (https://aclanthology.org/2023.arabicnlp-1.70/)
- Anthology ID: 2023.arabicnlp-1.70 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 방언 식별 시스템은 음성 및 언어 기술, 언어 교육, 사회언어학 연구 지원, 언어 다양성 보전, 텍스트 음성 변환 시스템을 향상시키는 등 다양한 분야와 응용에서 중요한 역할을 한다.
    2. 본 논문에서는 국가 수준의 방언 식별 및 방언에서 MSA(Moderate Shared Arabic)로의 기계 번역(MT)을 위한 NADI 2023 공유 작업에서의 연구 결과를 제시한다.
    3. 실험 단계에서 제안된 모델은 전통적인 fine-tuning과 비교하여 성능이 향상된 매개변수 효율적인 훈련 방법을 사용한다.

###### UniManc at NADI 2023 Shared Task: A Comparison of Various T5-based Models for Translating Arabic Dialectical Text to Modern Standard Arabic (https://aclanthology.org/2023.arabicnlp-1.71/)
- Anthology ID: 2023.arabicnlp-1.71 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문은 너안스 아라비아 방언 식별(NADI) 2023 공유 작업을 위해 개발한 방법들을 소개한다. 
    2. 아라비아어 사투리 (이집트, 아랍에미리트, 요르단, 팔레스타인)로 쓰인 텍스트를 표준 아라비아어로 문장 수준 기계 번역하는 두 가지 하위 작업에 대해서 주로 타겟으로 삼는다.
    3. 저자들의 팀인 UniManc은 mT5, mT0, AraT5와 같은 T5를 기반으로 한 모델들을 사용하였고, J-R (joint model training for all regional dialects) 및 I-R (independent model training for every regional dialect) 두 가지 구성에 따라 모델을 훈련시켰다. 결과적으로 I-R AraT5 모델이 제일 높은 BLEU 점수를 얻어 그 부문에서 1위를 차지했다.

###### IUNADI at NADI 2023 shared task: Country-level Arabic Dialect Classification in Tweets for the Shared Task NADI 2023 (https://aclanthology.org/2023.arabicnlp-1.72/)
- Anthology ID: 2023.arabicnlp-1.72 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 본 논문에서는 NADI2023 shared task에 대한 참여 방법과 아랍어 방언 트윗의 분류를 위한 모델 개발을 제시한다.
    2. 실험 결과, Arabertv2-Large, Arabertv2-Base, CAMeLBERT-Mix DID MADAR과 같은 큰 언어 모델이 SVM, XGBOOST, Multinomial Naive Bayes, AdaBoost, Random Forests와 같은 전통적인 방법들보다 일관적으로 좋은 성능을 보였다.
    3. 총 18개의 아랍 국가로부터 수집된 트윗을 분류하기 위해 여러 가지 머신러닝 모델을 활용하는 접근법을 기술하였다.

###### The Helsinki-NLP Submissions at NADI 2023 Shared Task: Walking the Baseline (https://aclanthology.org/2023.arabicnlp-1.73/)
- Anthology ID: 2023.arabicnlp-1.73 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 헬싱키-NLP 팀은 아랍어 방언 번역 NADI 2023의 공유 작업에 7개의 제출물로 참여했다. 우리는 통계적(SMT) 및 신경망 기계 번역(NMT) 방법을 사용하고, 문자 및 서브워드 기반의 데이터 전처리를 탐구했다.
    2. 우리의 제출물은 양 트랙 모두 2등을 차지했다. 오픈 트랙에서 우리의 우승 제출물은 Modern Standard Arabic 언어 모델을 추가한 문자 수준의 SMT 시스템이었다.
    3. 닫힌 트랙에서는 leave-as-is 베이스라인과 입력의 단순한 복사, 그리고 SMT 시스템이 뒤를 이었으며, AraT5 또는 ByT5와 같은 기존 다국어 모델의 fine-tuning은 SMT와 비교했을 때 우수한 성능을 제공하지 않았다.

###### Mavericks at NADI 2023 Shared Task: Unravelling Regional Nuances through Dialect Identification using Transformer-based Approach (https://aclanthology.org/2023.arabicnlp-1.74/)
- Anthology ID: 2023.arabicnlp-1.74 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. "Nuanced Arabic Dialect Identification (NADI) Shared Task 2023"를 위한 접근 방식을 소개한다. 우리는 나라별 방언 식별(subtask 1)을 위한 방법론을 강조한다. 방언 인식은 음성 인식과 번역과 같은 다양한 NLP 태스크의 성능을 향상시키는 데 중요한 역할을 한다.
    2. 트위터 데이터셋(TWT-2023)을 사용하여, 다양한 아라비아어 transformer 기반 모델을 나라별 방언 식별에 활용한다.
    3. 제공된 데이터셋에서 최첨단 모델들을 fine-tuning하고, 앙상블 기법을 사용하여 시스템의 성능을 개선한다. 테스트 데이터셋에서 F1-score 76.65를 달성했다.

###### ANLP-RG at NADI 2023 shared task: Machine Translation of Arabic Dialects: A Comparative Study of Transformer Models (https://aclanthology.org/2023.arabicnlp-1.75/)
- Anthology ID: 2023.arabicnlp-1.75 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문은 NADI-2023 공유 과제(Subtask 2)의 맥락에서 결과를 제시한다. 이 과제는 마더 병렬 코퍼스(MADAR)를 사용하여 팔레스타인, 요르단, 아랍 에미리트, 이집트 방언으로부터 현대 표준 아랍어(MSA)로의 번역 모델 개발을 포함한다.
    2. 이 논문에서는 마더 코퍼스를 학습 자료로 사용하여 다양한 transformer 모델의 fine-tuning 결과를 비교 분석하고 에미리트 방언에 대한 병렬 하위 셋이 없는 경우에 대한 도전을 다룬다.
    3. 추가로, 기존의 번역 도구의 효과를 평가하여 번역 목표를 달성하는 데 어떤지 확인하였으며, 최고 성능 모델은 dev set에서 11.14%, test set에서 10.02%의 BLEU 점수를 달성하였다.

###### Qur’an QA 2023 Shared Task: Overview of Passage Retrieval and Reading Comprehension Tasks over the Holy Qur’an (https://aclanthology.org/2023.arabicnlp-1.76/)
- Anthology ID: 2023.arabicnlp-1.76 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. Holy Qur'an에 대한 지식 기반 질문 응답 시스템의 필요성을 바탕으로 Qur'an QA 2023이 개최되었다. 이 공유 과제는 두 가지 하위 과제인 passage retrieval (PR) task와 machine reading comprehension (MRC) task로 구성되어 있으며, Holy Qur'an에 대한 상위 연구를 장려하기 위해 진행되었다.
    2. 공유 과제에는 PR task에 9개의 팀이 22개의 실행 결과를 제출하였고, MRC task에는 6개의 팀이 17개의 실행 결과를 제출하였다.
    3. 이 논문에서는 공유 과제의 개요를 제시하고, 각 하위 과제에 참여한 팀들의 접근 방식에 대해 개요를 제공한다.

###### AHJL at Qur’an QA 2023 Shared Task: Enhancing Passage Retrieval using Sentence Transformer and Translation (https://aclanthology.org/2023.arabicnlp-1.77/)
- Anthology ID: 2023.arabicnlp-1.77 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 연구는 약 20억의 무슬림에게 영향을 미치고 언어적 풍부함과 복잡성으로 알려진 성전 꾸란에 대한 태스크 A에 참여했다. 문장 변환기와 OpenAI의 임베딩을 사용하여 두 가지 모델을 사용하고 아랍어 질의를 해석하고 이를 아랍어로 번역하여 검색 결과를 도출하는 기능을 제공하는 모델이 아랍어 질의응답 시스템의 성능을 향상시킬 수 있는 것을 보였다.
    2. 기계 번역 기능을 도입하면 아랍어 질의응답 시스템의 성능이 향상되는 것을 실험을 통해 확인하였다.
    3. 상당한 성능 향상을 보인 번역 모델은 모든 메트릭에서 비번역 모델에 비해 우수한 성능을 보였다.

###### LowResContextQA at Qur’an QA 2023 Shared Task: Temporal and Sequential Representation Augmented Question Answering Span Detection in Arabic (https://aclanthology.org/2023.arabicnlp-1.78/)
- Anthology ID: 2023.arabicnlp-1.78 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 퀴란은 신학적, 역사적 중요성을 가지고 있으며, 이 성서로부터 질문에 대답하는 기술 기반 솔루션을 개발하는 것이 매우 중요하다.
    2. 본 논문에서는 QRCD를 활용하여 퀴란 구절로부터 정확하고 문맥적인 답변을 추출하기 위해 혁신적인 기술과 고급 모델을 제안한다.
    3. Start 및 End logits, LSTM 네트워크, 퓨전 메커니즘을 활용한 접근법은 기술과 영성이 교차되는 분야에서의 지속적인 대화에 기여한다.

###### GYM at Qur’an QA 2023 Shared Task: Multi-Task Transfer Learning for Quranic Passage Retrieval and Question Answering with Large Language Models (https://aclanthology.org/2023.arabicnlp-1.79/)
- Anthology ID: 2023.arabicnlp-1.79 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 본 논문은 크루안(코란)과 같은 고전 텍스트에 대한 질문 응답의 도전과제에 대해 다루고 있다.
    2. 이 논문에서는 두 가지 작업인 passage retrieval과 reading comprehension을 소개한다.
    3. 아라일렉트라(AraElectra)라는 모델을 사용하여 읽기 이해 작업에서 기존 모델보다 23% 성능 향상을 보였다.

###### LKAU23 at Qur’an QA 2023: Using Transformer Models for Retrieving Passages and Finding Answers to Questions from the Qur’an (https://aclanthology.org/2023.arabicnlp-1.80/)
- Anthology ID: 2023.arabicnlp-1.80 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. Qur’an QA 2023 공유 작업에는 Passage Retrieval (PR) task와 Machine Reading Comprehension (MRC) task가 있으며, 우리는 PR task에 참여하여 Sentence-Transformers 아키텍처를 사용하여 몇 가지 아라비아 문장 사전 학습 모델을 추가로 훈련시키고 최고의 성능을 낼 수 있는 모델들을 앙상블하였다. 개발 세트의 결과와 테스트 세트의 결과가 일치하지 않았다.
    2. MRC task에도 참여하여 기존의 AraBERT의 베이스와 큰 변형을 Classical Arabic과 Modern Standard Arabic 데이터셋을 사용하여 더 잘 fine-tuning했다. 베이스 AraBERT는 개발 세트에서 가장 좋은 결과를 보여주었으며, pAP가 0.49, 테스트 세트에서는 0.5를 달성했다.
    3. 이 외에도 최고의 성능을 보이는 모델들을 앙상블하고 후처리 단계를 적용하여 최종 결과를 얻었다. 개발 세트의 실험에서는 제안한 모델이 0.537의 pAP를 달성했으며, 테스트 세트에서는 pAP 점수가 0.49가 되었다.

###### TCE at Qur’an QA 2023 Shared Task: Low Resource Enhanced Transformer-based Ensemble Approach for Qur’anic QA (https://aclanthology.org/2023.arabicnlp-1.81/)
- Anthology ID: 2023.arabicnlp-1.81 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. Qur'an QA 2023 공유 작업 A와 B에 대한 접근 방식을 제공한다. 훈련 데이터의 부족으로 인한 도전에 대처하기 위해, 여러 번의 실험을 통해 예측의 안정성을 향상시키기 위해 전이 학습과 투표 앙상블을 사용한다. 또한, 각 작업에 대해 다양한 아라비아어 사전 훈련된 트랜스포머 모델의 아키텍처와 학습 메커니즘을 사용한다.
    2. 대답할 수 없는 질문을 식별하기 위해 임계값 기반의 메커니즘을 제안한다.
    3. 성능이 우수한 시스템은 숨겨진 분할에서 기준 성능을 크게 뛰어넘으며, 과업 A에서 MAP 점수 25.05%, 과업 B에서 부분 평균 정밀도 (pAP) 57.11%를 달성한다.

###### Al-Jawaab at Qur’an QA 2023 Shared Task: Exploring Embeddings and GPT Models for Passage Retrieval and Reading Comprehension (https://aclanthology.org/2023.arabicnlp-1.82/)
- Anthology ID: 2023.arabicnlp-1.82 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 본 논문은 실행 가능한 평가 척도로 "Knowledge Dependent Answerability" (KDA)을 제안하여 자동 생성된 Multiple Choice Questions (MCQ)의 교육적 가치를 평가한다.
    2. 이 논문은 contrastive learning과 counterfactual augmentation을 활용하여 deep learning 모델의 강건성을 향상시킨다.
    3. 이 연구에서는 OpenAI의 "text-embedding-ada-002" 임베딩 모델과 GPT-4 언어 모델을 활용하여 Holy Qur'an과 관련된 데이터셋에 대한 텍스트 기반 자연어처리 태스크를 수행하는 종합 시스템을 제안한다.

###### WojoodNER 2023: The First Arabic Named Entity Recognition Shared Task (https://aclanthology.org/2023.arabicnlp-1.83/)
- Anthology ID: 2023.arabicnlp-1.83 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. "WojoodNER-2023는 국문명 개체 인식(Named Entity Recognition, NER)의 첫번째 아라비아어 공유 작업이다."
    2. "이 작업은 아라비아어 NER에 초점을 맞추어 새로운 NER 데이터셋과 다양한 NER 접근법 간의 유의미한 비교를 용이하게 하기 위한 서브태스크 정의를 제공한다."
    3. "WojoodNER-2023에는 FlatNER과 NestedNER 두 가지 서브태스크가 포함되었으며, 총 45개의 팀이 참가하고 최종 승자는 각각 91.96과 93.73의 F1 스코어를 달성하였다."

###### ELYADATA at WojoodNER Shared Task: Data and Model-centric Approaches for Arabic Flat and Nested NER (https://aclanthology.org/2023.arabicnlp-1.84/)
- Anthology ID: 2023.arabicnlp-1.84 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. "우리는 WojoodNER 공유 과제에 대한 참가 결과를 설명하는 논문입니다. 우리는 flat과 nested Named Entity Recognition (NER) 두 가지 하위 과제에 참여했습니다."
    2. "우리의 시스템은 Nested NER에서 8개 팀 중 1위, Flat NER에서 11개 팀 중 3위로 랭크되었습니다."
    3. "우리의 주요 제출물은 DiffusionNER 모델을 기반으로 하며, nested WojoodNER에서는 93.73%의 높은 신뢰도를 가지는 최고의 결과를 얻었습니다. Flat sub-task에서는 91.92%의 micro F1-score로 세 번째로 좋은 성능을 보였습니다."

###### Lotus at WojoodNER Shared Task: Multilingual Transformers: Unveiling Flat and Nested Entity Recognition (https://aclanthology.org/2023.arabicnlp-1.85/)
- Anthology ID: 2023.arabicnlp-1.85 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. "Wojood"의 Arabic NER detection 공유 과제에서 Subtask 1과 Subtask 2를 위해 개발한 시스템을 소개한다. 
    2. Subtask 1에서는 단일 분류기를 사용하여 XLM-R 모델을 적용하여 주어진 토큰에 대한 Flat NER 레이블을 예측한다. 
    3. Subtask 2에서는 21개의 개별 분류기를 구축하여 XLM-R 인코더를 사용하며, 각 분류기는 특정 레이블의 존재 여부를 결정하기 위해 설계되었다.

###### AlexU-AIC at WojoodNER shared task: Sequence Labeling vs MRC and SWA for Arabic Named Entity Recognition (https://aclanthology.org/2023.arabicnlp-1.86/)
- Anthology ID: 2023.arabicnlp-1.86 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 명명된 개체 인식(NER)은 아라비아어 자연어 처리에서 많은 어려운 과제 중 하나이다. 또한 주요 동향과 대중 의견을 이해하는 데 도움이 되는 다양한 중요한 하위 작업의 기반이 되기도 한다. 
    2. 본 논문은 아라비아어 NLP 2023의 NER Shared Task에 대한 참가 결과를 설명한다. Flat NER Subtask에서는 간단한 기계 독해 기반 기술을 사용하여 리더보드에서 8위를 차지하였으며, Nested NER Subtask에서는 언어 모델을 fine-tuning하여 리더보드에서 3위에 올랐다.

###### UM6P & UL at WojoodNER shared task: Improving Multi-Task Learning for Flat and Nested Arabic Named Entity Recognition (https://aclanthology.org/2023.arabicnlp-1.87/)
- Anthology ID: 2023.arabicnlp-1.87 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 우리는 플랫(flat)과 네스티드(nested) 아라비아어 명칭 엔티티 인식(NER)을 다루는 WojoodNER 공유 태스크를 위해 제출한 시스템을 제안한다. 객체는 BERT 기반 멀티태스크 학습 모델을 기반으로 하며, 아라비아어 사전훈련 언어 모델(Arabic Pretrained Language Models)을 활용하여 입력 문장을 인코딩한다. 
    2. 모델의 성능을 개선하기 위해 멀티태스크 손실 분산 벌칙과 크로스 엔트로피 손실, 다이스 손실, 트베르스키 손실, 포칼 손실 등 여러 학습 목적을 결합하여 사용하였다. 
    3. 공식 테스트 세트에서 우리의 시스템은 플랫 NER(서브태스크 1)에서 0.9113의 마이크로-F1 점수를, 네스티드 NER(서브태스크 2)에서는 0.9303의 점수를 얻었고 각각 해당 서브태스크에서 참가 시스템 중 6위와 2위를 기록하였다.

###### AlphaBrains at WojoodNER shared task: Arabic Named Entity Recognition by Using Character-based Context-Sensitive Word Representations (https://aclanthology.org/2023.arabicnlp-1.88/)
- Anthology ID: 2023.arabicnlp-1.88 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문은 single-task와 multi-task learning을 활용한 아라비아어 Named Entity Recognition(NER) 모델을 제안한다.
    2. 모델은 단어 시퀀스의 입력 레이어에서 character-based contextualized Embeddings from Language Model (ELMo)를 사용하여 개발되었다.
    3. 싱글 태스크 모델이 멀티 태스크 모델보다 더 우수한 성능을 보이며, 플랫과 네스트된 annotations에 대해 각각 0.8751과 0.8884의 micro F1-score을 달성하였다.

###### LIPN at WojoodNER shared task: A Span-Based Approach for Flat and Nested Arabic Named Entity Recognition (https://aclanthology.org/2023.arabicnlp-1.89/)
- Anthology ID: 2023.arabicnlp-1.89 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. Wojood Named Entity Recognition (NER) shared task는 한정된 Arabic 자원에 대한 도전을 해결하기 위한 포괄적인 Arabic NER 데이터셋을 소개한다.
    2. 이 논문에서는 NER을 span classification 문제로 처리하고, 사전 훈련된 언어 모델과 신경망 분류기를 사용하여 두 가지 하위 작업을 다루는 LIPN 팀의 접근 방식을 소개한다.
    3. LIPN 팀은 flat NER에서 91.96의 F-스코어로 1위, nested NER에서 92.45의 F-스코어로 4위를 달성하였다.

###### Alex-U 2023 NLP at WojoodNER shared task: AraBINDER (Bi-encoder for Arabic Named Entity Recognition) (https://aclanthology.org/2023.arabicnlp-1.90/)
- Anthology ID: 2023.arabicnlp-1.90 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이름 인식(Named Entity Recognition, NER)은 텍스트로부터 중요한 정보를 추출하는데 도움이 되는 자연어 처리의 중요한 작업입니다. 그러나 아라비아어로 NER를 수행하는 것은 해당 언어의 특성으로 인해 큰 도전이 있습니다.
    2. 이 논문에서는 우리의 AraBINDER (Arabic Bi-Encoder for Named Entity Recognition)를 소개합니다. AraBINDER는 두 개의 트랜스포머 인코더를 활용하며 대상 텍스트 범위와 엔터티 유형을 동일한 벡터 표현 공간으로 매핑하기 위해 대조 학습을 사용합니다.
    3. AraBINDER는 Wojood 데이터셋에서 Flat NER의 경우 0.918의 마이크로 F-1 점수와 Nested NER의 경우 0.9의 마이크로 F-1 점수를 달성했습니다.

###### El-Kawaref at WojoodNER shared task: StagedNER for Arabic Named Entity Recognition (https://aclanthology.org/2023.arabicnlp-1.91/)
- Anthology ID: 2023.arabicnlp-1.91 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. Named Entity Recognition (NER)은 위치, 조직, 인물, 화폐와 같은 개체에 해당하는 단어를 식별하는 작업이다. 이 논문에서는 아랍어에서 flat-entity classification 작업을 다루며, 각 단어에 대해 하나의 개체를 식별해야 한다.
    2. 우리는 StagedNER라는 새로운 기술을 제안하여 NER 다운스트림 작업의 fine-tuning을 수행한다. 이 기술은 transformer 모델의 학습 과정을 두 단계로 나누어 시퀀스 태그와 개체 태그를 따로 학습함으로써 분류 문제를 해결한다.
    3. 이 방법을 사용하여 두 개의 기본 모델의 앙상블을 만들고, 개발 집합에서의 점수는 XXX이며, 검증 집합에서의 F1 성능은 90.03%이고 테스트 집합에서의 F1 성능은 91.95%이다.


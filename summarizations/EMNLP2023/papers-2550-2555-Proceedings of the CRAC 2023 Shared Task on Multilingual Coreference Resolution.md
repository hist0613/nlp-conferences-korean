# Korean Three-Line Summarizations of Papers 2550-2555 in Proceedings of the CRAC 2023 Shared Task on Multilingual Coreference Resolution
###### Proceedings of the CRAC 2023 Shared Task on Multilingual Coreference Resolution (https://aclanthology.org/2023.crac-sharedtask.0/)
- Anthology ID: 2023.crac-sharedtask.0 
- Volume: Proceedings of the CRAC 2023 Shared Task on Multilingual Coreference Resolution 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Findings of the Second Shared Task on Multilingual Coreference Resolution (https://aclanthology.org/2023.crac-sharedtask.1/)
- Anthology ID: 2023.crac-sharedtask.1 
- Volume: Proceedings of the CRAC 2023 Shared Task on Multilingual Coreference Resolution 
- Summary: 
    1. 논문은 멀티링귀언어(CorefUD 데이터셋)의 공동 참조 해결(shared task)에 대한 두 번째 에디션에 대한 요약이다. 작년과 같이 공동 참조 해결을 위한 학습 가능한 시스템을 생성하는 참가자들의 참여가 이뤄졌지만, 이번에는 조금 다른 주요 평가 점수와 12개 언어에 대한 17개 데이터셋을 사용했다.
    2. 이번에는 학습 및 평가 데이터로 CorefUD 데이터셋의 1.1 버전을 사용했다. 
    3. 이번에는 7개 시스템이 이 공동 참조 해결(shared task)에 참가했다.

###### Multilingual coreference resolution: Adapt and Generate (https://aclanthology.org/2023.crac-sharedtask.2/)
- Anthology ID: 2023.crac-sharedtask.2 
- Volume: Proceedings of the CRAC 2023 Shared Task on Multilingual Coreference Resolution 
- Summary: 
    1. CRAC 공유 작업 2023을 위해 제출된 두 개의 다국어 coreference resolution 시스템을 소개하며, DFKI-Adapt 시스템은 4.9 F1 점으로 공식 기준치를 능가하는 성능을 보인다.
    2. DFKI-Adapt 시스템은 문자 임베딩, 어댑터 모듈, 공동 사전 훈련 및 손실 기반 재훈련 등 다양한 특징과 학습 설정의 조합을 사용한다.
    3. 다른 제출인 DFKI-MPrompt는 mention generation을 위해 프롬프트를 사용하는 혁신적인 접근법을 채택하였으며, 훈련을 단 5회만 시행하여 좋은 결과를 제공한다.

###### Neural End-to-End Coreference Resolution using Morphological Information (https://aclanthology.org/2023.crac-sharedtask.3/)
- Anthology ID: 2023.crac-sharedtask.3 
- Volume: Proceedings of the CRAC 2023 Shared Task on Multilingual Coreference Resolution 
- Summary: 
    1. 형태론이 풍부한 언어에서는 단어가 형태소로 구성되어 있어 형태소 수준의 표현을 사용해야 할 수도 있고, 이 연구에서는 transformer 기반 단어 임베딩에 형태론 정보를 통합하여 다국어 end-to-end coreference resolution 시스템을 소개한다.
    2. 형태론 정보를 명시적으로 coreference resolution에 포함시키면 특히 형태론이 풍부한 언어에서 (예: 카탈로니아어, 헝가리어, 터키어) 성능이 향상된다.
    3. 이 모델은 CoNLL F-score가 59.53%로 기준 모델보다 평균적으로 2.57% 포인트 우수한 성능을 달성한다.

###### ÚFAL CorPipe at CRAC 2023: Larger Context Improves Multilingual Coreference Resolution (https://aclanthology.org/2023.crac-sharedtask.4/)
- Anthology ID: 2023.crac-sharedtask.4 
- Volume: Proceedings of the CRAC 2023 Shared Task on Multilingual Coreference Resolution 
- Summary: 
    1. CorPipe는 다국어 코어퍼런스 해결 CRAC 2023 공유 작업에서 우승한 시스템으로, 다른 참가자들을 4.5% 이상 앞섰다.
    2. CorPipe는 먼저 멘션 탐지를 수행하고 그 후에 검색된 스팬에서 속기 원칙을 적용하여 코어퍼런스 링크를 수행한다.
    3. CorPipe는 모든 사용 가능한 말뭉치를 공유 사전 학습 언어 모델을 사용하여 함께 학습시키며, 512개의 subwords보다 큰 입력과 멘션 디코딩 변경 및 앙상블 지원을 포함한 주요 개선 사항이 있다.

###### McGill at CRAC 2023: Multilingual Generalization of Entity-Ranking Coreference Resolution Models (https://aclanthology.org/2023.crac-sharedtask.5/)
- Anthology ID: 2023.crac-sharedtask.5 
- Volume: Proceedings of the CRAC 2023 Shared Task on Multilingual Coreference Resolution 
- Summary: 
    1. CRAC 2023 공유 작업을 위해 제출된 우리의 모델은 12개 언어를 포함한 17개 데이터셋을 공동 학습한 엔티티 순위 모델로, 이전에 제출된 모델들을 F1 스코어 차이 +8.47로 앞선 성능을 보여주어, 공유 작업에서 4등을 달성했다.
    2. 데이터 전처리, 사전 훈련된 인코더, 데이터 혼합과 관련된 설계 결정에 대해 탐구하였다. 
    3. 우리의 모델은 최종적으로 F1 스코어 65.43을 달성하여 공유 작업에서 우수한 성과를 보여주었다.


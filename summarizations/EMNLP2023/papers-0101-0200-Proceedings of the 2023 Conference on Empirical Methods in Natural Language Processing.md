# Korean Three-Line Summarizations of Papers 101-200 in Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing
###### Increasing Coverage and Precision of Textual Information in Multilingual Knowledge Graphs (https://aclanthology.org/2023.emnlp-main.100/)
- Anthology ID: 2023.emnlp-main.100 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어처리와 컴퓨터 비전분야에서는 지식 그래프 안에 있는 텍스트 정보인 entity 이름과 설명을 활용하여 고품질의 구조화된 데이터에 neural model을 적용하는 연구가 진행되어왔으나, 비영어 언어에서는 텍스트 정보의 양과 품질이 부족하다. 
    2. 이 논문은 영어와 비영어 언어 간의 텍스트 정보의 양과 품질의 격차를 줄이기 위해 자동 지식 그래프 완성(KGE)이라는 새로운 과제를 제안한다. 
    3. M-NTA라는 새로운 비지도 학습 방법을 제시하여 높은 품질의 텍스트 정보를 생성하고, 비영어 텍스트 정보의 다국어 커버리지와 정확성이 Entity Linking, Knowledge Graph Completion 및 Question Answering에 미치는 영향을 연구하였다.

###### Memory-Based Invariance Learning for Out-of-Domain Text Classification (https://aclanthology.org/2023.emnlp-main.101/)
- Anthology ID: 2023.emnlp-main.101 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다양한 소스 도메인에서 학습된 분류 모델을 처음 보는 타겟 도메인에 적용하는 OOD 텍스트 분류 작업에 대해 조사한다. 
    2. 최근 연구들이 불변 표현 학습이 OOD 일반화 성능을 향상시킬 수 있다고 보여줬지만, 서로 다른 도메인 간의 데이터 분포 차이로 인해 효과적인 불변 표현 학습이 어려움을 겪는다. 
    3. 이 연구에서는 메모리 증강 기법을 적용하여 이 문제를 해결하고, key-value 메모리를 이용하여 원래의 특성 공간을 보강하고, 메타 학습 기반 접근법을 사용하여 불변 표현의 품질을 향상시키는 방법을 제안한다.

###### Outlier Suppression+: Accurate quantization of large language models by equivalent and effective shifting and scaling (https://aclanthology.org/2023.emnlp-main.102/)
- Anthology ID: 2023.emnlp-main.102 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Transformer 언어 모델의 후훈련 양자화(PTQ)는 활성화 함수 내의 잘못된 아웃라이어(outlier)로 인해 심각한 문제가 있다. 
    2. 이 논문에서는 아웃라이어로 인한 비대칭성과 불규칙한 분포를 해결하기 위해 채널별 이동과 스케일링을 제안한다.
    3. 실험 결과, 이 방법은 다양한 태스크에서 탁월한 성능을 보여주고, 특히 4-bit BERT에서 15.5%의 개선을 이끌어낸다.

###### Three Stream Based Multi-level Event Contrastive Learning for Text-Video Event Extraction (https://aclanthology.org/2023.emnlp-main.103/)
- Anthology ID: 2023.emnlp-main.103 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 텍스트-비디오 기반 다중 모달 이벤트 추출에서는 주어진 텍스트-비디오 쌍에서 이벤트 정보를 식별하는 것을 의미한다. 기존의 방법들은 비디오의 외관 특징(VAF)과 텍스트 시퀀스의 특징(TSF)을 주로 입력 정보로 활용한다.
    2. 이 논문에서는 비디오의 모션 표현과 대조적 학습의 최적화 문제에 대해 다룬다.
    3. 우리는 비슷한 모션 트라젝토리를 가진 이벤트 트리거가 같은 이벤트를 발생시킨다는 것을 관찰하고, 이를 활용하여 이벤트 추출 능력을 향상시키기 위해 Three Stream Multimodal Event Extraction (TSEE) 프레임워크를 제안한다.

###### Diversify Question Generation with Retrieval-Augmented Style Transfer (https://aclanthology.org/2023.emnlp-main.104/)
- Anthology ID: 2023.emnlp-main.104 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사람들은 주어진 텍스트와 답변에 대해 다양한 표현으로 질문을 할 수 있는 반면, 대부분의 질문 생성(QG) 시스템은 이를 아직 도전적으로 여기고 있다.
    2. 기존의 해결책은 대부분 주어진 텍스트 내부의 지식이나 다양한 콘텐츠 계획을 위한 의미적 단어 공간에 초점을 맞추었다. 그러나 이러한 방법들은 외부 지식의 표현 다양성의 잠재력을 고려하지 않았다.
    3. 본 논문에서는 "Retrieval-Augmented Style Transfer"라는 프레임워크를 제안하여 다양한 템플릿의 스타일을 활용하여 질문을 생성한다. 실험 결과는 다양성에 있어 이전의 다양성 중심 기준선보다 우수하면서 일관성 점수에 있어서는 비교 가능함을 보여준다.

###### Fast and Accurate Factual Inconsistency Detection Over Long Documents (https://aclanthology.org/2023.emnlp-main.105/)
- Anthology ID: 2023.emnlp-main.105 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "생성적 AI 모델들은 놀라운 잠재력을 보여주지만, 긴 입력에 대해서는 현재의 접근법이 효과적으로 대응하기 어려운 다양한 작업에서 환각이 발생하는 것은 큰 문제입니다."
    2. 저희는 SCALE (Source Chunking Approach for Large-scale inconsistency Evaluation)라는 임의 작업 모델을 소개합니다. 이 모델은 새로운 청크 전략을 사용하여 사실상의 불일치를 감지하기 위한 모델입니다. 
    3. SCALE은 단일한 언어 판별(Natural Language Inference, NLI) 모델이며, 긴 텍스트를 처리하기 위해 대규모 텍스트 청크를 사용합니다. 이 접근법은 다양한 작업과 긴 입력에 대한 사실상의 불일치 감지에서 최고의 성능을 보입니다.

###### Interpreting Embedding Spaces by Conceptualization (https://aclanthology.org/2023.emnlp-main.106/)
- Anthology ID: 2023.emnlp-main.106 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 텍스트의 연산적인 해석을 위한 주요 방법 중 하나는 embedding space로 맵핑하는 것이다. 이 논문에서는 latent embedding space를 이해하기 쉬운 개념적인 공간으로 변환하는 새로운 방법을 제안한다.
    2. 논문에서는 개념적인 공간을 동적으로 생성하는 알고리즘을 소개하고, 인간 평가자나 LLM(Large Language Models) 기반 평가자를 사용하여 개념화된 벡터가 실제 의미를 잘 표현하는지 보여준다.
    3. 개념화된 벡터를 사용하여 대체 모델의 의미를 비교하고 LLM의 레이어를 추적하는 등 다양한 태스크에 사용할 수 있음을 보여준다.

###### Knowledge-Augmented Language Model Verification (https://aclanthology.org/2023.emnlp-main.107/)
- Anthology ID: 2023.emnlp-main.107 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 언어 모델은 내부 지식을 파라미터에 내재시키므로 훌륭한 텍스트 생성 능력을 보여주지만, 지식이 부정확하거나 불완전하거나 오래되어 결과가 사실적이지 않을 수 있다. 
    2. 이 논문에서는 외부 지식 소스와 함께 언어 모델을 보완하기 위해 별도의 검증기를 도입하여, 지식과 결과를 검증하고 에러를 수정하는 방법을 제안하였다. 
    3. 실험 결과, 제안된 검증 단계가 언어 모델의 문제를 규명하는 데 효과적이었으며, 정확한 결과를 제공하는 데 도움이 되었다.

###### A Generation-based Deductive Method for Math Word Problems (https://aclanthology.org/2023.emnlp-main.108/)
- Anthology ID: 2023.emnlp-main.108 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 선형 방정식 풀이와 같은 고급 연산자를 포함한 수학 워드 문제는 기존의 방법들로 쉽게 해결할 수 없다. 이 논문에서는 기존의 이진 표현 트리나 증명 방법의 이진 유향 비순환 그래프 대신 새로운 다중 변수 유향 비순환 그래프 (mDAG)을 제안한다.
    2. mDAG의 위상 순서를 생성하기 위해, 기존의 증명 방법의 비싼 열거를 피하면서 증명 속성을 유지하기 위해 세대 기반 증명 (GeDe) 모델을 제안한다.
    3. GeDe는 널리 사용되는 벤치마크에서 여러 연산자를 가진 수학 문제와 자체 CMWPA 벤치마크에서 다중 변수 연산자를 효과적으로 해결하는 성능을 보여준다.

###### Failures Pave the Way: Enhancing Large Language Models through Tuning-free Rule Accumulation (https://aclanthology.org/2023.emnlp-main.109/)
- Anthology ID: 2023.emnlp-main.109 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델들은 놀라운 성능을 보여주지만, 샘플들 사이의 관계를 파악하지 못하는 문제로 인해 비슷한 실수를 반복하는 경향이 있다.
    2. 우리는 이 논문에서 이전의 실수로부터 배우면서 성능을 향상시키는 Tuning-free Rule Accumulation (TRAN) 프레임워크를 제안한다.
    3. 시퀀셜하게 도착하는 데이터를 고려하여, LLM은 틀린 케이스로부터 규칙을 점진적으로 축적하여 규칙 컬렉션을 형성하고, 이후의 입력 처리 시에 비슷한 실수를 피하기 위해 이러한 규칙을 활용한다. TRAN은 최근 기준선에 비해 성능을 크게 향상시킴을 실험적으로 보여준다.

###### Building Persona Consistent Dialogue Agents with Offline Reinforcement Learning (https://aclanthology.org/2023.emnlp-main.110/)
- Anthology ID: 2023.emnlp-main.110 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 오픈 도메인 대화 시스템에서 일관된 개성 유지는 중요한 품질이다. 기존 SOTA 시스템은 supervised learning 또는 online reinforcement learning으로 에이전트를 훈련시켜 이를 달성한다. 그러나 supervised learning으로 훈련된 시스템은 모순을 말할 경우에도 벌을 받지 않기 때문에 일관성이 부족하다. RL 훈련을 추가로 하면 이러한 문제를 완화할 수 있지만, 훈련 과정이 비용이 많이 든다.
    2. 본 논문에서는 대화 시스템의 개성 일관성을 향상시키기 위해 오프라인 RL 프레임워크를 제안한다. supervised learning과 유사하게 기존 데이터로 모델을 저비용으로 훈련하면서도 RL에서 특정 발언을 벌하거나 보상하는 것과 같은 이점을 결합할 수 있다.
    3. 또한, 오프라인 RL 훈련에서 중요도 가중치의 분산을 줄이기 위해 Variance-Reducing MLE-Initialized (VaRMI) importance sampling이라는 간단한 중요도 샘플링 방법을 도입한다. 자동 및 인간 평가 결과에서 본 프레임워크가 SOTA 소셜 챗봇의 개성 일관성 및 대화 품질을 향상시킨다는 것을 보여준다.

###### Augmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories (https://aclanthology.org/2023.emnlp-main.111/)
- Anthology ID: 2023.emnlp-main.111 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 우리는 Mixture-Of-Memory Augmentation (MoMA)을 통해 언어 모델의 zero-shot generalization 능력을 향상시켰다. 이 기법은 다중 정보 말뭉치(외부 메모리)에서 augmentation 문서를 검색하여 보완하는 메커니즘이다.
    2. 우리는 end retrieval task로부터 유래된 잠재적 레이블과 memory mixture의 hard negatives와 함께 augmentation 구성 요소를 훈련시키는 공동 학습 메커니즘을 개발했다.
    3. 우리의 모델은 T5 기반의 강력한 retriever를 MoMA로 보완하여 zero-shot 검색 정확도를 향상시킨다. 우리의 모델은 T5-base만 사용하여 표준 BEIR 벤치마크에 포함된 18가지 작업에서 강력한 zero-shot 검색 정확도를 보이며, 일부 큰 모델 크기를 가진 시스템들을 능가한다.

###### Active Instruction Tuning: Improving Cross-Task Generalization by Training on Prompt Sensitive Tasks (https://aclanthology.org/2023.emnlp-main.112/)
- Anthology ID: 2023.emnlp-main.112 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Instruction tuning(IT)는 instruction이 포함된 다양한 task에 대해 대규모 언어 모델(LLMs)을 학습하여 높은 일반화 성능을 얻었지만, 어떤 새로운 task를 선택해야 IT 모델의 성능과 일반화 능력을 향상시킬 수 있는지는 여전히 미해결한 문제이다.
    2. 이 논문에서는 prompt uncertainty를 바탕으로 하는 active instruction tuning이라는 새로운 프레임워크를 제안하여 정보성이 있는 task를 식별하고 선택된 task에서 모델을 적극적으로 조정한다.
    3. 실험 결과는 prompt uncertainty와 예측 확률에 기반한 task map을 소개하고, 모호한 task는 일반화를 향상시키고 어려운 task는 이점이 없다는 것을 발견하여 instruction tuning에서 task 선택의 중요성을 강조하고 있다.

###### Towards Example-Based NMT with Multi-Levenshtein Transformers (https://aclanthology.org/2023.emnlp-main.113/)
- Anthology ID: 2023.emnlp-main.113 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Retrieval-Augmented Machine Translation (RAMT)은 번역 지표를 향상시킬 뿐만 아니라 도메인 적응을 구현하는 데에도 관심이 높아지고 있다.
    2. 논문에서는 RAMT의 또 다른 특징인 번역 결정의 투명성 향상을 위해 새로운 아키텍처를 제안한다.
    3. 실험에서, 여러 예시를 동시에 편집하는 것이 번역 점수에 긍정적인 영향을 미치며, 기존 인스턴스로부터 복사된 대상 구간의 수를 증가시킨다는 것을 보여준다.

###### DUnE: Dataset for Unified Editing (https://aclanthology.org/2023.emnlp-main.114/)
- Anthology ID: 2023.emnlp-main.114 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 고급 언어 모델들도 수정 없이는 오류에 취약한데, 모델 편집은 원하는 결과를 얻기 위해 모델의 지식이나 표현을 수정하는 것을 의미한다.
    2. 이 연구에서는 사실 기반 데이터만 수정하던 이전 연구들과 달리, 편집 문제의 범위를 더 넓혀 여러 편집 작업에 대응하고, 모델의 출력을 수정하는 어떤 자연어 표현도 편집으로 간주함을 제안한다.
    3. DUnE라는 편집 벤치마크를 도입하여 DUnE 문제에 대한 다양한 편집 접근 방식을 실험적으로 검증하고, 특화된 편집 기술보다 검색 기반 언어 모델링이 더 좋은 성능을 보이며, 벤치마크가 다루는 일반화된 편집 문제를 완전히 해결하지 못한 상태임을 주장한다.

###### “Fifty Shades of Bias”: Normative Ratings of Gender Bias in GPT Generated English Text (https://aclanthology.org/2023.emnlp-main.115/)
- Anthology ID: 2023.emnlp-main.115 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어는 사회적인 신념 체계의 표현 도구로서 강력한 역할을 하지만, 동시에 우리 사회의 편견을 지속시킨다. 성별 편견은 온라인과 오프라인 대화에서 가장 만연한 편견 중 하나이다. 이 연구에서는 binary classification 문제가 아니라 상대적인 척도에서 성별 편견을 인식해야 한다는 점을 감안하여 다양한 정도의 편견을 생성하고 사람들의 반응을 조사한다.
    2. Best-Worst Scaling을 사용하여 성별 편견의 정량적 평가를 포함하는 GPT로 생성된 영어 텍스트의 첫 데이터셋을 만들었다.
    3. 우리는 편견의 다른 주제들에 대한 분석 결과를 보여주고, 신원-공격 (identity-attack)이 성별 편견과 가장 밀접하게 관련되어 있다는 것을 밝혔다. 또한, 우리의 데이터셋에서 관련 개념에 대해 훈련된 기존 자동 모델의 성능을 보여주었다.

###### Hybrid Inverted Index Is a Robust Accelerator for Dense Retrieval (https://aclanthology.org/2023.emnlp-main.116/)
- Anthology ID: 2023.emnlp-main.116 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "역 파일 구조는 밀집 검색을 가속화하기 위한 일반적인 기술이다. 그러나 군집화는 항상 손실이 발생하여 검색 품질을 저하시킨다. 따라서 이 논문에서는 Embedding 군집화와 중요한 용어들이 함께 작동하여 밀집 검색을 가속화하는 Hybrid Inverted Index (HI2)를 제안한다."
    
    2. "우리는 효율성과 효과적인 사용을 동시에 달성하기 위해 HI2를 구축하기 위해 군집 선별자와 용어 선택자를 개발한다. 또한 간단한 비지도 학습 알고리즘과 엔드 투 엔드 지식 전달 기법을 활용하여 이 두 모듈을 학습시키며, 후자는 효과성을 한층 향상시킨다."
    
    3. "인기 있는 검색 기준에 대한 포괄적인 실험을 기반으로 HI2가 군집과 용어가 서로 보완함을 확인하며 다양한 인덱스 설정에서 손실이 없는 검색 품질과 경쟁력 있는 효율성을 달성한다."

###### ChatGPT to Replace Crowdsourcing of Paraphrases for Intent Classification: Higher Diversity and Comparable Model Robustness (https://aclanthology.org/2023.emnlp-main.117/)
- Anthology ID: 2023.emnlp-main.117 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델의 등장은 크라우드 소싱에 어떤 영향을 미칠까? 
    2. 이 연구에서는 ChatGPT와 Falcon-40B를 사용하여 의도 분류를 위한 유사질문 생성 작업을 수행하고, ChatGPT가 생성한 유사질문이 더 다양하며 더 견고한 모델을 만들 수 있다는 것을 보여준다.

###### Query-as-context Pre-training for Dense Passage Retrieval (https://aclanthology.org/2023.emnlp-main.118/)
- Anthology ID: 2023.emnlp-main.118 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에는 컨텍스트-지도된 사전 훈련을 사용하여 밀집된 패스리트리벌의 성능을 향상시키기 위한 방법들이 개발되고 있다. 그러나 이러한 방법은 약하게 상관된 다른 두 패스지를 관련이 있다고 간주하며 약한 상관 관계의 부정적인 영향을 고려하지 않는다.
    2. 따라서 이 논문은 이 문제를 완화하기 위한 간단하고 효과적인 사전 훈련 기술인 query-as-context 사전 훈련을 제안한다. query-as-context 사전 훈련은 패스지에서 파생된 쿼리가 해당 패스지와 더 관련이 있을 가능성이 높다고 가정하고 패스지-쿼리 쌍을 형성한다.
    3. 이와 같은 치환 또는 생성적 컨텍스트-지도된 사전 훈련에서 사용된 사전 훈련 모델은 대규모 패스리트리벌 벤치마크 및 도메인 밖의 제로샷 벤치마크에서 평가되었다. 실험 결과, query-as-context 사전 훈련을 통해 검색 성능이 상당히 향상되었으며 그 효과와 효율성을 입증하였다.

###### A Suite of Generative Tasks for Multi-Level Multimodal Webpage Understanding (https://aclanthology.org/2023.emnlp-main.119/)
- Anthology ID: 2023.emnlp-main.119 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 웹페이지는 비전-언어 및 언어 과제에 대한 풍부하고 확장 가능한 자원이지만, 기존 데이터셋에서는 이미지-캡션 쌍, 긴 텍스트 기사 또는 원시 HTML과 같은 일부분만 보관되어 왔다. 이로 인해 웹페이지 과제는 별로 주목받지 못했으며, 구조화된 이미지-텍스트 데이터는 잘 활용되지 않았다.
    2. 우리는 다중 모달 웹페이지 이해를 연구하기 위해 Wikipedia Webpage Suite (WikiWeb2M)를 소개한다. 이 데이터셋은 이미지, 텍스트 및 구조 데이터를 모두 갖춘 2백만 개의 웹페이지를 포함하고 있다.
    3. 우리는 페이지 설명 생성, 섹션 요약 및 문맥적 이미지 캡션 등 세 가지 생성 작업에서 유용성을 검증하였다. 또한, 페이지 구조를 사용하여 가장 관련성이 높은 이미지와 텍스트 콘텐츠를 글로벌 토큰으로 선택하고 나머지 웹페이지에 대해 문맥적으로 주의를 기울이기 위한 새로운 어텐션 메커니즘인 Prefix Global을 설계했다.
    
    In addition, Please translate the keywords (in English) to Korean.
    1. automatic generation, Multiple Choice Questions (MCQ), evaluation metrics, BLEU, ROUGE, METEOR, target fact, knowledge, human survey
    2. deep models, NLP tasks, robustness, contrastive learning, counterfactual augmentation, augmentation, dataset, spurious patterns, causality, task model bias, generalization, scarce data
    3. Webpages, vision-language, language only tasks, image-caption pairs, long text articles, raw HTML, multimodal, webpage understanding, Wikipedia Webpage suite, page description generation, section summarization, contextual image captioning, attention mechanism, computational complexity, task performance

###### Democratizing Reasoning Ability: Tailored Learning from Large Language Model (https://aclanthology.org/2023.emnlp-main.120/)
- Anthology ID: 2023.emnlp-main.120 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델(Large language models, LLMs)은 탁월한 문장 처리 능력을 가지지만, 계산 요구량과 소스 코드의 닫힌 성격 때문에 민주화가 방해되고 있다. 
    2. 이 논문에서는 더 도전적인 추론 능력을 작은 언어 모델에 축소시키기 위한 학습 방법을 제안한다.
    3. 학습자의 학습 상태에 맞게 적응하는 다중 라운드 학습 패러다임과 함께 자기 반성 학습, LLM의 추론 역량을 활용하여 명확한 추론 능력을 더 효과적으로 도출할 수 있다는 결과가 실험과 분석을 통해 입증되었다.

###### OpenAsp: A Benchmark for Multi-document Open Aspect-based Summarization (https://aclanthology.org/2023.emnlp-main.121/)
- Anthology ID: 2023.emnlp-main.121 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 자동 요약 모델의 성능은 크게 향상되었지만, 실제 사용자의 특정 정보 요구를 충족시키는 데는 여전히 한계가 있다. 특히 본 논문에서는 유용한 측면 중심의 요약 설정에 중점을 두어 원하는 대상 요약을 제공하기 위한 연구가 필요하다.
    2. 현재의 데이터셋과 연구는 주로 사전 정의된 몇 가지 측면에만 집중하거나 단일 문서 입력에만 초점을 맞추거나, 합성 데이터에 의존하고 있다.
    3. 더 현실적인 시나리오에 대한 연구를 진전시키기 위해, 우리는 OpenAsp라는 다중 문서 개방형 측면 중심의 요약을 위한 벤치마크를 소개한다. 이 벤치마크는 새로운 비용 효과적인 어노테이션 프로토콜을 사용하여 기존의 일반적인 다중 문서 요약 데이터셋으로부터 개방형 측면 데이터셋을 유도한다.

###### PEFTDebias : Capturing debiasing information using PEFTs (https://aclanthology.org/2023.emnlp-main.122/)
- Anthology ID: 2023.emnlp-main.122 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 foundation 모델의 증가는 pretraining 중 발생하는 묵시적 편견을 해결해야 하는 시급한 필요성을 강조하고 있다. 
    2. 본 논문에서는 Parameter-Efficient Fine-tuning (PEFT)을 사용하여 foundation 모델 내의 편견을 완화하는 PEFTDebias라는 새로운 접근 방법을 소개한다.
    3. gender와 race라는 두 가지 편견 축을 가진 4개의 데이터셋에서 평가를 실시한 결과, PEFT를 통해 downstream 편향을 효과적으로 감소시킬 수 있음을 발견하였다.

###### Byte Pair Encoding for Symbolic Music (https://aclanthology.org/2023.emnlp-main.123/)
- Anthology ID: 2023.emnlp-main.123 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 딥러닝과 함께 사용되는 기호 음악 모드는 대부분 언어 모델 아키텍처와 결합된다. 하지만 음악은 여러 속성을 가진 동시에 일어나는 음표들로 구성되기 때문에 이를 토큰화해야 한다. 기존의 토큰화 방법은 작은 어휘를 가진 토큰들로 음표 속성과 시간 이벤트를 설명하기 때문에 토큰 시퀀스가 상대적으로 길고 언어 모델의 임베딩 공간을 효율적으로 사용하지 못하는 문제가 있다.
    2. 이 논문에서는 자연어 처리에서 널리 사용되는 압축 기술인 Byte Pair Encoding (BPE)를 사용하여 토큰 시퀀스의 길이를 크게 줄이고 어휘 크기를 증가시킴으로써 더 표현력 있는 토큰으로 언어 모델의 임베딩 기능을 활용할 수 있게 했다. 이를 통해 생성 및 분류 작업에서 더 나은 결과와 더 빠른 추론이 가능해졌다.
    3. Byte Pair Encoding은 [Github](https://github.com/Natooz/bpe-symbolic-music)에서 공유된 소스 코드와 함께 [companion website](https://Natooz.github.io/BPE-Symbolic-Music)로 구현되어 있으며, [MidiTok](https://github.com/Natooz/MidiTok)에서 BPE를 직접 구현함으로써 독자들은 이 방법을 쉽게 활용할 수 있다.

###### Combining Denoising Autoencoders with Contrastive Learning to fine-tune Transformer Models (https://aclanthology.org/2023.emnlp-main.124/)
- Anthology ID: 2023.emnlp-main.124 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 자연어처리(NLP) 분야에서 큰 사전 훈련을 한 Transformer 모델을 전이학습에 사용하는 것이 주목받고 있으며, 이에 따라 프롬프트 기반, 어댑터 및 비지도 학습 방법과의 결합 등 다양한 전망이 등장하고 있다.
    2. 본 논문에서는 분류 작업을 위해 기본 모델을 조정하기 위한 3 단계 기법을 제안한다. 먼저 잡음 제거 오토 인코더(DAE)를 사용하여 모델의 신호를 데이터 분포에 맞게 조정하고, 그 다음 대조학습(CL) 방법에 의해 출력의 표현 공간을 해당 클래스에 맞게 조정한다.
    3. 또한, 균형이 맞지 않는 데이터셋을 보정하기 위해 지도 대조학습을 위한 새로운 데이터 증강 방법을 도입한다. 마지막으로, 사전 정의된 범주를 제한하기 위해 fine-tuning을 적용한다. 이러한 다른 단계는 모델이 최종 작업을 학습하는 데 유용하고 상보적인 지식을 제공한다. 실험 결과와 기법들과의 비교를 통해 이러한 주장을 입증한다.

###### Self-Influence Guided Data Reweighting for Language Model Pre-training (https://aclanthology.org/2023.emnlp-main.125/)
- Anthology ID: 2023.emnlp-main.125 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 텍스트 코퍼스에서 셀프-슈퍼바이전을 통해 사전 훈련 된 언어 모델들이 여러 NLP 태스크에 대한 모델 개발의 기본이 되었다. 그러나, 데이터의 상관성과 품질에 따라, 모든 데이터 샘플에 동일한 중요성을 부여하는 것이 최적의 선택이 아닐 수 있다. 
    2. 이 논문에서는 사전 훈련 데이터에 대한 모델 기반의 가중치 조정을 고려하지 않고, 태스크에 특화된 지도 학습과 LM fine-tuning에서만 가중치 재조정이 탐색되었다. 
    3. 우리는 이 중요한 부분을 채우기 위해, self-influence (SI) 점수를 사용하여 샘플의 중요성과 사전 훈련에 대한 정보를 고려하여 샘플을 공동으로 재조정하는 PRESENCE라는 방법을 제안한다.

###### ACTOR: Active Learning with Annotator-specific Classification Heads to Embrace Human Label Variation (https://aclanthology.org/2023.emnlp-main.126/)
- Anthology ID: 2023.emnlp-main.126 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 일반적으로 다수결로 레이블을 통합하는 것이 레이블 정보 분석에 많이 사용되지만, 이는 소수의 의견을 배려하지 못한다. 
    2. 최근의 연구에서는 단일 레이블 대신 개별 어노테이션으로부터 학습하는 것이 성능이 더 좋다는 것이 밝혀졌지만, 이는 많은 양의 어노테이션이 필요하다. 
    3. 본 논문에서는 경황학습 (active learning) 환경에서 여러 머리 (multi-head) 모델이 확실성 추정 측면에서 단일 머리 모델보다 훨씬 우수한 성능을 보인다. 또한, 두 개의 데이터셋에서 annotator별 머리를 사용하여 획득 함수를 설계하고 평가함으로써 그룹 수준 엔트로피 방법이 두 데이터셋 모두에 대해 일반적으로 잘 작동하며, 억제 시간 70%를 절약하면서 예측과 확실성 추정에 있어서 충분한 성능을 달성한다는 것을 보여준다.

###### TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models (https://aclanthology.org/2023.emnlp-main.127/)
- Anthology ID: 2023.emnlp-main.127 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어추론(NLI) 모델을 사용한 사실적 일관성 평가는 종종 실망스러운 성과를 보임. 기존 연구는 합성 트레이닝 데이터로 이 모델의 성능을 개선했지만, 이 데이터는 실제로 생성된 모델의 요약문과 특성이 다르며 가능한 사실적 오류의 범위가 제한적임. 
    2. 이 연구에서는 TrueTeacher라는 방법을 소개하는데, 이는 다양한 모델 생성 요약문을 대규모 언어 모델을 사용하여 주석을 달아 합성 데이터를 생성함. TrueTeacher는 기존 연구와 달리 인간이 작성한 요약문에 의존하지 않으며, 자연스럽게 다국어를 다룸.
    3. TRUE 벤치마크 실험 결과, TrueTeacher로 훈련된 학생 모델은 동등한 용량의 최신 모델과 LLM 트리처보다 현저히 우수한 성능을 보임. 도메인 이동에 대한 통일성과 우수성을 비교한 체계적인 연구를 통해, TrueTeacher의 우수성 및 견고성을 입증하며, 이 방법이 다국어 시나리오에도 일반화됨을 보임. 마지막으로, 이 데이터로 훈련한 체크포인트와 함께 TrueTeacher로 생성한 대규모 합성 데이터셋(1.4M 개의 예제)을 공개함.

###### VivesDebate-Speech: A Corpus of Spoken Argumentation to Leverage Audio Features for Argument Mining (https://aclanthology.org/2023.emnlp-main.128/)
- Anthology ID: 2023.emnlp-main.128 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. VivesDebate-Speech는 논쟁 추정과제에 오디오 기능을 활용하기 위해 생성된 말하기 논쟁의 말뭉치(VivesDebate-Speech)로, 이 논문은 이러한 말뭉치의 생성이 말하기 처리와 논쟁 추정 커뮤니티의 교차점에 중요한 기여이며 이 주제에서 가장 완전한 공개 자료 중 하나라고 설명한다.
    2. 또한, 우리는 오디오 기능을 논쟁 추정 pipeline에 통합할 때 개선이 나타나는 기존에 없던 실험들을 수행하였다.
    3. 제공된 결과는 향후 연구에 대한 기준선으로 활용될 수 있다.

###### Tagging-Assisted Generation Model with Encoder and Decoder Supervision for Aspect Sentiment Triplet Extraction (https://aclanthology.org/2023.emnlp-main.129/)
- Anthology ID: 2023.emnlp-main.129 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. ASTE (Aspect Sentiment Triplet Extraction)는 최근 주목을 받고 있으며, 이 테스크를 위한 최근 연구들은 대부분 자연어 생성 기반(NLG) 접근법에 의해 이루어졌다. 
    2. 하지만 대부분의 NLG 방법은 인코더-디코더의 숨겨진 표현을 감독하지 않는다는 문제가 있으며, 라벨이 제공하는 의미 정보를 완전히 활용하지 못하여 암묵적인 측면과 의견을 추출하는 데 어려움을 겪는다. 
    3. 이러한 도전에 대응하기 위해, 우리는 다중 관점 태깅 보조 생성 모델 (TAGS)을 제안한다. TAGS는 다중 관점 태깅 보조와 라벨 의미 표현을 통해 인코더와 디코더의 감독을 강화한다. TAGS는 추가적인 시퀀스 태깅 작업을 통해 인코더가 트리플렛의 단어를 구분할 수 있는 능력을 향상시키며, 시퀀스 태깅 확률을 활용하여 디코더를 안내함으로써 생성된 내용의 품질을 개선한다. 또한, TAGS는 라벨의 의미 표현을 얻기 위해 자체 디코딩 과정을 사용하고 이러한 의미 표현과 디코더의 숨겨진 상태를 정렬하여 디코더의 숨겨진 상태에 대한 강화된 의미 감독을 달성한다. 다양한 공개 벤치마크에서의 실험 결과는 TAGS가 최고의 성능을 달성한다는 것을 보여준다.

###### Larger Probes Tell a Different Story: Extending Psycholinguistic Datasets Via In-Context Learning (https://aclanthology.org/2023.emnlp-main.130/)
- Anthology ID: 2023.emnlp-main.130 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Language model probing은 모델의 특정 능력을 테스트하기 위해 종종 사용되지만, 작고 통계적으로 유의미한 파워가 부족한 probing 벤치마크를 사용할 때 결론이 제한될 수 있다.
    2. 이 논문에서는 심리언어학적 연구에서 영감을 받아 negation(NEM-1500-SIMP)과 role reversal (ROLE-1500)을 위한 새로운 대규모 데이터셋을 소개한다.
    3. 작은 벤치마크에 비해 GPT3를 사용하여 기존 NEG-136와 ROLE-88 벤치마크를 크게 확장하고, 모델의 성능이 원래의 작은 벤치마크와 비교하여 20-57% 감소하는 것을 관찰한다.

###### Norm of Word Embedding Encodes Information Gain (https://aclanthology.org/2023.emnlp-main.131/)
- Anthology ID: 2023.emnlp-main.131 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 단어의 분산 표현은 어휘 의미 정보를 인코딩하지만, 어떤 종류의 정보를 인코딩하고 어떻게 인코딩되는지는 어떤가요? 
    2. 우리는 skip-gram with negative-sampling 방법에 주목하여, 정적 단어 임베딩의 제곱 노름이 단어가 전달하는 정보 획득량을 인코딩한다는 것을 발견했습니다. 
    3. 이론적 프레임워크와 실험을 통해 우리의 결과를 확인하고, 단어 빈도에서 생기는 잘못된 상관관계를 제거하는 정확한 실험을 통해 결과를 확인하였습니다.

###### CRT-QA: A Dataset of Complex Reasoning Question Answering over Tabular Data (https://aclanthology.org/2023.emnlp-main.132/)
- Anthology ID: 2023.emnlp-main.132 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 대형 언어 모델은 텍스트 기반 작업에서 강력한 추론 능력을 보여주지만, 구조화된 데이터인 테이블에 대한 추론 능력은 체계적으로 탐구되지 않았다. 
    2. 이 논문에서는 테이블 데이터 분석을 위한 추론 및 작업 유형에 대한 포괄적인 분류 체계를 제안한다.
    3. 또한, 테이블에 대한 복잡한 추론 QA 데이터셋인 CRT-QA 데이터셋을 구축하여, LLM의 추론 능력을 철저히 탐구할 수 있도록 하였다.

###### Promoting Topic Coherence and Inter-Document Consorts in Multi-Document Summarization via Simplicial Complex and Sheaf Graph (https://aclanthology.org/2023.emnlp-main.133/)
- Anthology ID: 2023.emnlp-main.133 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다중 문서 요약(MDS)은 다수의 소스 문서로부터 정보를 압축하여 간결한 요약을 만들어내는 작업을 의미한다. 그러나 기존 시스템들은 인코딩 중 토큰 길이에 제한을 두거나, 다중 문서 간의 복잡한 관계를 제대로 포착하지 못하는 등의 한계점을 가지고 있다. 이러한 제한사항은 요약물이 사실적이지 않고 충실하지 않은 경우를 만들며, 독자들에게 일부 주제에 대한 부당한 이해를 제공할 수 있다.
    2. 이 논문에서는 FIBER라는 새로운 인코더-디코더 모델을 제안하는데, 이 모델은 사전 훈련된 BART를 사용하여 언어적 뉘앙스를 포괄적으로 분석하고, 단순한 복합체 복잡 계층을 사용하여 짝별 관계를 초월하는 고유한 속성을 이해하며, 시프 그래프 어텐션을 사용하여 이질 속성을 효과적으로 포착한다.
    3. FIBER는 Multinews, CQASumm, DUC, Opinosis와 같은 네 가지 평가 데이터셋에서 열 한 가지 기준선과 비교하여 일관된 성능 향상을 보여주며, 구문적, 의미적 및 충실성 평가 척도를 통해 이러한 개선 사항을 보다 정확하게 입증하였다.

###### MAGNIFICo: Evaluating the In-Context Learning Ability of Large Language Models to Generalize to Novel Interpretations (https://aclanthology.org/2023.emnlp-main.134/)
- Anthology ID: 2023.emnlp-main.134 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인간은 언어 표현에 새로운 해석을 부여하여 새로운 단어를 학습하고 커뮤니티 특정 용례를 이해하는 능력을 가지고 있지만, 대형 언어 모델 (LLM)은 학습 가능한 한계를 가지고 있으며 반복적인 학습은 비용이 많이 든다. 따라서 LLM이 맥락에서 새로운 해석을 배울 수 있도록 하는 것이 중요하다.
    2. 이 논문에서는 실제 세계의 복잡성을 시뮬레이션하기 위해 다양한 토큰 및 프롬프트 설정을 포함한 텍스트-투-SQL 의미 분석 프레임워크 내에서 구현된 평가 툴 MAGNIFICo를 소개한다.
    3. MAGNIFICo에서의 실험 결과는 LLM이 자연어 설명과 긴 대화 내에서 새로운 해석을 이해하는 능력이 놀랄 정도로 강력하다는 것을 보여주지만, 불쾌한 단어 해석이나 동시에 여러 새로운 해석을 동일한 예제에서 구성하는데 있어서 추가적인 개선이 필요함을 강조한다. 또한, 우리의 분석에서 LLM의 의미적 편향을 규명하고 긴 맥락에서 제시된 정보에 대한 최근성 편향의 영향을 밝힌다.

###### Generating and Evaluating Tests for K-12 Students with Language Model Simulations: A Case Study on Sentence Reading Efficiency (https://aclanthology.org/2023.emnlp-main.135/)
- Anthology ID: 2023.emnlp-main.135 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 교육용 시험지를 작성하고 학생들의 응답을 수집하여 평가하는 것은 비용과 시간이 많이 드는 작업이다. 본 연구에서는 이전 학생들의 응답을 시뮬레이션하기 위해 큰 언어 모델을 fine-tuning 하는 방법을 제안하고, 이를 통해 시험 문항의 난이도와 모호성을 추정할 수 있다.
    2. 우리는 GPT-4를 사용하여 전문가가 개발한 규칙을 따라 새로운 시험 문항을 생성하고, 심리학적 측정 기준에 따라 fine-tuned 언어 모델을 사용하여 문항을 필터링하는 방법을 제안한다.
    3. 실험 결과, 생성된 시험지의 평가 결과가 인간 전문가가 작성하고 수천 명의 학생을 대상으로 평가된 표준 시험지와 높은 상관관계를 가짐을 확인하였다.

###### Counter Turing Test (CT2): AI-Generated Text Detection is Not as Easy as You May Think - Introducing AI Detectability Index (ADI) (https://aclanthology.org/2023.emnlp-main.136/)
- Anthology ID: 2023.emnlp-main.136 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. ChatGPT의 등장으로 AI 생성 텍스트의 위험과 결과가 심각해졌다. 이에 수천 명의 연구원과 기술 리더로부터 서명된 2023년 3월의 편지를 시작으로, GPT-4보다 더 세련된 AI 시스템의 훈련에 6개월 동안 중단을 요구하는 사태가 일어났다. 또한 미국 저작권국은 "머신이 생산한 내용이 전통적인 작성 요소라면 그 작품은 인간의 저작이 아니므로 저작권 등록 대상이 아니다"라고 발표했다. 
    2. 이 논문에서는 AI 생성 텍스트 감지(AGTD)에 초점을 맞추어 기존 AGTD 기술의 견고성을 평가하는 테스트인 CT2를 소개한다. 우리의 경험적 결과는 제안된 AGTD 방법의 취약성을 명확하게 보여준다. 또한 LLMs의 감지 가능성 레벨을 평가하고 순위를 매기기 위한 AI 감지 가능성 지수 (ADI)를 제안한다.
    3. 15가지의 현대적인 LLMs를 철저히 조사한 결과, 더 큰 LLMs일수록 작은 LLMs와 비교하여 감지 가능성이 낮아진다는 것을 입증하였다. 우리는 ADI가 NLP 커뮤니티에게 큰 가치를 가지고 있으며, AI 관련 정책 결정에 대한 평가 지표로 사용될 수 있는 잠재력을 가지고 있다고 단언한다.

###### Revisiting the Optimality of Word Lengths (https://aclanthology.org/2023.emnlp-main.137/)
- Anthology ID: 2023.emnlp-main.137 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Zipf (1935)은 단어형태가 의사소통 비용을 최소화하도록 최적화된다고 주장했습니다. 이 논문에서는 Piantadosi et al. (2011)의 가설과 비교하여, 단어의 길이가 기대값과 분산-평균비율에 비례해야 한다는 새로운 가설을 제안합니다.
    2. 실험 결과, 13개 언어와 여러 실험 설정에서 단어의 길이가 주어진 가설들을 예측하는 데 있어 빈도수 가설이 더 좋은 결과를 보였습니다.
    3. 이 결과는 Zipf의 가설이 여전히 옳다는 증거로 받아들일 수 있다고 설명합니다.

###### Document-level Relationship Extraction by Bidirectional Constraints of Beta Rules (https://aclanthology.org/2023.emnlp-main.138/)
- Anthology ID: 2023.emnlp-main.138 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 문서 수준 관계 추출(DocRE)은 문서 내 entity pair 사이의 관계를 추출하는 것을 목표로 한다. 그러나 기존의 DocRE 모델에서 불명확성과 약한 논리문제를 해결하기 위해 도입된 몇몇 작업들은 forward logic 제약에만 초점을 두고 있고, 이러한 작업에서 채굴된 규칙들은 표준 신뢰도는 높지만 서포트는 낮은 pseudo rule에 가장 많은 영향을 받는다.
    2. 이 논문에서는 새로운 logic 제약 프레임워크인 BCBR을 제안한다. BCBR은 우선 베타 기여에 의해 규칙을 모델링하는 새로운 규칙 마이너를 도입한다. 그런 다음 베타 규칙을 기반으로 forward와 reverse logic 제약을 구축한다. 마지막으로 BCBR은 양방향 제약에 의해 규칙 일관성 손실을 재구성하여 DocRE 모델의 출력을 조절한다.
    3. 실험 결과, BCBR은 관계 추출 성능 (~2.7 F1 점수) 및 논리적 일관성 (~3.1 논리 점수) 측면에서 기존의 DocRE 모델들보다 우수한 성능을 보여주며, 또한 BCBR은 두 가지 다른 logic 제약 프레임워크들보다 꾸준히 우수한 성능을 보여준다.

###### Instructed Language Models with Retrievers Are Powerful Entity Linkers (https://aclanthology.org/2023.emnlp-main.139/)
- Anthology ID: 2023.emnlp-main.139 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 큰 언어 모델(Large Language Model, LLM)에 기반한 생성적인 방법은 복잡한 추론 능력이 필요한 작업에서 급발진한 능력을 보여주지만, 생성적인 특성으로 인해 생성된 내용은 환영에 시달리기 때문에 entity linking과 같은 entity-centric 작업에는 적합하지 않다.
    2. 우리는 Instructed Generative Entity Linker (INSGENEL)이라는 접근법을 제안하여 언어 모델이 지식 베이스 상에서 entity linking 작업을 수행할 수 있도록 한다. 이를 위해 (i) instruction-tuning을 통한 sequence-to-sequence 학습 목표를 갖춘 EL, (ii) 경량의 잠재적 명칭 탐색기를 기반으로 한 신규 생성적 EL 프레임워크 등 다양한 방법을 제안한다.
    3. INSGENEL은 이전의 생성적 대안보다 평균 +6.8 F1 포인트의 성능 향상을 보이며, 훈련 데이터 효율성과 훈련 계산 비용에서도 큰 이점을 가진다. 또한, 우리가 공들여 개발한 in-context learning (ICL) 프레임워크는 여전히 INSGENEL에 비해 크게 뒤쳐지므로, entity linking 작업은 일반적인 LLM에게 직면한 지속적인 어려움임을 확인할 수 있다.

###### Towards Noise-Tolerant Speech-Referring Video Object Segmentation: Bridging Speech and Text (https://aclanthology.org/2023.emnlp-main.140/)
- Anthology ID: 2023.emnlp-main.140 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. HCI에서는 언어적 소통이 주로 이루어지는데, 소리 (말 언어) 는 소음과 악센트로 인해 텍스트와 비교해 모호할 수 있기 때문에 차이가 있다. 2. 본 연구에서는 의미적으로 세밀한 정의가 필요한 HCI 작업인 R-VOS (Referring Video Object Segmentation) 을 연구했습니다. 3. 기존 텍스트 입력 기반 모델을 활용하여 소음이 있는 음성 입력을 효과적으로 처리할 수 있는 방법을 제안하고, 실험 결과에서 우수한 성능을 보였습니다.

###### PROSE: A Pronoun Omission Solution for Chinese-English Spoken Language Translation (https://aclanthology.org/2023.emnlp-main.141/)
- Anthology ID: 2023.emnlp-main.141 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Neural Machine Translation(NMT) 시스템은 pro-drop(의미적으로 수식어 생략 가능한) 언어(예: 중국어)를 non-pro-drop 언어(예: 영어)로 번역할 때, 생략된 대명사를 복원해야 하는 독특하고 중요한 작업이지만, 어느 정도 충분한 벤치마크 데이터셋이 없다. 따라서, 우리는 다양한 pro-drop 사례를 포함한 새로운 벤치마크인 PROSE를 소개한다."
    2. "또한, 우리는 이 데이터셋에서 중국어에서 pro-drop 현상에 대해 철저한 조사를 진행하여, pro-drop이 중국어-영어 번역에서 NMT 시스템의 성능을 낮춘다는 것을 다시 확인한다. pro-drop이 도입하는 부정적인 영향을 줄이기 위해, 우리는 생략된 대명사의 의미 임베딩을 활용한 새로운 접근 방식인 Mention-Aware Semantic Augmentation을 제안한다."
    3. "4개의 중국어-영어 번역 코퍼스에서 실시한 실험 결과, 우리의 제안한 방법은 생략된 대명사 검색과 전체 번역 품질 측면에서 기존 방법들보다 우수한 성능을 보였다."

###### A Diachronic Analysis of Paradigm Shifts in NLP Research: When, How, and Why? (https://aclanthology.org/2023.emnlp-main.142/)
- Anthology ID: 2023.emnlp-main.142 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "과학 분야의 기본 개념과 트렌드를 이해하는 것은 지속적인 발전과 핵심이다. 이 연구에서는 인과적 발견과 추론 기술을 사용하여 과학 분야의 연구 주제의 진화를 분석하기 위한 체계적인 프레임워크를 제안한다."
    2. "우리는 NLP 분야 내에서 연구 주제의 진화의 다양한 측면을 포괄하는 세 가지 변수를 정의하고 관찰 데이터를 사용하여 이러한 변수들 사이의 인과 관계를 해명하기 위한 인과적 발견 알고리즘을 활용한다."
    3. "ACL Anthology corpus에서의 실험을 통해 우리의 프레임워크가 다양한 NLP 연구 주제에 대한 진화적 동향과 근본적인 원인을 효과적으로 밝혀내었음을 보여준다. 특히, 과업과 방법이 NLP 연구의 주된 원동력이며, 데이터셋은 그 다음이고, 평가 지표는 최소한의 영향을 미친다."

###### Does the Correctness of Factual Knowledge Matter for Factual Knowledge-Enhanced Pre-trained Language Models? (https://aclanthology.org/2023.emnlp-main.143/)
- Anthology ID: 2023.emnlp-main.143 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 연구에서는 이전에 학습한 언어 모델의 성능에 실제 지식을 주입하는 것이 하류 작업 성능과 매우 강한 양의 상관 관계를 가지고 있다는 것을 보였다.
    2. 하지만 기존 연구들은 주입된 지식이 언어 모델이 성공적으로 학습하고 하류 작업 성능 향상과의 인과 관계를 증명하지 못했다.
    3. 이 논문에서는 인과 관계 파악을 위해 counterfactual 기반의 분석 프레임워크를 제시하고, 다양한 규모에서 실제 지식 소스를 변형하여 이전과 이후의 언어 모델 성능을 비교함으로써 이 문제를 분석한다.

###### Syntactic Substitutability as Unsupervised Dependency Syntax (https://aclanthology.org/2023.emnlp-main.144/)
- Anthology ID: 2023.emnlp-main.144 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 논문에서는 반복 프로세스의 구조를 해석하는 방법을 설명한다.
    2. 어절들의 의미적 변환이 가능하다는 사실을 이용하여, 분석하기 위한 구문을 정의한다.
    3. 이러한 방법을 이용하면, 자연어 처리 작업에서 파싱 정확도가 향상되며 다른 파싱 설정으로의 전이성을 보인다.

###### MProto: Multi-Prototype Network with Denoised Optimal Transport for Distantly Supervised Named Entity Recognition (https://aclanthology.org/2023.emnlp-main.145/)
- Anthology ID: 2023.emnlp-main.145 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. DS-NER (Distantly Supervised Named Entity Recognition)은 지식 베이스나 가제터와 무라벨링 된 말뭉치만 가지고 개체 명칭과 그 타입을 인식하는 것을 목표로 한다. 그러나 먼 거리에서의 주석은 노이즈가 많아져 NER 모델의 성능을 저하시킨다. 
    2. 본 논문에서는 DS-NER 작업을 위한 노이즈에 강건한 프로토타입 네트워크인 MProto를 제안한다. MProto는 이전의 프로토타입 기반 NER 방법과 다르게 각 entity 유형을 여러 프로토타입으로 표현하여 entity 표현 사이의 내부 클래스 분산을 특색 짓는다. 
    3. 실험 결과, MProto 모델은 여러 DS-NER 벤치마크에서 최고 성능을 보여주고 있다.

###### The Shifted and The Overlooked: A Task-oriented Investigation of User-GPT Interactions (https://aclanthology.org/2023.emnlp-main.146/)
- Anthology ID: 2023.emnlp-main.146 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 대용량 언어 모델의 발전은 다양한 NLP 태스크에서 놀라운 성과를 보이고 있다. 그러나 NLP 연구의 집중점이 실제 사용자의 요구를 정확하게 반영하는지 여부는 여전히 불분명하다. 
    2. 이 논문은 대규모 사용자-GPT 대화 기록을 통해 NLP 연구와 실제 NLP 응용의 요구 사항 사이의 격차를 철저히 분석한다. 
    3. 우리는 사용자들이 LLMs에게 자주 요청하는 작업과 학술적 연구에서 일반적으로 연구되는 작업 사이에 상당한 차이를 발견하고, 사용자 요청 작업인 "design"과 "planning"과 같은 작업이 전통적인 NLP 벤치마크에서는 주로 무시되거나 다른 것임을 보여준다. 그리고 이러한 간과된 작업을 조사하고 실제적인 도전 과제를 분석하여 사용자 요구에 더욱 맞추기 위한 로드맵을 제시한다.

###### Learning the Visualness of Text Using Large Vision-Language Models (https://aclanthology.org/2023.emnlp-main.147/)
- Anthology ID: 2023.emnlp-main.147 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 시각적 텍스트는 사람의 머릿속에 이미지를 떠올리게 하지만 시각적이지 않은 텍스트는 그렇지 못하다. 텍스트의 시각성을 자동으로 감지하는 방법은 텍스트-이미지 검색 및 생성 모델에서 관련 이미지와 함께 텍스트를 보완하는 데 도움이 될 수 있다.
    2. 긴 형식의 텍스트에서 시각성을 정확히 감지하는 것은 어려운 작업인데, 이 논문에서는 큰 비전-언어 모델인 CLIP을 fine-tuning하여 시각적이 아닌 텍스트를 NULL 이미지에 매핑하고, 시각적인 텍스트는 해당 문서에서의 대응 이미지와 일치하도록 모델의 목표를 수정하는 전략을 제안한다.
    3. 실험적 평가 결과, 이 방법은 제안된 작업에 대해 여러 가지 휴리스틱 및 기준 모델보다 더 좋은 성능을 보여주며, 텍스트의 시각성 모델링의 중요성을 강조하기 위해 DALL-E와 같은 텍스트-이미지 생성 시스템의 정성적 분석을 수행한다.

###### The Past, Present and Better Future of Feedback Learning in Large Language Models for Subjective Human Preferences and Values (https://aclanthology.org/2023.emnlp-main.148/)
- Anthology ID: 2023.emnlp-main.148 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 큰 언어 모델(Large Language Models, LLMs)의 행동을 조절하기 위해 인간의 피드백이 점점 더 사용되고 있으나, 특히 매우 주관적인 인간의 선호도와 가치를 고려하여 피드백을 효율적이고 효과적이며 편향되지 않게 수집하고 통합하는 방법은 여전히 불명확하다.
    2. 이 논문은 인간의 피드백을 학습에 활용하기 위해 기존 접근 방식들을 조사하였으며, 인간의 피드백을 언어 모델에 통합하는 과거 동향, 현재 기술 및 실천 방법, 피드백을 사용하는 동기, 가치와 선호도를 정의하는 개념적 프레임워크, 그리고 피드백을 수집하는 방법과 수집 대상에 대한 개요를 제시한다.
    3. 마지막으로, 개념적 및 실질적으로 해결되지 않은 다섯 가지 도전과제를 제기함으로써 언어 모델의 피드백 학습에 대한 미래를 개선하고자 한다.

###### TempTabQA: Temporal Question Answering for Semi-Structured Tables (https://aclanthology.org/2023.emnlp-main.149/)
- Anthology ID: 2023.emnlp-main.149 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 비구조적인 데이터인 Infobox 테이블은 흔히 암묵적이거나 명시적인 형태로 entity에 대한 시간 정보를 포함하고 있다. 이런 정보를 NLP 시스템이 추론할 수 있는가? 
    2. 이 연구에서는 시간에 관한 질문-답변을 Infobox 테이블에서 수행하는 과제를 제안한다. 
    3. TEMPTABQA 데이터셋은 90개 이상의 도메인에 걸친 1,208개의 Wikipedia Infobox 테이블에서 추출된 11,454개의 질문-답변 쌍으로 구성되어 있으며, 이를 사용하여 시간적 추론 능력을 평가한다.

###### Task-Level Thinking Steps Help Large Language Models for Challenging Classification Task (https://aclanthology.org/2023.emnlp-main.150/)
- Anthology ID: 2023.emnlp-main.150 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화 생성, 상식 추론 및 질문 응답과 같은 여러 작업에서 대형 언어 모델 (LLM)의 성능이 뛰어남을 보였지만, 일부 어려운 분류 작업에서만큼이나 작업에서 보여주는 경향이 성능에 큰 영향을 줄 수 있다. 
    2. 이 논문에서는 몇 가지 시연을 통해 LLM을 downstream 작업에 적응시키기 위한 중요한 개념인 task-level thinking steps를 제안한다. 
    3. 또한, 혼란스러운 클래스를 구별할 수 있도록 LLM이 진화할 수 있는 progressive revision framework를 설계하여 thinking steps를 개선한다. 전문가들에 의해 레이블링된 적은 양의 데이터셋에서도 최고의 성능을 달성하는 우리의 제안된 방법의 우수성을 실험적으로 검증하였다.

###### RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation (https://aclanthology.org/2023.emnlp-main.151/)
- Anthology ID: 2023.emnlp-main.151 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 저장소 수준의 코드 완성 작업은 저장소의 더 넓은 문맥을 기반으로 미완성된 코드를 작성하는 작업이다. 그러나 자동 코드 완성 도구는 다른 파일에 흩어진 유용한 정보를 활용하기 어렵다.
    2. 본 논문에서는 유사도 기반 검색기와 사전 학습된 코드 언어 모델을 반복적인 검색-생성 파이프라인에 포함시켜 저장소 수준의 코드 완성 작업을 간소화하는 RepoCoder라는 간단하고 일반적인 효과적인 프레임워크를 제안한다.
    3. 실험 결과는 RepoCoder가 모든 설정에서 In-File completiion 기준을 10% 이상 향상시키고, vanilla retrieval-augmented code completion 접근법을 일관되게 앞선 성능을 보인다는 것을 보여준다.

###### Influence Scores at Scale for Efficient Language Data Sampling (https://aclanthology.org/2023.emnlp-main.152/)
- Anthology ID: 2023.emnlp-main.152 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 현대 머신러닝 시스템은 합성, 인간 주석, 실시간 고객 트래픽과 같은 다양한 원천에서 집계된 데이터를 이용한다. 학습 알고리즘의 성능에 중요한 예시들을 이해하는 것은 효율적인 모델 훈련을 위해 중요하다. 이 논문에서는 Language Classification Task 에서 영향력 점수(influence scores) 의 적용 가능성을 탐구한다.
    2. 이 논문에서는 SNLI 데이터셋을 사용하여 다양한 영향력 점수의 서브셋을 평가하고, 임의 및 영향력 점수 기반 샘플링을 통해 훈련 데이터를 축소함으로써 정확도 변화를 계량화한다.
    3. 에코더 기반 언어 모델은 원본 데이터의 약 50%로 미세 조정될 수 있으며, 성능 지표 저하 없이 훈련할 수 있다는 것이 이 실험에서 입증되었다. 또한, 영향력 점수의 오픈 소스 구현 적용을 통해 얻은 경험, 노이즈와 클래스 불균형 데이터의 영향을 계량화하고 더 나은 정확도와 훈련 효율성을 위한 점수 기반 샘플링에 대한 권장 사항을 요약한다.

###### G-Eval: NLG Evaluation using Gpt-4 with Better Human Alignment (https://aclanthology.org/2023.emnlp-main.153/)
- Anthology ID: 2023.emnlp-main.153 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 생성(NLG) 시스템이 생성한 텍스트의 품질을 자동으로 측정하기 어렵다. 기존의 기준 기반 메트릭(예: BLEU, ROUGE)은 창의성과 다양성을 필요로하는 작업에서 사람의 판단과 상대적으로 낮은 상관관계를 갖는 것으로 나타났다.
    2. 이 논문에서는 chain-of-thoughts (CoT) 및 form-filling 패러다임을 사용하여 큰 언어 모델(GPT-4)과 함께 G-Eval이라는 NLG 출력물의 품질을 평가하는 프레임워크를 제안한다. 
    3. 요약 작업에서 인간과의 스피어만 상관관계가 0.514로, 기존 방법을 큰 폭으로 능가하는 결과를 얻었으며, LLM 기반 평가자의 동작에 대한 분석을 제시하고 LLM 기반 평가자가 LLM이 생성한 텍스트에 편향될 가능성에 대해 강조한다.

###### Learning Retrieval Augmentation for Personalized Dialogue Generation (https://aclanthology.org/2023.emnlp-main.154/)
- Anthology ID: 2023.emnlp-main.154 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인물 프로필만으로는 진정한 개인화 대화를 생성하기 어려운 문제로 인해, 이 논문은 외부 지식을 활용한 개인화 대화 생성을 위한 학습 검색 학습 (LAPDOG)을 제안한다.
    2. LAPDOG 모델은 이야기 검색기와 대화 생성기로 구성되어 있으며, 이야기 검색기는 주어진 인물 프로필을 사용하여 이야기 문서에서 관련 정보를 검색하여 인물 프로필을 보강하는 보조 컨텍스트로 사용한다.
    3. CONVAI2 데이터셋과 ROCStory를 보조 데이터 소스로 사용하여 수행한 실험 결과, 제안한 LAPDOG 방법이 기준 모델들보다 큰 향상을 보였다.

###### The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations (https://aclanthology.org/2023.emnlp-main.155/)
- Anthology ID: 2023.emnlp-main.155 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 대형 언어 모델(Large Language Models, LLMs)은 놀라운 신기능을 갖게 되었지만, 그로 인해 가상 탄생 문제(hallucination)가 상당한 우려 요소로 부각되고 있다. 본 논문에서는 가상 탄생에 대한 세부적인 분류와 완화 방법을 제시한다. Factual Mirage (FM)과 Silver Lining (SL)의 두 가지 방향을 서술하고, 인과관계를 이해하기 위해 내재적과 외재적으로 나누어 심각함의 세 가지 정도를 제시한다. 가상 탄생은 약어 모호성, 숫자적 오용, 생성된 고렘, 가상 음성, 지리적 오류, 시간 왜곡 등 여섯 가지 유형으로 자세히 분류된다.
    2. Hallucination의 증거화를 위해 HallucInation eLiciTation (HILT)라는 도구를 개발해 15개의 LLMs로 생성된 75,000개의 샘플과 위에서 언급한 카테고리에 대한 인간의 주석이 포함된 데이터셋을 공개한다. 더불어, Hallucination Vulnerability Index (HVI)라는 지표를 제안하여 LLMs의 가상 탄생 취약성을 측정하고 평가할 수 있는 비교 스펙트럼을 제공한다.
    3. 인공지능 개발을 규제하는 정책을 만드는 데 있어 가상 탄생에 취약한 LLM은 어떤 것인지 평가하고 측정하는 것이 매우 중요하다. HVI는 널리 사용되는 NLP 커뮤니티에서 유용한 도구로서 기능을 하며, 인공지능 관련 정책 결정에도 사용될 수 있는 척도(rubric)가 될 것이다. 마지막으로, 가상 탄생을 완화하기 위한 두 가지 해결 전략을 제안한다.

###### NAIL: Lexical Retrieval Indices with Efficient Non-Autoregressive Decoders (https://aclanthology.org/2023.emnlp-main.156/)
- Anthology ID: 2023.emnlp-main.156 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 신경망 문서 재순위 모델은 정확도 측면에서 매우 효과적이지만, 특정 하드웨어가 필요하고 비용이 많이 들어 가장 좋은 성능을 낼 수 있는 모델은 실현 가능하지 않다.
    2. 이 논문에서는 문서별 계산 양(FLOPs)을 매우 줄여 CPU로 제공할 수 있는 어휘화된 점수 함수를 사용하여 Transformer 교차 어텐션 모델의 성능 향상을 86%까지 달성하는 방법을 제안한다.
    3. 본 방법은 BM25 검색기와 결합되어 가속기가 필요하지 않은 최신 듀얼 인코더 검색기 수준의 품질을 구현할 수 있다.

###### Analyzing Modular Approaches for Visual Question Decomposition (https://aclanthology.org/2023.emnlp-main.157/)
- Anthology ID: 2023.emnlp-main.157 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에는 별도의 학습 없이 모듈식 신경망이 어려운 Vision-Language 태스크에서 end-to-end 신경망을 능가하는 결과가 나타났다. 이 연구에서는 ViperGPT를 중점적으로 다루고, 해당 모델의 성능 향상 요소가 최신 end-to-end 모델인 BLIP-2 모델과 추가적인 symbolic components 중 어느 정도인지 분석한다.
    2. ViperGPT의 성능 향상 요소는 Task-specific 모듈 선택과 관련이 있으며, 해당 모델이 Task-agnostic 모듈 선택으로 돌아갈 경우 이러한 향상 효과가 사라진다는 결과를 도출한다.
    3. Prompting-based decomposition 전략과 비교해본 결과, 일부 벤치마크에서 자연어로 하위 작업을 표현하는 모듈식 방법이 코드보다 훨씬 성능을 향상시키는 것으로 나타났다.

###### Improving Summarization with Human Edits (https://aclanthology.org/2023.emnlp-main.158/)
- Anthology ID: 2023.emnlp-main.158 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 연구는 인간 피드백 패러다임으로 학습하여 인간 결정에 기반한 고품질 텍스트를 생성할 수 있다는 가능성을 보여주고 있다.
    2. 이 논문에서는 인간 수정을 활용한 인간 피드백의 한 형태에 초점을 맞추고, 인간 편집과 모델 생성된 데이터를 함께 사용하는 새로운 기술인 SALT를 제안한다.
    3. 실험 결과는 SALT가 인간 및 모방 수정을 통해 요약 품질을 향상시키는 데 효과적임을 보여준다. 또한, SALT가 인간 편집 데이터에 적용될 때, 인간 기호를 위해 설계된 기존 RLHF 방법보다 우수한 성능을 보여준다.

###### Did You Mean...? Confidence-based Trade-offs in Semantic Parsing (https://aclanthology.org/2023.emnlp-main.159/)
- Anthology ID: 2023.emnlp-main.159 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최적화된 confience scores를 사용하여 비용과 주석 작업 부담 사이의 균형을 맞추는 방법을 제시했다. 
    2. confidence scores는 사용성과 안정성 사이의 균형을 최적화하는 데 도움이 되며, 잘못된 저신뢰도 프로그램 수행을 줄일 수 있다.
    3. 사용성과 안정성을 더 잘 균형있게 조율하기 위해 low-confidence input을 재구성하는 DidYouMean 시스템을 제안하였다.

###### The Skipped Beat: A Study of Sociopragmatic Understanding in LLMs for 64 Languages (https://aclanthology.org/2023.emnlp-main.160/)
- Anthology ID: 2023.emnlp-main.160 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 연구에서 대규모 언어 모델들의 역할에 대해 다양한 NLP 벤치마크를 통해 조사했으나, cross-linguistic 상호작용적 의미(SM)를 이해하는 능력에 대해 철저한 조사가 부족하다.
    2. 이 논문에서는 SM 이해를 위한 다국어 벤치마크인 SPARROW를 제안한다. SPARROW는 169개의 데이터셋으로 구성되어 있으며, 6가지 주요 범주의 13가지 작업 유형을 포함하고 있다.
    3. 다양한 다국어 언어 모델과 instruction-tuned LLM들의 성능을 SPARROW를 통해 평가한 결과, 기존의 오픈소스 instruction-tuned LLM들은 여러 언어로 SM을 이해하는 데 어려움을 겪으며, 일부 경우에서는 랜덤 기준에 가까운 결과를 보여준다.

###### Understanding the Effect of Model Compression on Social Bias in Large Language Models (https://aclanthology.org/2023.emnlp-main.161/)
- Anthology ID: 2023.emnlp-main.161 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대량 언어 모델들은 웹 텍스트의 사회적 편향에 맞게 자기 지도 학습을 수행하는데, 이러한 사회적 편향은 모델의 downstream task 예측에도 영향을 미쳐 표현상의 위해를 야기한다.
    2. 모델 압축 방법인 양자화와 지식 전달이 LLM의 사회적 편향에 미치는 영향을 조사한 연구는 거의 없는데, 이 논문은 모델 압축이 사회적 편향과의 상호작용을 조사한 잘 제어된 실험을 수행하였다.
    3. 연구 결과, 더 긴 사전 학습 시간과 큰 모델은 더 높은 사회적 편향을 가지며, 양자화는 최적의 균형점을 가지는 정규화 효과를 보였다.

###### BioPlanner: Automatic Evaluation of LLMs on Protocol Planning in Biology (https://aclanthology.org/2023.emnlp-main.162/)
- Anthology ID: 2023.emnlp-main.162 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 과학 실험을 위한 정확한 프로토콜을 자동으로 생성하는 것은 과학 자동화에 큰 도약이 될 것이다. 그러나 현재의 언어 모델은 다단계 문제 및 장기 계획에 어려움을 겪어 과학 실험 설계에 중요한 역할을 못하고 있다.
    2. 이 논문은 과학 실험 프로토콜 작성 작업에 대한 자동 평가 프레임워크를 제안하고, BioProt라는 생물학 프로토콜과 의사 코드 표현을 갖는 데이터셋을 소개한다.
    3. GPT-3와 GPT-4를 이용해 실험 프로토콜 생성 과제를 평가하고, 의사 코드를 활용하여 정확한 새로운 프로토콜을 생성하고 생물학 실험실에서 성공적으로 실행하는 것을 확인하였다.

###### Cross-lingual Prompting: Improving Zero-shot Chain-of-Thought Reasoning across Languages (https://aclanthology.org/2023.emnlp-main.163/)
- Anthology ID: 2023.emnlp-main.163 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Chain-of-thought (CoT)은 모델이 추론 경로를 명시적으로 생성하도록 유도하여 추론 정확성을 향상시키는데 효과적이며, 이에 대한 관심이 증가하고 있다.
    2. 이 논문은 zero-shot CoT의 성공에도 불구하고 기존의 zero-shot prompting 기법이 단일 언어에 한정되어 다른 언어로 일반화하기 어려워 전 세계적인 개발을 어렵게 했음을 언급한다.
    3. 작업에서는 cross-lingual prompting (CLP)을 소개하며, 이를 통해 zero-shot CoT 추론을 다양한 언어로 확장하고 성능을 향상시켰다는 결과를 제시한다.

###### FinGPT: Large Generative Models for a Small Language (https://aclanthology.org/2023.emnlp-main.164/)
- Anthology ID: 2023.emnlp-main.164 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대부분의 큰 언어 모델은 작은 언어들에 대한 커버리지가 매우 한정적이고, 프리트레이닝을 위한 거의 무제한의 데이터가 있는 언어에 주로 초점이 맞춰진다.
    2. 본 논문에서는 세계 인구의 0.1%미만이 사용하는 핀란드어를 대상으로 LLM을 구축하는 도전과제를 연구한다.
    3. 핀란드의 다양한 데이터셋을 활용하여, FinGPT 및 BLUUMI라는 두 가지 모델을 프리트레이닝하는 방법을 소개하고, 핀란드어 과제를 포함한 모델 평가를 수행한다.

###### Boosting Summarization with Normalizing Flows and Aggressive Training (https://aclanthology.org/2023.emnlp-main.165/)
- Anthology ID: 2023.emnlp-main.165 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. FlowSUM은 Transformer 기반 요약을 위한 normalizing flows 기반의 변분 인코더-디코더 프레임워크를 제안한다. 이 방법은 변분 요약에서의 주요한 도전 과제인 잠재 표현의 의미 정보 부족과 훈련 중 후자분붕(collapse)을 해결하기 위해 normalizing flows를 사용하여 유연한 잠재 후방분모델링을 가능하게 한다.
    2. 제안된 controlled alternate aggressive training (CAAT) 전략과 개선된 게이트 메커니즘을 사용하여 이러한 도전을 해결한다. 실험 결과는 FlowSUM이 생성된 요약의 품질을 크게 향상시키고, 추론 시간에 미미한 영향을 미치면서 지식 압축에 대한 잠재력을 발휘한다는 것을 보여준다.
    3. 또한, normalizing flows에서의 후자분붕 문제를 조사하고 훈련 전략, 게이트 초기화, 사용된 normalizing flows의 유형과 개수가 요약의 품질에 어떤 영향을 미치는지 분석함으로써 향후 연구에 대한 유용한 통찰을 제공한다.

###### Indicative Summarization of Long Discussions (https://aclanthology.org/2023.emnlp-main.166/)
- Anthology ID: 2023.emnlp-main.166 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 온라인 포럼은 여러 주제에 대해 다양한 관점의 교환과 토론을 장려한다. 그러나 긴 토론은 쉽게 파악하기 어렵다. 
    2. 우리는 큰 언어 모델 (LLM)을 사용하여 긴 토론에 대한 표제 요약을 생성하는 비지도 학습 방법을 제안한다. 
    3. 우리의 제안된 표제 요약은 토론을 탐색하기 위한 편리한 탐색 도구로 사용될 수 있다는 사용자 연구 결과를 보여준다.

###### A Framework for Vision-Language Warm-up Tasks in Multimodal Dialogue Models (https://aclanthology.org/2023.emnlp-main.167/)
- Anthology ID: 2023.emnlp-main.167 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 멀티모달 open-domain 대화 시스템에 대한 대부분의 연구는 목표 데이터셋 이외에도 추가적인 풍부한 데이터셋을 사용한 사전 훈련과 다중 작업 학습에 초점을 두고 있다.
    2. 그러나 실제 환경에서 이러한 추가 데이터셋을 활용하는 방법은 제한적일 수 있으며, 목표 데이터셋만을 기반으로한 효율적인 에이전트 구축 방법이 더 필요하다.
    3. 이 논문에서는 목표 데이터만을 사용하는 새로운 학습 전략인 VLAW-MDM를 제안한다. 이 전략은 큰 사전 훈련 데이터나 다중 작업 데이터셋을 사용하지 않고 목표 데이터로만 학습하는 방법이다. 이 접근 방식은 이미지에 대한 자동 캡션 생성 및 문맥 정보의 향상을 위해 그것들을 모델의 입력에 포함시키는 기법을 활용한다. 실험 결과, 제안된 방법은 제한된 데이터와 비교적 작은 모델에 대해 효과적임을 입증하였다. 다양한 평가 메트릭에서 기존 최신 모델에 비해 동등하거나 우수한 성능을 보였다.

###### Once is Enough: A Light-Weight Cross-Attention for Fast Sentence Pair Modeling (https://aclanthology.org/2023.emnlp-main.168/)
- Anthology ID: 2023.emnlp-main.168 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Transformer-based 모델은 답 선택과 자연어 추론(NLI) 같은 문장 쌍 모델링 작업에서 큰 성공을 거두었으나, 이러한 모델은 입력 쌍에 대해 cross-attention을 수행하기 때문에 계산 비용이 많이 든다.
    2. 이 논문에서는 효율적인 문장 쌍 모델링을 위한 새로운 패러다임인 TopicAns를 소개한다. TopicAns는 가벼운 cross-attention 메커니즘을 사용하여 쿼리 인코딩을 한 번만 수행하고 동시에 쿼리-후보 상호작용을 모델링한다.
    3. 네 가지 작업에서 수행한 실험 결과는 TopicAns가 cross-attention 모델과 비교할 만한 성능을 달성하면서 문장 쌍 연산을 113배 이상 가속화할 수 있다는 것을 보여준다.

###### Plan, Verify and Switch: Integrated Reasoning with Diverse X-of-Thoughts (https://aclanthology.org/2023.emnlp-main.169/)
- Anthology ID: 2023.emnlp-main.169 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델 (LLM)이 Thought 체인, Thought 프로그램과 같은 다양한 프로모팅 방법과 함께 유효성을 입증했지만, 이들 방법은 수학 추론 작업에서 서로 보완재성을 갖고 있다고 발견되었다.
    2. 이 논문에서는 XoT라는 통합 문제 해결 프레임워크를 제안하는데, 다양한 추론 측면에서 LLMs에게 프롬프트를 제공한다.
    3. 각 질문에 대해 XoT는 항상 가장 적합한 방법을 선택하고 각 방법을 반복적으로 실행하여 문제를 해결한다. 이를 통해 XoT는 동적으로 다른 프로모팅 방법 사이를 전환할 수 있으며, 외부 실행자로부터의 피드백을 통합하여 생성된 답변의 유효성을 확인한다.

###### GLEN: General-Purpose Event Detection for Thousands of Types (https://aclanthology.org/2023.emnlp-main.170/)
- Anthology ID: 2023.emnlp-main.170 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문에서는 넓은 범위와 대용량의 데이터셋 부재로 인해 이벤트 추출 연구의 진행이 방해되었다고 주장한다.
    2. GLEN은 3,465개의 다른 유형을 포함한 205,000개의 이벤트 언급을 다루는 일반 목적의 이벤트 감지 데이터셋으로, 오늘날 가장 큰 이벤트 데이터셋의 온톨로지보다 20배 이상 크다.
    3. GLEN은 PropBank의 기존 주석을 원격 감독으로 활용하는 DWD 오버레이를 사용하여 생성되었으며, GLEN의 큰 온톨로지 크기에 특별히 설계된 새로운 다단계 이벤트 감지 모델이 높은 성능을 보여준다는 것을 보여주고 있다.

###### Hierarchical Pretraining on Multimodal Electronic Health Records (https://aclanthology.org/2023.emnlp-main.171/)
- Anthology ID: 2023.emnlp-main.171 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사전 훈련은 NLP 분야에서 강력한 기술이지만 전자 건강 기록(EHR)에 대한 기존 사전 훈련된 모델은 EHR 데이터의 계층적 특성을 잘 포착하지 못하여 다양한 급행 태스크에 대한 일관된 일대 다 학습이 제한된다.
    2. 이 논문에서는 MedHMP라는 새로운 사전 훈련 프레임워크를 소개하여 계층적으로 다중 모달 EHR 데이터에 대해 특별히 설계되었다.
    3. 실험 결과를 통해 제안된 MedHMP의 효과를 보여주고, 18개의 기준선과의 비교에서 우리 접근법의 효능이 강조되었다.

###### Critic-Driven Decoding for Mitigating Hallucinations in Data-to-text Generation (https://aclanthology.org/2023.emnlp-main.172/)
- Anthology ID: 2023.emnlp-main.172 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 입력된 정보와 연결되지 않은 텍스트의 생성은 신경망 기반의 데이터 텍스트 생성에서 잘 알려진 문제이다. 이 논문에서는 기존의 모델 아키텍처나 추가 데이터 수집을 필요로 하지 않고, 생성 모델과 "텍스트 비평가" 분류기의 출력을 결합하여 환영을 완화하는 새로운 방법을 탐구한다. 
    2. 이 방법은 워드 확률에 기반한 모델과 디코딩과 조합될 수 있으며, 텍스트 비평가는 기존 LM의 훈련 데이터와 합성된 부정적 예제를 사용하여 추가적인 훈련 데이터가 필요하지 않는다.
    3. 실험 결과, 이 방법은 WebNLG와 OpenDialKG 벤치마크에서 기준 모델과 비교하여 성능을 개선시킨다.

###### Bridging the Gap between Synthetic and Authentic Images for Multimodal Machine Translation (https://aclanthology.org/2023.emnlp-main.173/)
- Anthology ID: 2023.emnlp-main.173 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 멀티모달 기계 번역(MMT)은 번역을 위해 입력으로 소스 문장과 관련 이미지를 동시에 사용한다. 
    2. 최근 연구들은 입력 문장에 연결된 이미지가 대부분 없기 때문에 강력한 텍스트-이미지 생성 모델을 활용하는 것을 제안한다. 
    3. 그러나 이 논문에서는 MMT 모델에 합성 이미지와 실제 이미지를 각각 제공하여, 합성 이미지에서 발생하는 분포 차이를 줄이고, 메인 모델이 실제 이미지에 의존하지 않는 성능 향상을 이끌어냈다.

###### DEPN: Detecting and Editing Privacy Neurons in Pretrained Language Models (https://aclanthology.org/2023.emnlp-main.174/)
- Anthology ID: 2023.emnlp-main.174 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사전 학습 언어 모델은 대규모 코퍼스에서 인간의 지식을 배웠지만, 그들의 강력한 메모리화 능력은 데이터 누출의 위험성을 불러온다. 이 논문에서는 사생활 데이터의 영향을 제거하기 위해 위험한 뉴런을 식별하고 제거하는 방법을 제안한다. 
    2. 새로운 방법을 사용하여 사생활 텍스트와 관련된 뉴런을 확인하고 이들을 활성화 값이 0인 것으로 설정하여 제거한다. 
    3. 실험 결과 우리의 방법은 모델의 성능에 영향을 주지 않으면서 사생활 데이터의 영향을 효과적이고 빠르게 제거할 수 있음을 보여준다. 또한, 실험을 통해 모델의 메모리화와 뉴런 간의 관계를 설명하며 우리 방법의 강건성을 더욱 명확하게 보여준다.

###### Investigating Bias in Multilingual Language Models: Cross-Lingual Transfer of Debiasing Techniques (https://aclanthology.org/2023.emnlp-main.175/)
- Anthology ID: 2023.emnlp-main.175 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 연구는 다국어 모델 내에서 편향 해소 기법의 전이성(transferability)에 대해 조사한다.
    2. 저자들은 영어, 프랑스어, 독일어, 네덜란드어에 대한 이러한 기법의 적용 가능성을 조사한다.
    3. 연구 결과, 크로스-링교(다중 언어) BERT(mBERT)를 사용하여 편향 해소 기법의 언어 간 전이가 가능하며, 실제로 유망한 결과를 얻었다. 특히 SentenceDebias 기법의 성능이 언어에 상관없이 우수하게 나타나며, mBERT의 편향을 평균 13% 줄일 수 있다고 발견되었다. 또한, 전이 학습을 추가한 편향 해소 기법은 특히 데이터 부족한 언어에서 크로스-링교적 효과를 갖는다는 것이 조사 결과로 밝혀졌다.

###### Can Language Models Laugh at YouTube Short-form Videos? (https://aclanthology.org/2023.emnlp-main.176/)
- Anthology ID: 2023.emnlp-main.176 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 소셜 네트워크의 짧은 형식의 유머 동영상이 인기를 얻으면서, AI 모델이 인식하기 위해 사람들과 더 잘 소통할 수 있게 됩니다. 그러나 이전의 비디오 유머 데이터셋은 연설이나 시트콤과 같은 특정 도메인을 대상으로하며 주로 언어적 단서에 초점을 맞추고 있습니다.
    2. 우리는 YouTube에서 수집한 1만 개의 다중모달 유머 동영상 데이터셋 (ExFunTube) 을 만들었습니다. 이를 위해 GPT-3.5와 비디오 필터링 파이프라인을 사용하여 유머에 기여하는 음성 및 시각적 요소를 확인하고 여러 도메인에 걸쳐 다양한 유형의 유머를 가지고 있는 동영상을 주석과 함께 주석을 추가했습니다.
    3. 자동 점수, 근거 품질 실험 및 인간 평가를 사용하여 세 가지 다른 평가 방법으로 우리의 프롬프팅이 LLMs (Large Language Model)의 유머에 대한 이해 능력을 크게 향상시킴을 보여줍니다.

###### Random Entity Quantization for Parameter-Efficient Compositional Knowledge Graph Representation (https://aclanthology.org/2023.emnlp-main.177/)
- Anthology ID: 2023.emnlp-main.177 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 지식 그래프(Knowledge Graphs)에서의 표현 학습은 하위 태스크에 있어서 중요하다. 기존 방법인 지식 그래프 임베딩(KG Embedding)은 많은 scalability 도전과 파라미터 효율성의 문제를 안고 있다. 하지만 이 논문에서는 간단한 무작위(entity quantization) 방법이 현재 전략과 유사한 결과를 얻을 수 있다고 보여준다. 
    2. random entity quantization을 통해 다른 entity가 더 easily distinguish되는 것으로 분석하고, 이를 통해 effectve한 KG representation을 이룰 수 있다.
    3. 즉, KG representation에서 현재 quantization 전략은 중요하지 않으며, entity distinguishability 개선에는 여전히 개선의 여지가 있다.

###### Exploring All-In-One Knowledge Distillation Framework for Neural Machine Translation (https://aclanthology.org/2023.emnlp-main.178/)
- Anthology ID: 2023.emnlp-main.178 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존 지식추출(Knowledge Distillation, KD) 접근 방식은 경량화된 학생 모델을 한 번에 하나씩 얻지만, 동시에 다른 학생들이 필요한 경우 반복적으로 KD를 수행해야 하므로 자원을 많이 소비할 수 있다. 
    2. 이 논문에서는 한 번에 여러 개의 만족스러운 학생 모델을 생성하는 All-In-One Knowledge Distillation (AIO-KD) 프레임워크를 제안한다. 
    3. AIO-KD를 통해 여러 개의 서로 상호작용하는 학생 모델을 동시에 최적화하여 자원과 효능을 향상시킬 수 있다.

###### HistAlign: Improving Context Dependency in Language Generation by Aligning with History (https://aclanthology.org/2023.emnlp-main.179/)
- Anthology ID: 2023.emnlp-main.179 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어 모델(LMs)은 환각과 무결점이 있으며 문맥 종속성이 약한 문제를 가지고 있다. Cache-LMs는 최근 기록을 저장하여 문맥 종속성을 높일 수 있기 때문에 다양한 언어 생성 작업에서 우수한 성능을 보여주고 있다. 그러나 현재의 cache-LMs의 cache 구성요소로 인한 성능 향상이 부족하다는 문제점을 발견했다.
    
    2. 우리는 HistAlign이라는 새로운 훈련 접근 방식을 제안하여 모델이 기록에서 유용한 신호를 받을 수 있는 좋은 cache 정렬을 보장한다.
    
    3. 우리는 먼저 기록이 올바른 예측에 필수적인 단순하고 합성 과제에서 개념을 증명하고, HistAlign의 cache 구성요소가 더 잘 정렬되어 전체 성능을 향상시킨다는 것을 보여준다. 그다음, 우리는 prompt continuation, 추상적 요약, data-to-text 등 다양한 하위 언어 생성 작업에서 HistAlign을 평가한다. HistAlign이 열린 문맥 및 조건부 생성 환경에서 각각 텍스트 일관성과 충실성을 향상시킨다는 것을 입증한다. HistAlign은 다른 모델 유형에서 일반화되어 적용될 수 있으며, 다양한 시나리오에서 LMs의 문맥 종속성 향상에 강점을 보여준다.

###### CombLM: Adapting Black-Box Language Models through Small Fine-Tuned Models (https://aclanthology.org/2023.emnlp-main.180/)
- Anthology ID: 2023.emnlp-main.180 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 최근의 트렌드인 높은 품질의 모델이 API를 통해서만 사용 가능한 블랙박스로 되어있을 때, 파라미터를 수정하지 않고도 새로운 도메인과 과제에 대한 언어 모델을 적용하는 경량화된 방법을 제안한다. 
    2. 대규모 블랙박스 언어 모델과 작은 화이트박스 언어 모델을 작은 검증 데이터셋을 기반으로 학습한 작은 네트워크를 사용하여 확률 수준에서 결합시키는 방법을 사용한다.
    3. 실험 결과, 이 방법을 사용하여 대규모 언어 모델을 여러 도메인과 번역 과제에 적용하였을 때, 성능이 향상되는 것을 보여준다.

###### Image Manipulation via Multi-Hop Instructions - A New Dataset and Weakly-Supervised Neuro-Symbolic Approach (https://aclanthology.org/2023.emnlp-main.181/)
- Anthology ID: 2023.emnlp-main.181 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문에서는 자연어 텍스트를 통한 이미지 조작에 대해 다루며, 복합적인 다중 모달 공간 상에서의 복잡한 추론이 필요한 과제를 다룬다.
    2. Neuro Symbolic Concept Learning (NSCL)이라는 방법을 Visual Question Answering (VQA) 작업에서 제안된 것을 자연어를 통한 이미지 조작 작업에 확장한다.
    3. NeuroSIM은 약한 지도 데이터 형태인 VQA에 대한 주석이 포함된 데이터로 복잡한 다중 객체 장면에서 다중 홉 추론을 수행할 수 있으며, 심볼릭 프로그램을 생성하여 실행을 안내한다.

###### Generative Spoken Language Model based on continuous word-sized audio tokens (https://aclanthology.org/2023.emnlp-main.182/)
- Anthology ID: 2023.emnlp-main.182 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. NLP에서는 단어나 서브워드를 기반으로 한 텍스트 언어 모델이 character 기반 모델보다 우수한 성능을 보인다. 하지만 음성 커뮤니티에서는 입력이 20ms 또는 40ms 길이의 이산 단위 (phoneme보다 짧은)로 이루어지곤 한다. 이 논문에서는 단어 기반 언어 모델에서 영감을 얻어 word-size 연속값 오디오 토큰을 기반으로 하는 생성형 음성 언어 모델을 소개한다. 
    2. 기존의 단어 기반 언어 모델에 대한 데이터, 손실 함수, 샘플링 방법 등을 연속값을 기반으로 대체하여, 다양하고 표현적인 언어 출력을 생성할 수 있다.  
    3. 이 모델은 자동 평가 메트릭과 주관적인 인간 판단으로 측정된 생성 품질 면에서 이산 단위 기반 모델과 성능이 동등하면서, 200ms 단위의 큰 메모리를 사용하기 때문에 5배 더 메모리 효율적이다. 또한 Lexical Embedder 이전과 이후의 임베딩은 음운적 및 의미론적으로 해석 가능하다.

###### Enhancing Chat Language Models by Scaling High-quality Instructional Conversations (https://aclanthology.org/2023.emnlp-main.183/)
- Anthology ID: 2023.emnlp-main.183 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. ChatGPT와 같은 채팅 언어 모델에 대한 지시 데이터의 미세 조정은 효과적인 방법으로 널리 인정받고 있지만, 이 논문에서는 오픈 소스 모델의 상한선을 더욱 높이기 위한 연구를 진행한다고 밝혀졌다. 
    2. 연구진은 우선, 인간 쿼리를 포함하지 않는 Instructional 대화의 다양하고 정보성이 높은 대규모 데이터셋인 UltraChat을 개발하였다. 
    3. UltraChat을 기반으로 한 UltraLM 모델은 기존 오픈 소스 모델인 WizardLM, Vicuna 등을 능가하는 성능을 보여주었다.

###### Weakly-Supervised Learning of Visual Relations in Multimodal Pretraining (https://aclanthology.org/2023.emnlp-main.184/)
- Anthology ID: 2023.emnlp-main.184 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 시각-언어 사전학습 연구는 더 나은, 고도로 세분화된 다중모달 표현을 학습하기 위해 객체 탐지 데이터로부터의 지도 신호를 조사했다. 
    2. 본 연구에서는 이러한 방법을 한 걸음 더 나아가 작은 규모의 시각적 관계 데이터로부터 지도 신호를 추출하는 방법을 조사한다. 
    3. 우리는 구조화된 캡션으로 시각적 관계 쌍들을 변환하고, 이미지 설명으로 추가하여 시각적 개체를 다중 모달 설정에서 문맥화하는 두 가지 사전 학습 접근법을 제안한다.

###### Unsupervised Grammatical Error Correction Rivaling Supervised Methods (https://aclanthology.org/2023.emnlp-main.185/)
- Anthology ID: 2023.emnlp-main.185 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최신 문법 오류 수정(GEC) 시스템은 병렬 훈련 데이터(비문법적 문장과 그것들의 수동으로 수정된 반대방향 문장)에 의존하는데, 이는 구축 비용이 많이 든다. 
    2. 이 논문에서는 unsupervised GEC 시스템을 구축하기 위해 Break-It-Fix-It (BIFI) 방법을 사용한다. 
    3. 실험 결과는 우리의 GEC 시스템이 이전의 unsupervised GEC 시스템보다 우수하며, ensemble 없이도 supervised GEC 시스템과 성능이 비중화된다는 것을 보여준다.

###### S2abEL: A Dataset for Entity Linking from Scientific Tables (https://aclanthology.org/2023.emnlp-main.186/)
- Anthology ID: 2023.emnlp-main.186 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. entity linking (EL)은 지식 기반 NLP 애플리케이션에서 매우 중요한 텍스트 언급을 지식 베이스의 해당 항목에 연결하는 작업입니다. 이 논문에서는 scientific 논문의 테이블에 대한 EL을 위한 첫 번째 데이터셋을 제시합니다.
    2. Scientific Table Entity Linking (S2abEL) 데이터셋은 머신러닝 결과 테이블에서의 EL에 초점을 맞추고 있으며, PaperswithCode 택소노미의 8439개 셀에 대한 손으로 라벨링된 셀 유형, 소스 및 entity 링크가 포함되어 있습니다.
    3. 우리는 지식 베이스에 없는 많은 언급을 포함하는 scientific 테이블에 대한 EL을 위해 설계된 신경망 기준선 방법을 도입하고, 최첨단 범용 테이블 EL 방법보다 훨씬 뛰어난 성능을 보인다는 것을 보여줍니다. 최상의 베이스라인은 인간의 성능을 아래로 미치며, 분석 결과 개선 가능한 방향을 강조합니다.

###### API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs (https://aclanthology.org/2023.emnlp-main.187/)
- Anthology ID: 2023.emnlp-main.187 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 연구에서, 대형 언어 모델 (LLM)들이 외부 도구를 활용하여 능력을 향상시킬 수 있다는 것이 입증되었습니다. 그러나 세 가지 핵심적인 질문들에는 아직 대답이 되지 않았습니다.
    2. 우리는 GPT-3.5와 비교하여 GPT-3가 개발된 Alpaca에 비해 API 이용 능력이 향상되었음을 실험결과로 보여주고, GPT-4는 계획력에서 우수한 성과를 나타냈습니다.
    3. 그러나 더 발전할 여지는 여전히 많습니다. 또한, Lynx는 Alpaca의 도구 활용 성능을 26 이상으로 개선하였고, GPT-3.5의 효과성에 근접했습니다. 따라서 이 도메인에서 미래 연구에 대한 핵심적인 도전 과제를 강조합니다.

###### Language and Mental Health: Measures of Emotion Dynamics from Text as Linguistic Biosocial Markers (https://aclanthology.org/2023.emnlp-main.188/)
- Anthology ID: 2023.emnlp-main.188 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 감정 변화의 패턴인 감정 동태(emotion dynamics)는 정신 건강 상태를 나타낼 수 있다는 것을 심리병리학 연구에서 보여주었다.
    2. 우리는 유저의 트윗에서 추출한 감정 동태 지표 (UED metrics)와 정신 질환과의 관계를 분석한 첫번째 연구이다.
    3. 우리는 UED metrics가 사용자의 진단된 정신 질환과 유의미한 상관관계를 갖는다는 것을 발견했으며, 감정 동태 언어적 cue들이 정신 질환의 이해, 진단 및 관리에 중요한 역할을 할 수 있다는 것을 보여준다.

###### Lion: Adversarial Distillation of Proprietary Large Language Models (https://aclanthology.org/2023.emnlp-main.189/)
- Anthology ID: 2023.emnlp-main.189 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 고급 상용 LLM에서 경량 오픈소스 LLM으로의 지식 전달(practicing knowledge transfer)이 많은 관심을 받고 있다. 그러나 현재의 기술은 학생 모델의 성능이 부족한 과제를 찾아내어 이를 향상시키는 "피드백"을 통합하는 가능성을 간과하고 있다. 
    2. 본 논문에서는 새로운 적대적 전달 프레임워크를 제안하여 강사 모델이 "어려운" 과제를 식별하고 학생 모델을 위해 새로운 "어려운" 과제를 생성하도록 한다. 
    3. 이 적대적 프레임워크를 적용하여 70k 학습 데이터로 ChatGPT에서 학생 모델(Lion)로 지식을 성공적으로 전달하였으며, Lion-13B는 ChatGPT와 유사한 성능을 가지며 BIG-Bench Hard, AGIEval과 같은 어려운 문제에서 Vicuna-13B와 비교하여 성능을 크게 개선하였다.

###### Evaluating Large Language Models on Controlled Generation Tasks (https://aclanthology.org/2023.emnlp-main.190/)
- Anthology ID: 2023.emnlp-main.190 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 연구들은 질문 생성, 읽기 이해력, 다국어 등 다양한 기준 작업에서 대형 언어 모델들의 능력을 조사했으나, 생성 작업에서의 대형 언어 모델의 컨트롤 가능성에 대해 연구가 부족하다.
    2. 우리는 문장 계획을 포함한 다양한 벤치마크를 사용하여 대형 언어 모델과 최신 피니튜닝 작은 모델을 비교한 후, 대형 언어 모델이 작은 모델의 능력을 뒤지거나 비교 가능하거나 초월하는 것을 나타내는 스펙트럼을 제시한다.
    3. 우리는 대형 언어 모델이 세부적인 제약 조건을 충족시키기 어렵다고 결론을 내렸다.

###### DeSIQ: Towards an Unbiased, Challenging Benchmark for Social Intelligence Understanding (https://aclanthology.org/2023.emnlp-main.191/)
- Anthology ID: 2023.emnlp-main.191 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사회적 지능은 인간의 표현, 의도, 상호작용에 대한 이해와 추론에 필수적이다. 이 분야의 연구를 위한 대표적인 벤치마크 중 하나는 복잡한 사회적 상호작용 영상에 대한 다중 선택 문제를 포함하는 Social-IQ 데이터셋이다. 
    2. 우리는 Social-IQ의 타당성을 연구하기 위한 철저한 방법론을 정의한다. 벤치마크 데이터셋의 타당성은 연구 문제를 조사하는 데 중요하다. 
    3. 우리의 분석 결과, Social-IQ에는 상당한 편향성이 존재하며, 중간 정도의 강한 언어 모델이 맥락이나 질문 없이도 완벽한 성능을 달성하기 위해 편향된 상관관계를 학습할 수 있음을 보여준다. 이에 우리는 Social-IQ에 간단한 변조를 가하여 새로운 도전적인 데이터셋인 DeSIQ를 소개한다.

###### Why LLMs Hallucinate, and How to Get (Evidential) Closure: Perceptual, Intensional, and Extensional Learning for Faithful Natural Language Generation (https://aclanthology.org/2023.emnlp-main.192/)
- Anthology ID: 2023.emnlp-main.192 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. LLMs는 증거적 폐쇄(evidential closure) 조건에 의해 제한되지 않기 때문에 환각을 갖게 된다. 즉, LLM의 출력은 그들이 증거를 가진 주장과 동의어적이지 않아도 된다는 것이다.
    2. 우리는 LLM들이 증거적 폐쇄를 만족시키는 출력을 생성하도록 제한하는 방법을 제안한다.
    3. 실제로 검증된 증거 집합과 동의어적인 출력을 갖는 출력으로부터 충실한 결과를 얻기 위해 Learn-Babble-Prune라는 휴리스틱 절차를 제안한다.

###### A Question Answering Framework for Decontextualizing User-facing Snippets from Scientific Documents (https://aclanthology.org/2023.emnlp-main.193/)
- Anthology ID: 2023.emnlp-main.193 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "많은 실제 응용 프로그램들(예: 노트 정리, 검색)에서는 문서에서 문장이나 단락을 추출하고 원본 문서 외부에서 인간에게 그 스니펫을 제공하는 것이 필요하다. 그러나 사용자들은 원본 문서의 문맥을 갖지 못하여 스니펫을 이해하기 어려울 수 있다." 
    2. "우리는 언어 모델을 사용하여 과학 문서의 스니펫을 독립적으로 읽을 수 있게 다시 작성하는 작업을 수행한다. 이를 위해 사용자 중심의 이 문맥 특화 작업을 수행하기 위한 요구사항과 과제를 정의한다."
    3. "우리는 질문 생성, 질문 답변, 문장 다시 작성으로 작업을 분해하는 프레임워크를 제안하며, state-of-the-art 상업용 및 오픈소스 언어 모델을 사용하여 여러 실험을 수행한다".

###### SLOG: A Structural Generalization Benchmark for Semantic Parsing (https://aclanthology.org/2023.emnlp-main.194/)
- Anthology ID: 2023.emnlp-main.194 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 구성적 일반화 기준은 모델이 새로운 복잡한 언어 표현에 얼마나 잘 일반화하는지를 평가하는 것을 목표로 한다. 그러나 기존 벤치마크는 종종 훈련에서 익숙한 문법 구조에서 새로운 어휘 항목의 해석에 초점을 맞추고, 훈련에서 익숙하지 않은 문법 구조의 일반화 작업은 종종 미흡하게 다루어지며 모델이 얼마나 잘 일반화할 수 있는지에 대한 overly optimistic perceptions을 만들어낸다.
    2. 우리는 17개의 구조적 일반화 케이스를 포함한 COGS를 확장한 의미 파싱 데이터셋인 SLOG을 소개한다.
    3. 실험에서, 사전 훈련된 Transformer 모델들을 포함한 일반화 정확도는 40.6%에 불과하며 구조를 고려한 파서는 70.8%만 달성한다. 이 결과는 기존 모델이 COGS에서 거의 완벽한 정확도를 달성하는 것과는 거리가 멀며, SLOG가 모델의 어휘적 일반화 능력과 구조적 일반화 능력 간의 큰 차이를 강조하는 역할을 한다.

###### Pushdown Layers: Encoding Recursive Structure in Transformer Language Models (https://aclanthology.org/2023.emnlp-main.195/)
- Anthology ID: 2023.emnlp-main.195 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인간의 언어에는 재귀적인 특징이 있으며, 이는 명시적인 재귀 상태 추적 메커니즘이 없는 self-attention에 대해서 근본적인 도전이다.
    2. 이 논문에서는 recursive state를 추적하기 위해 stack tape를 이용한 새로운 self-attention layer인 Pushdown Layers를 제안한다. Pushdown Layers를 사용한 Transformer LMs는 재귀적 언어 모델로, 새로운 토큰을 예측하면서 stack tape를 업데이트하고 토큰들에 대한 attention을 부드럽게 제어한다.
    3. Pushdown Layers를 적용한 Transformers는 훨씬 더 효과적이고 샘플 효율적인 구문적 일반화를 달성하며, perplexities는 유지하면서 GLUE 텍스트 분류 작업에서 향상되는 결과를 얻었다.

###### Can LLMs Facilitate Interpretation of Pre-trained Language Models? (https://aclanthology.org/2023.emnlp-main.196/)
- Anthology ID: 2023.emnlp-main.196 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사전 훈련된 언어 모델의 지식을 파악하기 위한 연구는 주로 주석이 달린 말뭉치나 사람을 통한 방법을 사용한다. 
    2. 우리는 대규모 언어 모델인 ChatGPT를 주석 달기 도구로 사용하여 사전 훈련된 언어 모델의 세밀한 해석 분석을 가능케 한다. 
    3. 우리의 연구 결과는 ChatGPT가 인간 주석보다 정확하고 의미론적으로 더 풍부한 주석을 생성한다는 것을 보여준다. 또한 GPT 기반의 주석이 해석 분석 방법론을 강화하는 데 어떻게 도움이 되는지도 보여준다.

###### Enhancing Low-resource Fine-grained Named Entity Recognition by Leveraging Coarse-grained Datasets (https://aclanthology.org/2023.emnlp-main.197/)
- Anthology ID: 2023.emnlp-main.197 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Named Entity Recognition (NER)에서는 레이블된 데이터가 부족한 문제가 자주 발생한다. 기존의 K-shot learning 기술을 적용할 수 있지만, 어노테이션의 수가 수십 개가 넘으면 그 성능은 포화되기 쉽다.
    2. 이 논문에서는 그 문제를 해결하기 위해 수 많은 어노테이션을 제공하는 coarse-grained 데이터셋을 활용한다. 그러나, 기존의 pre-finetuning 방법은 coarse-grained 데이터를 표현 학습에 사용할 수 있게 해줄 뿐이며, fine-grained와 coarse-grained entities 사이의 관계를 직접적으로 활용하지는 못하는 문제가 있다.
    3. 이 논문에서는 F2C (Fine-to-Coarse) 매핑 행렬을 사용한 fine-grained NER 모델을 제안하였고, 또한 fine-grained entity가 coarse-grained entity의 하위 카테고리일 가능성이 높기 때문에 이러한 계층 구조를 명시적으로 활용한다. 추가로 fine-grained entity 타입과 일치하지 않는 coarse-grained entity를 걸러내는 inconsistency filtering 방법을 제시하여 성능 저하를 방지한다. 실험 결과에서 소수의 fine-grained 어노테이션을 처리할 때 우리의 방법이 K-shot learning 및 지도 학습 방법보다 우월한 성능을 보였다.

###### Oolong: Investigating What Makes Transfer Learning Hard with Controlled Studies (https://aclanthology.org/2023.emnlp-main.198/)
- Anthology ID: 2023.emnlp-main.198 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사전 훈련된 언어 모델을 새로운 언어로 전이할 때, 문법적 유사성과 어휘적 유사성과 같은 다양한 요인들이 동시에 변하게 된다. 이 논문에서는 GLUE 벤치마크의 언어를 체계적으로 변형하여 교차언어적 변이의 한 축을 변경한 후, 사전 훈련된 모델의 후속 성능 저하를 측정함으로써 다른 요인들의 영향을 분리하기 위한 제어된 전이 연구 세트를 제안한다.
    
    2. 문법적 스타일의 변화에서 모델은 대부분 회복될 수 있지만, 어휘의 불일치와 임베딩 행렬 재초기화에서는 사전 훈련된 모델의 성능이 회복되지 않으며, 지속적인 사전 훈련을 해도 회복되지 않는다는 것을 발견했다.
    
    3. 또한, 전이 언어에서 좋은 품질의 토크나이저는 어휘 정렬을 쉽게하지 않는다. 우리의 실험은 언어 전이 시나리오를 설계할 때 연구자들이 가장 집중해야 할 교차언어적 전이 요소에 대한 통찰력을 제공한다.

###### Non-Autoregressive Math Word Problem Solver with Unified Tree Structure (https://aclanthology.org/2023.emnlp-main.199/)
- Anthology ID: 2023.emnlp-main.199 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존 MWP 문제 해결 모델들은 문제를 표현하고 해결 방법을 파악하기 위해 순차적이거나 이진 트리 구조를 사용하지만, 이러한 구조는 수학적으로 변형 가능한 경우를 처리할 수 없다. 
    2. 이 논문에서는 표현식의 다양한 해결 방법을 표현하기 위해 통합된 트리 구조를 도입하고, 이를 기반으로 문제를 해석하고 해결 방법을 유추하는 비자기적인 (non-autoregressive) 모델을 제안한다. 
    3. 또한, 통합된 트리의 가능한 표현식들을 평가하기 위해 경로 기반 메트릭을 설계하여 제안된 모델의 효과를 실험을 통해 입증하였다.


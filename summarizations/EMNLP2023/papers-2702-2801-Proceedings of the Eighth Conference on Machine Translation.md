# Korean Three-Line Summarizations of Papers 2702-2801 in Proceedings of the Eighth Conference on Machine Translation
###### Proceedings of the Eighth Conference on Machine Translation (https://aclanthology.org/2023.wmt-1.0/)
- Anthology ID: 2023.wmt-1.0 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors:  
- Summary: 
    요약문을 생성할 수 없습니다.

###### Findings of the 2023 Conference on Machine Translation (WMT23): LLMs Are Here but Not Quite There Yet (https://aclanthology.org/2023.wmt-1.1/)
- Anthology ID: 2023.wmt-1.1 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 이 논문은 2023년 기계 번역 컨퍼런스(WMT) 일환으로 열린 General Machine Translation Task의 결과를 제시한다.
    2. 일반적인 기계 번역 과제에서는 참가자들에게 8개의 언어 쌍(14개의 번역 방향에 해당) 중 하나에 대해 기계 번역 시스템을 구축하라고 요청하고, 최대 네 가지 다른 도메인으로 구성된 테스트 세트에서 평가한다.
    3. 우리는 Source-based Direct Assessment와 scalar quality metric(DA+SQM)의 조합을 사용하여 전문인간 평가자들이 시스템 출력을 평가한다.

###### Findings of the WMT 2023 Biomedical Translation Shared Task: Evaluation of ChatGPT 3.5 as a Comparison System (https://aclanthology.org/2023.wmt-1.2/)
- Anthology ID: 2023.wmt-1.2 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1.  WMT23에서 진행된 Biomedical Translation Task에 대한 개요를 제공한다. 이 Task의 목표는 PubMed 데이터베이스에서 생체 의학적인 초록을 자동으로 번역하는 것이다. 
    2. 이 Task에는 프랑스어, 스페인어, 포르투갈어, 이탈리아어, 독일어, 러시아어 등 12개의 언어 방향 (영어를 기준으로 번역하거나 번역되는 방향)이 포함되었다. 
    3. ChatGPT 3.5를 기반으로 한 비교 시스템이 많은 제출작 중에서 아주 잘 수행되었다고 한다.

###### Findings of the WMT 2023 Shared Task on Discourse-Level Literary Translation: A Fresh Orb in the Cosmos of LLMs (https://aclanthology.org/2023.wmt-1.3/)
- Anthology ID: 2023.wmt-1.3 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 文학작품 번역은 기계번역에서 계속해서 어려운 도전으로 남아있고, 이 도메인에서 진전을 이끌기 위해 'Discourse-Level Literary Translation' 공유 작업을 WMT 2023에서 개최한다. 
    2. 저자들은 저작권이 있는 한영 웹 소설 말뭉치를 공개하고 사람의 평가 과정을 안내하는 산업 인증 기준을 제시한다. 
    3. 이번 작업에서는 총 7개의 학계와 산업 팀으로부터 14개의 제출을 받았고, 제출된 시스템의 성능을 측정하기 위해 자동 평가와 인간 평가를 사용했다.

###### Findings of the Second WMT Shared Task on Sign Language Translation (WMT-SLT23) (https://aclanthology.org/2023.wmt-1.4/)
- Anthology ID: 2023.wmt-1.4 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 이 논문은 자동 수화 번역을 위한 두 번째 WMT Shared Task 결과를 제시한다. 이 공유 작업은 수화와 구어 언어 간의 자동 번역에 관련되어 있다. 이미 잘 알려진 텍스트-텍스트 기계 번역의 패러다임을 넘어서 시각 정보 (비디오 프레임 또는 인간 자세 추정과 같은)를 처리하는 것이 필요하다는 점에서 이 작업은 유일하다.
    2. 이 작업은 DSGS-to-German 트랙을 포함한 네 가지 트랙이 제공된다.
    3. 이 작업은 새로운 말뭉치와 재현 가능한 베이스라인 시스템을 포함하여 다음과 같은 과학적 기여를 한다.

###### Findings of the WMT 2023 Shared Task on Parallel Data Curation (https://aclanthology.org/2023.wmt-1.5/)
- Anthology ID: 2023.wmt-1.5 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 우리는 문서 정렬 및 문장 필터링에 대한 이전 WMT 공유 태스크를 기반으로, 에스토니아-리투아니아 웹 데이터의 가능한 훈련 데이터의 최적 하위 집합을 찾는 엔드 투 엔드 데이터 정제 파이프라인의 공유 태스크를 제시했다.
    2. 참가자들은 정렬과 필터링을 포함한 데이터 정제 파이프라인의 어느 부분에 집중할 수 있었다.
    3. 우리는 결론적으로 기계 번역 품질을 기준으로 결과를 평가했으며, 강력한 기준 시스템의 다양한 중간 결과와 함께 처리된 Common Crawl 데이터를 공개하여 이에 대한 차후 연구를 가능하게 할 것이라고 생각한다.

###### Samsung R&D Institute Philippines at WMT 2023 (https://aclanthology.org/2023.wmt-1.6/)
- Anthology ID: 2023.wmt-1.6 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 삼성 R&D Institute Philippines의 제약 조건 있는 submission 시스템은 WMT 2023 일반 번역 작업에 대한 en->he와 he->en 두 방향으로 구성되어 있다.
    2. 해당 시스템은 Transformer 기반의 sequence-to-sequence 모델로, 종합적인 데이터 전처리 파이프라인, 후반환(backtranslation) 데이터의 합성, 그리고 온라인 디코딩 중 noisy channel reranking 사용 등의 다양한 방법론을 통해 학습되었다.
    3. FLORES-200 및 NTREX-128라는 두 개의 공개 벤치마크에서, 해당 모델은 mBART50 M2M 및 NLLB 200 MoE와 같은 강력한 기준 모델과 유사한 성능을 보이며, 가중치 수가 상당히 적다.

###### NAIST-NICT WMT’23 General MT Task Submission (https://aclanthology.org/2023.wmt-1.7/)
- Anthology ID: 2023.wmt-1.7 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 이 논문은 WMT'23의 영일 ↔ 일영 일반 기계 번역 작업에 대한 NAIST-NICT의 제출 시스템을 설명한다.
    2. 이 시스템은 다양한 기법을 사용하여 다양한 번역 후보를 생성하고, 두 단계의 재정렬 시스템을 사용하여 최상의 번역을 찾는다.
    3. 다양한 번역 후보를 생성하는 것이 번역 품질을 향상시키는데 도움이 되었으며, 재정렬 모델을 사용하여 최종 후보를 순위화하는 것이 성능을 향상시킨다는 것을 발견하였다.

###### CUNI at WMT23 General Translation Task: MT and a Genetic Algorithm (https://aclanthology.org/2023.wmt-1.8/)
- Anthology ID: 2023.wmt-1.8 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 이 논문은 Charles 대학의 팀이 WMT23 General 번역 과제 (영어에서 체코어 및 체코어에서 우크라이나어 번역 방향) 에 대한 기여를 소개한다.
    2. CUNI-GA는 CUNI-Transformer 및 CUNI-DocTransformer 두 개의 다른 시스템이 생성한 번역 후보에 대해 새로운 n-best list reranking 및 수정 방법을 적용하여 달성되었다.
    3. 우리의 방법은 유전 알고리즘과 MBR 디코딩을 사용하여 특정한 메트릭에 대해 최적의 번역을 탐색하고, 이는 ChrF, BLEU, COMET22-DA 및 COMET22-QE-DA의 가중 조합으로 이루어진다. 우리의 제출은 제약된 트랙에서 첫 번째이며 다양한 자동 메트릭에서 최고 수준의 제약이 없는 시스템과 경쟁력 있는 성능을 보여준다.

###### SKIM at WMT 2023 General Translation Task (https://aclanthology.org/2023.wmt-1.9/)
- Anthology ID: 2023.wmt-1.9 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. SKIM 팀은 기본 모델 훈련, 데이터 확장을 위한 역번역, 역번역 훈련 데이터를 사용하는 몇 가지 최종 모델의 재훈련을 포함한 일반적인 프로시저를 사용하여 앙상블 트랜스포머 모델을 구축했다.
    2. 각 최종 모델은 10.5B 개의 매개변수로 구성되어 있으며, 디코더에서 self-attention과 cross-sublayer를 교차+자기 어텐션 서브레이어로 대체했다.
    3. SKIM 팀은 13개의 다른 모델에서 생성된 70개의 번역 후보 중에서 가장 좋은 후보를 선택하기 위해 COMET 및 COMET-QE를 사용하는 MBR 재순위 메소드를 사용했으며, 트랜스포머 모델의 훈련 데이터에 데이터 증강 및 선택 기법을 적용했다.

###### KYB General Machine Translation Systems for WMT23 (https://aclanthology.org/2023.wmt-1.10/)
- Anthology ID: 2023.wmt-1.10 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 이 논문은 WMT 2023 일반 기계 번역 공유 작업을 위한 신경망 기계 번역 시스템 구축 방법에 대해 설명한다. 모델은 Transformer 아키텍처의 기본 설정을 기반으로 하며, 다양한 전략을 통해 성능을 최적화한다.
    2. 모델의 능력을 향상시키기 위해 미리 학습 된 모델을 확장 데이터셋으로 fine-tuning하는 전처리 기법을 사용한다. 번역 품질을 더욱 향상시키기 위해 전처리 및 후처리 기술을 사용한다.
    3. 컴팩트한 모델과 정제된 데이터의 시너지를 통해 예외적인 정확도를 달성하기 위해 효율적인 모델 훈련에 중점을 두었으며, 영어에서 일본어 및 일본어에서 영어로의 번역을 위해 N-best 랭킹에 의한 앙상블 학습도 수행하였다.

###### Yishu: Yishu at WMT2023 Translation Task (https://aclanthology.org/2023.wmt-1.11/)
- Anthology ID: 2023.wmt-1.11 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 본 논문은 WMT 2023 Universal Translation Shared Task를 위해 개발된 Dtranx AI 번역 시스템을 소개한다. 영어에서 중국어로의 번역과 중국어에서 영어로의 번역 두 가지 언어 방향으로 팀이 참여했다. 
    2. 특히 우리는 중국어에서 영어로의 모델의 효과성을 높이기 위해 이중 언어 모델을 구현하는 데 초점을 맞췄다. 데이터 코퍼스 필터링, 모델 크기 조절, sparse expert model (특히 어댑터와 Transformer 모델) 등 다양한 기술을 사용했다.
    3. 자동 평가 결과, 우리 시스템은 영어-중국어 부문에서 1위, 중국어-영어 부문에서 2위를 차지했다.

###### PROMT Systems for WMT23 Shared General Translation Task (https://aclanthology.org/2023.wmt-1.12/)
- Anthology ID: 2023.wmt-1.12 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 본 논문은 WMT23 Shared General Translation Task에 대한 PROMT의 제출 내용을 설명한다. 올해에는 영어에서 러시아어로 번역하는 방향과 러시아어에서 영어로 번역하는 방향 두 가지에 참가하였다. 
    2. 우리는 MarianNMT 툴킷을 사용하여 transformer-big 구성으로 모델을 훈련시켰고, 텍스트 인코딩을 위해 BPE를 사용하였다. 모델은 규제되지 않았고, 자동 평가 메트릭에 따라 양방향으로 경쟁력 있는 결과를 얻었다.

###### AIST AIRC Submissions to the WMT23 Shared Task (https://aclanthology.org/2023.wmt-1.13/)
- Anthology ID: 2023.wmt-1.13 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 본 논문에서는 AIST AIRC 팀이 WMT 2023 General Translation 과제에 제출한 NMT 시스템의 개발 과정을 설명한다.
    2. 우리는 영어, 독일어, 일본어 사이의 번역을 위해 constrained track 모델을 학습하였다.
    3. 최종 모델을 학습하기 전에 parallel 및 단일 언어 데이터를 걸러내고, iterative back-translation 및 parallel data distillation을 수행하여 non-autoregressive 모델 학습에 사용하였다.

###### MUNI-NLP Submission for Czech-Ukrainian Translation Task at WMT23 (https://aclanthology.org/2023.wmt-1.14/)
- Anthology ID: 2023.wmt-1.14 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 우리는 기계 번역된 텍스트, 러시아어 텍스트 및 기타 노이즈를 제거하기 위해 데이터를 철저히 정제하였다.
    2. 우리는 TorchScale 라이브러리의 DeepNorm 변형을 사용하여 18개의 인코더 레이어와 6개의 디코더 레이어를 가진 transformer 아키텍처로 시스템을 훈련시켰다.
    3. 초기 시스템에서는 HFT 토크나이저를 사용하였고, 최종 시스템에서는 HFT에서 파생된 커스텀 토크나이저를 사용하였다.

###### Exploring Prompt Engineering with GPT Language Models for Document-Level Machine Translation: Insights and Findings (https://aclanthology.org/2023.wmt-1.15/)
- Anthology ID: 2023.wmt-1.15 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 본 연구에서는 WMT 2023 General Translation 공유 작업을 위한 Lan-Bridge 번역 시스템을 설명한다. 우리는 영어-중국어 양방향으로 참가하였으며, 대용량 모델의 등장으로 문서 수준 기계 번역 분야에서 많은 변화가 있었다고 말할 수 있다.
    2. 우리는 GPT-3.5와 GPT-4와 같은 모델의 발전에 집중하여 작업했으며, 여러 prompt 기반 실험을 수행하였다. 우리의 목표는 문서 수준 기계 번역에서 최적의 인간 평가 결과를 얻는 것이며, 이를 통해 일반 트랙에서 최종 결과를 제출하였다.

###### Treating General MT Shared Task as a Multi-Domain Adaptation Problem: HW-TSC’s Submission to the WMT23 General MT Shared Task (https://aclanthology.org/2023.wmt-1.16/)
- Anthology ID: 2023.wmt-1.16 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 이 논문은 중국어-영어 동시 번역에서 Huawei Translate Services Center (HW-TSC)의 참가 결과를 보여준다. Transformer 아키텍처를 사용하여, 매개변수 크기가 큰 변형 모델을 통해 최고의 성능을 얻는다.
    2. 제공된 대규모 이중 및 단일 언어 데이터에 대해 세밀한 전처리와 필터링을 수행한다.
    3. Regularized Dropout, Bidirectional Training, Data Diversification, Forward Translation, Back Translation, Alternated Training, Curriculum Learning 및 Transductive Ensemble Learning과 같은 모델 개선 전략을 주로 사용하여 경쟁력 있는 결과를 얻었다.

###### UvA-MT’s Participation in the WMT 2023 General Translation Shared Task (https://aclanthology.org/2023.wmt-1.17/)
- Anthology ID: 2023.wmt-1.17 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 이 논문은 WMT 2023 공유 과제에 대한 UvA-MT의 제출 내용을 설명한다. 우리는 제약된 트랙에서 두 가지 방향인 영어 ↔ 히브리어로 참가했다.
    2. 우리는 한 모델을 사용하여 양방향 작업을 처리함으로써 Multilingual Machine Translation (MMT)의 최소한의 설정으로 전통적인 이중 번역과 비교 가능한 결과를 얻을 수 있다는 것을 이 대회에서 입증했다.
    3. 백 번역, 재매개 변수화된 임베딩 테이블, 과업 지향적 fine-tuning과 같은 효과적인 전략을 포함하여 영어 → 히브리어 및 히브리어 → 영어 방향 모두에서 경쟁력 있는 최종 결과를 얻었다.

###### Achieving State-of-the-Art Multilingual Translation Model with Minimal Data and Parameters (https://aclanthology.org/2023.wmt-1.18/)
- Anthology ID: 2023.wmt-1.18 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 이 논문에서는 WMT 2023 General Machine Translation Task를 위해 13개의 언어 방향으로 기계 번역 모델을 개발하였다. 다국어 데이터셋을 사용하여 디코더만을 가진 아키텍처를 채택하고, 고품질의 병렬 말뭉치를 사용하여 모델을 세밀하게 튜닝하여 번역 작업을 수행할 수 있도록 하였다.
    2. 자동 평가 메트릭에 의하면, 이 모델은 영어에서 러시아어, 독일어, 우크라이나어로의 번역 방향에서 1위를 차지하였다. 또한 영어에서 체코어, 히브리어, 히브리어에서 영어, 우크라이나어에서 영어로의 번역 방향에서 2위를 차지하였다.
    3. 13개의 번역 방향을 모두 커버하는 이 다국어 모델은 GPT-4와 비슷한 수준의 성능을 보여주고, 7개의 번역 방향에서는 GPT-4보다 높은 BLEU 점수를 기록하였다.

###### IOL Research Machine Translation Systems for WMT23 General Machine Translation Shared Task (https://aclanthology.org/2023.wmt-1.19/)
- Anthology ID: 2023.wmt-1.19 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. IOL Research 팀은 WMT23 일반 기계 번역 공유 과제에 대한 제출 시스템을 설명한다. 영어에서 중국어 및 중국어에서 영어로 두 가지 번역 방향에 참여했다. 우리의 최종 주요 제출은 제약된 시스템에 속하며, 두 번역 방향 모두에서 공식적으로 제공 된 단일 언어 및 양방향 데이터만을 사용하여 번역 시스템을 훈련시켰다.
    2. 우리의 시스템은 Transformer 아키텍처를 기반으로 하며, pre-norm 또는 deep-norm을 사용하여 더 깊은 모델을 훈련하는 데 도움이되었다. 우리는 역 번역, 데이터 다양화, 도메인 세부 조정 및 모델 앙상블과 같은 방법을 사용하여 번역 시스템을 구축했다.
    3. 특히 데이터 정제 프로세스와 데이터 확대를 위해 상당한 양의 단일 언어 데이터를 활용하는 우리의 신중한 데이터 정리 방법을 언급할만한 중요한 측면이다. 기준 시스템과 비교하여 우리의 제출은 BLEU 점수에서 큰 개선을 보였다.

###### GTCOM and DLUT’s Neural Machine Translation Systems for WMT23 (https://aclanthology.org/2023.wmt-1.20/)
- Anthology ID: 2023.wmt-1.20 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 글로벌톤 커뮤니케이션과 대련공과대학이 EMNLP의 WMT23 공유 일반 기계 번역(MT) 태스크에 대한 참가 결과를 발표한다. 영어-우크라이나어, 우크라이나어-영어, 체코-우크라이나어, 영어-히브리어, 히브리어-영어, 영어-체코어, 독일어-영어, 일본어-영어 등 8개의 언어 쌍에 참가했다. 특정 제약이나 요구사항 없이 시스템을 설계하여 기계 번역의 다양한 가능성을 탐구했다.
    2. 백번역을 우선순위로 두고, 다국어 번역 모델을 활용하며 성능을 향상시키는 세부조정 전략을 도입했다. 또한, 인간 주석을 활용하여 고품질의 훈련 데이터를 생성하는 새로운 데이터 생성 방법을 제안했고, 이로써 시스템 성능을 향상시켰다. 인공평가 결과, 우리 시스템은 우크라이나어-영어, 히브리어-영어, 영어-히브리어, 독일어-영어에서 BLEU 점수 기준으로 1위를 차지했다.
    3. (추가) 백번역(backtranslation): 목표 언어로 번역한 훈련 데이터를 다시 원래 언어로 번역하여 다양한 예문을 얻는 방법. 다양한 예문을 통해 모델의 성능을 향상시킬 수 있다.

###### RoCS-MT: Robustness Challenge Set for Machine Translation (https://aclanthology.org/2023.wmt-1.21/)
- Anthology ID: 2023.wmt-1.21 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. Robust Challenge Set for Machine Translation (MT)로 디자인된 RoCS-MT는 맞춤법 오류, 모음 삭제, 약어 등과 같은 비표준적인 특성을 가진 UGC(사용자 생성 콘텐츠)를 번역하는 MT 시스템의 능력을 테스트하기 위해 만들어졌다. 
    2. RoCS-MT는 Reddit의 비표준적인 영어 댓글들을 수작업으로 일반화하고 프로페셔널하게 다섯 가지 언어로 번역한 데이터이다.
    3. 비표준 UGC 텍스트를 처리할 때 최신 MT 모델이 직면하는 문제 유형을 분석하고, 품질 평가를 포함한 자동 메트릭을 비교하여 MT 시스템의 강건성을 평가하였다. GPT4는 가장 우수한 성능을 보이지만, RoCS의 소스 측면과 유사한 데이터에서 학습된 모델이기 때문에 일반화 능력에 대한 결론을 이끌어내는 데 주의가 필요하다.

###### Multifaceted Challenge Set for Evaluating Machine Translation Performance (https://aclanthology.org/2023.wmt-1.22/)
- Anthology ID: 2023.wmt-1.22 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 기계 번역 평가는 기계 번역 연구에 있어서 매우 중요한데, 평가 결과는 훈련 전략의 효과를 반영하기 때문이다. 그러므로 공정하고 효율적인 평가 방법이 필요하다. 
    2. 본 논문에서는 소스 문장의 난이도 수준과 평가 결과에 미치는 영향을 분석한 것은 이 논문이 처음이라고 한다. 
    3. 그들은 단어의 난이도, 길이의 난이도, 문법의 난이도, 모델 학습의 난이도 네 가지 측면에서 challenge set을 고려했으며, Zh→En 및 En→Zh를 위한 두 개의 Multifaceted Challenge Set도 공개하였다.

###### Linguistically Motivated Evaluation of the 2023 State-of-the-art Machine Translation: Can ChatGPT Outperform NMT? (https://aclanthology.org/2023.wmt-1.23/)
- Anthology ID: 2023.wmt-1.23 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 본 논문은 8회 기계 번역 학회(WMT23)에서의 공유 과제(context of the Shared Task)에서의 기계 번역 결과를 세밀한 분석한다. 이 분석은 Large Language Model과 새로운 언어 현상을 포함한 업데이트된 테스트 세트를 기반으로 한다. 
    2. GPT-4 번역 결과에 대한 첫 번째 세밀한 언어 분석이며, 독일어-영어, 영어-독일어, 영어-러시아어 언어 방향으로 평가를 진행한다. 
    3. 독일어-영어에서 가장 낮은 정확도를 보이는 현상으로는 관용구와 결과적 서술 동사가 있으며, 영어-독일어에서는 중절 수동태와 명사 형성이 포함된다. 영어-러시아어에서는 관용구와 의미론적 역할이 포함된다. GPT-4는 독일어-영어와 영어-독일어에서 최고 시스템과 동등하거나 비교 가능한 성능을 보이지만, 영어-러시아어에서는 두 번째로 중요한 군집에 속한다.

###### IIIT HYD’s Submission for WMT23 Test-suite Task (https://aclanthology.org/2023.wmt-1.24/)
- Anthology ID: 2023.wmt-1.24 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 이 논문은 영어-독일어 (en-de) 언어 쌍의 기계 번역 시스템 12개를 대상으로 한 WMT23 공유 작업의 테스트 스위트 평가 결과를 요약하고 있다.
    2. 테스트 스위트는 다섯 가지 특정 도메인 (엔터테인먼트, 환경, 건강, 과학, 법률)과 다섯 가지 서로 다른 글쓰기 스타일 (서술적, 판례, 서술적, 리포팅, 기술 글)을 다루고 있다.
    3. 도메인별 및 글쓰기 스타일별 평가에 초점을 맞춘 자동 평가 방법을 통해 결과를 분석한다.

###### Test Suites Task: Evaluation of Gender Fairness in MT with MuST-SHE and INES (https://aclanthology.org/2023.wmt-1.25/)
- Anthology ID: 2023.wmt-1.25 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. WMT-2023 "Test suites" 공유 과제의 일환으로, 이 논문에서는 MuST-SHEWMT23과 INES의 두 가지 테스트 스위트 평가 결과를 요약한다. en-de와 de-en 언어 쌍에 초점을 맞춰, 새롭게 생성된 테스트 스위트를 통해 시스템이 여성과 남성 성별을 번역하고 포괄적인 성별 포함 번역을 생성하는 능력을 조사한다.
    2. 우리는 테스트 스위트와 관련된 메트릭을 논의하고, 인간 평가를 통해 이를 검증한다. 결과는 시스템이 자연스러운 성별 현상에 대해 여성과 남성 성별 형태를 정확하게 번역하는데 합리적이고 비교 가능한 성능을 달성한다는 것을 보여준다.
    3. 그러나 포괄적인 언어 형태의 생성은 모든 평가된 기계 번역 모델에 대해 어려운 과제로 나타나며, 이를 개선하고 연구할 여지가 있다고 제시한다. MuST-SHEWMT23과 INES를 무료로 제공한다.

###### Biomedical Parallel Sentence Retrieval Using Large Language Models (https://aclanthology.org/2023.wmt-1.26/)
- Anthology ID: 2023.wmt-1.26 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 자체 도메인 코퍼스에서 평행문장 필터링 시 도메인 지식의 영향을 조사했습니다. 도메인 지식 없이 자체 도메인 코퍼스에서 문장을 채굴하여 만든 모델의 성능이 좋지 않았으며, 도메인 중심의 필터링을 추가하면 평균 2.3 BLEU 포인트 이상의 성능 향상이 있었습니다. 
    2. 유사하고 도메인에 맞는 문장을 선택하는 데에 큰 언어 모델을 사용했습니다. 초기 비교 가능 코퍼스가 도메인이 아닌 경우에도 도메인 지식의 포함은 문장 선택 방법론에 중요함을 실험적으로 보였습니다.

###### The Path to Continuous Domain Adaptation Improvements by HW-TSC for the WMT23 Biomedical Translation Shared Task (https://aclanthology.org/2023.wmt-1.27/)
- Anthology ID: 2023.wmt-1.27 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 이 논문은 화웨이 번역서비스 센터 (HW-TSC)가 WMT23 바이오의학 번역 과제의 영어↔독일어 (en↔de) 언어 쌍에서 신경망 기계 번역 (NMT) 시스템을 훈련하기 위해 도메인 적응 방법을 제시한다.  
    2. 화웨이의 NMT 시스템은 기존의 교육용 NMT 시스템을 기반으로 하고, 커리큘럼 학습, 데이터 다양화, 전방 번역, 역방향 번역 및 설명적 앙상블 학습을 활용하여 시스템 성능을 더 개선시켰다. 
    3. 전반적으로, 저자들은 공식 최종 평가에서 매우 경쟁력 있는 결과를 달성할 수 있다고 믿고 있다.

###### Investigating Techniques for a Deeper Understanding of Neural Machine Translation (NMT) Systems through Data Filtering and Fine-tuning Strategies (https://aclanthology.org/2023.wmt-1.28/)
- Anthology ID: 2023.wmt-1.28 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 생명 과학 분야에서 데이터 필터를 구현하여 훈련 데이터의 선택을 향상시켰습니다. 이를 통해 생명 과학 분야에 특화된 모델을 fine-tuning하기 위한 실용적인 전략을 개발하고, 훈련 데이터의 필터링 기준을 정의하며, 테스트 데이터에 맞춰 모델 예측 및 fine-tuning 데이터를 비교하여 신경기계번역(NMT) 시스템의 작동에 대해 깊은 통찰력을 얻고자 합니다.
    2. 텍스트메트릭 분석을 사용하여 테스트 세트 내에서 반복되는 세그먼트를 감지하고, 이를 사용하여 mBart-50 기준 모델의 fine-tuning에 사용되는 훈련 데이터를 개선합니다.
    3. 생명 과학 분야에 특화된 훈련 데이터에 대한 fine-tuning 전략을 개발하고, 테스트 세트에 따른 모델 예측 및 fine-tuning 데이터를 비교함으로써 NMT 시스템의 작동에 대한 깊은 통찰력을 얻기 위해 이러한 접근 방식을 사용합니다.

###### MAX-ISI System at WMT23 Discourse-Level Literary Translation Task (https://aclanthology.org/2023.wmt-1.29/)
- Anthology ID: 2023.wmt-1.29 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 본 논문에서는 WMT23 shared task에서 discourse-level literary translation task - constrained track에 참여한 번역 시스템에 대해 설명한다. 
    2. 기존의 Transformer 모델과 최근에 도입된 MEGA 모델을 비교 분석하여, MEGA 모델이 전통적인 Transformer에 비해 장거리 시퀀스를 모델링하는 능력이 향상되었는지 확인한다.
    3. 문학 데이터셋에서 문장을 단락으로 집계하여 언어 모델이 문서 수준의 문맥을 더 효과적으로 활용할 수 있는지 탐구하였고, 이 단락 수준의 데이터는 Transformer와 MEGA 모델 양쪽에서 활용되었다.

###### The MAKE-NMTVIZ System Description for the WMT23 Literary Task (https://aclanthology.org/2023.wmt-1.30/)
- Anthology ID: 2023.wmt-1.30 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. MAKE-NMTVIZ 시스템은 WMT 2023 Literary task를 위해 훈련된 시스템으로, mBART50 모델을 GuoFeng corpus 데이터로 fine-tuning 한다.
    2. contrastive1 submission에서는 fine-tuned concatenation transformer를 사용하여 sentence-level transformer를 구현하고, document-level에서 fine-tuning을 진행한다.
    3. contrastive2 submission에서는 sentence-level transformer model을 구현하여 general data로 훈련하고, sentence- vs document-based training의 영향을 다양한 관점에서 비교한다.

###### DUTNLP System for the WMT2023 Discourse-Level Literary Translation (https://aclanthology.org/2023.wmt-1.31/)
- Anthology ID: 2023.wmt-1.31 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. DUTNLP Lab은 문맥 수준의 중국어에서 영어 번역에 대한 WMT23 과제에 대한 사전 송부 기술을 설명한다. 
    2. 주된 방법론은 다양한 prompt 전략을 가진 대형 언어 모델을 활용하여 문맥 수준의 신경망 기계 번역의 잠재력을 탐색하는 데 있다.
    3. 실험 결과, 대형 언어 모델을 기반으로 한 적절한 prompt 전략을 선택하는 것은 전통적인 모델 학습 방법에 비해 번역 성능을 상당히 향상시킬 수 있다는 것을 보여준다.

###### HW-TSC’s Submissions to the WMT23 Discourse-Level Literary Translation Shared Task (https://aclanthology.org/2023.wmt-1.32/)
- Anthology ID: 2023.wmt-1.32 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. WMT23 Discourse-Level Literary Translation 공유 태스크에 대한 HW-TSC의 제출을 소개한다. 이 논문에서는 기본적으로 sentence-level transformer를 사용하고 domain 적응과 discourse modeling을 통해 discourse-level 기능을 향상시킨다.
    2. domain 적응을 위해 역 번역(Back-Translation), 직진 번역(Forward-Translation) 및 데이터 다양화(Data Diversification)를 사용한다.
    3. Discourse modeling을 위해 Multi-resolutional Document-to-Document Translation 및 TrAining Data Augmentation과 같은 전략을 적용한다.

###### TJUNLP:System Description for the WMT23 Literary Task in Chinese to English Translation Direction (https://aclanthology.org/2023.wmt-1.33/)
- Anthology ID: 2023.wmt-1.33 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 테스트를 위해 사용된 기본 모델은 트랜스포머(Transformer) 기반의 MOE(Mixture of Experts) 모델이며, 훈련 데이터셋이 상대적으로 작기 때문에 희소 모델을 강화하기 위해 데이터 증강 기술을 활용했다.
    2. 이를 위해 먼저 훈련 데이터셋에서 기본 트랜스포머 기반 밀집모델(dense model)을 훈련시키고, 이 모델을 사용하여 초기화된 MOE 기반 번역 모델을 구축하여 훈련시켰다.
    3. 실험 결과, 이 방법은 신경망 기계 번역 성능을 효과적으로 향상시킬 수 있음을 보여준다.

###### Machine Translation for Nko: Tools, Corpora, and Baseline Results (https://aclanthology.org/2023.wmt-1.34/)
- Anthology ID: 2023.wmt-1.34 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 현재는 수천만 명이 사용하는 서아프리카의 Nko 언어를 위한 사용 가능한 기계 번역 시스템이 없다. 이 문제를 해결하기 위해, 사용 가능한 대화형 평행 텍스트 모음을 개발하기 위한 도구, 데이터 리소스, 기준 결과를 제시한다.
    2. Fria∥el은 협업형 텍스트 가공 소프트웨어로, 품질 관리를 위해 편집기반 워크플로를 통합한다.
    3. FLoRes-200와 NLLB-Seed 코퍼스는 Nko와 함께 204개와 40개의 다른 언어와 2,009개와 6,193개의 고품질 번역으로 확장되었다.
    4. nicolingua-0005는 130,850개의 평행 문장과 300만개 이상의 Nko 단어를 포함하는 볼링귀언어와 이중 언어 코퍼스이다. 그리고 최고 모델은 FLoRes-devtest에서 영어-Nko chrF++ 30.83의 점수를 받았다.

###### TTIC’s Submission to WMT-SLT 23 (https://aclanthology.org/2023.wmt-1.35/)
- Anthology ID: 2023.wmt-1.35 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 이 논문은 스위스-독일 수화 (DSGS)에서 독일어로의 수화 번역 작업에 대한 TTIC의 참여에 대해 설명한다. 
    2. 기존의 광학 주석(gloss annotations)과 같은 비용이 많이 드는 레이블 의존적인 전통적인 방식 대신, 대규모 자가 지도 사전 학습의 이점을 수화 번역 작업에 사용하는 방법에 초점을 맞춘다.
    3. 제안된 모델은 이미지 인코딩을 위한 VideoSwin transformer와 텍스트 대신 VideoSwin 특징을 입력으로 받도록 조정된 T5 모델로 구성되어 있다.

###### KnowComp Submission for WMT23 Sign Language Translation Task (https://aclanthology.org/2023.wmt-1.36/)
- Anthology ID: 2023.wmt-1.36 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 수화 번역(Sign Language Translation, SLT)은 수화 동작을 정확하게 해석하고 이를 말이나 쓰기로 번역하는 복잡한 작업이다. 이 논문에서는 gloss-free 방법을 제안하여 텍스트 소스 문맥이 없는 SLT에서도 효율적으로 작동되는 모델을 구축한다.
    2. 기존의 방법은 수화 동작의 gloss annotation을 사용하여 동작을 구별하고 모델이 이를 학습할 수 있도록 도와준다. 그러나 다국어를 커버하기 위해 gloss로 주석을 추가하는 것은 비용이 많이 들고 현실적으로 어렵다.
    3. 이 논문에서 제안하는 시스템은 비주석 방식이며 시각 추출기와 번역 텍스트를 생성하는 생성 모델로 구성되어 있다. 또한 시각 추출기의 임베딩 공간을 생성기의 임베딩 공간과 일치시키는 임베딩 정렬 블록을 사용한다.

###### A Fast Method to Filter Noisy Parallel Data WMT2023 Shared Task on Parallel Data Curation (https://aclanthology.org/2023.wmt-1.37/)
- Anthology ID: 2023.wmt-1.37 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 기계 번역(MT) 시스템의 효과성은 훈련 데이터셋의 품질과 밀접하게 연결되어 있다. 이 논문에서는 정확한 번역을 대표하는 문장 쌍이나 문서를 찾는 것이 주요 과제라고 소개한 후, WMT2023 공유 과제에 대한 결과를 제시한다.
    2. 공유 과제에서는 MT 모델의 훈련과 평가를 위한 고품질 병렬 코포라를 만들기 위해 데이터의 정렬과 필터링을 수행하는 방법을 평가한다.
    3. 사전과 규칙 기반 방법의 조합을 활용하여 데이터의 품질과 일관성을 보장하는 접근 방식을 제안하고, 기준 시스템에 비해 가장 높은 1.6 BLEU 점수 향상을 달성하였다. 테스트 세트 전체에 일관된 향상이 보여지며, 이는 접근 방식의 효율성을 시사한다.

###### A Sentence Alignment Approach to Document Alignment and Multi-faceted Filtering for Curating Parallel Sentence Pairs from Web-crawled Data (https://aclanthology.org/2023.wmt-1.38/)
- Anthology ID: 2023.wmt-1.38 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 이 논문에서는 WMT23 공유 작업을 위한 AST의 제출 내용을 설명하여, 웹 스크랩된 텍스트로부터 데이터를 수정하는 두 가지 접근 방식에 대한 실험을 진행한다. 
    2. 문장 정렬을 사용하여 데이터에서 문서 정렬을 찾고, 정렬된 문서에서 병렬 문장 쌍을 추출한다. 다른 모든 문장들은 코사인 유사도에 기반하여 매칭하고, 다양한 필터를 적용한다. 
    3. 필터링을 위해 언어 감지, 유창성 분류, 단어 정렬, 다국어 문장 임베딩 모델 계산에 의한 코사인 거리, 그리고 Bicleaner AI를 사용한다. 최고의 모델은 네 개의 평가 세트에서 약 1.9 BLEU 포인트로 베이스라인을 능가한다.

###### Document-Level Language Models for Machine Translation (https://aclanthology.org/2023.wmt-1.39/)
- Anthology ID: 2023.wmt-1.39 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 기계 번역 시스템은 대부분 문장 단위로 작동하며 문서 수준의 메타 정보가 없어, 이러한 제한이 알려져 있음에도 불구하고 문장 수준에 연결된 병렬 훈련 데이터를 대부분 사용한다. 따라서 본문 수준의 단일언어 데이터를 사용하여 컨텍스트에 민감한 번역 시스템을 구축하는 것이 목표이다.
    2. 기존의 접근법을 개선하기 위해 최근 모델 결합 기술을 활용하는 방법을 제안하고, 시스템 결합의 유연성을 높이고 계산 오버헤드를 크게 줄이는 새로운 가중치 기술을 제안한다.
    3. 완전한 평가에서 우리는 우리의 확장이 문서를 대상으로 한 점수를 유의하게 향상시키고 계산적으로 더 효율적임을 보여준다. 그러나 대부분의 경우 다시 훈련해야하는 비용이 들지만 역번역은 더 좋은 결과를 제공하는 것으로 나타났다. 마지막으로 최근 대형 언어 모델의 발전을 고려하여 언어 모델 결합을 탐색한다.

###### ChatGPT MT: Competitive for High- (but Not Low-) Resource Languages (https://aclanthology.org/2023.wmt-1.40/)
- Anthology ID: 2023.wmt-1.40 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 대형 언어 모델 (LLM)은 기계 번역 (MT)을 포함한 다양한 언어 작업을 암묵적으로 학습한다. 하지만, 최근 LLM MT 성능이 평가되지 않은 다양한 언어가 존재한다. 이 논문은 204개 언어에 대한 첫 번째 실험적 증거를 제시하며, GPT 모델은 일부 고능사 원어민 (HRL) 언어에 대해 전통적인 MT 모델의 성능과 유사하거나 뛰어날 수 있지만, 저능사 원어민 (LRL) 언어에서는 일관되게 후퇴한다는 경향을 보인다.
    
    2. 저자들은 일부 고능사 원어민 언어(HRL)에서 GPT 모델의 기존 MT 모델 성능과 유사한 시도를 보여주었지만, 저능사 원어민 언어 (LRL)에서는 전통적인 MT보다 성능이 좋지 않음을 밝혀냈다. 
    
    3. 이 분석은 언어의 자원 수준이 ChatGPT가 해당 언어를 번역하는 상대적 능력을 결정하는 가장 중요한 요소임을 보여주며, ChatGPT는 특히 저능사 원어민 언어와 아프리카 언어에 대해 불리하게 작용한다는 것을 시사한다.

###### Large Language Models Effectively Leverage Document-level Context for Literary Translation, but Critical Errors Persist (https://aclanthology.org/2023.wmt-1.41/)
- Anthology ID: 2023.wmt-1.41 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 최근의 대형 언어 모델 (LLM)은 문장 수준의 번역 작업에 대해 최상의 성능을 보이고 있다. 그러나 문단이나 문서 수준의 번역 능력은 아직 탐구되지 않은 상태이다.
    2. 본 논문에서는 GPT-3.5 LLM을 통해 문단 전체를 한 번에 번역하는 것이 표준적인 문장 단위 번역보다 더 우수한 품질의 번역을 제공함을 인간 평가로 입증하였다.
    3. 문장 수준보다 더 많은 미번역, 문법 오류, 스타일 일관성 부재와 같은 문제가 있으나, 저자의 음성을 유지하기 위해 인간 번역가의 개입이 필요하다는 점을 알 수 있다.

###### Identifying Context-Dependent Translations for Evaluation Set Production (https://aclanthology.org/2023.wmt-1.42/)
- Anthology ID: 2023.wmt-1.42 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 문맥 기계 번역으로의 전환에 대한 큰 장애물은 좋은 평가 메트릭과 테스트 세트의 부재이다. 문맥을 바르게 번역해야 하는 문장은 테스트 세트에서 흔치 않아 COMET, BLEU와 같은 표준 코퍼스 수준의 메트릭의 유틸리티가 감소한다.
    2. 그러나 이러한 문장을 주석 달아 놓은 데이터셋은 드물고 규모가 작으며 몇 개의 언어에 한정되어 있다. 
    3. 이 논문에서는 문맥적 문장을 식별하기 위해 이전 어노테이션 파이프라인을 개선하고 확장하여 MultiPro라는 도구를 만들었다. 이 도구는 성별, 공손함, 대명사의 생물성, 동사 구문 탈락, 모호한 명사 변화 등 다섯 가지 현상을 바르게 번역하기 위해 문맥을 필요로 하는 문장을 선별한다.

###### Machine Translation with Large Language Models: Prompting, Few-shot Learning, and Fine-tuning with QLoRA (https://aclanthology.org/2023.wmt-1.43/)
- Anthology ID: 2023.wmt-1.43 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 큰 규모의 언어 모델은 자연어 생성에서 놀라운 발전을 이루고 있지만, 특히 fine-tuning을 할 때 기계 번역에서의 잠재력은 아직 탐구되지 않은 상태이다.
    2. 이 연구에서는 15개의 공개된 언어 모델을 기계 번역 과제에서 종합적으로 실험하고 성능을 평가한다.
    3. QLoRA라는 효율적인 fine-tuning 방법을 사용하여 프렌치-영어 번역에서 QLoRA fine-tuning은 few-shot learning과 모델을 처음부터 학습하는 것보다 우수한 성능을 보여준다.

###### Towards Effective Disambiguation for Machine Translation with Large Language Models (https://aclanthology.org/2023.wmt-1.44/)
- Anthology ID: 2023.wmt-1.44 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. "의미적 모호성 해결은 기계 번역 분야에서의 중요한 과제로 인식되고 있으며, 최근에는 모호한 문장에 대한 번역 성능을 벤치마킹하는 연구가 해당 분야의 전통적인 NMT 시스템의 한계를 드러냈다."
    2.  "우리는 대용량 언어 모델(LLMs)이 "모호한 문장"을 번역하는 능력을 연구하고, 이들의 명료화 능력을 향상시키기 위해 (a) 문맥 내 학습과 (b) 세련된 모호한 데이터셋에 대한 fine-tuning 두 가지 방법을 제안한다."
    3. "실험 결과, 우리의 방법들은 DeepL과 NLLB와 같은 최첨단 시스템과 비교했을 때 5 개 언어 중 4 개의 언어 방향에서 동등하거나 뛰어난 성능을 보여주었다. 우리의 연구는 기계 번역에서 LLMs를 효과적으로 개선하기 위한 가치있는 통찰력을 제공한다. 우리는 정리된 명료화 코퍼스와 자원들을 https://data.statmt.org/ambiguous-europarl 에서 공유한다."

###### A Closer Look at Transformer Attention for Multilingual Translation (https://aclanthology.org/2023.wmt-1.45/)
- Anthology ID: 2023.wmt-1.45 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 기계 번역에 대한 대표적인 모델인 Transformer는 여러 언어 쌍에 대한 번역을 학습하는 데 좋은 성과를 내었다. 이 논문에서는 다른 언어 쌍을 번역하는 데에서 multilingual Transformer 모델이 어떻게 attention을 기울이는지 조사했다.
    2. 먼저 자동 가지치기를 통해 noise가 많은 head를 제거한 후, self-attention과 cross-attention에서 남은 head의 기능과 행동을 분석했다.
    3. 다른 언어 쌍은 문법과 단어 순서가 다르더라도 같은 기능을 위해 같은 head를 사용하는 경향이 있는 것을 발견했으나, 서로 다른 언어 쌍의 특성은 기능 head에 방해를 주고 head 정확도에 영향을 준다는 것을 밝혀냈다. 또한, 깊은 레이어 cross-attention head는 다른 word 재정렬 옵션을 학습하기 위해 협력하는 것으로 나타났다.

###### Bridging the Gap between Position-Based and Content-Based Self-Attention for Neural Machine Translation (https://aclanthology.org/2023.wmt-1.46/)
- Anthology ID: 2023.wmt-1.46 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. FNet과 MLPMixer와 같은 Position-based token-mixing 접근법은 computer vision과 natural language understanding에 대한 흥미로운 attention 대안으로 알려져 있다. 
    2. rPosNet은 position-based attention을 제안하여 attention weights를 position representations에서 계산하는 multi-head attention의 변형판이다.
    3. 상대적인 위치 표현과 gating 메커니즘을 사용하여 rPosNet은 이전의 position-based 접근법보다 우수한 성능을 보이며, Transformer의 품질과 일치하면서도 학습 후 attention 파라미터를 20% 더 적게 필요로 한다.

###### Visual Prediction Improves Zero-Shot Cross-Modal Machine Translation (https://aclanthology.org/2023.wmt-1.47/)
- Anthology ID: 2023.wmt-1.47 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 최근에는 몇 가지 언어 쌍에 대해 멀티모달 기계 번역(MMT) 시스템이 성공적으로 개발되었으나, 이러한 모델을 훈련시키기 위해서는 소스 언어 텍스트, 타겟 언어 텍스트, 이미지의 튜플이 필요하다. 이 데이터를 얻기 위해서는 비용이 많이 드는 인간의 주석이 필요하므로, 텍스트만 있는 언어 쌍을 위한 모델을 개발하기가 어렵다.
    2. 우리는 새로운 번역 방향으로 기존의 멀티모달 병렬 코퍼스로부터 멀티모달 지식을 전송하는 제로샷 크로스모달 기계 번역 과제를 제안한다.
    3. 우리는 멀티모달 병렬 데이터를 기반으로 시각적 특징을 학습하고 텍스트만 있는 언어 쌍을 위해 유사 특징을 제공하는 새로운 MMT 모델을 도입한다. 이 훈련 방식으로 우리의 MMT 모델이 텍스트만 있는 대응 모델보다 더 성능이 우수함을 보여준다. 추가적인 분석을 통해 시각적 특징의 선택이 중요하며 이미지 인식 번역에서 훈련하고 비슷한 언어 쌍에 기반을 두는 것이 필수적임을 보여준다.

###### The Gender-GAP Pipeline: A Gender-Aware Polyglot Pipeline for Gender Characterisation in 55 Languages (https://aclanthology.org/2023.wmt-1.48/)
- Anthology ID: 2023.wmt-1.48 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 언어 생성 시스템의 성별 편향은 어렵게 해소할 수 있는 문제이다. 이러한 편향의 가능한 원인 중 하나는 학습 및 평가 데이터의 성별 표현 격차일 수 있다.
    2. 이 논문에서는 광범위한 데이터셋의 성별 표현을 보고하기 위한 자동 파이프라인인 Gender-Gap 파이프라인을 제안한다.
    3. 이 파이프라인은 텍스트 내의 성별화된 인칭 대명사들에 대한 다국어 어휘 사전을 활용하여 성별 표현을 계량화한다.

###### Towards Better Evaluation for Formality-Controlled English-Japanese Machine Translation (https://aclanthology.org/2023.wmt-1.49/)
- Anthology ID: 2023.wmt-1.49 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 이 논문에서는 일본어 텍스트의 정도를 자동으로 분류하는 새로운 접근 방식을 제안한다. 
    2. 기존의 자료와 일본의 하원 및 상원 웹사이트에서 스크랩한 공식 문장들을 합친 새로운 데이터셋을 소개하며, 변환기 기반의 분류 모델을 제안하여 벤치마크 데이터셋에서 최고 성능을 달성했다.
    3. 제안된 분류기를 사용하여 큰 언어 모델(Large Language Models)을 사용한 기계 번역의 정도 제어 효과를 연구하는 방법을 제안하였다. 실험 결과는 우리의 접근 방식의 강건성과 효과를 검증하며, LLM을 활용한 정도 제어가 실행 가능한 방법임을 제안한다.

###### There’s No Data like Better Data: Using QE Metrics for MT Data Filtering (https://aclanthology.org/2023.wmt-1.50/)
- Anthology ID: 2023.wmt-1.50 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. Quality Estimation(QE)는 명시적인 참조 없이 기계 번역 결과를 평가하는데 사용되는데, 웹 크롤링 데이터와 같은 많은 양의 텍스트 모음에서 오류가 있는 예제를 감지하는 것이 일반적이지만, QE 모델은 세밀한 품질 차이를 구별하는 데 사용된다.
    2. 우리는 QE 메트릭을 사용하여 훈련 데이터에서 질이 낮은 문장 쌍을 걸러내는 것의 실용성을 분석한다.
    3. 우리는 훈련 데이터에서 가장 품질이 높은 문장 쌍을 선택함으로써 번역 품질을 향상시킬 수 있고, 동시에 훈련 크기를 절반으로 줄일 수 있다는 것을 보여준다.

###### Results of WMT23 Metrics Shared Task: Metrics Might Be Guilty but References Are Not Innocent (https://aclanthology.org/2023.wmt-1.51/)
- Anthology ID: 2023.wmt-1.51 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 이 논문은 WMT23 Metrics Shared Task의 결과를 제시한다. 자동 MT 평가 metric을 제출한 참가자들은 WMT23 News Translation Task에서 경쟁하는 번역 시스템의 출력을 평가하도록 요청받았다.
    2. 작년과 유사하게 MQM을 통해 전문가 기반의 인간 평가를 기반으로 한 우리만의 인간 평가를 수행했으며, metric의 특정 유형의 번역 오류를 포착하고 벌점을 주는 능력을 평가하기 위해 대회 세트 서브태스크를 포함하였다.
    3. 결과는 신경망 기반 metric이 인간 판정과의 상관관계 수준에서 비신경망 metric보다 훨씬 우수함을 선명하게 확인하며, 나쁜 참고 번역이 metric과 인간 판단의 상관관계에 미치는 영향과 새로운 metric의 중요성에 대한 관계를 연구한다.

###### Findings of the WMT 2023 Shared Task on Quality Estimation (https://aclanthology.org/2023.wmt-1.52/)
- Anthology ID: 2023.wmt-1.52 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. WMT 2023 공유 작업에서 뉴럴 머신 번역 시스템의 출력 품질을 예측하는 도전을 하는데, 레퍼런스 번역을 사용하지 않고 단어 수준과 문장 수준에서 품질을 예측하는 것이 목표이다.
    2. 이번 대회에서는 더 세분화되고 설명 가능한 품질 예측 접근 방식을 위해 몇 가지 혁신적인 측면과 확장을 도입했다.
    3. 다양한 언어 쌍에 대해 문장 및 단어 수준의 품질 점수를 얻기 위해 다차원 품질 지표를 사용하는 업데이트된 품질 주석 체계를 도입했으며, 저자원 언어에 대한 데이터도 제공한다.

###### Findings of the Word-Level AutoCompletion Shared Task in WMT 2023 (https://aclanthology.org/2023.wmt-1.53/)
- Anthology ID: 2023.wmt-1.53 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 이 논문은 워드-레벨 자동 완성 (WLAC) 공유 과제의 개요를 제시한다. WLAC는 사람이 입력한 문자열을 포함한 번역 문맥에서 대상 단어를 자동으로 완성하는 것을 목표로 한다. 전체적으로 이전 라운드의 공유 과제 설정을 따르지만, 사람 번역가의 타이핑 과정에서 얻은 문자열을 사용하여 실제 시나리오에서 시스템 성능을 보여주고 테스트 예시를 준비한다는 점에서 두 가지 주요한 차이점이 있다.
    2. 실험 결과에서는 번역 과제가 WLAC 모델의 성능을 향상시키는 데 도움이 된다는 것을 관찰할 수 있다. 또한, 추가 분석 결과에서 의미적 오류가 모든 오류의 상당 부분을 차지하므로, 미래에 이러한 종류의 오류를 고려하는 것이 유망할 것으로 판단된다.

###### Findings of the WMT 2023 Shared Task on Machine Translation with Terminologies (https://aclanthology.org/2023.wmt-1.54/)
- Anthology ID: 2023.wmt-1.54 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. WMT 2023 Terminology Shared Task는 전문 용어를 포함한 텍스트의 기계 번역에 대한 진전 상황을 조사한다. 
    2. 팀들은 Chinese→English, English→Czech, German→English 3개의 언어 쌍에 대해 소스 텍스트와 segment-level 용어 사전을 제공받았다. 
    3. 용어 사전을 포함하는 것은 번역 품질을 향상시키지만, 참조 정보와 동일한 정보를 포함하는 것과 유사한 결과를 내는 것으로 나타났다.

###### Findings of the WMT 2023 Shared Task on Automatic Post-Editing (https://aclanthology.org/2023.wmt-1.55/)
- Anthology ID: 2023.wmt-1.55 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. WMT 공유 작업의 9번째 라운드 결과가 발표되었다. 이 작업은 black-box 기계 번역 시스템의 출력 결과를 인간의 수정을 통해 자동으로 교정하는 것을 목표로 한다. 기존 작년과 마찬가지로 영어→마라티어로 진행되었으며, 여러 도메인에서 데이터가 수집되었다. 
    2. 올해의 데이터는 예전에 비해 매우 어렵다고 판명되었다. 사실, 참가 팀 중 어느 팀도 이미 높은 수준의 초기 번역(기준 TER와 BLEU 점수가 각각 26.6과 70.66)의 품질을 향상시키지 못했다. 
    3. 팀 중 하나가 "늦은" 제출로 인정받아 기준 점수를 넘어선 자동 평가 점수를 얻었다.

###### Findings of the WMT 2023 Shared Task on Low-Resource Indic Language Translation (https://aclanthology.org/2023.wmt-1.56/)
- Anthology ID: 2023.wmt-1.56 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 2023년 WMT에서 개최된 저자가 저자가 비교적 데이터가 적은 인디아어 번역 작업에 대한 결과를 제시하였다.
    2. 참가자들은 영어와 아사메스어, 미조어, 카시어, 매니퓌리어의 4개 언어 쌍에 대한 기계 번역 시스템을 구축하는 것을 요청받았다.
    3. 이 작업을 위해 인디아어 데이터셋인 IndicNE-Corp1.0이 공개되었으며, 자동 평가 지표(BLEU, TER, RIBES, COMET, ChrF)와 인간 평가를 통해 평가가 진행될 것이다.

###### ACES: Translation Accuracy Challenge Sets at WMT 2023 (https://aclanthology.org/2023.wmt-1.57/)
- Anthology ID: 2023.wmt-1.57 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. ACES Challenge Set을 사용하여 WMT 2023에 제출된 segment-level metrics의 성능을 벤치마킹한다. 
    2. WMT 2023에 제출된 metrics 중에서는 명확한 우승자가 없으며, 2023 버전과 2022 버전의 metrics 간의 성능 변화는 매우 다양하다. 
    3. metric 개발자들은 서로 다른 디자인 패밀리의 metrics를 앙상블로 구성하고, 원본에 더 많은 주의를 기울이고 표면적인 겹치기에 덜 의존하는 metrics를 개발하며, 다국어 임베딩이 기계 번역 평가에 미치는 영향을 신중하게 결정해야 한다.

###### Challenging the State-of-the-art Machine Translation Metrics from a Linguistic Perspective (https://aclanthology.org/2023.wmt-1.58/)
- Anthology ID: 2023.wmt-1.58 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 이 연구에서는 8회 기계 번역 컨퍼런스의 Metrics Shared Task에 제출된 최신 기계 번역 메트릭을 평가하기 위해 언어학적으로 도전적인 셋을 사용한다.
    2. 이 도전 셋은 100개 이상의 문법적 현상과 14가지 범주에 걸쳐 3개의 언어 방향에서 155개의 기계 번역 시스템에서 추출한 약 21,000개의 항목을 포함하고 있다.
    3. 언어학적 분석을 기반으로 가장 우수한 성능을 가진 메트릭은 Cometoid22-wmt23(증류 기반 학습 메트릭)가 독일어-영어 및 MetricX-23-c(mT5 인코더-디코더 언어 모형에 기반한 fine-tuned 메트릭)가 영어-독일어 및 영어-러시아어에 대해 각각이다.

###### Tokengram_F, a Fast and Accurate Token-based chrF++ Derivative (https://aclanthology.org/2023.wmt-1.59/)
- Anthology ID: 2023.wmt-1.59 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. "Tokengram_F"는 chrF++에서 영감을 받은 기계 번역 평가 메트릭으로, 단어 n-gram을 토큰화 알고리즘에서 얻은 n-gram으로 대체해 단어간 유사성을 더 잘 캡처할 수 있다.
    2. 기존 평가 메트릭에 비해 더 정확한 대안으로 작용할 수 있다.
    3. Tokengram_F는 Machine Translation에서 사용되는 F-score 기반의 평가 메트릭이다.

###### Embed_Llama: Using LLM Embeddings for the Metrics Shared Task (https://aclanthology.org/2023.wmt-1.60/)
- Anthology ID: 2023.wmt-1.60 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. Embed_llama은 최근에 소개된 Llama 2 Large Language Model (LLM)의 임베딩 레이어를 활용하여 문장을 벡터 공간으로 변환하여 기하학적 및 의미적 유사성을 연결하는 언어 번역 평가 메트릭이다.
    2. Embed_llama은 언어 번역 평가에서 LLM의 임베딩 레이어를 활용하여 문장 간의 의미적 유사성을 측정함으로써 평가지표로 사용한다.
    3. Embed_llama은 기하학적 및 의미적인 접근 방식으로 문장의 유사성을 측정하여 언어 번역 평가를 수행할 수 있다.

###### eBLEU: Unexpectedly Good Machine Translation Evaluation Using Simple Word Embeddings (https://aclanthology.org/2023.wmt-1.61/)
- Anthology ID: 2023.wmt-1.61 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. BLEU 메트릭 대신 임베딩 유사성을 사용하는 eBLEU 메트릭을 제안한다. 이 메트릭은 fastText와 같은 효율적이고 비컨텍스트 단어 임베딩을 사용하여 의미적으로 유사한 단어의 n-gram을 매칭시키는데 사용한다.
    2. WMT23 데이터에서, eBLEU는 BLEU와 ChrF를 약 3.8% 시스템 수준 점수로 능가하며, BERTScore와 -0.9%의 절대적인 차이로 접근한 수치를 보여준다.
    3. WMT22 시나리오에서는 eBLEU가 f101spBLEU와 ChrF를 2.2% ~ 3.6%만큼 능가하는 MQM 점수를 기록한다. MTurk 평가에서는 eBLEU가 3.9% ~ 8.2% (f200spBLEU, COMET-22)의 성능을 보여준다. eBLEU는 전통적인 메트릭과 사전 훈련된 메트릭 사이의 흥미로운 중간지점을 제시한다.

###### Cometoid: Distilling Strong Reference-based Machine Translation Metrics into Even Stronger Quality Estimation Metrics (https://aclanthology.org/2023.wmt-1.62/)
- Anthology ID: 2023.wmt-1.62 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 지식 증류를 활용하여 작은 학생 모델을 만들고 기존의 품질 평가(reference-based metric)를 reference-free 학생 메트릭(QE)으로 증류함으로써 기계 번역 평가 메트릭을 개선한다.
    2. COMET22와 ChrF를 증류하는데 초점을 맞추며, 공식적인 WMT-22 Metrics 평가 작업에서 distilled Cometoid QE 메트릭은 모든 다른 QE 메트릭을 능가하며 reference-based teacher 메트릭과 동등하거나 능가한다.
    3. 우리의 메트릭은 인간의 참값 점수를 직접 볼 수 없으며, 오직 원래 개발자에 의해 인간의 점수에 대해 훈련된 teacher 메트릭만 학습한다. 또한, ChrFoid는 전적으로 인간의 점수가 없는 상태에서, WMT-22 작업에서 teacher 메트릭보다 7% 이상의 정확성을 가지는 것을 확인할 수 있다.

###### MetricX-23: The Google Submission to the WMT 2023 Metrics Shared Task (https://aclanthology.org/2023.wmt-1.63/)
- Anthology ID: 2023.wmt-1.63 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 이 보고서는 WMT23 Metrics Shared Task에 대한 MetricX-23 제출 내용과 어떤 메트릭스를 제출할지 결정하는데 기반이 된 실험에 대한 개요를 제공한다.
    2. 제출한 3가지 버전은 모두 학습된 회귀 기반 메트릭스로, 학습에 사용된 데이터와 초기화에 사용된 사전 훈련 언어 모델이 다양하게 다르다.
    3. 실험 결과로는 (1) 어떤 감독 학습 데이터를 사용할지, (2) 학습 레이블을 정규화하는 방식이 어떤 영향을 미치는지, (3) 합성 훈련 데이터의 양, (4) 메트릭스 성능과 모델 크기의 관계, (5) 다른 사전 훈련 언어 모델로 메트릭스를 초기화하는 효과 등에 대한 결과를 보고한다.

###### GEMBA-MQM: Detecting Translation Quality Error Spans with GPT-4 (https://aclanthology.org/2023.wmt-1.64/)
- Anthology ID: 2023.wmt-1.64 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. GEMBA-MQM는 사람의 참고 번역 없이 품질 평가 설정에서 번역 품질 오류를 감지하기 위한 GPT 기반 평가 메트릭이다.
    2. GEMBA-MQM은 LLM (large language models)의 힘을 활용하여 GPT-4 모델에 쿼리를 보내어 오류 품질 범위를 표시하는 고정된 세 개의 프롬프트 기술을 사용한다.
    3. 기존 방법들과 비교했을 때 GEMBA-MQM은 언어에 중립적인 프롬프트를 가지고 있어 새로운 언어에 대해서는 수동 프롬프트 준비가 필요 없다. 단, GPT 모델에 의존하기 때문에 학문적인 작업에서 다른 방법들과 비교해 성능 향상을 입증하는 데 주의가 필요하다.

###### Metric Score Landscape Challenge (MSLC23): Understanding Metrics’ Performance on a Wider Landscape of Translation Quality (https://aclanthology.org/2023.wmt-1.65/)
- Anthology ID: 2023.wmt-1.65 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. "The Metric Score Landscape Challenge (MSLC23)" 데이터셋은 기계번역 (MT) 품질의 넓은 범위에 대한 메트릭 점수를 이해하기 위해 고안되었다. 이 데이터셋은 WMT23 일반 과제 테스트셋에서 낮은부터 중간 품질의 MT 출력 모음을 제공한다.
    2. 이 데이터셋과 과제에 제출된 고품질 시스템을 함께 사용하여, 다양한 수준의 번역 품질에서 메트릭 점수를 더 잘 해석할 수 있다.
    3. 이 논문에서는 이보다 더 넓은 번역 품질 범위에서 메트릭의 특성을 시각화하고 분석한다.

###### MEE4 and XLsim : IIIT HYD’s Submissions’ for WMT23 Metrics Shared Task (https://aclanthology.org/2023.wmt-1.66/)
- Anthology ID: 2023.wmt-1.66 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 이 논문은 WMT2023 공유 메트릭스 작업에 대한 기여를 설명하는데, 두 가지 다른 평가 접근 방식인 (a) 비지도 기준 메트릭과 (b) 지도 기준 메트릭을 포함하고 있다. 
    2. MEE4는 단어 임베딩을 활용하여 언어적 특징을 수량화하는 비지도, reference-based 평가 메트릭이다. 
    3. 반면에 XLsim은 Siamese Architecture를 사용하여 과거 WMT 뉴스 번역 공유 작업의 직접 평가 (DA)에 대한 회귀를 수행하는 지도, reference-based 평가 메트릭이다.

###### Quality Estimation Using Minimum Bayes Risk (https://aclanthology.org/2023.wmt-1.67/)
- Anthology ID: 2023.wmt-1.67 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. MBR decoding과 BLEURT와 같은 신경망 효용 메트릭을 사용하여 고품질 기계 번역을 생성하는 것이 효과적이라는 것이 알려져 있다.
    2. 우리는 MBR 디코딩의 기술을 사용하여 레퍼런스 없는 품질 측정 메트릭을 개발한다.
    3. 우리의 방법은 evaluator 기계 번역 시스템과 레퍼런스 기반 유틸리티 메트릭을 사용하여 모델의 품질 측정 점수를 계산한다.

###### Evaluating Metrics for Document-context Evaluation in Machine Translation (https://aclanthology.org/2023.wmt-1.68/)
- Anthology ID: 2023.wmt-1.68 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. SLIDE는 WMT 2023 메트릭스 과제에 제출된 새로운 지표로, 테스트 세트에서 문서에 고정된 길이의 창을 만들어 청크를 연결하고, 한 번에 단위로 평가하는 비참조 품질 추정 메트릭이다.
    2. SLIDE는 이전의 문맥을 고려하지 않는 지표에 비해 두 개의 WMT22 평가 캠페인에서 큰 개선을 보여주었다.
    3. SLIDE는 COMET을 사용하여 점수를 매길 수 있도록 구현되었다.

###### Semantically-Informed Regressive Encoder Score (https://aclanthology.org/2023.wmt-1.69/)
- Anthology ID: 2023.wmt-1.69 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 기계 번역은 소스 텍스트를 다른 언어로 번역하는 자연어 생성(NLG) 문제로, 평가 메트릭을 필요로 한다. 
    2. 인간의 평가는 비용과 시간이 많이 드는 문제이므로, 전문가 평가와의 상관관계에서 대폭 향상된 자동 기계 번역 평가 결과를 얻기 위해 사전 훈련된 transformer 구조와 대형 언어 모델(LLM)이 등장한 지난 몇 년 동안 많은 발전이 있었다. 
    3. 우리는 MRE-Score, seMantically-informed Regression Encoder Score를 도입하여 회귀 인코더 및 대조적 사전 훈련을 기반으로 한 자동 기계 번역 평가 시스템을 구축하는 접근 방법을 제안한다.

###### Empowering a Metric with LLM-assisted Named Entity Annotation: HW-TSC’s Submission to the WMT23 Metrics Shared Task (https://aclanthology.org/2023.wmt-1.70/)
- Anthology ID: 2023.wmt-1.70 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 이 논문은 WMT23 metrics 공유 작업에 대한 Huawei 번역 서비스 센터 (HW-TSC)의 참가를 소개하고, KG-BERTScore와 HWTSC-EE-Metric 두 가지 지표를 제출한다.
    2. KG-BERTScore는 참조 없는 메트릭으로, segment-level 및 system-level 점수를 제공할 수 있다. HWTSC-EE-Metric은 참조 있는 메트릭으로, system-level 점수만 제공할 수 있다.
    3. 우리의 메트릭은 이전 연도의 metrics 과제에서 MQM 점수와 상대적으로 높은 상관관계를 보여준다. 특히 system-level 점수 과제에서 여러 언어 쌍에서 새로운 최고 성능을 달성한다.

###### Unify Word-level and Span-level Tasks: NJUNLP’s Participation for the WMT2023 Quality Estimation Shared Task (https://aclanthology.org/2023.wmt-1.71/)
- Anthology ID: 2023.wmt-1.71 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 2023 WMT Quality Estimation (QE) shared task에서 NJUNLP 팀의 제출 결과를 소개합니다. 팀은 (i) 문장 및 단어 수준의 품질 예측과 (ii) 세밀한 오류 범위 감지 두 가지 하위 과제에 대한 영어-독일어 언어 쌍의 예측을 제출했습니다.
    2. 많은 향상을 위해 pseudo data 기법을 NJUQE 프레임워크를 기반으로 한 QE에 더욱 탐구했습니다. WMT 번역 작업의 병렬 데이터를 사용하여 pseudo MQM 데이터를 생성합니다. 그 후, XLMR large 모델을 pseudo QE 데이터로 사전 훈련한 뒤, 실제 QE 데이터로 세부 조정합니다.
    3. 실험을 통해 성능 향상에 기여하는 중요한 하이퍼파라미터를 찾기 위해 실험을 수행하였습니다. 또한, 단어 수준 출력을 세밀한 오류 범위 결과로 변환하기 위한 간단한 방법을 제안합니다. 전반적으로, 우리의 모델은 단어 수준 및 세밀한 오류 범위 감지 하위 과제에서 상당한 격차로 영어-독일어에서 최고의 결과를 달성했습니다.

###### HW-TSC 2023 Submission for the Quality Estimation Shared Task (https://aclanthology.org/2023.wmt-1.72/)
- Anthology ID: 2023.wmt-1.72 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 기계 번역 품질을 참조 번역 없이 평가하는 품질 예측(QE)은 핵심 기술이다. 이 연구에서는 Huawei Translation Services Center의 Ensemble-CrossQE라는 문장 수준 QE 공유 작업에 중점을 두었다.
    2. 우리 시스템은 CrossQE를 사용하며, 다국어 기반 모델과 작업 특정 downstream 레이어로 구성되어 있다. 성능을 향상시키기 위해 XLM-R, InfoXLM, RemBERT, CometKiwi와 같은 여러 기본 모델을 finetune하고 앙상블했다.
    3. 또한, 우리는 새로운 corruption 기반 데이터 증강 방법을 도입하여 원래 번역에 삭제, 대체, 삽입 오류를 생성하고 참조 기반 QE 모델을 사용하여 가상 점수를 얻었다. 결과적으로 우리 시스템은 문장 수준 QE 테스트 세트에서 훌륭한 성능을 보여주었으며, 영어-힌디어, 영어-타밀어, 영어-텔루구어 세 언어 쌍에서 1위를 차지했다.

###### Scaling up CometKiwi: Unbabel-IST 2023 Submission for the Quality Estimation Shared Task (https://aclanthology.org/2023.wmt-1.73/)
- Anthology ID: 2023.wmt-1.73 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. Unbabel과 Instituto Superior Técnico는 WMT 2023 Shared Task on Quality Estimation (QE)에 대한 공동 기여를 제시합니다. 우리 팀은 문장 및 단어 수준의 품질 예측과 세부 오류 범위 감지에 모두 참여했습니다.
    2. 모든 작업에서 저희는 CometKiwi 모델 (rei et al., 2022)을 기반으로 구축했습니다. 저희의 다국어 접근 방식은 모든 작업에서 1위를 차지하며, 단어, 범위, 문장 수준에서 품질 예측의 최첨단 성능을 달성했습니다.
    3. 이전 최첨단 모델인 CometKiwi와 비교하여 인간 판단과의 상관관계에서 큰 개선을 보여주고 (스피어만 점수 최대 10점 이상 증가), 2위의 다국어 제출을 절대 점수로 앞서게 했습니다.

###### SurreyAI 2023 Submission for the Quality Estimation Shared Task (https://aclanthology.org/2023.wmt-1.74/)
- Anthology ID: 2023.wmt-1.74 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 레퍼런스가 없는 상황에서 번역의 품질을 평가해야 할 때, Quality Estimation (QE) 시스템은 중요하다.
    2. SurreyAI 팀은 WMT23의 Sentence-Level Direct Assessment 공유 작업에 대한 접근 방식을 설명한다.
    3. TransQuest 프레임워크를 기반으로 한 MonoTQ-InfoXLM-large 방식은 대부분의 언어 쌍에서 기준 모델을 크게 능가하며, 강력한 전략으로 나타난다.

###### MMT’s Submission for the WMT 2023 Quality Estimation Shared Task (https://aclanthology.org/2023.wmt-1.75/)
- Anthology ID: 2023.wmt-1.75 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. WMT 2023 Quality Estimation (QE) shared task 1에서 제출한 논문은 간단한 훈련 데이터 augmentation 접근 방식을 제안한다. 이를 통해 QE 모델의 예측과 사람들의 품질 평가 간의 상관관계를 개선할 수 있다.
    2. 11가지 데이터 augmentation 접근 방식과 6개의 언어 쌍을 활용하여 각 언어 쌍의 원래 훈련 세트에 각 방법을 개별적으로 적용하여 증강된 훈련 세트를 생성한다.
    3. 실험 결과, 영어-독일어, 영어-마라티어, 영어-구자라트어와 같은 언어 쌍에 대해서 Paraphrase Database (PPDB)를 통한 동의어 대체가 가장 큰 성능 향상을 가져오며, 나머지 언어 쌍에 대해서는 문맥 단어 임베딩 기반 단어 삽입, 백 번역, 직접 대치 등의 방법이 더 효과적임을 보여준다.

###### IOL Research’s Submission for WMT 2023 Quality Estimation Shared Task (https://aclanthology.org/2023.wmt-1.76/)
- Anthology ID: 2023.wmt-1.76 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 이 논문은 IOL Research가 WMT 2023 quality estimation 공유 작업에서 제출한 결과를 제시한다. 우리는 문장 수준과 단어 수준의 두 가지 Quality Estimation 작업에 참여하였다. 교차 언어적과 다중 작업 모델을 사용하여 문장 수준의 점수와 단어 수준의 태그를 예측한다. 
    2. 우리는 다양한 다국어 사전 훈련 언어 모델 (PLM)을 백본으로 사용하고 이들을 기반으로 작업 모듈을 구축하여 더 나은 예측을 이룬다. 
    3. 우리의 방법은 각 모델의 예측 결과를 통합하여 성능을 개선하며, 각 모델의 가중치는 Dev 세트의 성능에 의해 자동으로 검색 및 최적화된다. 우리의 방법은 경쟁력 있는 결과를 얻은 것을 보여준다.

###### SJTU-MTLAB’s Submission to the WMT23 Word-Level Auto Completion Task (https://aclanthology.org/2023.wmt-1.77/)
- Anthology ID: 2023.wmt-1.77 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 컴퓨터 지원 번역에서 단어 수준 자동완성(WLAC)은 중요한 역할을 한다. 이 논문에서는 SJTU-MTLAB의 WMT23 WLAC 과제 참가 결과에 대해 설명한다. 
    2. 우리는 기계 번역 작업을 WLAC 작업에 통합하는 합동 방법을 제안한다. 이 제안된 접근법은 다양한 인코더 기반 아키텍처에 적용될 수 있다.
    3. 우리의 접근법은 모델 크기를 크게 줄이면서 성능을 크게 향상시킬 수 있다는 실험 결과를 보여준다.

###### PRHLT’s Submission to WLAC 2023 (https://aclanthology.org/2023.wmt-1.78/)
- Anthology ID: 2023.wmt-1.78 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 본 논문에서는 WMT23의 Word-Level AutoCompletion 공유 작업에 대한 제출 내용을 설명한다. 저자들은 영어-독일어 및 독일어-영어 카테고리에 참여하였다. 이전 연구에서는 문맥이 없을 때의 약점을 해결하기 위해 segment-based interactive machine translation 접근법을 확장하였다. 또한, 사전 학습된 mT5 large 언어 모델을 autocompletion에 사용하기 위해 fine-tuning을 수행하였다.
    2. 영어-독일어 및 독일어-영어 Word-Level AutoCompletion 작업에 참여하여, 이전에 보완되지 못한 약점을 segment-based interactive machine translation와 사전 학습된 mT5 large 언어 모델의 fine-tuning을 통해 해결하였다.
    3. WMT23의 Word-Level AutoCompletion 공유 작업에 제출된 저자들의 방법론을 설명하고, 언어 모델의 fine-tuning을 통해 autocompletion 작업을 수행했다.

###### KnowComp Submission for WMT23 Word-Level AutoCompletion Task (https://aclanthology.org/2023.wmt-1.79/)
- Anthology ID: 2023.wmt-1.79 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 최근 자연어처리에서의 대형 언어 모델(Large Language Models, LLMs)의 성공을 보았지만, 다국어 환경에서의 단어 수준 자동 완성에 대한 LLMs의 잠재력은 아직 충분히 탐구되지 않았다. 
    2. 이 논문에서는 WMT23 단어 수준 자동 완성(WLAC) 과제에 대한 LLM 기반 시스템을 제안하고 성능을 평가한다. 
    3. 실험 결과, 우리의 시스템은 평균적으로 테스트셋에서 29.8%의 정확도를 달성하며, LLMs는 zero-shot 상황에서 WLAC에 어려움을 겪지만 추가적인 예시의 도움을 받으면 성능이 크게 향상되었다.

###### Terminology-Aware Translation with Constrained Decoding and Large Language Model Prompting (https://aclanthology.org/2023.wmt-1.80/)
- Anthology ID: 2023.wmt-1.80 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 번역 시스템에 전문 용어 제약을 주입하여 용어의 정확성을 보장하는 것은 매우 중요하다. WMT 2023 용어 번역 과제에 대한 접근 방식으로 우리는 도메인에 독립적이고 최소한의 수작업이 필요한 번역 후 개선(translate-then-refine) 방식을 채택한다.
    2. 우리는 먼저 워드 얼라인먼트로부터 얻은 가짜 용어 번역을 가진 예시를 사용해 전문 용어를 고려하는 모델을 훈련시킨다. 그리고 우리는 두 가지 후처리 방법을 탐구한다.
    3. 첫째, 우리는 용어 제약의 위반 여부를 파악하기 위해 얼라인먼트 프로세스를 사용하고, 용어 제약에 위반한 경우 해당 단어를 제약을 둔 상태로 다시 디코딩한다. 그리고 대안으로 대용량 언어 모델을 활용하여 용어 제약을 제공함으로써 가설을 개선한다. 수행 결과 우리의 용어인식 모델은 효과적으로 용어를 포함하는 것을 학습하며, 대용량 언어 모델 개선 과정은 용어 인식을 더욱 향상시킬 수 있다.

###### Lingua Custodia’s Participation at the WMT 2023 Terminology Shared Task (https://aclanthology.org/2023.wmt-1.81/)
- Anthology ID: 2023.wmt-1.81 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 기계 번역 결과의 최종 품질을 평가하는 데 기술 용어의 정확한 번역은 중요한 역할을 합니다. 이 논문은 Lingua Custodia의 WMT23 공유 작업에 제출된 용어 공유 작업 관련 제안방법을 제시합니다. 
    2. 우리는 기계 번역 시스템을 적용할 때 용어 제약을 따르려고 합니다. 우리는 비지도학습 방식으로 추출된 합성 사전을 활용하여 기계 학습 훈련 데이터에 주석을 달기로 제안합니다.
    3. 우리는 이러한 훈련 데이터로 학습한 모델을 유연하게 특정 용어로 텍스트를 번역하는 데 사용할 수 있습니다. 우리의 제출된 시스템과 함께 자동 평가 메트릭은 제안한 방법의 효과를 보여줍니다.

###### Domain Terminology Integration into Machine Translation: Leveraging Large Language Models (https://aclanthology.org/2023.wmt-1.82/)
- Anthology ID: 2023.wmt-1.82 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. WMT 2023 Terminology Shared Task에서 우리는 large language model (LLM)을 사용하여 도메인 특화 용어의 번역에 특화된 machine translation (MT) 시스템을 개발하였다. 제안된 용어를 기반으로 한 LLM은 합성된 이중 언어 용어 기반 데이터를 생성하고, MT 모델이 생성한 번역을 사전 승인된 용어를 포함시키면서 후처리하는 데 활용된다.
    2. 우리의 방법은 LLM을 사용해 합성 데이터를 생성하고 generic MT 모델을 fine-tuning한 후 번역을 생성하며, 필요한 용어를 포함하지 않은 번역에는 LLM을 활용하여 용어 제약을 가진 자동 후처리를 수행한다.
    3. 실험 결과, 우리의 접근 방법은 사전 승인된 용어를 번역에 효과적으로 통합하는 데 성공하였고, 블라인드 데이터셋의 용어 통합 수는 평균 36.67%에서 우리의 과정을 거침에 따라 평균 72.88%로 거의 두 배로 증가하였다.

###### OPUS-CAT Terminology Systems for the WMT23 Terminology Shared Task (https://aclanthology.org/2023.wmt-1.83/)
- Anthology ID: 2023.wmt-1.83 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 이 논문은 OPUS-CAT 프로젝트의 WMT 2023 용어 공유 작업에 대한 제출 내용을 설명한다. 
    2. 모든 시스템은 동일한 훈련 파이프라인과 동일한 방법을 사용하여 훈련되었다. 
    3. 훈련 데이터에서 소스 언어 용어를 해당하는 대상 언어 용어와 주석으로 지원하는 용어 지원 기능이 구현되었다.

###### VARCO-MT: NCSOFT’s WMT’23 Terminology Shared Task Submission (https://aclanthology.org/2023.wmt-1.84/)
- Anthology ID: 2023.wmt-1.84 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 최고의 성능을 보이는 신경 기계 번역 (NMT) 모델에서조차 전문적인 용어 변환의 일관성 부족은 문학, 의학 및 비디오 게임 관련용어와 같은 좁은 도메인에서 번역의 품질을 저해한다.
    2. 용어 데이터베이스 구축과 통일성 향상을 위해 종종 사전을 사용하지만, 이는 실제로 구축하고 통합하기 어렵다.
    3. 저자들은 WMT'23 Terminology Shared Task에 제출한 연구를 설명함과 동시에, 용어 인식 기계 번역의 프레임워크를 제안한다. 이 프레임워크는 낮은 지도 환경 설정에서 용어 인식 기계 번역 데이터를 구축하는 자동 용어 추출 과정과 용어 제약 조건을 가진 두 가지 모델 아키텍처로 구성된다. 이 모델들은 중국어에서 영어로 번역하는 WMT'23 Terminology Shared Task 테스트 데이터에서 용어 검출에서 각각 21.51%p와 19.36%p 성능 향상을 보였다.

###### HW-TSC’s Participation in the WMT 2023 Automatic Post Editing Shared Task (https://aclanthology.org/2023.wmt-1.85/)
- Anthology ID: 2023.wmt-1.85 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. HW-TSC는 WMT 2023 자동 후 처리 (APE) 공유 작업에서 영어-마라티어 (En-Mr) 언어 쌍을 위한 기여를 제안한다. 저자들의 방법은 몇 가지 중요한 단계를 포함하는데, APE 모델을 사전 훈련시키고 실제 APE 데이터를 활용하여 모델을 세밀 조정한다. 또한, 외부 기계 번역 (MT) 시스템에서 얻은 후보 번역을 데이터 확장에 도입한다. 이들의 실험은 사전 훈련된 APE 모델이 한정된 크기의 APE 말뭉치와 함께 세밀 조정되었을 때 효과적임을 보여주며, 외부 MT 보강으로 성능을 더 향상시킬 수 있음을 보여준다.
    2. 성능 향상을 위해 오버피팅 문제를 해결하기 위해 훈련 단계에서 R-Drop을 사용한다. APE 시스템은 '과도한 수정' 경향을 가지기 때문에, 최종 출력을 선택하기 위해 문장 단위의 품질 추정 (QE) 시스템을 사용한다.
    3. 실험 결과, HW-TSC 방법은 개발 세트에서 TER과 BLEU 점수를 각각 -2.42와 +3.76 점 향상시킨다.

###### Neural Machine Translation for English - Manipuri and English - Assamese (https://aclanthology.org/2023.wmt-1.86/)
- Anthology ID: 2023.wmt-1.86 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 영어로 작성된 가치있는 정보는 많지만, 지역 언어에 더 익숙한 사람들에게는 이러한 지식에 접근하는 것이 어려울 수 있다. 이 논문에서는 신경망 기계 번역(NMT)을 사용하여 영어와 아사미 어, 매니푸리 어간의 번역에 효과적인 방법을 제안한다.
    2. 기존의 기계 번역 방법 중 하나인 NMT 변형 모델을 사용하여 영어와 아사미어, 매니푸리어간의 번역을 수행하였으며, BLEU 점수로 성능을 평가하였다.
    3. 영어에서 매니푸리어로의 번역에서 15.02 점, 매니푸리어에서 영어로의 번역에서 18.7 점, 영어에서 아사미어로의 번역에서 5.47 점, 아사미어에서 영어로의 번역에서 8.5 점의 BLEU 점수를 달성하였다.

###### GUIT-NLP’s Submission to Shared Task: Low Resource Indic Language Translation (https://aclanthology.org/2023.wmt-1.87/)
- Anthology ID: 2023.wmt-1.87 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. GUIT-NLP 팀은 “Shared Task: Low Resource Indic Language Translation” 에 참가하여, 영어-Mizo, 영어-Khasi, 영어-Assamese와 같은 저자원 언어 쌍에 초점을 맞춘다.
    2. 이 논문에서는 제한된 데이터에 특화된 Neural Machine Translation (NMT) 기법을 깊이 있게 탐구하며 가장 효과적인 방법을 찾는다.
    3. 또한, monolingual 데이터를 활용하여 Back Translation 기법을 영어-Mizo 번역에서 혁신적으로 시스템적으로 적용하고, 이를 통해 모델의 성능을 크게 향상시킨다.

###### NICT-AI4B’s Submission to the Indic MT Shared Task in WMT 2023 (https://aclanthology.org/2023.wmt-1.88/)
- Anthology ID: 2023.wmt-1.88 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 이 논문에서는 Team NICT-AI4B가 2023 WMT Indic MT 과제에 제출한 MT 시스템에 대해 설명한다. 주요 시스템은 3단계로 구성되며, 공식적으로 승인된 단일 언어 및 병렬 말뭉치를 사용하여 공동 노이즈 제거 및 기계 번역 훈련, 역번역 및 원본 및 역번역 병렬 말뭉치를 사용한 기계 번역 훈련으로 구성된다.
    2. 역번역은 번역 품질을 4 BLEU 점까지 크게 향상시킨다는 것을 관찰했다.
    3. 또한, 우리는 무제한 설정에서 2개의 대조 시스템을 개발했으며, 첫 번째 시스템은 공식 병렬 말뭉치와 AI4Bharat et al, (2023)에서 사용된 시드 데이터에서 IndicTrans2 DA 모델을 미세 조정하는 것이고, 두 번째 시스템은 주요 시스템과 위에서 언급한 시스템의 시스템 결합을 수행한다. 
    4. 결과적으로, 우리는 주력되는 4가지 저자원 동북인도 언어에 대해 고품질 기계 번역 시스템을 구축할 수 있었다.

###### Machine Translation Advancements for Low-Resource Indian Languages in WMT23: CFILT-IITB’s Effort for Bridging the Gap (https://aclanthology.org/2023.wmt-1.89/)
- Anthology ID: 2023.wmt-1.89 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 자동 MCQ 생성 시 평가 메트릭이 교육적 가치를 고려하지 못하는 문제를 해결하기 위해 KDA라고 불리는 새로운 평가 메트릭을 제안한다.
    2. 우리의 방법은 사람의 응답을 기반으로 KDA를 측정하고, 미리 학습된 언어 모델을 활용하여 KDA_disc와 KDA_cont라는 자동 평가 메트릭을 제안한다. 
    3. KDA_disc와 KDA_cont는 실제 강의실 세팅에서 사용성과 강한 상관관계를 가지며, n-gram 기반 메트릭과 결합하면 다양한 MCQ 품질 평가를 잘 예측하는 힘이 있다.
    
    1. 최근 NLP 태스크에서 딥 모델은 사람을 뛰어넘는 정확성을 보이지만, Bias나 맞지 않는 패턴에 의존하는 한계가 있다. 
    2. 따라서 이 논문은 contrastive learning과 counterfactual augmentation을 활용하여 딥 모델의 안정성을 높이는 것을 목표로 한다.
    3. 기존의 augmentation 방법과는 달리, 우리의 방법은 "집합적 의사 결정"을 통해 딥 모델의 인과관계 학습에 robust한 지도를 제공하여 성과를 향상시킨다.
    
    1. 'WMT23 IndicMT' 공유 작업을 위해 CFILT-IITB 팀이 제출한 논문이다. 
    2. 이 논문은 작업에 대한 MT 시스템 개발 및 WMT23 IndicMT에 제출된 MT 시스템에 대해 설명하고 있다.
    3. 작은 병렬 말뭉치로 학습된 저 품질의 시스템을 전이 학습을 통해 개선하고 최종으로 제출했다.

###### Low-Resource Machine Translation Systems for Indic Languages (https://aclanthology.org/2023.wmt-1.90/)
- Anthology ID: 2023.wmt-1.90 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 이 논문에서는 영어와 Assamese, Khasi, Mizo, Manipuri 간의 번역을 위한 WMT23 공유 작업에 대한 참가 내용을 제시한다.
    2. 우리는 모든 시스템을 다중 언어 마스킹 언어 모델링 및 노이즈 제거 자동 인코딩 작업에 대해 사전 학습시켰다.
    3. 우리의 주요 시스템은 다시 네 가지 언어 방향에서의 다국어 기계 번역을 위해 사전 학습되었고, 각 언어 쌍에 대해 제한된 병렬 데이터에 대해 따로 사전 조정된다.

###### MUNI-NLP Systems for Low-resource Indic Machine Translation (https://aclanthology.org/2023.wmt-1.91/)
- Anthology ID: 2023.wmt-1.91 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. WMT 2023의 저자 한국어 번역은 대부분 경쟁력 있는 성능에 도달하지 못했으나, 데이터셋과 모델 크기 사이의 관계와 훈련 프레임워크의 영향에 대한 흥미로운 점을 발견했다. 
    2. 이전 연구와는 대조적으로, 단어 임베딩 초기화, 역 번역, 모델 깊이에 대한 몇 가지 초기 실험 결과도 있었다. 
    3. 최종 결과에서는 평가에 사용된 자동 측정 항목들 사이에 불일치가 있었다.

###### NITS-CNLP Low-Resource Neural Machine Translation Systems of English-Manipuri Language Pair (https://aclanthology.org/2023.wmt-1.92/)
- Anthology ID: 2023.wmt-1.92 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 이 논문은 NITSCNLP가 WMT 2023 공유 작업에서 제출한 저소득 지역 언어 번역 작업을 위한 transformer 기반 NMT 시스템에 대해 설명한다. 해당 모델은 영어-마니푸리어 언어 쌍에서 전체적으로 BLEU 점수 22.75 및 26.92를 달성했다.
    2. 영어에서 마니푸리어 및 마니푸리어에서 영어 모델에 대한 실험 결과로는 chrF는 각각 48.35 및 48.64, RIBES는 각각 0.61 및 0.65, TER는 각각 70.02 및 67.62, 그리고 COMET은 각각 0.70 및 0.66이 보고되었다.
    3. 이 모델은 번역 작업에서 상대적으로 좋은 성능을 보여 주며, 특히 저소득 지역 언어에 대한 자동 번역에 유용할 것으로 기대된다.

###### IACS-LRILT: Machine Translation for Low-Resource Indic Languages (https://aclanthology.org/2023.wmt-1.93/)
- Anthology ID: 2023.wmt-1.93 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 지난 10년 동안 기계 번역은 큰 발전을 이루었지만, 인디안 언어의 번역 품질은 여전히 낮아 제한된 양의 병렬 데이터 사용량과 관련이 있다.
    2. 본 논문에서는 특히 영어-마니푸리어와 아사메어-영어와 같은 인디안 언어 쌍을 위한 적은 양의 병렬 훈련 데이터 문제를 완화하기 위한 접근 방식을 제시한다.
    3. 마니푸리에서 영어로의 번역 작업에 대한 저희 주요 제출 시스템은 이 언어 쌍에 대해 최고의 점수를 받았으며, 저희는 자세한 시스템 구축과 과정에서의 발견에 대해 설명한다.

###### IOL Research Machine Translation Systems for WMT23 Low-Resource Indic Language Translation Shared Task (https://aclanthology.org/2023.wmt-1.94/)
- Anthology ID: 2023.wmt-1.94 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. IOL Research 팀은 WMT23 low-resource Indic 언어 번역 공유 작업에 대한 제출 시스템을 설명한다. 
    2. 저자들은 전이학습과 데이터 증강을 통해 목적언어 번역의 품질을 향상시킬 수 있음을 보인다. 
    3. 실험 결과에서 이 방법은 네 개 언어 쌍에 대한 번역의 BLEU 점수를 크게 향상시키는 것으로 나타났다.

###### Trained MT Metrics Learn to Cope with Machine-translated References (https://aclanthology.org/2023.wmt-1.95/)
- Anthology ID: 2023.wmt-1.95 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 인간의 MT(Machine Translation) 평가에 기반을 둔 신경 메트릭은 인간 판단과 잘 상관될 수 있지만, 그 동작 원리가 완전히 이해되지 않는다. 
    2. 이 논문에서는 기준 메트릭과 동일한 메트릭의 학습 버전을 비교 실험을 통해 분석하고, 학습된 메트릭의 경우 기계 번역된 참고 자료에 대한 강건성이 향상되는 것을 발견했다.
    3. 이는 메트릭 학습의 효과가 인간 판단과의 전반적인 상관 관계 향상 이외의 효과를 가질 수 있다는 것을 시사한다.

###### Training and Meta-Evaluating Machine Translation Evaluation Metrics at the Paragraph Level (https://aclanthology.org/2023.wmt-1.96/)
- Anthology ID: 2023.wmt-1.96 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 기계 번역 연구가 문장 이상의 텍스트 번역으로 확장됨에 따라, 자동 평가 메트릭이 더 긴 번역을 평가하는 데 효과적인지 여전히 불명확한 상태이다.
    2. 우리는 기존의 문장 수준 데이터에서 문단 수준 데이터를 만들기 위한 방법을 제안하고, 이러한 새로운 데이터를 사용하여 기존의 문장 수준 평가 메트릭과 문단 수준에서 학습된 학습 메트릭을 벤치마크로 활용하였다. 
    3. 흥미로운 결과로, 우리의 실험 결과는 문장 수준 메트릭을 사용하여 전체 문단의 점수를 매기는 것이 문단 수준 메트릭을 사용하는 것과 동일한 효과를 내는 것으로 나타났다. 이 결과는 참조 기반 평가 작업의 특성 및 문단 수준 번역에서 발생하는 모든 현상을 캡처하는 데 대한 데이터셋의 한계와 관련이 있다고 추측한다.

###### Automating Behavioral Testing in Machine Translation (https://aclanthology.org/2023.wmt-1.97/)
- Anthology ID: 2023.wmt-1.97 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. NLP에서의 행동 테스트는 입출력 행동의 분석을 통해 언어 능력을 자세하게 평가하는 기능을 제공한다. 
    2. 기계 번역에서 이러한 행동 테스트의 적용은 특정 기능과 언어에 국한되어 있으며 수작업으로 된 테스트만을 다루고 있다. 
    3. 이 논문에서는 대규모 언어 모델을 사용하여 다양한 상황에서 기계 번역 모델의 행동을 테스트하기 위한 다양한 소스 문장을 생성하고, 이를 통해 기대된 결과를 확인할 수 있다고 제안한다.

###### One Wide Feedforward Is All You Need (https://aclanthology.org/2023.wmt-1.98/)
- Anthology ID: 2023.wmt-1.98 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. Transformer 아키텍처에서는 Attention과 FFN 두 가지의 구성요소가 있다. Attention은 단어들 간의 관련성을 고려하지만 위치에 상관 없이 처리하고, FFN은 각각의 입력 토큰을 비선형으로 변환한다. 
    2. 이 논문에서는 FFN의 역할을 조사한 결과, FFN은 모델의 매개변수 중 상당 부분이 중복되었다는 것을 발견했다. 따라서 디코더 레이어에서 FFN을 제거하고 인코더 전체에서 동일한 하나의 FFN을 공유하면 매개변수 수를 크게 줄일 수 있다. 
    3. 마지막으로 FFN의 hidden 차원을 늘려서 이 아키텍처를 원래 크기로 다시 확장하면 원래 Transformer보다 정확도와 대기 시간 모두 크게 향상시킬 수 있다.

###### A Benchmark for Evaluating Machine Translation Metrics on Dialects without Standard Orthography (https://aclanthology.org/2023.wmt-1.99/)
- Anthology ID: 2023.wmt-1.99 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Authors: Philipp Koehn | Barry Haddow | Tom Kocmi | Christof Monz 
- Summary: 
    1. 자연어 처리에서 진전하기 위해서는 사용하는 평가 메트릭의 한계를 잘 알고 있어야 중요하다. 본 연구에서는 표준화되지 않은 방언이나 맞춤법이 없는 언어 변종으로 인한 철자 차이에 대한 평가 메트릭의 강건성을 평가했다.
    2. 우리는 영어에서 스위스 독일어 방언 두 가지로의 자동 번역에 대한 인간 번역 및 판단 데이터셋을 수집했다. 우리는 방언 변화에 대한 챌린지 세트를 만들고 기존 메트릭의 성능을 평가하였다. 
    3. 결과적으로, 기존의 메트릭은 스위스 독일어 텍스트 생성 출력을 신뢰할 수 없으며, 특히 세그먼트 수준에서의 평가가 어렵다는 것을 보여주었다. 우리는 표준화되지 않은 방언에 대한 강건성을 높이기 위한 초기 설계 수정사항을 제안하였다.


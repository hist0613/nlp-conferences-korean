# Korean Three-Line Summarizations of Papers 1887-1986 in Findings of the Association for Computational Linguistics: EMNLP 2023
###### InstructSafety: A Unified Framework for Building Multidimensional and Explainable Safety Detector through Instruction Tuning (https://aclanthology.org/2023.findings-emnlp.700/)
- Anthology ID: 2023.findings-emnlp.700 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 언어 모델의 고도로 발전함에 따라 안전 감지 시스템을 개발하는 것이 점점 중요해지고 있으나, 현재 사용 가능한 안전 감지 시스템은 다용도성과 해석 가능성 측면에서 한계가 있다.
    2. 이 논문에서는 7가지 일반적인 안전 감지 서브 태스크를 통합하는 InstructSafety라는 안전 감지 프레임워크를 소개한다.
    3. 다양한 데이터셋과 태스크에서 수행한 실험 결과를 통해 Safety-Flan-T5의 성능이 교육된 기준선과 제공되는 API들과 비교하여 강력함을 입증하고 있다.

###### “A Tale of Two Movements’: Identifying and Comparing Perspectives in #BlackLivesMatter and #BlueLivesMatter Movements-related Tweets using Weakly Supervised Graph-based Structured Prediction (https://aclanthology.org/2023.findings-emnlp.701/)
- Anthology ID: 2023.findings-emnlp.701 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 소셜 미디어는 온라인 사회운동의 형성을 돕는 것으로 사회적 변화의 주요 원동력이 되었다. 그러나 주장하는 입장과 반대하는 의견을 자동으로 이해하는 것은 주석이 달린 데이터를 얻기가 어렵기 때문에 어려운 과제이다.
    2. 우리는 #BackLivesMatter와 관련된 트윗에서 명시적으로 주장을 모델링하는 약한 지도학습 기반의 그래프 기반 접근법을 제안한다.
    3. 우리의 모델은 작은 양의 레이블된 예제를 사용하며, 큰 언어 모델을 사용하여 가상의 학습 예제를 생성하는 것으로 실험한 결과, 수동 주석과 비교하여 비슷한 성능을 달성한다.

###### ClusterPrompt: Cluster Semantic Enhanced Prompt Learning for New Intent Discovery (https://aclanthology.org/2023.findings-emnlp.702/)
- Anthology ID: 2023.findings-emnlp.702 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 사용자 발화로부터 새로운 의도 카테고리를 발견하는 것은 에이전트의 스킬을 확장하는데 매우 중요한 작업이다. 그러나 기존의 메서드들은 의도 간 관계나 클러스터에 더욱 중점을 두고 전이 학습을 수행했다. 이 논문에서는 새로운 의도를 발견하기 위해 Cluster Semantic Enhanced Prompt Learning (CsePL)이라는 새로운 접근 방식을 제안한다. 
    2. 이 방법은 레이블 의미 정렬을 이용해 의도 클러스터의 의미 있는 표현을 학습하고, 이러한 학습된 의도 표현을 새로운 의도를 구별하는 데 사용하여 기존 의도를 억압하고 의도 클러스터를 의미 없는 새로운 의도 클러스터로 만들지 않는다. 
    3. 세 개의 공개 데이터셋에서 범위를 넓게 실험한 결과 우리의 방법이 기존의 방법보다 성능이 우수하며 의미 있는 의도 레이블을 제안하고 새로운 의도를 조기에 감지할 수 있다는 것을 보여주었다.

###### Investigating the Effect of Pre-finetuning BERT Models on NLI Involving Presuppositions (https://aclanthology.org/2023.findings-emnlp.703/)
- Anthology ID: 2023.findings-emnlp.703 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 선험적 지식(presupposition), 담화(discourse), 풍자(sarcasm) 사이의 연결을 탐구하고 전이 학습 시나리오에서 이 연결을 활용하여 NLI 모델의 선험적 지식을 포함한 사례에서의 성능을 개선하기 위한 논문이 제안되었다.
    2. 우리는 사전-세세 조정(pre-finetuning)을 활용하여 NLI 모델을 주의 깊게 선택된 과제에서 사전 조정하고 선험적 지식을 포함한 NLI 사례에서의 성능 향상을 시도한다.
    3. 실험 결과, 이러한 과제에서의 사전-세세 조정은 성능 향상을 이끌어냄을 보여주었다. 추가적인 훈련 데이터가 도움이 되고 있는 경우도 있으나 과제 선택이 성능 향상에 영향을 미친다는 것을 진단 테스트를 통해 확인하였다.

###### MRRL: Modifying the Reference via Reinforcement Learning for Non-Autoregressive Joint Multiple Intent Detection and Slot Filling (https://aclanthology.org/2023.findings-emnlp.704/)
- Anthology ID: 2023.findings-emnlp.704 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 최근 non-autoregressive 접근법의 등장으로 Joint Multiple Intent Detection 및 Slot Filling을 위한 non-autoregressive 모델들이 빠른 추론 속도를 얻었다. 하지만, 대부분의 기존 SLU 모델들은 여러 가지 문제로 인해 참조 의도와 슬롯이 훈련에 적합하지 않을 수 있다.
    2. 이 논문에서는 MRRL이라는 새로운 방법을 제안하여 multiple intent detection 및 slot filling을 위한 non-autoregressive SLU 모델에 대해 수정된 참조를 도입하고 강화학습을 적용한다. 
    3. 실험 결과, MRRL이 기존 기준선 성능을 일관되게 향상시킬 수 있으며, 최고 성능은 MixATIS 데이터셋에서 이전 접근법 대비 3.6의 전체 정확도향상을 보였다.

###### DemoNSF: A Multi-task Demonstration-based Generative Framework for Noisy Slot Filling Task (https://aclanthology.org/2023.findings-emnlp.705/)
- Anthology ID: 2023.findings-emnlp.705 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 최근 프롬프트 기반 생성 프레임워크는 순차적 라벨링 태스크에서 뛰어난 성능을 보이지만, 단순한 템플릿과 전통적인 코퍼스에만 의존하는 것은 알려지지 않은 입력 변동에 대한 일반화에 도전을 제시한다.
    2. 우리는 이 간극을 해결하기 위해 노이즈 슬롯 채우기를 위한 멀티태스크 데모 기반 생성 프레임워크인 DemoNSF를 제안한다. 
    3. 두 가지 벤치마크 실험에서 DemoNSF가 모든 기준선 방법을 능가하고 강력한 일반화 성능을 달성하는 것을 보여준다.

###### SHARCS: Efficient Transformers Through Routing with Dynamic Width Sub-networks (https://aclanthology.org/2023.findings-emnlp.706/)
- Anthology ID: 2023.findings-emnlp.706 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. SHARCS는 입력 샘플의 난이도를 고려한 적응 추론을 위한 기법을 제안한다. 이를 통해 SHARCS는 다양한 분류 작업에서 다른 per-sample 적응 추론 방법들에 비해 정확성과 FLOPs 기준에서 성능을 향상시킨다.
    2. SHARCS는 다양한 아키텍처에서 일반화되며, 압축되고 효율적인 transformer encoder에도 적용하여 효율성을 더욱 향상시킬 수 있다.
    3. SHARCS는 무시할 만한 정확도 하락과 함께 2배의 추론 속도 향상을 제공할 수 있다.

###### Always the Best Fit: Adaptive Domain Gap Filling from Causal Perspective for Few-Shot Relation Extraction (https://aclanthology.org/2023.findings-emnlp.707/)
- Anthology ID: 2023.findings-emnlp.707 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. "Cross-domain Relation Extraction"은 저자가 제안한 "CausalGF"라는 새로운 프레임워크를 사용하여 다른 도메인으로 지식을 전달하여 low-resource 상황에서의 도전에 대응한다. 
    2. 이전 연구는 주로 도메인 간 공유 특성 표현을 통해 지식을 전달하였으나, 각 도메인의 특성에 따라 데이터 편향을 발생시킬 수 있는 각 요소의 영향을 분석하지 않고 있다.
    3. "CausalGF"는 통합된 구조적 인과 모델을 구축하여 구문 구조, 레이블 분포, 엔티티 등의 요소에 대한 인과효과를 측정하고 도메인 특성을 기반으로 동적으로 조정함으로써 도메인 간 격차를 적응적으로 채우는 것을 가능하게 한다.

###### MEGClass: Extremely Weakly Supervised Text Classification via Mutually-Enhancing Text Granularities (https://aclanthology.org/2023.findings-emnlp.708/)
- Anthology ID: 2023.findings-emnlp.708 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 전통적인 텍스트 분류 방법은 비용이 많이 들거나 특화된 도메인에서는 부족할 수 있기 때문에, 클래스 의미어만을 사용하여 text classification을 수행하는 방식이 제안되었다.
    2. 그러나 기존의 방법들은 문서, 문장 또는 단어와 같은 다른 수준의 텍스트 구체성을 독립적으로 다루어, 서로간에 disagreement과 독립적인 컨텍스트들을 고려하지 않는다.
    3. MEGClass는 어휘 및 문장을 동시에 고려하여 저차원 및 고차원의 컨텍스트 신호를 이용하여 text classification을 수행하며, 다른 방법과 비교했을 때 우수한 성능을 보여주었다.

###### Causal Inference from Text: Unveiling Interactions between Variables (https://aclanthology.org/2023.findings-emnlp.709/)
- Anthology ID: 2023.findings-emnlp.709 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 관측 텍스트 데이터로부터 인과 효과를 추정하기 위해서는 잠재 배제변수(latent covariates)를 조정하는 것이 중요하다. 기존 방법들은 처리와 결과에 영향을 미치는 혼동(covariates)에만 초점을 맞추고, 비혼동 혼동 요인을 충분히 고려하지 않아 편향된 인과 효과 추정으로 이어질 수 있다.
    2. 우리는 텍스트로부터 인과 효과를 추정할 때, 다른 변수들 간의 상호작용을 파악하여 비혼동 혼동 요인을 분리시키는 것으로 이 편향을 완화하기 위해 노력한다.
    3. 실험 결과는 우리의 제안 모델이 강력한 기준과 비교하여 상당한 향상을 보였으며, 수익 전화 트랜스크립트에 대한 철저한 분석은 모델이 변수들을 효과적으로 분리할 수 있음을 보여주고, 실제 상황에 대한 추가 조사는 투자자들에게 정보를 제공하여 판단을 돕는다.

###### Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples! (https://aclanthology.org/2023.findings-emnlp.710/)
- Anthology ID: 2023.findings-emnlp.710 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 대형 언어 모델 (LLMs)은 다양한 작업에서 놀라운 성과를 보였다. 그러나 LLM이 정보 추출 (IE) 작업에 대해 일반적으로 경쟁력 있는 몇 가지 샷 솔버인지는 여전히 미개한 문제이다.
    2. 여러 실험을 통해 현재의 고급 LLM이 대부분의 설정에서 성능이 떨어지고 더 느린 응답 시간 및 증가한 예산 요구사항을 가지는 것을 보여준다. 따라서 LLM은 일반적으로 효과적인 소수샷 정보 추출기가 아니다.
    3. 그러나 적절한 프롬프팅 전략으로 LLM이 SLM을 보완하고 SLM이 처리하기 어려운 어려운 샘플을 처리할 수 있다는 것을 보여준다. 또한 LLM과 SLM의 강점을 결합하기위해 적응형 필터링 후 재정렬 패러다임을 제안한다. 이 패러다임에서 SLM은 필터로 작용하고 LLM은 재정렬기 역할을한다. SLM이 식별한 어려운 샘플의 일부를 LLM에 재정렬하도록 유도함으로써 우리의 초기 시스템은 다양한 IE 작업에서 일관된 향상 (평균 2.4% F1 점수 향상)을 안정적으로 달성한다.

###### Prompting and Evaluating Large Language Models for Proactive Dialogues: Clarification, Target-guided, and Non-collaboration (https://aclanthology.org/2023.findings-emnlp.711/)
- Anthology ID: 2023.findings-emnlp.711 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 대형 언어 모델(ChatGPT 등) 기반의 대화 시스템은 맥락 이해와 응답 생성에서 탁월한 능력을 보이지만, 모호한 질의에 대해 명확화 질문을 하지 못하거나 사용자의 불합리한 요청을 거부하는 등의 한계를 가지고 있다.
    2. 따라서 이 논문에서는 Proactive Chain-of-Thought prompting 방법을 제안하여 LLM에 목표 기반 계획능력을 부여하여 프로액티브한 대화 문제를 다룰 수 있는지 분석하였다.
    3. 명확화, 목표 지향, 비협업적 대화라는 프로액티브 대화의 세 가지 측면에 집중하여 LLM 기반 대화 시스템을 종합적으로 분석하고, 향후 연구를 촉진시키기 위한 실험 결과를 제시하였다.

###### Ecologically Valid Explanations for Label Variation in NLI (https://aclanthology.org/2023.findings-emnlp.712/)
- Anthology ID: 2023.findings-emnlp.712 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. NLP 태스크에서 인간의 라벨 다양성이 존재하는데, 모델이 라벨에 대해 해석하는 방법에 영향을 준다는 것을 직접적으로 알기 위해, LiveNLI라는 데이터셋을 구축했다. 
    2. LiveNLI 설명은 사람들이 해석에서 체계적으로 다양할 수 있고, 라벨이 같지만 선택된 이유가 다를 수 있는 것을 확인한다.
    3. 우리는 몇몇 실험에서 prompt large language model이 유효하고 유익한 설명을 생성하는 반면, 그렇지 않은 라벨을 지원하지 않는 설명도 생성한다는 것을 확인했고, 이를 개선할 방향을 제시했다.

###### A Benchmark for Semi-Inductive Link Prediction in Knowledge Graphs (https://aclanthology.org/2023.findings-emnlp.713/)
- Anthology ID: 2023.findings-emnlp.713 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 지식 그래프 (knowledge graph)에서의 반지도 학습 기반의 링크 예측(link prediction)은 새로운 엔티티에 대한 사전에 보지 못한 맥락 정보를 기반으로 사실(fact)을 예측하는 작업이다. 
    2. 본 논문에서는 대규모 지식 그래프에서 반지도 학습 기반의 링크 예측 모델을 평가하기 위한 벤치마크를 제안한다.
    3. 이 벤치마크는 Wikidata5M을 기반으로 하며, KG 구조만을 사용한 transductive task부터 텍스트 언급과 개체에 대한 자세한 설명까지 다양한 정보를 활용한 k-shot 및 0-shot LP task를 제공한다.

###### SummIt: Iterative Text Summarization via ChatGPT (https://aclanthology.org/2023.findings-emnlp.714/)
- Anthology ID: 2023.findings-emnlp.714 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 기존 텍스트 요약 시스템은 최근에 큰 발전을 이루었지만 일반적으로 요약을 한 번에 작성하는 방식이며, 독자의 관심사와 관련된 중요한 세부사항을 누락하거나 창작하는 경우가 있다.
    2. 이 논문에서는 SummIt이라는 반복적인 텍스트 요약 프레임워크를 제안하여 자기 평가 및 피드백을 통해 생성된 요약을 반복적으로 개선하는 것을 가능하게 한다. 
    3. 또한 지식과 주제 추출기를 프레임워크에 통합하여 요약의 충실성과 조절 가능성을 향상시키는 잠재적 이점을 탐구하였으며, Empirical 및 정성적 분석을 통해 프레임워크의 성능을 평가하였다.

###### Orthogonal Subspace Learning for Language Model Continual Learning (https://aclanthology.org/2023.findings-emnlp.715/)
- Anthology ID: 2023.findings-emnlp.715 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 대규모 언어 모델 (LLM)은 언어 이해와 생성에서 탁월한 성능을 보이지만, 과도한 잊기(catastrophic forgetting)라고 알려진 순차적인 다중 작업을 수행할 때 성능이 저하된다. 
    2. 이 논문에서는 연속 학습을 위한 간단하고 효율적인 접근 방식인 orthogonal low-rank adaptation (O-LoRA)를 제안하여 새로운 작업을 학습하는 동안 catastrophic forgetting을 효과적으로 완화한다. 
    3. 실험 결과, O-LoRA는 기존 방법보다 우수한 성능을 보이고, 예전 방식과 비교했을 때 LLM의 일반화 능력을 더 잘 보존한다.

###### Attention-Enhancing Backdoor Attacks Against BERT-based Models (https://aclanthology.org/2023.findings-emnlp.716/)
- Anthology ID: 2023.findings-emnlp.716 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 최근 연구에서는 Backdoor 공격이 자연어 처리 모델의 안전성을 위협할 수 있다고 밝혀졌다. 이 논문에서는 Backdoor 공격의 전략을 조사하여 모델의 취약점을 이해하는 데 도움을 준다.
    2. 대부분의 기존 텍스트 Backdoor 공격은 약한 트리거를 생성하거나 모델 가중치를 수정하는 데 초점을 맞추고 있다. 그러나 이 논문에서는 신경망의 내부 구조와 Backdoor 메커니즘 자체를 공격의 대상으로 삼아 새로운 Trojan Attention Loss (TAL)를 제안한다.
    3. TAL은 이러한 주의 패턴을 직접 조작함으로써 Trojan 행동을 향상시키고, 공격 성공률과 감염률을 높이기 위해 다양한 공격 방법에 적용될 수 있다. BERT, RoBERTa, DistilBERT 등 다양한 Backbone 모델과 Sentiment Analysis, Toxic Detection, Topic Classification 등의 다양한 작업에서 우리의 방법을 검증하였다.

###### Hi-ToM: A Benchmark for Evaluating Higher-Order Theory of Mind Reasoning in Large Language Models (https://aclanthology.org/2023.findings-emnlp.717/)
- Anthology ID: 2023.findings-emnlp.717 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. Theory of Mind (ToM)은 개인의 정신 상태와 타인의 정신 상태에 대해 추론할 수 있는 능력이다. 이 논문은 ToM 연구에 처음으로 3차 이상의 ToM을 다루며, 더 높은 수준의 ToM 과제에서 현재의 언어 모델의 한계를 보여준다.
    2. 새로운 속임수(deception) 메커니즘을 ToM 추론에 반영하였으며, Higher Order Theory of Mind 벤치마크인 Hi-ToM을 소개한다.
    3. 다양한 대형 언어 모델(Large Language Models)을 사용한 실험적 평가 결과, 더 높은 수준의 ToM 과제의 성능이 저하되는 것을 보여주며, 이러한 실패 사례에 대한 철저한 분석과 이러한 결과의 NLP의 미래에 대한 함의를 공유한다.

###### Image and Text: Fighting the same Battle? Super Resolution Learning for Imbalanced Text Classification (https://aclanthology.org/2023.findings-emnlp.718/)
- Anthology ID: 2023.findings-emnlp.718 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 본 논문에서는 이미지와 텍스트 처리 사이의 유사성을 기반으로한 데이터 augmentation인 SRL4NLP를 제안한다. 이 방법은 저해상도 이미지의 문제를 극복하기 위해 고해상도 이미지를 사용하는 것으로, 이미지 처리에서 흔히 사용되는 기술이지만 NLP에서는 처음으로 적용되는 것이다.
    2. 저자들은 이 방법을 텍스트 분류에 적용하고, 긴급 사태 시점에 작성된 트윗을 사용한 긴급도 감지와 같이 어려운 작업에서의 효과를 평가했다.
    3. 저자들은 이 전략이 두 개의 언어로 이루어진 여러 벤치마크 데이터셋에서 경쟁 기술들과 비교했을 때 효과적임을 보였다.

###### SELFOOD: Self-Supervised Out-Of-Distribution Detection via Learning to Rank (https://aclanthology.org/2023.findings-emnlp.719/)
- Anthology ID: 2023.findings-emnlp.719 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. CE loss로 훈련된 딥 뉴럴 분류기는 일반적으로 보정이 잘 안되어서 OOD(분포에서 벗어난) 감지가 필요하지만, 기존의 OOD 감지 방법들은 상당한 비용을 들이는 in-distribution과 OOD 샘플을 수작업으로 라벨링해야 하는 문제가 있다. 
    2. 이 논문에서는 in-distribution 샘플만 있으면 되는 OOD 감지 방법인 SELFOOD를 제안한다. 
    3. SELFOOD는 inter-document intra-label (IDIL) 랭킹 문제로 OOD 감지를 다루고, 이를 위해 IDIL 손실이라는 pairwise 랭킹 손실을 사용하여 분류기를 학습한다.

###### Mind the Gap Between Conversations for Improved Long-Term Dialogue Generation (https://aclanthology.org/2023.findings-emnlp.720/)
- Anthology ID: 2023.findings-emnlp.720 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 대화가 시작되고 며칠, 몇 달 또는 몇 년에 걸쳐 계속되는 것은 의사소통의 자연스러운 일부로, 주제가 얼마나 중요하고 어떤 질문을 해야 하는지를 결정하는 역할을 한다. 따라서 시간을 명시적으로 모델링하지 않는 대화 시스템은 부자연스러운 응답을 생성할 수 있다.
    2. 이 연구에서는 대화 모델이 시간을 인식하도록 하는 아이디어를 탐구하고, 각 세션 사이의 시간이 다양하게 변하는 GapChat이라는 멀티 세션 대화 데이터셋을 제시한다.
    3. 우리는 모델에 시간 정보를 제공하고, 시간 및 사건 진행 상황의 다른 표현을 비교한다. 휴먼 평가에서는 시간을 인식하는 모델이 선택된 주제의 관련성 및 대화에서 얻은 정보에 대한 평가 메트릭에서 더 우수한 성능을 보였다.

###### A Structure-Aware Generative Adversarial Network for Bilingual Lexicon Induction (https://aclanthology.org/2023.findings-emnlp.721/)
- Anthology ID: 2023.findings-emnlp.721 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 양방향 어휘 인식(BLI)은 두 언어 간 단어 임베딩 공간을 일치시키는 학습된 매핑 함수로 단어 번역을 유도하는 작업이다. 기존 방법들은 단어 임베딩을 고립된 개체로 다루며, 단어 간의 공간 내 및 공간 간 위상적 관계를 고려하지 못하여 토폴로지 구조가 다른 임베딩 공간에서 단어를 일치시키는 것이 어렵다.
    2. 이 논문은 경량 그래프 합성곱 신경망(Graph Convolutional Network, GCN)을 사용하여 단어 간의 공간 내 위상적 상관관계를 이용하여 소스 및 타겟 임베딩을 생성하고, 점진적으로 소스 임베딩을 타겟 임베딩 공간으로 매핑하는 공간 간 위상 구조를 학습하기 위해 GAN 모델을 사용하는 Structure-Aware Generative Adversarial Network (SA-GAN) 모델을 제안한다.
    3. 먼 거리 및 밀접한 언어 간 관계를 가진 언어를 포함한 공개 데이터셋에서 수행된 실험 결과는 SA-GAN 모델의 효과적인 성능을 보여주었다.

###### NLP Evaluation in trouble: On the Need to Measure LLM Data Contamination for each Benchmark (https://aclanthology.org/2023.findings-emnlp.722/)
- Anthology ID: 2023.findings-emnlp.722 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 현재의 자연어 처리 (NLP) 과제의 평가 방법 중 하나인 주석이 달린 벤치마크에 기반한 평가가 문제가 있다고 주장한다. 벤치마크의 테스트 세트로 모델을 훈련한 후 동일한 벤치마크에서 평가하기 때문에 클래식한 평가 방식은 데이터 오염에 영향을 받는다고 주장한다.
    2. 데이터 오염은 오염된 모델이 비오염된 모델에 비해 대상 벤치마크 및 관련 과제에서 성능을 과대 평가하게 만들어 오해를 야기할 수 있다고 설명한다.
    3. 이 위치논문은 데이터 오염의 다양한 수준을 정의하고, 데이터가 모델에 노출되었는지 감지하는 자동 및 반자동 측정 방법을 개발하고 데이터 오염에 의해 영향받은 논문을 식별하는 것을 포함한 공동 노력을 제안한다.

###### Improving Pacing in Long-Form Story Planning (https://aclanthology.org/2023.findings-emnlp.723/)
- Anthology ID: 2023.findings-emnlp.723 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 기존의 긴 형식 이야기 작성 시스템들은 중요한 사건들을 누락하거나 사소한 세부 사항에 너무 많은 설명을 하여 독자에게 불편한 경험을 주는 문제점이 있다. 
    2. 이 논문에서는 CONCOCT 시스템을 제안하여 이야기 개요를 자동으로 생성할 때 pacing을 개선한다. 훈련된 concreteness evaluator를 사용하여 계층적 개요 생성에서 pacing을 조절하는 방법을 탐구한다.
    3. CONCOCT 시스템은 사람들에게 일관된 pacing을 제공하며, 이러한 향상은 다른 이야기들에도 영향을 미친다고 인간 평가를 통해 확인하였다.

###### Argument mining as a multi-hop generative machine reading comprehension task (https://aclanthology.org/2023.findings-emnlp.724/)
- Anthology ID: 2023.findings-emnlp.724 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 주장 마이닝은 무구조적인 주장 텍스트를 입력으로 받아 주장 구조 그래프를 생성하는 자연어 처리 작업입니다. 논문에서는 주장 구조를 "사고의 연결" 개념과 비슷하다고 설명하며, 연구에서는 multi-hop reading comprehension 작업으로 주장 마이닝을 전환하고 "사고의 연결" 정보가 주장 마이닝 작업에 도움이 된다는 것을 실험적으로 입증했습니다.
    2. 주장 텍스트를 "왜" 질문에 대한 답으로 볼 수 있으며, 학생의 에세이와 같은 특정 장르의 주장 텍스트들은 일반적으로 비슷한 "사고의 연결"을 가지고 있습니다.
    3. 실험 결과는 SOTA 결과를 초과한다는 것을 보여주었으며, 자세한 분석을 통해 "사고의 연결" 정보가 주장 마이닝 작업에 도움이 된다는 것을 확인하였습니다.

###### HuatuoGPT, Towards Taming Language Model to Be a Doctor (https://aclanthology.org/2023.findings-emnlp.725/)
- Anthology ID: 2023.findings-emnlp.725 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. HuatuoGPT는 ChatGPT로부터 얻은 압축된 데이터와 의사들의 실제 데이터를 활용한 의료 상담을 위한 대형 언어 모델이며, 이러한 접근은 ChatGPT로부터 얻은 데이터만 사용하는 것으로는 '모델 붕괴'가 발생할 수 있고, 의사들의 실제 데이터는 ChatGPT로부터 얻은 데이터와 보완적인 역할을 할 수 있기 때문에 사용된다.
    2. ChatGPT로부터 나오는 응답은 일반적으로 자세하고 유창하며 지시 사항을 따르지만, 대화식 진단을 비롯한 여러 측면에서 의사처럼 작동할 수 없다. 따라서, 의사들의 추가 데이터는 압축된 언어 모델을 의사처럼 작동시키기 위해 사용된다.
    3. 실험 결과 (GPT-4 평가, 인간 평가, 의료 벤치마크 데이터셋)는 HuatuoGPT가 오픈소스 대형 언어 모델 중 의료 상담에서 최고 성능을 보여준다는 것을 보여준다. 추가적인 실제 데이터와 RLMF의 사용을 통해, 압축된 언어 모델인 HuatuoGPT가 대부분의 경우에는 ChatGPT보다 우수한 성과를 낸다는 점에 주목할 만하다.

###### Debias NLU Datasets via Training-free Perturbations (https://aclanthology.org/2023.findings-emnlp.726/)
- Anthology ID: 2023.findings-emnlp.726 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 최근의 연구들은 자연어 이해(NLU)를 위한 고급 모델들이 편향된 특징들을 포착하고, 이러한 특징들이 작업과 독립적이지만 label과 spuriously correlated 될 수 있다는 것을 보여주었다. 이러한 모델들은 일반적으로 in-distribution (ID) 데이터셋에서는 잘 작동하지만 out-of-distribution (OOD) 데이터셋으로의 일반화에 실패한다.
    2. PDD는 ID 성능을 희생하지 않고 OOD 성능을 향상시키기 위해 학습을 요구하지 않는 Perturbations을 사용하는 디바이스 NLU 데이터셋을 위한 프레임워크이다. PDD는 사전 훈련된 마스크 언어 모델 (MLM)을 통해 반복적으로 간섭을 수행하여 작동한다.
    3. 많은 실험을 통해 PDD가 이전의 최첨단 디바이싱 전략과 경쟁력 있는 성능을 보여준다는 것을 확인했고, 모델-중심 디바이스 방법과 결합할 때 새로운 최첨단 기술을 수립한다.

###### Aspect-to-Scope Oriented Multi-view Contrastive Learning for Aspect-based Sentiment Analysis (https://aclanthology.org/2023.findings-emnlp.727/)
- Anthology ID: 2023.findings-emnlp.727 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. Aspect 기반 감성 분석 (ABSA)은 특정 aspect의 감성 극성을 식별하기 위해 aspect와 해당 감성 표현을 매핑하는 것을 목표로 한다. 
    2. 기존 ABSA 방법들은 문장에 여러 가지 aspect가 존재할 때 attention mechanism과 dependency tree로 인해 소음이 발생하여 여전히 문제가 있다.
    3. 이 논문에서는 새로운 관점에서 ABSA를 재검토하고, scope-assisted multi-view graph contrastive learning framework를 제안하여 aspect와 해당 감성 의견을 aspect-specific scope로 더 정확하게 식별하고, 감성 극성과 구문/의미 정보 간의 상관 관계와 차이를 포착한다는 것을 보여준다.

###### Robustness of Named-Entity Replacements for In-Context Learning (https://aclanthology.org/2023.findings-emnlp.728/)
- Anthology ID: 2023.findings-emnlp.728 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 현대의 대형 언어 모델의 핵심 기능 중 하나인 in-context learning은 최종 query 이전에 query-answer demonstrations를 보여주는 prompting 기술로, 파라미터 업데이트 없이 새로운 규칙을 학습할 수 있는 일반화 능력을 제공한다. 하지만, demonstrations의 선택과 특정 query와의 관계는 모델 정확도에 깊은 영향을 미칠 수 있어 실제 in-context generalization 능력에 대한 우려가 있다.
    2. 본 연구에서는 entity에 주목하여 in-context learning 패러다임의 robustness를 탐색한다. 특히, 명칭 개체 변환에 대한 LLM의 in-context learning의 robustness를 이해하고자 한다.
    3. 우리는 세 가지 인기 있는 추론 태스크와 두 가지 인기 있는 LLM을 기반으로, 명칭 개체의 선택에 따라 후속 성능에 상당한 차이가 있음을 발견하였다. 특히, 테스트 세트에서의 모델 정확도는 명칭 개체 변환의 선택에 따라 -2.7에서 +8.0 점까지 편차가 나타난다고 한다. 우리의 분석은 명칭 개체에 대한 LLM in-context learning의 민감성을 드러내며, 주어진 데이터셋에 대해 명칭 개체의 하이퍼파라미터 튜닝을 통해 테스트 성능을 개선하는 간단한 방법을 제안한다. 결과 재현을 위한 코드와 데이터셋은 공개적으로 제공된다.

###### Contrastive Learning-based Sentence Encoders Implicitly Weight Informative Words (https://aclanthology.org/2023.findings-emnlp.729/)
- Anthology ID: 2023.findings-emnlp.729 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 단순한 contrastive loss fine-tuning을 통해 문장 인코더의 성능을 크게 향상시킬 수 있다.
    2. 이 논문은 contrastive 기반의 문장 인코더가 정보 이론적 양에 기반하여 단어에 가중치를 부여하는 것을 이론적으로 및 실험적으로 보여준다.
    3. 다양한 모델, 여러 데이터셋, 두 가지 모델의 암묵적 가중치 측정 방법(Integrated Gradients와 SHAP), 그리고 두 정보 이론적 양(정보 이득과 자기 정보)을 사용하여 포괄적인 실험을 수행하였으며, 그 결과 contrastive fine-tuning이 정보가 풍부한 단어에 중점을 둔다는 경험적 증거를 제공한다.

###### Legally Enforceable Hate Speech Detection for Public Forums (https://aclanthology.org/2023.findings-emnlp.730/)
- Anthology ID: 2023.findings-emnlp.730 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 혐오 발언은 사회적으로 심각한 문제를 일으킨다. 적절한 혐오 발언 법 집행은 피해를 받는 그룹을 유해하고 차별적인 언어로부터 보호하는 데 중요하다고 한다. 
    2. 기존 작업들은 혐오 발언을 어떻게 정의할지 판단하기가 복잡하고 주관적인 해석에 매우 개방적이기 때문에 목표와 일관성이 없을 수 있다. 
    3. 본 연구는 법적 정의에 기반을 둔 강제형 혐오 발언 탐지에 대한 새로운 시각과 과업을 제안하고, 법적 전문가들이 정의 하는 십일 가지 위반에 대한 데이터셋을 소개한다.

###### ConPrompt: Pre-training a Language Model with Machine-Generated Data for Implicit Hate Speech Detection (https://aclanthology.org/2023.findings-emnlp.731/)
- Anthology ID: 2023.findings-emnlp.731 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 암시적인 혐오 발언 탐지는 텍스트 분류에서 도박과 같은 명확한 단서가 없기 때문에 어려운 작업이다. 기존의 pre-trained 언어 모델은 암시적인 혐오 발언에 특화되어 있지 않다. 
    2. 이 논문에서는 머신 생성을 통해 암시적인 혐오 발언 데이터셋을 제어하며, 이를 효과적으로 활용하기 위해 ConPrompt라는 사전 훈련 방법을 제안한다. 
    3. 실험 결과, ToxiGen-ConPrompt는 다른 pre-trained 모델보다 암시적인 혐오 발언 감지에서 우수한 일반화 능력을 보이고, Identity term bias를 완화하는 효과도 있다는 것을 보여준다.

###### Incorporating Syntactic Knowledge into Pre-trained Language Model using Optimization for Overcoming Catastrophic Forgetting (https://aclanthology.org/2023.findings-emnlp.732/)
- Anthology ID: 2023.findings-emnlp.732 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 일반적인 사전 훈련된 언어 모델들은 구문 지식이 충분하지 않기 때문에 복잡하거나 긴 문장을 처리하는 많은 태스크들에서 실패한다.
    2. 이 논문에서는 구문 지식을 언어 모델에 통합하기 위해 추가적인 훈련을 탐구한다. 
    3. 구문 지식을 추가하고 원래 지식과 추가 지식 사이의 균형을 유지하기 위해 치명적인 잊기(catastrophic forgetting) 문제를 해결하였으며, 추가 구문 훈련은 성능 향상을 일관되게 보여준다.

###### Toward Human Readable Prompt Tuning: Kubrick’s The Shining is a good movie, and a good prompt too? (https://aclanthology.org/2023.findings-emnlp.733/)
- Anthology ID: 2023.findings-emnlp.733 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 대규모 언어 모델은 원하는 동작을 지정하는 자연어 프롬프트를 사용하여 downstream 태스크를 제로샷 방식으로 수행할 수 있다. 하지만 이 프롬프트가 효과적인 요소는 알려져 있지 않다. 
    2. 이 연구에서는 분류 문제에서 효과적인 프롬프트의 공통 속성을 조사했다. 따라서 효과적이고 자연스러운 프롬프트의 분포를 찾기 위해 Langevin dynamics를 기반으로 하는 human readable 프롬프트 튜닝 방법 (FluentPrompt)을 제안했다.
    3. 분석결과 효과적인 프롬프트는 태스크 영역과 주어진 출력 레이블의 사전 확률을 조정하는 것이 효과적이라는 것을 알아내었으며, 이를 바탕으로 라벨이 없는 데이터만 사용하여 프롬프트를 생성하는 방법을 제안하였다. 이 방법은 세 가지 태스크에서 강력한 베이스라인을 평균 7.0% 정확도로 능가한다.

###### Chain-of-Thought Reasoning in Tabular Language Models (https://aclanthology.org/2023.findings-emnlp.734/)
- Anthology ID: 2023.findings-emnlp.734 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 표 기반 수학 추론 작업은 표와 질문으로부터 얻은 이질적인 데이터를 기반으로 다단계 연산, 정보 조회 및 숫자 계산 등을 수행하는 모델을 요구한다.
    2. 이전의 솔루션들은 강력한 대형 언어 모델 (LLM)을 사용하여 다중 점프 수학적 추론을 활용하는 추세였으나, LLM 기반 방법은 현장에서의 배포나 제한적 리소스 상황에서 사용하기 어려운 해결책이다.
    3. 본 논문에서는 TaLM을 활용하여 CoT 추론을 소규모 탭릿 언어 모델 (TaLMs)로 확장하고, CoT 생성과 답 유추에 각각 책임을질 수 있는 특별한 프레임워크 인 TaCo를 제안한다.

###### Diffusion Language Model with Query-Document Relevance for Query-Focused Summarization (https://aclanthology.org/2023.findings-emnlp.735/)
- Anthology ID: 2023.findings-emnlp.735 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. "Query-Focused Summarization (QFS)"은 특정 질문에 대답할 수 있는 요약을 생성하는 작업입니다. 그러나 주류인 QFS 모델들은 autoregressive 모델로서 장기 종속성 및 exposure bias의 문제에 시달리는 한계가 있습니다.
    2. 이 논문에서는 non-autoregressive diffusion language model인 "QFS-DLM"을 제안하여 QFS 작업의 적응성을 향상시킵니다. 질문과 문서 조각의 관련성을 고려하여 요약 생성 과정을 개선하고, 모델의 손실 함수에 질문과 문서 간의 전역적인 관련성 점수를 통합하여 모델이 고품질 데이터를 선호하고 저품질 데이터를 피할 수 있도록 합니다.
    3. 해당 방법은 Debatepedia와 PubMedQA 데이터셋에서 ROUGE 점수, GPT-4 및 인간 평가에서 최고 성능을 달성하였습니다.

###### Grounded and well-rounded: a methodological approach to the study of cross-modal and cross-lingual grounding (https://aclanthology.org/2023.findings-emnlp.736/)
- Anthology ID: 2023.findings-emnlp.736 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 그라운딩은 보다 완전하고 진정한 의미론적으로 유능한 인공지능 시스템의 개발에 중요한 요소로 주장되고 있다.
    2. 기존 연구들은 그라운딩이 질적으로 다른 일반화를 가능하게 한다고 주장하는 반면, 다른 사람들은 모노모달 데이터의 양으로 보상될 수 있다고 믿고 있다.
    3. 본 논문에서는 텍스트만 있는 모델에 비해 더 풍부한 입력 소스를 제공하는 것의 효과를 연구하기 위한 방법론적인 프레임워크를 제시한다. 이 프레임워크를 사용하여 실험을 한 결과, 교차 모달 그라운딩, 교차 언어 그라운딩 및 언그라운딩 모델 간에 모델 동작의 질적인 차이가 있음을 발견하였다.

###### EMO-KNOW: A Large Scale Dataset on Emotion-Cause (https://aclanthology.org/2023.findings-emnlp.737/)
- Anthology ID: 2023.findings-emnlp.737 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 요즘 몇 년동안 감정-원인 분석이 연구자들의 관심을 받고 있다. 하지만 대부분의 기존 데이터셋은 작은 규모이며 감정 범주도 제한적이다. 이 논문은 15년 동안의 980만개 트윗 데이터를 바탕으로 한 방대한 감정 원인 데이터셋을 소개한다.
    2. 우리는 데이터 수집, 정제, 라벨링, 검증을 위한 종합적인 파이프라인을 설명하며 데이터셋의 신뢰성과 풍부성을 보장한다. 48가지 감정 클래스에 걸쳐 70만 개가 넘는 트윗과 해당 감정 원인 쌍을 포함한 최종 데이터셋은 인간 평가자들로부터 검증되었다.
    3. 이 데이터셋은 다양한 감정 반응을 고려하는 감정을 고려한 시스템의 설계를 가능하게 하기 위해 감정-원인 지식 그래프를 구축하는 것을 용이하게 하는 특징을 가지고 있다. 예전의 작은 규모의 데이터셋에서는 불가능했던 이러한 능력이 이 데이터셋의 독자적인 특징이다.

###### Boosting Inference Efficiency: Unleashing the Power of Parameter-Shared Pre-trained Language Models (https://aclanthology.org/2023.findings-emnlp.738/)
- Anthology ID: 2023.findings-emnlp.738 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 리소스 제한적인 환경에서 매개 변수 공유 사전 훈련 언어 모델 (PLM)은 모델 저장 및 메모리 비용을 상당히 줄여주기 때문에 매우 성공적인 방법으로 부각되고 있다. 그러나 매개 변수 공유는 추론과 관련된 계산 부담을 완화해주지 않으므로, 시간적 제약 또는 계산 자원이 제한된 상황에서는 실용성이 떨어진다.
    2. 우리는 신경 계산 미분 방정식 (ODE)을 기반으로하여 매개 변수 공유 PLM의 추론 효율성을 향상시키는 간단한 기술을 소개한다. 또한, 전체적 또는 부분적으로 공유 모델을 구현할 수 있는 간단한 사전 훈련 기법을 제안한다.
    3. 실험 결과를 통해 의도한 방법의 효과를 자가 회귀 및 자동 인코딩 PLM에서 입증하며, 리소스가 제한된 환경에서 매개 변수 공유 모델을 더 효율적으로 활용할 수 있는 새로운 통찰력을 제공한다.

###### Natural Response Generation for Chinese Reading Comprehension (https://aclanthology.org/2023.findings-emnlp.739/)
- Anthology ID: 2023.findings-emnlp.739 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 기존의 기계 독해 (MRC) 벤치마크는 대부분 타겟 코퍼스에서 추출한 구간이나 주어진 후보들 중에서 선택된 답변에 초점을 두고 있어서 높은 품질의 응답의 자연스러운 측면을 무시하고 있다.
    2. 이를 해결하기 위해 저자들은 Penguin이라는 새로운 데이터셋을 구축하여 현실적인 시나리오에서 자연스러운 응답 생성에 대한 연구를 촉진한다.
    3. Penguin은 상대적으로 대규모인 중국어 MRC에서 자연스러운 응답 생성을 위한 첫 번째 벤치마크이며, Prompt-BART와 같은 강력한 베이스라인의 효과적인 설계를 실험 결과로 검증하였다.

###### Treepiece: Faster Semantic Parsing via Tree Tokenization (https://aclanthology.org/2023.findings-emnlp.740/)
- Anthology ID: 2023.findings-emnlp.740 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 자연어처리 (NLP) 작업에서 최근에 나온 deep model들은 인과적 인과성으로 향상된 반면, spurious pattern에 의존해서 그 robustness가 제한된다는 것이 보고되었다. 
    2. 기존의 augmentation 기법은 counterfactual들을 dataset에 추가하기 위해 사람들이 작업한 것이거나, 이미 dataset에 있는 대조 사례를 찾기 위해 기계 학습된 것들이 필요했는데, 이러한 augmentation은 여전히 spurious correlation에 영향을 받는다는 한계점이 있다. 
    3. 이 논문에서는 "a set"의 counterfactuals을 합성하고 이 집합의 예측 분포에 대한 집단적인 의사 결정으로 각 용어의 인과 관계를 강력하게 지도하는 방법을 소개한다.

###### Semantic Parsing by Large Language Models for Intricate Updating Strategies of Zero-Shot Dialogue State Tracking (https://aclanthology.org/2023.findings-emnlp.741/)
- Anthology ID: 2023.findings-emnlp.741 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. "Zero-shot Dialogue State Tracking (DST)"는 작업 지향 대화 형식의 획득과 주석화에 대한 도전을 다루며, 멀리간 업무를 수행함에 따라 대화 상태를 효과적으로 업데이트하기 위해 효과적인 전략을 요구한다.
    2. 우리는 ParsingDST라는 새로운 In-Context Learning (ICL) 방법을 제안하여 실시간 DST에서 더욱 복잡한 업데이트 전략을 도입한다.
    3. 실험 결과, 우리의 방법은 MultiWOZ에서 기존의 ICL 방법들과 비교하여 Joint Goal Accuracy (JGA) 및 슬롯 정확도에서 상당한 향상을 보여주며, 기존의 zero-shot DST 방법을 능가한다.

###### Mitigating Framing Bias with Polarity Minimization Loss (https://aclanthology.org/2023.findings-emnlp.742/)
- Anthology ID: 2023.findings-emnlp.742 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 정치적 편향을 완화하기 위해, 우리는 다양한 정치적 견해를 가진 언론사들이 동일한 사건을 보도할 때 극성화된 언어를 사용하고 있는데 이를 감소시키기 위한 새로운 loss function을 제안한다.
    2. 우리의 실험 결과는 제안된 극성 감소 loss를 적용하면 BART 기반 다중문서 요약 모델에 비해 극성화된 편향을 크게 감소시킬 수 있음을 보여준다.
    3. 더욱 효과적인 방법은 모델이 정보적 편향 (즉, 보도할 정보의 편향된 선택)과 관련된 polarity loss를 최소화하기 위해 훈련되었을 때 나타났다.

###### Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation (https://aclanthology.org/2023.findings-emnlp.743/)
- Anthology ID: 2023.findings-emnlp.743 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. ChatGPT는 인과 추론에 있어서 좋은 해석자지만, 실제로는 좋은 인과 추론자가 아니다. 
    2. ChatGPT의 인과 추론 능력은 프롬프트에서 사용되는 단어에 민감하며, 폐쇄형 프롬프트가 개방형 프롬프트보다 더 잘 작동한다. 
    3. ChatGPT는 명시적 인과관계를 포착하는 데 우수하지만, 암묵적인 인과관계에는 미약한 성능을 보이며, 이벤트의 밀도가 낮고 이벤트 사이의 어휘적 거리가 작은 문장에서 더 잘 작동한다.

###### Steering Large Language Models for Machine Translation with Finetuning and In-Context Learning (https://aclanthology.org/2023.findings-emnlp.744/)
- Anthology ID: 2023.findings-emnlp.744 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 대규모 언어 모델은 기계 번역에 유망한 방법이지만, 현재의 LLM 기반 기계 번역 시스템은 몇 가지 샷 예제의 선택에 매우 의존하며, 과 생성으로 인해 추가적인 후처리가 필요하다.
    2. 번역 지침에 대한 섬세한 조정은 계산적으로 비싸며, 논맥 학습 능력이 과도하게 특수화되어 제약을 약화할 수도 있다.
    3. 이 논문에서는 LoRA를 사용한 어탭터 기반 조정 과정이 전통적인 조정과 성능을 맞추면서 50배 적은 파라미터 수로 작동한다는 것을 보여준다. 이 방법은 몇 가지 샷 활성화 및 후처리나 논맥 예시 없이도 작동한다. 그러나 조정은 일반적으로 몇 가지 샷 성능을 저하시키며 적응 능력을 방해하는 것을 보여준다. 최선의 해결책을 얻기 위해, 우리는 기울기 조정 중 몇 가지 샷 예제를 통합하는 간단한 접근 방식을 제안한다. 10개의 언어 쌍에서 실시한 실험 결과, 우리의 제안 방법은 원래의 몇 가지 샷 가능성을 회복하면서 조정의 추가 이점을 유지한다.

###### How Many Demonstrations Do You Need for In-context Learning? (https://aclanthology.org/2023.findings-emnlp.745/)
- Anthology ID: 2023.findings-emnlp.745 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 대규모 언어 모델들은 몇 개의 입출력 데모(demo)와 그 데모의 중간 추론 단계(chain of thoughts (CoT))를 제공하면 일루스트를 통해 복잡한 추론을 수행할 수 있다. 이 논문에서는 ICL에서 더 적은 수의 데모로 각 테스트 쿼리를 공부하는 방법을 연구한다. 놀랍게도, 무작위로 선택된 하나의 데모만 사용할 때도 큰 성능 하락을 관측하지 않았다.
    2. 데모를 각 테스트 쿼리에 대해 "옳은 대답을 이끄는 긍정적인 데모"와 "잘못된 대답을 만드는 부정적인 데모"로 분류하고 분석 결과, 널리 연구된 데이터셋에는 내재된 편향과 데모의 중복성이 존재한다는 것을 알 수 있다.
    3. 하나의 긍정적인 데모만을 사용한 ICL은 대부분의 이전 연구에서 채택된 다중 데모 ICL보다 더 우수한 성능을 보이며, 그 결과는 LLMs가 입력 쿼리에 대해 긍정적인 데모를 찾는 능력이 다소 약하다는 것을 보여준다. 이러한 편향된 데이터셋에서 평가하기 어렵다. 또한, 다중 데모를 사용한 ICL의 역설적인 동작이 있는데, 긍정적인 데모가 더 많은 경우 정확성이 저하(향상)된다. 이는 데모들 간의 간섭과 편향된 상관 관계 때문에 ICL이 쉽게 오도될 수 있다는 것을 의미한다. 이 분석은 LLMs 훈련, ICL 및 벤치마크 디자인에 대해 해결해야 할 몇 가지 기본적인 도전 과제를 강조한다.

###### Improving word mover’s distance by leveraging self-attention matrix (https://aclanthology.org/2023.findings-emnlp.746/)
- Anthology ID: 2023.findings-emnlp.746 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 두 문장 간의 의미적 유사성을 측정하는 것은 여전히 중요한 과제이다. 그러나, Word Mover's Distance(WMD)는 단어들의 집합 간 최적 정렬을 통해 유사성을 계산하지만 단어 순서를 고려하지 않아, 의미적으로 크게 다른데도 유사한 단어들이 많이 겹치는 문장을 구별하는 것이 어렵다.
    2. 우리는 BERT의 self-attention matrix(SAM)로 표현되는 문장 구조를 WMD에 통합하여 개선하려고 한다. 제안된 방법은 단어 임베딩의 유사성과 SAM의 유사성을 동시에 고려하여 두 문장 사이의 최적 전송을 계산하는 Fused Gromov-Wasserstein distance에 기반한다.
    3. 실험 결과, 제안된 방법은 WMD 및 그 변형에 대해 paraphrase identification에서 개선되었으며 의미적 텍스트 유사성에서 거의 동등한 성능을 보였다.

###### Improving Span Representation by Efficient Span-Level Attention (https://aclanthology.org/2023.findings-emnlp.747/)
- Anthology ID: 2023.findings-emnlp.747 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 자연어 처리 태스크에서 span 예측 및 분류와 관련된 고품질의 span 표현은 매우 중요하다.
    2. 이 논문에서는 span 표현을 향상시키기 위해 span-span 상호작용과 포괄적인 span-token 상호작용을 고려한다.
    3. span간의 attention을 적용함으로써 모델의 성능을 개선하고 다양한 span 관련 태스크에서 기준 모델보다 우수한 성능을 보여준다.

###### Long-Horizon Dialogue Understanding for Role Identification in the Game of Avalon with Large Language Models (https://aclanthology.org/2023.findings-emnlp.748/)
- Anthology ID: 2023.findings-emnlp.748 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 불일치하는 이해 관계와 대화 동안의 속임수와 설득은 특히 이해 관계와 목표가 일치하지 않는 다자 간의 대화에서 핵심적인 역할을 한다. 하지만 현재의 큰 언어 모델은 속임수와 설득에 쉽게 현혹되어 장기적인 대화에서 낮은 성능을 보인다. 
    2. 본 논문에서는 Avalon: The Resistance 게임을 소개하여 큰 언어 모델의 의사 결정과 언어 처리 능력을 연구하기 위한 테스트베드와 데이터셋을 제안한다. 이 게임은 협력 및 경쟁적인 환경에서 장기적인 속임수를 보여주는 사람들의 대화를 포함한다. 
    3. 실험 결과로, 최신의 큰 언어 모델은 인간의 성능에 도달하지 못하는 것으로 나타났다. 이를 통해 클레멘슨 의사 결정과 언어 처리 능력을 조사하는 동기부여적인 벤치마크로 활용할 수 있는 데이터셋을 제공한다.

###### Improving Sequential Model Editing with Fact Retrieval (https://aclanthology.org/2023.findings-emnlp.749/)
- Anthology ID: 2023.findings-emnlp.749 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. Pre-trained Language Models (PLMs)에서의 지식 오류를 효율적이고 정확하게 수정하는 sequential model editing 작업은 기존 방법들은 조금 수정하는 데에는 잘 작동하지만 수정하는 횟수가 많아지면 성능이 저하되거나 추가 주석 데이터가 필요한 문제가 있다. 
    2. 이 논문에서는 RASE (Retrieval Augmented Sequential Model Editing) 프레임워크를 제안하는데, 이는 fact-patch 메모리에서 관련 사실을 검색하여 편집 일반화를 향상시키고 편집 식별을 가이드하기 위해 사실적인 정보를 활용한다. 
    3. RASE는 대규모 PLMs 편집을 가능하게 하고 서로 다른 편집기의 성능을 높일 수 있다. 또한, ChatGPT에 통합하여 성능을 더욱 향상시킬 수 있다.

###### Battle of the Large Language Models: Dolly vs LLaMA vs Vicuna vs Guanaco vs Bard vs ChatGPT - A Text-to-SQL Parsing Comparison (https://aclanthology.org/2023.findings-emnlp.750/)
- Anthology ID: 2023.findings-emnlp.750 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. ChatGPT의 성공으로 인해 AI 경쟁이 시작되었으며, 연구자들은 상업용 모델의 언어 이해 및 생성 능력을 도달하거나 뛰어넘는 새로운 대형 언어 모델을 개발하기 위해 노력하고 있다.
    
    2. 최근에는 여러 가지 instruction tuning 방법을 통해 GPT-3.5 또는 GPT-4와 유사한 성능을 거론하는 여러 모델들이 등장하였으나, 이러한 주장에 대해 비판적인 시각으로 접근하고 이러한 모델의 실제 효과를 확인하는 것이 중요하다.
    
    3. 본 연구에서는 6개의 인기있는 대형 언어 모델을 서로 비교하여, 제로샷 및 퓨샷 시나리오를 모두 포함하는 9개의 벤치마크 데이터셋에서 Text-to-SQL 파싱 능력을 체계적으로 평가하였으며, 여러 오픈 소스 모델들이 GPT-3.5와 같은 클로즈드 소스 모델의 성능에 대한 괄목할 만한 부족함을 보여주었다. 이는 이러한 모델들 간의 성능 차이를 줄이기 위해 추가적인 연구가 필요함을 강조한다.

###### KBioXLM: A Knowledge-anchored Biomedical Multilingual Pretrained Language Model (https://aclanthology.org/2023.findings-emnlp.751/)
- Anthology ID: 2023.findings-emnlp.751 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 대부분의 바이오의료 사전 학습 언어 모델은 단일 언어로만 작동하며, 다양한 언어 요구 사항을 처리할 수 없다. 도메인별 데이터셋의 부족으로 인해 다국어 바이오의료 모델을 훈련시키는 일이 어려움을 겪고 있다.
    2. 우리는 지식-rooted (knowledge-anchored) 접근 방식을 사용하여 다국어 사전 학습 모델 XLM-R을 바이오의료 도메인으로 변환하는 KBioXLM 모델을 제안한다. 이를 위해 단일 언어 데이터셋에 entity, fact, passage 수준의 지식 정합을 고려하여 바이오의료 멀티링구얼 문장을 생성한다.
    3. 실험 결과는 우리의 모델이 크로스-언어 zero-shot 및 few-shot 시나리오에서 단일 언어 및 멀티링구얼 사전 학습 모델보다 큰 개선이 있다는 것을 보여준다. 
    10+ 포인트까지 개선이 이루어진다.

###### Words, Subwords, and Morphemes: What Really Matters in the Surprisal-Reading Time Relationship? (https://aclanthology.org/2023.findings-emnlp.752/)
- Anthology ID: 2023.findings-emnlp.752 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. LLM의 예측은 subword tokenization에 기반하고, 단어를 형태소로 분해하지 않기 때문에 이는 중요한 가정이다. 
    2. 이 논문에서는 orthographic, morphological, BPE tokenization을 사용하여 surprisal estimates를 비교함으로써 이를 주의 깊게 조사한다.
    3. 결과적으로 BPE tokenization에 기반한 예측이 morphological과 orthographic 세그멘테이션에 비해 큰 차이가 없지만, 더 세밀한 분석은 BPE 기반 세그멘테이션에 의존하는 것에 대한 잠재적인 문제를 지적하고, 형태소를 고려한 surprisal estimates에서 유망한 결과를 제시하는 것을 확인할 수 있다.

###### A Zero-Shot Language Agent for Computer Control with Structured Reflection (https://aclanthology.org/2023.findings-emnlp.753/)
- Anthology ID: 2023.findings-emnlp.753 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 대형 언어 모델들은 MiniWoB++와 같은 실제 컴퓨터 환경에서 상위 수준의 목표를 계획하고 실행하는 능력이 점점 늘어나고 있다. 
    2. 이 논문에서는 trace 예제 없이도 새로운 태스크까지 자율적으로 학습하고 그 제어를 개선할 수 있는 zero-shot 에이전트를 제안한다. 
    3. MiniWoB++의 쉬운 태스크에서는 우리의 zero-shot 에이전트가 최신 기법들보다 더 효율적인 추론을 통해 뛰어난 성능을 보이며, 더 복잡한 태스크에서는 전문가 추적이나 추가 화면 정보에 대한 이전 작업의 장점을 배제하고서도 우수한 성과를 보인다.

###### SteerLM: Attribute Conditioned SFT as an (User-Steerable) Alternative to RLHF (https://aclanthology.org/2023.findings-emnlp.754/)
- Anthology ID: 2023.findings-emnlp.754 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 큰 언어 모델 (Large Language Models, LLM) 의 인간의 선호와 모델의 일치는 인공지능이 인간의 가치와 일관성 있게 도움을 줄 수 있는 가장 중요한 단계이다. 그러나 RLHF는 복잡한 학습 방식과 모델이 사용자가 실행 중에 제어할 수 없는 암묵적인 가치와 일치하는 경향 등으로 인해 고유한 한계를 가지고 있다. 
    2. SteerLM은 사용자가 유추 과정에서 응답을 조절할 수 있는 방법으로, RLHF로 훈련된 많은 최첨단 기준선보다 인간과 자동 평가자들이 선호하는 응답을 생성할 수 있으며 훈련이 훨씬 쉽다는 것을 실험을 통해 보여주고 있다.
    3. SteerLM은 명시적으로 정의된 다차원 속성 집합에 따라 응답을 조건부로 설정하여 도움이 되고 고품질의 응답을 생성하면서도 맞춤 설정 가능성을 유지하는 조정 가능한 AI를 구현한다.

###### IdealGPT: Iteratively Decomposing Vision and Language Reasoning via Large Language Models (https://aclanthology.org/2023.findings-emnlp.755/)
- Anthology ID: 2023.findings-emnlp.755 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 최신 언어 모델이 VL 이해 분야에서 많은 진전을 이루었지만, multi-step 추론이 필요한 zero-shot reasoning 태스크에서 부족하다.
    2. 기존 방법들은 domain-specific sub-question decomposing 모델에 의존하고, sub-answers가 충분한 정보를 주지 않더라도 최종 답을 예측하도록 강제한다.
    3. IdealGPT는 large language models를 사용하여 VL 추론을 반복적으로 decompose하는 프레임워크로, sub-questions를 생성하는 LLM, corresponding sub-answers를 제공하는 VLM, 그리고 최종 답을 도출하는 다른 LLM을 사용한다. 이러한 세 가지 모듈이 최종 답에 대한 확신을 가질 때까지 divide-and-conquer 절차를 반복적으로 수행한다.

###### GRI: Graph-based Relative Isomorphism of Word Embedding Spaces (https://aclanthology.org/2023.findings-emnlp.756/)
- Anthology ID: 2023.findings-emnlp.756 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 기계 번역에서 단일 언어 임베딩 공간을 사용한 양방향 사전의 자동 생성은 핵심적인 과제다. 현재까지의 연구들은 다른 공간들 사이의 상대적인 등동성을 제어하는 데 실패하고 있다.
    2. 이 논문에서는 상대적인 등동성을 정의하고 계산하는 데 필요한 의미적으로 유사한 단어들의 어휘적 차이의 영향을 함께 고려하는 방법인 GRI를 제안한다.
    3. 실험적 평가 결과, GRI가 기존 연구에 비해 최대 63.6%의 상대적 성능 향상을 이룬다는 것을 보여주고 있다.

###### PersonaLM: Language Model Personalization via Domain-distributed Span Aggregated K-Nearest N-gram Retrieval Augmentation (https://aclanthology.org/2023.findings-emnlp.757/)
- Anthology ID: 2023.findings-emnlp.757 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. PersonaLM은 personalization을 위해 language modeling을 개선하기 위한 "Domain-distributed Span-Aggregated K-nearest N-gram retrieval augmentation"을 소개한다. 이 방법은 흔하지 않은 도메인 관련 단어 패턴을 인식하기 위해 문맥적으로 유사한 n-gram 단어 빈도를 활용한다.
    2. 이 논문에서는 SCAN retriever라는 "Span Aggregated Group-Contrastive Neural"을 제안하여, 동일 그룹에 속하는 span 표현을 함께 묶고, 상관 없는 그룹으로부터의 span을 동의어 공간에서 멀어지도록 하는 방법으로 외부 도메인/사용자의 랭킹을 학습한다.
    3. PersonaLM은 Wikitext-103, UserLibri, 그리고 ASAP 데이터셋에서 perplexity를 10-16% 개선하고, Word Error Rate를 5-8% 줄이는 등 강력한 기준 모델을 대폭 능가한다는 실험 결과를 보여준다. SCAN retriever는 LAMP 벤치마크에서 zero-shot prompting과 few-shot fine-tuning을 통해 7-12% 정확도 향상을 달성하는 사례로 사용되기도 한다.

###### Scaling Vision-Language Models with Sparse Mixture of Experts (https://aclanthology.org/2023.findings-emnlp.758/)
- Anthology ID: 2023.findings-emnlp.758 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 최근 NLP 분야에서는 대규모 비전-언어 모델(VLMs)의 개발을 통해 큰 진전을 이루었다. 그러나 이러한 모델들이 점점 더 크고 복잡해지면서 훈련과 배포가 어려워지는 문제가 있다. 
    2. 이 논문에서는 모델을 작은 전문 서브 모델로 분할하여 공동으로 문제를 해결하는 희소 gate 모델(MoE) 기법의 효과를 탐구한다. 
    3. MoE는 계산 비용이 동일한 밀집 모델보다 우수한 성능을 보일 수 있는 잠재력을 보여주고 있으며, VLMs의 확장에 있어 컴퓨팅 성능을 조절하는 상충 관계에 대한 통찰력을 제공한다.

###### Aspect-Category Enhanced Learning with a Neural Coherence Model for Implicit Sentiment Analysis (https://aclanthology.org/2023.findings-emnlp.759/)
- Anthology ID: 2023.findings-emnlp.759 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 소셜 네트워킹 서비스의 급격한 성장 이후로, aspect-based sentiment analysis (ABSA)는 광범위하게 연구되었지만, 명시적인 의견 단어가 없는 내재적인 감정의 인식은 아직 덜 탐구되고 있다.
    2. 본 논문에서는 aspect-category enhanced learning with a neural coherence model (ELCoM)을 제안한다. 이 모델은 대조학습을 사용하여 문서 수준의 일관성을 포착하며, 하이퍼그래프를 사용하여 문장 수준의 의견을 채굴하여 내재적인 감정 분류에 도움을 준다.
    3. 실험 결과 ELCoM은 벤치마크 데이터셋에서 최고의 성능을 달성하였다. 소스 코드와 데이터는 https://github.com/cuijin-23/ELCoM에서 공개되었다.

###### End-to-end Adversarial Sample Generation for Data Augmentation (https://aclanthology.org/2023.findings-emnlp.760/)
- Anthology ID: 2023.findings-emnlp.760 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 적대적 샘플들은 신경 NLP 모델에 큰 도전을 줍니다. 이 논문에서는 적대적 학습과 데이터 augmentation을 결합한 네트워크 NLP 모델의 robustness를 향상시키는 새로운 A3 접근 방식을 제안합니다.
    2. 우리는 조건부 paraphrasing 모델과 조건 생성기로 구성된 적대적 샘플 생성기를 제안합니다. 후자는 적대적 샘플을 생성하도록 paraphrasing 모델을 가이드하는 조건들을 생성합니다.  또한 사전 훈련된 discriminator를 도입하여 적대적 샘플 생성기가 다른 작업의 데이터 특성에 적응할 수 있도록 합니다.
    3. 실험 결과는 우리의 접근 방식이 훈련된 모델의 전체적인 성능을 향상시킨다는 것을 보여줍니다. 특히, 개선된 모델이 다양한 공격 기법에 대해 robust하다는 것이 입증되었습니다.

###### Query2Triple: Unified Query Encoding for Answering Diverse Complex Queries over Knowledge Graphs (https://aclanthology.org/2023.findings-emnlp.761/)
- Anthology ID: 2023.findings-emnlp.761 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 지식 그래프에서의 복잡한 질문에 대답하는 것은 어려운 작업이다. 이 논문에서는 질의 임베딩 방법을 제안하여 단순한 질문과 복잡한 질문을 분리하여 효율적인 학습을 가능하게 한다. 
    2. 제안된 방법은 단순한 질문에 대한 신경망 링크 오퍼레이터를 먼저 사전 학습하고, 복잡한 질문에 대한 쿼리 인코더를 학습시키는 두 단계로 이루어진다. 이를 통해 고효율로 다양한 복잡한 질문에 대한 상태-오브-더-아트 성능을 달성한다. 
    3. 복잡한 질문을 해결하기 위해 명시적인 모델링을 사용하지 않아도 되는데, 이는 Q2T가 다양한 종류의 신경망 링크 오퍼레이터에 적용 가능하고 효율적인 학습을 가능하게 한다는 것을 의미한다.

###### Self-Polish: Enhance Reasoning in Large Language Models via Problem Refinement (https://aclanthology.org/2023.findings-emnlp.762/)
- Anthology ID: 2023.findings-emnlp.762 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 대규모 언어 모델의 다단계 추론 능력을 향상시키기 위해, 인간과 비슷한 근거를 명시적으로 도출하는 Chain-of-Thought (CoT) 방법을 중심으로 많은 prompting 방법들이 실험되었으나, 더 품질이 높은 문제를 작성함으로써 모델의 추론 성능을 향상시키는 잠재력은 간과되어 왔다.
    2. 이 논문에서는 Self-Polish (SP)라고 불리는 새로운 방법을 제안하여 주어진 문제를 점진적으로 개선시켜 모델의 추론을 용이하게 하는 방법을 제시한다.
    3. 제안된 방법은 CoT와 같은 답변/추론 측면의 다른 prompting 방법과 병행이 가능하며, 다양한 모델에 걸쳐 다섯 가지 추론 벤치마크에서 효과적이고 일관된 결과를 보여준다. 또한, 강건성 평가에서도 훌륭한 성능을 보여준다.

###### Breaking through Deterministic Barriers: Randomized Pruning Mask Generation and Selection (https://aclanthology.org/2023.findings-emnlp.763/)
- Anthology ID: 2023.findings-emnlp.763 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 일반적으로 크고 희박한 모델은 같은 모델 크기 제한 하에서 작고 밀집한 모델보다 더 높은 정확성을 보이는 것으로 알려져 있으며, 이를 동기로 우리는 큰 모델을 훈련시킨 후 가지고 있는 쓸모 없는 뉴런이나 가중치를 가지를 제거하는 모델 가지치기(pruning)를 제안한다. 
    2. 기존 연구들은 단일한 가지치기 기준에 의존하고 있어 다양성이 부족한데 반해, 우리는 복수의 가지치기 마스크를 디자인된 무작위 방식으로 생성한 뒤 효과적인 마스크 선택 규칙과 함께 최적의 마스크를 후보 중에서 선택한다. 
    3. 더불어, 효율성을 향상시키기 위해 여러 개의 마스크를 훈련하는 데 관련된 부하를 완화하기 위한 조기 마스크 평가 전략을 도입함으로써 이러한 접근 방식이 GLUE 데이터셋의 여덟 가지 태스크에서 최고 수준의 성능을 달성함을 보여준다.

###### Eyes Show the Way: Modelling Gaze Behaviour for Hallucination Detection (https://aclanthology.org/2023.findings-emnlp.764/)
- Anthology ID: 2023.findings-emnlp.764 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 자연어처리(NLP)에서 환영 감지는 언어의 의미론적과 번역론적 측면을 깊게 이해해야 하는 중요한 과제이다. 이 논문에서는 사용자의 시각(Gaze) 신호를 활용한 심리학적 접근 방법을 제안하여 환영 감지를 수행한다.
    2. 사람들은 분포 유사성을 기반으로 텍스트의 관련 부분에 주목한다는 것을 알아냈으며, 글로벌 주의와 로컬 주의 두 가지 주의 전략을 사용한다. 이를 바탕으로 주의 편향을 반영한 새로운 환영 감지를 위한 심리학적 프레임워크를 제안한다.
    3. 실험적 평가 결과, 제안한 방법은 FactCC 데이터셋에서 87.1%의 균형 재현율을 달성하며, gaze 기반 접근 방법이 환영 감지 과제에 효과적임을 입증하고, 사람들이 불일치를 식별하는 데 사용하는 인지적 과정에도 새로운 통찰을 제공한다.

###### Noisy Pair Corrector for Dense Retrieval (https://aclanthology.org/2023.findings-emnlp.765/)
- Anthology ID: 2023.findings-emnlp.765 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 대부분의 dense retrieval 모델은 training query-document pairs이 정확히 일치한다는 가정을 가지고 있는데, 실제 응용에서는 수동으로 코퍼스를 주석 달기가 비용이 많이 들기 때문에 자동으로 수집하는 경우가 많아지면서 mismatched-pair noise가 도입된다. 
    2. 따라서, 이 논문에서는 mismatched-pair noise가 있는 상황에서 효과적인 모델을 어떻게 훈련할 수 있는지를 연구한다. 
    3. 이를 해결하기 위해, detection 모듈과 correction 모듈로 구성된 새로운 방법인 Noisy Pair Corrector (NPC)를 제안한다. NPC는 주석된 positive와 쉬운 negative 문서 사이의 perplexity를 계산함으로써 noise pair를 추정하는 detection 모듈과, noise의 영향을 완화하기 위한 소프트한 지도 신호를 제공하기 위해 지수 이동 평균 (EMA) 모델을 활용하는 correction 모듈로 이루어져 있다. 실험 결과로, NPC가 synthetic와 realistic noise 모두를 처리하는 데에 우수한 성능을 보인다고 나타냈다.

###### Enhancing Accessible Communication: from European Portuguese to Portuguese Sign Language (https://aclanthology.org/2023.findings-emnlp.766/)
- Anthology ID: 2023.findings-emnlp.766 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 현재 포르투갈에서 교육용 언어로 쓰이는 포르투갈 수화 (LGP)는 수동적인 규칙에 의존하는 번역 시스템을 사용한다. 
    2. 본 논문에서는 European Portuguese와 LGP glosses 간의 자동적으로 훈련된 규칙 기반 기계 번역 시스템과 두 개의 신경망 기계 번역 모델을 제시한다.
    3. 밑바탕이 된 시스템을 통해 구축된 LGP-5-Domain 코퍼스와 LGP 전문가들에 의해 주석이 달린 골드 데이터도 제공하며, PE2LGP와 비교해 새로운 규칙 기반 모델은 항상 더 좋은 결과를 보여주고 하나의 신경망 모델과 최고 점수를 겨룬다.

###### Diversifying language models for lesser-studied languages and language-usage contexts: A case of second language Korean (https://aclanthology.org/2023.findings-emnlp.767/)
- Anthology ID: 2023.findings-emnlp.767 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 현재 사용 가능한 형태소 파서/태거가 중요성이 낮은 언어나 언어 사용 환경에서 얼마나 잘 작동하는지, 특히 두 번째 언어인 한국어(L2 Korean)에 초점을 맞추어 연구하였다.
    2. 우리는 (1) 첫 번째 언어(L1 Korean) 데이터로 사전 훈련된 신경망 모델을 다양한 L2 데이터에 대해 훈련시키고, (2) 이 모델이 L2 테스트 세트에서 형태소 파싱/POS 태깅 성능을 측정함으로써 이 문제를 연구하였다. 
    3. 결과적으로, L2 훈련된 모델은 L1 사전 훈련된 기준 모델과 비교하여 일반적으로 도메인-특정 토큰화 및 POS 태깅에서 우수한 성능을 보여주었다. 흥미롭게도, L2 훈련 데이터의 크기를 키우는 것은 모델의 성능 향상을 일관되게 이끌지 못하였다.

###### Improving generalization in large langue model by learning prefix subspaces (https://aclanthology.org/2023.findings-emnlp.768/)
- Anthology ID: 2023.findings-emnlp.768 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 본 논문은 희소 데이터 환경에서 대형 언어 모델의 (LLM) fine-tuning에 초점을 맞추고 있다. 신경망 서브스페이스를 기반으로 LLM의 일반화 능력을 향상시키는 방법을 제안한다.
    2. 기존 방법들은 훈련 데이터가 적은 상황에서 LLM의 일반화를 향상시키기 위해서는 훈련 데이터가 많아야 했으나, 이 논문에서 제안하는 방법은 훈련 데이터가 적은 상황에서도 성능을 향상시킬 수 있다.
    3. 지속적인 접두사 튜닝(prefix-tuning)을 배우는 방법으로 LLM을 훈련시켜 희소 데이터 환경에서의 평균 성능 향상을 보였다.

###### Domain Adaptation for Sentiment Analysis Using Robust Internal Representations (https://aclanthology.org/2023.findings-emnlp.769/)
- Anthology ID: 2023.findings-emnlp.769 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. Sentiment analysis는 기업들이 제품 개발과 최적의 마케팅 전략을 위해 고객의 의견을 조사하는 것이 필수적이지만 많은 비용이 드는 작업이다.
    2. 따라서 여러 도메인과 제품, 서비스 간의 차이로 인한 도메인 갭을 완화하기 위해 cross-domain sentiment analysis 방법이 주목받고 있다.
    3. 우리는 데이터 분포를 일치시키고 서로 다른 클래스에 속하는 데이터 표현 사이의 큰 간격을 생성하는 도메인-비의존(embedding space)으로 학습하는 도메인 적응 방법을 개발하였다.

###### KeFVP: Knowledge-enhanced Financial Volatility Prediction (https://aclanthology.org/2023.findings-emnlp.770/)
- Anthology ID: 2023.findings-emnlp.770 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 기업의 위험 프로필을 나타내기 위해 금융 변동성 예측은 중요하다. 이 논문에서는 회사의 수익 통화 통화를 통해 금융 metric 지식을 통합하여 텍스트 이해에 반영하는 방법을 제안한다.
    2. KeFVP는 지식 강화 사전 학습 (KePt)을 통해 금융 metric에 대한 지식을 텍스트 이해에 주입하고 조건부 시계열 예측 모듈을 도입하여 텍스트와 가격 정보를 효과적으로 통합한다.
    3. 실제 데이터셋에서 수행된 실험 결과 KeFVP가 다른 최신 기법보다 우수하며 효과적임을 보여준다.

###### A Frustratingly Easy Plug-and-Play Detection-and-Reasoning Module for Chinese Spelling Check (https://aclanthology.org/2023.findings-emnlp.771/)
- Anthology ID: 2023.findings-emnlp.771 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 최근에는, 중국어 철자 교정 (CSC)은 과연에서 더 직접적고 효율적으로 중국어에 대한 다양한 외부 지식을 활용할 수 있도록 탐지, 추론 및 탐색 (detection, reasoning, and searching) 하위태스크로 분해하는 것이 가능해졌다.
    2. 우리는 기존 SOTA 비자동 CSC 모델과 호환되는 plug-and-play detection-and-reasoning 모듈을 설계하여 성능을 더욱 향상시켰다. 하나의 모델에서 훈련된 탐지-추론 모듈은 다른 모델에도 도움이 될 수 있음을 발견했다. 
    3. 광범위한 실험과 상세한 분석을 통해 제안된 모듈의 효과와 경쟁력이 입증되었다.

###### Asking Clarification Questions to Handle Ambiguity in Open-Domain QA (https://aclanthology.org/2023.findings-emnlp.772/)
- Anthology ID: 2023.findings-emnlp.772 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 개방형 도메인 질의 응답에서 애매한 질문은 정확하고 유일한 답변을 포현하기 어려워 지속적으로 발생한다. 이 논문에서는 애매한 질문의 가능한 해석에 대해 모든 해석에 대한 구분된 질문을 요청하는 대신 사용자의 응답을 이용하여 사용자의 의도와 가장 일치하는 해석을 식별하는 "clarification question"을 요청하는 방법을 제안한다. 
    2. CAmbigNQ라는 데이터셋을 구성하고, (1) 모호성 감지, (2) clarification question 생성, (3) clarification 기반 질의응답이라는 세 가지 태스크로 파이프라인을 정의한다. 
    3. 이 논문은 세 가지 태스크에서 F1 점수를 61.3, 25.1, 40.5로 보여주면서 계속해서 개선이 필요한 것을 보여주고, 향후 연구에 경쟁력 있는 기준을 마련한다.

###### Addressing the Length Bias Challenge in Document-Level Neural Machine Translation (https://aclanthology.org/2023.findings-emnlp.773/)
- Anthology ID: 2023.findings-emnlp.773 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 문서 수준의 신경 기계 번역은 최대 문장 길이를 늘림으로써 문맥 정보를 통합함으로써 유망한 결과를 보여주었다. 그러나 이 접근 방식은 문장의 길이에 대한 편향 문제를 도입하며, 훈련 중에 최대 문장 길이보다 훨씬 짧거나 긴 문장을 디코딩 할 때 번역 품질이 크게 저하된다.
    2. 우리는 모델이 더 짧은 문장을 무시하지 않도록 훈련 데이터를 샘플링하여 서로 다른 문장 길이 간에 보다 균일한 분포를 보장함으로써 이 문제를 해결한다. 또한, 긴 문장을 처리하는 동안 주목의 발산 문제를 완화하기 위해 길이 정규화된 어텐션 메커니즘을 도입한다.
    3. 실험 결과는 우리의 방법이 여러 개의 공개된 데이터셋에서 최고 수준의 결과를 달성할 수 있으며, 더 나아가 우리의 방법이 길이 편향 문제를 크게 완화시킬 수 있음을 보여주었다.

###### EconBERTa: Towards Robust Extraction of Named Entities in Economics (https://aclanthology.org/2023.findings-emnlp.774/)
- Anthology ID: 2023.findings-emnlp.774 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 특정 도메인 내에서 일반적인 언어 모델을 적용하는 것은 효과적인 방법으로 나타났다. 이 논문에서는 경제 문헌에서 entity를 추출하는 작업을 다루고 있다.
    2. EconBERTa라는 대용량 언어 모델을 소개하고, 이를 경제학의 논문들에 pretrain시킨다. 또한, 새로운 경제학 논문들을 Named Entity Recognition (NER)을 위해 전문가에 의해 어노테이팅하여 새로운 데이터셋 ECON-IE를 발표한다.
    3. EconBERTa가 NER 작업에서 최고 성능을 달성하며, 일반화 능력을 상세하게 분석한 결과, 대부분의 오류가 entity의 일부만 감지되거나 더 긴 시퀀스에 대해 추론하지 못하는 것으로 나타났다. 이 한계는 훈련 중에 보지 못한 형태소 순서를 감지하지 못하는 능력부족 때문이다. 이 한계는 훈련 세트의 고유한 인스턴스 수가 증가할수록 줄어든다. 도메인 특화 언어 모델의 일반화 능력을 조사함으로써 인과지식 추출을 위한 NER 모델의 강건성 향상을 위한 길을 열 수 있다.

###### Consonant is all you need: a compact representation of English text for efficient NLP (https://aclanthology.org/2023.findings-emnlp.775/)
- Anthology ID: 2023.findings-emnlp.775 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 자연어 처리(NLP)에서 텍스트의 표현은 언어 모델링, 감성 분석, 기계 번역과 같은 다양한 작업에서 중요한 역할을 한다. 이 논문에서는 텍스트를 자음으로만 표현하는 새로운 접근 방식을 제안하며, 성능을 희생하지 않고 향상된 효율성을 제공한다.
    2. 우리는 자음이 모음보다 구분성이 뛰어나다는 사실을 활용하고, 텍스트를 자음으로 표현함으로써 텍스트 데이터를 저장하고 처리하기 위해 필요한 메모리와 연산량을 크게 줄일 수 있다.
    3. 실험 결과, 우리의 자음 기반 표현은 표준 텍스트 표현에 비해 비슷한 성능을 보이며 훨씬 적은 계산 자원을 요구한다는 것을 보여준다. 또한, 우리의 표현은 기존 NLP 모델과 프레임워크와 원활하게 통합될 수 있다는 것을 보여주며 효율적인 텍스트 처리에 대한 실용적인 해결책을 제공한다.

###### Detrimental Contexts in Open-Domain Question Answering (https://aclanthology.org/2023.findings-emnlp.776/)
- Anthology ID: 2023.findings-emnlp.776 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 지식 집약적인 NLP 태스크에서는 더 많은 정보에 접근하는 것이 모델의 최종 성능 향상에 도움이 된다고 알려져 있다. 그러나 paradimn QA 데이터셋에서는 많은 문맥이 모델에 부정적인 영향을 미칠 수 있다는 놀라운 사실이 있다.
    2. 이 논문에서는 질문 응답에 사용되는 retrieve-then-read 아키텍처에서 passages가 어떻게 악영향을 미치는지 분석한다. 실험 결과, 현재의 read 아키텍처는 검색된 passages을 제대로 활용하지 못하며, 전체 passages를 활용하는 것보다 이들의 부분집합을 활용하는 것이 성능을 크게 저하시킨다.
    3. 우리의 연구 결과는 유해한 passages을 걸러내면 두 가지 인기 있는 QA 데이터셋에서 모델의 정확도를 10% 향상시킬 수 있다는 것을 보여준다. 또한, 이러한 결과는 추가적인 훈련이나 데이터 없이 이미 존재하는 retrieval 방법을 활용하여 얻을 수 있다.

###### PMIndiaSum: Multilingual and Cross-lingual Headline Summarization for Languages in India (https://aclanthology.org/2023.findings-emnlp.777/)
- Anthology ID: 2023.findings-emnlp.777 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 이 논문은 PMIndiaSum이라는 다국어 및 대규모 요약 말뭉치를 소개하며, 인도 언어에 집중한다. 이 말뭉치는 4개의 언어 패밀리, 14개의 언어, 그리고 196개의 언어 쌍을 대상으로 한 최대 규모의 데이터이다. 
    2. 또한, 데이터 획득, 처리, 품질 관리를 포함한 구축 워크플로우를 상세히 설명한다. 
    3. 실험 결과는 PMIndiaSum 데이터가 인도어 간 요약에 도움이 되는 중요한 역할을 한다는 것을 확인하며, 이 데이터는 공개적으로 이용 가능하며 자유롭게 수정 및 재배포할 수 있다.

###### Beyond Labels: Empowering Human Annotators with Natural Language Explanations through a Novel Active-Learning Architecture (https://aclanthology.org/2023.findings-emnlp.778/)
- Anthology ID: 2023.findings-emnlp.778 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 실제 도메인 전문가들은 (의사 등) 단순히 결정 레이블을 주지 않고도 설명을 함께 제공하는데, 기존의 저자원 학습 기법들은 단어에 초점을 맞추어 설명을 간과하고 있는 것으로 나타났습니다.
    2. 저희는 저자원 상황에서 전문가들이 라벨과 설명을 동시에 주는 현실 세계의 요구를 지원하기 위해 새로운 활성학습(AL) 아키텍처를 제안합니다.
    3. 저희의 AL 아키텍처는 인간의 설명을 가이드로 한 설명 생성 모델, 생성된 설명을 예측에 활용하는 예측 모델, 그리고 설명 주석에서 이점을 얻는 새로운 데이터 다양성 기반 AL 샘플링 전략을 활용합니다.

###### Decoding Stumpers: Large Language Models vs. Human Problem-Solvers (https://aclanthology.org/2023.findings-emnlp.779/)
- Anthology ID: 2023.findings-emnlp.779 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 이 논문은 Large Language Models (LLMs)의 문제 해결 능력을 조사하고, 사람의 퍼포먼스와 비교하여 평가한다. 
    2. 새로운 세대의 LLMs는 stumpers(짧은 질문)를 풀 때 우수한 성능을 보이며, 인간의 퍼포먼스를 앞지를 수 있다.
    3. 그러나, 인간은 동일한 문제의 해답을 검증하는 데에는 뛰어난 기술을 보인다고 한다. 이 연구는 LLMs의 인지 능력을 이해하고 다양한 분야에서 문제 해결 능력을 향상시키는 데에 참고할 수 있는 정보를 제공한다.

###### Efficient Cross-Task Prompt Tuning for Few-Shot Conversational Emotion Recognition (https://aclanthology.org/2023.findings-emnlp.780/)
- Anthology ID: 2023.findings-emnlp.780 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 감정인식 대화 (ERC)는 감정인식 가능한 감정적 기계를 개발하기 위한 중요성으로 인해 많이 연구되었다. 최근 PLMs(사전 훈련된 언어 모델)을 이용한 ERC 연구들은 대부분 데이터 중심적이며, 전체 PLMs를 fine-tuning하는 것을 요구한다. 
    2. 이 논문에서는 최소 데이터 및 계산 비용으로 매수 대화식 감정 인식을 개선하기 위해 Cross-Task Prompt Tuning (CTPT)이라고 불리는 기울기 없는 최적화 방법 제안한다.
    3. CTPT는 개별 태스크의 독립적인 지식을 학습하는 기존 방법과는 달리, 다른 소스 태스크의 외부 지식을 활용하여 희소 셋팅에서의 학습 성능을 개선하는 작업 간 공유 가능한 지식을 활용한다.

###### SYMPTOMIFY: Transforming Symptom Annotations with Language Model Knowledge Harvesting (https://aclanthology.org/2023.findings-emnlp.781/)
- Anthology ID: 2023.findings-emnlp.781 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 고위험의 의료결정에서 카카스의 효율성을 향상시키기 위해 완전 자동화 솔루션으로써가 아니라 사람의 주석 작성자의 효율성을 향상시키기 위해 노력하고 있다.
    2. 우리는 SYMPTOMIFY라고 불리는 새로운 데이터셋을 소개한다. 이 데이터셋은 개별 백신 반응에 대한 주석이 달린 예방 접종 부작용 보고서를 포함하고 있다.
    3. 우리는 어떤 방법과 학습 패러다임을 사용했는지에 대한 성능을 평가하여 앞으로 비교와 기준을 제시하는 방법을 제공한다.

###### TokenDrop + BucketSampler: Towards Efficient Padding-free Fine-tuning of Language Models (https://aclanthology.org/2023.findings-emnlp.782/)
- Anthology ID: 2023.findings-emnlp.782 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 최근 언어 모델(LMs)의 성공은 pre-training 단계와 fine-tuning 단계 모두에서 계산적인 어려움을 동반한다. 그 중 fine-tuning 과정에서 가변 길이의 입력 시퀀스로 인해 padding 토큰이 필요하지만, 이러한 padding 토큰이 불필요한 연산을 유발하여 fine-tuning의 효율성을 저하시킨다.
    2. 이 논문에서는 TokenDrop + BucketSampler라는 프레임워크를 제안하여 fine-tuning의 효율성과 정확성을 동시에 개선한다. BucketSampler는 시퀀스 길이의 분산을 줄여 padding 토큰의 수를 감소시키는데, 이전 접근법과는 달리 정확성 감소 없이 대안을 제시한다.
    3. TokenDrop은 과적합을 방지하기 위해 매 에폭마다 각 입력 시퀀스에서 무의미한 토큰의 일부를 임의로 제거하는 새로운 정규화 방법이다. TokenDrop + BucketSampler는 기존의 fine-tuning 방법에 비해 최대 10.61배 정도의 가속을 실현하면서 1.17% 정확성 향상을 보여준다.

###### Unified Representation for Non-compositional and Compositional Expressions (https://aclanthology.org/2023.findings-emnlp.783/)
- Anthology ID: 2023.findings-emnlp.783 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 비 구성적 언어의 정확한 처리를 위해서는 해당 표현에 대한 잘 된 표현을 생성하는 것이 필요한데, 이 논문에서는 BART를 기반으로 한 PIER+이라는 언어 모델을 제안하여 영어에서 비구성적인 표현을 의미 있는 의미론적인 표현으로 만들 수 있다는 것을 보여주었다. 
    2. PIER+로 생성된 표현은 BART보다 임베딩 군집화에 더 나은 일관성 점수를 가지고 있으며, PIE 의미 분류와 구간 탐지의 경우 최신 IE 표현 모델인 GIEA와 비교했을 때 3.12%와 3.29%의 정확도 및 시퀀스 정확도 향상을 보였다.
    3. 이러한 향상은 PIER+의 NLU 작업에서의 성능 (+/- 1% 정확도)을 희생하지 않고 이루어진다.

###### Context Quality Matters in Training Fusion-in-Decoder for Extractive Open-Domain Question Answering (https://aclanthology.org/2023.findings-emnlp.784/)
- Anthology ID: 2023.findings-emnlp.784 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 검색 보완 생성 모델은 생성 중에 추가적인 관련 외부 지식(컨텍스트)을 제공하여 언어 모델로부터 지식을 확장시킨다. 그러나 컨텍스트의 양과 품질이 검색 보완 생성 모델의 성능에 영향을 주는 것이 밝혀졌으나, 이러한 특성이 모델 훈련에 어떤 영향을 미치는지에 대한 연구는 제한적이다.
    2. 본 논문에서는 모델 훈련 중 컨텍스트의 양과 품질이 추출형 개방형 도메인 질문 응답 작업에서 최고 수준의 검색 보완 생성 모델인 FiD의 성능에 어떻게 영향을 미치는지 조사한다.
    3. 실험 결과는 FiD 모델이 훈련 중에 컨텍스트 품질에 과적합되어, 다른 컨텍스트 품질로 평가할 때 최적화되지 않은 성능을 보인다는 것을 보여준다. 이러한 관찰을 바탕으로, 우리는 교차 어텐션 분포에 편향성을 도입하여 특정 컨텍스트 품질에 대한 과적합을 완화하는 방법을 제안하고, 이는 FiD 모델의 성능을 향상시키는 데 효과적임을 시연한다.

###### Error Detection for Text-to-SQL Semantic Parsing (https://aclanthology.org/2023.findings-emnlp.785/)
- Anthology ID: 2023.findings-emnlp.785 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 최근 텍스트-SQL 의미 해석에서 상당한 진전이 있었지만, 기존 파서의 성능은 여전히 완벽하게는 못 미치고 있다. 특히, 딥 러닝을 기반으로 한 파서들은 종종 자신감이 너무 강해서 실제 사용 시 신뢰성이 의심된다.
    2. 본 논문에서는 텍스트-SQL 의미 해석을 위한 파서 독립적 오류 탐지 모델을 제안한다. 코드의 언어 모델을 기반으로 하여 자연어 질문과 SQL 쿼리의 구조적 특징을 학습하는 그래프 신경망을 이용하여 오류 탐지 모델을 개선한다.
    3. 여러 가지 디코딩 메커니즘을 가진 세 개의 강력한 텍스트-SQL 파서들과의 실험 결과, 우리의 방법이 파서 종속적인 불확실성 메트릭보다 우수한 결과를 나타낸다. 또한, 우리의 모델은 아키텍처와 상관없이 텍스트-SQL 의미 해석기의 성능과 사용성을 효과적으로 향상시킬 수 있다.

###### Ultra-Fine Entity Typing with Prior Knowledge about Labels: A Simple Clustering Based Strategy (https://aclanthology.org/2023.findings-emnlp.786/)
- Anthology ID: 2023.findings-emnlp.786 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. Ultra-fine entity typing (UFET)은 주어진 개체 언급에 적용되는 다양한 fine-grained 후보들 중에서 시맨틱 타입을 추론하는 작업이다. 이 작업은 많은 타입에 대해 훈련 예제가 적기 때문에 특히 어렵다. 하지만 pre-trained label embeddings을 사용하여 레이블을 의미 도메인으로 클러스터링하는 간단한 기술을 사용하면 기존 방법들의 성능을 향상시킬 수 있다.
    2. 레이블 클러스터는 간단한 후처리 기술에 사용되어 더 나은 결과를 얻을 수 있다.
    3. 둘 다 UFET 모델을 블랙 박스로 취급하여 기존 모델의 성능을 개선하는 데 사용할 수 있다.

###### Multilingual Coarse Political Stance Classification of Media. The Editorial Line of a ChatGPT and Bard Newspaper (https://aclanthology.org/2023.findings-emnlp.787/)
- Anthology ID: 2023.findings-emnlp.787 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 뉴럴 네트워크 기반의 언어 모델이 신문 기사를 작성할 수 있게 되었을 때, 그 신문의 편견이 뉴럴 네트워크의 편견과 일치하는지, 또는 다른지 알아보려고 저자들은 평가 점수를 기반으로 한 공식적인 뉴스매체의 평가를 사용하여 다국어 코퍼스를 만들었다. 
    2. 이 실험에서 우리는 영어, 독일어, 스페인어, 카탈로니아어에서 보이는 반면, ChatGPT나 Bard로 작성된 신문과 유사한 4개 언어의 101개 기사에 이러한 분류기를 적용하여, 전통적인 신문과 마찬가지로 ChatGPT의 편집 선도 시간이 지남에 따라 변화하며, 데이터 기반 시스템이므로 생성된 기사의 성격은 언어에 따라 다르다는 것을 알 수 있었다.

###### Do “English” Named Entity Recognizers Work Well on Global Englishes? (https://aclanthology.org/2023.findings-emnlp.788/)
- Anthology ID: 2023.findings-emnlp.788 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 인기있는 영어 개체명 인식(NER) 데이터셋의 대부분은 미국이나 영국의 데이터를 포함하고 있으며, 세계 각지의 영어 사용 분석에 적합한지 여부는 불명확하다. 
    2. 이 연구에서는 Worldwide English NER Dataset이라는 신문 데이터셋을 구축하여 세계의 저자원 영어 변종에서 NER 모델의 성능을 분석한다. 
    3. CoNLL 또는 OntoNotes 데이터셋으로 훈련된 모델은 Worldwide English 데이터셋에 대한 성능이 현저히 하락함을 확인하였고, Worldwide 데이터셋과 CoNLL 또는 OntoNotes 데이터셋으로 훈련된 결합 모델은 테스트 세트에서 F1이 1-2 정도만 하락하였다.

###### Affective and Dynamic Beam Search for Story Generation (https://aclanthology.org/2023.findings-emnlp.789/)
- Anthology ID: 2023.findings-emnlp.789 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 이 논문에서는 흥미로운 이야기를 생성하기 위해 Affective Story Generator (AffGen)을 제안한다. AffGen은 Dynamic Beam Sizing과 Affective Reranking이라는 두 가지 새로운 기법을 사용하여 이야기에 "흥미로운 전개"를 도입한다. 
    2. Dynamic Beam Sizing은 문맥 기반의 다중암 바둑판 모델을 사용하여 예측되기 어려운, 더 흥미로운 단어 선택을 촉진한다. Affective Reranking은 감정 강도를 기준으로 문장 후보들을 우선순위화한다.
    3. 자동 및 인간 평가를 통해 우리는 AffGen이 감정적으로 동기를 부여하고 흥미로운 이야기를 생성하는 기존 기준들보다 우수한 성능을 보여준다는 것을 확인하였다. 우리의 분석은 AffGen의 강점과 약점에 대한 통찰력을 제공한다.

###### Multiview Clickbait Detection via Jointly Modeling Subjective and Objective Preference (https://aclanthology.org/2023.findings-emnlp.790/)
- Anthology ID: 2023.findings-emnlp.790 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 클릭베이트 타이틀은 사람들의 주의와 감정을 조작하기 위해 부정확하거나 오도하는 정보를 유포하며, 소셜미디어의 신뢰성을 크게 해치고 있다. 
    2. 기존의 클릭베이트 검출 모델은 게시물의 객관적 의미를 분석하거나 기사 내용과 연관성을 분석하는 것에만 의존하여 사용자의 주관적인 조작 의도를 파악하지 못한다. 
    3. 따라서, 이 논문에서는 주관적 및 객관적 기준을 동시에 모델링하는 다중 뷰 클릭베이트 검출 모델(MCDM)을 제안한다. MCDM은 주관적 감정과 객관적 컨텐츠 관련성을 모델링하기 위한 두 가지 새로운 보완재 모듈을 도입한다.

###### Let’s Synthesize Step by Step: Iterative Dataset Synthesis with Large Language Models by Extrapolating Errors from Small Models (https://aclanthology.org/2023.findings-emnlp.791/)
- Anthology ID: 2023.findings-emnlp.791 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 데이터 합성은 매우 적은 레이블 데이터로 작은 모델을 훈련시키는 유망한 방법이다. 그러나 합성된 데이터셋은 실제 태스크 데이터 분포와 분포적 불일치 문제가 있다. 
    2. 따라서 이 논문에서는 작은 모델을 합성된 데이터셋으로 훈련시켰을 때 작은 실제 세계 검증 데이터셋에서 대형 언어 모델을 사용하여 발생한 오류를 반복적으로 확장하여 분포 차이를 축소하는 데이터 합성 프레임워크인 S3를 제안한다. 
    3. 다양한 NLP 태스크에서의 실험 결과, S3가 합성 데이터와 실제 데이터 간의 차이를 줄여 작은 모델의 성능을 향상시켜 ZeroGen과 GoldGen에 비해 9.48%와 2.73%의 성능 향상을 보였으며, 인간 주석 데이터로 훈련된 작은 모델과 비교하여 최대 15.17%의 성능 향상을 얻을 수 있다.

###### Identifying Early Maladaptive Schemas from Mental Health Question Texts (https://aclanthology.org/2023.findings-emnlp.792/)
- Anthology ID: 2023.findings-emnlp.792 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 정서치료에서는 부정적 인식으로 인해 현실에도 불구하고 개인이 자신, 타인 또는 세상에 대해 가지는 부적응 스키마나 나쁜 생각이 있을 때, 우울증, 불안, 공황 발작 등과 같은 정신 건강 문제의 저항과 재발로 이어질 수 있습니다. 
    2. 이 논문에서는 스키마 요법기반 상담 세션에서의 필요성과, LLM (Large Language Models) 및 non-LLM 접근 방식을 사용하여 스키마 식별에 대해 연구합니다. 
    3. 우리의 평가 결과, 최신 LLM은 EMS 식별에 효과적일 수 있지만, 예측 결과의 설명 가능성이 부족하고 정확한 "프롬프트"에 지나치게 민감합니다. LLM 및 non-LLM 접근 방식 모두 EMS 라벨이 없는 경우를 신뢰성 있게 대응할 수 없습니다. 그러나 이 두 가지 접근 방식은 상호 보완적인 속성을 가지며, 함께 사용하여 EMS 식별 기술을 개발할 수 있다고 주장합니다.

###### Re-ViLM: Retrieval-Augmented Visual Language Model for Zero and Few-Shot Image Captioning (https://aclanthology.org/2023.findings-emnlp.793/)
- Anthology ID: 2023.findings-emnlp.793 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 사전 훈련된 language model(LM)에 비전 인코더를 추가하면 이미지에서 텍스트로의 생성 작업에서 최첨단 성능을 얻을 수 있다. 그러나, 이러한 모델은 많은 시각적 개념과 풍부한 텍스트 설명을 모델링하기 위해 엄청난 모델 파라미터가 필요하고, 새로운 데이터를 효율적으로 포함시키기 어려워 계산량이 많이 드는 fine-tuning 과정이 필요하다.
    2. 이 논문에서는 Flamingo 모델을 기반으로한 Retrieval-augmented Visual Language Model(Re-ViLM)을 소개한다. 이 모델은 외부 데이터베이스에서 관련 지식을 검색하여 zero-shot과 in-context few-shot 이미지-텍스트 생성 작업에서 사용된다.
    3. Re-ViLM은 외부 데이터베이스에 특정 지식을 명시적으로 저장함으로써 모델 파라미터의 수를 줄이고, 데이터베이스를 갱신하는 간단한 방법으로 새로운 데이터를 쉽게 수용할 수 있다. 또한, in-context few-shot 학습 기능을 용이하게 하는 interleaved 이미지와 텍스트 데이터를 구축하였다. 이 모델은 이미지-텍스트 생성 작업에서 특히 zero-shot과 few-shot 생성에서 4배 더 적은 파라미터를 가지면서 성능을 크게 향상시킨다.

###### Syntax Matters: Towards Spoken Language Understanding via Syntax-Aware Attention (https://aclanthology.org/2023.findings-emnlp.794/)
- Anthology ID: 2023.findings-emnlp.794 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. Task-oriented 대화 시스템에서 중요한 구성 요소인 Spoken Language Understanding (SLU)은 학계와 산업계에서 지속적인 관심을 받고 있다. 
    2. 우리는 구문 정보를 모델에 통합하여 사용자 발화의 이해를 향상시키고 높은 성능을 얻을 수 있는 SAT(Syntax-aware attention) 모델을 제안한다.
    3. 세 개의 데이터셋 실험 결과, 우리의 모델이 큰 향상과 훌륭한 성능을 보여준다. 또한 SAT는 다른 BERT 기반 언어 모델에 통합하여 성능을 더욱 향상시킬 수 있다.

###### Can ChatGPT Defend its Belief in Truth? Evaluating LLM Reasoning via Debate (https://aclanthology.org/2023.findings-emnlp.795/)
- Anthology ID: 2023.findings-emnlp.795 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. ChatGPT와 GPT-4와 같은 대형 언어 모델들은 복잡한 추론 과제에서 인상적인 성능을 보여주고 있다. 하지만 이 모델들이 진실과 논리에 대한 깊은 이해를 기반으로 추론을 하는지 아니면 상대적으로 표면적인 방식으로 메모리 패턴을 활용하는지에 대해서는 알기 어렵다.
    2. 본 논문에서는 논쟁과 유사한 대화를 통해 LLM의 추론을 테스트하는 방법을 제안한다. 사용자와 함께 정당한 결정을 내리기 위해 LLM에게 질문을 제시하고 논의를 통해 올바른 결론에 도달해야 한다. 이를 통해 LLM이 문제 해결에 필요한 추론의 본질을 깊게 이해하는지 테스트할 수 있다.
    3. 수학, 상식, 논리, BIG-Bench 과제 등 다양한 복잡한 추론 벤치마크에서 우리는 ChatGPT와 같은 LLM이 처음에는 올바른 단계별 해결책을 생성하는 데 탁월한 성과를 보이지만, 자주 불필요한 논증에 도전받을 때 그들의 믿음을 유지하지 못하는 것을 발견하였다.

###### Using In-Context Learning to Improve Dialogue Safety (https://aclanthology.org/2023.findings-emnlp.796/)
- Anthology ID: 2023.findings-emnlp.796 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 대화 모델들은 더 정확해졌지만, 독성과 편향성을 가진 대화를 생성하는 경우가 많다. 이 논문은 안전한 대화를 위해 retrieval 기반 접근 방법을 연구하고, 안전한 응답에 대한 영감을 얻기 위해 유사한 대화 상황에서 안전한 응답을 찾는 방법을 제안한다. 
    2. 이 방법은 학습 없이도 기존의 대화 안전 접근 방법들과 경쟁력 있는 성과를 보이며, 자동 및 인간 평가에서 독성을 줄이면서 동시에 매력성과 일관성을 유지할 수 있다고 보여준다. 
    3. 추가로 이 방법은 RLHF와 같은 기존의 대화 안전 접근 방법과 함께 사용될 수 있다는 점을 언급한다.

###### HEAR: Hearing Enhanced Audio Response for Video-grounded Dialogue (https://aclanthology.org/2023.findings-emnlp.797/)
- Anthology ID: 2023.findings-emnlp.797 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. "Video-grounded Dialogue (VGD)"는 비디오, 오디오, 대화 이력을 포함한 다중 모달 입력에 대한 질문에 대답하는 것을 목표로 한다. 
    2. 기존의 VGD 시스템은 비디오와 텍스트 정보만을 활용하여 응답의 품질을 개선할 수 있었지만, 의문에 적절한 응답을 생성하는 과정에서 오디오에서 필요한 정보를 추출하기 어려워 한다.
    3. 따라서, 논문에서는 오디오 데이터를 무시하는 현재의 시스템의 증상인 "deaf response" 문제를 극복하기 위해 HEAR (Hearing Enhanced Audio Response) 프레임워크를 제안한다. HEAR은 질문에서 필요한 경우에만 오디오에 주의를 기울여 신중하게 듣는 것을 목표로 한다.

###### Improving Consistency for Text Summarization with Energy Functions (https://aclanthology.org/2023.findings-emnlp.798/)
- Anthology ID: 2023.findings-emnlp.798 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 현재의 요약 모델은 일관되지 않은 내용을 생성하는데, 이는 출처 문서에서 직접 추론할 수 없는 텍스트이거나 세계적인 지식과 일치하지 않거나 상반된 내용일 수 있다. 이 문제들에 대해 이 논문에서는 "신뢰성(faithfulness)", "사실적임(factuality)", 그리고 "자기주장(self-supportiveness)"을 다루기 위해 새로운 일관성 갈래를 소개한다.
    2. 그러나, 최근의 일관성 개선 연구들은 대부분 "신뢰성"만을 다루고 다른 일관성 현상들을 무시하여 모델의 확장성을 제한하고 있다.
    3. 따라서, 이 연구에서는 "에너지 썸(EnergySum)"을 소개하며 각 유형의 일관성을 반영하는 에너지 스코어를 설계하여 후보 선정 과정에서 활용하는 방법을 제안한다. XSUM 및 CNN/DM 데이터셋에서의 실험 결과, EnergySum은 정확성과 일관성 사이의 trade-off를 완화시킨다.

###### Defining a New NLP Playground (https://aclanthology.org/2023.findings-emnlp.799/)
- Anthology ID: 2023.findings-emnlp.799 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Authors: Houda Bouamor | Juan Pino | Kalika Bali 
- Summary: 
    1. 대형 언어 모델 (LLM)의 최근 성능 폭발은 자연어 처리 (NLP) 분야에서 80년 역사 중 가장 급격하고 변화를 가져왔다. 이로 인해 이 분야가 동질화되고 리소스를 많이 소요하는 우려가 생겼다.
    2. 본 논문은 이러한 새로운 상황에서 많은 학계 연구자, 특히 박사과정 학생들에게 불리한 상황을 야기하였다. 따라서 본 논문은 이를 극복하기 위해 이론적 분석, 새로운 도전적인 문제, 학습 패러다임 및 교차 학문적 응용 분야를 다루는, 20개 이상의 박사 학위 논문 수준의 연구 방향을 제안한다.


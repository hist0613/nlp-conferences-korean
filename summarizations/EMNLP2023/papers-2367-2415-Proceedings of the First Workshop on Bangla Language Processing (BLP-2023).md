# Korean Three-Line Summarizations of Papers 2367-2415 in Proceedings of the First Workshop on Bangla Language Processing (BLP-2023)
###### Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) (https://aclanthology.org/2023.banglalp-1.0/)
- Anthology ID: 2023.banglalp-1.0 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors:  
- Summary: 
    요약문을 생성할 수 없습니다.

###### Offensive Language Identification in Transliterated and Code-Mixed Bangla (https://aclanthology.org/2023.banglalp-1.1/)
- Anthology ID: 2023.banglalp-1.1 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 온라인 커뮤니티를 안전하게 만들기 위해서는 소셜 미디어에서의 모욕적인 콘텐츠를 식별하는 것이 중요하다. 본 논문은 다국어 사회에서 일반적인 언어 현상인 표기변경과 코드믹싱으로 구성된 텍스트에서 모욕적 언어를 식별하는 방법을 탐구한다. 
    2. 우리는 5,000개의 수작업으로 주석이 달린 코멘트가 포함된 표기변경된 방글라어 모욕적 언어 데이터셋인 TB-OLID를 소개한다. 
    3. TB-OLID에서 기계 학습 모델을 훈련 및 세밀화한 후 이 데이터셋에서 결과를 평가한 결과, fBERT와 HateBERT와 같은 영어로 사전 훈련된 transformer 기반 모델이 가장 우수한 성능을 보여주었다.

###### BSpell: A CNN-Blended BERT Based Bangla Spell Checker (https://aclanthology.org/2023.banglalp-1.2/)
- Anthology ID: 2023.banglalp-1.2 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 방글라어 타이핑은 주로 영어 키보드를 사용하며, 조합된 문자와 비슷한 발음의 문자 때문에 맞춤법이 많이 틀리다. 
    2. 이 논문에서는 문장 수준에서 단어를 단어별로 수정하기 위해 BSpell 이라는 특화된 BERT 모델을 제안한다. 
    3. BSpell은 스펠링 에러가 있는 상황에서 highly inflected 방글라 단어에 특화된 CNN 하위 모델인 SemanticNet과 특화된 보조 손실을 포함하고 있다.

###### Advancing Bangla Punctuation Restoration by a Monolingual Transformer-Based Method and a Large-Scale Corpus (https://aclanthology.org/2023.banglalp-1.3/)
- Anthology ID: 2023.banglalp-1.3 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 문장부호 복구는 텍스트 내 누락되거나 잘못 된 문장부호를 복원하고 온문에서 모호성을 제거하기 위한 작업이다. 하지만 방글라어에서는 이 작업이 적게 주목받아왔으며, 이를 위한 transformer 기반 방법과 대규모 말뭉치의 활용 등의 문제가 여전히 해결되지 않은 상태이다.
    2. 본 연구에서는 Jatikarok이라는 단일 언어 transformer 기반 방법을 제안하고, 전이 학습의 효과를 철저히 조사하며 이전의 문제를 해결하기 위해 1.48M개의 소스-타겟 쌍을 포함하는 대규모 말뭉치를 제공하였다.
    3. Jatikarok은 BanglaPRCorpus, Prothom-Alo Balanced, BanglaOPUS 말뭉치에서 95.2%, 85.13%, 91.36%의 정확도를 달성하여 BanglaT5 및 T5-Small 대비 우수한 성능으로 state-of-the-art 방법임을 입증하였다. Jatikarok과 BanglaPRCorpus는 공개적으로 사용 가능하다.

###### Pipeline Enabling Zero-shot Classification for Bangla Handwritten Grapheme (https://aclanthology.org/2023.banglalp-1.4/)
- Anthology ID: 2023.banglalp-1.4 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 이 연구는 Zero-Shot Learning (ZSL)을 조사하고 CycleGAN 기반의 이미지 합성과 정확한 레이블 매핑을 제안하여 레이블과 그래프 사이에 강한 연관성을 형성한다. 이를 통해 보이지 않는 클래스를 탐지하는 모델의 정확성을 향상시키는 것을 목표로 한다. 
    2. 본 연구는 복잡한 벵골어 문자 인식 문제를 다룬다. 그래프의 복잡한 배열로 인해 문자 조합은 영어보다 많은 약 13,000개의 고유한 변형을 만들어 낼 수 있다. 
    3. 벵골어 OCR의 진척을 향상시키기 위해 생성 모델과 신중한 레이블링 기술을 결합하는 새로운 ZSL 전략을 제시한다. 이는 인도 하위대륙의 교육 자원의 디지털화에 상당한 영향을 미치고자 하는 것이다.

###### Low-Resource Text Style Transfer for Bangla: Data & Models (https://aclanthology.org/2023.banglalp-1.5/)
- Anthology ID: 2023.banglalp-1.5 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 주어진 텍스트의 언어적 스타일을 변경하면서 핵심 콘텐츠를 유지하는 텍스트 스타일 변환 작업이 있다. 그러나 이 논문은 이러한 작업을 수행하는 데에 어려움이 있는 방글라어 언어로 된 텍스트 스타일 변환에 대해 다루고 있다.
    2. 방글라어를 이용한 텍스트 감정 전환 데이터셋을 제안함으로써 이 작업의 어려움을 극복하려고 한다. 이 데이터셋을 사용하여 긍정적인 감정 문장을 부정적으로 변환하거나 그 반대로 변환할 수 있도록 한다.
    3. 더 나은 연구를 위해 기존의 영어 데이터셋을 정제하고 수정하고, 영어 자료와 유사한 방글라어 데이터셋을 소개한다. 또한 데이터셋을 검증하고 더 나은 연구를 위한 베이스라인으로 사용될 수 있는 여러 벤치마크 모델을 제공한다.

###### Intent Detection and Slot Filling for Home Assistants: Dataset and Analysis for Bangla and Sylheti (https://aclanthology.org/2023.banglalp-1.6/)
- Anthology ID: 2023.banglalp-1.6 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 음성 어시스턴트가 우리의 기술적으로 선진화된 사회에서 자리를 잡으면서, 비공식적인 형태의 저자원 언어를 포함한 다양한 언어적 환경에 대응할 필요가 여전히 존재한다.
    2. 이 연구는 형식적인 방글라어, 비공식적인 방글라어, 실헤티어에서의 의도 감지와 슬롯 채우기에 대한 포괄적인 데이터셋을 처음으로 제시한다.
    3. 우리의 분석 결과는 대용량 언어 모델의 강건성과 작은 데이터로도 다양한 하위 작업을 처리하는 능력을 보여준다. 또한, GPT-3.5 모델은 비공식적인 방글라어에서 의도 감지에서 0.94의 F1 점수, 슬롯 채우기에서 0.51의 F1 점수를 달성한다.

###### BEmoLexBERT: A Hybrid Model for Multilabel Textual Emotion Classification in Bangla by Combining Transformers with Lexicon Features (https://aclanthology.org/2023.banglalp-1.7/)
- Anthology ID: 2023.banglalp-1.7 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 다중 수준 텍스트 감성 분류는 텍스트 데이터에서 감정을 추출하는 작업으로, 고대용량 언어에 대해서는 상당한 진전이 있었으나 Bangla와 같은 저자원 언어에는 상대적으로 덜 주목되고 있다.
    2. 본 논문에서는 Bangla 언어를 위해 lexicon 특징과 transformers를 결합한 하이브리드 모델을 제안한다.
    3. 실험 결과 lexicon 특징을 transformers와 통합하는 것이 성능을 크게 향상시킨다는 것을 보였으며, 제안한 하이브리드 접근법은 BanglaBERT와 감정 lexicon을 사용하여 가장 높은 성능을 달성한다.

###### Assessing Political Inclination of Bangla Language Models (https://aclanthology.org/2023.banglalp-1.8/)
- Anthology ID: 2023.banglalp-1.8 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 인공지능 주도 언어 모델의 발전으로 자연어 처리는 텍스트 생성부터 질문에 답하기까지 넓은 범위에서 적용되고 있다. 
    2. 그러나 이 모델들은 다양한 데이터 소스에서 사전 학습되는 과정에서 훈련 데이터 내에서 포함된 다양한 시각을 무의식적으로 흡수하게 된다. 
    3. 이 논문은 저자들이 사회적, 경제적 차원에 초점을 맞추어 방글라 언어 모델 내에 존재하는 편향성을 포괄적으로 분석하고, 배울 점과 주의해야 할 윤리적 고려사항과 한계에 대한 통찰을 제공한다.

###### Vio-Lens: A Novel Dataset of Annotated Social Network Posts Leading to Different Forms of Communal Violence and its Evaluation (https://aclanthology.org/2023.banglalp-1.9/)
- Anthology ID: 2023.banglalp-1.9 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 이 논문에서는 방글라데시와 인도 서벵갈 지역의 사회적 폭력에 관련된 데이터셋을 생성하고, 평가하기 위한 계산적 접근 방식을 제안한다.
    2. 소셜 미디어가 종교적·인종적 혐오를 조장하여 실제 폭력으로 이어지는 문제를 해결하기 위해, 우리는 적응형 질문 기반 접근 방식을 사용하여 온라인 게시물을 분류하는 프레임워크를 제안한다.
    3. 수작업으로 선택된 폭력 조장 동영상에서 168,000개 이상의 YouTube 댓글을 수집하고, 비구조화된 데이터에 대해 비지도 및 반지도 학습 기법을 사용하여 평화와 폭력에 관련된 주요 단어 집합을 발견하였으며, 이를 통해 레이블이 부여된 6,046개의 게시물을 검증하기 위해 언어적 특징 및 문장 변형기법을 적용하여 최고 성능 모델에서 약 71%의 매크로 F1 점수로 평가하였다.

###### BanglaCHQ-Summ: An Abstractive Summarization Dataset for Medical Queries in Bangla Conversational Speech (https://aclanthology.org/2023.banglalp-1.10/)
- Anthology ID: 2023.banglalp-1.10 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 온라인 건강 상담은 환자들이 의료 문의를 나누는 플랫폼으로 인기를 얻고 있으며 COVID-19 대유행으로 인하여 더 많은 질문이 달려, 한정된 의료진에게 부담을 주고 있다.
    2. 추상적 텍스트 요약은 이 도전에 대한 유망한 솔루션이며, CHQ(Consumer Health Questions)를 답변하는 데 필요한 정보만 요약함으로써 불필요한 정보를 파싱하는 데 필요한 시간을 줄일 수 있는 장점을 가진다. 이 요약 과정은 최종적으로 자동 의료 질문-응답 시스템을 개발하기 위한 중간 단계로서도 활용될 수 있다.
    3. 이 논문은 예를 들어, 2,350개의 질문-요약 쌍으로 구성된 배제어 요약 데이터셋인 'BanglaCHQ-Summ'을 제공하며, Bangla 및 다국어 텍스트 생성 모델과의 벤치마크를 제시하였다. 최고 성능을 내는 BanglaT5 모델은 ROUGE-L 점수 48.35%를 달성하였고, 인간 평가를 통해 요약에 대한 기존 자동 메트릭스의 한계를 해결하였다.

###### Contextual Bangla Neural Stemmer: Finding Contextualized Root Word Representations for Bangla Words (https://aclanthology.org/2023.banglalp-1.11/)
- Anthology ID: 2023.banglalp-1.11 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 기존의 스테머(stemmer) 방법은 NLP에서 단어를 뿌리 형태로 줄이는 데 사용되지만, 이 과정에서 중요한 정보가 손실되고 잘못된 뿌리 형태가 생성되어 NLP 작업의 정확성에 영향을 미칠 수 있다.
    2. 이 논문에서는 방글라어를 위한 문맥적 신경 스테머(Contextual Bangla Neural Stemmer)를 제안하여 단어 표현을 향상시킨다. 
    3. 실험 결과로 우리는 vanilla 방법에 비해 약 5%의 평균 성능 향상을 보였고, BERT 재학습을 회피하면서 OOV(out-of-vocabulary) 단어 및 서브워드 문제를 해결하고 뿌리 단어 감지에 초점을 맞춘 메소드입니다.

###### Investigating the Effectiveness of Graph-based Algorithm for Bangla Text Classification (https://aclanthology.org/2023.banglalp-1.12/)
- Anthology ID: 2023.banglalp-1.12 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 이 연구에서는 방글라 텍스트 분류 작업에 대한 여러 그래프 기반 모델들의 동작을 조사하고 분석한다. 그래프 기반 알고리즘은 텍스트 데이터로부터 이질적 그래프를 생성한다. 각 노드는 단어나 문서를 나타내고, 각 엣지는 두 단어나 단어와 문서 간의 관계를 나타낸다.
    2. BERT 모델과 TextGCN, GAT, BertGAT, BertGCN과 같은 다양한 그래프 기반 모델들을 방글라 텍스트에 대해 SentNoB, Sarcsam detection, BanFakeNews, Hate speech detection, Emotion detection 데이터셋을 사용하여 평가했다.
    3. BERT 모델이 정확도, Macro F1 스코어, weighted F1 스코어 측면에서 TextGCN과 GAT 모델을 큰 차이로 앞서고, BertGCN과 BertGAT이 단독 그래프 모델 및 BERT 모델보다 우수한 성능을 보였다. BertGAT은 Emotion detection 데이터셋에서 높은 성능을 보여주었으며, Sarcasm detection, Hate speech detection, BanFakeNews 데이터셋에서 BERT 성능에 1%-2%까지 향상되었다. BertGCN은 SetNoB, BanFakeNews 데이터셋에서 BertGAT을 1% 이상 앞섰으며, Sarcasm detection, Hate Speech, Emotion detection 데이터셋에서 2% 이상의 성능 향상이 있었다. 그래프 구조의 다양한 변화와 그 영향도 분석했다.

###### SynthNID: Synthetic Data to Improve End-to-end Bangla Document Key Information Extraction (https://aclanthology.org/2023.banglalp-1.13/)
- Anthology ID: 2023.banglalp-1.13 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 엔드투엔드 문서 핵심 정보 추출 모델은 실제 데이터셋에서 잘 작동하기 위해 많은 계산량과 레이블된 데이터가 필요하다. 특히 도메인별 다중모달 문서 데이터셋이 제한적인 번글라(Bangla)와 같은 저자원 언어에 대해서는 이것이 도전적이다.
    2. 우리는 SynthNID라는 시스템을 도입하여 OCR 없는 엔드투엔드 핵심 정보 추출 시스템을 훈련시키기 위한 도메인별 문서 이미지 데이터를 생성했다.
    3. 우리는 생성된 데이터가 실제 데이터셋에서 추출 모델의 성능을 향상시키고, 이 시스템은 다양한 문서 이해 작업에 대해 다른 유형의 스캔된 문서를 생성하는 데 쉽게 확장할 수 있다는 것을 보였다.

###### BaTEClaCor: A Novel Dataset for Bangla Text Error Classification and Correction (https://aclanthology.org/2023.banglalp-1.14/)
- Anthology ID: 2023.banglalp-1.14 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 방글라 언어에서는 다양한 요인으로 인해 온라인 사용자들이 언어를 비틀거나 오류를 만들기 쉽다. 이 논문에서는 기계 학습과 심층 학습 모델을 사용하여 이러한 오류를 탐지, 분류 및 교정하려고 한다. 
    2. 방글라BERT는 오류 범주 분류에서 우수성을 보이며, BanglaT5는 텍스트 교정에 효과적임을 강조한다. 
    3. 이 연구는 방글라어 사용자 커뮤니티에서 디지털 토론의 품질을 향상시키고, 온라인 상호작용에서 언어의 정확성과 일관성을 촉진하는 데 중요한 진전을 나타내고 있다.

###### Crosslingual Retrieval Augmented In-context Learning for Bangla (https://aclanthology.org/2023.banglalp-1.15/)
- Anthology ID: 2023.banglalp-1.15 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 대형 언어 모델 (LLM)은 자연어 처리에서의 성능이 한글 등의 저자원 언어에서 제한되는 문제로 인해 항상 암묵적인 가능성이 가려지고 있었다.
    2. 이를 해결하기 위해 본 논문은 cross-lingual retrieval과 augmented in-context learning을 활용한 선구적인 접근 방식을 제시한다.
    3. 고립된 저자원 언어에서 성능을 획기적으로 향상시키기 위해 고자원 언어로부터 의미론적으로 유사한 프롬프트를 추출하여 다국어 사전훈련 언어 모델 (MPLM)에서 실제로 개선되는 것을 실험 확증하였다.

###### Pseudo-Labeling for Domain-Agnostic Bangla Automatic Speech Recognition (https://aclanthology.org/2023.banglalp-1.16/)
- Anthology ID: 2023.banglalp-1.16 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 낮은 자원 언어에 대한 자동 음성 인식 (ASR) 개발의 주요 도전 중 하나는 도메인 특정 변동성이 있는 레이블이 지정된 데이터에 제한적으로 접근할 수 있다는 점이다.
    2. 우리는 거시적 도메인에 관계없는 ASR 데이터셋을 개발하기 위해 의사 라벨링 접근법을 제안한다. 우리는 다양한 주제, 발화 스타일, 방언, 잡음이 있는 환경 및 대화 시나리오를 포함하는 20,000시간 이상의 Bangla 음성 데이터셋을 개발했다.
    3. 우리의 결과는 의사 라벨 데이터로 훈련된 모델이 공개적으로 사용 가능한 Bangla 데이터셋과 설계된 테스트셋에서의 효과를 입증한다. 실험 자료는 공개적으로 사용 가능하다.

###### BanglaNLP at BLP-2023 Task 1: Benchmarking different Transformer Models for Violence Inciting Text Detection in Bangla (https://aclanthology.org/2023.banglalp-1.17/)
- Anthology ID: 2023.banglalp-1.17 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 본 논문은 방글라어에서 폭력을 선동하는 텍스트를 감지하는 공유 과제를 해결하는 동안 개발한 시스템을 소개한다.
    2. 우리는 전통적인 방법과 최근의 방법을 사용하여 모델을 학습시키기 위해 사용한 접근 방식을 설명한다.
    3. 한정된 데이터셋이 있는 경우 데이터 증강의 영향을 연구하였고, 실험 결과에서 다른 transformer 기반 모델과 비교하여 멀티링귈러-e5-base 모델의 fine-tuning이 최상의 성능을 보였다. 채점에서 우리의 성과는 리더보드에서 23위로 평가되었다.

###### Team CentreBack at BLP-2023 Task 1: Analyzing performance of different machine-learning based methods for detecting violence-inciting texts in Bangla (https://aclanthology.org/2023.banglalp-1.18/)
- Anthology ID: 2023.banglalp-1.18 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 소셜 미디어의 급격한 성장은 소통을 용이하게 해줌과 동시에 혐오 표현에 대한 문제를 야기한다. 이 논문은 폭력 유인 텍스트 탐지를 위한 시스템을 구축하기 위해 다양한 기법을 시도하였다. 
    2. 논문에서는 뱅글라BERT 언어 모델을 fine-tuning 함으로써 가장 좋은 성능을 얻었으며, 대회가 끝난 후에는 데이터 전처리를 통해 성능을 개선할 수 있다고 밝혔다.
    3. 이 연구에서는 폭력 유인 텍스트를 비폭력, 수동 폭력, 직접 폭력으로 분류하는 시스템을 구축하려고 시도하였고, 최종 리더보드에서 27개 팀 중 21위를 차지하였다.

###### EmptyMind at BLP-2023 Task 1: A Transformer-based Hierarchical-BERT Model for Bangla Violence-Inciting Text Detection (https://aclanthology.org/2023.banglalp-1.19/)
- Anthology ID: 2023.banglalp-1.19 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 인터넷의 보편화로 인해 사람들은 소셜 미디어를 통해 정보를 쉽게 공유할 수 있게 되었다. 하지만 악의적인 의도를 가진 사람들은 소셜 미디어를 통해 쉽게 폭력적인 콘텐츠를 공유할 수 있다. 따라서 본 연구는 소셜 미디어에서 방글라 폭력 선동 텍스트를 감지하는 것을 목표로 한다.
    2. BLP 워크샵에서는 방글라 폭력 선동 텍스트 감지를 위한 공유 태스크가 진행되었으며, 이를 위해 VITD 데이터셋을 제공했다. 여러 가지 머신 러닝 및 딥러닝 기법을 사용하여 모델을 구현하고 VITD 데이터셋으로 각 모델을 학습하고 평가한 결과, Hierarchical-BERT 모델이 가장 우수한 결과를 제공했다.
    3. Hierarchical-BERT 모델은 테스트 세트에서 F1 스코어 0.73797의 성능을 보여주었으며, BLP 워크샵의 공유 태스크 1에서 9위를 차지했다.

###### nlpBDpatriots at BLP-2023 Task 1: Two-Step Classification for Violence Inciting Text Detection in Bangla - Leveraging Back-Translation and Multilinguality (https://aclanthology.org/2023.banglalp-1.20/)
- Anthology ID: 2023.banglalp-1.20 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 본 논문에서는 Bangla 언어 처리 (BLP) 워크샵과 함께 열린 Violence Inciting Text Detection (VITD) 공유 태스크에 대한 nlpBDpatriots 의 참가 결과를 논의한다.
    2. 이 태스크의 목표는 파생적인 반합법적 폭력행위를 부추기는 폭력 위협을 식별하고 분류하는 것이다.
    3. Back translation과 multilinguality를 사용한 두 단계 분류가 최고 수행 결과로 27개 팀 중 6위를 차지하며 macro F1 스코어는 0.74이다.

###### Score_IsAll_You_Need at BLP-2023 Task 1: A Hierarchical Classification Approach to Detect Violence Inciting Text using Transformers (https://aclanthology.org/2023.banglalp-1.21/)
- Anthology ID: 2023.banglalp-1.21 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 리소스가 제한된 언어(방글라)에서 폭력성 텍스트를 식별하기 위한 전이 학습 방법론을 제안함. 
    2. 방글라BERT, XLM-R, m-BERT와 같은 transformer 모델을 사용하여 다단계 분류 모델 개발. 
    3. 수행한 시스템은 72.37의 정확도를 얻어 14위를 차지함.

###### Mavericks at BLP-2023 Task 1: Ensemble-based Approach Using Language Models for Violence Inciting Text Detection (https://aclanthology.org/2023.banglalp-1.22/)
- Anthology ID: 2023.banglalp-1.22 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 이 논문은 Bangla 언어 처리에 대한 첫 번째 워크샵의 Violence Inciting Text Detection 공유 과제에 대한 작업을 제시한다. 소셜 미디어는 혐오와 폭력을 부추기는 언어의 전파를 가속화시킨다. 이러한 텍스트의 전파를 탐지하고 억제하기 위한 효율적인 메커니즘을 개발하는 것이 중요하다.
    2. 폭력을 부추기는 텍스트의 탐지 문제는 연구와 데이터가 희소한 저자원 환경에서 더 악화된다.
    3. 우리는 여러 BERT 기반 모델을 시도하고 평가한 후 최종 제출을 위해 모델의 앙상블을 사용한다. 우리의 제출은 macro F1 점수 0.737로 최종 리더보드에서 10위에 해당한다.

###### VacLM at BLP-2023 Task 1: Leveraging BERT models for Violence detection in Bangla (https://aclanthology.org/2023.banglalp-1.23/)
- Anthology ID: 2023.banglalp-1.23 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 이 논문에서는 VITD (Violence Inciting Text Detection) 과제에 대한 VacLM 팀의 시스템을 소개한다. 텍스트 내의 폭력을 감지하기 위해 다양한 transformer-based 모델들의 영향을 분석하였다.
    2. BanglaBERT가 다른 경쟁 모델들보다 우수한 성능을 보였다. transformer-based 모델들은 Passive Violence와 Direct Violence를 구분하는 데는 능숙하지 않았지만, 텍스트 내의 폭력을 감지하는 데에는 우수한 성과를 보였다.
    3. BLP Shared Task에서는 72.656%의 macro F1-score로 12위를 차지했다.

###### Aambela at BLP-2023 Task 1: Focus on UNK tokens: Analyzing Violence Inciting Bangla Text with Adding Dataset Specific New Word Tokens (https://aclanthology.org/2023.banglalp-1.24/)
- Anthology ID: 2023.banglalp-1.24 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. BLP-2023 Task 1은 Bangla YouTube 댓글에서 위협을 감지하고 분석하기 위한 자연어 추론 시스템을 개발하는 것을 목표로 한다.
    2. BanglaBERT와 같은 Bangla 언어 모델은 다양한 Bangla 자연어 처리 작업에서 높은 성능을 보여주었다.
    3. 우리는 BanglaBERT를 사용하여 폭력 감지 작업에 적용하고 새로운 토큰을 도입하여 모델의 성능을 향상시켰다. 이로써 우리의 모델은 테스트 세트에서 76.90%의 매크로 F1 점수를 달성하였다.

###### SUST_Black Box at BLP-2023 Task 1: Detecting Communal Violence in Texts: An Exploration of MLM and Weighted Ensemble Techniques (https://aclanthology.org/2023.banglalp-1.25/)
- Anthology ID: 2023.banglalp-1.25 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 본 연구에서는 벵갈 지역의 폭력적 사건과 관련된 YouTube 댓글에서 폭력 선동 텍스트를 분류하는 공유 작업을 다루고 있다.
    2. 우리는 다양한 종류의 비공식 텍스트에서 사전에 존재하는 Masked Language Model을 꼼꼼히 fine-tuning 함으로써 도메인 적응 기술을 원활하게 통합했다. 이뿐만 아니라 Transfer Learning, Stacking, Ensemble 기법을 결합하여 모델의 성능을 향상시켰다.
    3. Fine-tuning된 BanglaBERT 모델과 Weighted Ensemble 접근법을 통합한 우리의 통합 시스템은 매크로 F1 점수가 각각 71%와 72%로 향상되어 해당 참가자 중 18위를 기록함으로써 디지털 영역 내에서 폭력적인 내러티브의 민감한 감지와 분류에 대한 우리의 제안된 패러다임의 강건성과 정밀성을 강조한다.

###### the_linguists at BLP-2023 Task 1: A Novel Informal Bangla Fasttext Embedding for Violence Inciting Text Detection (https://aclanthology.org/2023.banglalp-1.26/)
- Anthology ID: 2023.banglalp-1.26 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. "폭력 자극 텍스트 탐지" 작업에 대한 비용 효율적인 솔루션을 설계하기 위해 소개된 새로운 informal Bangla word  embedding은 폭력을 분류하고 추가적인 폭력을 일으킬 수 있는 텍스트를 분류하는 분류 시스템을 개발하는 작업에 초점을 맞추었다. 
    2. 우리는 informal Bangla FastText embedding에 대한 반지도 학습 접근법을 제안하며, 작업 특정 데이터셋에서 경량 모델로 fine-tuning을 수행하여 초기 메소드인 BanglaBERT를 대체하는 경쟁력있는 결과를 얻었다.
    3. 우리는 제안된 embedding의 효율성 및 폭력 분류에 대한 일반성, 그리고 작업 데이터셋에 대한 커버리지를 평가하기 위해 포괄적인 실험을 수행하였고, 제안된 Bangla IFT embedding은 경쟁력있는 macro average F1 점수 70.45%를 달성했다.

###### UFAL-ULD at BLP-2023 Task 1: Violence Detection in Bangla Text (https://aclanthology.org/2023.banglalp-1.27/)
- Anthology ID: 2023.banglalp-1.27 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. BLP Shared Task 1: Violence Inciting Text Detection (VITD)에서 UFAL-ULD 팀의 시스템을 소개한다. 이 과제는 폭력 선동 텍스트를 직접, 간접 또는 비폭력 수준으로 분류하는 것을 목표로 한다.
    2. XLM-RoBERTa, BanglaBERT, Bangla BERT Base 및 Multilingual BERT를 포함한 여러 사전 훈련된 sequence classification 모델을 실험하였다.
    3. XLM-RoBERTa 기반의 모델이 최고의 성능을 보여 기준 모델을 능가했고, UFAL-ULD 팀의 시스템은 과제에 참여한 27개 팀 중 20위를 차지했다.

###### Semantics Squad at BLP-2023 Task 1: Violence Inciting Bangla Text Detection with Fine-Tuned Transformer-Based Models (https://aclanthology.org/2023.banglalp-1.28/)
- Anthology ID: 2023.banglalp-1.28 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. Transformer 기반 모델을 사용하여 폭력 위협을 식별하는 연구를 수행하였다.
    2. 실험 결과, BanglaBERT은 기준선에 근사한 F1 점수를 얻었다.
    3. 연구 결과는 온라인 플랫폼의 안전 조치를 향상시키기 위한 귀중한 통찰력을 제공하며, 대용량 모델의 성능 저하에 대해 추가적인 조사가 필요하다는 점을 강조한다.

###### LowResourceNLU at BLP-2023 Task 1 & 2: Enhancing Sentiment Classification and Violence Incitement Detection in Bangla Through Aggregated Language Models (https://aclanthology.org/2023.banglalp-1.29/)
- Anthology ID: 2023.banglalp-1.29 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. Youjin et al. (2023)은 MCQ 평가를 위한 새로운 지식 종속 가능성(KDA) 평가 메트릭을 제안하였다. 이는 MCQ가 대상 사실의 학생 학습 지식과 상관관계를 평가한다.
    2. Lee et al. (2023)은 deep learning 모델의 강건성을 향상시키기 위해 contrastive learning과 counterfactual augmentation을 활용한다. 그들의 방법은 초점을 두 테스크에서 좋은 성능을 보여준다: 1) counterfactual 강건성, 2) cross-domain 일반화, 3) 희소 데이터로부터의 일반화.
    3. Bangla 언어에서 낮은 리소스 문제로 인해, Rahman et al. (2023)은 violence incitement detection과 sentiment analysis를 위한 혁신적인 접근 방식을 제안한다. 이들의 방법은 fine-tuning, MLM training 및 다국적 BERT를 결합하여 Bangla 텍스트의 정확도를 크게 향상시킨다.

###### Team Error Point at BLP-2023 Task 1: A Comprehensive Approach for Violence Inciting Text Detection using Deep Learning and Traditional Machine Learning Algorithm (https://aclanthology.org/2023.banglalp-1.30/)
- Anthology ID: 2023.banglalp-1.30 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 현재의 디지털 환경에서, 소셜 미디어 플랫폼은 전례 없는 연결성을 도모하면서도 광범위한 폭력 선동 콘텐츠로 인해 어두운 면을 가지고 있다. 이 연구는 벵골어 소셜 미디어에서 폭력 선동 텍스트 분류에 대해 머신러닝과 딥러닝 모델을 다양하게 사용하여 콘텐츠 관리와 온라인 안전을 향상시키는 전략에 대한 통찰력을 제공한다.
    2. 기술과 사회적 책임의 교차점에 위치한 이 연구는 플랫폼과 커뮤니티가 온라인 폭력과 싸우는 데 도움을 주기 위한 것이다.
    3. 이 연구는 모델 선택과 방법론에 대한 통찰력을 제공하여 디지털 시대의 어두운 면이 가져오는 도전에 대한 지속적인 대화에 큰 기여를 한다.

###### NLP_CUET at BLP-2023 Task 1: Fine-grained Categorization of Violence Inciting Text using Transformer-based Approach (https://aclanthology.org/2023.banglalp-1.31/)
- Anthology ID: 2023.banglalp-1.31 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 최근 인터넷 사용자의 증가로 인해 소셜 미디어 게시물, 온라인 채팅, 웹 포털 등을 통해 온라인 텍스트 컨텐츠 양이 크게 증가하였으나, 사이버 폭력을 부추기는 텍스트를 감지하는 시스템을 개발하는 것은 어렵다.
    2. 이 논문에서는 저자들은 Bangla 언어로 된 폭력적인 텍스트를 분류하기 위해 deep learning, machine learning, transformers 및 GAN 기반 모델을 사용하여 해결책을 제시한다.
    3. GAN+Bangla-ELECTRA 모델은 BLP-2023 Task 1에서 3위를 차지하며, 가장 높은 macro f1-score (74.59)을 달성하였다.

###### Team_Syrax at BLP-2023 Task 1: Data Augmentation and Ensemble Based Approach for Violence Inciting Text Detection in Bangla (https://aclanthology.org/2023.banglalp-1.32/)
- Anthology ID: 2023.banglalp-1.32 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 이 논문은 BLP Workshop 1에서 진행된 EMNLP 2023의 Task1 (VITD)에 대한 참가 결과를 설명하며, 폭력과 관련된 위협을 감지하고 분류하는 작업에 초점을 맞추었다.
    2. 우리의 접근 방식은 사전 훈련된 transformer 모델의 fine-tuning과 self-training, 데이터 증강, 앙상블 학습 등의 기술을 활용하는 것이다.
    3. 우리의 결과는 앙상블 방법과 데이터 증강 기법이 방글라 텍스트 분류에서 효과적임을 강조하며, 참가자 중 19위에 랭크되었으나 경쟁 후 실험을 통해 성능을 높였음을 보여준다.

###### BLP-2023 Task 1: Violence Inciting Text Detection (VITD) (https://aclanthology.org/2023.banglalp-1.33/)
- Anthology ID: 2023.banglalp-1.33 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 이 논문은 VITD (Violence Inciting Text Detection) 공유 작업의 결과에 대한 포괄적인 기술 설명을 제공한다. 
    2. 이 작업은 다양한 텍스트에서 폭력 선동 수준을 분류하기 위해 시작되었다.
    3. 이 논문에서는 VITD의 기준 성능, 제출된 모델의 오류 분석 및 참가 팀이 적용한 계산 기법에 대해 종합적인 요약을 제공한다.

###### BanglaNLP at BLP-2023 Task 2: Benchmarking different Transformer Models for Sentiment Analysis of Bangla Social Media Posts (https://aclanthology.org/2023.banglalp-1.34/)
- Anthology ID: 2023.banglalp-1.34 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 방글라(Bangla)는 전 세계에서 7번째로 많이 사용되는 언어로, 2억 3천 4백만 명의 주요 사용자가 있다. 그러나 그 언어는 자연어 처리 및 음성 커뮤니티에서 저자원 언어로 분류되어 있다.
    2. 저자원 언어에서 변환 모델을 사용하는 실험 결과, 전이학습은 이 언어의 모델 학습에 큰 도움이 된다는 것을 보여준다. 트위터 데이터로 이미 학습된 모델을 업데이트한 결과, 다른 모델보다 성능이 가장 좋았다.
    3. 성능 분석을 통해 정답 레이블을 확인해야 할 일부 경우가 발견되었다. 오차 분석을 통해 테스트 세트에서 67.02%의 micro-F1와 21위의 성과를 달성하였다.

###### Knowdee at BLP-2023 Task 2: Improving Bangla Sentiment Analysis Using Ensembled Models with Pseudo-Labeling (https://aclanthology.org/2023.banglalp-1.35/)
- Anthology ID: 2023.banglalp-1.35 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 이 논문은 Bangla Language Processing (BLP) 워크숍에서 Sentiment Analysis Shared Task에 대한 submission 내용을 개요로 소개한다. 
    2. 본 논문에서는 BanglaBERT를 기반으로한 방법을 제안하여, 데이터 확장을 위해 pseudo-label을 생성하고, 이를 사용하여 최종 모델을 훈련시켰다.
    3. 평가 과정에서, 30개 팀 중 우리 시스템은 두 번째로 높은 성능을 내었다. (F1 score: 0.7267)

###### M1437 at BLP-2023 Task 2: Harnessing Bangla Text for Sentiment Analysis: A Transformer-based Approach (https://aclanthology.org/2023.banglalp-1.36/)
- Anthology ID: 2023.banglalp-1.36 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 소셜 미디어에서 대중의 감정을 분석하는 것은 어떠한 주제에 대한 대중의 감정을 이해하는 데 도움이 된다. 
    2. BLP 워크샵에서 George Mason University의 M1437 팀은 Bangla 언어 처리 (BLP) 워크샵의 감성 분석 공유 과제에 참여하였다. 
    3. 문서는 BanglaBERTlarge라는 Bangla 텍스트로 사전 학습한 언어 모델이 다른 BERT 기반 모델보다 우수한 성능을 보였다고 보고한다.

###### nlpBDpatriots at BLP-2023 Task 2: A Transfer Learning Approach towards Bangla Sentiment Analysis (https://aclanthology.org/2023.banglalp-1.37/)
- Anthology ID: 2023.banglalp-1.37 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 이 논문은 Bangla Sentiment Analysis를 위한 nlpBDpatriots의 정교한 접근 방식에 대해 논의한다. 이는 EMNLP 주최로 개최된 Bangla Language Processing (BLP) 워크숍에서 공유된 과제이다.
    2. 이 과제의 주요 목표는 소셜 미디어 콘텐츠의 감성 극성을 식별하는 것이다. 30개의 NLP 열정가 그룹들이 이 공유 과제에 참여하였고, 우리가 가장 성과가 좋은 방법은 데이터 증강과 전이 학습을 결합한 것이다.
    3. 이 방법으로 우리는 이 경연에서 12위를 차지하여 매우 높은 0.71의 마이크로 F1 점수를 얻었다.

###### Ushoshi2023 at BLP-2023 Task 2: A Comparison of Traditional to Advanced Linguistic Models to Analyze Sentiment in Bangla Texts (https://aclanthology.org/2023.banglalp-1.38/)
- Anthology ID: 2023.banglalp-1.38 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. BLP Workshop-2023 Task-2의 Sentiment Analysis 과제에 대한 분석 접근 방식을 설명하는 논문이다. 우리는 DistilBERT를 사용하여 과제를 제출했으며, 추가적인 하이퍼파라미터 튜닝과 전처리를 통해 vanilla LSTM으로 결과를 개선하였다. 
    2. 데이터 불균형 문제를 해결하기 위해 oversampling 방법을 사용한 데이터 증강 및 언어 의미의 표현을 효과적으로 캡처하기 위한 attention masking과 masked language modeling을 적용한 기여도 있다. 
    3. 해당 시스템은 competition에서 초반에 대략 0.26의 micro-F1 점수를 받아 30위에 들었으나, LSTM과 XLM-RoBERTa-base 모델을 사용하여 결과를 각각 0.68과 0.65로 개선하였다.

###### EmptyMind at BLP-2023 Task 2: Sentiment Analysis of Bangla Social Media Posts using Transformer-Based Models (https://aclanthology.org/2023.banglalp-1.39/)
- Anthology ID: 2023.banglalp-1.39 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 소셜 미디어 플랫폼의 인기로 인해 매일 많은 양의 디지털 텍스트 데이터가 생성되고 있으며, 이에 대한 감정 분석은 실제로 많은 응용 분야에서 중요한 주제이다. 
    2. 그러나 영어와 같이 언어 자원이 풍부한 언어에 대한 연구가 많이 이루어져 왔지만, Bangla와 같은 저자원 언어에 대한 연구는 제한적이다. 
    3. 이 논문에서는 Bangla 감정 분석을 위해 다양한 transformer-based 모델을 finetune하고, BLP 워크샵과 EMNLP-2023의 공유 작업에서 제공된 데이터셋을 사용하여 모델을 훈련 및 평가하였다. 또한, Bangla 감정 분석을 위해 다양한 기계 학습 모델, 딥 러닝 모델, transformer-based 모델을 비교적으로 연구하여 BanglaBERT (Large) 모델이 최상의 결과를 달성하였음을 확인하였다.

###### RSM-NLP at BLP-2023 Task 2: Bangla Sentiment Analysis using Weighted and Majority Voted Fine-Tuned Transformers (https://aclanthology.org/2023.banglalp-1.40/)
- Anthology ID: 2023.banglalp-1.40 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 이 논문은 방글라 소셜 미디어 게시글의 감성 분석을 위한 공유 작업 2에서의 제출물에 대한 접근 방식을 설명한다. 
    2. 스마트폰과 소셜 미디어의 급격한 성장으로 인해 자동 감성 분석의 응용이 증가하고 있으나, 대부분의 연구는 영어에 기반한다.
    3. 본 연구에서는 다양한 다국어 및 사전 훈련된 BERT 기반 모델을 실험하고 성능을 향상시키기 위해 다수 투표 및 가중 앙상블 모델을 사용하는 접근 방식을 제안한다.

###### Semantics Squad at BLP-2023 Task 2: Sentiment Analysis of Bangla Text with Fine Tuned Transformer Based Models (https://aclanthology.org/2023.banglalp-1.41/)
- Anthology ID: 2023.banglalp-1.41 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. Bangla 언어와 같은 다양한 언어적 특성을 가지는 맥락에서 Sentiment analysis (SA)는 자연어 처리에서 중요한 작업이다.
    2. 이 논문에서는 BLP-2023 Shared Task 2의 Bangla text SA에 대한 여섯 가지 transformer 기반 모델의 성능을 조사하고, fine-tuning 및 포괄적인 성능 평가를 진행했다.
    3. BanglaBERT Small을 사용하여 한국어BERT는 대회 리더보드에서 20위를 기록했으며, BanglaBERT는 71.33%의 정확도로 다른 모델들을 능가하였다.

###### Aambela at BLP-2023 Task 2: Enhancing BanglaBERT Performance for Bangla Sentiment Analysis Task with In Task Pretraining and Adversarial Weight Perturbation (https://aclanthology.org/2023.banglalp-1.42/)
- Anthology ID: 2023.banglalp-1.42 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 이 논문에서는 "Aambela"라는 방법을 소개하며, "Bangla Social Media Posts"의 감정 분석 작업에 대한 최고 성과 방법을 소개한다.
    2. 접근 방식은 세 가지 명확한 분류 헤드를 가진 Bangla 언어 모델을 fine-tuning하는 것이다.
    3. 최종 예측을 위해 다양한 모델의 예측을 결합한 모드 기반 앙상블 방법을 사용하여 대회에서 1위를 차지하였다.

###### Z-Index at BLP-2023 Task 2: A Comparative Study on Sentiment Analysis (https://aclanthology.org/2023.banglalp-1.43/)
- Anthology ID: 2023.banglalp-1.43 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 이 논문에서는 BLP-2023 shared task의 Task 2에 참여한 결과를 보고한다. 이 과제의 주요 목표는 주어진 텍스트의 감정 (긍정, 중립, 부정)을 결정하는 것이었다.
    2. 우리는 URL, 해시태그 등을 제거하고 전통적인 방법과 사전 학습된 언어 모델을 적용했다. 우리는 리더보드에 여러 시스템을 제출하였고, 토큰화된 데이터와 함께 사용한 BanglaBERT가 가장 좋은 결과를 나타내었으며 F1-micro 점수 71.64로 대회에서 5위를 차지했다.
    3. 우리의 연구는 사전 학습된 언어 모델에서 토큰화의 중요성이 감소하고 있음을 보고한다. 또한, 우리의 평가에서 BanglaBERT가 다른 모델보다 우수한 결과를 나타내었고, 중립 클래스를 예측하는 것은 모든 모델에게 여전히 도전적인 문제임을 보여준다.

###### Team Error Point at BLP-2023 Task 2: A Comparative Exploration of Hybrid Deep Learning and Machine Learning Approach for Advanced Sentiment Analysis Techniques. (https://aclanthology.org/2023.banglalp-1.44/)
- Anthology ID: 2023.banglalp-1.44 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 본 연구는 감성 분석을 위해 사용되는 다양한 모델과 기술에 대해 철저하고 포괄적인 조사를 제시한다. 이 연구의 차별점은 감성 분석의 효과를 향상시키기 위해 목적 화된 데이터 증강 기술을 의도적으로 도입한다는 것이다.
    2. 우리는 LSTM (Long Short-Term Memory) 및 LSTM-CNN (Convolutional Neural Network) Combine과 같은 고급 모델부터 Logistic Regression, Decision Tree, Random Forest, Multi-Naive Bayes, Support Vector Machine, Stochastic Gradient Descent와 같은 전통적인 기계 학습 모델, 전처리 기술을 포함하여 다양한 접근법을 체계적으로 탐색했다.
    3. 우리의 연구는 데이터 증강이 모델 정확도 향상과 방글라어 감성의 미묘한 특징 이해에 미치는 상당한 영향을 강조한다. 또한, 우리는 LSTM 모델이 방글라어 텍스트의 장거리 상관 관계를 포착하는 능력을 강조한다.

###### UFAL-ULD at BLP-2023 Task 2 Sentiment Classification in Bangla Text (https://aclanthology.org/2023.banglalp-1.45/)
- Anthology ID: 2023.banglalp-1.45 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. BLP 공유 작업 2에서 우리 UFAL-ULD 팀은 Bangla 소셜 미디어 게시물의 감성 분석을 위한 시스템을 제시한다.
    2. XLM-RoBERTa-base 아키텍처를 기반으로 한 우리의 최상의 성능 모델은 베이스라인 모델보다 우월하며, 30개 팀 중 19위에 랭크되었다.
    3. Pre-trained 시퀀스 분류 모델인 XLM-RoBERTa, BanglaBERT, Bangla BERT Base 및 Multilingual BERT를 사용하여 일련의 실험을 수행했다.

###### Embeddings at BLP-2023 Task 2: Optimizing Fine-Tuned Transformers with Cost-Sensitive Learning for Multiclass Sentiment Analysis (https://aclanthology.org/2023.banglalp-1.46/)
- Anthology ID: 2023.banglalp-1.46 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 이 연구는 Bangla 소셜 미디어 포스트에 대한 감성 분석 작업에서 발생하는 두 가지 중요한 도전 과제에 대해 다룬다. 첫 번째 도전 과제는 모델 성능 향상을 위해 클래스 불균형을 해결하기 위한 oversampling 기술을 채용할 때 발생하는 광범위한 학습 시간과 메모리 제약이다. 
    2. 우리는 클래스 불균형을 해결하기 위해 cost-sensitive 접근 방식을 통해 모델 성능을 향상시키기 위한 방법을 사용하여 이러한 도전 과제를 극복한다. 
    3. 추가 실험을 통해 BanglaBERT-Large 모델과 자기 조정 Dice 손실 함수를 결합하여 F1-micro 점수를 0.7186으로 높일 수 있었다.

###### LowResource at BLP-2023 Task 2: Leveraging BanglaBert for Low Resource Sentiment Analysis of Bangla Language (https://aclanthology.org/2023.banglalp-1.47/)
- Anthology ID: 2023.banglalp-1.47 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. 이 논문은 소셜 미디어 플랫폼에서 수집된 공개 게시물과 댓글들을 대상으로 한 감성 분석을 수행하는 BLP-2023의 Task 2에 대한 LowResource 팀의 시스템을 설명한다.
    2. Bangla corpus에서 사전 훈련된 BERT 모델인 BanglaBert를 다양한 전략을 활용하여 활용하고, fine-tuning, 무작위 토큰 제거, 여러 외부 데이터셋 사용 등을 포함한다.
    3. 우리의 최종 모델은 세 가지 다른 BanglaBert 변형의 앙상블로, 참여한 30개 팀 중 테스트 세트에서 전체 3위를 차지하여 0.718의 점수를 달성했다.

###### BLP-2023 Task 2: Sentiment Analysis (https://aclanthology.org/2023.banglalp-1.48/)
- Anthology ID: 2023.banglalp-1.48 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Authors: Firoj Alam | Sudipta Kar | Shammur Absar Chowdhury | Farig Sadeque | Ruhul Amin 
- Summary: 
    1. "BLP Sentiment Shared Task"는 소셜 미디어 텍스트에서 감성(sentiment)을 감지하는 작업으로, 이 작업에는 71명의 참가자 중 29명과 30개의 팀이 각각 개발 및 평가 단계에서 시스템을 제출했다.
    2. 제출된 시스템의 접근 방식은 고전적인 기계 학습 모델, 사전 훈련된 모델의 파인튜닝, 제로샷 및 퓨샷 설정에서의 대형 언어 모델(Large Language Model, LLM)을 활용하는 방법 등이다.
    3. 본 논문에서는 데이터셋 개발 및 평가 설정을 포함하여 작업의 상세한 설명과 참가자가 제출한 시스템의 간략한 개요를 제공한다. 모든 데이터셋과 평가 스크립트는 연구 커뮤니티에 공개되어 이 도메인에서의 추가 연구를 촉진하기 위해 사용할 수 있다.


# Korean Three-Line Summarizations of Papers 2659-2687 in Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023)
###### Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) (https://aclanthology.org/2023.nlposs-1.0/)
- Anthology ID: 2023.nlposs-1.0 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### calamanCy: A Tagalog Natural Language Processing Toolkit (https://aclanthology.org/2023.nlposs-1.1/)
- Anthology ID: 2023.nlposs-1.1 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. calamanCy는 spaCy를 기반으로한 Tagalog 자연어 처리 (NLP) 파이프라인을 구축하기 위한 오픈 소스 툴킷이다. 
    2. calamanCy는 의존 파싱, 품사 태깅, 개체명 인식과 같은 작업을 위한 general-purpose multitask 모델을 제공하여 NLP 애플리케이션 개발에 일관된 API를 제공한다. 
    3. calamanCy는 분리된 자원을 통합된 프레임워크로 통합하고자 하며 Tagalog NLP의 발전을 가속화하기 위해 공개되었다.

###### Jina Embeddings: A Novel Set of High-Performance Sentence Embedding Models (https://aclanthology.org/2023.nlposs-1.2/)
- Anthology ID: 2023.nlposs-1.2 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. Jina Embeddings는 텍스트로부터 의미를 캡처하는 수치적 표현으로 변환하는 고성능 문장 임베딩 모델 세트이다. 
    2. 이 논문에서는 Jina Embeddings의 개발 과정을 상세히 설명하며, 데이터 클리닝, 모델 훈련 프로세스 등에 대한 통찰력을 제공하고, Massive Text Embedding Benchmark (MTEB)을 사용하여 종합적인 성능 평가를 수행한다. 
    3. 또한, 문법적 부정에 대한 모델의 인식을 향상시키기 위해 부정된 문장과 부정되지 않은 문장으로 구성된 독창적인 훈련 및 평가 데이터셋을 구축하였다.

###### Deepparse : An Extendable, and Fine-Tunable State-Of-The-Art Library for Parsing Multinational Street Addresses (https://aclanthology.org/2023.nlposs-1.3/)
- Anthology ID: 2023.nlposs-1.3 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 주소 구분을 위한 파서 (address parsing)는 record linkage부터 geocoding과 package delivery까지 많은 응용 분야에서 필수적인 과정으로 여겨진다.
    2. 본 논문에서는 Deepparse라 불리는 오픈소스 파서를 소개하며, 이 파서는 최첨단 딥러닝 알고리즘을 사용하여 다국적 주소를 파싱하는 기능을 제공한다. 
    3. 미리 학습된 모델은 평균 99%의 정확도를 보이며, 새로운 데이터 fine-tuning을 지원하여 사용자 정의 주소 파서를 생성할 수 있다.

###### PyThaiNLP: Thai Natural Language Processing in Python (https://aclanthology.org/2023.nlposs-1.4/)
- Anthology ID: 2023.nlposs-1.4 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. PyThaiNLP는 파이썬으로 구현된 태국어 자연어 처리(NLP) 라이브러리로, 태국어에 대한 다양한 소프트웨어, 모델, 데이터셋을 제공한다. 
    2. PyThaiNLP의 기능, 데이터셋, 사전 훈련된 언어 모델에 대해 간략히 소개하고, 개발 이전의 태국어 도구에 대한 역사적 문맥을 설명한다. 
    3. 산업 및 연구 커뮤니티에서 PyThaiNLP를 어떻게 활용하는지를 설명하고, 해당 라이브러리를 https://github.com/pythainlp/pythainlp에서 무료로 사용할 수 있다고 마무리한다.

###### Empowering Knowledge Discovery from Scientific Literature: A novel approach to Research Artifact Analysis (https://aclanthology.org/2023.nlposs-1.5/)
- Anthology ID: 2023.nlposs-1.5 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 다양한 연구 분야에서 투명성, 재현성, 혁신을 촉진하기 위해 과학 문헌으로부터 지식을 추출하는 것은 주요한 문제이다.
    2. 이 논문에서는 과학 문헌 내의 데이터셋과 코드/소프트웨어 언급을 식별, 추출 및 분석하기 위한 혁신적인 접근 방식을 제시한다.
    3. ChatGPT를 사용하여 합성된 데이터셋을 소개하고, 인간 중심 프로세스를 통해 실제 과학 텍스트 조각을 사용하여 철저히 만들고 보강하고 확장했다.

###### Zelda Rose: a tool for hassle-free training of transformer models (https://aclanthology.org/2023.nlposs-1.6/)
- Anthology ID: 2023.nlposs-1.6 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. Zelda Rose는 명령 줄 인터페이스로, transformer 기반 모델의 사전 훈련을 위한 것이다. 
    2. 이 도구는 사용자가 더 포괄적이면서도 복잡한 프레임워크와 라이브러리 간의 복잡한 상호작용과 관련 없이 간편하게 모델을 훈련할 수 있도록 한다. 
    3. 또한 유지 보수 비용을 낮추기 위해 코드를 모듈화하고 제3자 라이브러리를 활용하여 ad-hoc 코드를 최소한으로 유지하는 것에 중점을 둔다.

###### GPT4All: An Ecosystem of Open Source Compressed Language Models (https://aclanthology.org/2023.nlposs-1.7/)
- Anthology ID: 2023.nlposs-1.7 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 최근 많은 언어 모델은 전문적이고 학문적인 기준에서 사람 수준의 성능을 보이지만, 이러한 모델에 대한 접근성은 성능에 미치지 못하고 있다.
    2. 이 논문은 GPT4All이라는 인기있는 오픈 소스 저장소를 통해 LLM에 대한 접근성을 더욱 폭넓게 하기 위한 기술적인 세부 사항과 프로젝트의 변화에 대해 설명한다.
    3. 이 논문은 GPT4All 모델과 오픈 소스 생태계의 성장을 기술적으로 개괄하면서 GPT4All이 개방형 생태계로 성장한 사례 연구로서의 역할을 수행하기를 희망한다.

###### Kani: A Lightweight and Highly Hackable Framework for Building Language Model Applications (https://aclanthology.org/2023.nlposs-1.8/)
- Anthology ID: 2023.nlposs-1.8 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 언어 모델 응용 프로그램은 점점 인기가 있고 복잡해지고 있지만, 기존의 프레임워크는 개발자들이 프롬프트를 어떻게 포맷팅해야 하는지를 결정하고 사용자 정의성과 재현성을 제한하는 경향이 있다.
    2. Kani는 언어 모델 응용 프로그램을 구축하기 위한 가볍고 유연하며 모델에 구애받지 않는 오픈소스 프레임워크를 제공한다.
    3. Kani는 개발자들이 모델과 상호 작용, 채팅 관리, 강력한 함수 호출을 위한 핵심 기능을 구현하는 데 도움이 되며, 사용자 정의 기능을 할 수 있도록 함으로써 개발자들에게 개발을 가속화하면서 상호 운용성과 세밀한 제어를 유지할 수 있는 유용한 도구로 제공된다.

###### Beyond the Repo: A Case Study on Open Source Integration with GECToR (https://aclanthology.org/2023.nlposs-1.9/)
- Anthology ID: 2023.nlposs-1.9 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 저희는 교육평가서비스의 제품과 프로토타입에 사용되는 NLP 파이프라인에 오픈 소스 GECToR 코드와 모델을 통합하는 노력을 서술한 사례 연구를 제시합니다. 
    2. 이 논문에서는 통합 과정에서 마주친 문제들과 우리의 해결책, 오픈 소스 프로젝트 통합에 대한 교훈, 그리고 여정의 일환으로 만든 오픈 소스 기여에 대해 논의하고 있습니다.

###### Two Decades of the ACL Anthology: Development, Impact, and Open Challenges (https://aclanthology.org/2023.nlposs-1.10/)
- Anthology ID: 2023.nlposs-1.10 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. ACL Anthology는 컴퓨터 언어학과 NLP의 연구 논문을 위한 주요 자원으로, 개방 소스와 커뮤니티 주도형 프로젝트로 유지되고 있다. Anthology는 Gildea 등의 논문(2018)을 기반으로한 상태 및 계획 방향성을 보고한 이후, 주요한 기술적인 변경이 이루어졌다.
    2. 우리는 이러한 변경사항이 장기적인 유지 관리성과 커뮤니티 참여에 어떤 영향을 미쳤는지에 대해 논의하며, Anthology가 현재 제공하는 오픈 소스 데이터와 소프트웨어 도구를 설명하고, Anthology를 주요 데이터 원천으로 사용한 문헌 조사를 제공한다.

###### nanoT5: Fast & Simple Pre-training and Fine-tuning of T5 Models with Limited Resources (https://aclanthology.org/2023.nlposs-1.11/)
- Anthology ID: 2023.nlposs-1.11 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. T5와 같은 최신 언어 모델은 NLP 분야에 혁명적인 영향을 끼치지만, 그 계산 요구량 때문에 연구 커뮤니티의 많은 부분에 제한을 가하고 있다.
    2. nanoT5는 T5 모델의 효율적인 사전 훈련과 세밀 조정을 위한 특별히 최적화된 PyTorch framework 로 이러한 도전에 대응하고 있다.
    3. nanoT5를 통해 T5-Base 모델은 성능의 손실 없이 단 한 개의 GPU에서 16시간만에 사전 훈련이 가능하며, 이 오픈 소스 프레임워크를 통해 언어 모델링 연구의 접근성을 넓히고 사용자 친화적인 T5 (Encoder-Decoder) 구현에 대한 커뮤니티의 요구에 부응하길 희망한다.

###### AWARE-TEXT: An Android Package for Mobile Phone Based Text Collection and On-Device Processing (https://aclanthology.org/2023.nlposs-1.12/)
- Anthology ID: 2023.nlposs-1.12 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. AWARE-text 패키지는 안드로이드 모바일 기기에서 텍스트 데이터를 수집하기 위한 오픈 소스 소프트웨어 패키지를 제공한다.
    2. 이 패키지는 raw 데이터 수집 외에도 표준 텍스트 기반 측정치를 수집할 수 있도록 설계되었으며, 이는 민감하고 식별 가능한 정보를 포함할 수 있는 모바일 폰의 경우 특히 중요하다.
    3. AWARE-text 패키지는 개인(평생 SMS 히스토리), 대화(SMS 대화 및 그룹 채팅의 양쪽), 메시지(단일 SMS), 문자(애플리케이션 전체에서 입력 된 개별 키 스트로크)의 다양한 상호작용 수준에서 개인 정보를 보호하는 동시에 텍스트 정보를 수집할 수 있다.

###### SOTASTREAM: A Streaming Approach to Machine Translation Training (https://aclanthology.org/2023.nlposs-1.13/)
- Anthology ID: 2023.nlposs-1.13 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 기계 번역 도구의 데이터 준비과정은 트레이너가 직접 사용할 수있는 텐서 형식으로 원시 데이터를 변환하는 단계를 포함하는데, 이러한 처리 단계는 일반적인 훈련 시간 요구 사항 (예 : 서브워드 샘플링)을 어렵게 만든다.
    2. 본 논문에서는 데이터 생성과 데이터 사용을 분리하는 대안적인 접근 방식을 제안한다. 데이터 생성은 원시 훈련 데이터의 무한한 순열 스트림을 생성하고, 트레이너는 이를 텐서로 변환하여 사용한다.
    3. 이러한 데이터 스트림은 데이터 정규화, 증강 또는 필터링과 같은 사용자 정의 연산자에 의해 실시간으로 수정될 수 있으며, 이러한 접근 방식은 훈련 시간을 단축시키고 유연성을 높이며 실험 관리 복잡성을 감소시키고 디스크 공간을 줄이면서 훈련된 모델의 정확성에 영향을주지 않는다.

###### An Open-source Web-based Application for Development of Resources and Technologies in Underresourced Languages (https://aclanthology.org/2023.nlposs-1.14/)
- Anthology ID: 2023.nlposs-1.14 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 이 논문에서는 Linguistic Field Data Management and Analysis System (LiFE)이라는 새로운 오픈소스 웹 기반 소프트웨어에 대해 논의한다. 이 시스템은 현장에서 수집한 언어 데이터와 YouTube, Twitter, Facebook, Instagram, 블로그, 신문, 위키백과 등 다양한 웹 소스에서 크롤링한 데이터를 체계적으로 저장, 관리, 주석 달기, 분석 및 공유할 수 있게 해준다.
    2. 이 소프트웨어는 현장 언어학자의 작업 흐름과 컴퓨터 언어학자의 작업 흐름을 지원하며, 다양한 작업을 위해 데이터를 수집하고 주석을 달고 언어 기술을 개발하는 데 사용할 수 있다.
    3. 이 외에도 다중 사용자가 유연한 접근 제어와 공유 옵션을 통해 동일한 프로젝트에서 협업 작업을 수행할 수 있고, 다양한 형식으로 데이터를 내보내거나 가져오는 등의 기능을 제공한다.

###### Rumour Detection in the Wild: A Browser Extension for Twitter (https://aclanthology.org/2023.nlposs-1.15/)
- Anthology ID: 2023.nlposs-1.15 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 소셜 미디어 상에서의 소문 감지는 최근에 인기를 끌게 되었고, 기계 학습 커뮤니티에서는 이러한 플랫폼에서 소문을 자동으로 탐지하기 위한 방법을 조사하는 데 많은 기여를 하였다. 그러나 이러한 SoTA 모델은 소셜 미디어 회사에서 배포되기 때문에 일반 사용자는 자신의 소문 탐지에 이 논문의 솔루션을 활용할 수 없다.
    2. 이 문제를 해결하기 위해 우리는 사용자가 Twitter에서 소문 감지를 수행할 수 있는 새로운 브라우저 익스텐션을 제안한다. 특히, 이전에는 SoTA 아키텍처의 성능을 활용하지 않았다.
    3. 사용자 연구에서 초기 결과는이 브라우저 익스텐션이 혜택을 제공한다는 것을 확인하였다. 또한, 우리의 브라우저 익스텐션의 소문 감지 모델의 성능을 시뮬레이션 배포 환경에서 조사하였다. 결과적으로, 브라우저 익스텐션을 안정적으로 대규모의 Twitter 사용자에게 배포하기 위해 추가 인프라가 필요하다는 것을 보여주었다.

###### DeepZensols: A Deep Learning Natural Language Processing Framework for Experimentation and Reproducibility (https://aclanthology.org/2023.nlposs-1.16/)
- Anthology ID: 2023.nlposs-1.16 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 기계 학습 실험 재현의 중요성과 어려움을 고려하여 결과의 분산을 줄이는 노력이 크게 진행되고 있다.
    2. 이 논문의 기여는 일관된 결과 재현을 용이하게 하는 오픈 소스 프레임워크를 제안한다.
    3. 이 프레임워크는 기능과 임베딩의 hot-swapping을 허용하며, 데이터셋을 추가로 처리하고 재벡터화하지 않고도 자연어 처리 딥러닝 모델을 쉽게 만들고 훈련 및 평가할 수 있게 해준다.

###### Improving NER Research Workflows with SeqScore (https://aclanthology.org/2023.nlposs-1.17/)
- Anthology ID: 2023.nlposs-1.17 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. SeqScore는 명명된 개체 인식(Named Entity Recognition, NER) 데이터 작업을 위한 Python 도구로, NER 스코어링을 돕는 도구로 시작되었으나, 이제는 NER 데이터 전체 생명주기에 도움을 주는 기능을 가지고 있다.
    2. SeqScore는 주석의 유효성을 검증하고 데이터의 요약 및 상세 정보를 제공하며 실험을 지원하기 위해 주석을 수정하고 시스템 출력을 스코어링하며 오류 분석을 돕는다.
    3. SeqScore는 PyPI를 통해 배포되며(https://pypi.org/project/seqscore/), 개발은 GitHub에서 진행된다(https://github.com/bltlab/seqscore).

###### torchdistill Meets Hugging Face Libraries for Reproducible, Coding-Free Deep Learning Studies: A Case Study on NLP (https://aclanthology.org/2023.nlposs-1.18/)
- Anthology ID: 2023.nlposs-1.18 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 최근 심층학습의 발전으로 지원받는 기계학습, 자연어처리, 컴퓨터 비전 등의 연구 커뮤니티에서는 과학적인 작업의 재현성이 점점 중요해지고 있다.
    2. 이 논문에서는 초기 버전에서 주로 이미지 분류와 객체 감지 작업을 지원하던 torchdistill을 업그레이드하여 다른 태스크를 지원하는 모듈화된 코드없이 심층학습 프레임워크를 제안한다.
    3. 업그레이드된 torchdistill을 기반으로 한 스크립트를 사용하여 BERT 모델의 GLUE 벤치마크 결과를 재현하고, Hugging Face 라이브러리와 조화를 이루며 다양한 태스크를 지원할 수 있음을 보여준다.

###### Using Captum to Explain Generative Language Models (https://aclanthology.org/2023.nlposs-1.19/)
- Anthology ID: 2023.nlposs-1.19 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. Captum은 PyTorch에서 모델 설명성을 위한 포괄적인 라이브러리로, 사용자가 PyTorch 모델을 이해하는 데 도움이 되는 다양한 방법을 제공한다.
    2. 본 논문에서는 Captum에 generative language model의 동작을 분석하기 위해 특별히 설계된 새로운 기능을 소개한다.
    3. 우리는 이용 가능한 기능들과 generative language model 내에서 학습된 연관성을 이해하는 데 있어서의 잠재력을 보여주는 예시 응용 프로그램을 제공한다.

###### nerblackbox: A High-level Library for Named Entity Recognition in Python (https://aclanthology.org/2023.nlposs-1.20/)
- Anthology ID: 2023.nlposs-1.20 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. nerblackbox는 transformer 기반의 최신 모델을 사용하여 named entity recognition 작업을 쉽게 할 수 있도록 돕는 파이썬 라이브러리이다. 
    2. 다양한 소스로부터 데이터와 모델에 액세스할 수 있으며, 완전히 자동화된 모델 훈련과 평가 및 다양한 모델 추론을 위한 강력한 방법을 제공한다.
    3. 응용 프로그램 개발자와 기계 학습 전문가 및 연구자를 대상으로하며, 사용자에게는 기본적으로 숨겨진 기술적 도전 과제를 해결하면서도 세밀한 제어와 사용자 지정 가능한 기능을 제공한다.

###### News Signals: An NLP Library for Text and Time Series (https://aclanthology.org/2023.nlposs-1.21/)
- Anthology ID: 2023.nlposs-1.21 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. "우리는 입력이 텍스트 데이터 클러스터이고 출력이 하나 이상의 시계열 신호로 표현된 데이터셋을 만들고 사용할 수 있는 오픈 소스 Python 라이브러리를 제안한다.
    2. news-signals 라이브러리는 텍스트 데이터 피드를 사용하여 시계열 동작을 예측하는 다양한 데이터 과학 및 NLP 문제 설정을 지원한다. 이는 예를 들어, 뉴스 도메인에서는 특정 개체에 대한 하루 동안의 뉴스 기사에 해당하는 문서 클러스터가 입력되고, 대상은 특정 인물 또는 회사에 대한 뉴스 양 또는 특정 위키미디어 페이지의 페이지 뷰 수와 같은 실수 값 시계열과 명시적으로 연결된다.
    3. 이러한 문제 설정에 대한 많은 산업 및 연구 사용 사례가 있음에도 불구하고, News Signals는 우리의 지식으로는 자연어 입력과 시계열 대상을 사용하는 데이터 과학 및 연구 설정을 효과적으로 지원하기 위해 특별히 설계된 유일한 오픈 소스 라이브러리이다."

###### PyTAIL: An Open Source Tool for Interactive and Incremental Learning of NLP Models with Human in the Loop for Online Data (https://aclanthology.org/2023.nlposs-1.22/)
- Anthology ID: 2023.nlposs-1.22 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 온라인 데이터 스트림은 시간이 지남에 따라 분포 변화와 새로운 패턴이 발생하기 때문에 기계 학습 모델을 학습시키기 어렵다. 특히 룰과 어휘에 기반한 NLP 태스크에서는 이러한 기능을 변화하는 데이터에 적응시키는 것이 중요하다.
    2. 이 논문에서는 PyTAIL이라는 파이썬 라이브러리를 소개하며, NLP 모델을 적극적으로 훈련시키는 사람을 포함한 접근 방식을 제안한다.
    3. PyTAIL은 새로운 인스턴스를 레이블링하는 것뿐만 아니라 룰과 어휘와 같은 새로운 기능을 레이블링하기도 함께 제안하며, 훈련 중에 사용자가 룰과 어휘를 수용, 거부 또는 업데이트할 수 있는 유연성을 가지고 있다.

###### Antarlekhaka: A Comprehensive Tool for Multi-task Natural Language Annotation (https://aclanthology.org/2023.nlposs-1.23/)
- Anthology ID: 2023.nlposs-1.23 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. NLP 기술의 낮은 자원 언어(low-resource language)에 대한 발전에 있어 가장 큰 장애물 중 하나는 기계 학습 모델을 훈련 및 테스트하기 위한 주석이 달린 데이터셋 부족이다.
    2. 우리는 Antarlekhaka라는 NLP와 관련된 포괄적인 과제에 대한 수동 주석 도구를 소개한다. 이 도구는 유니코드 호환, 언어 독립적, 웹 배포 가능하며 동시에 여러 주석자들에 의해 주석을 동시에 수행할 수 있다.
    3. Antarlekhaka는 자연어 처리 작업 중 가장 중요한 작업인 문장 경계 감지와 텍스트의 시적인 형태를 위한 단어 순서 결정 등을 포함하는 8가지 유형의 작업에 대한 사용자 친화적인 인터페이스를 제공한다.

###### GPTCache: An Open-Source Semantic Cache for LLM Applications Enabling Faster Answers and Cost Savings (https://aclanthology.org/2023.nlposs-1.24/)
- Anthology ID: 2023.nlposs-1.24 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. ChatGPT와 같은 대형 언어 모델의 API를 호출하는 것은 오랜 시간이 걸릴 수 있고, peak 시간에는 응답 속도가 느려져 개발자들 사이에서 불만을 일으킬 수 있다.
    2. GPTCache는 LLM 응답을 저장하는 세마틱 캐시로, 응용 프로그램이 GPTCache와 통합되면 사용자 쿼리가 ChatGPT와 같은 LLM에 전송되기 전에 먼저 GPTCache에 보내져서 캐시에 답이 있다면 LLM에 다시 쿼리하지 않아도 빠르게 답을 제공할 수 있다.
    3. GPTCache는 API 호출 비용을 줄이고 응답 시간을 빠르게 하여 개발 비용을 절감할 수 있으며, OpenAI가 제공하는 GPT 서비스와 통합 시 응답 속도를 2-10배 향상시킬 수 있다. 또한 네트워크 변동에도 안정적인 성능을 보인다.

###### The Vault: A Comprehensive Multilingual Dataset for Advancing Code Understanding and Generation (https://aclanthology.org/2023.nlposs-1.25/)
- Anthology ID: 2023.nlposs-1.25 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 기존의 MCQ 생성 평가 방법은 교육적 가치를 고려하지 않고 데이터셋의 답과 유사성을 비교하기 때문에 한계가 있다.
    2. 본 논문에서는 MCQ의 대답 가능성을 평가하는 새로운 메트릭인 KDA를 제안하고, 이를 기반으로 자동 평가 메트릭인 KDA_disc와 KDA_cont를 개발했다.
    3. 실험 결과 KDA_disc와 KDA_cont가 실제 강의 환경에서 usability와 강한 상관관계를 가짐을 확인했다.
    
    1. 최근 NLP 모델의 정확도는 인간을 뛰어넘지만, 특정 패턴에 의존적이기 때문에 robustness에 한계가 있다.
    2. 이 논문에서는 대조학습과 대조적 augmentation을 이용하여 robustness를 향상시키는 것을 목표로 한다.
    3. 실험 결과, 본 연구는 집합적 의사 결정을 통해 각 단어의 인과관계를 robust하게 지도할 수 있었고, 이를 통해 counterfactual robustness, cross-domain generalization, scarce data로부터의 일반화에서 기존 모델보다 혁신적인 개선을 이룩할 수 있었다.

###### SEA-LION (Southeast Asian Languages In One Network): A Family of Southeast Asian Language Models (https://aclanthology.org/2023.nlposs-1.26/)
- Anthology ID: 2023.nlposs-1.26 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 기존 자동 MCQ 생성에 대한 평가 메트릭은 교육적 가치를 고려하지 않고, 단어 유사성에만 집중한다.
    2. 따라서, 우리는 지식 종속 가능성(KDA)이라는 새로운 평가 메트릭을 제안하여 MCQ의 대답 가능성과 학생의 지식을 평가한다.
    3. 실험 결과, KDA_disc와 KDA_cont는 실제 강의 환경에서의 사용성과 강한 상관관계를 보였다.
    
    1. 최근의 deep model들은 NLP 작업에서 인간을 능가하는 정확성을 보이지만, spurious pattern에 의존하기 때문에 robustness가 제한된다.
    2. 따라서, 우리는 대조 학습과 반증적 augmentation을 활용하여 robustness를 강화하려고 한다.
    3. 여러 개의 counterfactual을 생성하고 집합적 의사 결정을 통해 단어들의 인과관계를 강력하게 파악함으로써, 과제 모델의 편향을 덜 민감하게 만든다.
    
    1. 기존의 자동 MCQ 생성 평가 메트릭은 교육적 가치를 고려하지 않으며, 단어 유사성을 중점으로 한다.
    2. 본 연구에서는 새로운 KDA 평가 메트릭을 제안하여 MCQ의 대답 가능성과 대상 사실에 대한 학생의 지식을 평가한다.
    3. 실험 결과로, KDA_disc와 KDA_cont는 실제 수업에서 사용 가능하며, KDA와의 강한 상관관계를 보여준다.

###### trlX: A Framework for Large Scale Open Source RLHF (https://aclanthology.org/2023.nlposs-1.27/)
- Anthology ID: 2023.nlposs-1.27 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 기존의 MCQ 생성 평가 메트릭은 교육적 가치를 고려하지 않고, KDA를 측정하는 새로운 자동 평가 메트릭을 제안한다.
    2. 지식 종속 가능성(KDA)을 측정하기 위해, 학생 응답을 기반으로한 사람 조사를 활용하며, KDA_disc와 KDA_cont라는 두 가지 자동 평가 메트릭을 제안한다.
    3. KDA_disc와 KDA_cont는 교사의 라벨링된 MCQ 품질 측정에 강한 예측력을 가지고 있으며, 강의실 환경에서의 사용성과 관련도가 높다는 것을 보여준다.
    
    1. 최근 deep model의 정확성이 사람을 뛰어넘으나, spurious pattern에 의존하여 robustness가 제한되는 문제를 contrastive learning과 counterfactual augmentation을 활용하여 해결하고자 한다.
    2. 기존 augmentation의 경우 데이터셋에 counterfactual을 추가하는 것이나 이미 있는 counterfactual과 유사한 것들을 자동으로 찾는 것이 필요한 반면, 이 논문에서는 "여러 개의" counterfactual을 합성하여 인과관계를 더 robust하게 파악한다.
    3. 실험 결과, collective decisions를 통한 방법은 task model의 편향과 상관없이 counterfactual robustness, cross-domain generalization, scarce data에서의 generalization에서 유의한 향상을 보인다.

###### Towards Explainable and Accessible AI (https://aclanthology.org/2023.nlposs-1.28/)
- Anthology ID: 2023.nlposs-1.28 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. MCQ 생성에 대한 기존 평가 메트릭은 교육적 가치를 고려하지 못하고, 우리는 지식 종속 가능성(KDA)이라고 불리는 새로운 평가 메트릭을 제안한다.
    2. 기존 자동화 방법과 다르게 우리의 방법은 여러 개의 수치를 통해서 각 단어들 간의 인과관계를 파악하여 더 robust한 유의미한 결과들을 얻을 수 있다.
    3. KDA_disc와 KDA_cont는 강의실에서의 사용성과 강한 상관관계를 가지고 있음을 human evaluation을 통해 입증하였다.


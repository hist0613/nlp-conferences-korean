# Korean Three-Line Summarizations of EMNLP 2023
## Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing
###### Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (https://aclanthology.org/2023.emnlp-main.0/)
- Anthology ID: 2023.emnlp-main.0 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    요약문을 생성할 수 없습니다.

###### IAG: Induction-Augmented Generation Framework for Answering Reasoning Questions (https://aclanthology.org/2023.emnlp-main.1/)
- Anthology ID: 2023.emnlp-main.1 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 외부 지식과 파라미터 기반 언어 모델의 메모리를 결합한 RAG 모델은 오픈 도메인 QA 태스크에서 최고의 아키텍처가 되었습니다. 그러나 일반적인 지식 베이스는 한정된 커버리지와 노이즈가 있는 정보로 제한되어 있어 암묵적 추론 질문에 대한 검색 기반 접근법은 부적절합니다.
    2. 이 논문에서는 검색 문서와 함께 유추적인 지식을 활용하는 Induction-Augmented Generation (IAG) 프레임워크를 제안합니다. 이를 위해 유추적 추론 패턴을 기반으로하는 독특한 프롬프팅 방법을 사용하여 대규모 언어 모델을 활용하여 이러한 지식을 도출합니다.
    3. 실험 결과, IAG는 RAG 기준선 및 ChatGPT보다 두 개의 오픈 도메인 QA 태스크에서 우수한 성능을 보였습니다. 특히, 우리의 최고 모델은 CSQA2.0 (2022년 11월 1일부터) 및 StrategyQA (2023년 1월 8일부터)의 공식 리더보드에서 1위를 차지했습니다.

###### Absolute Position Embedding Learns Sinusoid-like Waves for Attention Based on Relative Position (https://aclanthology.org/2023.emnlp-main.2/)
- Anthology ID: 2023.emnlp-main.2 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 어텐션 가중치는 Transformer 기반 모델의 추론 과정을 해석하는 데 도움이 되는 신호입니다.
    2. 일부 어텐션 헤드에서는 각 토큰의 이웃에 집중하여, 주변 토큰에 따라 각 토큰의 출력 벡터가 의존성을 가짐으로써 추론이 문맥에 따라 다를 수 있습니다.
    3. 연구 결과는 학습된 위치 임베딩이 사인 함수 형태의 구성 요소를 가지고 있으며, 이러한 구성 요소가 셀프-어텐션에서 query와 key에 전달되고, 어텐션 헤드가 관련 상대적 위치의 인근 토큰에 집중하도록 사인 함수 구성 요소의 위상을 조정한다는 것을 보여줍니다.

###### Chinese Lexical Substitution: Dataset and Method (https://aclanthology.org/2023.emnlp-main.3/)
- Anthology ID: 2023.emnlp-main.3 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존 lexical substitution (LS) 벤치마크는 인간 주석자에게 기억에서 대체어를 생각하도록 한 것으로, 카버리지가 제한되고 규모도 상대적으로 작은 문제가 있다. 따라서 우리는 사람과 기계의 협업을 바탕으로 한 LS 데이터셋을 구성하기 위한 새로운 주석 방법을 제안한다.
    2. 우리의 주석 방법을 기반으로, 우리는 중국어 LS 데이터셋 CHNLS를 구축했으며, 뉴스, 소설 및 위키피디아 등 세 가지 텍스트 장르를 커버하는 33,695개의 인스턴스와 144,708개의 대체어로 구성되어 있다.
    3. 실험 결과로 앙상블 방법이 다른 LS 방법보다 우수하게 나타났으며, 중국어 LS 작업에서 최초로 연구되었다.

###### Decoding the Silent Majority: Inducing Belief Augmented Social Graph with Large Language Model for Response Forecasting (https://aclanthology.org/2023.emnlp-main.4/)
- Anthology ID: 2023.emnlp-main.4 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 뉴스 미디어를 위한 자동 응답 예측은 소셜 및 컨텍스트 정보를 활용하여 뉴스 릴리스의 영향력을 예측하고 사회적 충돌 및 도덕적 상해와 같은 예기치 않은 부정적 결과를 방지하는 데 핵심적인 역할을 한다.
    2. 기존의 방법들은 사용자의 명시적 프로필이나 과거 활동이 제한된 경우 (lurker라고 함)에도 인간-인간 상호작용 및 문맥 정보를 활용하여 효과적으로 응답을 예측해야 한다는 요건을 충족시키기 위해 최적의 처리와 활용 방법에 대해 제한적으로 다루었다.
    3. 이 논문에서는 대규모 언어 모델을 활용하여 기존 소셜 네트워크 위에 믿음-중심 그래프를 형성하고 그래프 기반 전파를 통해 사회적 역학을 캡처하는 프레임워크인 SocialSense를 제안한다. 이 방법론은 먼 거리에 위치한 유사한 신념을 가진 사용자들을 연결하는 인공 그래프를 형성하여 응답 패턴을 효과적으로 파악할 수 있다는 가설을 세우고 있다.

###### Fine-grained Conversational Decoding via Isotropic and Proximal Search (https://aclanthology.org/2023.emnlp-main.5/)
- Anthology ID: 2023.emnlp-main.5 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화 응답 생성에는 보통 범용 텍스트 디코딩 접근 방식이 사용되는데, 이 논문에서는 대화 특정 인코딩 방법을 활용하여 응답의 품질을 개선하지만, 대화 디코딩 방법에는 여전히 자세히 연구되지 않았다.
    2. 이 논문에서는 지역성(locality)과 동질성(isotropy)의 규칙을 따르는 좋은 대화 특징 공간이어야 한다는 SimDRC의 영감을 받아, 세밀한 대화 디코딩 방법인 IPS (isotropic and proximal search)를 제안한다.
    3. 실험 결과, IPS는 자동 및 인간 평가 메트릭 모두에서 대화 분야에서 기존 디코딩 전략보다 유의미하게 우수한 성과를 보여주며, 더 심층적인 분석을 통해 우리의 방법의 효과를 확인하였다.

###### Holistic Inter-Annotator Agreement and Corpus Coherence Estimation in a Large-scale Multilingual Annotation Campaign (https://aclanthology.org/2023.emnlp-main.6/)
- Anthology ID: 2023.emnlp-main.6 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문에서는 6개의 언어와 약 40 명의 주석가들이 참여한 대규모 다국어 주석 캠페인의 난이도를 보고한다. 사람들이 주석을 달기 어려워하는 기술을 강조하고, 이 현상의 원인에 대해 설명한다.
    2. 우리는 단어 임베딩을 기반으로 한 새로운 Annotator 확인(metric)인 Holistic IAA를 소개하고, 이 metric을 사용한 다양한 실험과 전통적인 Inter Annotator Agreement(IAA) metric과의 상관관계에 대해 보고한다.
    3. 그러나 주석가들 간의 상호 작용이 다소 제한되어 있고, 즉, 몇 명의 주석가들만 동일한 문서 하위 집합에 주석을 달으며, 우리는 데이터 세트 전체의 일관성을 평가하고, 서로 다른 문서와 언어에 대해 주석을 달은 주석가 간의 IAA에 대한 좋은 대리자를 찾기 위한 방법을 모색한다.

###### PHD: Pixel-Based Language Modeling of Historical Documents (https://aclanthology.org/2023.emnlp-main.7/)
- Anthology ID: 2023.emnlp-main.7 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 고전문서의 디지털화는 역사학자에게 이전에 없던 연구 기회를 제공하지만, 전통적인 방식은 OCR을 사용하여 이미지를 텍스트로 변환하는 것으로, 이미지로 처리하는 잠재적 이점을 간과하고 많은 노이즈를 도입하고 있다.
    2. 이 논문에서는 픽셀 기반 언어 모델을 사용하여 마스킹된 픽셀 패치를 재구성하는 방법을 제안한다.
    3. 역사적 스캔을 생성하기 위한 새로운 방법과 실제 역사적 신문을 결합하여 모델을 사전 훈련시키고, 이 모델을 역사적 QA 작업에 성공적으로 적용하여 유용성을 입증하였다.

###### Primacy Effect of ChatGPT (https://aclanthology.org/2023.emnlp-main.8/)
- Anthology ID: 2023.emnlp-main.8 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. ChatGPT와 같은 대형 언어 모델은 zero-shot 성능에서 탁월한 성과를 보여주고 있지만, 레이블의 순서에 따라 선택되는 기울기가 있다는 연구 결과를 발견하였다. 
    2. ChatGPT의 의사 결정은 레이블의 순서에 영향을 받고, 순서상 먼저 등장하는 레이블을 선호한다는 것을 확인하였다. 
    3. 이러한 결과는 더 신뢰할 수 있는 ChatGPT 기반 솔루션을 개발하기 위한 추가적인 통찰력을 제공할 수 있으며, 관련 코드를 공개하였다.

###### Evaluating the Rationale Understanding of Critical Reasoning in Logical Reading Comprehension (https://aclanthology.org/2023.emnlp-main.9/)
- Anthology ID: 2023.emnlp-main.9 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "논리적 읽기 이해 능력을 정확하게 평가하기 위해, 우리는 주요 추론의 이유를 이해하기 위한 데이터셋을 제공한다. 기존 다중 선택 논리적 읽기 이해 데이터셋의 질문을 사용하여 선택 또는 제거해야 하는 대답 옵션에 대한 이유에 대한 논리적 설명을 크라우드소싱하였다. 우리의 데이터셋 실험 결과, 최근의 대형 언어 모델들은 주요 질문에 올바른 답을 줄 수는 있지만, 서브 질문에 대답하는 데 어려움을 겪는다는 것을 보여준다."
    2. "모델들은 특히 주요 질문의 잘못된 답변 옵션을 위한 서브 질문에 대한 답변을 제공하기 어렵다는 것을 알 수 있었으며, 이는 모델들이 잘못된 대안이 왜 제거되어야 하는지에 대한 한정된 능력을 가지고 있다는 것을 시사한다."
    3. "이러한 결과들은 우리의 데이터셋이 언어 모델들의 중요한 추론 능력에 대한 추가적인 연구를 유도하면서 관련 대안의 제거 과정에 초점을 맞추고 있다는 것을 시사한다."

###### Evaluating and Modeling Attribution for Cross-Lingual Question Answering (https://aclanthology.org/2023.emnlp-main.10/)
- Anthology ID: 2023.emnlp-main.10 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 높은 리소스를 가진 언어에서는 신뢰할 수 있는 답변 콘텐츠가 풍부하게 제공되고 질문에 대한 답을 얻기가 쉬우나, 해당 언어를 알지 못하는 사람들은 이러한 콘텐츠에 접근하기 힘들다.
    2. 이 논문에서는 Cross-lingual 질문 응답(QA)을 위한 attribution (특정 출처 적용)에 대해 연구한다. 그리고 상위 cross-lingual QA 시스템의 attribution 수준을 평가한 결과, 답변의 상당 부분이 어떤 출처에 속하는지 알 수 없음이 발견되었다.
    3. 이러한 부족한 attribution 문제를 해결하기 위해 Natural Language Inference 모델과 PaLM 2 모델을 이용하여 attribution 감지를 시도하였고, 이를 통해 cross-lingual QA 시스템의 attribution 수준을 개선할 수 있었다.

###### Better Quality Pre-training Data and T5 Models for African Languages (https://aclanthology.org/2023.emnlp-main.11/)
- Anthology ID: 2023.emnlp-main.11 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 연구에서는 다국어 언어 모델의 사전 훈련 데이터의 품질 향상의 중요성을 강조한다. 특히 저자원 언어에 대한 기존 웹 크롤은 품질 문제를 가지고 있는데, 이러한 문제점을 이해하고 수정하기 위해 기존 사전 훈련 말뭉치를 정밀히 조사하여 16개 아프리카 언어용 새로운 다국어 사전 훈련 말뭉치를 소개한다.
    2. 이 데이터셋을 구축하기 위해 가장 포괄적인 다국어 웹 크롤 중 하나인 mC4에서 13개 언어에 대한 현재 데이터 소스를 철저히 조사하고, 세심한 조사와 개선된 웹 크롤링 전략을 통해 더 깨끗한 데이터를 추출한다.
    3. 이후 이 데이터셋을 사용하여 T5 기반 모델을 사전 훈련하고 여러 하위 작업에서의 성능을 평가한다. 새로운 모델은 네 가지 NLP 작업에서 기존 사전 훈련 모델보다 더 나은 효과를 보여주며, 저자원 시나리오에서 언어 모델의 사전 훈련에 데이터 품질이 중요한 역할을 한다는 것을 강조한다.

###### Sparse Universal Transformer (https://aclanthology.org/2023.emnlp-main.12/)
- Anthology ID: 2023.emnlp-main.12 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 유니버셜 트랜스포머(UT)는 레이어 간에 파라미터를 공유하며, 일정 가정하에서 Turing-complete한 트랜스포머 변종이다. 이 논문에서는 Sparse Mixture of Experts (SMoE)를 이용하여 이 UT의 계산 복잡성을 줄이고, 파라미터 효율성과 일반화 능력을 유지하는 Sparse Universal Transformer (SUT)을 제안한다.
    2. SUT는 견고한 일반화 결과와 WMT'14와 같은 표준적인 자연어 벤치마크에서의 파라미터 및 계산 효율을 달성하여, 유니버셜 트랜스포머와 베니라 트랜스포머의 장점을 모두 결합한다.
    3. 현재까지의 최첨단 자연어처리 시스템들은 대부분 베니라 트랜스포머를 기반 모델로 사용하고 있으며, 이는 UT의 파라미터 스케일링이 VT와 비교해 컴퓨팅과 메모리 비용이 더 많이 들기 때문이다.

###### Theory of Mind for Multi-Agent Collaboration via Large Language Models (https://aclanthology.org/2023.emnlp-main.13/)
- Anthology ID: 2023.emnlp-main.13 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델 (LLM)은 추론 및 계획에 뛰어난 성과를 보여주었지만, 다중 에이전트 협업에 대한 능력은 아직 탐구되지 않았다. 이 연구는 LLM 기반 에이전트를 Theory of Mind (ToM) 추론 과제를 가진 다중 에이전트 협력 텍스트 게임에서 평가하여, Multi-Agent Reinforcement Learning (MARL) 및 계획 기반 베이스라인과의 성능을 비교한다.
    2. LLM 기반 에이전트들은 긴 시야 범위에 대한 문맥 관리의 체계적인 실패 및 과제 상태에 대한 환각으로 인해 계획 최적화에 제한이 있음을 관찰했다.
    3. 명시적 신념 상태 표현의 사용은 이러한 문제를 완화하는 데 도움이 되며, LLM 기반 에이전트의 과제 성능 및 ToM 추론의 정확성을 향상시킨다는 것을 발견했다.

###### Establishing Trustworthiness: Rethinking Tasks and Model Evaluation (https://aclanthology.org/2023.emnlp-main.14/)
- Anthology ID: 2023.emnlp-main.14 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어 이해는 다면적인 인지 능력이며, NLP (자연어 처리) 커뮤니티는 수십 년 동안 컴퓨터 모델을 통해 이를 모델링하기 위해 노력해왔다. 
    2. 큰 언어 모델 (LLM)의 등장으로 인해 과거에는 특정 모델 구조와 평가 방법이 있다는 개념이 무너지고, 다목적, Task-agnostic 접근 방식이 대세가 되었다.
    3. 따라서 우리는 NLP에서 Task와 모델 평가의 개념을 재고하고, 더 ganzholistischen 언어 이해를 위한 평가 프로토콜을 추구해야 한다고 주장한다.

###### Let’s Think Frame by Frame with VIP: A Video Infilling and Prediction Dataset for Evaluating Video Chain-of-Thought (https://aclanthology.org/2023.emnlp-main.15/)
- Anthology ID: 2023.emnlp-main.15 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 결과들은 이미지를 자연어를 사용해 추론하는 vision-language system의 능력을 보여주었으나 비디오 추론 능력은 아직 충분히 연구되지 않았다. 
    2. 우리는 비디오 추론을 작은 수의 핵심 프레임에 대한 순차적 이해로 구성하고, 비디오 처리의 복잡성을 완화시키면서 vision-language의 강력함과 로버스트함을 활용하는 것을 제안한다. 
    3. 새로운 응용 프로그램을 평가하기 위해, 우리는 VIP라는 도전적인 데이터셋을 소개하는데 이는 비디오의 chain-of-thought를 통해 모델의 추론 능력을 탐구하기 위해 설계되었다. 비디오 인구 및 비디오 예측과 같은 두 가지 작업을 제안하여 그 능력을 평가한다.

###### GPTAraEval: A Comprehensive Evaluation of ChatGPT on Arabic NLP (https://aclanthology.org/2023.emnlp-main.16/)
- Anthology ID: 2023.emnlp-main.16 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. ChatGPT는 영어 벤치마크에서 뛰어난 성능을 보이지만, 다양한 언어 환경에서의 효능은 크게 알려져 있지 않다. 이 논문에서는 ChatGPT를 아랍어와 방언에 대해 평가하고자 한다.
    2. 대규모 자동 및 인간 평가를 통해 ChatGPT의 성능을 조사하고, 영어에서 뛰어난 성능을 보이는 ChatGPT보다 아랍어에 맞춰 finetuning된 작은 모델들이 일관적으로 우위에 서 있다는 결론에 도달하였다.
    3. ChatGPT와 GPT-4의 모던 스탠다드 아랍어와 아랍어 방언에 대한 성능을 세심하게 비교, 분석한 결과 두 모델 모두 MSA에 비하여 아랍어 방언을 다루는 데 상대적인 약점을 가지고 있다는 것을 밝혀냈다.

###### Dual-Channel Span for Aspect Sentiment Triplet Extraction (https://aclanthology.org/2023.emnlp-main.17/)
- Anthology ID: 2023.emnlp-main.17 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Aspect Sentiment Triplet Extraction (ASTE)"는 세세한 측면 기반 감성 분석(ABSA)의 합성 작업 중 하나로, 측면 용어, 해당 의견 용어 및 연관된 감성 방향의 세트를 추출하는 것을 목표로 한다. 
    2. 기존의 스팬 기반 접근 방법들은 모든 가능한 스팬을 열거해야 하는 문제점이 있었으나, 이 연구에서는 품사와 관련된 통사 관계를 이용하여 스팬 후보를 생성함으로써 이 부담을 줄이고, 스팬 표현에 풍부한 언어적 정보를 제공한다.
    3. 두 개의 공개 데이터셋에서의 실험 결과, 우리의 설계의 효과성과 ASTE/ATE/OTE 작업에서의 우수성을 입증하였다.

###### Cultural Concept Adaptation on Multimodal Reasoning (https://aclanthology.org/2023.emnlp-main.18/)
- Anthology ID: 2023.emnlp-main.18 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 저희는 다문화적인 역량을 향상시키기 위한 문화적 적응 방법의 개발이 중요하다고 생각하며, 낮은 자원 데이터에 대한 성능을 개선하고 모두가 공정한 기회를 누릴 수 있는 최첨단 기술을 제공합니다.
    2. 이 논문에서는 부족한 데이터와 비싼 어노테이션의 어려움을 극복하기 위해 높은 자원 문화를 활용하여 낮은 자원 문화를 이해시키는 방법을 소개합니다.
    3. 실험 결과, 우리의 방법은 다섯 가지 언어에 대해 제로샷과 퓨샷 설정에서 기존 다문화 및 다모달 모델의 성능을 일관되게 향상시킵니다.

###### Understanding Compositional Data Augmentation in Typologically Diverse Morphological Inflection (https://aclanthology.org/2023.emnlp-main.19/)
- Anthology ID: 2023.emnlp-main.19 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 데이터 부족 문제를 해결하기 위해 낮은 자원의 자동 형태 변형에서는 데이터 확장 기법이 널리 사용되지만, 이러한 기법의 전체적인 의미는 여전히 분명하지 않은 상태이다.
    2. 본 연구에서는 데이터 확장 전략 중 하나인 StemCorrupt의 이론적 측면에 대해 조명하고, 기존의 훈련 데이터 예제에서 어간 문자를 무작위로 치환하여 가상의 예제를 생성하는 방법을 분석한다.
    3. StemCorrupt는 근본적인 데이터 분포의 변화를 가져오며, 내재적인 구성합성 구조를 보여준다는 것을 발견하고, 일정 수준의 다양성과 예측적 불확실성을 가지는 데이터 포인트의 하위 집합을 선택하는 것이 경쟁하는 기준에 비해 데이터 효율성을 크게 향상시킨다는 것을 보여준다.

###### Evaluating Object Hallucination in Large Vision-Language Models (https://aclanthology.org/2023.emnlp-main.20/)
- Anthology ID: 2023.emnlp-main.20 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에 제안된 대형 언어 모델 (LLM)의 뛰어난 언어 능력에서 영감을 받아, 복잡한 다중 모달 태스크의 성능을 향상시키기 위해 강력한 LLM을 통합한 대형 시각-언어 모델 (LVLM)이 제안되었습니다.
    2. 그러나 LVLM은 객체 환시(object hallucination)라는 문제점을 가지고 있으며, 이는 설명과 대상 이미지와 일치하지 않은 객체를 생성하는 경향이 있습니다.
    3. 본 논문은 LVLM의 객체 환시에 대한 체계적인 연구를 제시하며, 대표적인 LVLM에 대한 평가 실험을 수행하여 심각한 객체 환시 문제가 있는 것을 보여줍니다.

###### Event Ontology Completion with Hierarchical Structure Evolution Networks (https://aclanthology.org/2023.emnlp-main.21/)
- Anthology ID: 2023.emnlp-main.21 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존 event detection 방법은 사전에 정의된 event schemas에 의존하지만, 이는 비용이 많이 들고 schemas의 커버리지가 제한되는 문제점이 있다.
    2. 본 논문에서는 Event Ontology Completion (EOC)이라는 새로운 연구 과제를 제안하고, 이를 위해 Hierarchical Structure Evolution Network (HalTon)을 개발하였다.
    3. 실험 결과, HalTon은 기존방법보다 ARI score에서 8.23%, 8.79%, 8.10% 더 높은 성능을 보여준다.

###### Parameter-efficient Tuning for Large Language Model without Calculating Its Gradients (https://aclanthology.org/2023.emnlp-main.22/)
- Anthology ID: 2023.emnlp-main.22 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델의 모든 매개변수를 fine-tuning 하는 것은 계산 및 시간적 리소스가 크게 요구되는데, 본 논문에서는 gradient를 계산하지 않고도 매개변수 효율 조정이 가능한 새로운 방법을 제안한다.
    2. 작은 언어 모델로부터 얻은 parameter-efficient 모듈들을 대규모 언어 모델로 전송하여 smooth하고 효과적인 적응 프로세스를 보장하는데, 이를 위해 Bridge 모델을 도입한다.
    3. 본 방법은 T5와 GPT-2 언어 모델을 사용하여 SuperGLUE 벤치마크에서 fine-tuning 및 parameter-efficient tuning과 비교 가능한 성능을 달성하며, gradient 기반 최적화 없이도 parameter-efficient tuning에 비해 최대 5.7배의 메모리 절감을 달성한다.

###### Discourse Structures Guided Fine-grained Propaganda Identification (https://aclanthology.org/2023.emnlp-main.23/)
- Anthology ID: 2023.emnlp-main.23 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Propaganda는 주로 정치적 목적으로 대중을 선동하거나 오도하는 형태의 기만적인 이야기이다. 이 논문에서는 정치 뉴스에서 propaganda를 문장 수준과 토큰 수준에서 식별하는 것을 목표로 한다.
    2. Propaganda 콘텐츠는 인과관계를 나타내거나 주변 문장과 대조적인 어조로 작성된 문장에 더 자주 포함되어 있다는 것을 관찰했다.
    3. 따라서 우리는 propaganda 탐지를 위해 지역적 및 전역적 담화 구조를 결합하고, 주변 문장 사이의 PDTB-style 담화 관계 및 뉴스 기사의 일반적인 담화 역할을 식별하기 위해 두 가지 교사 모델을 구성한다.

###### CompoundPiece: Evaluating and Improving Decompounding Performance of Language Models (https://aclanthology.org/2023.emnlp-main.24/)
- Anthology ID: 2023.emnlp-main.24 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 복합어 분해 작업 연구는 한국어, 동양어 등 복합어 형성이 매우 생산적인 언어에만 집중되어 왔고, 많은 언어들의 복합어 및 비복합어가 포함된 공개 데이터셋이 없었다. 본 논문에서는 56개의 다양한 언어로 이루어진 255,000개의 복합어 및 비복합어 단어를 포함하는 데이터셋을 소개하고, 이를 사용하여 대용량 언어 모델의 복합어 분해 작업을 평가한다.
    2. 실험 결과, 대용량 언어 모델의 복합어 분해 작업 성능이 낮다는 것을 확인하였고, 이는 subword tokenization에 의해 불리하게 토큰화된 단어들에 대한 영향이 컸다. 따라서, 이러한 문제를 해결하기 위해 두 단계의 접근 방식을 제안한다. 
    3. 첫 번째 단계에서는 fully self-supervised objective를 사용하여 모델을 학습시키고, 두 번째 단계에서는 Wiktionary의 주석 달린 데이터를 사용하여 모델을 fine-tuning한다. 이를 통해 unsupervised 모델은 이전에 보고된 모델보다 13.9%의 정확도를, fine-tuned 모델은 이전에 보고된 모든 복합어 분해 도구들보다 우수한 성능을 보였다.

###### Improving Image Captioning via Predicting Structured Concepts (https://aclanthology.org/2023.emnlp-main.25/)
- Anthology ID: 2023.emnlp-main.25 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이미지 캡션 작업에서 이미지와 텍스트 간의 의미적 간극을 해결하는 것이 어려운데, 이 분야의 기존 연구들은 의미 개념을 두 모드 간의 다리 역할로 취급하고 캡션 성능을 향상시키는 데 일부 주목했다.
    2. 그러나 이와 관련된 개념들의 관계를 무시하는 경우가 많으며, 이는 이미지의 객체 뿐만 아니라 텍스트의 단어 종속성에도 의존하기 때문에 좋은 설명을 만들어내는 과정 개선의 상당한 잠재력을 제공한다.
    3. 이 논문에서는 개념과 개념 구조를 예측하기 위해 구조화된 개념 예측자 (SCP)를 제안하고, 이를 캡션 작업에 통합하여 개념을 통해 시각 신호의 기여도를 향상시키고, 더 나은 설명 생성을 위해 이들의 관계를 구별하는 데 활용한다.

###### GATITOS: Using a New Multilingual Lexicon for Low-resource Machine Translation (https://aclanthology.org/2023.emnlp-main.26/)
- Anthology ID: 2023.emnlp-main.26 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최신 기계 번역 모델과 언어 모델은 병렬 데이터에 기반하지 않고도 번역할 수 있지만, 여전히 예측 가능한 방식으로 많은 문제를 겪고 있다. 이 연구에서는 양방향 어휘 정리자를 활용하여 이러한 문제를 해결하는 방법을 제안한다.
    2. 연구에서는 어휘 데이터 증강을 통해 비지도 번역에서 상당한 성능 향상을 보여준다.
    3. 여러 가지 데이터 증강 방법을 비교하여 유사한 개선 효과를 나타내고, 이를 결합함으로써 더 큰 향상을 얻을 수 있다는 것을 보여준다.

###### Continually Improving Extractive QA via Human Feedback (https://aclanthology.org/2023.emnlp-main.27/)
- Anthology ID: 2023.emnlp-main.27 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사용자의 피드백을 통해 추출형 질문 응답 시스템을 지속적으로 개선하는 연구를 수행했습니다.
    2. 정보를 얻고자 하는 사용자들이 질문을 하고, 모델이 예측한 답변을 받고, 피드백을 제공하는 반복적인 접근법을 설계하고 적용했습니다.
    3. 우리의 실험 결과는 다양한 데이터 조건에서 추출형 QA 모델의 사용자 피드백을 통한 시스템 개선이 효과적이며, 도메인 적응에 큰 잠재력을 보여줌을 보여줍니다.

###### Using Interpretation Methods for Model Enhancement (https://aclanthology.org/2023.emnlp-main.28/)
- Anthology ID: 2023.emnlp-main.28 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. neural 자연어 처리 시대에서 neural 모델의 해석을 유도하려는 연구들이 존재하는데, 기계 번역 및 기타 태스크에 대해 모델이 gold rationale과 일치할 수 있도록 추가적으로 학습시키는 방법이 제안되었다.
    2. 이 논문에서는 인터프리테이션 방법과 gold rationale을 이용하여 모델을 향상시키기 위한 프레임워크를 제안한다. 이 방법은 다양한 인터프리테이션 방법을 포함할 수 있다.
    3. 실험 결과, 저자들이 제안한 프레임워크는 특히 저자들이 제안한 새로운 두 가지 방법이 대부분의 설정에서 gradient-based 방법보다 우수한 성능을 보인다는 것을 확인하였다.

###### An Expression Tree Decoding Strategy for Mathematical Equation Generation (https://aclanthology.org/2023.emnlp-main.29/)
- Anthology ID: 2023.emnlp-main.29 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어로부터 수학식을 생성하기 위해서는 수학 표현 간의 관계를 정확하게 이해해야 한다. 기존 접근법은 토큰 수준과 표현 수준으로 크게 분류된다. 전자는 수학식을 수학 언어로 취급하여 순차적으로 수학 토큰을 생성한다. 후자는 각 표현을 한 번에 하나씩 생성한다. 하지만 각 표현은 문제 해결 단계를 나타내며, 이러한 단계 사이에는 병렬 또는 종속 관계가 자연스럽게 존재하는데, 현재의 순차적인 방법에서는 이를 무시한다.
    2. 따라서 우리는 표현 수준 생성에 트리 구조를 통합하고, 표현 트리 디코딩 전략을 제안한다. 표현을 노드로 하는 트리를 생성하기 위해 우리는 레이어별 병렬 디코딩 전략을 사용한다. 각 레이어에서는 독립적인 표현 (리프 노드)을 병렬로 디코딩하고, 다른 표현에 의존하는 부모 노드 표현을 순차적으로 생성하기 위해 레이어별로 병렬 디코딩을 반복한다. 또한, 각 레이어에서 여러 예측과 주석을 매칭시키기 위해 이분 매칭 알고리즘을 사용한다.
    3. 실험 결과, 우리의 방법이 다른 기준선에 비해 향상된 성능을 보이며, 특히 복잡한 구조를 가진 수학식에 대해서 더 좋은 성과를 얻는다.

###### Bootstrapping Small & High Performance Language Models with Unmasking-Removal Training Policy (https://aclanthology.org/2023.emnlp-main.30/)
- Anthology ID: 2023.emnlp-main.30 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "BabyBERTa는 작은 양의 아동 언어 모델로, 훈련 과정에서 단어들이 완전히 노출되지 않았음에도 불구하고 RoBERTa-base와 비교할만한 수준의 문법성을 보여준다."
    2. 이 논문은 BabyBERTa 기반 모델의 성능을 연구하며, Semantic Role Labeling (SRL) 및 두 개의 추출형 질의응답 과제에 초점을 맞추어 데이터 양과 모델 크기를 줄여 효율적인 시스템 구축을 목표로 한다.
    3. 실험 결과, BabyBERTa는 10M 단어로 훈련할 때 RoBERTa의 마스킹 정책보다 어느 정도 강력한 시작점이며, 이 경향은 훈련 데이터를 더 추가할 때에도 유지되는 것으로 나타났다.

###### Diversity Enhanced Narrative Question Generation for Storybooks (https://aclanthology.org/2023.emnlp-main.31/)
- Anthology ID: 2023.emnlp-main.31 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이미 많은 발전이 있었지만, 질문 생성(QG)에서 생성된 질문의 다양성을 향상하거나 측정하는 것에는 아직도 도전이 남아있다.
    2. 본 논문에서는 맥락과 질문에 초점을 맞춘 mQG 모델을 소개하며, 다양하고 답변 가능한 여러 개의 질문을 생성할 수 있다. 
    3. mQG는 SQuAD 2.0으로 세분화된 질문을 분류하여 생성된 질문의 답변 가능성을 검증하며, FairytaleQA 데이터셋에서 훈련 및 평가되고 TellMeWhy 및 SQuAD1.1 데이터셋에도 제로샷 적용을 수행한다.

###### Debiasing Made State-of-the-art: Revisiting the Simple Seed-based Weak Supervision for Text Classification (https://aclanthology.org/2023.emnlp-main.32/)
- Anthology ID: 2023.emnlp-main.32 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 약한 지도학습 텍스트 분류의 발전은 대부분 인간의 경험을 바탕으로 한 휴리스틱(근거)를 품질 좋은 가짜 라벨로 변환하기 위해 정교한 방법을 고안하는 것에 초점을 맞추고 있다.
    2. 이 논문에서는 유명한 가상 라벨 생성 방법인 seed matching 기반 방법을 재검토하여, 그 파워가 크게 과소평가되었다는 것을 보여준다.
    3. seed matching의 한계 성능은 단순한 seed-match 규칙에 의해 주입되는 라벨 편향으로 인해 발생하며, seed words를 삭제하면 이 편향을 완화시키고 더 나은 신뢰성을 학습할 수 있어 seed matching의 성능을 크게 향상시킬 수 있다는 것을 보여준다.

###### How to Enhance Causal Discrimination of Utterances: A Case on Affective Reasoning (https://aclanthology.org/2023.emnlp-main.33/)
- Anthology ID: 2023.emnlp-main.33 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대부분의 모델이 시맨틱 상관관계는 잘 파악하지만 특정한 인과관계를 결정하는 것에 어려움을 겪고 있다. 
    2. 이 논문에서는 대화 과정에 i.i.d. 잡음 요소를 통합하여 구조적 인과 모델(SCM)을 구축하는 방법을 제안한다. 
    3. 우리의 실험에서는 우리의 접근법의 효과성과 해석 가능성을 검증하였다.

###### Compressing and Debiasing Vision-Language Pre-Trained Models for Visual Question Answering (https://aclanthology.org/2023.emnlp-main.34/)
- Anthology ID: 2023.emnlp-main.34 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 Vision-Language Pre-trained Models(VLPs)은 언어 데이터셋의 편향에 의존하여 일반화하지 못하고, 메모리와 연산의 효율성도 낮은 문제가 있다.
    2. 본 논문에서는 VLP의 압축과 편향 보정을 동시에 고려하여 효과적으로 탐색한다.
    3. Sparse하고 robust한 subnetworks를 찾아 OOD 데이터셋에서 더 적은 파라미터로 좋은 성능을 보이는 것을 실험적으로 입증하였다.

###### Selectively Answering Ambiguous Questions (https://aclanthology.org/2023.emnlp-main.35/)
- Anthology ID: 2023.emnlp-main.35 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 신뢰할 수 있는 언어 모델은 답을 모르는 경우에 답을 하지 않아야 한다. 그러나 질문의 답이 알려지지 않은 경우는 다양한 이유로 인해 발생할 수 있다.
    2. 이 논문에서는 질문의 목적이나 맥락의 불명확성으로 인해 답이 애매한 경우에 대해 연구하였다.
    3. 이 실험에서는 샘플된 모델 출력별 반복 빈도수를 측정하는 것이 이전 연구에서 사용된 모델의 우도나 자체 검증보다 신뢰성 있는 캘리브레이션 방법임을 발견했으며, 이는 명확하지 않은 질문에 대한 답변에서 더욱 좋은 결과를 나타내었다.

###### Temporal Knowledge Graph Forecasting Without Knowledge Using In-Context Learning (https://aclanthology.org/2023.emnlp-main.36/)
- Anthology ID: 2023.emnlp-main.36 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 자연어 처리 기술을 사용하여 시간적 지식 그래프(TKG) 예측을 수행하는 방법을 제안하고, 사전 학습된 큰 언어 모델(LLM)이 최첨단 모델(SOTA)과 비슷한 성능을 보인다는 것을 관찰하였다.
    2. LLM은 사전 학습된 모델로, 예측 작업을 위해 정교한 아키텍처와 감독 학습을 사용하는 SOTA 모델과 비슷한 성능을 보여준다. 이러한 강력한 성능을 보이기 위해 LLM은 문맥의 상징적 패턴을 활용할 수 있으며, 사전 의미 지식은 필요하지 않다는 것을 실험에서 확인하였다.
    3. 더 나아가, 자연어 모델을 통해 TKG 예측을 수행할 때, 역사적 사실 선택, 프롬프트 구성, 정보 전파 제어, 출력의 확률 분포 구성에 대한 다양한 접근 방식을 탐구하였고, 이를 통해 더 강력한 성능을 얻었다.

###### Knowledge Graph Compression Enhances Diverse Commonsense Generation (https://aclanthology.org/2023.emnlp-main.37/)
- Anthology ID: 2023.emnlp-main.37 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 일반상식 설명을 생성하기 위해서는 문맥에 명시적으로 언급되지 않은 일반상식 지식에 대한 추론이 필요하다. 기존의 모델들은 ConceptNet과 같은 일반상식 지식 그래프를 사용하여 입력된 개념과 관련된 지식의 하위 그래프를 추출한다.
    2. 그러나 ConceptNet은 커버리지가 크고, 결국 광범위한 규모를 갖기 때문에 추출된 하위 그래프는 느슨하게 관련되거나 중복되는 정보를 포함할 수 있고, 이는 모델에 노이즈를 도입할 수 있다.
    3. 우리는 이를 해결하기 위해 과제에 관련된 지식에 초점을 맞춘 차별화 가능한 그래프 압축 알고리즘을 적용하여 이 문제를 해결하는 방법을 제안한다. 압축된 하위 그래프는 일반상식과 추론 설명을 생성하는 모델에 통합될 때 훨씬 다양한 출력을 제공한다.

###### Pragmatic Reasoning Unlocks Quantifier Semantics for Foundation Models (https://aclanthology.org/2023.emnlp-main.38/)
- Anthology ID: 2023.emnlp-main.38 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Generalized quantifiers (예: few, most)는 술어(predicate)가 얼마나 만족하는지 비율을 나타내는 데 사용됩니다. 최근 foundation models은 직접적인 훈련 신호가 없어 이 능력을 갖고 있는지 여전히 불확실합니다."
    2. 이 논문에서는 QuRe라는 크라우드 소싱된 인간 주석을 포함한 Wikipedia 문장의 일반화된 양화자를 도입하여 양자 이해를 탐구합니다.
    3. Natural language inference와 Rational Speech Acts 프레임워크를 결합한 PRESQUE를 사용하여 실험 결과, 추가적인 훈련 없이 특정 비율 범위를 예측하는 데 있어 PRESQUE가 literal listener 기준보다 20% 상대적인 개선을 나타내었습니다.

###### LLM-FP4: 4-Bit Floating-Point Quantized Transformers (https://aclanthology.org/2023.emnlp-main.39/)
- Anthology ID: 2023.emnlp-main.39 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 우리는 LLM-FP4라는 방법을 제안하여 용량이 큰 언어 모델에서 가중치와 활성화 함수를 후처리 방식으로 4비트 부동 소수점 값으로 양자화하는 것을 제안한다.
    2. 기존 post-training quantization (PTQ) 솔루션은 주로 정수 기반이며 8비트 미만의 비트 폭에 대해 어려움이 있다.
    3. 우리는 최적의 양자화 매개변수를 탐색함으로써 강력한 FP-PTQ 기준을 구축하고, 활성화 양자화 난이도를 해결하기 위해 채널별 활성화 양자화를 제안한다.

###### Improving Biomedical Abstractive Summarisation with Knowledge Aggregation from Citation Papers (https://aclanthology.org/2023.emnlp-main.40/)
- Anthology ID: 2023.emnlp-main.40 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 생물의료 문헌에서 파생된 초록은 전문적인 글쓰기 스타일과 생물의료 용어와 같은 독특한 도메인 특성을 가지고 있어 관련 문헌에 대한 깊은 이해가 필요하다. 그 결과, 존재하는 언어 모델은 도메인 특정 배경 지식의 부재로 생물의료 전문가가 작성한 요약문과 견줄만한 정확한 기술적 요약문을 생성하기 어렵다.
    2. 이 연구는 소스 기사 내에서 인용된 외부 논문으로부터 지식을 집계하여 생물의료 분야에서 언어 모델의 성능을 향상시키고자 한다. 우리는 도메인 특정 지식을 인용 논문으로부터 통합하는 새로운 어텐션 기반의 인용 집계 모델을 제안한다. 이 모델은 논문 내용과 인용 논문으로부터의 관련 지식을 모두 활용하여 신경망이 요약문을 생성할 수 있게 한다.
    3. 실험 결과, 우리의 모델은 최신 기법을 능가하며 생물의료 텍스트의 요약에서 상당한 개선을 달성한다. 이를 위해 우리는 대규모 생물의료 요약 데이터셋을 구축하고 이를 연구의 기반으로 공개한다.

###### Explanation Selection Using Unlabeled Data for Chain-of-Thought Prompting (https://aclanthology.org/2023.emnlp-main.41/)
- Anthology ID: 2023.emnlp-main.41 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 연구들은 대규모 언어 모델에 설명을 포함하여 구성하면 텍스트 추론 작업에서 뛰어난 성능을 얻을 수 있다는 것을 보여준다. 그러나 조금 다른 설명은 결과적인 작업 정확도에 큰 영향을 미칠 수 있다. 
    2. 이 논문에서는 어떻게 설명을 포함한 프롬프트를 블랙박스로 최적화할지 다루고 있다. 먼저 각 예제에 대해 후보 설명 집합을 생성하고, 이러한 설명들의 효과적인 조합을 찾기 위해 두 단계의 프레임워크를 사용한다.
    3. 실험 결과, 우리의 프록시 메트릭은 실제 정확도와 상관관계를 가지고 있으며, 우리의 방법은 크라우드워커 주석 및 단순한 탐색 전략보다 높은 성능의 프롬프트를 효과적으로 개선할 수 있다는 것을 보여준다.

###### HalOmi: A Manually Annotated Benchmark for Multilingual Hallucination and Omission Detection in Machine Translation (https://aclanthology.org/2023.emnlp-main.42/)
- Anthology ID: 2023.emnlp-main.42 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기계 번역에서의 환각은 입력과 관련없는 정보가 포함된 번역을 의미하며, 생략은 일부 입력 정보가 누락된 번역을 의미한다. 두 경우 모두 사용자 신뢰를 약화시키는 치명적인 오류인데, 이러한 병과가 포함된 주석이 달린 데이터는 극히 부족하며 고수준 언어에서만 제한적으로 존재한다.
    2. 본 논문에서는 다양한 자원 수준과 스크립트를 다루는 18개의 번역 방향에 대한 환각과 생략 현상에 대한 주석이 달린 데이터셋을 공개한다.
    3. 또한, 이전의 환각과 생략 탐지 방법들을 재방문하고, 단일 언어 쌍을 기반으로 한 결론들이 대규모 평가에는 거의 적용되지 않음을 보이며, 새로운 견고한 기준을 수립한다.

###### Gradient-based Gradual Pruning for Language-Specific Multilingual Neural Machine Translation (https://aclanthology.org/2023.emnlp-main.43/)
- Anthology ID: 2023.emnlp-main.43 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 멀티링구얼 뉴럴 기계 번역(MNMT)은 단일 모델로 여러 언어 간 번역을 편리하게 제공하지만, 고자원 언어에서 MNMT는 양쪽 번역 대조군에 비해 성능 저하가 발생할 수 있다.
    2. 이 논문에서는 이러한 문제를 해결하기 위해 MNMT를 위한 점진적 그래디언트 기반 가지치기 기법을 제안한다.
    3. 실험 결과, 저자들의 방법은 IWSLT와 WMT 데이터셋에서 현저한 성능 향상을 보여주었다.

###### LLM-powered Data Augmentation for Enhanced Cross-lingual Performance (https://aclanthology.org/2023.emnlp-main.44/)
- Anthology ID: 2023.emnlp-main.44 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 매우 제한된 데이터셋에서 다국어 상식 추론 데이터셋의 데이터 증강을 위해 대용량 언어 모델(Large Language Models, LLMs)을 활용하는 잠재력을 탐구한다.
    2. LLMs로 생성된 데이터를 활용하여 작은 다국어 모델(mBERT, XLMR)의 성능을 평가하고, 영어와 대상 언어로 생성된 데이터와 번역된 영어로 생성된 데이터의 성능을 비교한다.
    3. LLMs인 ChatGPT와 GPT-4는 대부분의 언어에서 자연스러운 텍스트와 논리적일관성을 잘 생성하지만, Tamil 같은 특정 언어에서 의미 있는 텍스트를 생성하는 데 어려움이 있으며, ChatGPT는 원본 데이터에 비해 타당한 대안을 생성하는 데 실패하는 반면, GPT-4의 예제는 경쟁력 있는 논리적 일관성을 보인다.

###### Prompt-based Logical Semantics Enhancement for Implicit Discourse Relation Recognition (https://aclanthology.org/2023.emnlp-main.45/)
- Anthology ID: 2023.emnlp-main.45 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 명시적 연결어 없이 담화 관계를 추론하는 IDRR은 여전히 중요하고 어려운 작업이다. 최근의 연구들은 주석된 의미로부터 계층 구조 정보를 활용하여 담화 관계를 향상시킬 수 있다는 것을 보여주고 있다.
    2. 그러나 IDRR의 성능과 견고성은 주석된 데이터의 가용성에 크게 제약을 받는다. 다행히도 명시적 연결어가 있는 주석되지 않은 발화의 풍부한 자료를 활용하여 담화 관계 특성을 향상시킬 수 있다.
    3. 연구에서는 IDRR을 위해 특정 주제 단어 예측 기법을 사용하여 사전 훈련된 언어 모델에 담화 관계에 관련된 지식을 주입하는 PLSE 방법을 제안한다. 실험 결과, 우리의 방법은 PDTB 2.0 및 CoNLL16 데이터셋에서 현재 최첨단 모델과 일관된 탁월한 성능을 보여준다.

###### VLIS: Unimodal Language Models Guide Multimodal Language Generation (https://aclanthology.org/2023.emnlp-main.46/)
- Anthology ID: 2023.emnlp-main.46 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어와 시각의 시너지를 활용하는 다중모달 언어 생성은 급격히 확장되는 분야이며, 그러나 복잡한 언어 이해를 필요로 하는 작업에서 기존 시각-언어 모델은 어려움을 겪고 있다.
    2. 이 논문에서는 비전-언어 모델의 시각 적응 능력과 텍스트만 있는 단일 모달 언어 모델의 언어 이해를 조합하여 별도의 학습 없이 복잡한 작업을 수행하는 VLIS(Vision-Language models as Importance Sampling weights)라는 새로운 프레임워크를 소개한다.
    3. VLIS는 시각-언어 모델로부터 각 이미지와 텍스트의 점별 상호정보를 추출하고, 이 값을 텍스트 모델의 토큰 likelihood를 조정하는 중요 표본추출 가중치로 사용함으로써 다양한 작업에서 vision-language 모델의 성능을 향상시킨다.

###### Conceptual structure coheres in human cognition but not in large language models (https://aclanthology.org/2023.emnlp-main.47/)
- Anthology ID: 2023.emnlp-main.47 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어의 신경망 모델은 오랫동안 마인드와 뇌의 개념적 표현에 대한 가설 개발 도구로 사용되어 왔다. 최근 언어 모델에서는 인지심리학에서 일반적으로 사용되는 방법과 거의 동일한 방법을 사용하여 개념적 표현의 잠재적 구조를 조사하는 것이 가능하다. 
    2. 이 연구에서는 인간과 GPT-3의 DaVinci 변형이라는 잘 알려진 대형 언어 모델에서 어깨너머 대화방법으로도 작동하는 세 가지 기법을 사용하여 양쪽의 어휘-의미 구조를 추정하고 비교한다. 
    3. 결과적으로, LLM 행동에서 추정된 구조는 개별적으로 인간 행동에서 추정된 구조와 일치하지만, 특정 작업에 의존하므로 서로 일관되지 않은 추정 값이 나온다. 이 결과는 최신 LLM의 지식과 인간 인지와의 차이점중 한가지를 보여준다.

###### Towards LLM-driven Dialogue State Tracking (https://aclanthology.org/2023.emnlp-main.48/)
- Anthology ID: 2023.emnlp-main.48 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화 상태 추적(DST)은 과업 지향형 대화 시스템에서 사용자 목표와 시스템 동작을 정확하게 추적하는 데 매우 중요하다. 이 연구에서는 ChatGPT의 DST 능력을 초기로 조사한 결과를 보고한다.
    2. ChatGPT는 DST 작업에서 뛰어난 성능을 발휘하여 연구자들에게 가치 있는 통찰력을 제공하고 대화 시스템의 설계와 향상에 유용한 방향을 제시한다.
    3. 그러나 ChatGPT는 소스가 공개되지 않아 요청 제한과 데이터 프라이버시 우려 등의 중요한 한계가 있다. 이를 해결하기 위해 작은 오픈 소스 기반 모델을 기반으로 하는 LDST 라는 LLM 기반 DST 프레임워크를 제안한다.

###### Learning Language-guided Adaptive Hyper-modality Representation for Multimodal Sentiment Analysis (https://aclanthology.org/2023.emnlp-main.49/)
- Anthology ID: 2023.emnlp-main.49 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다중 모달 감성 분석(MSA)은 다양한 소스(언어, 비디오, 오디오 등)로부터 풍부한 정보를 활용하여 효과적이지만, 모달 간 감성과 무관한 정보 또는 충돌하는 정보들은 성능 향상을 방해할 수 있다.
    2. 따라서 저희는 Adaptive Hyper-modality Learning (AHL) 모듈을 사용하여 서로 다른 스케일의 언어 기능을 가이드로 하여 시각 및 오디오 기능에서 무관성/충돌 억제 표현을 학습하는 Adaptive Language-guided Multimodal Transformer (ALMT)를 제안한다.
    3. ALMT는 다중 모달 융합을 통해 보완적이고 통합된 표현을 얻어 효과적인 MSA를 수행하며, MOSI, MOSEI, CH-SIMS와 같은 인기 있는 데이터셋에서 최고의 성능을 달성하고, 무관성/충돌 억제 매커니즘의 타당성과 필요성을 보여주는 다양한 실험 결과를 보여준다.

###### Multitask Multimodal Prompted Training for Interactive Embodied Task Completion (https://aclanthology.org/2023.emnlp-main.50/)
- Anthology ID: 2023.emnlp-main.50 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인터랙티브하고 신체적인 작업은 기존의 Vision & Language (VL) 모델들에게 적어도 두 가지 기본적인 어려움을 제시하는데, 하나는 언어를 행동과 관측들의 경로에 기반하여 정립하는 것이고, 또 하나는 지시를 명확히 하는 것이다.
    2. 이 문제를 해결하기 위해, 우리는 Embodied MultiModal Agent (EMMA)라는 통합된 인코더-디코더 모델을 제안한다. EMMA는 이미지와 경로를 근거로 하여 행동 예측을 멀티모달 텍스트 생성으로 바꾼다. EMMA는 모든 작업을 텍스트 생성으로 통합함으로써, 작업 간의 전이를 용이하게 하는 행동 언어를 학습한다.
    3. 독립적으로 훈련되는 모듈러 접근법과는 달리, EMMA는 각 작업이 목표 달성에 기여하는 하나의 멀티태스크 모델을 사용한다. EMMA는 몇 가지 VL 벤치마크에서 유사한 모델과 비슷한 성능을 보이며, Dialog-guided Task Completion (DTC)에서는 새로운 최고 성능(36.81% 성공률)을 보여준다. (DTC는 Alexa Arena에서 독립 가이드가 있는 에이전트를 평가하는 벤치마크입니다.)

###### We’re Afraid Language Models Aren’t Modeling Ambiguity (https://aclanthology.org/2023.emnlp-main.51/)
- Anthology ID: 2023.emnlp-main.51 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 어디선가 모호함은 자연어의 본질적인 특징이다. 모호한 언어를 처리하는 것은 대화상대로서 오해를 예상하고 청취자로서 해석을 수정하는데 핵심적인 부분이다. 이 논문에서는 AmbiEnt라는 언어학자 주석이 달린 1,645개의 다양한 모호한 어구 예제를 활용하여 사전 훈련된 언어 모델이 모호함을 인식하고 가능한 의미를 분리하는 첫 번째 평가를 제시한다.
    2. 사전 훈련된 언어 모델은 모호함을 인식하고 의미를 분리하기 위한 작업에서 여전히 매우 어렵다는 것을 발견한다. Crowdworker 평가에서 GPT-4의 생성된 모호 해소는 데이터셋의 모호 해소에 비해 올바른 경우에만 32%의 정확도를 보였다. 
    3. 마지막으로, 모호함에 민감한 도구의 가치를 보여주기 위해, 다중 레이블 NLI 모델이 모호함으로 인해 잘못된 정치적 주장을 찾아내는 데 사용될 수 있음을 보여준다. NLP에서 모호함의 중요성을 되새기도록 연구 분야에 독려한다.

###### Linear-Time Modeling of Linguistic Structure: An Order-Theoretic Perspective (https://aclanthology.org/2023.emnlp-main.52/)
- Anthology ID: 2023.emnlp-main.52 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 텍스트 간의 관계를 모델링하는 것은 자연어를 이해하는 데 필수적이다. 하지만 이와 같은 작업은 토큰들 간의 조합에 대한 비교가 필요하므로 문자열의 길이에 대한 이차 시간 복잡도를 가진다. 
    2. 우리는 토큰 간의 관계를 문자열에 대한 부분 순서로 변환하여 이러한 비교를 피할 수 있으며, 또한 작업의 복잡도를 선형으로 감소시킬 수 있다고 보여준다. 
    3. 실험 결과, 우리의 방법은 의존성 구문 및 핵심 분석 작업에서 최첨단 또는 비슷한 성능을 달성한다는 것을 보여준다. 또한, 우리의 방법의 선형 복잡성과 병렬성은 그래프 기반 공유 지침 해결 모델의 속도를 두 배로 높이고, 그래프 기반 의존성 파서의 속도를 10배 높인다.

###### GEMINI: Controlling The Sentence-Level Summary Style in Abstractive Text Summarization (https://aclanthology.org/2023.emnlp-main.53/)
- Anthology ID: 2023.emnlp-main.53 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인간 전문가들은 문서에서 문장을 추출하거나 다양한 정보를 퓨전하여 요약을 작성하는 등 다양한 기술을 활용한다. GEMINI 모델은 이러한 다양성을 따라하기 위해 문장 다시 작성과 요약 기술을 흉내내는 리라이터와 생성기를 통합하는 방식으로 구성되어 있다.
    2. GEMINI는 특정 문서 문장을 다시 작성할지 아니면 요약 문장을 처음부터 생성할지 선택하는 적응형 모델이다.
    3. 실험 결과, GEMINI는 순수하게 인용적 요약 기법이나 다시 작성 기법보다 성능이 뛰어나며, WikiHow 데이터셋에서 최상의 결과를 달성한다. 또한, 문맥에 따라 요약 문장의 인간적 스타일이 일관되게 예측 가능하다는 것을 실험 결과로 보여주고 있다.

###### Fidelity-Enriched Contrastive Search: Reconciling the Faithfulness-Diversity Trade-Off in Text Generation (https://aclanthology.org/2023.emnlp-main.54/)
- Anthology ID: 2023.emnlp-main.54 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 생성 작업에서 자주 발생하는 환영(hallucination) 문제에 대해 다루고 있다. 언어 모델은 종종 유창하고 설득력 있는 내용을 생성하지만 제공된 소스와 일관성이 부족하여 잠재적인 부정확성을 초래한다. 
    2. 제안된 새로운 디코딩 방법인 FECS는 문맥에 민감한 규제항을 사용하여 대조 탐색 프레임워크를 확장한다. FECS는 제공된 소스와 의미적으로 유사한 토큰을 촉진하면서 생성된 텍스트의 반복성을 벌점화한다. 
    3. FECS는 환영에 취약한 두 작업인 요약 생성과 대화 생성에서 효과적임을 보여준다. 결과는 FECS가 다양한 언어 모델 크기에서 충실성을 지속적으로 향상시키면서 잘 수행되는 디코딩 알고리즘과 비슷한 출력 다양성을 유지한다는 것을 보여준다.

###### Analyzing Norm Violations in Live-Stream Chat (https://aclanthology.org/2023.emnlp-main.55/)
- Anthology ID: 2023.emnlp-main.55 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 유해한 언어, 예를 들어 혐오 발언은 사용자가 온라인 커뮤니티에서 참여하는 것을 방해하고 인기있는 플랫폼에서 즐기는 것을 어렵게 만들 수 있다. 하지만 이러한 유해한 언어를 탐지하기 위한 이전 접근 방식은 Reddit와 Twitter와 같은 온라인 포럼과 소셜 미디어의 대화에 주로 관심을 두었으며, 라이브 스트리밍 플랫폼인 Twitch와 YouTube Live에서의 대화에 적용할 때 효과적이지 않다는 것이다.
    2. 따라서 이 논문에서는 라이브 스트리밍 플랫폼에서의 대화에서의 규범 위반을 탐지하기 위한 최초의 NLP 연구를 제시한다. 우리는 Twitch에서 4,583개의 중재된 댓글을 주석으로 달고 라이브 스트림 채팅에서 규범 위반 범주를 정의한다.
    3. 우리는 이 연구를 통해 사람들이 라이브 스트림 모더레이션에서 사용하는 정보적 문맥을 파악하고, 문맥을 활용하여 규범 위반을 식별하는 모델을 훈련시킨다는 것을 밝혔으며, 결과적으로 적절한 문맥 정보가 모더레이션 성능을 35% 향상시킬 수 있다는 것을 보여준다.

###### Coarse-to-Fine Contrastive Learning in Image-Text-Graph Space for Improved Vision-Language Compositionality (https://aclanthology.org/2023.emnlp-main.56/)
- Anthology ID: 2023.emnlp-main.56 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 비교적 괜찮은 성과를 보였던 Contrastively trained vision-language 모델들이 객체, 속성, 관계에 대한 구성적 추론 능력이 제한되어 있다는 한계점이 최근에 드러나고 있다.
    2. 우리는 이미지에서 파싱된 scene graph를 이미지 scene graph의 프록시로 간주하고, 이미지와 텍스트 간의 거친-정교한 contrastive 학습 목적함수와 함께 다양한 복잡도의 문장을 동일한 이미지에 맞추는 그래프 분해 및 augmentation 프레임워크를 제안한다.
    3. 우리는 어트리뷰트 바인딩과 관계 이해를 향상시키기 위해 scene graph 공간에서의 새로운 negative mining 기법을 도입하였고, 다양한 벤치마크에서 속성 바인딩, 관계 이해, 체계적 일반화, 생산성을 크게 향상시키는 효과적인 접근법을 실험을 통해 입증하였다.

###### Reading Books is Great, But Not if You Are Driving! Visually Grounded Reasoning about Defeasible Commonsense Norms (https://aclanthology.org/2023.emnlp-main.57/)
- Anthology ID: 2023.emnlp-main.57 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 상식적 규범은 맥락에 의해 유연하게 결정된다: 책을 읽는 것은 대부분 좋지만, 운전할 때는 그렇지 않다. 그러나 시각적으로 제공되는 상황에서 이러한 맥락을 해결하는 것은 기계에게는 도전이다.
    2. 이 논문에서는 시각적 이해와 상식적 규범에 대한 추론이 필요하며, 이를 연구하기 위한 NormLens라는 다중 모달 벤치마크를 구축한다.
    3. 특히 우리는 대형 언어 모델로부터 상식적 지식을 추출하여 모델과 인간의 일치도를 높이는 간단하면서도 효과적인 방법을 제시한다.

###### Enhancing Uncertainty-Based Hallucination Detection with Stronger Focus (https://aclanthology.org/2023.emnlp-main.58/)
- Anthology ID: 2023.emnlp-main.58 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델은 다양한 분야에서 놀라운 성능을 보여주어 인기를 끌었지만, 높은 확률로 유사하지 않거나 무의미한 출력을 생성하는 경우가 많다. 
    2. 기존에는 외부 지식을 필요로 하거나 다양한 응답을 샘플링하여 일관성을 검증하는 방법을 사용했지만 비용과 효율성이 문제였다.
    3. 이 논문에서는 언어 모델의 허상 여부를 탐지하기 위해 참조 자료없이 불확실성 기반의 새로운 방법을 제안한다. 실험 결과는 우리의 방법이 모든 평가 메트릭에서 최고 수준의 성능을 달성하고 추가 정보가 필요하지 않도록 한다.

###### FactKB: Generalizable Factuality Evaluation using Language Models Enhanced with Factual Knowledge (https://aclanthology.org/2023.emnlp-main.59/)
- Anthology ID: 2023.emnlp-main.59 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 신뢰할 수 있는 요약 시스템의 진보와 채택을 위해 자동 생성된 요약의 사실적 일치성을 평가하는 것은 필수적이다.
    2. 기존의 사실성 평가 모델은 새로운 도메인에서 entity와 relation 오류에 특히 취약하여 robust하지 않다.
    3. 우리는 외부 지식 베이스에서 추출한 사실을 사용하여 사실성 평가 모델을 사전 훈련시키는 간단하고 일반화 가능한 FactKB 방법을 제안한다.

###### Mitigating Backdoor Poisoning Attacks through the Lens of Spurious Correlation (https://aclanthology.org/2023.emnlp-main.60/)
- Anthology ID: 2023.emnlp-main.60 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 NLP 모델들은 신뢰할 수 없는 대규모 데이터셋으로 훈련되는 경우가 많아 악의적인 공격자가 모델 동작을 손상시킬 수 있는 위험이 존재한다.
    2. 이 논문은 악의적인 공격에 대한 방어 수단으로 spurious correlation을 완화하는 방법을 제안한다.
    3. 실험 결과, 해당 방어 방법은 backdoor 공격의 성공율을 크게 감소시키며 insertion-based 공격의 경우 거의 완벽한 방어를 제공한다.

###### Symbol tuning improves in-context learning in language models (https://aclanthology.org/2023.emnlp-main.61/)
- Anthology ID: 2023.emnlp-main.61 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 심볼 튜닝(symbol tuning)을 소개하는데, 이는 언어 모델을 실제 문장 대신 임의의 심볼로 된 입력-라벨 쌍으로 학습시키는 것이다. 심볼 튜닝은 모델이 지시사항이나 자연어 라벨을 사용하여 작업을 이해할 수 없을 때, 입력-라벨 매핑을 학습하여 작업을 수행하게끔 유도하는 개념을 기반으로 한다. 실험 결과, 심볼 튜닝은 보다 다양한 설정에서 성능을 향상시키며, 알고리즘적 추론 작업에서 뛰어난 결과를 보인다.
    2. 심볼 튜닝은 이전 지식을 무시하고 현재 문맥 정보를 사용하여 라벨을 덮어씌우는 기능이 더욱 강화되어, 입출력간의 관계 매핑에 더 효과적인 방법이다. 
    3. 심볼 튜닝은 보다 다양한 작업에서 성능이 향상되며, 특히 알고리즘적 추론 작업과 더 체계적인 문맥 정확성을 필요로 하는 작업에서 더 높은 성능을 보인다.

###### The neural dynamics of word recognition and integration (https://aclanthology.org/2023.emnlp-main.62/)
- Anthology ID: 2023.emnlp-main.62 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 청중은 다가오는 내용에 대한 기대와 감각적인 증거를 함께 결합하여 빠르고 소음이 있는 일상적인 언어에 있는 단어를 인식한다. 이 연구에서는 Bayesian decision theory로 통계적 가설을 제안하며, scalp EEG 신호를 분석하여 인식과 통합하는 과정과 관련된 뇌 활동의 근본적인 특성을 밝힌다. 
    2. 이 모델은 빠르게 인식되는 단어와 그렇지 않은 단어에 대해 서로 다른 뇌 처리를 보여준다. 
    3. 우리의 결과는 단어 인식과 함께 빠른 과정의 단어 통합을 결합한 말해 듣기 두 가지 모델을 지원하며, 이를 분리하는 데 도움이 될 수 있는 잠재적인 모델링 단계를 토의한다.

###### Tree of Clarifications: Answering Ambiguous Questions with Retrieval-Augmented Large Language Models (https://aclanthology.org/2023.emnlp-main.63/)
- Anthology ID: 2023.emnlp-main.63 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 오픈 도메인 질문 응답에서의 질문은 종종 다의성을 가지며, 여러 가지 해석이 가능하다. 이 논문에서는 Tree of Clarifications (ToC)라는 새로운 프레임워크를 제안하여 다의성을 다루고, 외부 지식을 활용하여 AQ에 대한 트리로 구성된 명료화를 생성하고 이를 통해 긴 형식의 대답을 생성한다.
    2. ToC는 ASQA에서 몇 가지 예상 밖의 상황(few-shot setup)에서 기존 기준선을 앞질러서 Disambig-F1 및 Disambig-ROUGE 측면에서 훈련 세트 전체에 훈련된 완전 지도학습과 비교했을 때 우수한 결과를 보여준다.
    3. 코드는 https://github.com/gankim/tree-of-clarifications에서 제공된다.

###### Incorporating Worker Perspectives into MTurk Annotation Practices for NLP (https://aclanthology.org/2023.emnlp-main.64/)
- Anthology ID: 2023.emnlp-main.64 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 아마존 메카니컬 터크(MTurk)에서의 자연어 처리를 위한 데이터 수집은 데이터 품질에 대한 연구와 NLP 연구자들 사이에서 공유되는 휴리스틱에 의존하는 경우가 많으나, MTurk 작업자들의 시각을 고려하지 않으면 작업자의 권리와 응답 품질과 관련된 문제가 발생할 수 있다. 
    2. MTurk 작업자들에 대한 조사 결과, NLP 연구자들의 지식과 작업자들의 선호 사항이 상충되는 경우가 많았다. 그들은 믿을 수 있고 합리적인 보수에 불확실하고 매우 높은 보수를 선호하는 추세이며, 인구 통계 질문에 흔히 거짓으로 대답하고 작업이 거부되는 것에 분노를 표했다. 
    3. 이러한 결과를 바탕으로 우리는 향후 NLP 연구에서 MTurk 작업자들의 경험을 고려하여 작업자의 권리를 존중하고 데이터 품질을 개선할 수 있는 방안을 제시한다.

###### Predict the Future from the Past? On the Temporal Data Distribution Shift in Financial Sentiment Classifications (https://aclanthology.org/2023.emnlp-main.65/)
- Anthology ID: 2023.emnlp-main.65 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 금융 텍스트의 시간적 데이터 분포 변동은 일반적으로 흐름 (prevalent) 하다. 금융 감성 분석 시스템은 어떻게 변화하는 데이터 분포에 강건하면서도 정확한 감성을 추론할 수 있는 변동성 있는 시장 환경에서 훈련되어야 하는가?
    2. 이 논문에서는 세년간의 실제 금융 소셜 미디어 데이터셋을 사용하여 시간적 데이터 분포 변동에서의 금융 감성 분석 시스템에 대한 실험을 수행한다. 그 결과, fine-tuned 모델은 시간적 분포 변동이 발생할 때 일반적인 성능 저하를 겪는다.
    3. 이러한 문제에 대응하기 위해 본 논문에서는 금융 텍스트의 독특한 시간적 특성에 영감을 받아 분포 탐지와 시계열 모델링을 결합한 새로운 방법을 제안한다. 실험 결과는 제안된 방법이 변동성 있는 금융 시장에서 진화하는 시간적 변화에 적응하는 모델의 능력을 향상시킨다는 것을 보여준다.

###### Look-back Decoding for Open-Ended Text Generation (https://aclanthology.org/2023.emnlp-main.66/)
- Anthology ID: 2023.emnlp-main.66 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 단순히 문맥을 따라가는 것이 아닌, 일관성 있는 언어 생성을 위해 확장된 디코딩 알고리즘인 Look-back을 제안한다.
    2. Look-back은 현재와 이전 디코딩 단계의 분포 차이를 추적하여 중복된 구문과 주제의 변화를 예측하고 제거함으로써 더 유창하고 일관성 있는 텍스트를 생성할 수 있다.
    3. 문서 연속성과 이야기 생성에서의 디코딩 실험을 수행하여, Look-back이 다른 강력한 디코딩 방법들을 능가하는 결과를 얻었다.

###### Large Language Models Can Self-Improve (https://aclanthology.org/2023.emnlp-main.67/)
- Anthology ID: 2023.emnlp-main.67 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델 (LLMs)은 다양한 작업에서 우수한 성능을 달성했지만, LLM의 fine-tuning은 광범위한 지도를 필요로 한다. 
    2. 하지만 사람들은 외부 입력 없이 자체적 thinking 으로 추론 능력을 향상시킬 수 있다. 
    3. 본 논문에서는 미리 학습된 LLM을 사용하여 라벨이 없는 질문에 대한 "높은 확신"이 있는 rationale-augmented 답변을 생성하고, 이를 대상 출력 값으로 사용하여 LLM을 fine-tuning하는 방법을 제안한다.

###### CodeT5+: Open Code Large Language Models for Code Understanding and Generation (https://aclanthology.org/2023.emnlp-main.68/)
- Anthology ID: 2023.emnlp-main.68 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델(Large language models, LLMs)은 코드 지능(Code intelligence) 분야에서 두 가지 주요 한계를 가지고 있다. 첫째, 특정 아키텍처(encoder-only 또는 decoder-only)를 채택하거나 다양한 downstream 작업에 효율적인 아키텍처에 적용할 수 있는 융통성이 부족하다. 둘째, 몇몇 작업에 관련이 없을 수 있는 제한된 사전학습 목적을 사용하고 있어 성능 저하를 유발한다.
    2. 이 논문에서는 다양한 코드 작업에 적합하도록 유연하게 조합할 수 있는, encoder-decoder 구조의 LLM인 "CodeT5+"를 제안한다. 이 작업들을 위한 사전 학습 목표의 혼합을 제안하며, 이는 span denoising, contrastive learning, text-code matching, causal LM pretraining 작업을 다양한 단일 및 다중 언어 코드 코퍼스에서 수행한다.
    3. 우리는 CodeT5+를 처음부터 학습시키지 않고 사전에 학습된 LLM으로 초기화하고, 자연어 지시사항과 조화를 이루기 위해 instruction-tuning을 탐구한다. 우리는 zero-shot, finetuning, instruction-tuning을 포함한 다양한 설정에서 CodeT5+를 20개 이상의 코드 관련 벤치마크에서 평가하였고, 다양한 코드 관련 작업에서 최첨단 성능을 보였다. 특히 instruction-tuned CodeT5+ 16B는 다른 오픈 소스 코드 LLMs와 비교하여 HumanEval 코드 생성 작업에서 35.0% pass@1 및 54.5% pass@10의 최첨단 결과를 달성하여 OpenAI code-cushman-001 모델을 능가하였다.

###### Structural generalization in COGS: Supertagging is (almost) all you need (https://aclanthology.org/2023.emnlp-main.69/)
- Anthology ID: 2023.emnlp-main.69 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어처리(Natural Language Processing) 응용 프로그램에서 신경망(neural network)은 OOD(out-of-distribution) 예제에 대한 일반화에 실패한다고 알려져 있다. 특히 최근의 의미 분석 데이터셋에서는 신경망의 구성적 적용이 필요한 경우에 대한 제한 사항을 제기하고 있다. 
    2. 본 논문에서는 본래 그래프 기반 파싱 프레임워크(neural graph-based parsing framework)를 여러 가지 방법으로 확장하여 이 문제를 완화한다. 
    3. 실험적으로, 우리의 접근 방식은 구성적 적용에 대한 알려진 어려운 COGS 데이터셋에서 구조적 합성에 필요한 예제의 결과를 크게 향상시킨다.

###### BioT5: Enriching Cross-modal Integration in Biology with Chemical Knowledge and Natural Language Associations (https://aclanthology.org/2023.emnlp-main.70/)
- Anthology ID: 2023.emnlp-main.70 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 생물학 연구에서는 분자, 단백질, 자연어의 통합을 통해 약물 개발을 향상시키고 있는데, 문제는 유효하지 않은 SMILES 표현을 생성하고, 문맥 정보를 제대로 활용하지 않으며, 구조화되지 않은 지식과 구조화된 지식을 동일하게 처리한다는 것이다. 
    2. 따라서 이 논문에서는 BioT5라는 종합적인 사전학습 프레임워크를 제안하여, 화학 지식과 자연어 연관성을 통한 생물학의 교차 모달 통합을 강화한다. 
    3. BioT5는 SELFIES를 사용하여 100% 강력한 분자 표현을 만들고, 구조화되지 않은 생물학적 문헌의 문맥에서 생물 개체의 지식을 추출한다. 또한, BioT5는 구조화된 지식과 구조화되지 않은 지식을 구분하여 정보를 더 효과적으로 활용한다. 이후 fine-tuning을 통해 BioT5는 다양한 작업에서 우수한 성능을 보이며, 생물 개체의 내재된 관계와 속성을 잘 포착한다는 것을 보여준다.

###### Hyperpolyglot LLMs: Cross-Lingual Interpretability in Token Embeddings (https://aclanthology.org/2023.emnlp-main.71/)
- Anthology ID: 2023.emnlp-main.71 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다국어 대형 언어 모델 (LLM)의 교양적 전달 학습은 매우 중요한 성질이다. 하지만 LLM은 언어 간의 관계를 어떻게 표현하는가? 입력 임베딩 간의 유사성은 해석 가능하며, 이 임베딩의 기하학은 모델 패밀리에 따라 다르다.
    2. 한 모델 (XLM-RoBERTa)은 임베딩에서 언어를 인코딩하고, 서로 다른 문자체계의 토큰을 99.2%의 정확도로 선형 분리할 수 있다.
    3. 다른 모델 패밀리 (mT5)는 교차 언어 의미 유사성을 나타내며, 어떤 토큰에 대해 50개의 가장 근접한 이웃은 평균적으로 7.61개의 문자체계로 나타나며, 자주 번역어들이다. 이 결과들은 명확한 평행 교차 언어 학습 및 사전 훈련 목적에 동기부여가 없음에도 불구하고 놀라운 결과이다.

###### Target-oriented Proactive Dialogue Systems with Personalization: Problem Formulation and Dataset Curation (https://aclanthology.org/2023.emnlp-main.72/)
- Anthology ID: 2023.emnlp-main.72 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "대화 목표를 사전에 정의하거나 특정 시스템 목표를 달성하기 위해 대화를 미리 조정하는 대상 지향적 대화 시스템은 대화형 AI 분야에서 흥미로운 영역이다."
    2. "본 논문은 <대화 행위, 주제> 쌍을 대화 목표로 고려하여 개인 맞춤형 대상 지향적 대화의 새로운 문제를 탐구한다. "
    3. "이를 위해, 우리는 역할 모델링 접근법을 사용하여 자동 데이터셋 조립 프레임워크를 제안하고, 이 프레임워크를 기반으로 대규모 개인맞춤형 대상 지향 대화 데이터셋인 TopDial을 구축했다."

###### SeqXGPT: Sentence-Level AI-Generated Text Detection (https://aclanthology.org/2023.emnlp-main.73/)
- Anthology ID: 2023.emnlp-main.73 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델(Large Language Models, LLMs)은 인간과 유사한 내용을 생성할 수 있기 때문에 LLM의 남용에 대한 우려가 제기되고 있다. 그러므로 강력한 AI 생성 텍스트(AIGT) 감지기를 구축하는 것이 중요하다.
    2. 이 논문에서는 현재의 연구들이 문서 수준의 AIGT 감지만을 고려하고 있으며, 그래서 문장 수준의 감지 도전을 소개한다.
    3. Sequence X (Check) GPT라는 새로운 방법을 제안하며, 이 방법은 백박스 LLMs로부터의 로그 확률 목록을 sentence-level AIGT 감지의 특성으로 활용한다. 이 특성은 음성 처리에서 파동과 같이 구성되며, LLMs로 연구하기 어렵다. 따라서 저자들은 SeqXGPT를 컨볼루션과 self-attention 네트워크를 기반으로 구축하였다. 실험 결과는 이전의 방법들이 문장 수준의 AIGT 감지를 해결하는데 어려움이 있음을 보여주고, 저자들의 방법은 문장 및 문서 수준의 감지 도전에서 기준선 방법을 크게 능가할 뿐만 아니라 강한 일반화 능력을 보여준다.

###### QTSumm: Query-Focused Summarization over Tabular Data (https://aclanthology.org/2023.emnlp-main.74/)
- Anthology ID: 2023.emnlp-main.74 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사람들은 데이터 분석이나 특정 질문에 답하기 위해 주로 테이블을 참고한다. 사용자의 정보 요구에 맞는 정확한 테이블 요약을 제공할 수 있는 텍스트 생성 시스템은 관련 데이터 인사이트에 대한 효율적인 접근을 용이하게 할 수 있다. 이를 바탕으로 우리는 쿼리 중심 테이블 요약 작업을 정의하고, 주어진 테이블을 기반으로 인간과 유사한 추론과 분석을 수행하여 맞춤형 요약을 생성하는 텍스트 생성 모델을 개발하였다.
    2. 우리는 이 작업을 위해 QTSumm이라는 새로운 벤치마크를 소개한다. 이 데이터셋은 다양한 주제를 다루는 2,934개의 테이블에 대한 7,111개의 인간 주석된 쿼리-요약 쌍으로 구성되어 있다. 우리는 텍스트 생성, 테이블-텍스트 생성 및 대규모 언어 모델 등의 강력한 기준선 모델들을 QTSumm에서 실험하였다.
    3. 실험 결과와 수동 분석은 이 새로운 작업이 향후 연구에서 테이블-텍스트 생성에서 상당한 도전을 제시한다는 것을 보여주었다. 또한, 우리는 ReFactor라는 새로운 접근법을 제안하여 쿼리와 관련된 정보를 테이블 데이터에서 검색하고 추론하여 여러 자연어 사실을 생성한다. 실험 결과는 ReFactor가 모델 입력에 생성된 사실을 연결함으로써 기준선을 효과적으로 개선할 수 있음을 보여준다.

###### From Wrong To Right: A Recursive Approach Towards Vision-Language Explanation (https://aclanthology.org/2023.emnlp-main.75/)
- Anthology ID: 2023.emnlp-main.75 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 제한적으로 주어진 주석으로 시각-언어 모델을 적응시키기 위해 Insightful Explanation 생성에 대한 Recursive Visual Explanation 알고리즘인 ReVisE를 제안한다.
    2. 이 알고리즘은 다중 단계 접근법으로, 답변이 수렴할 때까지 차례로 시각적 특징, 답변 및 설명을 계산하여 설명 품질을 단계적으로 향상시킨다.
    3. ReVisE에 의해 생성된 설명은 몇 가지 셀프-트레이닝에 유용한 주석으로 활용되며, 이 방법은 사람 주석의 5%만을 사용하면서 이전 방법보다 뛰어난 성능을 발휘한다.

###### ‘Don’t Get Too Technical with Me’: A Discourse Structure-Based Framework for Automatic Science Journalism (https://aclanthology.org/2023.emnlp-main.76/)
- Anthology ID: 2023.emnlp-main.76 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자동 과학 저널리즘(automatic science journalism)을 지원하기 위해, 실제 세계의 과학 논문을 일반 대중에게 보다 적절한 뉴스 기사로 리포팅하는 자동 시스템을 설계하는 것이 목표이다.
    2. 새롭게 구축된 실제 데이터셋 (SciTechNews)을 소개하며, 해당 데이터셋의 논문, 해당 뉴스 기사, 전문가가 작성한 간단한 요약 스니펫의 튜플을 제공한다.
    3. 우리의 모델이 대상 독자를 위한 의미 있는 콘텐츠 계획을 상세히 설명하고, 선택한 정보를 단순화하며, 일관된 최종 보고서를 일반인 스타일로 생성하는 데 있어서 기존 baseline 방법 (예: Alpaca와 ChatGPT)보다 더 뛰어난 성능을 보인다는 폭넓은 자동 및 인간 실험을 통해 이를 증명한다.

###### LACMA: Language-Aligning Contrastive Learning with Meta-Actions for Embodied Instruction Following (https://aclanthology.org/2023.emnlp-main.77/)
- Anthology ID: 2023.emnlp-main.77 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "End-to-end Transformers는 훈련 데이터에서는 목표 환경을 본 바 있는 경우에는 근거 있는 지시 따르기에서 높은 성공률을 보여주었으나," 미처 보지 못한 환경에서는 어려움을 겪는다.
    2. 이러한 일반화의 부족은 에이전트가 자연어 지시에서의 미묘한 변화에 둔감하기 때문이다.
    3. 우리는 대조 학습을 통해 에이전트의 숨겨진 상태와 지시문을 명시적으로 맞추는 것을 제안하고, 고위 수준의 메타 액션을 도입하여 관련성을 강화함으로써, 에이전트가 미처 보지 못한 환경에서 일반화하는 것을 돕는다.

###### Penalty Decoding: Well Suppress the Self-Reinforcement Effect in Open-Ended Text Generation (https://aclanthology.org/2023.emnlp-main.78/)
- Anthology ID: 2023.emnlp-main.78 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 본 논문은 텍스트 생성에서 latent representations을 의미 있는 문장으로 변환하는 디코딩 알고리즘의 효과에 대해 연구한다.
    2. 또한, 디코딩 중 반복 페널티(repetition penalty)의 효과를 알기 위해 연구하였다.
    3. 실제사례를 통한 실험결과는 세 가지 전략을 적용한 이 방안이 인간의 출력과 유사한 고품질의 문장 생성을 돕는다는 것을 입증한다.

###### Towards Robust Pruning: An Adaptive Knowledge-Retention Pruning Strategy for Language Models (https://aclanthology.org/2023.emnlp-main.79/)
- Anthology ID: 2023.emnlp-main.79 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 잘 훈련된 모델들은 정확성과 희소성 뿐만 아니라 강인성에 대한 가지는 목표를 가지고 있다. 하지만 기존 방법들은 모델의 희소성을 지속적으로 증가시키면서 적대적 공격에 대한 강인성을 향상시키는 것에 어려움을 겪으며 재훈련 과정이 필요하다.
    2. 이 논문에서는 언어 모델의 강건성은 사전에 학습된 지식의 범위에 비례한다고 주장한다. 따라서 저자들은 밀집 언어 모델의 임베딩 공간과 피처 공간을 충실히 복제하는 사후 훈련 가지치기 전략을 제안하여 가지치기 과정에서 더 많은 사전 학습 지식을 보존하도록 한다.
    3. 실험 결과, 저자들의 방법은 BERT 모델에 대해 SST2, IMDB, AGNews 데이터셋에서 정확성, 희소성, 강인성, 가지치기 비용의 균형을 더 잘 잡아내는 것으로 나타났다. 이는 언어 모델에서 강인 가지치기에 대한 중요한 발전을 의미한다.

###### Clinical Contradiction Detection (https://aclanthology.org/2023.emnlp-main.80/)
- Anthology ID: 2023.emnlp-main.80 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 문장의 모순을 탐지하는 것은 문헌의 타당성과 소비하는 정보의 중요한 요소이다. 의료 문헌은 모순된 진술로 가득 차 있다. 
    2. 의료 도메인에서 모순을 탐지하는 것은 임상 전문 지식이 필요하기 때문에 어렵다고 알려져 있다. 
    3. 본 논문에서는 의료 온톨로지를 활용하여 잠재적 의료 모순의 시드를 구축하는 '원격 지도' 방법을 제안한다.

###### Vera: A General-Purpose Plausibility Estimation Model for Commonsense Statements (https://aclanthology.org/2023.emnlp-main.81/)
- Anthology ID: 2023.emnlp-main.81 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 언어 모델은 지적인 면에서 뛰어날 수 있지만 일상적인 상식 오류를 포함한 텍스트를 생성하기도 한다. 이를 위해 본 논문에서는 기계 텍스트의 상식적 타당성을 평가할 수 있는 후방 검증(retrospective verification) 접근 방법을 제안한다.
    2. Vera라는 일반적인 모델을 소개하며, 이 모델은 진술문의 상식적 타당성을 추정하는 것을 학습한다. Vera는 19개의 QA 데이터셋과 두 개의 상식 지식 베이스에서 자동으로 변환된 약 7백만 개의 상식적 진술문을 사용하여 다양한 상식 도메인을 지원한다.
    3. Vera는 검증 형식의 상식 문제 해결에 적용되면, GPT-3.5/ChatGPT/GPT-4를 비롯한 기존 모델들보다 훨씬 우수한 성능을 보이며, 보다 효과적인 일반화 능력과 잘 조정된 결과를 제공한다. Vera는 기계가 생성한 상식적 지식을 걸러내는 데 능숙하며, ChatGPT와 같은 모델에서 생성된 잘못된 상식적 진술문을 실제 환경에서 탐지하는 데 유용하다.

###### Text-Transport: Toward Learning Causal Effects of Natural Language (https://aclanthology.org/2023.emnlp-main.82/)
- Anthology ID: 2023.emnlp-main.82 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어 기술이 실제 환경에서 중요해짐에 따라, 언어의 변화가 독자의 인식에 어떤 영향을 주는지 이해하는 것이 중요하다.
    2. 이 논문에서는 텍스트 분포 하의 자연어로부터 인과효과를 추정하기 위한 Text-Transport 방법을 제안한다.
    3. Text-Transport를 사용하여 혐오 발언과 같은 현실적인 상황에서 인과 추론을 수행할 때 텍스트 도메인 간 인과효과가 크게 변하는 것을 보여주며 강력한 방법임을 입증한다.

###### How Does Generative Retrieval Scale to Millions of Passages? (https://aclanthology.org/2023.emnlp-main.83/)
- Anthology ID: 2023.emnlp-main.83 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기 존의 정보 검색 문제를 sequence-to-sequence 모델링 작업으로 바꾸어 전체 문서 코퍼스를 하나의 Transformer로 인코딩하는 generative retrieval의 신기한 패러다임이 등장하였다.
    2. 이 논문은 100K 정도의 규모의 문서 코퍼스에서 generative retrieval 기술을 개선하기 위한 다양한 접근 방식을 평가한 첫 번째 연구이다.
    3. 연구 결과로는 검색 성능과 관련하여 synthetic query를 문서 표현으로 사용하는 것의 중요성, 연산 비용을 고려할 때 기존의 구조 수정 제안의 비효율성, 그리고 모델 파라미터 스케일링의 한계 등을 발견하였다.

###### Unveiling the Implicit Toxicity in Large Language Models (https://aclanthology.org/2023.emnlp-main.84/)
- Anthology ID: 2023.emnlp-main.84 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델(LLM)의 개방성과 놀라운 기능들은 악용될 경우 새로운 안전 문제를 일으킬 수 있다. 
    2. 기존 연구들은 주로 기존 독성 분류기로 감지하기 쉬운 독성 결과를 조사하는데 초점을 맞추었지만, 우리는 LLM이 간단한 zero-shot prompting으로 감지하기 어려운 다양한 암시적인 독성 결과를 생성할 수 있다고 보여준다.
    3. 또한, 우리는 강화학습(Reinforcement Learning, RL) 기반의 공격 방법을 제안하여 LLM에서 암시적인 독성을 유발한다. 실험 결과, RL fine-tuning을 통해 공격 성공률을 크게 향상시킬 수 있다는 것을 보여준다.

###### Is ChatGPT a General-Purpose Natural Language Processing Task Solver? (https://aclanthology.org/2023.emnlp-main.85/)
- Anthology ID: 2023.emnlp-main.85 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델 (LLM)의 발전으로 인해, LLM은 downstream 데이터에 대한 적응 없이도 다양한 자연어 처리 (NLP) 작업을 zero-shot으로 수행할 수 있는 능력을 보였다. 
    2. 이 논문에서는 ChatGPT의 zero-shot 학습 능력을 20개의 인기 있는 NLP 데이터셋에서 평가함으로써 현재 버전의 ChatGPT의 효과성과 한계를 실험적으로 분석한다.
    3. ChatGPT는 추론 능력을 필요로 하는 많은 작업에서 잘 수행되지만, 시퀀스 태깅과 같은 특정 작업에서는 여전히 도전을 겪는다는 결론을 찾아냈다.

###### Length is a Curse and a Blessing for Document-level Semantics (https://aclanthology.org/2023.emnlp-main.86/)
- Anthology ID: 2023.emnlp-main.86 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에는 contrastive learning (CL)이 이전의 언어 모델을 기반으로 문장과 문서 수준의 인코딩 능력을 복구하는 데에 널리 사용되고 있습니다. 그러나 이 논문에서는 CL을 기반으로 하는 모델의 길이 일반화 능력에 대해 의문을 제기하며, 텍스트의 길이에 의한 의미 변화에 취약하다는 것을 확인하였습니다.
    2. 저희는 길이 공격에 대한 이론적 기반을 유도하였고, 문서의 길이를 늘리는 것이 이미 CL에서 가져온 높은 문서 내 유사성을 강화시킬 것이라는 것을 보였습니다. 또한, CL이 제공하는 등방성(isotropy)도 훈련 중 노출된 텍스트의 길이 범위에 크게 의존한다는 것을 발견했습니다.
    3. 이러한 연구 결과에 영감을 받아, 저희는 간단하면서도 범용적인 문서 표현 학습 프레임워크인 LA(SER)3를 소개하였습니다. 이 모델은 세마틱으로 강건한 문장 표현 학습을 위한 길이에 무관한 자기 참조(length-agnostic self-reference) 방법을 사용하며, 표준 정보 검색 벤치마크에서 최고 성능을 달성했습니다.

###### ALCUNA: Large Language Models Meet New Knowledge (https://aclanthology.org/2023.emnlp-main.87/)
- Anthology ID: 2023.emnlp-main.87 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. NLP의 발달로 대규모 언어 모델 (LLM)들이 다양한 도메인에서 여러 가지 작업을 뛰어넘는 성능을 보이고 있는데, 기존 벤치마크들은 특히 새로운 지식을 다룰 때 이러한 모델의 역량을 충분히 측정하지 못할 수 있다.
    2. 이 논문에서는 빠르게 진화하는 세계에서 중요하면서도 어려운 새로운 지식을 처리하는 LLM의 능력을 평가하기 위한 벤치마크의 부재를 다룬다.
    3. 우리는 기존의 개체 속성과 관계를 조작하여 새로운 지식을 생성하는 KnowGen이라는 접근법을 제안하고, 이를 통해 LLM의 지식 이해, 구별, 연관성을 평가하기 위한 ALCUNA라는 벤치마크를 도입한다.

###### Location-Aware Visual Question Generation with Lightweight Models (https://aclanthology.org/2023.emnlp-main.88/)
- Anthology ID: 2023.emnlp-main.88 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "이 연구는 특정 지리적 위치와 관련된 데이터로부터 매력적인 질문을 생성하는 새로운 작업인 위치 인식 시각적 질문 생성(LocaVQG)을 소개한다. 구체적으로, 우리는 주변 이미지와 GPS 좌표로 이러한 위치 인식 정보를 표현한다. 이 작업에 대처하기 위해, 우리는 GPT-4를 활용하여 다양하고 복잡한 질문을 생성하기 위한 데이터셋 생성 파이프라인을 제시한다."
    2. "그런 다음, 휴대 전화와 같은 엣지 장치에 맞는 경량 모델을 학습할 수 있는 방법을 제안한다. 이를 위해, 위치 인식 정보로부터 매력적인 질문을 신뢰성 있게 생성할 수 있는 방법을 제안한다. 우리의 제안된 방법은 인간 평가(참여도, 연결성, 일관성) 및 자동 평가 메트릭(BERTScore, ROUGE-2)에서 기준 모델보다 우수한 성능을 보여준다."
    3. "또한, 데이터셋 생성과 작업 해결을 위한 우리의 제안된 기술을 정당화하기 위해 포괄적인 태색 연구를 수행한다."

###### MemeCap: A Dataset for Captioning and Interpreting Memes (https://aclanthology.org/2023.emnlp-main.89/)
- Anthology ID: 2023.emnlp-main.89 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "MemesCap" 데이터셋은 웹 사용자가 시각적 인쇄표현을 사용하여 자신의 생각을 표현하는 데에 폭넓게 사용되는 도구이다.
    2. 최근의 비젼-언어(VL) 모델들은 이미지 캡셔닝, 시각적 질문 답변 과제에서도 성공을 거두었지만, MemeCap 데이터셋에서 시각적 인쇄표현에 여전히 어려움을 겪고 있으며, 사람보다 훨씬 성능이 떨어진다.
    3. 우리는 시각적 인쇄표현을 이해하기 위해 면밀한 실험을 진행하였고, 최신 VL 모델을 사용하여 모델이 visual metaphors을 해석하는 데에 어려움을 겪는 점을 확인하였다.

###### Where to start? Analyzing the potential value of intermediate models (https://aclanthology.org/2023.emnlp-main.90/)
- Anthology ID: 2023.emnlp-main.90 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 연구에서 성급하게 훈련된 모델(finetuned models)이 vanillar pretrained model보다 더 좋은 기반 모델(base model)일 수 있다는 것을 관찰했다.
    2. 우리는 이러한 intertraining 방식을 다양한 영어 분류 작업에 대해 체계적으로 분석했고, 결과적으로 대상 데이터셋과 시작점으로 삼을 기반 모델에 대해 독립적으로 평가할 수 있는 잠재적인 이득이 있다는 것을 알았다.
    3. 또한, 우리의 분석을 기반으로 실제 환경에서 어떤 기반 모델을 선택할지 결정하는 것에 대한 실용적이고 효율적인 접근 방식을 제안한다.

###### Transcending Scaling Laws with 0.1% Extra Compute (https://aclanthology.org/2023.emnlp-main.91/)
- Anthology ID: 2023.emnlp-main.91 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어 모델의 성능을 향상시키는 것은 컴퓨팅 비용이 많이 들지만, 이 논문에서 제안되는 UL2R은 상대적으로 작은 양의 추가 연산으로 기존 언어 모델과 스케일링 곡선을 크게 개선한다.
    2. 우리는 UL2의 mixture-of-denoiser 목적을 사용하여 최신 대형 언어 모델을 몇 단계 더 학습하는 방식인 UL2R을 제안하였고, 거의 소량의 추가 연산 비용과 새로운 데이터 소스 없이 큰 언어 모델의 스케일링 특성을 향상시킬 수 있음을 보여준다.
    3. U-PaLM이라고 불리는 8B, 62B, 540B의 규모의 새로운 모델들을 도입하여, UL2R로 기준이 되는 언어 모델인 PaLM을 계속 학습시켰으며, 540B의 스케일에서 타겟 모델의 성능과 비슷한 성능을 달성하면서 약간의 연산 비용을 절약하는 것을 보였다.

###### CoAnnotating: Uncertainty-Guided Work Allocation between Human and Large Language Models for Data Annotation (https://aclanthology.org/2023.emnlp-main.92/)
- Anthology ID: 2023.emnlp-main.92 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에 큰 언어 모델들이 발전함에 따라, ChatGPT와 같은 모델들은 많은 텍스트 주석 작업에서 유사했거나 심지어 인간 주석자를 능가하는 zero-shot 능력을 보여주고 있다.
    2. 이 논문은 인간과 언어 모델 사이에 주석 작업을 어떻게 분배하여 품질과 비용 목표를 동시에 달성할 수 있는지에 대해 연구한다.
    3. CoAnnotating이라는 새로운 패러다임을 제안하여 uncertainty를 활용하여 LLM의 주석 능력을 추정한다.

###### Optimizing Retrieval-augmented Reader Models via Token Elimination (https://aclanthology.org/2023.emnlp-main.93/)
- Anthology ID: 2023.emnlp-main.93 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Fusion-in-Decoder(FiD)는 질문 답변, 사실 확인과 같은 여러 open-domain 태스크에 효과적으로 사용되는 retrieval-augmented 언어 모델이다. 그러나 FiD에서는 먼저 검색된 passage들을 generative 모델(Reader)을 통해 처리하는데, 특히 긴 출력일 경우 디코딩 시간이 매우 지연될 수 있다. 
    2. 본 논문에서는 모든 검색된 passage들이 Reader 모델의 성능에 어떤 기여를 하는지 분석하고, 답변 생성 과정에 있어서 필수적인 정보를 제공하지 않을 수 있는 토큰 레벨에서 일부 검색 정보를 제거하는 방법을 제안한다.
    3. 실험 결과로, 우리의 방법은 성능 저하가 2%로 제한되며, 실행 시간을 최대 62.2%까지 줄일 수 있으며, 경우에 따라서는 성능을 향상시킬 수 있다는 것을 보여준다.

###### WSDMS: Debunk Fake News via Weakly Supervised Detection of Misinforming Sentences with Contextualized Social Wisdom (https://aclanthology.org/2023.emnlp-main.94/)
- Anthology ID: 2023.emnlp-main.94 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 가짜 뉴스 검출 방법들은 뉴스 기사의 진실성을 판단하는 데 초점을 맞추고 있어서 가짜 뉴스가 진실과 거짓의 요소를 혼합한 경우에 대해서는 과소 간주된다.
    2. 따라서 이 연구에서는 가짜 뉴스에 포함된 문장 수준의 오진에 대한 탐지를 다루는 새로운 과제를 조사한다. 
    3. "Weakly Supervised Detection of Misinforming Sentences (WSDMS)"라는 모델을 제안하여 문장 수준의 오진과 기사 수준의 진실성을 추론하는 데에 유용한 모델을 개발한다.

###### Robust Prompt Optimization for Large Language Models Against Distribution Shifts (https://aclanthology.org/2023.emnlp-main.95/)
- Anthology ID: 2023.emnlp-main.95 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델(Large Language Model, LLM)은 다양한 자연어 처리 작업에서 높은 성능을 보여주지만, 작업 프롬프트의 구문에 따라서 성능이 크게 달라질 수 있어서 레이블된 작업 데이터를 사용한 자동 프롬프트 최적화에 대한 연구가 진행되고 있다.
    2. 그러나 이러한 프롬프트 최적화 기술은 실제 상황에서 발생하는 하위집단 분포 변화와 같은 분포 변화에 취약하다는 것을 알 수 있다. 이러한 문제에 대응하기 위해 우리는 LLM에 대한 강건한 프롬프트 최적화 문제를 제안하였는데, 이는 레이블된 소스 그룹으로 최적화된 프롬프트가 동시에 레이블되지 않은 타겟 그룹에도 적용될 수 있는 능력을 요구한다.
    3. 이를 해결하기 위해 우리는 타겟 그룹의 레이블되지 않은 데이터를 프롬프트 최적화에 통합하는 Generalized Prompt Optimization (GPO) 프레임워크를 제안한다. 실험 결과, 이러한 프레임워크가 타겟 그룹에서 상당한 성능 향상을 보여주고 소스 그룹에서도 비슷한 성능을 보인다.

###### Exploiting Asymmetry for Synthetic Training Data Generation: SynthIE and the Case of Information Extraction (https://aclanthology.org/2023.emnlp-main.96/)
- Anthology ID: 2023.emnlp-main.96 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델(Large language models, LLMs)은 구조화된 출력 문제에 대해서도 역방향으로 작동하도록 유도하여, 복잡한 작업을 위한 대규모이고 고품질의 데이터를 생성할 수 있다는 것을 보여줍니다.
    2. 이 논문은 정보 추출을 위한 데이터셋 생성의 어려움을 극복하기 위해 LLM을 사용하여 합성 데이터를 생성하는 방법을 설명합니다.
    3. 합성된 데이터는 사람들에 의해 평가되어 기존 데이터셋보다 우수한 품질을 가지며, 다른 작은 모델들을 세밀하게 조정하여 기존 최고 성과와 큰 차이로 이길 수 있음을 보여줍니다.

###### Condensing Multilingual Knowledge with Lightweight Language-Specific Modules (https://aclanthology.org/2023.emnlp-main.97/)
- Anthology ID: 2023.emnlp-main.97 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어별 모듈이나 Mixture-of-Experts (MoE)를 사용하는 것은 멀티링귀스 모델 성능을 향상시키는 입증된 방법이나, 수백 개의 언어나 전문가를 다루는 것은 관리하기 어렵다.
    2. 우리는 이러한 문제를 해결하기 위해 Language-specific Matrix Synthesis (LMS)라는 새로운 방법을 제안한다. 
    3. LMS는 매개변수를 효율적으로 사용하고 가벼운 모듈을 사용하여 기존 방법보다 우수한 성능을 보이며, 멀티링귀지 번역에서 Switch Transformer보다 +1.73 BLEU를 달성한다. 또한, 우리는 Fuse Distillation (FD)를 도입하여 여러 언어별 모듈에서 멀티링귀지 지식을 한 개의 공유 모듈로 압축하여 모델 추론 및 저장 효율성을 향상시킨다.

###### The Framework Tax: Disparities Between Inference Efficiency in NLP Research and Deployment (https://aclanthology.org/2023.emnlp-main.98/)
- Anthology ID: 2023.emnlp-main.98 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 처리 시스템의 계산 효율성에 대한 관심이 증가함에 따라 효율적인 모델 아키텍처와 하드웨어 가속기 개선이 이뤄졌으나, 이로 인해 계산 처리량이 증가하고 부동 소수점 연산이 감소한 결과가 실제로 벽시계 추론 지연 시간에 직접적인 향상으로 이어지지 않는다는 것을 보여준다.
    2. 이 불일치는 딥러닝 프레임워크에 의해 도입된 병목 현상으로 설명될 수 있으며, 하드웨어의 속도가 시간이 흐름에 따라 증가함에 따라 불일치가 더 커지는 것을 관찰할 수 있다.
    3. 이 논문에서는 모델 디자인 결정, 프레임워크 패러다임, 하드웨어 플랫폼이 총 모델 지연 시간에 미치는 영향을 분석하는 일련의 사례 연구를 통해 이 현상을 검토한다. 그리고 이러한 연구 결과를 바탕으로 효율적인 NLP 모델 연구와 실제 적용 사이의 격차를 좁히기 위한 조치 가능한 권고사항을 제공한다.

###### Evaluating Cross-Domain Text-to-SQL Models and Benchmarks (https://aclanthology.org/2023.emnlp-main.99/)
- Anthology ID: 2023.emnlp-main.99 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Text-to-SQL 벤치마크에서 모델이 생성한 SQL 쿼리와 벤치마크의 참조 SQL 쿼리를 정확하게 일치시키는 것은 여러 이유로 실패할 수 있다. 이 논문에서는 여러 프로미넌트한 텍스트-투-SQL 벤치마크를 연구하고, 수동으로 SQL 쿼리를 평가하고 동등한 표현으로 재작성하여 성능을 재평가한다.
    2. 이 연구에서는 벤치마크에서 제공되는 샘플에서 파생될 수 있는 여러 해석 때문에 이 벤치마크에 대한 완벽한 성능 달성은 어렵다는 사실을 발견하였다. 
    3. 가장 놀라운 발견으로 GPT4 기반 모델이 Spider 벤치마크에서 골드 스탠더드 참조 쿼리를 능가했다는 사실을 발견하였다. 이 결과는 벤치마크 평가를 조심스럽게 해석하고 동시에 독립된 추가 평가의 중요성을 인정하는 것의 중요성을 강조한다.

###### Increasing Coverage and Precision of Textual Information in Multilingual Knowledge Graphs (https://aclanthology.org/2023.emnlp-main.100/)
- Anthology ID: 2023.emnlp-main.100 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어처리와 컴퓨터 비전분야에서는 지식 그래프 안에 있는 텍스트 정보인 entity 이름과 설명을 활용하여 고품질의 구조화된 데이터에 neural model을 적용하는 연구가 진행되어왔으나, 비영어 언어에서는 텍스트 정보의 양과 품질이 부족하다. 
    2. 이 논문은 영어와 비영어 언어 간의 텍스트 정보의 양과 품질의 격차를 줄이기 위해 자동 지식 그래프 완성(KGE)이라는 새로운 과제를 제안한다. 
    3. M-NTA라는 새로운 비지도 학습 방법을 제시하여 높은 품질의 텍스트 정보를 생성하고, 비영어 텍스트 정보의 다국어 커버리지와 정확성이 Entity Linking, Knowledge Graph Completion 및 Question Answering에 미치는 영향을 연구하였다.

###### Memory-Based Invariance Learning for Out-of-Domain Text Classification (https://aclanthology.org/2023.emnlp-main.101/)
- Anthology ID: 2023.emnlp-main.101 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다양한 소스 도메인에서 학습된 분류 모델을 처음 보는 타겟 도메인에 적용하는 OOD 텍스트 분류 작업에 대해 조사한다. 
    2. 최근 연구들이 불변 표현 학습이 OOD 일반화 성능을 향상시킬 수 있다고 보여줬지만, 서로 다른 도메인 간의 데이터 분포 차이로 인해 효과적인 불변 표현 학습이 어려움을 겪는다. 
    3. 이 연구에서는 메모리 증강 기법을 적용하여 이 문제를 해결하고, key-value 메모리를 이용하여 원래의 특성 공간을 보강하고, 메타 학습 기반 접근법을 사용하여 불변 표현의 품질을 향상시키는 방법을 제안한다.

###### Outlier Suppression+: Accurate quantization of large language models by equivalent and effective shifting and scaling (https://aclanthology.org/2023.emnlp-main.102/)
- Anthology ID: 2023.emnlp-main.102 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Transformer 언어 모델의 후훈련 양자화(PTQ)는 활성화 함수 내의 잘못된 아웃라이어(outlier)로 인해 심각한 문제가 있다. 
    2. 이 논문에서는 아웃라이어로 인한 비대칭성과 불규칙한 분포를 해결하기 위해 채널별 이동과 스케일링을 제안한다.
    3. 실험 결과, 이 방법은 다양한 태스크에서 탁월한 성능을 보여주고, 특히 4-bit BERT에서 15.5%의 개선을 이끌어낸다.

###### Three Stream Based Multi-level Event Contrastive Learning for Text-Video Event Extraction (https://aclanthology.org/2023.emnlp-main.103/)
- Anthology ID: 2023.emnlp-main.103 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 텍스트-비디오 기반 다중 모달 이벤트 추출에서는 주어진 텍스트-비디오 쌍에서 이벤트 정보를 식별하는 것을 의미한다. 기존의 방법들은 비디오의 외관 특징(VAF)과 텍스트 시퀀스의 특징(TSF)을 주로 입력 정보로 활용한다.
    2. 이 논문에서는 비디오의 모션 표현과 대조적 학습의 최적화 문제에 대해 다룬다.
    3. 우리는 비슷한 모션 트라젝토리를 가진 이벤트 트리거가 같은 이벤트를 발생시킨다는 것을 관찰하고, 이를 활용하여 이벤트 추출 능력을 향상시키기 위해 Three Stream Multimodal Event Extraction (TSEE) 프레임워크를 제안한다.

###### Diversify Question Generation with Retrieval-Augmented Style Transfer (https://aclanthology.org/2023.emnlp-main.104/)
- Anthology ID: 2023.emnlp-main.104 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사람들은 주어진 텍스트와 답변에 대해 다양한 표현으로 질문을 할 수 있는 반면, 대부분의 질문 생성(QG) 시스템은 이를 아직 도전적으로 여기고 있다.
    2. 기존의 해결책은 대부분 주어진 텍스트 내부의 지식이나 다양한 콘텐츠 계획을 위한 의미적 단어 공간에 초점을 맞추었다. 그러나 이러한 방법들은 외부 지식의 표현 다양성의 잠재력을 고려하지 않았다.
    3. 본 논문에서는 "Retrieval-Augmented Style Transfer"라는 프레임워크를 제안하여 다양한 템플릿의 스타일을 활용하여 질문을 생성한다. 실험 결과는 다양성에 있어 이전의 다양성 중심 기준선보다 우수하면서 일관성 점수에 있어서는 비교 가능함을 보여준다.

###### Fast and Accurate Factual Inconsistency Detection Over Long Documents (https://aclanthology.org/2023.emnlp-main.105/)
- Anthology ID: 2023.emnlp-main.105 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "생성적 AI 모델들은 놀라운 잠재력을 보여주지만, 긴 입력에 대해서는 현재의 접근법이 효과적으로 대응하기 어려운 다양한 작업에서 환각이 발생하는 것은 큰 문제입니다."
    2. 저희는 SCALE (Source Chunking Approach for Large-scale inconsistency Evaluation)라는 임의 작업 모델을 소개합니다. 이 모델은 새로운 청크 전략을 사용하여 사실상의 불일치를 감지하기 위한 모델입니다. 
    3. SCALE은 단일한 언어 판별(Natural Language Inference, NLI) 모델이며, 긴 텍스트를 처리하기 위해 대규모 텍스트 청크를 사용합니다. 이 접근법은 다양한 작업과 긴 입력에 대한 사실상의 불일치 감지에서 최고의 성능을 보입니다.

###### Interpreting Embedding Spaces by Conceptualization (https://aclanthology.org/2023.emnlp-main.106/)
- Anthology ID: 2023.emnlp-main.106 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 텍스트의 연산적인 해석을 위한 주요 방법 중 하나는 embedding space로 맵핑하는 것이다. 이 논문에서는 latent embedding space를 이해하기 쉬운 개념적인 공간으로 변환하는 새로운 방법을 제안한다.
    2. 논문에서는 개념적인 공간을 동적으로 생성하는 알고리즘을 소개하고, 인간 평가자나 LLM(Large Language Models) 기반 평가자를 사용하여 개념화된 벡터가 실제 의미를 잘 표현하는지 보여준다.
    3. 개념화된 벡터를 사용하여 대체 모델의 의미를 비교하고 LLM의 레이어를 추적하는 등 다양한 태스크에 사용할 수 있음을 보여준다.

###### Knowledge-Augmented Language Model Verification (https://aclanthology.org/2023.emnlp-main.107/)
- Anthology ID: 2023.emnlp-main.107 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 언어 모델은 내부 지식을 파라미터에 내재시키므로 훌륭한 텍스트 생성 능력을 보여주지만, 지식이 부정확하거나 불완전하거나 오래되어 결과가 사실적이지 않을 수 있다. 
    2. 이 논문에서는 외부 지식 소스와 함께 언어 모델을 보완하기 위해 별도의 검증기를 도입하여, 지식과 결과를 검증하고 에러를 수정하는 방법을 제안하였다. 
    3. 실험 결과, 제안된 검증 단계가 언어 모델의 문제를 규명하는 데 효과적이었으며, 정확한 결과를 제공하는 데 도움이 되었다.

###### A Generation-based Deductive Method for Math Word Problems (https://aclanthology.org/2023.emnlp-main.108/)
- Anthology ID: 2023.emnlp-main.108 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 선형 방정식 풀이와 같은 고급 연산자를 포함한 수학 워드 문제는 기존의 방법들로 쉽게 해결할 수 없다. 이 논문에서는 기존의 이진 표현 트리나 증명 방법의 이진 유향 비순환 그래프 대신 새로운 다중 변수 유향 비순환 그래프 (mDAG)을 제안한다.
    2. mDAG의 위상 순서를 생성하기 위해, 기존의 증명 방법의 비싼 열거를 피하면서 증명 속성을 유지하기 위해 세대 기반 증명 (GeDe) 모델을 제안한다.
    3. GeDe는 널리 사용되는 벤치마크에서 여러 연산자를 가진 수학 문제와 자체 CMWPA 벤치마크에서 다중 변수 연산자를 효과적으로 해결하는 성능을 보여준다.

###### Failures Pave the Way: Enhancing Large Language Models through Tuning-free Rule Accumulation (https://aclanthology.org/2023.emnlp-main.109/)
- Anthology ID: 2023.emnlp-main.109 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델들은 놀라운 성능을 보여주지만, 샘플들 사이의 관계를 파악하지 못하는 문제로 인해 비슷한 실수를 반복하는 경향이 있다.
    2. 우리는 이 논문에서 이전의 실수로부터 배우면서 성능을 향상시키는 Tuning-free Rule Accumulation (TRAN) 프레임워크를 제안한다.
    3. 시퀀셜하게 도착하는 데이터를 고려하여, LLM은 틀린 케이스로부터 규칙을 점진적으로 축적하여 규칙 컬렉션을 형성하고, 이후의 입력 처리 시에 비슷한 실수를 피하기 위해 이러한 규칙을 활용한다. TRAN은 최근 기준선에 비해 성능을 크게 향상시킴을 실험적으로 보여준다.

###### Building Persona Consistent Dialogue Agents with Offline Reinforcement Learning (https://aclanthology.org/2023.emnlp-main.110/)
- Anthology ID: 2023.emnlp-main.110 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 오픈 도메인 대화 시스템에서 일관된 개성 유지는 중요한 품질이다. 기존 SOTA 시스템은 supervised learning 또는 online reinforcement learning으로 에이전트를 훈련시켜 이를 달성한다. 그러나 supervised learning으로 훈련된 시스템은 모순을 말할 경우에도 벌을 받지 않기 때문에 일관성이 부족하다. RL 훈련을 추가로 하면 이러한 문제를 완화할 수 있지만, 훈련 과정이 비용이 많이 든다.
    2. 본 논문에서는 대화 시스템의 개성 일관성을 향상시키기 위해 오프라인 RL 프레임워크를 제안한다. supervised learning과 유사하게 기존 데이터로 모델을 저비용으로 훈련하면서도 RL에서 특정 발언을 벌하거나 보상하는 것과 같은 이점을 결합할 수 있다.
    3. 또한, 오프라인 RL 훈련에서 중요도 가중치의 분산을 줄이기 위해 Variance-Reducing MLE-Initialized (VaRMI) importance sampling이라는 간단한 중요도 샘플링 방법을 도입한다. 자동 및 인간 평가 결과에서 본 프레임워크가 SOTA 소셜 챗봇의 개성 일관성 및 대화 품질을 향상시킨다는 것을 보여준다.

###### Augmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories (https://aclanthology.org/2023.emnlp-main.111/)
- Anthology ID: 2023.emnlp-main.111 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 우리는 Mixture-Of-Memory Augmentation (MoMA)을 통해 언어 모델의 zero-shot generalization 능력을 향상시켰다. 이 기법은 다중 정보 말뭉치(외부 메모리)에서 augmentation 문서를 검색하여 보완하는 메커니즘이다.
    2. 우리는 end retrieval task로부터 유래된 잠재적 레이블과 memory mixture의 hard negatives와 함께 augmentation 구성 요소를 훈련시키는 공동 학습 메커니즘을 개발했다.
    3. 우리의 모델은 T5 기반의 강력한 retriever를 MoMA로 보완하여 zero-shot 검색 정확도를 향상시킨다. 우리의 모델은 T5-base만 사용하여 표준 BEIR 벤치마크에 포함된 18가지 작업에서 강력한 zero-shot 검색 정확도를 보이며, 일부 큰 모델 크기를 가진 시스템들을 능가한다.

###### Active Instruction Tuning: Improving Cross-Task Generalization by Training on Prompt Sensitive Tasks (https://aclanthology.org/2023.emnlp-main.112/)
- Anthology ID: 2023.emnlp-main.112 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Instruction tuning(IT)는 instruction이 포함된 다양한 task에 대해 대규모 언어 모델(LLMs)을 학습하여 높은 일반화 성능을 얻었지만, 어떤 새로운 task를 선택해야 IT 모델의 성능과 일반화 능력을 향상시킬 수 있는지는 여전히 미해결한 문제이다.
    2. 이 논문에서는 prompt uncertainty를 바탕으로 하는 active instruction tuning이라는 새로운 프레임워크를 제안하여 정보성이 있는 task를 식별하고 선택된 task에서 모델을 적극적으로 조정한다.
    3. 실험 결과는 prompt uncertainty와 예측 확률에 기반한 task map을 소개하고, 모호한 task는 일반화를 향상시키고 어려운 task는 이점이 없다는 것을 발견하여 instruction tuning에서 task 선택의 중요성을 강조하고 있다.

###### Towards Example-Based NMT with Multi-Levenshtein Transformers (https://aclanthology.org/2023.emnlp-main.113/)
- Anthology ID: 2023.emnlp-main.113 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Retrieval-Augmented Machine Translation (RAMT)은 번역 지표를 향상시킬 뿐만 아니라 도메인 적응을 구현하는 데에도 관심이 높아지고 있다.
    2. 논문에서는 RAMT의 또 다른 특징인 번역 결정의 투명성 향상을 위해 새로운 아키텍처를 제안한다.
    3. 실험에서, 여러 예시를 동시에 편집하는 것이 번역 점수에 긍정적인 영향을 미치며, 기존 인스턴스로부터 복사된 대상 구간의 수를 증가시킨다는 것을 보여준다.

###### DUnE: Dataset for Unified Editing (https://aclanthology.org/2023.emnlp-main.114/)
- Anthology ID: 2023.emnlp-main.114 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 고급 언어 모델들도 수정 없이는 오류에 취약한데, 모델 편집은 원하는 결과를 얻기 위해 모델의 지식이나 표현을 수정하는 것을 의미한다.
    2. 이 연구에서는 사실 기반 데이터만 수정하던 이전 연구들과 달리, 편집 문제의 범위를 더 넓혀 여러 편집 작업에 대응하고, 모델의 출력을 수정하는 어떤 자연어 표현도 편집으로 간주함을 제안한다.
    3. DUnE라는 편집 벤치마크를 도입하여 DUnE 문제에 대한 다양한 편집 접근 방식을 실험적으로 검증하고, 특화된 편집 기술보다 검색 기반 언어 모델링이 더 좋은 성능을 보이며, 벤치마크가 다루는 일반화된 편집 문제를 완전히 해결하지 못한 상태임을 주장한다.

###### “Fifty Shades of Bias”: Normative Ratings of Gender Bias in GPT Generated English Text (https://aclanthology.org/2023.emnlp-main.115/)
- Anthology ID: 2023.emnlp-main.115 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어는 사회적인 신념 체계의 표현 도구로서 강력한 역할을 하지만, 동시에 우리 사회의 편견을 지속시킨다. 성별 편견은 온라인과 오프라인 대화에서 가장 만연한 편견 중 하나이다. 이 연구에서는 binary classification 문제가 아니라 상대적인 척도에서 성별 편견을 인식해야 한다는 점을 감안하여 다양한 정도의 편견을 생성하고 사람들의 반응을 조사한다.
    2. Best-Worst Scaling을 사용하여 성별 편견의 정량적 평가를 포함하는 GPT로 생성된 영어 텍스트의 첫 데이터셋을 만들었다.
    3. 우리는 편견의 다른 주제들에 대한 분석 결과를 보여주고, 신원-공격 (identity-attack)이 성별 편견과 가장 밀접하게 관련되어 있다는 것을 밝혔다. 또한, 우리의 데이터셋에서 관련 개념에 대해 훈련된 기존 자동 모델의 성능을 보여주었다.

###### Hybrid Inverted Index Is a Robust Accelerator for Dense Retrieval (https://aclanthology.org/2023.emnlp-main.116/)
- Anthology ID: 2023.emnlp-main.116 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "역 파일 구조는 밀집 검색을 가속화하기 위한 일반적인 기술이다. 그러나 군집화는 항상 손실이 발생하여 검색 품질을 저하시킨다. 따라서 이 논문에서는 Embedding 군집화와 중요한 용어들이 함께 작동하여 밀집 검색을 가속화하는 Hybrid Inverted Index (HI2)를 제안한다."
    
    2. "우리는 효율성과 효과적인 사용을 동시에 달성하기 위해 HI2를 구축하기 위해 군집 선별자와 용어 선택자를 개발한다. 또한 간단한 비지도 학습 알고리즘과 엔드 투 엔드 지식 전달 기법을 활용하여 이 두 모듈을 학습시키며, 후자는 효과성을 한층 향상시킨다."
    
    3. "인기 있는 검색 기준에 대한 포괄적인 실험을 기반으로 HI2가 군집과 용어가 서로 보완함을 확인하며 다양한 인덱스 설정에서 손실이 없는 검색 품질과 경쟁력 있는 효율성을 달성한다."

###### ChatGPT to Replace Crowdsourcing of Paraphrases for Intent Classification: Higher Diversity and Comparable Model Robustness (https://aclanthology.org/2023.emnlp-main.117/)
- Anthology ID: 2023.emnlp-main.117 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델의 등장은 크라우드 소싱에 어떤 영향을 미칠까? 
    2. 이 연구에서는 ChatGPT와 Falcon-40B를 사용하여 의도 분류를 위한 유사질문 생성 작업을 수행하고, ChatGPT가 생성한 유사질문이 더 다양하며 더 견고한 모델을 만들 수 있다는 것을 보여준다.

###### Query-as-context Pre-training for Dense Passage Retrieval (https://aclanthology.org/2023.emnlp-main.118/)
- Anthology ID: 2023.emnlp-main.118 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에는 컨텍스트-지도된 사전 훈련을 사용하여 밀집된 패스리트리벌의 성능을 향상시키기 위한 방법들이 개발되고 있다. 그러나 이러한 방법은 약하게 상관된 다른 두 패스지를 관련이 있다고 간주하며 약한 상관 관계의 부정적인 영향을 고려하지 않는다.
    2. 따라서 이 논문은 이 문제를 완화하기 위한 간단하고 효과적인 사전 훈련 기술인 query-as-context 사전 훈련을 제안한다. query-as-context 사전 훈련은 패스지에서 파생된 쿼리가 해당 패스지와 더 관련이 있을 가능성이 높다고 가정하고 패스지-쿼리 쌍을 형성한다.
    3. 이와 같은 치환 또는 생성적 컨텍스트-지도된 사전 훈련에서 사용된 사전 훈련 모델은 대규모 패스리트리벌 벤치마크 및 도메인 밖의 제로샷 벤치마크에서 평가되었다. 실험 결과, query-as-context 사전 훈련을 통해 검색 성능이 상당히 향상되었으며 그 효과와 효율성을 입증하였다.

###### A Suite of Generative Tasks for Multi-Level Multimodal Webpage Understanding (https://aclanthology.org/2023.emnlp-main.119/)
- Anthology ID: 2023.emnlp-main.119 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 웹페이지는 비전-언어 및 언어 과제에 대한 풍부하고 확장 가능한 자원이지만, 기존 데이터셋에서는 이미지-캡션 쌍, 긴 텍스트 기사 또는 원시 HTML과 같은 일부분만 보관되어 왔다. 이로 인해 웹페이지 과제는 별로 주목받지 못했으며, 구조화된 이미지-텍스트 데이터는 잘 활용되지 않았다.
    2. 우리는 다중 모달 웹페이지 이해를 연구하기 위해 Wikipedia Webpage Suite (WikiWeb2M)를 소개한다. 이 데이터셋은 이미지, 텍스트 및 구조 데이터를 모두 갖춘 2백만 개의 웹페이지를 포함하고 있다.
    3. 우리는 페이지 설명 생성, 섹션 요약 및 문맥적 이미지 캡션 등 세 가지 생성 작업에서 유용성을 검증하였다. 또한, 페이지 구조를 사용하여 가장 관련성이 높은 이미지와 텍스트 콘텐츠를 글로벌 토큰으로 선택하고 나머지 웹페이지에 대해 문맥적으로 주의를 기울이기 위한 새로운 어텐션 메커니즘인 Prefix Global을 설계했다.
    
    In addition, Please translate the keywords (in English) to Korean.
    1. automatic generation, Multiple Choice Questions (MCQ), evaluation metrics, BLEU, ROUGE, METEOR, target fact, knowledge, human survey
    2. deep models, NLP tasks, robustness, contrastive learning, counterfactual augmentation, augmentation, dataset, spurious patterns, causality, task model bias, generalization, scarce data
    3. Webpages, vision-language, language only tasks, image-caption pairs, long text articles, raw HTML, multimodal, webpage understanding, Wikipedia Webpage suite, page description generation, section summarization, contextual image captioning, attention mechanism, computational complexity, task performance

###### Democratizing Reasoning Ability: Tailored Learning from Large Language Model (https://aclanthology.org/2023.emnlp-main.120/)
- Anthology ID: 2023.emnlp-main.120 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델(Large language models, LLMs)은 탁월한 문장 처리 능력을 가지지만, 계산 요구량과 소스 코드의 닫힌 성격 때문에 민주화가 방해되고 있다. 
    2. 이 논문에서는 더 도전적인 추론 능력을 작은 언어 모델에 축소시키기 위한 학습 방법을 제안한다.
    3. 학습자의 학습 상태에 맞게 적응하는 다중 라운드 학습 패러다임과 함께 자기 반성 학습, LLM의 추론 역량을 활용하여 명확한 추론 능력을 더 효과적으로 도출할 수 있다는 결과가 실험과 분석을 통해 입증되었다.

###### OpenAsp: A Benchmark for Multi-document Open Aspect-based Summarization (https://aclanthology.org/2023.emnlp-main.121/)
- Anthology ID: 2023.emnlp-main.121 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 자동 요약 모델의 성능은 크게 향상되었지만, 실제 사용자의 특정 정보 요구를 충족시키는 데는 여전히 한계가 있다. 특히 본 논문에서는 유용한 측면 중심의 요약 설정에 중점을 두어 원하는 대상 요약을 제공하기 위한 연구가 필요하다.
    2. 현재의 데이터셋과 연구는 주로 사전 정의된 몇 가지 측면에만 집중하거나 단일 문서 입력에만 초점을 맞추거나, 합성 데이터에 의존하고 있다.
    3. 더 현실적인 시나리오에 대한 연구를 진전시키기 위해, 우리는 OpenAsp라는 다중 문서 개방형 측면 중심의 요약을 위한 벤치마크를 소개한다. 이 벤치마크는 새로운 비용 효과적인 어노테이션 프로토콜을 사용하여 기존의 일반적인 다중 문서 요약 데이터셋으로부터 개방형 측면 데이터셋을 유도한다.

###### PEFTDebias : Capturing debiasing information using PEFTs (https://aclanthology.org/2023.emnlp-main.122/)
- Anthology ID: 2023.emnlp-main.122 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 foundation 모델의 증가는 pretraining 중 발생하는 묵시적 편견을 해결해야 하는 시급한 필요성을 강조하고 있다. 
    2. 본 논문에서는 Parameter-Efficient Fine-tuning (PEFT)을 사용하여 foundation 모델 내의 편견을 완화하는 PEFTDebias라는 새로운 접근 방법을 소개한다.
    3. gender와 race라는 두 가지 편견 축을 가진 4개의 데이터셋에서 평가를 실시한 결과, PEFT를 통해 downstream 편향을 효과적으로 감소시킬 수 있음을 발견하였다.

###### Byte Pair Encoding for Symbolic Music (https://aclanthology.org/2023.emnlp-main.123/)
- Anthology ID: 2023.emnlp-main.123 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 딥러닝과 함께 사용되는 기호 음악 모드는 대부분 언어 모델 아키텍처와 결합된다. 하지만 음악은 여러 속성을 가진 동시에 일어나는 음표들로 구성되기 때문에 이를 토큰화해야 한다. 기존의 토큰화 방법은 작은 어휘를 가진 토큰들로 음표 속성과 시간 이벤트를 설명하기 때문에 토큰 시퀀스가 상대적으로 길고 언어 모델의 임베딩 공간을 효율적으로 사용하지 못하는 문제가 있다.
    2. 이 논문에서는 자연어 처리에서 널리 사용되는 압축 기술인 Byte Pair Encoding (BPE)를 사용하여 토큰 시퀀스의 길이를 크게 줄이고 어휘 크기를 증가시킴으로써 더 표현력 있는 토큰으로 언어 모델의 임베딩 기능을 활용할 수 있게 했다. 이를 통해 생성 및 분류 작업에서 더 나은 결과와 더 빠른 추론이 가능해졌다.
    3. Byte Pair Encoding은 [Github](https://github.com/Natooz/bpe-symbolic-music)에서 공유된 소스 코드와 함께 [companion website](https://Natooz.github.io/BPE-Symbolic-Music)로 구현되어 있으며, [MidiTok](https://github.com/Natooz/MidiTok)에서 BPE를 직접 구현함으로써 독자들은 이 방법을 쉽게 활용할 수 있다.

###### Combining Denoising Autoencoders with Contrastive Learning to fine-tune Transformer Models (https://aclanthology.org/2023.emnlp-main.124/)
- Anthology ID: 2023.emnlp-main.124 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 자연어처리(NLP) 분야에서 큰 사전 훈련을 한 Transformer 모델을 전이학습에 사용하는 것이 주목받고 있으며, 이에 따라 프롬프트 기반, 어댑터 및 비지도 학습 방법과의 결합 등 다양한 전망이 등장하고 있다.
    2. 본 논문에서는 분류 작업을 위해 기본 모델을 조정하기 위한 3 단계 기법을 제안한다. 먼저 잡음 제거 오토 인코더(DAE)를 사용하여 모델의 신호를 데이터 분포에 맞게 조정하고, 그 다음 대조학습(CL) 방법에 의해 출력의 표현 공간을 해당 클래스에 맞게 조정한다.
    3. 또한, 균형이 맞지 않는 데이터셋을 보정하기 위해 지도 대조학습을 위한 새로운 데이터 증강 방법을 도입한다. 마지막으로, 사전 정의된 범주를 제한하기 위해 fine-tuning을 적용한다. 이러한 다른 단계는 모델이 최종 작업을 학습하는 데 유용하고 상보적인 지식을 제공한다. 실험 결과와 기법들과의 비교를 통해 이러한 주장을 입증한다.

###### Self-Influence Guided Data Reweighting for Language Model Pre-training (https://aclanthology.org/2023.emnlp-main.125/)
- Anthology ID: 2023.emnlp-main.125 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 텍스트 코퍼스에서 셀프-슈퍼바이전을 통해 사전 훈련 된 언어 모델들이 여러 NLP 태스크에 대한 모델 개발의 기본이 되었다. 그러나, 데이터의 상관성과 품질에 따라, 모든 데이터 샘플에 동일한 중요성을 부여하는 것이 최적의 선택이 아닐 수 있다. 
    2. 이 논문에서는 사전 훈련 데이터에 대한 모델 기반의 가중치 조정을 고려하지 않고, 태스크에 특화된 지도 학습과 LM fine-tuning에서만 가중치 재조정이 탐색되었다. 
    3. 우리는 이 중요한 부분을 채우기 위해, self-influence (SI) 점수를 사용하여 샘플의 중요성과 사전 훈련에 대한 정보를 고려하여 샘플을 공동으로 재조정하는 PRESENCE라는 방법을 제안한다.

###### ACTOR: Active Learning with Annotator-specific Classification Heads to Embrace Human Label Variation (https://aclanthology.org/2023.emnlp-main.126/)
- Anthology ID: 2023.emnlp-main.126 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 일반적으로 다수결로 레이블을 통합하는 것이 레이블 정보 분석에 많이 사용되지만, 이는 소수의 의견을 배려하지 못한다. 
    2. 최근의 연구에서는 단일 레이블 대신 개별 어노테이션으로부터 학습하는 것이 성능이 더 좋다는 것이 밝혀졌지만, 이는 많은 양의 어노테이션이 필요하다. 
    3. 본 논문에서는 경황학습 (active learning) 환경에서 여러 머리 (multi-head) 모델이 확실성 추정 측면에서 단일 머리 모델보다 훨씬 우수한 성능을 보인다. 또한, 두 개의 데이터셋에서 annotator별 머리를 사용하여 획득 함수를 설계하고 평가함으로써 그룹 수준 엔트로피 방법이 두 데이터셋 모두에 대해 일반적으로 잘 작동하며, 억제 시간 70%를 절약하면서 예측과 확실성 추정에 있어서 충분한 성능을 달성한다는 것을 보여준다.

###### TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models (https://aclanthology.org/2023.emnlp-main.127/)
- Anthology ID: 2023.emnlp-main.127 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어추론(NLI) 모델을 사용한 사실적 일관성 평가는 종종 실망스러운 성과를 보임. 기존 연구는 합성 트레이닝 데이터로 이 모델의 성능을 개선했지만, 이 데이터는 실제로 생성된 모델의 요약문과 특성이 다르며 가능한 사실적 오류의 범위가 제한적임. 
    2. 이 연구에서는 TrueTeacher라는 방법을 소개하는데, 이는 다양한 모델 생성 요약문을 대규모 언어 모델을 사용하여 주석을 달아 합성 데이터를 생성함. TrueTeacher는 기존 연구와 달리 인간이 작성한 요약문에 의존하지 않으며, 자연스럽게 다국어를 다룸.
    3. TRUE 벤치마크 실험 결과, TrueTeacher로 훈련된 학생 모델은 동등한 용량의 최신 모델과 LLM 트리처보다 현저히 우수한 성능을 보임. 도메인 이동에 대한 통일성과 우수성을 비교한 체계적인 연구를 통해, TrueTeacher의 우수성 및 견고성을 입증하며, 이 방법이 다국어 시나리오에도 일반화됨을 보임. 마지막으로, 이 데이터로 훈련한 체크포인트와 함께 TrueTeacher로 생성한 대규모 합성 데이터셋(1.4M 개의 예제)을 공개함.

###### VivesDebate-Speech: A Corpus of Spoken Argumentation to Leverage Audio Features for Argument Mining (https://aclanthology.org/2023.emnlp-main.128/)
- Anthology ID: 2023.emnlp-main.128 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. VivesDebate-Speech는 논쟁 추정과제에 오디오 기능을 활용하기 위해 생성된 말하기 논쟁의 말뭉치(VivesDebate-Speech)로, 이 논문은 이러한 말뭉치의 생성이 말하기 처리와 논쟁 추정 커뮤니티의 교차점에 중요한 기여이며 이 주제에서 가장 완전한 공개 자료 중 하나라고 설명한다.
    2. 또한, 우리는 오디오 기능을 논쟁 추정 pipeline에 통합할 때 개선이 나타나는 기존에 없던 실험들을 수행하였다.
    3. 제공된 결과는 향후 연구에 대한 기준선으로 활용될 수 있다.

###### Tagging-Assisted Generation Model with Encoder and Decoder Supervision for Aspect Sentiment Triplet Extraction (https://aclanthology.org/2023.emnlp-main.129/)
- Anthology ID: 2023.emnlp-main.129 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. ASTE (Aspect Sentiment Triplet Extraction)는 최근 주목을 받고 있으며, 이 테스크를 위한 최근 연구들은 대부분 자연어 생성 기반(NLG) 접근법에 의해 이루어졌다. 
    2. 하지만 대부분의 NLG 방법은 인코더-디코더의 숨겨진 표현을 감독하지 않는다는 문제가 있으며, 라벨이 제공하는 의미 정보를 완전히 활용하지 못하여 암묵적인 측면과 의견을 추출하는 데 어려움을 겪는다. 
    3. 이러한 도전에 대응하기 위해, 우리는 다중 관점 태깅 보조 생성 모델 (TAGS)을 제안한다. TAGS는 다중 관점 태깅 보조와 라벨 의미 표현을 통해 인코더와 디코더의 감독을 강화한다. TAGS는 추가적인 시퀀스 태깅 작업을 통해 인코더가 트리플렛의 단어를 구분할 수 있는 능력을 향상시키며, 시퀀스 태깅 확률을 활용하여 디코더를 안내함으로써 생성된 내용의 품질을 개선한다. 또한, TAGS는 라벨의 의미 표현을 얻기 위해 자체 디코딩 과정을 사용하고 이러한 의미 표현과 디코더의 숨겨진 상태를 정렬하여 디코더의 숨겨진 상태에 대한 강화된 의미 감독을 달성한다. 다양한 공개 벤치마크에서의 실험 결과는 TAGS가 최고의 성능을 달성한다는 것을 보여준다.

###### Larger Probes Tell a Different Story: Extending Psycholinguistic Datasets Via In-Context Learning (https://aclanthology.org/2023.emnlp-main.130/)
- Anthology ID: 2023.emnlp-main.130 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Language model probing은 모델의 특정 능력을 테스트하기 위해 종종 사용되지만, 작고 통계적으로 유의미한 파워가 부족한 probing 벤치마크를 사용할 때 결론이 제한될 수 있다.
    2. 이 논문에서는 심리언어학적 연구에서 영감을 받아 negation(NEM-1500-SIMP)과 role reversal (ROLE-1500)을 위한 새로운 대규모 데이터셋을 소개한다.
    3. 작은 벤치마크에 비해 GPT3를 사용하여 기존 NEG-136와 ROLE-88 벤치마크를 크게 확장하고, 모델의 성능이 원래의 작은 벤치마크와 비교하여 20-57% 감소하는 것을 관찰한다.

###### Norm of Word Embedding Encodes Information Gain (https://aclanthology.org/2023.emnlp-main.131/)
- Anthology ID: 2023.emnlp-main.131 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 단어의 분산 표현은 어휘 의미 정보를 인코딩하지만, 어떤 종류의 정보를 인코딩하고 어떻게 인코딩되는지는 어떤가요? 
    2. 우리는 skip-gram with negative-sampling 방법에 주목하여, 정적 단어 임베딩의 제곱 노름이 단어가 전달하는 정보 획득량을 인코딩한다는 것을 발견했습니다. 
    3. 이론적 프레임워크와 실험을 통해 우리의 결과를 확인하고, 단어 빈도에서 생기는 잘못된 상관관계를 제거하는 정확한 실험을 통해 결과를 확인하였습니다.

###### CRT-QA: A Dataset of Complex Reasoning Question Answering over Tabular Data (https://aclanthology.org/2023.emnlp-main.132/)
- Anthology ID: 2023.emnlp-main.132 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 대형 언어 모델은 텍스트 기반 작업에서 강력한 추론 능력을 보여주지만, 구조화된 데이터인 테이블에 대한 추론 능력은 체계적으로 탐구되지 않았다. 
    2. 이 논문에서는 테이블 데이터 분석을 위한 추론 및 작업 유형에 대한 포괄적인 분류 체계를 제안한다.
    3. 또한, 테이블에 대한 복잡한 추론 QA 데이터셋인 CRT-QA 데이터셋을 구축하여, LLM의 추론 능력을 철저히 탐구할 수 있도록 하였다.

###### Promoting Topic Coherence and Inter-Document Consorts in Multi-Document Summarization via Simplicial Complex and Sheaf Graph (https://aclanthology.org/2023.emnlp-main.133/)
- Anthology ID: 2023.emnlp-main.133 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다중 문서 요약(MDS)은 다수의 소스 문서로부터 정보를 압축하여 간결한 요약을 만들어내는 작업을 의미한다. 그러나 기존 시스템들은 인코딩 중 토큰 길이에 제한을 두거나, 다중 문서 간의 복잡한 관계를 제대로 포착하지 못하는 등의 한계점을 가지고 있다. 이러한 제한사항은 요약물이 사실적이지 않고 충실하지 않은 경우를 만들며, 독자들에게 일부 주제에 대한 부당한 이해를 제공할 수 있다.
    2. 이 논문에서는 FIBER라는 새로운 인코더-디코더 모델을 제안하는데, 이 모델은 사전 훈련된 BART를 사용하여 언어적 뉘앙스를 포괄적으로 분석하고, 단순한 복합체 복잡 계층을 사용하여 짝별 관계를 초월하는 고유한 속성을 이해하며, 시프 그래프 어텐션을 사용하여 이질 속성을 효과적으로 포착한다.
    3. FIBER는 Multinews, CQASumm, DUC, Opinosis와 같은 네 가지 평가 데이터셋에서 열 한 가지 기준선과 비교하여 일관된 성능 향상을 보여주며, 구문적, 의미적 및 충실성 평가 척도를 통해 이러한 개선 사항을 보다 정확하게 입증하였다.

###### MAGNIFICo: Evaluating the In-Context Learning Ability of Large Language Models to Generalize to Novel Interpretations (https://aclanthology.org/2023.emnlp-main.134/)
- Anthology ID: 2023.emnlp-main.134 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인간은 언어 표현에 새로운 해석을 부여하여 새로운 단어를 학습하고 커뮤니티 특정 용례를 이해하는 능력을 가지고 있지만, 대형 언어 모델 (LLM)은 학습 가능한 한계를 가지고 있으며 반복적인 학습은 비용이 많이 든다. 따라서 LLM이 맥락에서 새로운 해석을 배울 수 있도록 하는 것이 중요하다.
    2. 이 논문에서는 실제 세계의 복잡성을 시뮬레이션하기 위해 다양한 토큰 및 프롬프트 설정을 포함한 텍스트-투-SQL 의미 분석 프레임워크 내에서 구현된 평가 툴 MAGNIFICo를 소개한다.
    3. MAGNIFICo에서의 실험 결과는 LLM이 자연어 설명과 긴 대화 내에서 새로운 해석을 이해하는 능력이 놀랄 정도로 강력하다는 것을 보여주지만, 불쾌한 단어 해석이나 동시에 여러 새로운 해석을 동일한 예제에서 구성하는데 있어서 추가적인 개선이 필요함을 강조한다. 또한, 우리의 분석에서 LLM의 의미적 편향을 규명하고 긴 맥락에서 제시된 정보에 대한 최근성 편향의 영향을 밝힌다.

###### Generating and Evaluating Tests for K-12 Students with Language Model Simulations: A Case Study on Sentence Reading Efficiency (https://aclanthology.org/2023.emnlp-main.135/)
- Anthology ID: 2023.emnlp-main.135 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 교육용 시험지를 작성하고 학생들의 응답을 수집하여 평가하는 것은 비용과 시간이 많이 드는 작업이다. 본 연구에서는 이전 학생들의 응답을 시뮬레이션하기 위해 큰 언어 모델을 fine-tuning 하는 방법을 제안하고, 이를 통해 시험 문항의 난이도와 모호성을 추정할 수 있다.
    2. 우리는 GPT-4를 사용하여 전문가가 개발한 규칙을 따라 새로운 시험 문항을 생성하고, 심리학적 측정 기준에 따라 fine-tuned 언어 모델을 사용하여 문항을 필터링하는 방법을 제안한다.
    3. 실험 결과, 생성된 시험지의 평가 결과가 인간 전문가가 작성하고 수천 명의 학생을 대상으로 평가된 표준 시험지와 높은 상관관계를 가짐을 확인하였다.

###### Counter Turing Test (CT2): AI-Generated Text Detection is Not as Easy as You May Think - Introducing AI Detectability Index (ADI) (https://aclanthology.org/2023.emnlp-main.136/)
- Anthology ID: 2023.emnlp-main.136 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. ChatGPT의 등장으로 AI 생성 텍스트의 위험과 결과가 심각해졌다. 이에 수천 명의 연구원과 기술 리더로부터 서명된 2023년 3월의 편지를 시작으로, GPT-4보다 더 세련된 AI 시스템의 훈련에 6개월 동안 중단을 요구하는 사태가 일어났다. 또한 미국 저작권국은 "머신이 생산한 내용이 전통적인 작성 요소라면 그 작품은 인간의 저작이 아니므로 저작권 등록 대상이 아니다"라고 발표했다. 
    2. 이 논문에서는 AI 생성 텍스트 감지(AGTD)에 초점을 맞추어 기존 AGTD 기술의 견고성을 평가하는 테스트인 CT2를 소개한다. 우리의 경험적 결과는 제안된 AGTD 방법의 취약성을 명확하게 보여준다. 또한 LLMs의 감지 가능성 레벨을 평가하고 순위를 매기기 위한 AI 감지 가능성 지수 (ADI)를 제안한다.
    3. 15가지의 현대적인 LLMs를 철저히 조사한 결과, 더 큰 LLMs일수록 작은 LLMs와 비교하여 감지 가능성이 낮아진다는 것을 입증하였다. 우리는 ADI가 NLP 커뮤니티에게 큰 가치를 가지고 있으며, AI 관련 정책 결정에 대한 평가 지표로 사용될 수 있는 잠재력을 가지고 있다고 단언한다.

###### Revisiting the Optimality of Word Lengths (https://aclanthology.org/2023.emnlp-main.137/)
- Anthology ID: 2023.emnlp-main.137 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Zipf (1935)은 단어형태가 의사소통 비용을 최소화하도록 최적화된다고 주장했습니다. 이 논문에서는 Piantadosi et al. (2011)의 가설과 비교하여, 단어의 길이가 기대값과 분산-평균비율에 비례해야 한다는 새로운 가설을 제안합니다.
    2. 실험 결과, 13개 언어와 여러 실험 설정에서 단어의 길이가 주어진 가설들을 예측하는 데 있어 빈도수 가설이 더 좋은 결과를 보였습니다.
    3. 이 결과는 Zipf의 가설이 여전히 옳다는 증거로 받아들일 수 있다고 설명합니다.

###### Document-level Relationship Extraction by Bidirectional Constraints of Beta Rules (https://aclanthology.org/2023.emnlp-main.138/)
- Anthology ID: 2023.emnlp-main.138 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 문서 수준 관계 추출(DocRE)은 문서 내 entity pair 사이의 관계를 추출하는 것을 목표로 한다. 그러나 기존의 DocRE 모델에서 불명확성과 약한 논리문제를 해결하기 위해 도입된 몇몇 작업들은 forward logic 제약에만 초점을 두고 있고, 이러한 작업에서 채굴된 규칙들은 표준 신뢰도는 높지만 서포트는 낮은 pseudo rule에 가장 많은 영향을 받는다.
    2. 이 논문에서는 새로운 logic 제약 프레임워크인 BCBR을 제안한다. BCBR은 우선 베타 기여에 의해 규칙을 모델링하는 새로운 규칙 마이너를 도입한다. 그런 다음 베타 규칙을 기반으로 forward와 reverse logic 제약을 구축한다. 마지막으로 BCBR은 양방향 제약에 의해 규칙 일관성 손실을 재구성하여 DocRE 모델의 출력을 조절한다.
    3. 실험 결과, BCBR은 관계 추출 성능 (~2.7 F1 점수) 및 논리적 일관성 (~3.1 논리 점수) 측면에서 기존의 DocRE 모델들보다 우수한 성능을 보여주며, 또한 BCBR은 두 가지 다른 logic 제약 프레임워크들보다 꾸준히 우수한 성능을 보여준다.

###### Instructed Language Models with Retrievers Are Powerful Entity Linkers (https://aclanthology.org/2023.emnlp-main.139/)
- Anthology ID: 2023.emnlp-main.139 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 큰 언어 모델(Large Language Model, LLM)에 기반한 생성적인 방법은 복잡한 추론 능력이 필요한 작업에서 급발진한 능력을 보여주지만, 생성적인 특성으로 인해 생성된 내용은 환영에 시달리기 때문에 entity linking과 같은 entity-centric 작업에는 적합하지 않다.
    2. 우리는 Instructed Generative Entity Linker (INSGENEL)이라는 접근법을 제안하여 언어 모델이 지식 베이스 상에서 entity linking 작업을 수행할 수 있도록 한다. 이를 위해 (i) instruction-tuning을 통한 sequence-to-sequence 학습 목표를 갖춘 EL, (ii) 경량의 잠재적 명칭 탐색기를 기반으로 한 신규 생성적 EL 프레임워크 등 다양한 방법을 제안한다.
    3. INSGENEL은 이전의 생성적 대안보다 평균 +6.8 F1 포인트의 성능 향상을 보이며, 훈련 데이터 효율성과 훈련 계산 비용에서도 큰 이점을 가진다. 또한, 우리가 공들여 개발한 in-context learning (ICL) 프레임워크는 여전히 INSGENEL에 비해 크게 뒤쳐지므로, entity linking 작업은 일반적인 LLM에게 직면한 지속적인 어려움임을 확인할 수 있다.

###### Towards Noise-Tolerant Speech-Referring Video Object Segmentation: Bridging Speech and Text (https://aclanthology.org/2023.emnlp-main.140/)
- Anthology ID: 2023.emnlp-main.140 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. HCI에서는 언어적 소통이 주로 이루어지는데, 소리 (말 언어) 는 소음과 악센트로 인해 텍스트와 비교해 모호할 수 있기 때문에 차이가 있다. 2. 본 연구에서는 의미적으로 세밀한 정의가 필요한 HCI 작업인 R-VOS (Referring Video Object Segmentation) 을 연구했습니다. 3. 기존 텍스트 입력 기반 모델을 활용하여 소음이 있는 음성 입력을 효과적으로 처리할 수 있는 방법을 제안하고, 실험 결과에서 우수한 성능을 보였습니다.

###### PROSE: A Pronoun Omission Solution for Chinese-English Spoken Language Translation (https://aclanthology.org/2023.emnlp-main.141/)
- Anthology ID: 2023.emnlp-main.141 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Neural Machine Translation(NMT) 시스템은 pro-drop(의미적으로 수식어 생략 가능한) 언어(예: 중국어)를 non-pro-drop 언어(예: 영어)로 번역할 때, 생략된 대명사를 복원해야 하는 독특하고 중요한 작업이지만, 어느 정도 충분한 벤치마크 데이터셋이 없다. 따라서, 우리는 다양한 pro-drop 사례를 포함한 새로운 벤치마크인 PROSE를 소개한다."
    2. "또한, 우리는 이 데이터셋에서 중국어에서 pro-drop 현상에 대해 철저한 조사를 진행하여, pro-drop이 중국어-영어 번역에서 NMT 시스템의 성능을 낮춘다는 것을 다시 확인한다. pro-drop이 도입하는 부정적인 영향을 줄이기 위해, 우리는 생략된 대명사의 의미 임베딩을 활용한 새로운 접근 방식인 Mention-Aware Semantic Augmentation을 제안한다."
    3. "4개의 중국어-영어 번역 코퍼스에서 실시한 실험 결과, 우리의 제안한 방법은 생략된 대명사 검색과 전체 번역 품질 측면에서 기존 방법들보다 우수한 성능을 보였다."

###### A Diachronic Analysis of Paradigm Shifts in NLP Research: When, How, and Why? (https://aclanthology.org/2023.emnlp-main.142/)
- Anthology ID: 2023.emnlp-main.142 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "과학 분야의 기본 개념과 트렌드를 이해하는 것은 지속적인 발전과 핵심이다. 이 연구에서는 인과적 발견과 추론 기술을 사용하여 과학 분야의 연구 주제의 진화를 분석하기 위한 체계적인 프레임워크를 제안한다."
    2. "우리는 NLP 분야 내에서 연구 주제의 진화의 다양한 측면을 포괄하는 세 가지 변수를 정의하고 관찰 데이터를 사용하여 이러한 변수들 사이의 인과 관계를 해명하기 위한 인과적 발견 알고리즘을 활용한다."
    3. "ACL Anthology corpus에서의 실험을 통해 우리의 프레임워크가 다양한 NLP 연구 주제에 대한 진화적 동향과 근본적인 원인을 효과적으로 밝혀내었음을 보여준다. 특히, 과업과 방법이 NLP 연구의 주된 원동력이며, 데이터셋은 그 다음이고, 평가 지표는 최소한의 영향을 미친다."

###### Does the Correctness of Factual Knowledge Matter for Factual Knowledge-Enhanced Pre-trained Language Models? (https://aclanthology.org/2023.emnlp-main.143/)
- Anthology ID: 2023.emnlp-main.143 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 연구에서는 이전에 학습한 언어 모델의 성능에 실제 지식을 주입하는 것이 하류 작업 성능과 매우 강한 양의 상관 관계를 가지고 있다는 것을 보였다.
    2. 하지만 기존 연구들은 주입된 지식이 언어 모델이 성공적으로 학습하고 하류 작업 성능 향상과의 인과 관계를 증명하지 못했다.
    3. 이 논문에서는 인과 관계 파악을 위해 counterfactual 기반의 분석 프레임워크를 제시하고, 다양한 규모에서 실제 지식 소스를 변형하여 이전과 이후의 언어 모델 성능을 비교함으로써 이 문제를 분석한다.

###### Syntactic Substitutability as Unsupervised Dependency Syntax (https://aclanthology.org/2023.emnlp-main.144/)
- Anthology ID: 2023.emnlp-main.144 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 논문에서는 반복 프로세스의 구조를 해석하는 방법을 설명한다.
    2. 어절들의 의미적 변환이 가능하다는 사실을 이용하여, 분석하기 위한 구문을 정의한다.
    3. 이러한 방법을 이용하면, 자연어 처리 작업에서 파싱 정확도가 향상되며 다른 파싱 설정으로의 전이성을 보인다.

###### MProto: Multi-Prototype Network with Denoised Optimal Transport for Distantly Supervised Named Entity Recognition (https://aclanthology.org/2023.emnlp-main.145/)
- Anthology ID: 2023.emnlp-main.145 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. DS-NER (Distantly Supervised Named Entity Recognition)은 지식 베이스나 가제터와 무라벨링 된 말뭉치만 가지고 개체 명칭과 그 타입을 인식하는 것을 목표로 한다. 그러나 먼 거리에서의 주석은 노이즈가 많아져 NER 모델의 성능을 저하시킨다. 
    2. 본 논문에서는 DS-NER 작업을 위한 노이즈에 강건한 프로토타입 네트워크인 MProto를 제안한다. MProto는 이전의 프로토타입 기반 NER 방법과 다르게 각 entity 유형을 여러 프로토타입으로 표현하여 entity 표현 사이의 내부 클래스 분산을 특색 짓는다. 
    3. 실험 결과, MProto 모델은 여러 DS-NER 벤치마크에서 최고 성능을 보여주고 있다.

###### The Shifted and The Overlooked: A Task-oriented Investigation of User-GPT Interactions (https://aclanthology.org/2023.emnlp-main.146/)
- Anthology ID: 2023.emnlp-main.146 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 대용량 언어 모델의 발전은 다양한 NLP 태스크에서 놀라운 성과를 보이고 있다. 그러나 NLP 연구의 집중점이 실제 사용자의 요구를 정확하게 반영하는지 여부는 여전히 불분명하다. 
    2. 이 논문은 대규모 사용자-GPT 대화 기록을 통해 NLP 연구와 실제 NLP 응용의 요구 사항 사이의 격차를 철저히 분석한다. 
    3. 우리는 사용자들이 LLMs에게 자주 요청하는 작업과 학술적 연구에서 일반적으로 연구되는 작업 사이에 상당한 차이를 발견하고, 사용자 요청 작업인 "design"과 "planning"과 같은 작업이 전통적인 NLP 벤치마크에서는 주로 무시되거나 다른 것임을 보여준다. 그리고 이러한 간과된 작업을 조사하고 실제적인 도전 과제를 분석하여 사용자 요구에 더욱 맞추기 위한 로드맵을 제시한다.

###### Learning the Visualness of Text Using Large Vision-Language Models (https://aclanthology.org/2023.emnlp-main.147/)
- Anthology ID: 2023.emnlp-main.147 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 시각적 텍스트는 사람의 머릿속에 이미지를 떠올리게 하지만 시각적이지 않은 텍스트는 그렇지 못하다. 텍스트의 시각성을 자동으로 감지하는 방법은 텍스트-이미지 검색 및 생성 모델에서 관련 이미지와 함께 텍스트를 보완하는 데 도움이 될 수 있다.
    2. 긴 형식의 텍스트에서 시각성을 정확히 감지하는 것은 어려운 작업인데, 이 논문에서는 큰 비전-언어 모델인 CLIP을 fine-tuning하여 시각적이 아닌 텍스트를 NULL 이미지에 매핑하고, 시각적인 텍스트는 해당 문서에서의 대응 이미지와 일치하도록 모델의 목표를 수정하는 전략을 제안한다.
    3. 실험적 평가 결과, 이 방법은 제안된 작업에 대해 여러 가지 휴리스틱 및 기준 모델보다 더 좋은 성능을 보여주며, 텍스트의 시각성 모델링의 중요성을 강조하기 위해 DALL-E와 같은 텍스트-이미지 생성 시스템의 정성적 분석을 수행한다.

###### The Past, Present and Better Future of Feedback Learning in Large Language Models for Subjective Human Preferences and Values (https://aclanthology.org/2023.emnlp-main.148/)
- Anthology ID: 2023.emnlp-main.148 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 큰 언어 모델(Large Language Models, LLMs)의 행동을 조절하기 위해 인간의 피드백이 점점 더 사용되고 있으나, 특히 매우 주관적인 인간의 선호도와 가치를 고려하여 피드백을 효율적이고 효과적이며 편향되지 않게 수집하고 통합하는 방법은 여전히 불명확하다.
    2. 이 논문은 인간의 피드백을 학습에 활용하기 위해 기존 접근 방식들을 조사하였으며, 인간의 피드백을 언어 모델에 통합하는 과거 동향, 현재 기술 및 실천 방법, 피드백을 사용하는 동기, 가치와 선호도를 정의하는 개념적 프레임워크, 그리고 피드백을 수집하는 방법과 수집 대상에 대한 개요를 제시한다.
    3. 마지막으로, 개념적 및 실질적으로 해결되지 않은 다섯 가지 도전과제를 제기함으로써 언어 모델의 피드백 학습에 대한 미래를 개선하고자 한다.

###### TempTabQA: Temporal Question Answering for Semi-Structured Tables (https://aclanthology.org/2023.emnlp-main.149/)
- Anthology ID: 2023.emnlp-main.149 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 비구조적인 데이터인 Infobox 테이블은 흔히 암묵적이거나 명시적인 형태로 entity에 대한 시간 정보를 포함하고 있다. 이런 정보를 NLP 시스템이 추론할 수 있는가? 
    2. 이 연구에서는 시간에 관한 질문-답변을 Infobox 테이블에서 수행하는 과제를 제안한다. 
    3. TEMPTABQA 데이터셋은 90개 이상의 도메인에 걸친 1,208개의 Wikipedia Infobox 테이블에서 추출된 11,454개의 질문-답변 쌍으로 구성되어 있으며, 이를 사용하여 시간적 추론 능력을 평가한다.

###### Task-Level Thinking Steps Help Large Language Models for Challenging Classification Task (https://aclanthology.org/2023.emnlp-main.150/)
- Anthology ID: 2023.emnlp-main.150 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화 생성, 상식 추론 및 질문 응답과 같은 여러 작업에서 대형 언어 모델 (LLM)의 성능이 뛰어남을 보였지만, 일부 어려운 분류 작업에서만큼이나 작업에서 보여주는 경향이 성능에 큰 영향을 줄 수 있다. 
    2. 이 논문에서는 몇 가지 시연을 통해 LLM을 downstream 작업에 적응시키기 위한 중요한 개념인 task-level thinking steps를 제안한다. 
    3. 또한, 혼란스러운 클래스를 구별할 수 있도록 LLM이 진화할 수 있는 progressive revision framework를 설계하여 thinking steps를 개선한다. 전문가들에 의해 레이블링된 적은 양의 데이터셋에서도 최고의 성능을 달성하는 우리의 제안된 방법의 우수성을 실험적으로 검증하였다.

###### RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation (https://aclanthology.org/2023.emnlp-main.151/)
- Anthology ID: 2023.emnlp-main.151 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 저장소 수준의 코드 완성 작업은 저장소의 더 넓은 문맥을 기반으로 미완성된 코드를 작성하는 작업이다. 그러나 자동 코드 완성 도구는 다른 파일에 흩어진 유용한 정보를 활용하기 어렵다.
    2. 본 논문에서는 유사도 기반 검색기와 사전 학습된 코드 언어 모델을 반복적인 검색-생성 파이프라인에 포함시켜 저장소 수준의 코드 완성 작업을 간소화하는 RepoCoder라는 간단하고 일반적인 효과적인 프레임워크를 제안한다.
    3. 실험 결과는 RepoCoder가 모든 설정에서 In-File completiion 기준을 10% 이상 향상시키고, vanilla retrieval-augmented code completion 접근법을 일관되게 앞선 성능을 보인다는 것을 보여준다.

###### Influence Scores at Scale for Efficient Language Data Sampling (https://aclanthology.org/2023.emnlp-main.152/)
- Anthology ID: 2023.emnlp-main.152 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 현대 머신러닝 시스템은 합성, 인간 주석, 실시간 고객 트래픽과 같은 다양한 원천에서 집계된 데이터를 이용한다. 학습 알고리즘의 성능에 중요한 예시들을 이해하는 것은 효율적인 모델 훈련을 위해 중요하다. 이 논문에서는 Language Classification Task 에서 영향력 점수(influence scores) 의 적용 가능성을 탐구한다.
    2. 이 논문에서는 SNLI 데이터셋을 사용하여 다양한 영향력 점수의 서브셋을 평가하고, 임의 및 영향력 점수 기반 샘플링을 통해 훈련 데이터를 축소함으로써 정확도 변화를 계량화한다.
    3. 에코더 기반 언어 모델은 원본 데이터의 약 50%로 미세 조정될 수 있으며, 성능 지표 저하 없이 훈련할 수 있다는 것이 이 실험에서 입증되었다. 또한, 영향력 점수의 오픈 소스 구현 적용을 통해 얻은 경험, 노이즈와 클래스 불균형 데이터의 영향을 계량화하고 더 나은 정확도와 훈련 효율성을 위한 점수 기반 샘플링에 대한 권장 사항을 요약한다.

###### G-Eval: NLG Evaluation using Gpt-4 with Better Human Alignment (https://aclanthology.org/2023.emnlp-main.153/)
- Anthology ID: 2023.emnlp-main.153 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 생성(NLG) 시스템이 생성한 텍스트의 품질을 자동으로 측정하기 어렵다. 기존의 기준 기반 메트릭(예: BLEU, ROUGE)은 창의성과 다양성을 필요로하는 작업에서 사람의 판단과 상대적으로 낮은 상관관계를 갖는 것으로 나타났다.
    2. 이 논문에서는 chain-of-thoughts (CoT) 및 form-filling 패러다임을 사용하여 큰 언어 모델(GPT-4)과 함께 G-Eval이라는 NLG 출력물의 품질을 평가하는 프레임워크를 제안한다. 
    3. 요약 작업에서 인간과의 스피어만 상관관계가 0.514로, 기존 방법을 큰 폭으로 능가하는 결과를 얻었으며, LLM 기반 평가자의 동작에 대한 분석을 제시하고 LLM 기반 평가자가 LLM이 생성한 텍스트에 편향될 가능성에 대해 강조한다.

###### Learning Retrieval Augmentation for Personalized Dialogue Generation (https://aclanthology.org/2023.emnlp-main.154/)
- Anthology ID: 2023.emnlp-main.154 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인물 프로필만으로는 진정한 개인화 대화를 생성하기 어려운 문제로 인해, 이 논문은 외부 지식을 활용한 개인화 대화 생성을 위한 학습 검색 학습 (LAPDOG)을 제안한다.
    2. LAPDOG 모델은 이야기 검색기와 대화 생성기로 구성되어 있으며, 이야기 검색기는 주어진 인물 프로필을 사용하여 이야기 문서에서 관련 정보를 검색하여 인물 프로필을 보강하는 보조 컨텍스트로 사용한다.
    3. CONVAI2 데이터셋과 ROCStory를 보조 데이터 소스로 사용하여 수행한 실험 결과, 제안한 LAPDOG 방법이 기준 모델들보다 큰 향상을 보였다.

###### The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations (https://aclanthology.org/2023.emnlp-main.155/)
- Anthology ID: 2023.emnlp-main.155 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 대형 언어 모델(Large Language Models, LLMs)은 놀라운 신기능을 갖게 되었지만, 그로 인해 가상 탄생 문제(hallucination)가 상당한 우려 요소로 부각되고 있다. 본 논문에서는 가상 탄생에 대한 세부적인 분류와 완화 방법을 제시한다. Factual Mirage (FM)과 Silver Lining (SL)의 두 가지 방향을 서술하고, 인과관계를 이해하기 위해 내재적과 외재적으로 나누어 심각함의 세 가지 정도를 제시한다. 가상 탄생은 약어 모호성, 숫자적 오용, 생성된 고렘, 가상 음성, 지리적 오류, 시간 왜곡 등 여섯 가지 유형으로 자세히 분류된다.
    2. Hallucination의 증거화를 위해 HallucInation eLiciTation (HILT)라는 도구를 개발해 15개의 LLMs로 생성된 75,000개의 샘플과 위에서 언급한 카테고리에 대한 인간의 주석이 포함된 데이터셋을 공개한다. 더불어, Hallucination Vulnerability Index (HVI)라는 지표를 제안하여 LLMs의 가상 탄생 취약성을 측정하고 평가할 수 있는 비교 스펙트럼을 제공한다.
    3. 인공지능 개발을 규제하는 정책을 만드는 데 있어 가상 탄생에 취약한 LLM은 어떤 것인지 평가하고 측정하는 것이 매우 중요하다. HVI는 널리 사용되는 NLP 커뮤니티에서 유용한 도구로서 기능을 하며, 인공지능 관련 정책 결정에도 사용될 수 있는 척도(rubric)가 될 것이다. 마지막으로, 가상 탄생을 완화하기 위한 두 가지 해결 전략을 제안한다.

###### NAIL: Lexical Retrieval Indices with Efficient Non-Autoregressive Decoders (https://aclanthology.org/2023.emnlp-main.156/)
- Anthology ID: 2023.emnlp-main.156 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 신경망 문서 재순위 모델은 정확도 측면에서 매우 효과적이지만, 특정 하드웨어가 필요하고 비용이 많이 들어 가장 좋은 성능을 낼 수 있는 모델은 실현 가능하지 않다.
    2. 이 논문에서는 문서별 계산 양(FLOPs)을 매우 줄여 CPU로 제공할 수 있는 어휘화된 점수 함수를 사용하여 Transformer 교차 어텐션 모델의 성능 향상을 86%까지 달성하는 방법을 제안한다.
    3. 본 방법은 BM25 검색기와 결합되어 가속기가 필요하지 않은 최신 듀얼 인코더 검색기 수준의 품질을 구현할 수 있다.

###### Analyzing Modular Approaches for Visual Question Decomposition (https://aclanthology.org/2023.emnlp-main.157/)
- Anthology ID: 2023.emnlp-main.157 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에는 별도의 학습 없이 모듈식 신경망이 어려운 Vision-Language 태스크에서 end-to-end 신경망을 능가하는 결과가 나타났다. 이 연구에서는 ViperGPT를 중점적으로 다루고, 해당 모델의 성능 향상 요소가 최신 end-to-end 모델인 BLIP-2 모델과 추가적인 symbolic components 중 어느 정도인지 분석한다.
    2. ViperGPT의 성능 향상 요소는 Task-specific 모듈 선택과 관련이 있으며, 해당 모델이 Task-agnostic 모듈 선택으로 돌아갈 경우 이러한 향상 효과가 사라진다는 결과를 도출한다.
    3. Prompting-based decomposition 전략과 비교해본 결과, 일부 벤치마크에서 자연어로 하위 작업을 표현하는 모듈식 방법이 코드보다 훨씬 성능을 향상시키는 것으로 나타났다.

###### Improving Summarization with Human Edits (https://aclanthology.org/2023.emnlp-main.158/)
- Anthology ID: 2023.emnlp-main.158 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 연구는 인간 피드백 패러다임으로 학습하여 인간 결정에 기반한 고품질 텍스트를 생성할 수 있다는 가능성을 보여주고 있다.
    2. 이 논문에서는 인간 수정을 활용한 인간 피드백의 한 형태에 초점을 맞추고, 인간 편집과 모델 생성된 데이터를 함께 사용하는 새로운 기술인 SALT를 제안한다.
    3. 실험 결과는 SALT가 인간 및 모방 수정을 통해 요약 품질을 향상시키는 데 효과적임을 보여준다. 또한, SALT가 인간 편집 데이터에 적용될 때, 인간 기호를 위해 설계된 기존 RLHF 방법보다 우수한 성능을 보여준다.

###### Did You Mean...? Confidence-based Trade-offs in Semantic Parsing (https://aclanthology.org/2023.emnlp-main.159/)
- Anthology ID: 2023.emnlp-main.159 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최적화된 confience scores를 사용하여 비용과 주석 작업 부담 사이의 균형을 맞추는 방법을 제시했다. 
    2. confidence scores는 사용성과 안정성 사이의 균형을 최적화하는 데 도움이 되며, 잘못된 저신뢰도 프로그램 수행을 줄일 수 있다.
    3. 사용성과 안정성을 더 잘 균형있게 조율하기 위해 low-confidence input을 재구성하는 DidYouMean 시스템을 제안하였다.

###### The Skipped Beat: A Study of Sociopragmatic Understanding in LLMs for 64 Languages (https://aclanthology.org/2023.emnlp-main.160/)
- Anthology ID: 2023.emnlp-main.160 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 연구에서 대규모 언어 모델들의 역할에 대해 다양한 NLP 벤치마크를 통해 조사했으나, cross-linguistic 상호작용적 의미(SM)를 이해하는 능력에 대해 철저한 조사가 부족하다.
    2. 이 논문에서는 SM 이해를 위한 다국어 벤치마크인 SPARROW를 제안한다. SPARROW는 169개의 데이터셋으로 구성되어 있으며, 6가지 주요 범주의 13가지 작업 유형을 포함하고 있다.
    3. 다양한 다국어 언어 모델과 instruction-tuned LLM들의 성능을 SPARROW를 통해 평가한 결과, 기존의 오픈소스 instruction-tuned LLM들은 여러 언어로 SM을 이해하는 데 어려움을 겪으며, 일부 경우에서는 랜덤 기준에 가까운 결과를 보여준다.

###### Understanding the Effect of Model Compression on Social Bias in Large Language Models (https://aclanthology.org/2023.emnlp-main.161/)
- Anthology ID: 2023.emnlp-main.161 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대량 언어 모델들은 웹 텍스트의 사회적 편향에 맞게 자기 지도 학습을 수행하는데, 이러한 사회적 편향은 모델의 downstream task 예측에도 영향을 미쳐 표현상의 위해를 야기한다.
    2. 모델 압축 방법인 양자화와 지식 전달이 LLM의 사회적 편향에 미치는 영향을 조사한 연구는 거의 없는데, 이 논문은 모델 압축이 사회적 편향과의 상호작용을 조사한 잘 제어된 실험을 수행하였다.
    3. 연구 결과, 더 긴 사전 학습 시간과 큰 모델은 더 높은 사회적 편향을 가지며, 양자화는 최적의 균형점을 가지는 정규화 효과를 보였다.

###### BioPlanner: Automatic Evaluation of LLMs on Protocol Planning in Biology (https://aclanthology.org/2023.emnlp-main.162/)
- Anthology ID: 2023.emnlp-main.162 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 과학 실험을 위한 정확한 프로토콜을 자동으로 생성하는 것은 과학 자동화에 큰 도약이 될 것이다. 그러나 현재의 언어 모델은 다단계 문제 및 장기 계획에 어려움을 겪어 과학 실험 설계에 중요한 역할을 못하고 있다.
    2. 이 논문은 과학 실험 프로토콜 작성 작업에 대한 자동 평가 프레임워크를 제안하고, BioProt라는 생물학 프로토콜과 의사 코드 표현을 갖는 데이터셋을 소개한다.
    3. GPT-3와 GPT-4를 이용해 실험 프로토콜 생성 과제를 평가하고, 의사 코드를 활용하여 정확한 새로운 프로토콜을 생성하고 생물학 실험실에서 성공적으로 실행하는 것을 확인하였다.

###### Cross-lingual Prompting: Improving Zero-shot Chain-of-Thought Reasoning across Languages (https://aclanthology.org/2023.emnlp-main.163/)
- Anthology ID: 2023.emnlp-main.163 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Chain-of-thought (CoT)은 모델이 추론 경로를 명시적으로 생성하도록 유도하여 추론 정확성을 향상시키는데 효과적이며, 이에 대한 관심이 증가하고 있다.
    2. 이 논문은 zero-shot CoT의 성공에도 불구하고 기존의 zero-shot prompting 기법이 단일 언어에 한정되어 다른 언어로 일반화하기 어려워 전 세계적인 개발을 어렵게 했음을 언급한다.
    3. 작업에서는 cross-lingual prompting (CLP)을 소개하며, 이를 통해 zero-shot CoT 추론을 다양한 언어로 확장하고 성능을 향상시켰다는 결과를 제시한다.

###### FinGPT: Large Generative Models for a Small Language (https://aclanthology.org/2023.emnlp-main.164/)
- Anthology ID: 2023.emnlp-main.164 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대부분의 큰 언어 모델은 작은 언어들에 대한 커버리지가 매우 한정적이고, 프리트레이닝을 위한 거의 무제한의 데이터가 있는 언어에 주로 초점이 맞춰진다.
    2. 본 논문에서는 세계 인구의 0.1%미만이 사용하는 핀란드어를 대상으로 LLM을 구축하는 도전과제를 연구한다.
    3. 핀란드의 다양한 데이터셋을 활용하여, FinGPT 및 BLUUMI라는 두 가지 모델을 프리트레이닝하는 방법을 소개하고, 핀란드어 과제를 포함한 모델 평가를 수행한다.

###### Boosting Summarization with Normalizing Flows and Aggressive Training (https://aclanthology.org/2023.emnlp-main.165/)
- Anthology ID: 2023.emnlp-main.165 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. FlowSUM은 Transformer 기반 요약을 위한 normalizing flows 기반의 변분 인코더-디코더 프레임워크를 제안한다. 이 방법은 변분 요약에서의 주요한 도전 과제인 잠재 표현의 의미 정보 부족과 훈련 중 후자분붕(collapse)을 해결하기 위해 normalizing flows를 사용하여 유연한 잠재 후방분모델링을 가능하게 한다.
    2. 제안된 controlled alternate aggressive training (CAAT) 전략과 개선된 게이트 메커니즘을 사용하여 이러한 도전을 해결한다. 실험 결과는 FlowSUM이 생성된 요약의 품질을 크게 향상시키고, 추론 시간에 미미한 영향을 미치면서 지식 압축에 대한 잠재력을 발휘한다는 것을 보여준다.
    3. 또한, normalizing flows에서의 후자분붕 문제를 조사하고 훈련 전략, 게이트 초기화, 사용된 normalizing flows의 유형과 개수가 요약의 품질에 어떤 영향을 미치는지 분석함으로써 향후 연구에 대한 유용한 통찰을 제공한다.

###### Indicative Summarization of Long Discussions (https://aclanthology.org/2023.emnlp-main.166/)
- Anthology ID: 2023.emnlp-main.166 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 온라인 포럼은 여러 주제에 대해 다양한 관점의 교환과 토론을 장려한다. 그러나 긴 토론은 쉽게 파악하기 어렵다. 
    2. 우리는 큰 언어 모델 (LLM)을 사용하여 긴 토론에 대한 표제 요약을 생성하는 비지도 학습 방법을 제안한다. 
    3. 우리의 제안된 표제 요약은 토론을 탐색하기 위한 편리한 탐색 도구로 사용될 수 있다는 사용자 연구 결과를 보여준다.

###### A Framework for Vision-Language Warm-up Tasks in Multimodal Dialogue Models (https://aclanthology.org/2023.emnlp-main.167/)
- Anthology ID: 2023.emnlp-main.167 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 멀티모달 open-domain 대화 시스템에 대한 대부분의 연구는 목표 데이터셋 이외에도 추가적인 풍부한 데이터셋을 사용한 사전 훈련과 다중 작업 학습에 초점을 두고 있다.
    2. 그러나 실제 환경에서 이러한 추가 데이터셋을 활용하는 방법은 제한적일 수 있으며, 목표 데이터셋만을 기반으로한 효율적인 에이전트 구축 방법이 더 필요하다.
    3. 이 논문에서는 목표 데이터만을 사용하는 새로운 학습 전략인 VLAW-MDM를 제안한다. 이 전략은 큰 사전 훈련 데이터나 다중 작업 데이터셋을 사용하지 않고 목표 데이터로만 학습하는 방법이다. 이 접근 방식은 이미지에 대한 자동 캡션 생성 및 문맥 정보의 향상을 위해 그것들을 모델의 입력에 포함시키는 기법을 활용한다. 실험 결과, 제안된 방법은 제한된 데이터와 비교적 작은 모델에 대해 효과적임을 입증하였다. 다양한 평가 메트릭에서 기존 최신 모델에 비해 동등하거나 우수한 성능을 보였다.

###### Once is Enough: A Light-Weight Cross-Attention for Fast Sentence Pair Modeling (https://aclanthology.org/2023.emnlp-main.168/)
- Anthology ID: 2023.emnlp-main.168 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Transformer-based 모델은 답 선택과 자연어 추론(NLI) 같은 문장 쌍 모델링 작업에서 큰 성공을 거두었으나, 이러한 모델은 입력 쌍에 대해 cross-attention을 수행하기 때문에 계산 비용이 많이 든다.
    2. 이 논문에서는 효율적인 문장 쌍 모델링을 위한 새로운 패러다임인 TopicAns를 소개한다. TopicAns는 가벼운 cross-attention 메커니즘을 사용하여 쿼리 인코딩을 한 번만 수행하고 동시에 쿼리-후보 상호작용을 모델링한다.
    3. 네 가지 작업에서 수행한 실험 결과는 TopicAns가 cross-attention 모델과 비교할 만한 성능을 달성하면서 문장 쌍 연산을 113배 이상 가속화할 수 있다는 것을 보여준다.

###### Plan, Verify and Switch: Integrated Reasoning with Diverse X-of-Thoughts (https://aclanthology.org/2023.emnlp-main.169/)
- Anthology ID: 2023.emnlp-main.169 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델 (LLM)이 Thought 체인, Thought 프로그램과 같은 다양한 프로모팅 방법과 함께 유효성을 입증했지만, 이들 방법은 수학 추론 작업에서 서로 보완재성을 갖고 있다고 발견되었다.
    2. 이 논문에서는 XoT라는 통합 문제 해결 프레임워크를 제안하는데, 다양한 추론 측면에서 LLMs에게 프롬프트를 제공한다.
    3. 각 질문에 대해 XoT는 항상 가장 적합한 방법을 선택하고 각 방법을 반복적으로 실행하여 문제를 해결한다. 이를 통해 XoT는 동적으로 다른 프로모팅 방법 사이를 전환할 수 있으며, 외부 실행자로부터의 피드백을 통합하여 생성된 답변의 유효성을 확인한다.

###### GLEN: General-Purpose Event Detection for Thousands of Types (https://aclanthology.org/2023.emnlp-main.170/)
- Anthology ID: 2023.emnlp-main.170 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문에서는 넓은 범위와 대용량의 데이터셋 부재로 인해 이벤트 추출 연구의 진행이 방해되었다고 주장한다.
    2. GLEN은 3,465개의 다른 유형을 포함한 205,000개의 이벤트 언급을 다루는 일반 목적의 이벤트 감지 데이터셋으로, 오늘날 가장 큰 이벤트 데이터셋의 온톨로지보다 20배 이상 크다.
    3. GLEN은 PropBank의 기존 주석을 원격 감독으로 활용하는 DWD 오버레이를 사용하여 생성되었으며, GLEN의 큰 온톨로지 크기에 특별히 설계된 새로운 다단계 이벤트 감지 모델이 높은 성능을 보여준다는 것을 보여주고 있다.

###### Hierarchical Pretraining on Multimodal Electronic Health Records (https://aclanthology.org/2023.emnlp-main.171/)
- Anthology ID: 2023.emnlp-main.171 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사전 훈련은 NLP 분야에서 강력한 기술이지만 전자 건강 기록(EHR)에 대한 기존 사전 훈련된 모델은 EHR 데이터의 계층적 특성을 잘 포착하지 못하여 다양한 급행 태스크에 대한 일관된 일대 다 학습이 제한된다.
    2. 이 논문에서는 MedHMP라는 새로운 사전 훈련 프레임워크를 소개하여 계층적으로 다중 모달 EHR 데이터에 대해 특별히 설계되었다.
    3. 실험 결과를 통해 제안된 MedHMP의 효과를 보여주고, 18개의 기준선과의 비교에서 우리 접근법의 효능이 강조되었다.

###### Critic-Driven Decoding for Mitigating Hallucinations in Data-to-text Generation (https://aclanthology.org/2023.emnlp-main.172/)
- Anthology ID: 2023.emnlp-main.172 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 입력된 정보와 연결되지 않은 텍스트의 생성은 신경망 기반의 데이터 텍스트 생성에서 잘 알려진 문제이다. 이 논문에서는 기존의 모델 아키텍처나 추가 데이터 수집을 필요로 하지 않고, 생성 모델과 "텍스트 비평가" 분류기의 출력을 결합하여 환영을 완화하는 새로운 방법을 탐구한다. 
    2. 이 방법은 워드 확률에 기반한 모델과 디코딩과 조합될 수 있으며, 텍스트 비평가는 기존 LM의 훈련 데이터와 합성된 부정적 예제를 사용하여 추가적인 훈련 데이터가 필요하지 않는다.
    3. 실험 결과, 이 방법은 WebNLG와 OpenDialKG 벤치마크에서 기준 모델과 비교하여 성능을 개선시킨다.

###### Bridging the Gap between Synthetic and Authentic Images for Multimodal Machine Translation (https://aclanthology.org/2023.emnlp-main.173/)
- Anthology ID: 2023.emnlp-main.173 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 멀티모달 기계 번역(MMT)은 번역을 위해 입력으로 소스 문장과 관련 이미지를 동시에 사용한다. 
    2. 최근 연구들은 입력 문장에 연결된 이미지가 대부분 없기 때문에 강력한 텍스트-이미지 생성 모델을 활용하는 것을 제안한다. 
    3. 그러나 이 논문에서는 MMT 모델에 합성 이미지와 실제 이미지를 각각 제공하여, 합성 이미지에서 발생하는 분포 차이를 줄이고, 메인 모델이 실제 이미지에 의존하지 않는 성능 향상을 이끌어냈다.

###### DEPN: Detecting and Editing Privacy Neurons in Pretrained Language Models (https://aclanthology.org/2023.emnlp-main.174/)
- Anthology ID: 2023.emnlp-main.174 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사전 학습 언어 모델은 대규모 코퍼스에서 인간의 지식을 배웠지만, 그들의 강력한 메모리화 능력은 데이터 누출의 위험성을 불러온다. 이 논문에서는 사생활 데이터의 영향을 제거하기 위해 위험한 뉴런을 식별하고 제거하는 방법을 제안한다. 
    2. 새로운 방법을 사용하여 사생활 텍스트와 관련된 뉴런을 확인하고 이들을 활성화 값이 0인 것으로 설정하여 제거한다. 
    3. 실험 결과 우리의 방법은 모델의 성능에 영향을 주지 않으면서 사생활 데이터의 영향을 효과적이고 빠르게 제거할 수 있음을 보여준다. 또한, 실험을 통해 모델의 메모리화와 뉴런 간의 관계를 설명하며 우리 방법의 강건성을 더욱 명확하게 보여준다.

###### Investigating Bias in Multilingual Language Models: Cross-Lingual Transfer of Debiasing Techniques (https://aclanthology.org/2023.emnlp-main.175/)
- Anthology ID: 2023.emnlp-main.175 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 연구는 다국어 모델 내에서 편향 해소 기법의 전이성(transferability)에 대해 조사한다.
    2. 저자들은 영어, 프랑스어, 독일어, 네덜란드어에 대한 이러한 기법의 적용 가능성을 조사한다.
    3. 연구 결과, 크로스-링교(다중 언어) BERT(mBERT)를 사용하여 편향 해소 기법의 언어 간 전이가 가능하며, 실제로 유망한 결과를 얻었다. 특히 SentenceDebias 기법의 성능이 언어에 상관없이 우수하게 나타나며, mBERT의 편향을 평균 13% 줄일 수 있다고 발견되었다. 또한, 전이 학습을 추가한 편향 해소 기법은 특히 데이터 부족한 언어에서 크로스-링교적 효과를 갖는다는 것이 조사 결과로 밝혀졌다.

###### Can Language Models Laugh at YouTube Short-form Videos? (https://aclanthology.org/2023.emnlp-main.176/)
- Anthology ID: 2023.emnlp-main.176 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 소셜 네트워크의 짧은 형식의 유머 동영상이 인기를 얻으면서, AI 모델이 인식하기 위해 사람들과 더 잘 소통할 수 있게 됩니다. 그러나 이전의 비디오 유머 데이터셋은 연설이나 시트콤과 같은 특정 도메인을 대상으로하며 주로 언어적 단서에 초점을 맞추고 있습니다.
    2. 우리는 YouTube에서 수집한 1만 개의 다중모달 유머 동영상 데이터셋 (ExFunTube) 을 만들었습니다. 이를 위해 GPT-3.5와 비디오 필터링 파이프라인을 사용하여 유머에 기여하는 음성 및 시각적 요소를 확인하고 여러 도메인에 걸쳐 다양한 유형의 유머를 가지고 있는 동영상을 주석과 함께 주석을 추가했습니다.
    3. 자동 점수, 근거 품질 실험 및 인간 평가를 사용하여 세 가지 다른 평가 방법으로 우리의 프롬프팅이 LLMs (Large Language Model)의 유머에 대한 이해 능력을 크게 향상시킴을 보여줍니다.

###### Random Entity Quantization for Parameter-Efficient Compositional Knowledge Graph Representation (https://aclanthology.org/2023.emnlp-main.177/)
- Anthology ID: 2023.emnlp-main.177 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 지식 그래프(Knowledge Graphs)에서의 표현 학습은 하위 태스크에 있어서 중요하다. 기존 방법인 지식 그래프 임베딩(KG Embedding)은 많은 scalability 도전과 파라미터 효율성의 문제를 안고 있다. 하지만 이 논문에서는 간단한 무작위(entity quantization) 방법이 현재 전략과 유사한 결과를 얻을 수 있다고 보여준다. 
    2. random entity quantization을 통해 다른 entity가 더 easily distinguish되는 것으로 분석하고, 이를 통해 effectve한 KG representation을 이룰 수 있다.
    3. 즉, KG representation에서 현재 quantization 전략은 중요하지 않으며, entity distinguishability 개선에는 여전히 개선의 여지가 있다.

###### Exploring All-In-One Knowledge Distillation Framework for Neural Machine Translation (https://aclanthology.org/2023.emnlp-main.178/)
- Anthology ID: 2023.emnlp-main.178 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존 지식추출(Knowledge Distillation, KD) 접근 방식은 경량화된 학생 모델을 한 번에 하나씩 얻지만, 동시에 다른 학생들이 필요한 경우 반복적으로 KD를 수행해야 하므로 자원을 많이 소비할 수 있다. 
    2. 이 논문에서는 한 번에 여러 개의 만족스러운 학생 모델을 생성하는 All-In-One Knowledge Distillation (AIO-KD) 프레임워크를 제안한다. 
    3. AIO-KD를 통해 여러 개의 서로 상호작용하는 학생 모델을 동시에 최적화하여 자원과 효능을 향상시킬 수 있다.

###### HistAlign: Improving Context Dependency in Language Generation by Aligning with History (https://aclanthology.org/2023.emnlp-main.179/)
- Anthology ID: 2023.emnlp-main.179 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어 모델(LMs)은 환각과 무결점이 있으며 문맥 종속성이 약한 문제를 가지고 있다. Cache-LMs는 최근 기록을 저장하여 문맥 종속성을 높일 수 있기 때문에 다양한 언어 생성 작업에서 우수한 성능을 보여주고 있다. 그러나 현재의 cache-LMs의 cache 구성요소로 인한 성능 향상이 부족하다는 문제점을 발견했다.
    
    2. 우리는 HistAlign이라는 새로운 훈련 접근 방식을 제안하여 모델이 기록에서 유용한 신호를 받을 수 있는 좋은 cache 정렬을 보장한다.
    
    3. 우리는 먼저 기록이 올바른 예측에 필수적인 단순하고 합성 과제에서 개념을 증명하고, HistAlign의 cache 구성요소가 더 잘 정렬되어 전체 성능을 향상시킨다는 것을 보여준다. 그다음, 우리는 prompt continuation, 추상적 요약, data-to-text 등 다양한 하위 언어 생성 작업에서 HistAlign을 평가한다. HistAlign이 열린 문맥 및 조건부 생성 환경에서 각각 텍스트 일관성과 충실성을 향상시킨다는 것을 입증한다. HistAlign은 다른 모델 유형에서 일반화되어 적용될 수 있으며, 다양한 시나리오에서 LMs의 문맥 종속성 향상에 강점을 보여준다.

###### CombLM: Adapting Black-Box Language Models through Small Fine-Tuned Models (https://aclanthology.org/2023.emnlp-main.180/)
- Anthology ID: 2023.emnlp-main.180 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 최근의 트렌드인 높은 품질의 모델이 API를 통해서만 사용 가능한 블랙박스로 되어있을 때, 파라미터를 수정하지 않고도 새로운 도메인과 과제에 대한 언어 모델을 적용하는 경량화된 방법을 제안한다. 
    2. 대규모 블랙박스 언어 모델과 작은 화이트박스 언어 모델을 작은 검증 데이터셋을 기반으로 학습한 작은 네트워크를 사용하여 확률 수준에서 결합시키는 방법을 사용한다.
    3. 실험 결과, 이 방법을 사용하여 대규모 언어 모델을 여러 도메인과 번역 과제에 적용하였을 때, 성능이 향상되는 것을 보여준다.

###### Image Manipulation via Multi-Hop Instructions - A New Dataset and Weakly-Supervised Neuro-Symbolic Approach (https://aclanthology.org/2023.emnlp-main.181/)
- Anthology ID: 2023.emnlp-main.181 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문에서는 자연어 텍스트를 통한 이미지 조작에 대해 다루며, 복합적인 다중 모달 공간 상에서의 복잡한 추론이 필요한 과제를 다룬다.
    2. Neuro Symbolic Concept Learning (NSCL)이라는 방법을 Visual Question Answering (VQA) 작업에서 제안된 것을 자연어를 통한 이미지 조작 작업에 확장한다.
    3. NeuroSIM은 약한 지도 데이터 형태인 VQA에 대한 주석이 포함된 데이터로 복잡한 다중 객체 장면에서 다중 홉 추론을 수행할 수 있으며, 심볼릭 프로그램을 생성하여 실행을 안내한다.

###### Generative Spoken Language Model based on continuous word-sized audio tokens (https://aclanthology.org/2023.emnlp-main.182/)
- Anthology ID: 2023.emnlp-main.182 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. NLP에서는 단어나 서브워드를 기반으로 한 텍스트 언어 모델이 character 기반 모델보다 우수한 성능을 보인다. 하지만 음성 커뮤니티에서는 입력이 20ms 또는 40ms 길이의 이산 단위 (phoneme보다 짧은)로 이루어지곤 한다. 이 논문에서는 단어 기반 언어 모델에서 영감을 얻어 word-size 연속값 오디오 토큰을 기반으로 하는 생성형 음성 언어 모델을 소개한다. 
    2. 기존의 단어 기반 언어 모델에 대한 데이터, 손실 함수, 샘플링 방법 등을 연속값을 기반으로 대체하여, 다양하고 표현적인 언어 출력을 생성할 수 있다.  
    3. 이 모델은 자동 평가 메트릭과 주관적인 인간 판단으로 측정된 생성 품질 면에서 이산 단위 기반 모델과 성능이 동등하면서, 200ms 단위의 큰 메모리를 사용하기 때문에 5배 더 메모리 효율적이다. 또한 Lexical Embedder 이전과 이후의 임베딩은 음운적 및 의미론적으로 해석 가능하다.

###### Enhancing Chat Language Models by Scaling High-quality Instructional Conversations (https://aclanthology.org/2023.emnlp-main.183/)
- Anthology ID: 2023.emnlp-main.183 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. ChatGPT와 같은 채팅 언어 모델에 대한 지시 데이터의 미세 조정은 효과적인 방법으로 널리 인정받고 있지만, 이 논문에서는 오픈 소스 모델의 상한선을 더욱 높이기 위한 연구를 진행한다고 밝혀졌다. 
    2. 연구진은 우선, 인간 쿼리를 포함하지 않는 Instructional 대화의 다양하고 정보성이 높은 대규모 데이터셋인 UltraChat을 개발하였다. 
    3. UltraChat을 기반으로 한 UltraLM 모델은 기존 오픈 소스 모델인 WizardLM, Vicuna 등을 능가하는 성능을 보여주었다.

###### Weakly-Supervised Learning of Visual Relations in Multimodal Pretraining (https://aclanthology.org/2023.emnlp-main.184/)
- Anthology ID: 2023.emnlp-main.184 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 시각-언어 사전학습 연구는 더 나은, 고도로 세분화된 다중모달 표현을 학습하기 위해 객체 탐지 데이터로부터의 지도 신호를 조사했다. 
    2. 본 연구에서는 이러한 방법을 한 걸음 더 나아가 작은 규모의 시각적 관계 데이터로부터 지도 신호를 추출하는 방법을 조사한다. 
    3. 우리는 구조화된 캡션으로 시각적 관계 쌍들을 변환하고, 이미지 설명으로 추가하여 시각적 개체를 다중 모달 설정에서 문맥화하는 두 가지 사전 학습 접근법을 제안한다.

###### Unsupervised Grammatical Error Correction Rivaling Supervised Methods (https://aclanthology.org/2023.emnlp-main.185/)
- Anthology ID: 2023.emnlp-main.185 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최신 문법 오류 수정(GEC) 시스템은 병렬 훈련 데이터(비문법적 문장과 그것들의 수동으로 수정된 반대방향 문장)에 의존하는데, 이는 구축 비용이 많이 든다. 
    2. 이 논문에서는 unsupervised GEC 시스템을 구축하기 위해 Break-It-Fix-It (BIFI) 방법을 사용한다. 
    3. 실험 결과는 우리의 GEC 시스템이 이전의 unsupervised GEC 시스템보다 우수하며, ensemble 없이도 supervised GEC 시스템과 성능이 비중화된다는 것을 보여준다.

###### S2abEL: A Dataset for Entity Linking from Scientific Tables (https://aclanthology.org/2023.emnlp-main.186/)
- Anthology ID: 2023.emnlp-main.186 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. entity linking (EL)은 지식 기반 NLP 애플리케이션에서 매우 중요한 텍스트 언급을 지식 베이스의 해당 항목에 연결하는 작업입니다. 이 논문에서는 scientific 논문의 테이블에 대한 EL을 위한 첫 번째 데이터셋을 제시합니다.
    2. Scientific Table Entity Linking (S2abEL) 데이터셋은 머신러닝 결과 테이블에서의 EL에 초점을 맞추고 있으며, PaperswithCode 택소노미의 8439개 셀에 대한 손으로 라벨링된 셀 유형, 소스 및 entity 링크가 포함되어 있습니다.
    3. 우리는 지식 베이스에 없는 많은 언급을 포함하는 scientific 테이블에 대한 EL을 위해 설계된 신경망 기준선 방법을 도입하고, 최첨단 범용 테이블 EL 방법보다 훨씬 뛰어난 성능을 보인다는 것을 보여줍니다. 최상의 베이스라인은 인간의 성능을 아래로 미치며, 분석 결과 개선 가능한 방향을 강조합니다.

###### API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs (https://aclanthology.org/2023.emnlp-main.187/)
- Anthology ID: 2023.emnlp-main.187 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 연구에서, 대형 언어 모델 (LLM)들이 외부 도구를 활용하여 능력을 향상시킬 수 있다는 것이 입증되었습니다. 그러나 세 가지 핵심적인 질문들에는 아직 대답이 되지 않았습니다.
    2. 우리는 GPT-3.5와 비교하여 GPT-3가 개발된 Alpaca에 비해 API 이용 능력이 향상되었음을 실험결과로 보여주고, GPT-4는 계획력에서 우수한 성과를 나타냈습니다.
    3. 그러나 더 발전할 여지는 여전히 많습니다. 또한, Lynx는 Alpaca의 도구 활용 성능을 26 이상으로 개선하였고, GPT-3.5의 효과성에 근접했습니다. 따라서 이 도메인에서 미래 연구에 대한 핵심적인 도전 과제를 강조합니다.

###### Language and Mental Health: Measures of Emotion Dynamics from Text as Linguistic Biosocial Markers (https://aclanthology.org/2023.emnlp-main.188/)
- Anthology ID: 2023.emnlp-main.188 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 감정 변화의 패턴인 감정 동태(emotion dynamics)는 정신 건강 상태를 나타낼 수 있다는 것을 심리병리학 연구에서 보여주었다.
    2. 우리는 유저의 트윗에서 추출한 감정 동태 지표 (UED metrics)와 정신 질환과의 관계를 분석한 첫번째 연구이다.
    3. 우리는 UED metrics가 사용자의 진단된 정신 질환과 유의미한 상관관계를 갖는다는 것을 발견했으며, 감정 동태 언어적 cue들이 정신 질환의 이해, 진단 및 관리에 중요한 역할을 할 수 있다는 것을 보여준다.

###### Lion: Adversarial Distillation of Proprietary Large Language Models (https://aclanthology.org/2023.emnlp-main.189/)
- Anthology ID: 2023.emnlp-main.189 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 고급 상용 LLM에서 경량 오픈소스 LLM으로의 지식 전달(practicing knowledge transfer)이 많은 관심을 받고 있다. 그러나 현재의 기술은 학생 모델의 성능이 부족한 과제를 찾아내어 이를 향상시키는 "피드백"을 통합하는 가능성을 간과하고 있다. 
    2. 본 논문에서는 새로운 적대적 전달 프레임워크를 제안하여 강사 모델이 "어려운" 과제를 식별하고 학생 모델을 위해 새로운 "어려운" 과제를 생성하도록 한다. 
    3. 이 적대적 프레임워크를 적용하여 70k 학습 데이터로 ChatGPT에서 학생 모델(Lion)로 지식을 성공적으로 전달하였으며, Lion-13B는 ChatGPT와 유사한 성능을 가지며 BIG-Bench Hard, AGIEval과 같은 어려운 문제에서 Vicuna-13B와 비교하여 성능을 크게 개선하였다.

###### Evaluating Large Language Models on Controlled Generation Tasks (https://aclanthology.org/2023.emnlp-main.190/)
- Anthology ID: 2023.emnlp-main.190 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 연구들은 질문 생성, 읽기 이해력, 다국어 등 다양한 기준 작업에서 대형 언어 모델들의 능력을 조사했으나, 생성 작업에서의 대형 언어 모델의 컨트롤 가능성에 대해 연구가 부족하다.
    2. 우리는 문장 계획을 포함한 다양한 벤치마크를 사용하여 대형 언어 모델과 최신 피니튜닝 작은 모델을 비교한 후, 대형 언어 모델이 작은 모델의 능력을 뒤지거나 비교 가능하거나 초월하는 것을 나타내는 스펙트럼을 제시한다.
    3. 우리는 대형 언어 모델이 세부적인 제약 조건을 충족시키기 어렵다고 결론을 내렸다.

###### DeSIQ: Towards an Unbiased, Challenging Benchmark for Social Intelligence Understanding (https://aclanthology.org/2023.emnlp-main.191/)
- Anthology ID: 2023.emnlp-main.191 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사회적 지능은 인간의 표현, 의도, 상호작용에 대한 이해와 추론에 필수적이다. 이 분야의 연구를 위한 대표적인 벤치마크 중 하나는 복잡한 사회적 상호작용 영상에 대한 다중 선택 문제를 포함하는 Social-IQ 데이터셋이다. 
    2. 우리는 Social-IQ의 타당성을 연구하기 위한 철저한 방법론을 정의한다. 벤치마크 데이터셋의 타당성은 연구 문제를 조사하는 데 중요하다. 
    3. 우리의 분석 결과, Social-IQ에는 상당한 편향성이 존재하며, 중간 정도의 강한 언어 모델이 맥락이나 질문 없이도 완벽한 성능을 달성하기 위해 편향된 상관관계를 학습할 수 있음을 보여준다. 이에 우리는 Social-IQ에 간단한 변조를 가하여 새로운 도전적인 데이터셋인 DeSIQ를 소개한다.

###### Why LLMs Hallucinate, and How to Get (Evidential) Closure: Perceptual, Intensional, and Extensional Learning for Faithful Natural Language Generation (https://aclanthology.org/2023.emnlp-main.192/)
- Anthology ID: 2023.emnlp-main.192 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. LLMs는 증거적 폐쇄(evidential closure) 조건에 의해 제한되지 않기 때문에 환각을 갖게 된다. 즉, LLM의 출력은 그들이 증거를 가진 주장과 동의어적이지 않아도 된다는 것이다.
    2. 우리는 LLM들이 증거적 폐쇄를 만족시키는 출력을 생성하도록 제한하는 방법을 제안한다.
    3. 실제로 검증된 증거 집합과 동의어적인 출력을 갖는 출력으로부터 충실한 결과를 얻기 위해 Learn-Babble-Prune라는 휴리스틱 절차를 제안한다.

###### A Question Answering Framework for Decontextualizing User-facing Snippets from Scientific Documents (https://aclanthology.org/2023.emnlp-main.193/)
- Anthology ID: 2023.emnlp-main.193 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "많은 실제 응용 프로그램들(예: 노트 정리, 검색)에서는 문서에서 문장이나 단락을 추출하고 원본 문서 외부에서 인간에게 그 스니펫을 제공하는 것이 필요하다. 그러나 사용자들은 원본 문서의 문맥을 갖지 못하여 스니펫을 이해하기 어려울 수 있다." 
    2. "우리는 언어 모델을 사용하여 과학 문서의 스니펫을 독립적으로 읽을 수 있게 다시 작성하는 작업을 수행한다. 이를 위해 사용자 중심의 이 문맥 특화 작업을 수행하기 위한 요구사항과 과제를 정의한다."
    3. "우리는 질문 생성, 질문 답변, 문장 다시 작성으로 작업을 분해하는 프레임워크를 제안하며, state-of-the-art 상업용 및 오픈소스 언어 모델을 사용하여 여러 실험을 수행한다".

###### SLOG: A Structural Generalization Benchmark for Semantic Parsing (https://aclanthology.org/2023.emnlp-main.194/)
- Anthology ID: 2023.emnlp-main.194 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 구성적 일반화 기준은 모델이 새로운 복잡한 언어 표현에 얼마나 잘 일반화하는지를 평가하는 것을 목표로 한다. 그러나 기존 벤치마크는 종종 훈련에서 익숙한 문법 구조에서 새로운 어휘 항목의 해석에 초점을 맞추고, 훈련에서 익숙하지 않은 문법 구조의 일반화 작업은 종종 미흡하게 다루어지며 모델이 얼마나 잘 일반화할 수 있는지에 대한 overly optimistic perceptions을 만들어낸다.
    2. 우리는 17개의 구조적 일반화 케이스를 포함한 COGS를 확장한 의미 파싱 데이터셋인 SLOG을 소개한다.
    3. 실험에서, 사전 훈련된 Transformer 모델들을 포함한 일반화 정확도는 40.6%에 불과하며 구조를 고려한 파서는 70.8%만 달성한다. 이 결과는 기존 모델이 COGS에서 거의 완벽한 정확도를 달성하는 것과는 거리가 멀며, SLOG가 모델의 어휘적 일반화 능력과 구조적 일반화 능력 간의 큰 차이를 강조하는 역할을 한다.

###### Pushdown Layers: Encoding Recursive Structure in Transformer Language Models (https://aclanthology.org/2023.emnlp-main.195/)
- Anthology ID: 2023.emnlp-main.195 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인간의 언어에는 재귀적인 특징이 있으며, 이는 명시적인 재귀 상태 추적 메커니즘이 없는 self-attention에 대해서 근본적인 도전이다.
    2. 이 논문에서는 recursive state를 추적하기 위해 stack tape를 이용한 새로운 self-attention layer인 Pushdown Layers를 제안한다. Pushdown Layers를 사용한 Transformer LMs는 재귀적 언어 모델로, 새로운 토큰을 예측하면서 stack tape를 업데이트하고 토큰들에 대한 attention을 부드럽게 제어한다.
    3. Pushdown Layers를 적용한 Transformers는 훨씬 더 효과적이고 샘플 효율적인 구문적 일반화를 달성하며, perplexities는 유지하면서 GLUE 텍스트 분류 작업에서 향상되는 결과를 얻었다.

###### Can LLMs Facilitate Interpretation of Pre-trained Language Models? (https://aclanthology.org/2023.emnlp-main.196/)
- Anthology ID: 2023.emnlp-main.196 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사전 훈련된 언어 모델의 지식을 파악하기 위한 연구는 주로 주석이 달린 말뭉치나 사람을 통한 방법을 사용한다. 
    2. 우리는 대규모 언어 모델인 ChatGPT를 주석 달기 도구로 사용하여 사전 훈련된 언어 모델의 세밀한 해석 분석을 가능케 한다. 
    3. 우리의 연구 결과는 ChatGPT가 인간 주석보다 정확하고 의미론적으로 더 풍부한 주석을 생성한다는 것을 보여준다. 또한 GPT 기반의 주석이 해석 분석 방법론을 강화하는 데 어떻게 도움이 되는지도 보여준다.

###### Enhancing Low-resource Fine-grained Named Entity Recognition by Leveraging Coarse-grained Datasets (https://aclanthology.org/2023.emnlp-main.197/)
- Anthology ID: 2023.emnlp-main.197 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Named Entity Recognition (NER)에서는 레이블된 데이터가 부족한 문제가 자주 발생한다. 기존의 K-shot learning 기술을 적용할 수 있지만, 어노테이션의 수가 수십 개가 넘으면 그 성능은 포화되기 쉽다.
    2. 이 논문에서는 그 문제를 해결하기 위해 수 많은 어노테이션을 제공하는 coarse-grained 데이터셋을 활용한다. 그러나, 기존의 pre-finetuning 방법은 coarse-grained 데이터를 표현 학습에 사용할 수 있게 해줄 뿐이며, fine-grained와 coarse-grained entities 사이의 관계를 직접적으로 활용하지는 못하는 문제가 있다.
    3. 이 논문에서는 F2C (Fine-to-Coarse) 매핑 행렬을 사용한 fine-grained NER 모델을 제안하였고, 또한 fine-grained entity가 coarse-grained entity의 하위 카테고리일 가능성이 높기 때문에 이러한 계층 구조를 명시적으로 활용한다. 추가로 fine-grained entity 타입과 일치하지 않는 coarse-grained entity를 걸러내는 inconsistency filtering 방법을 제시하여 성능 저하를 방지한다. 실험 결과에서 소수의 fine-grained 어노테이션을 처리할 때 우리의 방법이 K-shot learning 및 지도 학습 방법보다 우월한 성능을 보였다.

###### Oolong: Investigating What Makes Transfer Learning Hard with Controlled Studies (https://aclanthology.org/2023.emnlp-main.198/)
- Anthology ID: 2023.emnlp-main.198 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사전 훈련된 언어 모델을 새로운 언어로 전이할 때, 문법적 유사성과 어휘적 유사성과 같은 다양한 요인들이 동시에 변하게 된다. 이 논문에서는 GLUE 벤치마크의 언어를 체계적으로 변형하여 교차언어적 변이의 한 축을 변경한 후, 사전 훈련된 모델의 후속 성능 저하를 측정함으로써 다른 요인들의 영향을 분리하기 위한 제어된 전이 연구 세트를 제안한다.
    
    2. 문법적 스타일의 변화에서 모델은 대부분 회복될 수 있지만, 어휘의 불일치와 임베딩 행렬 재초기화에서는 사전 훈련된 모델의 성능이 회복되지 않으며, 지속적인 사전 훈련을 해도 회복되지 않는다는 것을 발견했다.
    
    3. 또한, 전이 언어에서 좋은 품질의 토크나이저는 어휘 정렬을 쉽게하지 않는다. 우리의 실험은 언어 전이 시나리오를 설계할 때 연구자들이 가장 집중해야 할 교차언어적 전이 요소에 대한 통찰력을 제공한다.

###### Non-Autoregressive Math Word Problem Solver with Unified Tree Structure (https://aclanthology.org/2023.emnlp-main.199/)
- Anthology ID: 2023.emnlp-main.199 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존 MWP 문제 해결 모델들은 문제를 표현하고 해결 방법을 파악하기 위해 순차적이거나 이진 트리 구조를 사용하지만, 이러한 구조는 수학적으로 변형 가능한 경우를 처리할 수 없다. 
    2. 이 논문에서는 표현식의 다양한 해결 방법을 표현하기 위해 통합된 트리 구조를 도입하고, 이를 기반으로 문제를 해석하고 해결 방법을 유추하는 비자기적인 (non-autoregressive) 모델을 제안한다. 
    3. 또한, 통합된 트리의 가능한 표현식들을 평가하기 위해 경로 기반 메트릭을 설계하여 제안된 모델의 효과를 실험을 통해 입증하였다.

###### Improving Chinese Pop Song and Hokkien Gezi Opera Singing Voice Synthesis by Enhancing Local Modeling (https://aclanthology.org/2023.emnlp-main.200/)
- Anthology ID: 2023.emnlp-main.200 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 가사와 악보를 기반으로 잘 들리는 보컬을 합성하는 데 사용되는 "노래 부르기 합성 (SVS)" 기술에서, 기존의 Transformer 기반 음향 모델은 전체 순서를 전역적으로 처리하고 간단한 L1 손실을 사용한다. 그러나, 이 방식은 순서 내에서의 로컬 모델링과 예측된 멜 스펙트로그램의 어려운 부분에 대한 로컬 최적화의 중요성을 간과한다.
    2. 이 문제를 해결하기 위해, 본 논문에서는 음향 모델에서 로컬 모델링을 개선하기 위한 두 가지 방법을 제안한다. 첫째로, 주변의 동음이의어 토큰에만 초점을 두는 가장 가까운 이웃 로컬 어텐션을 개발한다. 둘째로, 어려운 부분에 더 초점을 맞추기 위한 음소 수준의 로컬 적응적 가중치 손실 함수를 제안한다.
    3. 공개된 중국 팝 음악 및 Hokkien Gezi 오페라 데이터셋에서 우리의 방법의 일반성을 검증하였으며, 실험 결과는 강력한 기준과 비교했을 때 목적적 및 주관적 평가에서 상당한 향상을 보여주었다.

###### What Else Do I Need to Know? The Effect of Background Information on Users’ Reliance on QA Systems (https://aclanthology.org/2023.emnlp-main.201/)
- Anthology ID: 2023.emnlp-main.201 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. NLP 시스템은 관련 콘텍스트를 검색하여 질문에 대답하는 데에서 인상적인 성능을 보여주고 있다. 하지만 점점 커져가는 모델의 크기 때문에 모델의 지식이나 추론을 검색된 콘텍스트에만 제한하는 것은 불가능하고 종종 바람직하지 않다. 이는 모델의 답변 도출에 액세스하는 정보와 사용자가 평가하는 데 사용 가능한 정보간의 불일치를 야기한다.
    2. 본 연구에서는 사용자가 예측을 평가하기에 충분한 정보가 없는 상황에서 QA 시스템과 상호작용하는 방법을 연구하며, 필요한 백그라운드를 추가하면 사용자들이 예측에 과도하게 의존하는 것을 완화시킬 수 있는지 알아보고자 한다.
    3. 우리의 연구는 사용자들이 모델의 정확성을 평가하기에 충분한 정보가 없는 경우에도 모델 예측에 의존한다는 것을 밝혀냈다. 하지만 관련 백그라운드를 제공하는 것은 사용자가 모델의 오류를 더 잘 파악하고 잘못된 예측에 대한 과도한 의존성을 줄이는 데 도움이 된다.

###### GROOViST: A Metric for Grounding Objects in Visual Storytelling (https://aclanthology.org/2023.emnlp-main.202/)
- Anthology ID: 2023.emnlp-main.202 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 시각적인 이야기에 대한 평가는 일관성, 문법적 정확성, 그리고 시각적인 연결성 등 다양한 측면을 고려해야 한다. 
    2. 문제점이 있는 기존 메트릭들을 분석한 결과, 우리는 cross-modal dependencies, temporal misalignment, 그리고 시각적인 연결성에 대한 인간의 직관을 고려한 새로운 평가 도구인 GROOViST를 제안한다. 
    3. GROOViST는 각 구성 요소의 기여도를 개별적으로 평가하고 해석할 수 있는 모듈식 설계의 장점을 갖고 있다.

###### VIBE: Topic-Driven Temporal Adaptation for Twitter Classification (https://aclanthology.org/2023.emnlp-main.203/)
- Anthology ID: 2023.emnlp-main.203 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 실세계 소셜 미디어에서 언어 특성이 계속 변화함에 따라 동적인 텍스트 분류의 성능이 저하되고 있다. 이 논문에서는 시간적 적응을 연구하여 과거 데이터에 기반한 모델을 미래에서 테스트하는 방법을 제안한다. 
    2. 기존의 연구는 계속된 사전학습이나 지식 갱신에 초점을 맞추었으나 이는 소셜 미디어 데이터에서의 성능을 저하시킬 수 있다. 따라서 본 논문에서는 잠재 주제 변화를 모델링하여 특징 변화를 반영하는 방법을 제안한다.
    3. 실험 결과, VIBE 모델은 3%의 데이터만을 사용해 이전의 최신 기법들보다 훨씬 우수한 성능을 보였다.

###### TOD-Flow: Modeling the Structure of Task-Oriented Dialogues (https://aclanthology.org/2023.emnlp-main.204/)
- Anthology ID: 2023.emnlp-main.204 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에는 사전 훈련된 언어 모델 (pre-trained language model; PLM)을 사용한 대화 시스템이 중요한 요소로 사용되고 있지만, 투명성과 조절 가능성에 제한이 있다. 
    2. 이 논문에서는 대화 흐름 그래프를 추론하여 그래프 형태로 대화 데이터를 주석으로 어노테이션하고, 시스템이 예측을 할 때 예측 성능, 투명성 및 조절 가능성을 향상시키기 위해 대화 모델에 바로 통합할 수 있는 TOD-flow 그래프를 제안한다.
    3. 실험에서 이 방법이 사람이 주석을 단 그래프와 더 유사하게 추론되었으며, MultiWOZ와 SGD 벤치마크에서 대화 행위 분류 및 end-to-end 응답 생성 성능이 크게 향상되었다는 것을 보여준다.

###### TopWORDS-Poetry: Simultaneous Text Segmentation and Word Discovery for Classical Chinese Poetry via Bayesian Inference (https://aclanthology.org/2023.emnlp-main.205/)
- Anthology ID: 2023.emnlp-main.205 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 고전 중국 시에는 일반 중국어 텍스트에 흔히 나오지 않는 특수한 단어가 자주 사용되기 때문에, 자연어 처리에 큰 어려움이 있다. 
    2. 이 연구는 사전이나 훈련 말뭉치 없이도 고전 중국 시의 신뢰할 수 있는 텍스트 구분과 단어 발견을 동시에 수행할 수 있는 비지도 학습 방법인 TopWORDS-Poetry를 제안한다. 
    3. 실험 결과는 TopWORDS-Poetry가 Complete Tang Poetry의 고정 시에 존재하는 고유한 시어(이름 있는 단체와 문학적 언급 등)를 성공적으로 인식하고 의미 있는 단어로 나눌 수 있다는 것을 확인한다.

###### Knowledge Rumination for Pre-trained Language Models (https://aclanthology.org/2023.emnlp-main.206/)
- Anthology ID: 2023.emnlp-main.206 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 사전 훈련된 언어 모델(PLM)은 지식 집약적인 NLP 태스크를 처리하는 능력이 부족하다는 것이 밝혀져 왔으며, 몇 가지 연구에서는 외부 지식을 PLM에 통합하는 시도를 하였다. 
    2. 그러나, 유망한 결과를 보이더라도, PLM은 이미 사전 훈련된 매개변수에 풍부한 지식을 인코딩하고 있음에도 불구하고, 지식 집약적인 태스크에 적용할 때 그것을 충분히 활용하지 못한다는 것을 경험적으로 관측하였다. 
    3. 이 논문에서는 PLM이 외부 말뭉치에서 다시 검색하지 않고도 관련된 잠재적 지식을 활용하도록 돕기 위해 "내가 아는 한"과 같은 프롬프트를 PLM에 추가하는 새로운 패러다임인 "Knowledge Rumination"을 제안하고 있다.

###### Struct-XLM: A Structure Discovery Multilingual Language Model for Enhancing Cross-lingual Transfer through Reinforcement Learning (https://aclanthology.org/2023.emnlp-main.207/)
- Anthology ID: 2023.emnlp-main.207 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "크로스-언어 전이 학습은 잘 맞춰진 크로스-언어 표현에 많이 의존하는데, 문법 구조는 크로스-언어 전이에 유리하다고 알려져 있지만, 다국어 사전 훈련 언어 모델에서는 이를 활용한 연구가 제한적이다."
    2. "우리는 이러한 문제를 해결하기 위해 Sturct-XLM이라고 불리는 새로운 다국어 언어 모델을 제안한다. 이 모델은 강화학습을 활용하여 PLM의 크로스-언어 표현 정렬을 개선하기 위해 범용 문법 구조를 자동으로 발견하는 기능을 가지고 있다."
    3. "실험 결과, 우리의 접근법은 XTREME 벤치마크에서 다국어 PLM의 크로스-언어 전이를 향상시키는데 효과적임을 보여주었다."

###### AdaSent: Efficient Domain-Adapted Sentence Embeddings for Few-Shot Classification (https://aclanthology.org/2023.emnlp-main.208/)
- Anthology ID: 2023.emnlp-main.208 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 연구에서는 사전 학습된 Sentence Encoders (SEs)를 기반으로 한 몇 개의 데이터만을 가지고 문장 분류를 효과적으로 수행하는 것이 효율적이고 강건한 것으로 나타났다. 
    2. 이 연구에서는 몇 개의 데이터만 가지고도 효과적으로 도메인에 특화된 문장 분류를 수행하기 위한 전략을 조사한다.
    3. 기존의 SEs에 DAPT(Domain-Adaptive Pre-Training)을 적용하는 것은 효과적이지만 비효율적이므로, AdaSent라는 방법을 제안한다. AdaSent는 SE를 위해 DAPT-ed PLMs에 SEPT(Sentence Embedding Pre-Training) 어댑터를 추가하여 training cost를 크게 감소시키면서도 성능을 유지한다.

###### Interview Evaluation: A Novel Approach for Automatic Evaluation of Conversational Question Answering Models (https://aclanthology.org/2023.emnlp-main.209/)
- Anthology ID: 2023.emnlp-main.209 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화형 질문 답변(CQA)은 정보 검색 대화에서 사용자에게 자연어 답변을 제공하는 것을 목표로 한다. 기존의 CQA 벤치마크들은 전처리된 사람-사람 대화를 사용하여 모델을 평가한다.
    2. 하지만 모델이 예측한 대화 내용을 정답으로 대체하는 것은 CQA 평가의 자연성과 지속 가능성을 떨어뜨린다.
    3. 이 논문에서는 대화형 평가 방식으로 인터뷰 평가라는 새로운 자동 평가 방법을 제안한다. 이 방법은 ChatGPT가 인터뷰어(Q agent) 역할을 하고 CQA 모델이 인터뷰이(A agent) 역할을 한다.

###### TCFLE-8: a Corpus of Learner Written Productions for French as a Foreign Language and its Application to Automated Essay Scoring (https://aclanthology.org/2023.emnlp-main.210/)
- Anthology ID: 2023.emnlp-main.210 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자동 에세이 채점(Automated Essay Scoring, AES)은 에세이의 품질을 자동으로 평가하는 것을 목표로 한다. AES를 통해 규모 있는 채점, 일관성, 신뢰성, 표준화의 개선이 가능하다. 하지만 AES 시스템 개발의 주요 병목은 코퍼스의 부족이다.
    2. 이 논문에서는 TCFL-8 코퍼스를 제공함으로써 AES를 프랑스어에 적용하는 것을 촉진하고자 한다. 이를 위해 6.5k개의 에세이를 수집하고, CEFR 수준에 따라 최소한 두 명의 채점자가 각 에세이를 채점하고 균형 있는 코퍼스를 작성하는 엄격한 절차를 보고한다.
    3. 또한, 에세이의 언어적 특성과 학습자의 능력과의 관련성, 그리고 RoBERTa와 feature 기반의 두 가지 강력한 베이스라인을 실험하여 프랑스어 AES 작업의 최신 기술 결과를 제시한다. 마지막으로, TCFL-8을 사용한 AES의 도전과제에 대해서 논의한다.

###### Dancing Between Success and Failure: Edit-level Simplification Evaluation using SALSA (https://aclanthology.org/2023.emnlp-main.211/)
- Anthology ID: 2023.emnlp-main.211 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델(GPT-4)은 높은 텍스트 간소화 품질을 제공할 수 있으나, 기존의 인간 평가 방법은 시스템의 특정 강점과 약점을 명확히 제시할 수 없는 한계가 있다.
    2. 이를 극복하기 위해, 우리는 일관성 있고 상세한 텍스트 간소화 평가를 가능하게 하는 수정 기반 인간 주석 툴인 SALSA를 소개한다.
    3. 우리는 SALSA를 사용하여 840개의 간소화 문장에 대해 19,000개의 수정 주석을 수집하였고, 하이퍼 파라미터 튜닝된 모델, LLM 및 인간 간소화 전략의 분포에서 차이를 밝혀내었으며, GPT-3.5는 인간보다 더 품질 좋은 수정을 수행하지만 여전히 빈번한 오류를 보여준다.

###### Confidence-based Ensembling of Perspective-aware Models (https://aclanthology.org/2023.emnlp-main.212/)
- Anthology ID: 2023.emnlp-main.212 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 NLP 연구는 어노테이션 작업을 수행할 때 사람들이 라벨을 선택하는데 보여주는 변동성에 집중하고 있다. 어노테이션에서의 의견의 불일치를 활용하면 정확한 모델링과 공정한 평가에 이점이 있다는 것이 입증되었다.
    2. 이 논문에서는 자연어 문장의 지도 분류를 위한 강한 퍼스펙티비스트(perspectivist) 모델을 제안한다. 접근 방식은 플러 학습된 모델의 예측을 결합하여 언어 현상의 어노테이션에 인코딩된 주관성을 포착하기 위해 각 모델의 개별 신뢰도 관련 정보를 사용한다.
    3. 실험 결과는 (1) 아이러니와 혐오 발언 감지 두 가지 케이스 스터디에서, (2) 인도메인 및 크로스 도메인 설정에서 신뢰도 기반의 퍼스펙티비스트 모델의 앙상블이 모든 시나리오에서 분류 성능에 유리하다는 것을 보여준다. 또한, 어노테이터 메타데이터를 사용할 수 없을 때 어노테이션으로부터 자동으로 추출된 퍼스펙티브의 효과적인지도 데모를 제시한다.

###### ToViLaG: Your Visual-Language Generative Model is Also An Evildoer (https://aclanthology.org/2023.emnlp-main.213/)
- Anthology ID: 2023.emnlp-main.213 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 대형 비주얼-언어 생성 모델은 이미지/텍스트 생성에서 과거에 없었던 큰 발전을 이루었지만, 이러한 모델들은 독성 콘텐츠, 예를 들어 모욕적인 텍스트나 음란한 이미지를 생성할 수도 있어 윤리적인 위험성을 제기하고 있다. 
    2. 이 연구는 시각-언어 생성에서 독성 생성의 경향성과 독성 데이터에 대한 감수성을 다양한 VLGMs 상에서 탐색한다. 
    3. 우리는 시각-언어 생성에 맞춤화된 독성 메트릭인 WInToRe를 제안하고, 다양한 VLGMs의 독성을 평가하여 일부 모델들이 기대 이상의 독성을 가지고 있다는 사실을 발견하였으며, 독성 제거가 필요하다는 점을 강조한다.

###### GPT-RE: In-context Learning for Relation Extraction using Large Language Models (https://aclanthology.org/2023.emnlp-main.214/)
- Anthology ID: 2023.emnlp-main.214 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 큰 언어 모델(Large Language Models, LLM)은 in-context learning (ICL)을 통해 혁신적인 성과를 낼 수 있지만, 관계 추출 (RE)에서는 fully-supervised 기준에 비해 큰 차이가 난다. 
    2. 이 논문에서는 task-aware한 representation을 사용하여 ICL의 entity와 relation에 대한 관련성을 높이고, 골드 라벨로 유도된 추론 로직을 포함시켜 RE 작업을 수행하는 GPT-RE를 제안한다. 
    3. GPT-RE는 Semeval과 SciERC 데이터셋에서 SOTA 결과를 얻으며, TACRED와 ACE05 데이터셋에서도 경쟁력 있는 결과를 보여준다. 또한, NULL 예제를 잘못 분류하는 문제도 GPT-RE를 통해 상당히 완화되었다.

###### Sociocultural Norm Similarities and Differences via Situational Alignment and Explainable Textual Entailment (https://aclanthology.org/2023.emnlp-main.215/)
- Anthology ID: 2023.emnlp-main.215 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 문화 간 추론을 할 수 있는 시스템을 개발하기 위해서는 해당 문화의 표준에 기반을 둬야 한다. 하지만 현재 사회 규범의 컴퓨터 모델에 대한 연구는 주로 미국 사회에 초점을 맞추고 있다. 
    2. 이 논문은 중국문화와 미국문화 간에 기술적, 문화적 차이를 발견하고 비교하기 위해 중국의 Q&A 플랫폼과 SocialChemistry 데이터셋을 활용한 새로운 접근 방식을 제안한다. 
    3. 반응적 학습을 통해 텍스트에서 사회규범을 추출하고 중국문화와 미국문화 간의 사회규범을 비교하는 높은 품질의 데이터셋을 구축하였다. 이 데이터셋을 활용하여 문화 간 사회규범 추론의 성능을 평가하고, 이를 토대로 문화 간 규범의 차이를 분석하였다.

###### INFORM : Information eNtropy based multi-step reasoning FOR large language Models (https://aclanthology.org/2023.emnlp-main.216/)
- Anthology ID: 2023.emnlp-main.216 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "큰 언어 모델들은 공들여 만든 Chain-of-Thought (CoT) 프롬프트로 추론 태스크에서 뛰어난 성능을 보여주었다. 하지만, CoT 프롬프트의 효과는 다른 인-컨텍스트 예제의 선택에 따라 크게 변동할 수 있다. 또한, 사람이 루트 스텝을 수동으로 작성하는 것은 시간이 많이 소요되어 CoT 프롬프트의 보급에 어려움을 겪고 있다." 
    2. "이 논문에서는 정보 엔트로피를 CoT 프롬프트 선택 기준으로 도입하는 새로운 방법을 제안한다. 정보 엔트로피 점수가 더 높은 CoT 프롬프트를 자동으로 생성하고 적절한 샘플의 개수를 적응적으로 결정하는 방법을 소개한다. 이 세 단계를 통합한 우리의 제안된 INFORM 방법은 GPT-3.5-Turbo 및 text-davinci-003 이라는 두 가지 언어 모델을 사용하여 일곱 가지 추론 벤치마크에서 실험을 진행하였는데, 이 실험에서 INFORM이 성능과 효율성 측면에서 우수함을 입증하였다."
    3. "INFORM은 제안된 정보 엔트로피 기반의 다단계 추론 방법으로서, CoT 프롬프트 생성, CoT 프롬프트 선택, 추론 세 가지 단계에서 각각 정보 엔트로피를 활용하여 큰 언어 모델의 추론 성능을 향상시키는 접근 방법이다."

###### Adaptive Gating in Mixture-of-Experts based Language Models (https://aclanthology.org/2023.emnlp-main.217/)
- Anthology ID: 2023.emnlp-main.217 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다양한 NLP 태스크에서 대형 언어 모델들은 탁월한 언어 이해 능력을 보여주고 있다. 그러나 기존의 MoE (mixture-of-experts) 모델은 고정된 게이팅 네트워크를 채택하고 있어 각 토큰이 동일한 수의 전문가들에 의해 계산된다. 이는 각 시퀀스의 토큰들이 언어적 복잡성과 관련하여 다른 계산 비용을 필요로 한다는 직관과 상반된다.
    2. 이 논문은 MoE에 적응형 게이팅을 도입하여 각 토큰이 전문가의 확률 분포에 따라 가변적인 수의 전문가에 의해 처리될 수 있는 유연한 훈련 전략을 제안한다. 적응형 게이팅은 희소성을 보존하면서 훈련 효율성을 개선한다.
    3. 실험 결과 적응형 게이팅은 최대 22.5%의 훈련 시간을 단축시키면서 추론 품질을 유지한다는 것을 보여주며, 게이팅 결정에 대한 포괄적인 분석을 통해 특정 언어 작업에 어려운 토큰들을 파악한다.

###### On the Automatic Generation and Simplification of Children’s Stories (https://aclanthology.org/2023.emnlp-main.218/)
- Anthology ID: 2023.emnlp-main.218 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 대형 언어 모델 (LLMs)의 발전으로 인해 어린이 교육 자료를 자동으로 생성하는 개념이 점점 현실적으로 이루어지고 있다. 
    2. 이 연구에서는 어린이를 대상으로 한 텍스트의 어휘와 가독성 수준을 적절하게 조절하여 이야기를 생성할 수 있는 인기있는 LLM들의 능력을 조사한다.
    3. 그러나 LLM들은 아직 어린이 연령대에 적합한 어휘를 제한할 수 있는 능력이 없으며, 현재 가장 좋은 성능을 보이는 어휘 단순화 모델들도 LLM에 의존하는 한계 때문에 어린이를 대상으로 한 자료에서 좋은 성능을 내지 못한다는 것을 발견했다.

###### When Do Decompositions Help for Machine Reading? (https://aclanthology.org/2023.emnlp-main.219/)
- Anthology ID: 2023.emnlp-main.219 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 복잡한 질문에 대답하기 위해서는 보통 다단계 추론이 필요하지만, 기계 독해모델에서 복잡한 질문을 분해하는 연구는 미흡한 상태이다.
    2. 우리는 머신 독해모델에서 분해가 언제 유용한지를 이해하기 위해 다양한 모델과 데이터셋을 사용하여 실험을 진행하였다. 
    3. 우리는 분해가 적은 데이터셋에서는 정확도를 향상시킬 수 있음을 발견하였으나, 수백개 이상의 예제를 가지고 있는 경우에는 분해가 도움이 되지 않을 수 있다는 것을 보였다.

###### The Curious Case of Hallucinatory (Un)answerability: Finding Truths in the Hidden States of Over-Confident Large Language Models (https://aclanthology.org/2023.emnlp-main.220/)
- Anthology ID: 2023.emnlp-main.220 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델(Large language models)은 놀라운 성능을 보여주지만, 그들의 응답의 신뢰성에 대한 우려가 제기되고 있다. 이 연구는 (불)가능한 질의문에 대한 LLM의 행동을 탐색한다. 
    2. 연구 결과는 모델이 창작된 답을 생성할 때 질문이 (불)가능한지를 반영한다는 강한 증거를 보여준다. 특히, 첫 번째 디코딩 토큰의 표현은 강한 지표이다. 
    3. 이러한 발견은 LLM의 잠재적 표현 내에서의 공간적 구성에 대해 새로운 시각을 제공하며, 질의문 (불)가능성이 관련된 경우 사실적 생성에 더 잘 따르는 개선된 디코딩 기법의 개발을 위한 기반이 된다.

###### Identifying Informational Sources in News Articles (https://aclanthology.org/2023.emnlp-main.221/)
- Anthology ID: 2023.emnlp-main.221 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 뉴스 기사는 기자들이 보도에 사용한 정보 소스에 의해 주도된다. 이 논문에서는 이러한 소스가 언제, 어떻게, 왜 함께 사용되는지 모델링함으로써 우리가 소비하는 정보를 더 잘 이해하고 기사를 작성하는 기자들에게 도움을 줄 수 있다고 주장한다.
    2. 이 논문에서는 정보 검출과 소스 어트리뷰션을 위해 사용된 최대 및 가장 폭넓은 주석이 달린 데이터셋을 만들었음을 보여준다. 이 데이터셋을 사용하여 다양한 소스가 뉴스 기사에서 어떻게 선택되어 함께 사용되는지 조사하는 새로운 작업인 소스 예측을 제안한다.
    3. 이 작업에서 모델은 소스들이 뉴스 스토리텔링에서 어떻게 함께 사용되는지에 대한 패턴이 있다는 것을 보여주며, 이를 통해 이후에는 서술 기반 언어 생성을 위한 소스에 중점을 두고 연구하는 것과 정보를 돕기 위한 소스 추천 시스템을 포함한 컴퓨터 기반 기자학 연구에 집중할 수 있다.

###### Retrofitting Light-weight Language Models for Emotions using Supervised Contrastive Learning (https://aclanthology.org/2023.emnlp-main.222/)
- Anthology ID: 2023.emnlp-main.222 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 우리는 BERT와 RoBERTa와 같은 사전 훈련된 언어모델에 감정 측면을 도입하기 위한 새로운 retrofitting 방법을 제안한다. 
    2. 이 방법은 비슷한 감정을 나타내는 텍스트 조각들이 표현 공간에서 가까이 인코딩되고, 다른 감정을 가진 조각들은 멀리 떨어지도록 사전 훈련된 네트워크 가중치를 업데이트한다. 
    3. 이렇게 하면 PLM에 이미 존재하는 언어적 지식이 의도치 않게 변하지 않도록 보장하며, 감정을 인식할 수 있는 텍스트 표현을 생성한다. 이 retrofitting 방법을 사용한 모델은 다양한 클러스터링 및 검색 메트릭을 통해 평가되었을 때 감정을 인지할 수 있는 텍스트 표현을 생성하며, 감정 분석과 풍자 감지와 같은 다운스트림 태스크에서 사전 훈련된 모델 대비 약 1%의 개선 in F1-score를 보인다. 특히, 이미지 어록 학습 환경에서 retrofitting 된 모델의 성능 향상이 사전 훈련된 모델 대비로 더 크게 나타난다.

###### Longtriever: a Pre-trained Long Text Encoder for Dense Document Retrieval (https://aclanthology.org/2023.emnlp-main.223/)
- Anthology ID: 2023.emnlp-main.223 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사전 훈련된 언어 모델(PLM) 기반의 집약된 검색은 내재적 의미를 모델링할 때 강력한 성능을 보이지만, 기존의 모델은 계산 비용이 많이든다는 문제가 있다.
    2. 이 논문에서는 'Longtriever'라는 새로운 검색 모델을 소개하며, 장문 문서 검색의 핵심적인 문제들인 계산 비용, 불완전한 문서 이해, 희귀한 어노테이션에 대응한다.
    3. Longtriever는 장문 문서를 짧은 블록으로 나눈 뒤, 블록 내 지역적 의미와 블록 간 전역적 문맥 의미를 밀접하게 모델링하여 효율적으로 처리한다. 또한 사전 훈련 단계를 도입하여 기저 의미 상관관계를 더욱 잘 이해할 수 있다는 결과를 실험을 통해 입증하였다.

###### Revisiting De-Identification of Electronic Medical Records: Evaluation of Within- and Cross-Hospital Generalization (https://aclanthology.org/2023.emnlp-main.224/)
- Anthology ID: 2023.emnlp-main.224 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 익명화 작업은 전자 의료 기록에서 보호되어야 할 정보를 감지하고 제거하는 작업을 말하는데, 이전 연구들은 일반적으로 병원 내 환경에 초점을 맞추고 있고 큰 성과를 거두었지만, 병원 간 환경을 간과하고 있다. 
    2. 본 논문은 중국의 세 병원에서 가져온 EMR로 이루어진 새로운 익명화 데이터셋을 소개하고 병원 내 및 병원 간 일반화를 평가하는 기준을 마련하였다. 
    3. 병원 간에는 상당한 도메인 차이가 있으며, 거의 완벽한 성능을 가진 모델도 병원 간 이식에서 어려움을 겪는다. 사전 훈련된 언어 모델과 일부 도메인 일반화 방법을 사용하면 이 문제를 완화시킬 수 있다는 실험 결과도 제시되었다.

###### Small Language Models Fine-tuned to Coordinate Larger Language Models improve Complex Reasoning (https://aclanthology.org/2023.emnlp-main.225/)
- Anthology ID: 2023.emnlp-main.225 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 대형 언어 모델들은 chain-of-thought (CoT) 생성에서 뛰어난 추론 능력을 보여주지만, 복잡한 다단계 추론 문제를 해결하기 위한 prompt 분해는 이러한 모델이 동시에 분해와 해결을 할 수 있는 능력에 의존한다.
    2. 우리는 기존의 대형 언어 모델들은 fine-tuning할 수 없기 때문에 변형이 어렵다고 보며, 문제 분해와 해결 생성은 하나의 대형 언어 모델로 처리하는 것보다 각각 별도의 모듈로 다루는 것이 더 나은 방법이라고 주장한다.
    3. 우리는 DaSLaM이라는 모델을 소개하는데, 이 모델은 분해 생성 모듈을 사용하여 복잡한 문제를 작은 하위 문제로 분해하고, 해결자 모듈을 사용하여 이 하위 문제에 대한 답을 구한다. 이때 우리는 상대적으로 작은 규모의 언어 모델을 분해 생성기로 사용하여 성능을 향상시키고, 해결자 모델과 상호 작용하면서 하위 문제를 안내한다. 이로써 우리의 방법은 어떤 해결자 모델에도 적용 가능하다는 것을 보여준다.

###### Language Representation Projection: Can We Transfer Factual Knowledge across Languages in Multilingual Language Models? (https://aclanthology.org/2023.emnlp-main.226/)
- Anthology ID: 2023.emnlp-main.226 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다국어 사전학습 언어 모델은 사실 기반의 다국어지식 저장소 역할을 한다. 그러나 리소스가 풍부한 언어와 리소스가 제한된 언어 사이에는 실질적인 지식 이전에 큰 성능 차이가 존재하며, 다국어 사전학습 언어 모델에서의 언어 간 암묵적인 실제 지식 전달이 제한되었음을 시사한다. 
    2. 본 논문에서는 상대적으로 풍부한 실제 지식을 영어에서 다른 언어로 명시적으로 전달하는 것의 실현 가능성을 연구한다. 이를 위해, 두 개의 기본 파라미터 없는 언어 표현 전사 모듈(LRP2)을 제안한다. 첫 번째 모듈은 다른 언어의 표현을 영어와 유사한 표현으로 변환하고, 두 번째 모듈은 영어와 유사한 표현을 해당 다른 언어의 표현으로 되돌린다. 
    3. mLAMA 데이터셋에서의 실험결과는 LRP2가 실제 지식 검색의 정확도를 크게 향상시키고, 다양한 다른 언어 간의 지식 이전을 용이하게 하는 것을 보여준다. 또한 LRP2의 작동 메커니즘을 표현 공간과 언어 간 지식 뉴런으로부터 규명한다.

###### Structural Priming Demonstrates Abstract Grammatical Representations in Multilingual Language Models (https://aclanthology.org/2023.emnlp-main.227/)
- Anthology ID: 2023.emnlp-main.227 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델들은 인간과 유사하게 동작하여, 인간의 언어 구조 대단위에서의 형태소 특징 및 문법 패턴을 인식할 수 있다는 것을 보여준다.
    2. 그러므로, 크로스리규얼 구조 준비 실험을 사용하여 다국어 언어 모델에서 언어 구조 표상을 측정하고 인간의 행동 결과와 비교한다.
    3. 이 연구 결과는 다국어 언어 모델의 문법적 표현이 언어 간에 유사하며 서로 다른 언어로 생성된 텍스트에도 영향을 미칠 수 있다는 것을 보여준다.

###### ReasoningLM: Enabling Structural Subgraph Reasoning in Pre-trained Language Models for Question Answering over Knowledge Graph (https://aclanthology.org/2023.emnlp-main.228/)
- Anthology ID: 2023.emnlp-main.228 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Knowledge Graph Question Answering (KGQA)은 대규모 지식 그래프에서 자연어 질문에 대한 답을 찾는 것을 목표로 한다. 전통적인 방법에서는 pre-trained language model (PLM)과 graph neural network (GNN)을 따로 사용하여 모델링하였다. 그러나 PLM과 GNN은 구조적인 처리나 특징 상호작용에 있어서 직접적인 연동이 없어서 정보 공유가 제한되었다. 
    2. 우리는 위 두 모듈 접근 방식을 단순화하고 KGQA에 직접적인 서브그래프 추론을 지원하는 더 강력한 PLM인 ReasoningLM을 개발하기 위해 노력했다.
    3. 우리의 실험 결과, ReasoningLM은 Parameter의 수가 적고 학습 데이터가 줄어들더라도 기존 모델을 큰 폭으로 앞질러 나감을 보여주었다.

###### Deep Natural Language Feature Learning for Interpretable Prediction (https://aclanthology.org/2023.emnlp-main.229/)
- Anthology ID: 2023.emnlp-main.229 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 연구에서는 주요 복잡한 작업을 중간 단계의 더 쉬운 하위 작업 집합으로 나누는 일반적인 방법을 제안한다. 이 하위 작업은 최종 목표 작업과 관련된 바이너리 질문으로 자연어로 포뮬레이션된다.
    2. 우리의 방법은 이러한 질문에 대한 답변으로 각 예시를 나타내는 벡터로 표현 가능하게 한다. 우리는 이 표현을 "Natural Language Learned Features (NLLF)"라고 부른다.
    3. NLLF 벡터는 이진 질문에 대한 zero-shot inference를 다룰 수 있는 능력을 가지며, 어떠한 훈련 과정에서든 사용될 수 있다. 이 벡터는 분류기의 성능을 향상시키는 데 도움이 되는데, 또한 의사 결정 트리와 같은 해석하기 쉬운 기계 학습 모델의 입력으로 사용될 수 있다.

###### ROBBIE: Robust Bias Evaluation of Large Generative Language Models (https://aclanthology.org/2023.emnlp-main.230/)
- Anthology ID: 2023.emnlp-main.230 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 지금은 LLMs의 공정성을 측정하고 개선하기 위해 충분한 도구를 개발해야 할 때이다. 이 논문에서는 다양한 프롬프트 기반 데이터셋을 사용하여 텍스트 도메인과 인구 특성 축을 통해 사회적 편향성을 측정하는데 초점을 맞추었다. 또한, LLMs을 다양한 데이터셋에서 테스트하는 것은 편향성을 더욱 완전하게 파악하고, 사회적으로 소외된 인구 그룹들에게 공정한 대우를 보장하기 위해 도움이 될 수 있다.
    2. 이 논문은 6가지 다른 프롬프트 기반 편향 및 독성 메트릭을 12개의 인구 특성 축과 5개의 LLMs 패밀리에 걸쳐 비교하는 벤치마킹 분석을 수행한다. 또한, 비교 벤치마크를 통해 모델의 편향성과 독성에 대한 통찰력을 얻을 수 있다. 이를 통해 LLMs의 사전 훈련 말뭉치에서 인구 특성 용어의 빈도에 대해 조사하고, 이것이 모델의 편향과 관련이 있는지 알아본다.
    3. 또한, 이 논문은 3가지 편향/독성 완화 기술의 성능을 측정하여 평가했다. ROBBIE는 모델 배포 시 실무자에게 인사이트를 제공하고, 잠재적인 피해를 측정하는 것뿐만 아니라 피해가 어떻게 발생하는지 이해하기 위해 데이터를 특성화하고, 발견된 피해를 완화하고, 어떤 편중점을 조정해야 하는지를 강조한다. 또한, 향후 LLMs에서 편향을 보다 폭넓게 측정하도록 동기부여하기 위해 분석 코드를 공개하였다.

###### Enhancing Task-oriented Dialogue Systems with Generative Post-processing Networks (https://aclanthology.org/2023.emnlp-main.231/)
- Anthology ID: 2023.emnlp-main.231 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에는 태스크 지향형 대화 시스템에서 비미분 가능한 모듈까지 포함하여 임의의 모듈의 출력을 수정하는 후 처리 네트워크(PPN)가 제안되었습니다. 
    2. PPN은 NLU, DST, Policy 모듈을 분류 기반 접근법으로 후 처리하여 대화 성능을 성공적으로 개선하였으나, NLG 모듈에는 적용할 수 없습니다.  
    3. 따라서 우리는 dialogue act contribution이라는 새로운 척도를 사용하여 GenPPN에서 NLG에 대한 후 처리 구성 요소를 제안하고, RL을 통해 GenPPN을 최적화합니다. 이를 통해 MultiWOZ 데이터셋을 기반으로 한 시뮬레이션 및 인간 평가 실험을 통해 GenPPN이 태스크 완료 성능을 향상시킨다는 것을 확인하였습니다.

###### Adapting Language Models to Compress Contexts (https://aclanthology.org/2023.emnlp-main.232/)
- Anthology ID: 2023.emnlp-main.232 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Transformer 기반 언어 모델은 강력하고 다양한 분야에 적용 가능한 도구이지만, 유한한 문맥 창과 긴 텍스트 문서 처리의 계산 비용 때문에 제약이 있다.
    2. 이 논문에서는 사전 훈련된 언어 모델을 AutoCompressors로 적용하여, 긴 문맥을 요약 벡터로 압축하고 모델이 이 벡터를 소프트 프롬프트로 활용하는 방법을 제안한다.
    3. AutoCompressors는 긴 문장 처리에 대한 perplexity 향상과 함께 정확도를 높이고 추론 비용을 줄이는 효과를 보여주며, LMs의 문맥 창을 확장하는 간단하고 경제적인 해결책으로 등장한다.

###### Selective Labeling: How to Radically Lower Data-Labeling Costs for Document Extraction Models (https://aclanthology.org/2023.emnlp-main.233/)
- Anthology ID: 2023.emnlp-main.233 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인보이스, 영수증, 계산서, 세금 양식 등과 같은 시각적으로 풍부한 문서에 대한 자동 추출 모델을 구축하는 것은 최근에 상당한 관심을 받고 있다. 그러나 새로운 문서 유형의 추출 모델을 개발하는 주요 병목은 학습에 필요한 여러 천 개의 고품질 레이블이 지정된 문서를 구하기 위한 비용이다. 이 논문에서는 이 문제에 대한 해결책으로 선택적 레이블링을 제안한다.
    2. 선택적 레이블링은 부분적으로 레이블이 지정된 문서로 학습한 모델이 예측한 후보 추출물에 대해 "예/아니오" 레이블을 제공하는 것으로 레이블링 작업을 간소화하는 것을 주요 아이디어로 한다.
    3. 실험 결과, 선택적 레이블링은 10배 정도의 레이블링 데이터 구입 비용 절감과 무시할 수 있는 정확도 감소를 보이는 것으로 나타났다. (active learning)

###### TRAVEL: Tag-Aware Conversational FAQ Retrieval via Reinforcement Learning (https://aclanthology.org/2023.emnlp-main.234/)
- Anthology ID: 2023.emnlp-main.234 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 온라인 고객 서비스에서 사용자의 의도와 일치하는 FAQ 질문을 효율적으로 검색하는 것은 중요하다. 
    2. 기존의 방법들은 동적인 대화 문맥을 활용하여 사용자의 질문과 FAQ 질문의 의미 연관성을 향상시키려고 하지만, 대화 문맥에는 잡음이 존재하여 정확한 의미 모델링이 어려워진다. 
    3. 따라서 이 연구에서는 FAQ 질문의 태그를 도입하여 관련 없는 정보를 제거하고, 강화학습 프레임워크에 통합하여 동적인 대화 문맥에서 관련 없는 정보의 부정적인 영향을 최소화한다.

###### Continual Dialogue State Tracking via Example-Guided Question Answering (https://aclanthology.org/2023.emnlp-main.235/)
- Anthology ID: 2023.emnlp-main.235 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화 시스템은 자주 새로운 서비스에 맞추어 업데이트되지만, 이전에 학습한 서비스의 성능을 저하시키는 문제가 있다. 
    2. 이 논문에서는 대화 상태 추적(DST)을 단순한 자연어 이해 작업으로 구성하고, 서비스 간의 작업 변경을 최소화하기 위해 예시를 기반으로 하는 질문-답변 작업을 제안한다. 
    3. 제안한 방법은 서비스별로 특정 정보를 기억하는 것을 완화하고, 대화에서 필요한 정보를 추출하기 위해 주어진 질문과 예시를 문맥화하여 학습하는 경량 모델을 제안한다.

###### Lost in Translation, Found in Spans: Identifying Claims in Multilingual Social Media (https://aclanthology.org/2023.emnlp-main.236/)
- Anthology ID: 2023.emnlp-main.236 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. CSI (Claim span identification)는 사회적 미디어 게시물에서 검증할 가치가 있는 주장이나 어설션을 포함하는 텍스트 부분을 식별하는 중요한 단계이다. 
    2. 우리는 CSI를 위한 새로운 데이터셋 X-CLAIM을 생성하여 여러 인도어 언어와 영어로 구성되어 있음을 보여준다. 
    3. 우리는 state-of-the-art 언어 모델(XLM-R)을 사용하여 강력한 기준 성능을 보여주고, 저자원 언어인 영어로부터의 제로샷 전송 또는 번역된 데이터로 훈련하는 대안적 크로스-언어 전이 방법에 비해 여러 언어로 훈련하는 것의 장점을 보인다.

###### COVID-19 Vaccine Misinformation in Middle Income Countries (https://aclanthology.org/2023.emnlp-main.237/)
- Anthology ID: 2023.emnlp-main.237 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "이 논문은 COVID-19 백신에 대한 잘못된 정보를 가진 다국어 데이터셋을 소개하며, 브라질, 인도네시아, 나이지리아에서 수집한 트위터 데이터를 포함한다. 해당 데이터셋은 5,952개의 트윗에 대한 주제, COVID-19 백신과의 관련성, 그리고 잘못된 정보의 유무에 대한 주석을 포함하고 있다."
    2. "도메인 특이성, 데이터 부족, 데이터 불균형과 같은 도전을 해결하기 위해 우리는 COVID-19 백신 잘못된 정보 탐지 모델의 개발을 위해 도메인 특정 사전 훈련과 대규모 언어 모델을 사용한 텍스트 augmentation 두 가지 접근 방식을 채택한다."
    3. "최고의 잘못된 정보 탐지 모델은 기준 모델과 비교하여 macro F1-score에서 2.7에서 15.9 백분율 향상을 보여주며, 이 모델을 사용하여 브라질과 인도네시아의 COVID-19 백신 잘못된 정보율과 새로운 COVID-19 케이스 수의 백분율 변화와 긍정적인 관련성이 있음을 분석 결과로 보여준다."

###### Contrastive Learning of Sentence Embeddings from Scratch (https://aclanthology.org/2023.emnlp-main.238/)
- Anthology ID: 2023.emnlp-main.238 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에는 학습된 언어 모델을 활용하여 합성 데이터로 문장 임베딩을 학습하는 contrastive learning 방법이 주로 사용되고 있다. 이 연구는 제한된 도메인에서 unlabeled 데이터를 활용하여 contrastive learning을 수행하는 SynCSE라는 새로운 프레임워크를 제안한다.
    2. SynCSE는 unlabeled 데이터에 대해 긍정/부정 어노테이션을 구성하거나 무작위로 문장과 해당 어노테이션을 생성하는 데 활용할 수 있다. 특히, SynCSE는 수동으로 데이터를 수집하지 않고도 문장 임베딩을 학습하는 첫 번째 contrastive learning 방법을 구성한다.
    3. 문장 유사도 및 reranking 작업에서의 실험 결과는 SynCSE-partial 및 SynCSE-scratch가 비지도 기준 모델을 크게 능가하며, SynCSE-partial은 대부분의 setting에서 지도학습 기준 모델과 유사한 성능을 달성한다.

###### A Rose by Any Other Name would not Smell as Sweet: Social Bias in Names Mistranslation (https://aclanthology.org/2023.emnlp-main.239/)
- Anthology ID: 2023.emnlp-main.239 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 우리는 기계 번역의 이름에 대한 분야별 차이가 있는지 질문합니다. 우리는 미국의 인종 및 민족 소수자에 관련된 이름의 번역 품질이 전통적인 언어 패턴을 기준으로 표준화하는 기계 번역 시스템의 경향으로 인해 낮을 것이라고 가정합니다. 
    2. 우리는 인구 통계학적으로 관련된 이름의 데이터 세트를 개발하고, 왕복 번역에 기반한 번역 평가 절차를 제안합니다. 
    3. 이름의 인구 통계학적 특성이 번역 품질에 미치는 영향을 분석하여, 여성 관련 이름의 번역을 올바르게 하는 능력이 남성 관련 이름보다 현저히 낮다는 것을 발견했습니다. 이러한 효과는 특히 여성 관련 이름이 인종 (흑인) 및 민족 (히스패닉) 소수자와 관련된 경우에 두드러집니다.

###### Investigating Efficiently Extending Transformers for Long Input Summarization (https://aclanthology.org/2023.emnlp-main.240/)
- Anthology ID: 2023.emnlp-main.240 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 사전학습 모델은 자연어 처리 작업에 매우 능숙하지만, 긴 시퀀스 입력을 처리하는 것은 여전히 큰 도전이다.
    2. 이 논문에서는 긴 입력 요약 작업을 위해 미리 학습된 Transformer 모델을 가장 효율적으로 적용하기 위한 아키텍처 변경과 사전학습 패러다임을 탐구한다.
    3. 그 결과, 전역 인코더 토큰을 가진 단계적인 블록-로컬 Transformer 구조가 성능과 효율성의 균형을 잘 이루며, 긴 시퀀스에 대한 사전학습 단계가 요약 작업 성능을 의미있게 향상시킨다는 것을 발견했다.

###### CS2W: A Chinese Spoken-to-Written Style Conversion Dataset with Multiple Conversion Types (https://aclanthology.org/2023.emnlp-main.241/)
- Anthology ID: 2023.emnlp-main.241 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 음성 텍스트는 비유차와 문법적 오류를 포함하여 하위 태스크에 대한 막대한 과제를 제기한다. 이 문제를 해결하기 위해 우리는 CS2W라는 중국어 음성-문장 변환 데이터셋을 제시한다.
    2. CS2W는 대화 형식의 텍스트에서 추출한 7,237개의 음성 문장을 포함하며, 비유차, 문법적 오류, 음성 인식 오류 및 구어적인 표현을 포함하는 변환 문제를 다룬다.
    3. 우리의 주석 규칙, 데이터 및 코드는 https://github.com/guozishan/CS2W에서 공개적으로 이용 가능하다.

###### Unifying Cross-Lingual Transfer across Scenarios of Resource Scarcity (https://aclanthology.org/2023.emnlp-main.242/)
- Anthology ID: 2023.emnlp-main.242 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 세계의 많은 언어에서 데이터의 부족으로 인해, 다른 정보가 있는 resource-rich 언어로부터 지식을 전이해야 하는 필요가 있다. 그러나 부족한 정도는 다양한 차원에서 크게 달라진다. 
    2. 이 논문에서는 충분한 데이터가 없는 난감한 상황에서 cross-lingual transfer 도구를 사용하는 방법을 연구한다. 
    3. 실험결과, 매우 다국어적인 Transformers의 언어와 작업에 효율적인 매개변수를 사용하는 것이 가장 좋은 구성이며, 기계 번역 및 다양한 대상 언어의 자연어 데이터를 동시에 사용하여 학습시키는 것이 가장 좋은 성능을 보여준다.

###### A Tale of Pronouns: Interpretability Informs Gender Bias Mitigation for Fairer Instruction-Tuned Machine Translation (https://aclanthology.org/2023.emnlp-main.243/)
- Anthology ID: 2023.emnlp-main.243 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 instruction fine-tuned 모델들은 자연어 처리(NLP) 태스크를 여러 개 해결할 수 있지만, 현재의 연구들은 주로 성능 기준에만 초점을 맞추고 공정성과 윤리적 고려사항을 무시한다.
    2. 기계 번역(MT)에서는 성별에 대한 편견과 고정관념을 지속시키는 비성별적인 번역이 생길 수 있다. 이 연구에서는 IFT 모델들이 남성형식의 번역을 선호하는 것을 발견했고, 이를 해결하기 위해 few-shot learning을 이용한 편향 보완 방법을 제안한다.
    3. 발견한 문제에 기반하여 구체적인 해석 가능성 메서드를 사용하여 모델들이 비성별적인 번역에서 대상 직업의 성별을 나타내는 대명사를 무시하는 경향을 발견하였다.

###### DisCo: Distilled Student Models Co-training for Semi-supervised Text Mining (https://aclanthology.org/2023.emnlp-main.244/)
- Anthology ID: 2023.emnlp-main.244 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 많은 텍스트 마이닝 모델들은 downstream 태스크에서 대용량 deep pre-trained language model (PLM)을 fine-tuning하는 방식으로 구성된다. 그러나 최근에는 라벨링된 샘플이 제한된 상황에서 경량 모델을 사용할 때 성능을 유지하는 것이 큰 도전이 된다.
    2. 우리는 DisCo라는 세미-지도학습 (SSL) 프레임워크를 제안한다. 이는 대량 PLM에서 생성된 작은 student model들의 집단을 knowledge distillation을 이용해 fine-tuning하는 것이다.
    3. DisCo는 서로 다른 distillation 전략과 다양한 input augmentation에 의해 생산된 model view와 data view 사이에서 지식 공유를 촉진하는 co-training 기술을 사용하여 여러 작은 student model들의 집단을 최적화한다. 결과적으로 DisCo는 성능을 유지하면서 기준 PLM에 비해 7.6배 작고, 4.8배 빠른 추론 속도를 가진 student model을 생성할 수 있음을 실험 결과로 입증하였다.

###### Dynosaur: A Dynamic Growth Paradigm for Instruction-Tuning Data Curation (https://aclanthology.org/2023.emnlp-main.245/)
- Anthology ID: 2023.emnlp-main.245 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Instruction tuning"은 대형 언어 모델의 지침 이해 및 적절한 응답 생성 능력을 향상시키기 위해 등장했으나, 기존 방법들은 주로 데이터를 직접 주석을 달거나 기존의 LLM을 사용하는 것으로 한정되어 있었다. 
    2. 이 논문에서는 기존 주석이 있는 데이터셋과 지침을 연결시켜 자동으로 지침 튜닝 데이터를 구축하는 "Dynosaur"라는 동적 성장 패러다임을 제안한다. 
    3. Dynosaur는 비용 절감과 고품질의 튜닝 데이터 제공, 지속적인 모델 개선 등의 장점을 제공하며, 새로운 주석 데이터셋이 사용 가능해질 때마다 지속적으로 튜닝 데이터를 생성하여 지속적인 학습을 지원한다.

###### Are All Steps Equally Important? Benchmarking Essentiality Detection in Event Processes (https://aclanthology.org/2023.emnlp-main.246/)
- Anthology ID: 2023.emnlp-main.246 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어는 종종 이벤트를 높은 단위(goal) 이벤트로 나눌 수 있으며, 세부 단계(step) 이벤트들의 순서로 구성될 수 있다. 하지만 이러한 이벤트 프로세스의 중요성은 세부 단계 이벤트들이 중요하지 않을 수 있다는 사실에 있다.
    2. 이 논문에서는 현재 모델들이 목표 이벤트에 대한 세부 단계 이벤트들의 필수성을 얼마나 잘 이해하는지를 연구한다.
    3. 기존 최신 모델들이 인간 수준의 성능을 보이지 못하는 것으로 나타나며, 이러한 중요하지만 도전적인 과제에 대한 미래 연구의 필요성이 나타난다.

###### Language Model is Suitable for Correction of Handwritten Mathematical Expressions Recognition (https://aclanthology.org/2023.emnlp-main.247/)
- Anthology ID: 2023.emnlp-main.247 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 손으로 쓴 수식을 인식하는 작업에서 기존 방법들은 트리 디코더를 사용하여 계층적인 트리 구조를 파악하지만 CFG와 미리 생성된 트리플렛 데이터에 의존하여 확장성이 제한되고 시각적으로 모호한 도전을 간과하고 있다.
    2. 이 연구에서는 LaTeX 수식의 특징적인 언어 특성을 조사하여 구조적인 정보와 의미적인 정보를 동시에 제공할 수 있는 언어 모델의 사용을 제안한다.
    3. 실험 결과, RLFN 모델은 CROHME 2014/2016/2019 데이터셋에서 기존 최첨단 모델들보다 뛰어난 성능을 보여주었다.

###### Vicinal Risk Minimization for Few-Shot Cross-lingual Transfer in Abusive Language Detection (https://aclanthology.org/2023.emnlp-main.248/)
- Anthology ID: 2023.emnlp-main.248 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 고자원 언어에서 중간 및 저자원 언어로의 효과적인 교차 언어 전이 학습은 유망한 결과를 보여주고 있다. 그러나 대상 언어의 자원 부족은 여전히 도전 과제이다.
    2. 이 연구에서는 데이터 증강과 지속적인 사전 학습을 이용하여 도메인 적응을 향상시키고 교차 언어 악성 언어 감지를 개선하기 위해 노력한다.
    3. 데이터 증강 전략은 적은 양의 교차 언어 악성 언어 감지를 향상시킬 수 있는 것으로 나타났으며, 특히 MIXAG 방법은 다양한 도메인 및 다국어 환경에서 유의한 향상을 보였다.

###### SuperDialseg: A Large-scale Dataset for Supervised Dialogue Segmentation (https://aclanthology.org/2023.emnlp-main.249/)
- Anthology ID: 2023.emnlp-main.249 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화 세분화는 대화 시스템에 있어서 중요한 작업으로, 대화 내용을 더 잘 이해하는 데 도움을 준다. 그러나 최근의 비지도 대화 세분화 방법은 명시적인 지도 신호의 부족으로 성능이 제한되고 있다.
    2. 본 논문에서는 document-grounded 대화를 활용하여 대화 세분화 지점의 명확한 정의를 제공하고, SuperDialseg라는 대규모 지도 학습 데이터셋을 제작하였다.
    3. 실험 결과, SuperDialseg로 학습한 모델은 도메인 내 데이터에 대해서 매우 효과적이며, 다른 도메인의 데이터에도 좋은 일반화 능력을 보여준다는 것을 확인하였다.

###### ATFormer: A Learned Performance Model with Transfer Learning Across Devices for Deep Learning Tensor Programs (https://aclanthology.org/2023.emnlp-main.250/)
- Anthology ID: 2023.emnlp-main.250 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 점점 커지는 딥 뉴럴 네트워크의 훈련과 추론 효율성은 특정 하드웨어 플랫폼에서 텐서 연산자의 성능에 매우 의존한다. 따라서, 자동 텐서 생성 및 매개 변수 조정과 함께 컴파일 기반의 최적화 플로우가 효율적인 모델 배포에 필요하다.
    2. 성능 모델을 사용한 컴파일 기반 방법은 동적이고 적절한 코드 최적화를 제공할 수 있지만, 그들은 대략적인 측정 정확도와 다른 하드웨어 플랫폼 간의 낮은 이식성과 함께 큰 설계 공간 탐색에 문제가 있다.
    3. 이 논문에서는 ATFormer라는 간단하면서도 효율적인 디자인을 제안하는데, 이는 attent-ion에서 영감을 받은 모듈을 사용하여 전체 스케쥴링 공간에서 전역적이고 장거리적인 종속성을 포착하여 최적화된 연산자의 성능을 정확히 예측할 수 있다.

###### mRedditSum: A Multimodal Abstractive Summarization Dataset of Reddit Threads with Images (https://aclanthology.org/2023.emnlp-main.251/)
- Anthology ID: 2023.emnlp-main.251 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다중모달 온라인 토론의 증가로 인해 시간을 절약하고 콘텐츠 과부하를 줄이기 위해 자동 요약이 필요하지만, 기존의 요약 데이터셋은 토론, 다중 모달 둘 다를 다루지 않기 때문에 이를 위해 적합하지 않다.
    2. 이 논문에서는 첫 번째로 다중모달 토론 요약 데이터셋인 mRedditSum을 제공한다. 이 데이터셋은 3,033개의 토론 쓰레드로 구성되어 있으며, 이미지와 텍스트로 기술된 문제에 대한 조언을 요청하는 게시물과 다양한 의견을 표현한 댓글이 포함되어 있다.
    3. 실험 결과, GPT-3.5, BART, T5와 같은 인기있는 요약 모델은 시각적인 정보를 통합할 때 일관적으로 성능이 향상되었으며, 또한 클러스터 기반의 다단계 요약 방법을 소개하여 기존의 기준에 비해 더 나은 성능을 보여주었다.

###### Sparse Low-rank Adaptation of Pre-trained Language Models (https://aclanthology.org/2023.emnlp-main.252/)
- Anthology ID: 2023.emnlp-main.252 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 파라미터 효율적인 pre-trained language models fine-tuning은 효과와 효율성이 입증되었으나, 고정된 내재적인 rank로 이루어지기 때문에 항상 이상적인 선택이 아닐 수 있다.
    2. 기존의 low-rank adaptation 방법을 확장하여 동적으로 내재적인 rank를 조정할 수 있는 sparse low-rank adaptation (SoRA)라는 혁신적인 접근법을 제안한다.
    3. SoRA는 gate unit을 통해 카디널리티를 조절하여 sparse한 방식으로 rank를 업데이트하며, zeroed-out된 rank에 해당하는 파라미터 블록을 제거하여 concise하면서도 rank-optimal한 LoRA로 줄일 수 있는 표현 능력을 강화한 결과를 보여준다.

###### Human Learning by Model Feedback: The Dynamics of Iterative Prompting with Midjourney (https://aclanthology.org/2023.emnlp-main.253/)
- Anthology ID: 2023.emnlp-main.253 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 텍스트에서 이미지를 생성하기 위한 Text-to-Image 모델은 사용자들이 피드백을 받아 자신의 프롬프트를 업데이트하는 반복 과정을 거치는 경우가 많다. 
    2. 이 논문은 인지학적 연구인 참조 게임과 대화 정렬에서 영감을 받아 이러한 반복 과정에서 사용자 프롬프트의 동적을 분석한다. 
    3. 사용자 프롬프트는 특정 특성으로 수렴하며, 이러한 수렴이 사용자가 중요한 세부 정보를 놓친 것을 깨닫고 프롬프트를 수정함으로써 발생하는 것인지 모델의 "선호"에 적응함으로써 발생하는 것인지 연구하였다.

###### ULF: Unsupervised Labeling Function Correction using Cross-Validation for Weak Supervision (https://aclanthology.org/2023.emnlp-main.254/)
- Anthology ID: 2023.emnlp-main.254 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 수동 데이터 레이블링에 비용 대비 효과적인 대안은 약한 지도 (weak supervision)이다. 본 논문에서는 k-fold 교차 검증의 원리를 기반으로 약한 지도에서의 노이즈 감소 기법을 연구한다.
    2. ULF라는 새로운 알고리즘을 제안하여 동작하며, 이는 홀드아웃 된 LFs에 특정한 편향성을 인식하고 수정하기 위해 나머지 모든 LFs로부터 학습된 모델을 활용하여 WS 데이터를 노이즈 제거한다.
    3. 여러 데이터셋에서의 평가 결과 ULF는 수작업 레이블링의 필요없이 WS 학습을 향상시키는 효과가 있다는 것을 확인한다.

###### The Art of SOCRATIC QUESTIONING: Recursive Thinking with Large Language Models (https://aclanthology.org/2023.emnlp-main.255/)
- Anthology ID: 2023.emnlp-main.255 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Chain-of-Thought (CoT) prompting은 대형 언어 모델이 중간 단계를 생성함으로써 복잡한 추론 문제를 해결할 수 있게 한다. 그러나, 순차적으로 생성되는 CoT는 초기 결정에 매우 의존하므로 초기 단계의 오류가 누적되어 최종 답변에 영향을 미친다."
    2. "이 연구에서는 인간의 인지 과정에서 영감을 받아 재귀적인 사고 과정을 모방하는 SOCRATIC QUESTIONING이라는 알고리즘을 제안한다. 이 알고리즘은 충분한 정보를 수집하기 위해 대형 언어 모델을 활용하여 부분 질문을 제기하고 대답하는 방식으로 원래 질문을 해결한다."
    3. "다양한 복잡한 추론 과제인 MMLU, MATH, LogiQA, 그리고 시각적 질의응답에 대한 폭넓은 실험에서는 SOCRATIC QUESTIONING이 CoT, Tree-of-Thought와 같은 최신 prompting 방법보다 유의한 성능 향상을 보인다."

###### Ideology Takes Multiple Looks: A High-Quality Dataset for Multifaceted Ideology Detection (https://aclanthology.org/2023.emnlp-main.256/)
- Anthology ID: 2023.emnlp-main.256 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사람들의 의견과 사회에 대한 입장에 대한 통찰력을 얻는 것은 정치, 경제 및 사회과학 분야에서 많은 응용 가능성이 있는 "Ideology detection(ID)"연구에 있어서 중요한 과제이다.
    2. 기존의 ID 작업 데이터셋은 텍스트를 전체적으로 좌파 또는 우파로 라벨링 하지만, 텍스트는 다양한 주제를 담고 있을 수 있으며 결정은 주제마다 개별적으로 내려지는 경우가 일반적이다.
    3. 이 논문에서는 사회과학적 이론을 활용하여, 다각적 인식(Ideology)을 보다 완전하고 정교하게 표현하기 위해 새로운 다각적 인식(MID) 작업을 위한 5개 도메인과 12개 facet을 포함하는 독자적인 스키마를 설계하였고, 이를 위해 12,594개의 Twitter 포스트 데이터셋을 구축하고 각각의 facet에 대한 Relevance 및 Ideology 레이블을 붙였다.

###### Transductive Learning for Textual Few-Shot Classification in API-based Embedding Models (https://aclanthology.org/2023.emnlp-main.257/)
- Anthology ID: 2023.emnlp-main.257 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 소개된 논문은 소유 및 폐쇄적인 API가 자연어 처리 응용 프로그램에 미치는 영향과 적은 양의 레이블된 데이터로 모델을 사용하는 few-shot classification에 대해 알려주고 있다. 
    2. 그들은 gated API를 통해 사전 학습된 모델의 임베딩을 제공하는 시나리오를 소개하고, NLP 커뮤니티에서 소홀히 여겨진 transductive inference라는 학습 패러다임을 제안한다. 
    3. 또한, 개선된 실험 환경을 제안하고 4개 다른 언어에 걸쳐 8개의 데이터셋과 151개의 클래스로 구성된 벤치마크를 편집하여 자신들의 방법을 평가하였다.

###### MEGA: Multilingual Evaluation of Generative AI (https://aclanthology.org/2023.emnlp-main.258/)
- Anthology ID: 2023.emnlp-main.258 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 생성적 AI 모델은 영어에 대해서 많은 NLP 태스크에서 높은 성능을 보여주었지만, 다른 언어에 대한 이해와 생성에 대한 능력은 여전히 불문명하다. 이 논문에서는 다양한 언어들을 포함한 LLM 모델들의 성능을 평가하는 16개의 NLP 데이터셋을 포함하는 벤치마킹을 제안한다.
    2. Chat-GPT와 GPT-4를 포함한 생성 모델들과 SOTA의 non-autoregressive 모델을 비교하여 성능을 평가한다. 저자들은 저자별, 언어별, 태스크별 성능을 분석하고 저자들과 언어 리소스 부족 언어를 대상으로 한 generative LLMs의 성능 향상에 대한 도전점을 논의한다.
    3. 이 연구는 다국어 환경에서 generative LLMs를 평가하는 프레임워크를 개발하고, 이 분야의 미래적 발전 방향을 제시한다.

###### Support or Refute: Analyzing the Stance of Evidence to Detect Out-of-Context Mis- and Disinformation (https://aclanthology.org/2023.emnlp-main.259/)
- Anthology ID: 2023.emnlp-main.259 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인터넷에서의 거짓 정보와 오염된 정보는 다양한 형태의 온라인 피해의 주요 원인으로 사회적 문제가 되고 있다. 이 논문에서는 다양한 종류의 다양한 증거들에 대한 정보를 추출하는 알고리즘을 제안하여 소셜 미디어 플랫폼에서 잘못된 문맥에 있는 정보를 식별하는 데 있어 새로운 접근 방식을 제시한다.
    2. 정보의 스탠스(stance)는 다른 감지 결과에 대한 편향성을 나타내므로, 다양한 다중모달(evidence)의 스탠스를 통합적인 프레임워크에서 추출할 수 있는 'stance extraction network (SEN)'을 소개한다.
    3. 대규모 공개 데이터셋에서의 실험 결과에서 우리의 제안된 방법이 최신 기준 모델을 능가하는 것을 보여주며, 최고의 모델은 정확도에서 3.2%의 성능 향상을 얻었다.

###### Video-Helpful Multimodal Machine Translation (https://aclanthology.org/2023.emnlp-main.260/)
- Anthology ID: 2023.emnlp-main.260 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 다중 모달 기계 번역(MMT) 데이터셋은 이미지와 비디오 자막에 대한 설명 또는 교육 비디오 자막으로 구성되어 있으며, 언어적 모호성이 드물어 시각 정보가 적절한 번역을 생성하는 데 효과적이지 못하다.  
    2. 본 논문에서는 EVA라는 새로운 MMT 데이터셋을 제시하여 많은 양의 훈련 데이터와 모호한 자막 및 비디오에서 인과 관계 파악을 위한 도움을 준다.
    3. EVA의 실험 결과, 시각 정보와 제안된 방법들이 번역 성능을 향상시키며, 기존의 MMT 모델보다 우수한 성능을 보여준다.
    
    Note: The second summary sentence is quite long, you can consider summarizing it with the main point of the sentence in two separate sentences if required.

###### Large Language Models are Temporal and Causal Reasoners for Video Question Answering (https://aclanthology.org/2023.emnlp-main.261/)
- Anthology ID: 2023.emnlp-main.261 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Large Language Models (LLMs)의 사전 정보를 활용한 Video Question Answering (VideoQA)에서 언어적 편향을 완화하고, 시각적 콘텐츠도 고려하는 Flipped-VQA 프레임워크를 제안합니다."
    2. 이 프레임워크는 LLMs 기반 모델인 LLaMA-VQA를 개발하여 여러 도전적인 VideoQA 벤치마크에서 다른 기반 모델보다 우수한 성능을 보여주었습니다.
    3. 추가적으로, Flipped-VQA는 OPT와 GPT-J와 같은 다양한 LLMs에 적용 가능하며, 언어적인 단축키를 활용 뿐만 아니라 언어적 편향을 완화시키는 것을 실험적으로 입증하였습니다.

###### Uncertainty Guided Global Memory Improves Multi-Hop Question Answering (https://aclanthology.org/2023.emnlp-main.262/)
- Anthology ID: 2023.emnlp-main.262 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 트랜스포머는 많은 자연어 처리 작업과 특히 다중 홉 질문 답변 (MHQA) 작업에 있어서는 표준이 되었다. 기존들은 답변을 예측한 사실로 컨텍스트를 제한하는 반면, 두 번째 그룹은 멀티홉 추론을 위해 긴 입력 인코딩 모델의 attention 메커니즘에 의존한다. 
    2. 하지만 attention 기반의 토큰 표현은 추론 단계를 연결하는 데 필요한 명시적인 전역적 컨텍스트 정보가 부족하다. 
    3. 이 문제를 해결하기 위해 우리는 전체 문서에서 관련 정보들을 모아 메모리에 저장하고, 이를 지역적 컨텍스트와 결합해서 작업을 수행하는 GEMFormer를 제안한다. 실험 결과는 MHQA 데이터셋에서 기초 모형에 비해 미리 학습된 모형을 global elements을 포함한 메모리 증강 입력으로 미세 조정하는 것이 모델의 성능을 개선하는 것을 보여주었다. 또한, 전역적 컨텍스트 메모리는 올바른 답변을 도출하는 데 필요한 사실 정보를 담고 있다는 것을 확인하였다.

###### Prompting Large Language Models with Chain-of-Thought for Few-Shot Knowledge Base Question Generation (https://aclanthology.org/2023.emnlp-main.263/)
- Anthology ID: 2023.emnlp-main.263 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 지식 베이스를 활용한 질문 생성 작업에서 비용이 많이 드는 주석화된 데이터에 의존하여 fine-tuning하는 현재의 방법은 소수의 데이터로도 잘 동작하지 않음이 문제이다.
    2. 이 논문에서는 large language model을 활용하여 적은 데이터로도 잘 작동하는 질문 생성 방법을 제안한다. 추가적으로, reasoning을 고려한 "Chain-of-Thought (CoT)" prompting을 활용하여 복잡한 질문을 생성하는 논리 체인 생성 방법 (KQG-CoT)을 제안한다.
    3. 실험 결과는 KQG-CoT가 다른 baseline들보다 일관적으로 더 좋은 결과를 보이는 것을 보여주며, 특히 PathQuestions 데이터셋에서는 BLEU-4, METEOR, ROUGE-L에서 18.25, 10.72, 10.18 절대점수 차이로 기존 few-shot의 최고 성능을 뛰어넘는다.

###### TrojanSQL: SQL Injection against Natural Language Interface to Database (https://aclanthology.org/2023.emnlp-main.264/)
- Anthology ID: 2023.emnlp-main.264 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 텍스트-투-SQL 기술은 데이터베이스 접근 및 조작의 효율성을 크게 향상시켰으나, 악의적인 사용자 상호작용에서 발생하는 취약점에 대한 연구는 제한적이다.
    2. TrojanSQL을 제안함으로써, 최신 텍스트-투-SQL 파서가 악성 SQL 문을 쉽게 생성하여 사용자 쿼리를 무효화하거나 데이터베이스의 민감한 정보를 침해할 수 있다는 것을 보여준다.
    3. 실험 결과는 fine-tuning 기반의 중간 크기 모델과 prompting 기술을 사용하는 LLM 기반 파서 모두 이러한 유형의 공격에 취약하며, 공격 성공률은 각각 99%와 89%로 매우 높음을 보여준다.

###### Preserving Privacy Through Dememorization: An Unlearning Technique For Mitigating Memorization Risks In Language Models (https://aclanthology.org/2023.emnlp-main.265/)
- Anthology ID: 2023.emnlp-main.265 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델(Large Language models, LLMs)은 민감한 개인정보가 노출될 위험이 있는 데이터를 포함한 방대한 양의 데이터로 학습된다.
    2. 이 논문에서는 기존의 기억 문제를 해결하고 지식의 불필요한 재현을 방지하기 위해 "DeMem"이라는 새로운 재학습 접근 방식을 제안한다.
    3. DeMem은 강화 학습 피드백 루프를 통해 효율적으로 학습 모델을 조정하고, LLMs이 사전 훈련 데이터를 잊기 위한 변형 정책을 학습하도록 유도한다. 실험 결과, DeMem은 개인정보 보호와 LLM 성능 유지 사이의 균형을 유지하면서 강력한 기준선과 최신 기법을 능가한다.

###### MingOfficial: A Ming Official Career Dataset and a Historical Context-Aware Representation Learning Framework (https://aclanthology.org/2023.emnlp-main.266/)
- Anthology ID: 2023.emnlp-main.266 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 중국연구에서는 전통적인 연구에서는 확인할 수 없던 역사적 인물의 뉘앙스를 이해하는 것이 주요한 관심사이다. 이 논문에서는 중국의 명나라 관리들에 대한 연구를 조사하기 위해 MingOfficial이라는 대규모 다중 모달 데이터셋을 제안한다.
    2. MingOfficial 데이터셋은 구조화된 데이터 (경력 기록, 주석이 달린 인사 유형)와 텍스트 데이터 (역사적 텍스트)로 구성되어 있으며, 관료의 사회 구조를 조사하고 다운스트림 테스크에서 성능을 향상시키기 위해 그래프 신경망 (GNN)과 결합되어 있다.
    3. 실험 결과 MingOfficial은 관료의 정체성을 탐색적으로 분석하는데 도움이 되며, 유의미한 특성 (예: 군사력을 가진 민간 관리)을 식별하는 작업에서도 성능을 대폭 향상시킬 수 있음을 보여준다. 이 데이터셋은 중국 연구분야뿐만 아니라 다른 분야의 컴퓨팅 접근 방법에 대한 영감을 제공하기 위해 공개되었다.

###### DPP-TTS: Diversifying prosodic features of speech via determinantal point processes (https://aclanthology.org/2023.emnlp-main.267/)
- Anthology ID: 2023.emnlp-main.267 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 심층 생성 모델의 발전으로 최근 TTS 모델은 사람과 유사한 음성을 합성할 수 있으나, 흥미로운 TTS의 제작은 여전히 문제가 있다.
    2. 우리는 Determinantal Point Processes (DPPs)를 기반으로 한 TTS 모델인 DPP-TTS를 제안하여 음성 샘플의 다양성을 개선한다.
    3. DPP-TTS는 각 샘플과 다른 샘플 사이에도 지각적 다양성을 고려하여 음성 샘플을 생성하여 자연스러움을 유지한다.

###### Meta-Learning Online Adaptation of Language Models (https://aclanthology.org/2023.emnlp-main.268/)
- Anthology ID: 2023.emnlp-main.268 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델은 광범위한 세계지식을 인코딩하지만, 정적으로 학습된 언어 모델은 지식이 오래되어 모델의 유효한 수명을 제한한다. 
    2. 이 논문에서는 온라인 파인튜닝이 모델 정보 흡수에 있어서 부적합한 문제를 발견하였다. 
    3. 따라서, 이 논문에서는 중요한 정보에 충분히 주의를 기울이지 못하는 문제를 해결하기 위해 동적, 문맥-지능적 학습률을 제안하고, 개선된 정보 흡수를 위한 Context-aware Meta-learned Loss Scaling (CaMeLS)를 제안한다.

###### Self-Detoxifying Language Models via Toxification Reversal (https://aclanthology.org/2023.emnlp-main.269/)
- Anthology ID: 2023.emnlp-main.269 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 Language Model detoxification 방법들은 세분화(finetuning)와 decoding을 기반으로 한다. 그러나 전자는 자원이 많이 소모되고, 후자는 추가 구성 요소가 필요하며 생성 유창성을 저하시킬 수 있다.
    2. 저자는 PLM 자체가 'self-detoxification'을 달성할 수 있는 가벼운 방법을 제안한다. 이 방법은 부정적인 이동 prompt를 PLMs에 일으켜유해한 내용을 생성하도록 유도한다는 관찰에 기초한다.
    3. 실험 결과, 저자들의 방법은 세분화나 추가 구성 요소 없이도 최첨단 방법들과 비교 가능한 성능을 달성할 수 있다는 것을 보여준다.

###### Interactive Text Generation (https://aclanthology.org/2023.emnlp-main.270/)
- Anthology ID: 2023.emnlp-main.270 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 유저들은 텍스트, 이미지, 코드 등과 상호작용하는 에디터를 매일 사용하지만, 기계 학습 모델은 이러한 상호작용을 반영한 설정으로 훈련되는 경우가 거의 없다. 훈련할 때 실제 유저를 사용하는 것은 느리고 비용이 많이 들며, 모델이 배울 수 있는 내용이 유저 인터페이스 디자인 선택에 특정되기 때문이다.
    2. 이 논문에서는 유저 시뮬레이터를 사용하여 실제 유저를 수반하지 않고, 모델을 목표 텍스트로 안내하는 편집을 제공하여 상호작용적으로 훈련시킬 수 있는 새로운 Interactive Text Generation 과제를 제안한다.
    3. Imitation Learning을 사용하여 상호작용 모델을 훈련시킨 결과, 경쟁력 있는 비상호작용 세대 모델보다 훨씬 우수한 결과를 얻을 수 있었다.

###### Knowledge Distillation ≈ Label Smoothing: Fact or Fallacy? (https://aclanthology.org/2023.emnlp-main.271/)
- Anthology ID: 2023.emnlp-main.271 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 지식 전이를 위한 메소드로 제안된 지식 압축(Knowledge Distillation, KD)은 실제로 정규화의 한 형태라는 최근 연구들이 있다. 
    2. 두 방법 사이의 관계를 다시 검토하기 위해 각 방법으로 훈련된 모델들의 예측 신뢰도를 비교했다.
    3. 다양한 크기의 모델들이 포함된 4개의 텍스트 분류 작업 실험에서, KD와 LS는 대부분 상반된 방향으로 모델의 신뢰도를 조정하며, KD에서 학생은 지식과 함께 신뢰도도 선생으로부터 상속 받아 전통적인 지식 전달 관점이 강화됨을 보여준다.

###### Analyzing Cognitive Plausibility of Subword Tokenization (https://aclanthology.org/2023.emnlp-main.272/)
- Anthology ID: 2023.emnlp-main.272 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 현재 subword tokenization은 토큰화에 대한 국제적인 비교 평가가 부족한 상태이다. 기존의 연구는 토큰화 알고리즘의 위력이 downstream task에서 어떤 영향을 주는지, 수학적 기준들에 대해 집중했다.
    2. 우리 연구는 subword tokenization의 인지적 타당성에 초점을 맞춘 새로운 평가 방법론을 제시한다.
    3. 우리의 결과는 Unigram 알고리즘이 인지적으로 덜 타당성이 있으며 파생형 형태소의 커버리지 면에서도 문제가 있다는 것을 보여준다.

###### POE: Process of Elimination for Multiple Choice Reasoning (https://aclanthology.org/2023.emnlp-main.273/)
- Anthology ID: 2023.emnlp-main.273 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어 모델은 다지선다 추리 태스크에 대한 in-context 학습을 수행할 수 있지만, 이러한 태스크에서 옵션들은 동등하게 처리된다. 
    2. 우리는 인간들이 종종 마지막으로 올바른 대답을 고르기 전에 잘못된 옵션들을 먼저 제거하는데, 이러한 두 단계 전략이 언어 모델이 이러한 태스크에서 더 잘 수행되도록 할 수 있다고 주장한다. 
    3. 우리는 이를 위해 두 단계 점수화 방법인 POE를 제안하며, 8가지 추리 태스크에 대한 제로샷 실험을 통해 POE의 효과를 입증하고, 논리 추론 태스크에서 특히 우수한 성능을 나타내는 것으로 나타났다.

###### NeuSTIP: A Neuro-Symbolic Model for Link and Time Prediction in Temporal Knowledge Graphs (https://aclanthology.org/2023.emnlp-main.274/)
- Anthology ID: 2023.emnlp-main.274 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 지식 그래프 완성(Neuro-symbolic models for knowledge graph completion, KGC) 모델은 정적 사실을 다루는 데는 매우 강력하지만, 시간적 사실을 다루는 시간적 지식 그래프 완성(Temporal KGC) 모델은 제한적이다. 
    2. 우리는 Allen predicates를 사용하여 시간적 일관성을 보장하는 새로운 NS 모델인 NeuSTIP을 제안한다. 
    3. 우리의 실험 결과는 link prediction에서 경쟁력 있는 성능을 보이며, time interval prediction에서도 최고의 성능을 달성함을 보여준다.

###### Standardizing Distress Analysis: Emotion-Driven Distress Identification and Cause Extraction (DICE) in Multimodal Online Posts (https://aclanthology.org/2023.emnlp-main.275/)
- Anthology ID: 2023.emnlp-main.275 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사회적 발언에 대한 영향력이 커지면서, 사회적 미디어 위에서의 혐오 발언이 주목받고 있다. 그러나, 이전의 자동화된 방법들은 주로 텍스트 콘텐츠만을 분석하는 것이 한계였다. 이 연구에서는 다중모달 온라인 포스트로부터의 고통 파악과 원인 추출 문제를 제안하고 이에 대한 다중태스크 딥 프레임워크를 개발한 것으로, 이 연구는 고통의 내용을 동시에 감지하고 감정 정보를 활용하여 원인 구문을 식별한다. 
    2. 우리는 zero-shot 전략을 사용하여감정 정보를 훈련 프로세스에 통합하였으며, 다중모달 입력의 특징을 퓨즈 (fuse)하기 위해 새로운 메커니즘을 고안했다.
    3. 또한 우리는 Distress and Cause annotated Multimodal (DCaM) 데이터셋을 도입하였으며, 기존 벤치마크와의 비교를 통해 우리의 방법을 철저하게 평가하였다.

###### Out-of-Distribution Generalization in Natural Language Processing: Past, Present, and Future (https://aclanthology.org/2023.emnlp-main.276/)
- Anthology ID: 2023.emnlp-main.276 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 처리 (NLP)의 기계 학습 (ML) 시스템은 테스트 분포가 훈련 데이터 분포와 다른 out-of-distribution (OOD) 데이터에 일반화하는 데 중요한 도전을 겪고 있다. 이로 인해 NLP 모델의 robustness와 높은 정확성에 대한 의문이 제기되며, 이러한 정확성은 체계적인 편향에 민감함으로 인해 인위적으로 과장될 수 있다.
    2. 이 연구는 OOD 관점에서 자연어 이해의 일반화 도전에 대한 최근의 진전, 방법 및 평가에 대한 첫 번째 포괄적인 리뷰를 제시하여 이러한 공백을 메울 것을 목표로 한다. 
    3. 우리는 이미 존재하는 연구에 대한 편리한 접근을 제공함으로써 이 분야의 향후 연구를 격려하길 바란다.

###### Noisy Exemplars Make Large Language Models More Robust: A Domain-Agnostic Behavioral Analysis (https://aclanthology.org/2023.emnlp-main.277/)
- Anthology ID: 2023.emnlp-main.277 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 프롬프트 엔지니어링의 진전으로 인해 대형 언어 모델 (LLMs)이 멋진 정확성으로 다중 점프 논리 추론 문제를 해결할 수 있게 되었으나, 몇 회의 프롬프트 기법의 강건성을 조사한 연구는 거의 없다.
    2. 따라서 우리는 도메인에 무관한 간섭을 통해 LLM의 멀티합 추론 과제의 강건성을 시험하는 체계적인 접근법을 제안한다.
    3. 우리는 질문에 중간 추론 단계를 포함한 (오타와 같은 어휘적 간섭 및 의미적 간섭과 같은) 여러 수준의 변형을 포함하며 LLM에 대한 행동 분석을 진행한다.

###### Can Large Language Models Capture Dissenting Human Voices? (https://aclanthology.org/2023.emnlp-main.278/)
- Anthology ID: 2023.emnlp-main.278 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "큰 언어 모델(LLM)은 다양한 태스크 해결에서 인상적인 성과를 보였으며, instruction fine-tuning에 의해 zero-shot 상황에서도 일반화가 가능함이 입증되었으나, 특히 자연어 추론(NLI)의 범위 내에서 LLM이 인간의 불일치 분포와 얼마나 일치하는지는 잘 연구되지 않았다."
    2. "본 논문에서는 MCE(Monte Carlo Estimation)와 LPE(Log Probability Estimation) 두 가지 기법을 사용하여 LLM의 분포와 인간의 일치 여부를 평가한다."
    3. "결과적으로, 우리는 LLM이 NLI 태스크를 해결하는 능력이 제한적이며 동시에 인간의 불일치 분포를 잘 포착하지 못한다고 보여준다. 사람들과 견해가 차이가 많은 데이터 샘플에서는 推論 및 인간 일치 성능이 더욱 떨어지므로, 자연어 이해(NLU) 능력 및 더 큰 인간 집단에 대한 대표성에 대한 우려가 제기된다."

###### DecoMT: Decomposed Prompting for Machine Translation Between Related Languages using Large Language Models (https://aclanthology.org/2023.emnlp-main.279/)
- Anthology ID: 2023.emnlp-main.279 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 연구는 단어 순서와 어휘 유사성과 같은 언어적 특징을 공유하는 관련 언어 사이에서의 기계 번역에 대해 조사한다. 
    2. 기계 번역을 단어 묶음 번역의 일련의 순서로 분해하는 DecoMT라는 새로운 few-shot prompting 접근법을 제안한다. 
    3. 여러 언어 가족 간에 수행된 자동 및 인간 평가를 통해, DecoMT가 다양한 established few-shot 기준 모델보다 우수한 성능을 보여준다는 것을 입증한다.

###### Prototype-based HyperAdapter for Sample-Efficient Multi-task Tuning (https://aclanthology.org/2023.emnlp-main.280/)
- Anthology ID: 2023.emnlp-main.280 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Parameter-efficient fine-tuning (PEFT)은 사전 훈련된 언어 모델을 downstream task에 효과적으로 적용하는데, 일부 파라미터만 업데이트함으로써 작동한다. 그러나 대부분의 기존 방법들은 각각의 task를 독립적으로 적용하며, 다른 task 사이에서의 지식 전달을 고려하지 않으며, 데이터가 적은 경우에만 적용 가능하다. 
    2. 이 문제에 대해, 우리는 Adapter-tuning과 Hypernetwork 기반의 Prototye-based HyperAdapter (PHA)라는 새로운 프레임워크를 제안한다. 이는 효율적인 샘플링 방법을 통해 조건부 모듈을 생성하여 기존의 PEFT 기법들보다 비슷한 성능 향상을 이끌어낸다. 
    3. 다양한 데이터셋을 기반으로 한 실험 결과, PHA가 학습 가능한 파라미터, stream tasks에서의 정확성 및 샘플 효율성 간에 더 나은 균형을 이룬다는 것을 보여준다.

###### Towards Building More Robust NER datasets: An Empirical Study on NER Dataset Bias from a Dataset Difficulty View (https://aclanthology.org/2023.emnlp-main.281/)
- Anthology ID: 2023.emnlp-main.281 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 연구들은 Named Entity Recognition(NER) 시스템의 robustness 문제를 보여주고 있다. NER 모델은 종종 context의 evidence를 고려하지 않고 단순한 entity 패턴에 의존하여 예측을 수행한다. 이로 인해 최신 기술을 갖춘 NER 모델들도 out-of-distribution entity 패턴이 소개될 때 out-of-domain 시나리오에서 일반화가 잘 되지 않는다.
    2. 예전 연구는 NER 데이터셋의 bias가 robustness 문제의 원인이며, 더 간단하고 정규한 entity 패턴은 shortcut learning을 유도한다고 추론하였다. 그러나 이 논문에서는 dataset difficulty 관점에서 NER 데이터셋의 bias를 철저히 조사하여 새로운 통찰을 제시한다.
    3. 우리는 기존 데이터셋의 entity-context 어려움 분포를 정량화하고 이들이 모델의 robustness와의 관계를 설명한다. 이를 기반으로, 우리는 entity-context 분포를 변경하여 NER 데이터셋의 bias를 해결하기 위해 세 가지 접근법을 탐구하고, 실험을 통해 사실성을 입증한다. 마지막으로, 우리는 de-biased된 데이터셋이 다른 모델에 전이될 수 있으며, 기존의 robustness 개선 방법에도 도움을 줄 수 있음을 보여줌으로써, 보다 robust한 데이터셋을 구축하는 것이 보다 robust한 NER 시스템을 구축하는 데 근본적인 역할을 한다는 것을 보여준다.

###### GradSim: Gradient-Based Language Grouping for Effective Multilingual Training (https://aclanthology.org/2023.emnlp-main.282/)
- Anthology ID: 2023.emnlp-main.282 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 세계의 대부분 언어들은 자연어처리 모델에 낮은 리소스 도전과제를 제시합니다. 다국어 훈련을 통해 언어 간 지식을 공유할 수 있습니다. 하지만 모든 언어가 서로 긍정적으로 영향을 미치는 것은 아니며, 다국어 훈련에 가장 적합한 언어 집합을 선택하고 특성이나 데이터 분포가 호환되지 않는 언어 간의 부정적인 간섭을 피하는 방법은 여전히 연구되어야할 문제입니다.
    2. 이 논문에서는 그레디언트 유사도를 기반으로 한 언어 그룹화 방법인 GradSim을 제안합니다. 세 가지 다양한 다국어 벤치마크 데이터셋에서의 실험 결과, 이 방법이 다른 유사도 측정 방법보다 가장 큰 성능 향상을 이끌며, 크로스-언어 모델 성능과 더 나은 상관관계를 가짐을 보입니다.
    3. 우리는 저자들이 제안한 방법을 사용하여 낮은 리소스를 가진 아프리카 언어에 대한 감성 분석 벤치마크인 AfriSenti에서 새로운 최고 성적을 달성하였고, 더 나아가 언어 그룹화에 있어서 언어의 주제 뿐만 아니라 언어 특성 및 변형 모델의 하위 레이어들이 언어와 태스크 특정 정보를 포착한다는 사실을 밝혀내었습니다.

###### Discovering Universal Geometry in Embeddings with ICA (https://aclanthology.org/2023.emnlp-main.283/)
- Anthology ID: 2023.emnlp-main.283 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 연구는 독립 성분 분석 (ICA)을 활용하여 단어 또는 이미지의 임베딩 내에서 일관된 의미 구조를 밝힌다.
    2. PCA의 백색화 과정 이후 남아 있는 이방성 정보를 활용하여 사전 훈련된 모델의 임베딩에서 독립적인 의미 구성 요소를 추출한다.
    3. 임베딩의 기하 패턴에서 탐색한 범용적인 의미 구조의 발견은 임베딩 내의 표현에 대한 이해를 향상시킨다.

###### Toward a Critical Toponymy Framework for Named Entity Recognition: A Case Study of Airbnb in New York City (https://aclanthology.org/2023.emnlp-main.284/)
- Anthology ID: 2023.emnlp-main.284 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Critical toponymy"은 장소 이름과 이를 참조하는 장소의 권력, 자본, 저항의 역동성을 연구한다. 그러나 이 장소 이름이 일상 대화에서 어떻게 사용되고, 이들에 대한 상황적인 설명을 무시하는 경우가 많다.
    2. 본 논문에서는 뉴욕의 Airbnb에 등재된 47,440개의 리스트를 기반으로 문화적, 경제적 자본이 사람들이 장소를 참조하는 방식에 어떤 영향을 미치는지를 측정하는 컴퓨터 기반 방법을 개발하고, 장소를 특징 지을 때 중요한 언어적 특징을 인식하는 새로운 named entity recognition (NER) 모델을 소개한다.
    3. 이 연구 결과는 critical toponymy와 관련하여 새로운 연구 방향을 제시하며, 이웃상태, 주거 및 관광 시장, 젠트리피케이션에 관한 이전에 연구되지 않았던 언어적 신호들을 다룬다.

###### Well Begun is Half Done: Generator-agnostic Knowledge Pre-Selection for Knowledge-Grounded Dialogue (https://aclanthology.org/2023.emnlp-main.285/)
- Anthology ID: 2023.emnlp-main.285 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 지식 기반 대화 시스템에서 정확한 지식 선택은 매우 중요하다. 이 연구에서는 기존의 문헌을 지식 선택이 생성 전에, 후에, 생성 과정에서 어떻게 사용되었는지의 관점으로 분류하여 제안한다.
    2. 우리는 LLMs(예: ChatGPT)를 위해 지식 선택을 생성 전에 수행하는 것이 가벼우면서도 효과적인 방법이라는 것을 실험 결과를 통해 입증하였다.
    3. 우리의 제안인 GATE는 지식의 다양한 구조와 가변적인 지식 요구 사항들 중에서 문맥과 관련된 지식을 선택하여 후속 응답 생성 모델에 대비하는, 생성기-중립적인(knowledge selection method) 방법이다.

###### Merging Generated and Retrieved Knowledge for Open-Domain QA (https://aclanthology.org/2023.emnlp-main.286/)
- Anthology ID: 2023.emnlp-main.286 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 오픈 도메인 질문응답 시스템은 검색 모듈로 구축되는 경우가 많은데, 주어진 소스로부터 문단을 검색하는 것은 지식의 커버리지 부족으로 알려져 있다. 
    2. 이 논문에서는 검색된 결과와 대조적으로, parameter 지식에 기반한 large language model들이 문맥을 생성하게 함으로써 QA 성능을 향상시킬 수 있다고 한다.
    3. 논문은 두 가지 정보 소스를 효과적으로 결합하여 더 나은 오픈 도메인 QA 성능을 제공하는 COMBO라는 프레임워크를 제안하고 있다.

###### Best of Both Worlds: Towards Improving Temporal Knowledge Base Question Answering via Targeted Fact Extraction (https://aclanthology.org/2023.emnlp-main.287/)
- Anthology ID: 2023.emnlp-main.287 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Temporal question answering (QA)은 사건의 시간 간격을 단언하는 사실들에 대한 추론을 요구하는 복잡한 질문 응답 과제의 특수한 범주이다.
    2. 기존의 작업은 주로 지식 베이스 질문 응답 (KBQA)에 의존했으며, 이 시스템들이 질문응답에 필요한 모든 관련 사실들을 검색하지 못하는 문제가 있다.
    3. 이 논문에서는 KBQA가 교차 시간 사실을 검색하지 못하는 경우에 대응하기 위해 대상이 되는 시간적 사실 추출 기술을 사용하여 KBQA를 보조하는 방법을 제안한다.

###### Text Fact Transfer (https://aclanthology.org/2023.emnlp-main.288/)
- Anthology ID: 2023.emnlp-main.288 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 텍스트 스타일 전환은 텍스트의 사실적인 내용을 변경하지 않으면서 스타일을 조작하는 중요한 작업이다. 이 논문에서는 텍스트의 사실적인 내용을 스타일을 변경하지 않고 다른 주제로 전환하는 "텍스트 사실 전달" 작업을 제안한다.
    2. 기존 언어 모델은 출처 텍스트의 구체성과 문장 표현을 보존하지 못하고 오류를 조작하는 경향이 있어 텍스트 사실 전달 작업에서 어려움을 겪는다.
    3. 이 문제를 해결하기 위해, 우리는 최소한의 수정으로 출처 텍스트를 변경하는 새로운 조합인 end-to-end question generation과 specificity-aware question answering을 사용하는 ModQGA 프레임워크를 설계했다. ModQGA는 출처 텍스트의 스타일을 희생하지 않고 사실적인 내용을 정확하게 전달할 수 있다는 실험 결과를 보여준다.

###### A Cheaper and Better Diffusion Language Model with Soft-Masked Noise (https://aclanthology.org/2023.emnlp-main.289/)
- Anthology ID: 2023.emnlp-main.289 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에 제안된 확산 모델들은 이미지 생성과 같은 다양한 생성 작업에 활용되어왔으나 기존의 확산 모델은 연속적인 데이터를 위해 구축된 방식이기 때문에 언어와 같은 이산적인 데이터 모델링에는 제한이 있다.
    2. 이 논문에서는 언어 모델링을 위한 새로운 확산 모델, Masked-Diffuse LM을 소개하며, 언어의 언어적 특징에서 영감을 받아 훨씬 더 낮은 훈련 비용과 더 좋은 성능을 제공한다.
    3. 우리는 제안된 Masked-Diffuse LM을 통해 5가지 제어 생성 작업에서 실험을 통해 최신 확산 모델보다 더 좋은 생성 품질과 더 효율적인 성능을 보여줌으로써 우리의 방법의 효과를 입증하였다.

###### Mirages. On Anthropomorphism in Dialogue Systems (https://aclanthology.org/2023.emnlp-main.290/)
- Anthology ID: 2023.emnlp-main.290 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자동 대화 시스템은 사람들에게 사람과 같은 존재로 여겨질 수 있도록 개발되고 사용된다. 그러나 이 논문에서는 이러한 인간화 현상이 불필요하고 위험한 상황을 초래할 수 있다고 주장한다.
    2. 자연어 처리 연구자들은 이러한 인간화 현상을 유발시키는 요인을 연구하고 그 효과를 완화시키기 위한 자원을 개발하였으나, 이러한 연구들은 분산되어 있고, 인간화의 많은 측면이 아직 탐구되지 않았다.
    3. 논문은 대화 시스템의 인간화에 기여하는 언어적 요소와 그로 인해 발생할 수 있는 피해에 대해 논의하며, 앞으로의 대화 시스템 개발에 있어서 디자인, 개발, 출시, 설명 등에 특별한 주의를 기울여야 하며, 사용자들이 인간화를 유도할 수 있는 다양한 언어 신호들에 주의해야 한다고 제안한다.

###### Cognitive Dissonance: Why Do Language Model Outputs Disagree with Internal Representations of Truthfulness? (https://aclanthology.org/2023.emnlp-main.291/)
- Anthology ID: 2023.emnlp-main.291 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 신경 언어 모델은 사실적인 문장의 진실 여부를 평가하기 위해 질의나 내부 표현 방식으로 사용될 수 있다. 이전 연구들은 이 두 가지 절차가 때때로 일치하지 않으며, 내부 표현이 LM의 출력보다 더 정확한 경향이 있다고 발견했다. 이를 통해 일부 연구자들은 LMs가 "거짓말"을 하거나 비협력적인 의사소통 의도를 인코드한다고 결론을 내렸다.
    2. 이 논문에서는 이러한 질의-내부 표현의 불일치가 다른 방식으로 발생할 수 있는지 확인하였고, 이를 confabulation, deception, heterogeneity 세 가지 클래스로 구분하였다.
    3. 많은 경우에는 내부 표현의 우수성은 단순히 불확실한 답변에 대한 더 나은 보정(calibration)으로 설명될 수 있으며, 일부 입력의 서브셋에서는 질의와 내부 표현이 서로 다르게 수행되어 정확도를 더욱 향상시킬 수 있다고 한다.

###### KEBAP: Korean Error Explainable Benchmark Dataset for ASR and Post-processing (https://aclanthology.org/2023.emnlp-main.292/)
- Anthology ID: 2023.emnlp-main.292 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사용자 만족도와 밀접한 연관이 있는 Automatic Speech Recognition (ASR) 시스템은 다양한 응용 분야에서 중요한 역할을 한다. 그러나 기존의 ASR 평가 방법은 한 개의 통합 점수만을 제공해 특정한 시스템 취약점을 이해하기에는 불충분하다. 
    2. 이 논문에서는 ASR 및 후처리 (Post-processing)에 대한 한국어 오류 설명 벤치마크 데이터셋인 KEBAP을 소개함으로써 이전 ASR 평가 방법의 한계를 해결하고자 한다. 
    3. KEBAP은 음성 및 텍스트 수준에서 ASR 시스템을 포괄적으로 분석하여 음성 인식 정확도와 사용자 가독성을 모두 고려한 균형 잡힌 평가를 가능하게 한다.

###### Adaptive Policy with Wait-k Model for Simultaneous Translation (https://aclanthology.org/2023.emnlp-main.293/)
- Anthology ID: 2023.emnlp-main.293 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. SiMT (Simultaneous machine translation)에서는 높은 품질의 번역 모델과 함께 강력한 read/write 정책이 필요한데, 기존 방법들은 고정된 wait-k 정책과 wait-k 번역 모델을 사용하거나, 번역 모델과 연계하여 adaptive policy를 훈련시키지만 더 유연한 접근 방식을 제안한다.
    2. 이 연구에서는 향후 정보로 인해 발생하는 번역 분포의 다양성을 기반으로 어떤 번역 모델에 대한 read/write 결정을 내리는 DaP(Divergence-based Adaptive Policy)를 소개한다.
    3. 실험 결과는 DaP가 번역 정확도와 지연 시간 간의 개선된 균형을 제공하며 강력한 기준 모델을 능가한다는 것을 보여준다.

###### Cross-Document Event Coreference Resolution on Discourse Structure (https://aclanthology.org/2023.emnlp-main.294/)
- Anthology ID: 2023.emnlp-main.294 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Cross-document event coreference resolution (CD-ECR)은 여러 개의 문서에서 동일한 실제 이벤트를 참조하는 이벤트 언급을 군집화하는 작업이다. 
    2. 기존 연구들은 주로 pair-wise 유사도 비교 문제로 모델링하고 이벤트 언급의 지역적인 문맥을 고려하며 장거리 이벤트 언급의 상호작용을 무시했다. 
    3. 본 논문에서는 글로벌 정보로서 담론 구조를 활용하여 CD-ECR을 개선하고, tree 구조와 shortest dependency path를 사용하여 이벤트 언급의 유사도를 캡처하여 coreferent 이벤트를 해결하는 모델을 제안한다.

###### Post-hoc Utterance Refining Method by Entity Mining for Faithful Knowledge Grounded Conversations (https://aclanthology.org/2023.emnlp-main.295/)
- Anthology ID: 2023.emnlp-main.295 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 언어 생성 모델은 뛰어난 성능을 보이지만, 생성된 응답은 주어진 소스에 부합하지 않거나 사실에 어긋나는 환상적인 담화로 인해 고질적인 문제가 있다.
    2. REM은 소스 지식을 기반으로 생성된 환상적인 발언의 품질과 신뢰성을 향상시키기 위해 후처리 시스템을 제안한다.
    3. REM은 주어진 지식에서 주요 엔티티를 추출하여 환상을 수정함으로써 발언의 품질을 개선하는 것을 목표로 한다고 제안한 방법이다.

###### Can We Edit Factual Knowledge by In-Context Learning? (https://aclanthology.org/2023.emnlp-main.296/)
- Anthology ID: 2023.emnlp-main.296 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 초대형 언어 모델은 매개변수에 거대한 사실 지식을 보유하고 있지만, 이러한 지식은 잘못된 정보나 오래된 정보일 수 있다. 
    2. 이 논문에서는 gradient 기반의 방법이 아닌 in-context learning (ICL)을 활용하여 지식 편집을 수행하는 방법을 제안한다.
    3. 실험 결과, ICL 기반의 지식 편집은 gradient 기반 방법과 비교해 성능은 비슷하지만, 관련 없는 사실에 대한 수정과 이전에 저장된 지식에 대한 잊어버리기가 적은 부작용을 가지고 있다.

###### EDIS: Entity-Driven Image Search over Multimodal Web Content (https://aclanthology.org/2023.emnlp-main.297/)
- Anthology ID: 2023.emnlp-main.297 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 실제 검색 엔진 결과와

###### GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints (https://aclanthology.org/2023.emnlp-main.298/)
- Anthology ID: 2023.emnlp-main.298 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Multi-query attention(MQA)은 시간을 크게 단축시키지만, 품질 저하의 문제를 야기할 수 있고, 빠른 추론을 위해 별도의 모델을 훈련시키는 것이 원하는 바가 아닐 수 있다. 
    2. 이 논문에서는 기존의 다양한 헤드를 사용하는 언어 모델 체크포인트를 5%의 원래 pre-training compute만을 사용하여 MQA를 사용하는 모델로 업 트레이닝하기 위한 방법을 제안한다.
    3. 또한, 여러 개의 쿼리 헤드 수보다는 적은 개수의 중간 (intermediate) 키-값 헤드를 사용하는 GQA라는 새로운 기법을 도입하고, GQA로 업 트레이닝된 모델이 MQA와 속도가 비교 가능하면서 품질도 유사하게 달성됨을 보여준다.

###### Towards a Mechanistic Interpretation of Multi-Step Reasoning Capabilities of Language Models (https://aclanthology.org/2023.emnlp-main.299/)
- Anthology ID: 2023.emnlp-main.299 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 연구에서는 언어 모델이 다단계 추론 작업에 강력한 능력을 가지고 있다는 것을 보였으나, 사전 훈련된 코퍼스에서 기억한 답을 이용하여 이러한 작업을 수행한다는 것은 아니라는 사실을 알기 어렵다. 
    2. 본 논문에서는 언어 모델이 정확한 추론 과정과 비슷한 추론 트리를 내재적으로 담고 있는지를 탐구함으로써 이 질문에 답하려고 한다. 
    3. MechanisticProbe라는 새로운 접근법을 사용하여 추론 트리를 모델의 어태션 패턴으로 복원하는 실험을 진행하였고, 이를 통해 언어 모델이 많은 경우에 아키텍처 내에서 다단계 추론 과정을 거친다는 결론을 도출하였다.

###### BiasX: “Thinking Slow” in Toxic Content Moderation with Explanations of Implied Social Biases (https://aclanthology.org/2023.emnlp-main.300/)
- Anthology ID: 2023.emnlp-main.300 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 독성 주석기나 컨텐츠 모더레이터들은 결정을 내릴 때 종종 mental shortcuts을 사용한다. 이는 미묘한 독성이 놓칠 수 있고, 독성이 있어 보이지만 실제로는 무해한 컨텐츠가 과도하게 감지될 수 있다는 의미한다.
    2. BiasX라는 프레임워크를 소개하는데, 이는 뉘앙스적인 (비)독성 컨텐츠를 인식하기 위해 free-text 설명으로 컨텐츠 모더레이션 설정을 강화한다.
    3. 전체적으로 설명의 품질이 매우 중요하며, 기계 생성 설명은 전문가가 작성한 인간의 설명에 비해 도움이 적다는 것을 보여준다. 우리의 결과는 자유로운 텍스트 설명을 사용하여 좀더 사려깊은 독성 모더레이션을 유도하는 것의 잠재력을 보여준다.

###### Text encoders bottleneck compositionality in contrastive vision-language models (https://aclanthology.org/2023.emnlp-main.301/)
- Anthology ID: 2023.emnlp-main.301 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 CLIP 모델은 보다 복합적인 입력에 대해서는 감지가 약하다는 문제점이 있고, 어떤 텍스트 인코더가 다른 것보다 훨씬 더 잘 작동한다는 것을 발견했다. 
    2. 텍스트만으로 복구 가능성을 평가하는 것이 다중 모달 매칭 성능을 예측하는 유용한 지표라는 것을 발견했는데, 이는 새로 수집하고 배포한 평가 기준인 ControlledImCaps에 대해 증명되었다. 
    3. 본 논문에서는 CompPrompts라는 기존에 없던 데이터셋과 코드를 함께 제공한다.

###### Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs Through a Global Prompt Hacking Competition (https://aclanthology.org/2023.emnlp-main.302/)
- Anthology ID: 2023.emnlp-main.302 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "대화형 챗봇과 작문 어시스턴트와 같은 대화형 환경에서는 대규모 언어 모델 (LLM)이 점점 더 많이 사용됩니다. 그러나 이런 배포는 보안 위협이 있으며, 기존 명령을 무시하고 악의적인 명령을 따르도록 조작됩니다. 이 논문은 prompt hacking에 대한 대규모 자원 및 양적 연구의 결핍을 해결하기 위해 전세계적인 prompt hacking 대회를 진행하였습니다."
    2. "우리는 세 가지 최첨단 LLM에 대해 60만 개 이상의 적대적인 프롬프트를 모집했으며, 현재 LLM은 prompt hacking을 통해 실제로 수정될 수 있다는 것을 확인했습니다."
    3. "또한 우리는 적대적인 프롬프트 유형들에 대한 종합적인 체계를 제시하였습니다."

###### MMNMT: Modularizing Multilingual Neural Machine Translation with Flexibly Assembled MoE and Dense Blocks (https://aclanthology.org/2023.emnlp-main.303/)
- Anthology ID: 2023.emnlp-main.303 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 현재 널리 사용되는 다중 언어 신경 기계 번역에서 Mixture-of-Experts (MoE) 기반의 희소 아키텍처는 계산 오버헤드를 sublinear하게 증가시키면서 모델 용량을 크게 향상시킬 수 있지만, 낮은 자원언어 번역에서 과적합될 수 있다고 알려져 있다.
    2. 본 논문에서는 밀집 모듈과 MoE 기반 희소 모듈을 유연하게 조합하여 최상의 효과를 얻을 수 있는 모듈화 MNMT 프레임워크를 제안한다.
    3. 실험 결과, 제안한 모듈화 MNMT 프레임워크는 고/저 자원 언어 번역 및 제로샷 번역에서 MoE 및 밀집 모델보다 뛰어난 성능을 보이며, 다양한 방법들을 조합하고 오프더셀프 모델을 재활용하여 다중 언어 신경 기계 번역을 가능케 한다.

###### Localizing Active Objects from Egocentric Vision with Symbolic World Knowledge (https://aclanthology.org/2023.emnlp-main.304/)
- Anthology ID: 2023.emnlp-main.304 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. AI 에이전트가 과제를 해결하거나 인간을 가상으로 지원하기 위해서는, 자기 중심적 시점에서의 과제 지시를 적극적으로 이해하는 능력이 중요합니다. 이를 위한 중요한 단계 중 하나는 사람들에게 무엇을/어디를 어떻게 지시해야 하는지 정확히 알려주지 않고도, 사람의 행동/환경과 관련된 주요 활동 객체를 지역화하고 추적하는 것입니다.
    2. 기존 연구들은 이 문제를 순수한 비전 관점에서 다루었으나, 텍스트 모달리티(즉, 과제 지시)와 시각 모달리티와의 상호작용이 어느 정도 유용할 수 있는지 조사하였습니다.
    3. 우리는 구문 지지 모델이 활동적인 객체를 정확하게 지역화하는 능력을 향상시키기 위해 (1) '변화하는 객체'의 역할을 학습하고 그것들을 지시에서 정확하게 추출하는 방법, (2) 물체의 전/후 상태를 고려하는 방법, 그리고 (3) 기술적인 지식으로 객체를 더 견고하게 인식하는 방법을 제안합니다.

###### Introducing Rhetorical Parallelism Detection: A New Task with Datasets, Metrics, and Baselines (https://aclanthology.org/2023.emnlp-main.305/)
- Anthology ID: 2023.emnlp-main.305 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 말하거나 쓰는 피닉스는 내용 뿐만 아니라 스타일도 포함한다. 병렬 구조는 일반적인 스타일 도구로, 같은 시퀀스의 언어적 특징을 가진 구문의 병렬 배치이다. 병렬 구문을 자동으로 감지하는 과제를 소개하고, 강한 기준으로 측정했을 때 0.40과 0.43의 F1 스코어를 달성했다.
    
    2. 우리는 이 과제에 대한 공식적인 정의를 제시하고, 새로운 라틴어 데이터셋과 중국어 데이터셋을 구축했다.
    
    3. 또한, 기준 시스템과 병렬 구조를 포착하기 위한 새로운 시퀀스 라벨링 체계를 생성하여 이 과제에 대한 성능 평가를 수행했다.

###### Prompting is not a substitute for probability measurements in large language models (https://aclanthology.org/2023.emnlp-main.306/)
- Anthology ID: 2023.emnlp-main.306 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인간 언어 모델의 언어 지식을 평가하기 위해 Metalinguistic Prompting과 직접 확률 측정을 비교한 결과, Metalinguistic Prompting은 표현에서 직접 파생된 양보다 상대적으로 성능이 떨어진다는 것을 발견했다.
    2. 또한, Prompt Query가 다음 단어 확률의 직접 측정과 차이가 나갈수록 일관성이 떨어진다는 것을 알 수 있었다.
    3. 이 연구 결과는 Metalinguistic Prompting에 의존하는 부정적인 결과가 특정 언어 일반화가 부족한 것으로 결론지을 수 없음을 시사하며, 확률 분포에 제한이 있는 닫힌 API로의 전환으로 상실되는 가치를 강조한다.

###### Parameter-Efficient Language Model Tuning with Active Learning in Low-Resource Settings (https://aclanthology.org/2023.emnlp-main.307/)
- Anthology ID: 2023.emnlp-main.307 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사전 학습 언어 모델(PLMs)은 특히 저자원 도메인과 언어에서 효과적인 세밀 조정 기술에 대한 수요를 촉발시켰다. 기존의 active learning(AL) 알고리즘은 labeling 비용을 최소화하기 위해 라벨 복잡성을 최소화하는 데 유용하다. 
    2. 본 연구에서는 text classification을 위한 낮은 리소스 설정에서 AL과 adapter-based PEFT의 상호작용을 연구하였다. PEFT가 낮은 리소스 설정에서 full-fine tuning(FFT)보다 우수하며, 이 이점이 AL 설정에서도 유지됨을 입증하였다.
    3. PEFT와 FFT의 특성을 통해 forgetting dynamics와 instance-level representations을 조사해보았는데, PEFT가 FFT와 비교하여 초기 및 중간 레이어의 더 안정된 표현을 생성함을 발견하였다. 이 연구는 저자원 설정에서 AL과 PEFT의 상호작용의 잠재력을 강조하며 효율적이고 효과적인 fine-tuning의 진보에 길을 열었다.

###### Stop Uploading Test Data in Plain Text: Practical Strategies for Mitigating Data Contamination by Evaluation Benchmarks (https://aclanthology.org/2023.emnlp-main.308/)
- Anthology ID: 2023.emnlp-main.308 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 자동 수집 말뭉치로 사전 훈련 된 모델에서 데이터 오염이 일반화되어 어려움이 발생하고 있다.
    2. 공개 데이터는 공개 키로 암호화되어야 하며, 파생 배포를 금지하는 라이선스를 갖춰야 한다.
    3. 데이터 오염을 방지하기 위해 훈련 제외 콘트롤을 요구하고, 인터넷에 솔루션이 함께 나온 데이터를 피하고, 웹 페이지 컨텍스트와 함께 데이터를 공개해야 한다.

###### CoLT5: Faster Long-Range Transformers with Conditional Computation (https://aclanthology.org/2023.emnlp-main.309/)
- Anthology ID: 2023.emnlp-main.309 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Transformer 모델은 연산 복잡도가 큰 문제로 인해 긴 문서를 처리하는 데에 비용이 많이 든다. 그러나 긴 문서에는 모든 토큰이 동일한 중요성을 가지지 않으며, 이를 고려한 조건부 계산을 수행하는 CoLT5 모델을 제안한다. 
    2. CoLT5는 중요한 토큰에 더 많은 리소스를 할당하여 LongT5보다 더 빠른 학습과 추론 속도로 더 강력한 성능을 달성한다. SCROLLS 벤치마크에서 강력한 성과를 보여주며, 매우 긴 입력에도 효과적이고 계산 가능한 성과를 보인다.
    3. CoLT5는 긴 문서 처리를 효율적으로 수행할 수 있는 모델로서 최신 기술을 압도하는 성능을 보여준다.

###### DiSTRICT: Dialogue State Tracking with Retriever Driven In-Context Tuning (https://aclanthology.org/2023.emnlp-main.310/)
- Anthology ID: 2023.emnlp-main.310 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화 상태 추적(Dialogue State Tracking)은 과업지향 대화 시스템에서 사용자 의도를 파악하기 위해 대화에서 미리 정의된 슬롯 값들을 결정하는 중요한 구성 요소이다. 기존의 접근 방식은 손으로 만들어진 템플릿과 추가적인 슬롯 정보를 사용하여 대화 문맥에서 슬롯 값을 얻기 위해 대규모 사전훈련 언어 모델을 세밀하게 조정하는 방법을 사용한다.
    2. 이 논문에서는 손으로 만들어진 템플릿 없이 모델을 세밀하게 조정하기 위해 주어진 대화에 대해 매우 관련성 높은 훈련 예제를 검색하는 DiSTRICT라는 일반화 가능한 in-context 튜닝 방법을 제안한다.
    3. MultiWOZ 벤치마크 데이터셋을 사용한 실험 결과, DiSTRICT은 훨씬 작은 모델을 사용하면서 기존 접근 방식보다 다양한 제로샷 및 퓨샷 설정에서 성능이 향상되어, 자원이 제한 있는 실제 환경에서 중요한 장점을 제공한다.

###### Cross-Cultural Analysis of Human Values, Morals, and Biases in Folk Tales (https://aclanthology.org/2023.emnlp-main.311/)
- Anthology ID: 2023.emnlp-main.311 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 말담은 아이들의 인생에 큰 영향을 주고 도덕과 가치를 가르친다. 그러나 현재의 말담 연구는 대부분 유럽의 이야기에 국한되어 있다. 
    2. 본 연구에서는 6개 대륙에서 27개 문화에서 유래한 1,900개 넘는 말담을 모아 분석하였다. 
    3. 다양한 렉시콘과 상관 분석을 사용하여 말담에서 문화에 따라 인간의 가치, 도덕, 성차별이 어떻게 표현되는지 조사하였다.

###### Non-Programmers Can Label Programs Indirectly via Active Examples: A Case Study with Text-to-SQL (https://aclanthology.org/2023.emnlp-main.312/)
- Anthology ID: 2023.emnlp-main.312 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 비 프로그래머들이 복잡한 프로그램으로 자연어 발화를 주석으로 달 수 있을까? 우리는 APEL이라는 프레임워크를 소개하여 비 프로그래머들이 시맨틱 파서로부터 생성된 후보 프로그램들 중에서 선택할 수 있도록 한다.
    2. APEL은 후보 프로그램들의 입력-출력 예제를 살펴보고 간접적으로 선택하도록 요청하여 비 프로그래머들이 프로그램을 이해하지 못해도 정확한 프로그램을 선택할 수 있도록 한다.
    3. APEL을 사용하여 SPIDER라는 텍스트-SQL 데이터셋을 다시 주석으로 달도록 인간 비 프로그래머를 모집하였고, 이 방법은 원본 전문가 주석과 같은 정확성을 달성하며 원본 주석에서 많은 섬세한 오류를 노출시켰다.

###### LINC: A Neurosymbolic Approach for Logical Reasoning by Combining Language Models with First-Order Logic Provers (https://aclanthology.org/2023.emnlp-main.313/)
- Anthology ID: 2023.emnlp-main.313 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델이 논리 추론 작업을 더 효과적으로 수행하기 위해 제안된 많은 prompting 기반 전략들은 여전히 부족한 면이 있어서 예상치 못한 방식으로 성능이 떨어지는 경우가 많다.
    2. 본 논문에서는 LINC(LINC: Logical Inference via Neurosymbolic Computation)라고 부르는 모듈식 신경 기호 프로그래밍으로 이러한 작업을 다시 구성하는 것의 타당성을 조사한다.
    3. LINC를 사용하여 ProofWriter와 FOLIO에서 성능 향상을 확인하였으며, 작은 규모의 StarCoder+ 모델에 LINC를 추가한 경우에는 GPT-3.5 및 GPT-4보다 성능이 우수하다는 것을 보여준다.

###### Non-autoregressive Streaming Transformer for Simultaneous Translation (https://aclanthology.org/2023.emnlp-main.314/)
- Anthology ID: 2023.emnlp-main.314 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. SiMT 모델은 대기 시간과 번역 품질 사이의 균형을 유지하기 위해 훈련되지만, 낮은 대기 시간을 유지하면서 높은 품질을 달성하기 위한 훈련은 종종 공격적인 예측의 경향을 가지게 된다. 
    2. 이러한 문제는 대부분의 기존 SiMT 모델에서 사용되는 autoregressive 구조에서 기인한다고 주장한다.
    3. 이 논문에서는 이러한 문제를 해결하기 위해 단방향 인코더와 non-autoregressive 디코더로 구성된 non-autoregressive streaming Transformer (NAST)를 제안한다.

###### ViSoBERT: A Pre-Trained Language Model for Vietnamese Social Media Text Processing (https://aclanthology.org/2023.emnlp-main.315/)
- Anthology ID: 2023.emnlp-main.315 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 영어와 중국어는 resource-rich 언어로 알려져 있지만 베트남어에는 pre-trained 모델이 제한적이다. 하지만 이 논문에서는 대규모 베트남 소셜미디어 텍스트에 대해 pre-trained된 ViSoBERT 모델을 제안하고 다양한 베트남 소셜미디어 태스크에서 이 모델이 이전 최고 성능 모델들을 능가하는 것을 보였다.
    2. 작성한 ViSoBERT 모델은 감정인식, 혐오발언 판별, 감성분석, 스팸 리뷰 감지, 혐오발언 범위 감지 등 베트남 소셜미디어 텍스트로 구성된 다섯 가지 중요한 자연어 downstream 태스크에서 사용되었다.
    3. ViSoBERT는 훨씬 적은 파라미터를 가지고 이전 모델들을 능가하여 베트남 소셜미디어 태스크에서 우수한 성능을 보여주고 있다.

###### RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction (https://aclanthology.org/2023.emnlp-main.316/)
- Anthology ID: 2023.emnlp-main.316 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 소수의 레이블된 문서만 사용 가능한 상황에서 문서 수준의 의미 관계를 식별하는 방법은 어떠한가? 이 논문은 실제 상황에서 도전적인 데이터 부족 문제를 해결하기 위한 얼마 되지 않는 문서 수준의 의미 관계 추출(FSDLRE)에 대해 다룬다.
    2. 기존의 방법은 관계 원형(protoype)을 구성하기 위해 해당 관계를 갖는 모든 entity pair들의 표현을 집계하는데, 이러한 entity pair들은 다른 관계도 가질 수 있기 때문에 원형이 혼란스러울 수 있다는 문제가 있다.
    3. 본 논문에서는 관계 의미를 강화하기 위해 관계 설명과 실제 NOTA(NONE-OF-THE-ABOVE) 인스턴스를 지능적으로 활용하여 관계 원형을 개선하고 과제별 NOTA 원형을 생성하는 FSDLRE용 관계 인식 원형 학습 방법을 제안한다.

###### GeoLM: Empowering Language Models for Geospatially Grounded Language Understanding (https://aclanthology.org/2023.emnlp-main.317/)
- Anthology ID: 2023.emnlp-main.317 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사람들은 기사를 읽을 때 지리적 추론에 의해 무의식적으로 참여한다. 우리는 텍스트에서 장소 이름과 그들의 공간적 관계를 인식하고, 그들을 지구상의 실제 위치와 연관시킨다. 이 논문은 지리적 정보를 활용하여 언어 모델의 지리적 이해를 강화하는 GeoLM을 소개한다.
    2. GeoLM은 언어 모델을 사용하여 언어적 맥락을 활용하는 데에 그치지 않고, OpenStreetMap과 같은 대용량의 지리 데이터베이스에서 유용한 지리적 정보를 활용한다.
    3. 실제 실험에서 GeoLM은 지명 인식, 지명 링킹, 관계 추출 및 지리 개체 유형 분류와 같은 다양한 과제에서 유망한 성능을 보여주었다.

###### Cross-Modal Conceptualization in Bottleneck Models (https://aclanthology.org/2023.emnlp-main.318/)
- Anthology ID: 2023.emnlp-main.318 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Concept Bottleneck Models (CBMs)는 훈련 예시 (예: X-선 영상)가 고수준 개념 (예: 이상 종류)으로 주석이 달려 있으며, 이러한 개념을 기반으로 먼저 개념을 예측한 다음 레이블을 예측하여 분류를 수행한다고 가정한다. 그러나 CBM을 사용하는 주요 도전 과제는 레이블과 관련하여 예측력이 있는 개념을 정의하고 훈련 예시에 이러한 개념을 주석으로 달아야 한다는 요구 사항이다."
    2. 우리의 접근 방식에서는 보다 중간 정도의 가정을 채택하고 대신 이미지와 함께 오는 텍스트 설명 (예: 방사선학 보고서)를 사용하여 개념의 유도를 안내한다. 
    3. 실험을 통해 근사적 생성된 설명을 가진 합성 이미지에서부터 실제 의료 영상 데이터셋에 이르기까지 여러 데이터셋에서 Crossmodal Learning이 해석 가능한 개념의 유도를 촉진하는 것을 보여주며, 분리(disentanglement)을 용이하게 한다.

###### LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models (https://aclanthology.org/2023.emnlp-main.319/)
- Anthology ID: 2023.emnlp-main.319 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델(GPT-4, ChatGPT 등)의 성공으로 인해 과제별 데이터나 지시어 데이터를 사용하여 오픈 액세스 언어 모델을 fine-tuning하는 다양한 비용 효율적이고 접근 가능한 대안들이 개발되었다. 
    2. 이 논문은 어댑터 기반 PEFT(Parameter-Efficient Fine-Tuning) 방법을 연구하기 위해 사용하기 쉬운 LLM-Adapters 프레임워크를 제안한다. 
    3. 실제 실험에서 어댑터 유형, 위치, 하이퍼파라미터에 대한 영향을 평가하고, 산술 연상과 상식 연상이라는 두 가지 추론 작업에서 어댑터의 효과를 평가하여 작은 규모의 LLMs에서도 강력한 LLMs와 비교 가능한 성능을 제공함을 보였다.

###### DREAM: Deployment of Recombination and Ensembles in Argument Mining (https://aclanthology.org/2023.emnlp-main.320/)
- Anthology ID: 2023.emnlp-main.320 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Argument Mining (AM)에는 종합적인 나아가 검은 상자의 관점이 적용되었는데, 이 연구는 독립된 새로운 해결책 대신 현재 구성품을 기반으로 성능을 높이는 해결책을 제시한다. 
    2. DREAM 프레임워크를 통해 AM의 구성 요소들을 자동적으로 조합함으로써 정확도를 향상시킨다. 
    3. 성능 벤치마크를 통해 DREAM과 함께 사용된 시스템은 AM 벤치마크로 측정된 정확도에서 이전 최고 단일 시스템보다 우수한 성능을 보인다.

###### MILDSum: A Novel Benchmark Dataset for Multilingual Summarization of Indian Legal Case Judgments (https://aclanthology.org/2023.emnlp-main.321/)
- Anthology ID: 2023.emnlp-main.321 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 법적 사건 판결문의 자동 요약은 많은 나라에서 독립적인 연구에 많은 연구 노력을 투입한 실제적으로 중요한 문제이다.
    2. 이 논문은 인도의 법정 환경에서 영어로 작성된 법적 사건 판결문을 가장 많이 사용되는 인도어인 힌디어로 크로스-언어적으로 요약하는 도전적인 노력을 제안한다.
    3. 저자들은 인도 주요 법원의 영어로 된 3,122건의 사건 판결문과 영어와 힌디어로 된 요약문으로 구성된 첫 번째 고품질의 법적 코퍼스를 구축하고 해당 코퍼스에서 여러 다양한 요약 접근 방식의 성능을 평가하여 법적 도메인에서 크로스-언어적 요약 연구의 필요성을 보여준다.

###### Query Rewriting in Retrieval-Augmented Large Language Models (https://aclanthology.org/2023.emnlp-main.322/)
- Anthology ID: 2023.emnlp-main.322 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델(Large Language Models, LLMs)은 "검색해서 읽기(retrieve-then-read)" 파이프라인에서 강력한 블랙박스 리더로 작동하며, 지식 기반 태스크에서 현저한 진전을 이뤄내고 있다. 이 논문은 이전의 retrieve-then-read 대신에 query rewriting 관점에서 retrieval-augmented LLMs를 위한 Rewrite-Retrieve-Read 프레임워크를 소개한다. 
    2. 이 전략은 검색 대상으로 사용될 쿼리의 적응에 주안점을 둔 것으로, 검색 대상과 입력 텍스트 사이에 불가피한 간극이 존재하기 때문이다. 
    3. LLM을 사용해 쿼리를 생성하고, 웹 검색 엔진을 사용해 맥락을 검색한 후, 검색 대상 모듈에 대한 쿼리 조정을 위해 훈련 가능한 Rewriter 스킴을 제안한다. 실험 결과, 이 프레임워크는 일관된 성능 향상을 보여주며, retrieval-augmented LLM에 대한 효과적이고 확장 가능한 새로운 프레임워크를 제공한다는 것을 입증한다.

###### PromptMix: A Class Boundary Augmentation Method for Large Language Model Distillation (https://aclanthology.org/2023.emnlp-main.323/)
- Anthology ID: 2023.emnlp-main.323 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 데이터 증강은 훈련 데이터가 한정적인 경우 텍스트 분류 문제를 해결하기 위해 널리 사용되는 기술인데, 이 논문은 큰 언어 모델(GPT3)을 사용하여 더 유용한 증강 데이터를 생성하는 방법을 제안한다. 
    2. 제안된 메소드인 PromptMix는 어려운 경계 예제를 생성하고, 생성된 데이터의 정확성을 향상시키기 위해 LLM 분류기를 사용하여 라벨을 다시 지정한다. 
    3. 실험 결과, PromptMix는 2-shot 설정에서 여러 5-shot 데이터 증강 방법보다 성능이 우수하며, 큰 언어 모델의 지식을 작은 분류기로 전달하는 데 도움이 된다는 것을 보였다.

###### COHESENTIA: A Novel Benchmark of Incremental versus Holistic Assessment of Coherence in Generated Texts (https://aclanthology.org/2023.emnlp-main.324/)
- Anthology ID: 2023.emnlp-main.324 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "일관성(coherence)은 텍스트의 작은 단위들(문장, 명제) 간의 관계를 의미하며, 텍스트를 논리적으로 일관되고 의미 있는 것으로 만드는 언어적인 개념이다. 전통적인 기계 번역을 위한 구문, 단어 정렬과 같은 일관성 측정 방법과는 달리, 이 논문에서는 CoheSentia라는 새로운 benchmark를 소개하여 자동 생성된 텍스트의 일관성 평가에 관한 명시적인 연구를 진행하였다." 
    2. "우리의 benchmark는 500개의 자동 생성된 단락과 인간의 주관적인 일관성 점수로 구성되어 있으며, 문장별로 일관성을 평가하는 점수와 해당 지점에서의 비일관성 원인을 상세히 표시하는 점수를 제공한다." 
    3. "실험 결과, 일관성 감지를 위해 fine-tuned 된 표준 LMs는 다양한 일관성 요소에 대해 다양한 성능을 보여주었으며, 이러한 모델들은 신뢰할 수 있는 일관성 평가 방법 개발의 필요성을 강조한다."

###### QUDeval: The Evaluation of Questions Under Discussion Discourse Parsing (https://aclanthology.org/2023.emnlp-main.325/)
- Anthology ID: 2023.emnlp-main.325 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Questions Under Discussion (QUD)은 지속적인 질문과 그에 대한 답변을 통해 담론이 진행되는 다재다능한 언어적 구조이다. 이 논문에서는 문헌과 답변 문장을 제공받아 QUD의 언어적 제약을 만족하고 이전 문맥의 앵커 문장에 기반한 질문을 생성하는 복잡한 문제를 소개한다.
    2. 이 논문에서는 QUD 파싱의 자동 평가를 위한 첫 번째 프레임워크를 소개하며, QUD의 이론적 제약을 구체적인 프로토콜로 구현한다. 
    3. 이 논문은 QUDeval이라는 fine-tuned 시스템과 LLM으로부터 생성된 2,190개의 QUD 질문에 대한 세밀한 평가 데이터셋을 제안하며, 기존의 평가 메트릭은 파서의 품질을 부정확하게 추정한다는 것을 보여준다.

###### PRCA: Fitting Black-Box Large Language Models for Retrieval Question Answering via Pluggable Reward-Driven Contextual Adapter (https://aclanthology.org/2023.emnlp-main.326/)
- Anthology ID: 2023.emnlp-main.326 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Retrieval Question Answering (ReQA) 작업에서는 retriever와 generator로 구성된 retrieval-augmented framework이 사용된다. generator는 retriever가 검색한 문서를 기반으로 답변을 생성한다. 그러나 대부분의 Large Language Models (LLMs)은 예산 제약으로 인해 fine-tuning하기에 너무 크고, 일부 LLMs는 API를 통해서만 접근 가능하다. 이 문제에 대해 개선하고 ReQA 성능을 향상시키기 위해 우리는 trainable한 Pluggable Reward-Driven Contextual Adapter (PRCA)를 제안한다.
    2. PRCA는 retriever와 generator 사이에 Pluggable한 방식으로 위치하며, 강화학습 기반 reward를 최대화하는 token-autoregressive 전략으로 retrieved 정보를 개선한다. 실험을 통해 PRCA의 효과를 입증하고, 기존의 framework에 black-box LLMs을 효과적으로 적용하여 ReQA 성능을 최대 20% 향상시킬 수 있음을 보여준다.
    3. 이 논문은 LLMs 시대에 PRCA가 가지는 상당한 잠재력을 보여줌으로써, 기존의 framework에 black-box LLMs을 효과적으로 적용함으로써 ReQA 성능을 향상시키는 가능성을 보여준다.

###### Exploring Chain of Thought Style Prompting for Text-to-SQL (https://aclanthology.org/2023.emnlp-main.327/)
- Anthology ID: 2023.emnlp-main.327 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에는 대용량 언어 모델 (LLM)의 문맥 학습이 여러 가지 작업에 대한 우수한 퓨샷 성능으로 인해 많은 관심을 받고 있다. 그러나 텍스트- SQL 파싱에서의 성능은 여전히 크게 향상될 여지가 있다. 
    2. 이 논문에서는 텍스트- SQL 파싱에 대한 LLM의 성능을 향상시키기 위한 핵심적인 측면은 다단계 추론 능력임을 가정한다. 그러므로 우리는 LLM의 추론 능력을 최적화하기 위해 chain-of-thought (CoT) 스타일 프롬프팅을 체계적으로 연구한다.
    3. 우리의 실험은 텍스트- SQL 파싱에는 최소-최대 프롬프팅과 같은 반복적인 프롬프팅이 필요하지 않을 수 있으며, 상세한 추론 단계를 사용하는 것은 오류 전파 문제가 더 많이 발생할 수 있다는 것을 보여준다. 이러한 결과를 바탕으로 우리는 텍스트- SQL 파싱을 위한 새로운 CoT 스타일 프롬프팅 방법을 제안한다.

###### Efficient Algorithms for Recognizing Weighted Tree-Adjoining Languages (https://aclanthology.org/2023.emnlp-main.328/)
- Anthology ID: 2023.emnlp-main.328 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 트리-결합 언어의 클래스는 컨텍스트-자유 문법 (CFG) 또는 pushdown 자동기계 (PDA)가 다른 CFG 또는 PDA를 제어하는 다양한 이중 형식을 사용하여 특성화될 수 있다.
    2. 이 논문에서는 위의 이중 형식들의 반지름-가중친 버전을 정의하고, 그들의 문자합 (문자 파생을 위한 가중치)과 전체합 (모든 파생의 가중치)을 계산하기 위한 새로운 알고리즘을 설계한다.
    3. 또한, TAG, LIG, PAA 및 EPDA에 대한 문자합과 전체합 알고리즘을 즉시 얻는다. (Vijay-Shanker and Weir (1989) 알고리즘에 비해 LIG의 경우 약 O(N|𝒩|) 시간적 효율성 및 O(𝛤) 공간적 효율성을 가지며, EPDA의 경우 Alonso et al. (2001) 알고리즘에 비해 O(𝛤^2) 및 O(|𝛤|3) 이상의 공간적 및 시간적 효율성을 갖는다.)

###### Harnessing Black-Box Control to Boost Commonsense in LM’s Generation (https://aclanthology.org/2023.emnlp-main.329/)
- Anthology ID: 2023.emnlp-main.329 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. GPT-3와 같은 대형 언어 모델은 일관성 있고 문맥에 적절한 텍스트를 생성할 수 있다. 그러나 생성된 출력물은 때때로 상식이 부족한 문제가 여전히 존재한다.
    2. 이 논문에서는 기존 Pre-Trained Language Model (PTLM)을 공통적 의미론적 특성을 더 잘 반영하도록 유도하는 계산 효율적인 프레임워크를 제안한다.
    3. 구축한 판단기를 가이드로 삼아 PTLM을 향상시키고, GPT-2, Flan-T5, Alpaca 기반 언어 모델에 적용하는 실험 결과, 가장 상식적인 출력이 나왔다고 보여진다.

###### Just Ask for Calibration: Strategies for Eliciting Calibrated Confidence Scores from Language Models Fine-Tuned with Human Feedback (https://aclanthology.org/2023.emnlp-main.330/)
- Anthology ID: 2023.emnlp-main.330 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 실제 예측 시스템은 신뢰할 수 있는 확신 점수를 제공해야 하며, 답변에 대한 신뢰도는 정확한 답변의 가능성을 나타내어 신뢰도가 낮은 예측의 경우 전문가에게 이관할 수 있어야 한다.
    2. 최근 연구에 따르면, 관찰되는 현상에 대해 RLHF-LMs는 확지확율이 매우 나쁘게 보인다고 제안되었다. 이를 고려하여 우리는 RLHF-LMs에서 신뢰점수를 추출하는 다양한 방법을 평가한다.
    3. 우리의 연구에서는 ChatGPT, GPT-4, Claude와 같은 RLHF-LMs에 대해 TriviaQA, SciQ, TruthfulQA 벤치마크에서 출력 토큰으로 출력되는 신뢰 점수가 종종 기존의 조건부 확률과 비교하여 예상된 보정 오차를 상대적으로 50% 줄일 수 있음을 발견했다.

###### Representative Demonstration Selection for In-Context Learning with Two-Stage Determinantal Point Process (https://aclanthology.org/2023.emnlp-main.331/)
- Anthology ID: 2023.emnlp-main.331 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. In-Context Learning은 다양한 task에 효과적이지만, 시연 선택에 따라 그 효율이 크게 달라지고 있다. 기존 방법은 각 테스트 인스턴스마다 다른 시연을 선택하는데, 이는 시간 소모가 많고 실제 상황에서 제약사항이 있다. 이 논문은 특정 task에서 다양한 테스트 인스턴스를 효과적으로 유발할 수 있는 대표적인 in-context 시연의 부분집합을 선택하는 도전에 대해 다룬다. 
    2. 우리는 이 대표적인 부분집합이 높은 품질과 다양성을 갖추어야 한다고 제안한다. 실험 결과, 이러한 기준을 충족하는 시연은 모델의 성능을 향상시킬 수 있다는 것을 확인하였다. 
    3. 이를 위해, 우리는 품질과 다양성을 모두 고려한 두 단계의 Determinantal Point Process (DPP) 방법을 도입하여 대표적인 in-context 시연을 선택한다. 실험을 통해 우리의 제안 방법의 효과를 확인하였고, 더 실용적이고 효과적인 In-Context Learning을 위한 기반을 마련했다.

###### The Effect of Scaling, Retrieval Augmentation and Form on the Factual Consistency of Language Models (https://aclanthology.org/2023.emnlp-main.332/)
- Anthology ID: 2023.emnlp-main.332 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델은 사실 기반 지식에 자연스런 인터페이스를 제공하지만, 의미적으로 동일한 질문에 일관성 없는 답변을 하는 경향이 있다.
    2. 이 연구에서는 이러한 일관성의 원인을 파악하고, 두 가지 개선 전략인 up-scaling과 LM에 패시지 검색 데이터베이스를 추가하는 것의 효과를 평가한다.
    3. LLaMA 및 Atlas 모델에 대한 결과는 두 전략 모두 일관성을 감소시키지만, 검색 강화가 더 효율적임을 보여준다는 것을 보여준다. 또한, Atlas의 다양한 구성 요소들이 일관성에 어떤 기여를 하는지도 고려하고 분리한다.

###### ViPE: Visualise Pretty-much Everything (https://aclanthology.org/2023.emnlp-main.333/)
- Anthology ID: 2023.emnlp-main.333 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 비유적 표현과 비문법적 표현은 인간의 의사소통에서 깊이 통합되어 있다. 
    2. 이 연구에서는 이미지에 이러한 표현을 시각화하여 문화적인 생각을 전달하고 유감미 넘치는 감정을 불러일으킬 수 있는 "ViPE"를 소개한다.
    3. ViPE는 대규모로 훈련된 가사 데이터셋을 기반으로한 경량이고 강력한 언어 모델로, 인간 주석이나 이미지에 의존하지 않는다. ViPE는 임의의 텍스트를 시각적으로 표현 가능한 설명으로 변환하여 의미 있는 고품질 이미지 생성을 가능하게 한다.

###### Semi-automatic Data Enhancement for Document-Level Relation Extraction with Distant Supervision from Large Language Models (https://aclanthology.org/2023.emnlp-main.334/)
- Anthology ID: 2023.emnlp-main.334 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 문서 수준의 관계 추출 (DocRE)은 긴 맥락에서 관계를 추출하는 것으로, 세밀한 구조적 이해와 해석 가능한 문서 표현을 이루는 데 있어 중요한 도전과제이다.
    2. 이 논문은 대형 언어 모델 (LLM)인 ChatGPT와 같은 대형 모델의 in-context 학습 능력에서 영감을 받아 최소한의 인간 노력으로 DocRE를 자동 주석 처리하는 방법을 제안한다.
    3. 이를 위해, 사전에 정의된 다양한 세밀한 관계 유형과 LLM의 불규칙한 생성으로 인해 vanilla in-context 학습을 DocRE에 사용하기 어렵기 때문에, LLM과 자연어 추론 (NLI) 모듈을 통합하여 관계 삼중체를 생성하는 방법을 제안하고 이를 통해 문서 수준의 관계 데이터셋을 확장한다.

###### Navigating the Grey Area: How Expressions of Uncertainty and Overconfidence Affect Language Models (https://aclanthology.org/2023.emnlp-main.335/)
- Anthology ID: 2023.emnlp-main.335 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 실제 지식과 사실을 포함하는 실제 작업에 대한 LMs의 증가된 배치는 LMs가 무엇을 알고 있는지와 해당 지식에 대한 태도가 입력에서의 언어 사용에 어떻게 영향을 받는지 이해하는 것이 중요하다. 
    2. 우리는 epistemic marker의 여러 종류와 그들이 모델에 어떻게 영향을 주는지, 그리고 모델의 실패에 기여하는지를 연구한다. 
    3. 우리는 epistemic marker를 prompt로 삽입하고, LMs가 epistemic marker에 매우 민감하다는 것을 알게 되었다. 놀랍게도, 높은 확신의 표현은 정확성이 낮은 표현에 비해 7% 감소시키고, 사실을 나타내는 동사는 성능을 저하시키고, 증거를 나타내는 단어는 성능을 향상시킨다.

###### Elaborative Simplification as Implicit Questions Under Discussion (https://aclanthology.org/2023.emnlp-main.336/)
- Anthology ID: 2023.emnlp-main.336 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자동 텍스트 간소화는 복잡한 문장을 단순화된 문장으로 번역하는 단일 언어 번역 작업으로 간주되는 경우가 많다. 이 논문은 새로운 정보가 단순화된 텍스트에 추가되는 갈라놓는 단순화(elaborative simplification)를 고려해야 한다고 제안한다. 
    2. Question Under Discussion (QUD) 프레임워크로부터 갈라놓는 단순화를 바라보면, 작가들은 암묵적 질문에 대한 명시적 답변으로 갈라놓는다. 
    3. 이 논문에서는 ELABQUD 데이터셋을 소개하고, QUD 모델링을 통해 단순화의 품질을 향상시킬 수 있음을 보여준다.

###### EntSUMv2: Dataset, Models and Evaluation for More Abstractive Entity-Centric Summarization (https://aclanthology.org/2023.emnlp-main.337/)
- Anthology ID: 2023.emnlp-main.337 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Entity-centric summarization은 특정 entity에 대한 document의 요약을 생성하는 controllable summarization 형태로, 관련 어플리케이션에서 중요하다. 
    2. ENTSUMV2는 원래의 entity-centric ENTSUM 요약 dataset의 발전된 버전이다. 
    3. 이 논문에서는 supervised fine-tuning이나 large-scale instruction tuning을 사용하는 다양한 abstractive summarization 접근 방법으로 이 dataset에 대해 실험을 진행하고 당면 시스템들의 성능을 세밀하게 평가하고 향후 개선 방향을 제시한다.

###### SciRepEval: A Multi-Format Benchmark for Scientific Document Representations (https://aclanthology.org/2023.emnlp-main.338/)
- Anthology ID: 2023.emnlp-main.338 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 과학 문서 표현 평가 기준은 관련된 다양한 작업들의 다양성을 포착하지 못한다. 그래서 이 논문에서는 과학 문서 표현 모델의 일반화 능력을 개선하기 위한 첫 번째 종합적인 평가 기준인 SciRepEval을 소개한다. 이 평가 기준을 사용하여 SPECTER와 SciNCL과 같은 최신 모델의 일반화 능력을 연구하고 개선함을 보여준다.
    2. SPECTER2라는 다양한 형식들을 위한 멀티 포맷 모델 패밀리를 발표하고, 이 모델은 과학 문서 표현의 성능을 개선한다. 
    3. 이 논문에서는 문서에 대한 여러 개의 임베딩을 학습하는 새로운 접근 방식을 제시하고, 이를 통해 기존의 단일 임베딩 기반 최신 방법보다 더 뛰어난 성능을 보여준다.

###### A Diachronic Perspective on User Trust in AI under Uncertainty (https://aclanthology.org/2023.emnlp-main.339/)
- Anthology ID: 2023.emnlp-main.339 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인간-인공지능 협업에서 사용자들은 AI 시스템에 대한 "mental model"을 형성하게 되는데, 이는 시스템의 정확성과 예측 설명, 예측에 대한 신뢰도 등을 고려하여 형성된다. 그러나 현대의 NLP 시스템은 자주 confidence calibration이 이루어지지 않으며, 자신의 예측에 대해 자신감을 가지고 있는 경우가 많아 신뢰를 깎아내리게 된다. 
    2. 이 연구에서는 사용자들에게 NLP 시스템의 정확성에 대한 베팅을 시도하게 하고, 이를 통해 신뢰의 변화와 그 회복에 대해 연구한다.
    3. 몇 개의 불확실한 예측이 사용자의 신뢰를 상실시키고, 이후 시간이 지나도 회복이 어려움을 발견했으며, 신뢰를 회복하기 위해서는 확신을 가지고 잘못된 예측보다는 불확실한 상태에서 정확한 예측을 하는 것이 더 바람직함을 발견했다.

###### CT-GAT: Cross-Task Generative Adversarial Attack based on Transferability (https://aclanthology.org/2023.emnlp-main.340/)
- Anthology ID: 2023.emnlp-main.340 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존 전이 기반 방법들은 치료 모델을 사용하기 때문에 세부 정보가 없거나 실용적이지 않아 현실적인 상황에서 구현하는 것이 어렵다.
    2. 여기서는 다른 작업에 걸쳐 전이 가능한 특징을 추출하여 직접적으로 적대적인 예시를 구축하는 새로운 방법을 제안한다.
    3. 실험 결과, 작은 비용으로 우리의 방법이 우수한 공격 성능을 달성한다는 것을 보여준다.

###### Improving Long Document Topic Segmentation Models With Enhanced Coherence Modeling (https://aclanthology.org/2023.emnlp-main.341/)
- Anthology ID: 2023.emnlp-main.341 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 주제 분할은 구조화된 문서를 얻고 정보 검색과 같은 하위 작업의 성능을 향상시키기 위해 중요하다. 이 논문에서는 Topic-aware Sentence Structure Prediction (TSSP)와 Contrastive Semantic Similarity Learning (CSSL)을 제안하여 지도 모델이 논리적 구조와 의미적 유사성 측면에서 일관성을 파악할 수 있도록 모델의 능력을 강화하였다.
    2. TSSP는 모델이 무질서한 문서에서 문장 간 원래 관계를 학습함으로써 구조적 정보를 이해하도록 하는 작업이다. 이러한 불규칙한 문서는 주제와 문장 수준에서 원본 문서를 동시에 파괴하여 생성된다.
    3. 실험 결과, 우리의 방법을 활용한 Longformer가 이전의 최첨단 기법에 비해 크게 우수한 성능을 보였다. 우리의 방법은 WIKI-727K 데이터셋에서 이전 기법의 F1를 3.42 (73.74 → 77.16) 개선시켰으며, WikiSection에서는 Pk를 1.11 점 (15.0 → 13.89) 감소시켰다. 또한 두 개의 서로 다른 도메인 데이터셋에서는 평균 상대 Pk 감소율이 8.38%로 우리의 방법의 강건성을 입증하였다.

###### Dialogue Chain-of-Thought Distillation for Commonsense-aware Conversational Agents (https://aclanthology.org/2023.emnlp-main.342/)
- Anthology ID: 2023.emnlp-main.342 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인류와 유사한 챗봇을 만들기 위해서는 대화 속 암시적인 정보를 효과적으로 이해하고 응답하기 위해 상식적 추론이 필요하다. 그러나 대화 속에서 핵심 증거를 식별하고 통합하는 일은 대규모 언어 모델에게도 어려운 작업이다. 이 논문에서는 이러한 다중 호핑 추론을 위해 지식 전달 기법을 제안한다. 
    2. 불안정한 선생님 역할을 하는 LLMs (대규모 언어 모델)로부터 일관된 지식을 추출하기 위한 지식 전달 프레임워크를 제안한다. 이를 통해 신뢰할 수 있는 CoT (대화주제의 연속성) 이유를 통해 대답을 생성할 수 있는 DOCTOR라고 하는 도구를 제공한다. 
    3. 실험 결과, DOCTOR를 통해 대화 에이전트의 응답 품질을 크게 향상시킬 수 있음을 보여준다.

###### Information Value: Measuring Utterance Predictability as Distance from Plausible Alternatives (https://aclanthology.org/2023.emnlp-main.343/)
- Anthology ID: 2023.emnlp-main.343 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 우리는 다른 가능성의 합리적 대안에 상대하여 언어 표현의 예측 가능성을 측정하는 정보 가치라는 지표를 제시한다.
    2. 우리는 신경 네트워크를 사용하여 정보 가치를 해석 가능한 방법으로 추정하는 방법을 도입하고, 그들의 심리학적 예측 능력을 활용하여 인간의 이해 행동을 이끌어내는 예측 가능성의 차원을 조사한다. 
    3. 정보 가치는 토큰 수준의 놀람(aggregates of token-level surprisal)보다 작성 및 말하기 다이얼로그에서 발화의 수용 가능성을 더 강력하게 예측하며, 눈 추적 독서 시간을 예측하기 위해 놀람과 보완적인 역할을 한다.

###### Generating Commonsense Counterfactuals for Stable Relation Extraction (https://aclanthology.org/2023.emnlp-main.344/)
- Anthology ID: 2023.emnlp-main.344 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 대조적 확장 데이터 연구는 대개의 자연어 처리 과제에서 큰 성과를 이뤄냈다. 그러나 세부관계 추출 과제에서는 발생하는 두 가지 주요 문제가 있다. 첫째, 인과적 개념을 불변적으로 제한된 entity에서 정확하게 식별하기 어렵다. 둘째, 생활 상식(sense) 제약을 무시한다. 
    2. 이러한 문제를 해결하기 위해 우리는 안정적인 관계 추출을 위해 생성된 상식적 대조 사례에 대한 새로운 프레임워크를 제안한다. 구체적으로, 인과적인 용어를 정확하게 식별하기 위해 개입(인터벤션) 기반 전략을 도입하고, 구문 분석기를 사용하여 보정한다. 생활 상식 제약을 충족하기 위해 우리는 지식 베이스인 WordNet을 도입하고 하향식 관계 확장 알고리즘을 설계하여 entity 간의 생활 상식적 관계를 발견한다.
    3. 저희는 저자들이 저런 문제를 고려하여, 전래 추출 모델을 안정화하는 접근법을 소개함으로써, 다양한 평가, 심지어 자원이 적거나 타 도메인의 데이터, 공격적인 공격 등 실제 환경에서 안정성을 향상시킬 수 있음을 실험 결과를 통해 입증하였습니다.

###### C-STS: Conditional Semantic Textual Similarity (https://aclanthology.org/2023.emnlp-main.345/)
- Anthology ID: 2023.emnlp-main.345 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Semantic textual similarity (STS)는 NLP의 중요한 태스크인데, 문장 간의 유사성을 측정한다. 그러나 이 태스크는 특정 관점에 의존하여 문장의 유사성이 달라질 수 있는 모호한 문제다. 이 논문에서는 관련된 측면을 자연어로 명시하는 새로운 조건부 STS(C-STS)를 제안해서 STS의 주관성과 모호성을 해결하고 다양한 조건에서 문장의 세밀한 유사성을 평가할 수 있게 한다.
    2. C-STS는 약 20,000개의 다양한 도메인에서 문장 쌍을 포함하고 있으며, GPT-4, Flan, SimCSE와 같은 최첨단 모델들에 대한 실험을 통해 낮은 상관관계 점수를 얻는 등 어려움을 겪는 것을 보여준다.
    3. 이를 통해 저자들은 C-STS에서 세마틱 유사성과 자연어 이해에 대한 모델의 종합적인 평가를 제공할 것을 독려하고 있다.

###### Cross-lingual Transfer Can Worsen Bias in Sentiment Analysis (https://aclanthology.org/2023.emnlp-main.346/)
- Anthology ID: 2023.emnlp-main.346 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 감성 분석 시스템에서는 인종적 편견 문제가 있으며, 이러한 시스템에서는 transfer learning을 통해 다른 언어로 훈련된 pre-trained 모델을 사용한다.
    2. 이 연구에서는 다국어 transfer의 경우 성별이나 인종적 편견이 더욱 심화되는 경향이 있다는 것을 발견했다.
    3. 이에 따라 본 연구에서는 해당 분야의 추가 연구를 위해 사용된 sentiment 모델과 중간 체크포인트를 공개한다.

###### Rumor Detection on Social Media with Crowd Intelligence and ChatGPT-Assisted Networks (https://aclanthology.org/2023.emnlp-main.347/)
- Anthology ID: 2023.emnlp-main.347 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 소셜 미디어를 통한 광범위한 정보 전파 시대에서 소문 탐지의 과제는 신뢰할 수 있는 정보 환경을 구성하는 데 중요한 역할을 한다. 
    2. 기존 소문 탐지 연구는 텍스트 인코딩 시퀀스의 한계, 도메인 지식 커버리지 및 지식 그래프 기반 방법을 통한 효과적인 정보 추출 및 의미 구조 정보의 부족이라는 여러 가지 도전에 직면하고 있다. 
    3. 이 논문에서는 소문 분류를 위해 인공지능 기반 크라우드 소스와 ChatGPT-Assisted Network(CICAN)을 제안한다. 이를 통해 순차적 및 계층적 특징을 포착하는 크라우드 소스 기반 의미 기능 학습 모듈과 지식 향상을 위해 ChatGPT를 활용하는 지식 기반 의미 구조 규모 모듈이 설계되었다.

###### Grounding Visual Illusions in Language: Do Vision-Language Models Perceive Illusions Like Humans? (https://aclanthology.org/2023.emnlp-main.348/)
- Anthology ID: 2023.emnlp-main.348 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Vision-Language Models (VLMs)은 인간의 세계 이해를 모사하는 인간들에 의해 수집된 방대한 양의 데이터를 기반으로 학습되었습니다. 그러나, 시각적 환각으로 알려진 대로, 인간의 현실 인식은 항상 실제 세계와 일치하지 않을 수 있습니다. 이로 인해 주요한 질문이 제기됩니다. VLMs는 인간과 같은 환각을 가지고 있는 걸까요? 아니면 실제 세계를 충실히 학습하는 건가요?
    2. 이 질문에 답하기 위해, 우리는 다섯 가지 유형의 시각적 환각을 포함하는 데이터셋을 구축하고 최신 VLMs에서 시각적 환각을 조사하기 위해 네 가지 작업을 정의했습니다.
    3. 우리의 연구 결과는 전반적으로 정렬이 낮지만, 더 큰 모델일수록 인간의 인식에 더 가깝고 시각적 환각에 더 취약하다는 것을 보여줍니다. 우리의 데이터셋과 초기 결과는 인간과 기계가 공유된 시각적 세계에 대해 인간과 기계를 더 잘 조화시킬 수 있는 미래의 계산 모델을 위한 기반을 마련할 것입니다.

###### Analysing State-Backed Propaganda Websites: a New Dataset and Linguistic Study (https://aclanthology.org/2023.emnlp-main.349/)
- Anthology ID: 2023.emnlp-main.349 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 Reliable Recent News (rrn.world)와 WarOnFakes (waronfakes.com)라는 두 사이트를 분석하여 국가 지원을 받은 가짜 뉴스에 대한 연구를 수행한다.
    2. 이들 사이트는 아랍어, 중국어, 영어, 프랑스어, 독일어, 스페인어로 콘텐츠를 발행하고 있으며, 이에 대한 다국어 데이터셋을 사용하여 토픽 클러스터링을 수행한다.
    3. 이 논문의 주요 기여는 가짜 뉴스 탐지를 위한 NLP 도구의 훈련에 필요한 고유한 데이터셋을 마련하고, 가짜뉴스 네트워크에 대한 연구를 가능하게 한다.

###### Controllable Contrastive Generation for Multilingual Biomedical Entity Linking (https://aclanthology.org/2023.emnlp-main.350/)
- Anthology ID: 2023.emnlp-main.350 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다국어 바이오메디컬 entity linking(MBEL)은 생명과학 텍스트의 언어별 언급을 표준화된 개념(예: Unified Medical Language System)에 연결하는 것을 목표로 한다.
    2. Con2GEN은 MBEL을 판별적 분류기가 아닌 시퀀스-투-시퀀스 생성 과제로 정의함으로써 소스 언급과 타깃 entity 사이의 공유 종속성을 더 잘 활용한다.
    3. Con2GEN은 가능한 많은 언어와 유형의 UMLS 개념과 일치시켜 교차 정보의 모호성 해소를 용이하게 한다. 실험 결과, 이 모델은 12개 다양한 언어를 포함한 XL-BEL 및 Mantra GSC 데이터셋에서 몇 가지 최신 기술과 비교하여 유망한 성능 향상을 달성한다.

###### HyperRouter: Towards Efficient Training and Inference of Sparse Mixture of Experts (https://aclanthology.org/2023.emnlp-main.351/)
- Anthology ID: 2023.emnlp-main.351 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Sparse Mixture-of-Experts는 대규모 언어 모델의 효율적인 학습을 가능하게 해주는데, 최근 연구에서 모든 전문가가 결국 유사한 표현을 학습하는 문제를 완화하기 위해 router를 고정시키면 경쟁력있는 성능을 얻을 수 있다고 밝혀졌다.
    2. 하지만 이 전략은 두 가지 주요한 제한이 있는데, 첫째, 무작위 router에서 유도된 정책이 최적화가 되지 못할 수 있고, 둘째, 학습과 평가 과정에서 많은 자원을 필요로 하여 효율성의 한계가 발생할 수 있다.
    3. 이 논문에서는 HyperRouter를 소개하는데, 이는 고정된 하이퍼네트워크와 학습 가능한 임베딩을 통해 동적으로 router의 매개변수를 생성하여 더 나은 라우팅 정책을 학습하면서 라우터를 학습하고 고정시키는 균형을 이룬다. 다양한 태스크를 통해 수행된 실험은 HyperRouter의 우수한 성능과 효율성을 보여주었다.

###### MediaHG: Rethinking Eye-catchy Features in Social Media Headline Generation (https://aclanthology.org/2023.emnlp-main.352/)
- Anthology ID: 2023.emnlp-main.352 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 소셜 미디어 플랫폼에서의 매력적인 블로그 제목은 독자의 관심을 끌고 더 많은 클릭을 유도할 수 있습니다. 그러나 좋은 제목은 주요 내용을 압축하는 것뿐만 아니라 웹 사이트의 사용자와 목적에 의해 결정되는 도메인 플랫폼 특징으로도 눈에 띄어야 합니다. 
    2. 이 연구에서는 콘텐츠와 문맥적 특징을 균형있게 고려하는 headline generation 모델인 MediaHG (Social Media Headline Generation)을 제안합니다. 
    3. REDBook (중국 소셜 미디어 플랫폼)에서 수집된 70k개의 핫 포스트의 콘텐츠와 제목을 사용하여 실험 결과는 headline generation 태스크의 개선을 보여줍니다.

###### Fine-tuned LLMs Know More, Hallucinate Less with Few-Shot Sequence-to-Sequence Semantic Parsing over Wikidata (https://aclanthology.org/2023.emnlp-main.353/)
- Anthology ID: 2023.emnlp-main.353 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 큰 언어 모델(Large Language Models)은 많은 질문에 정확한 답을 할 수 있지만, 가끔 옳지 않은 답도 낼 수 있다. 본 논문에서는 Wikidata를 활용하여 언어 모델의 사실성을 향상시키기 위한 WikiWebQuestions라는 높은 품질의 질문-답변 벤치마크를 제안한다. 
    2. 이 논문에서는 Wikidata에 대한 few-shot sequence-to-sequence semantic parser를 제안한다. SPARQL을 수정하여 고유한 도메인과 속성명을 사용하고, entity linker의 결과나 쿼리 내의 언급을 활용하여 parser를 훈련시킨다. 
    3. 그 결과, 우리의 방법은 WikiWebQuestions의 dev와 test 세트에서 각각 76%와 65%의 답변 정확도를 보이며, QALD-7 Wikidata 데이터셋에서는 F1 score에서 최신 기법보다 3.6% 더 우수한 성능을 보인다.

###### ZEROTOP: Zero-Shot Task-Oriented Semantic Parsing using Large Language Models (https://aclanthology.org/2023.emnlp-main.354/)
- Anthology ID: 2023.emnlp-main.354 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 연구에서는 대규모 언어 모델 (LLM) 을 사용하여 zero-shot 의미 파싱을 탐구한다. 의미 파싱은 자연어 발화를 과제에 특화된 의미 표현으로 매핑하는 작업을 의미한다. 
    2. 우리는 LLM이 제로샷 환경에서 도메인 특화 파싱 작업에 직접적으로 일반화될 수 없다는 문제를 해결하기 위해 ZEROTOP이라는 제로샷 과제 지향 파싱 방법을 제안한다. 
    3. 실험 결과, QA 기반 분해와 fine-tuned LLM을 결합한 우리의 접근법은 MTOP 데이터셋에서 약 16%의 발화를 zero-shot으로 파싱할 수 있다는 것을 보여준다.

###### Efficient Grammatical Error Correction Via Multi-Task Training and Optimized Training Schedule (https://aclanthology.org/2023.emnlp-main.355/)
- Anthology ID: 2023.emnlp-main.355 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 네트워크 문법 오류 수정(GEC)에서의 진전은 주석이 달려 있는 훈련 데이터의 부족으로 어려움을 겪고 있다. 이 논문에서는 사용 가능한 데이터를 보다 효율적으로 활용하는 두 가지 방법을 제안한다.
    2. 우선, 원래 문장과 수정된 문장 사이의 매핑을 활용한 보조 작업을 제안하고, 시퀀스-투-시퀀스 문제로 정의하여 멀티태스크 학습을 수행한다.
    3. 또한, 훈련에 사용되는 데이터셋의 순서와 개별 인스턴스의 순서는 최종 성능에 중요한 영향을 미친다는 것을 발견하고, 최적의 훈련 일정을 찾기 위해 연구한다. 이 두 가지 아이디어는 크기가 작은 모델로도 최신 기술을 개선하는 결과를 도출하여 T5-XXL(110B 파라미터)을 기반으로 한 최고의 모델을 BART 기반 모델로 능가한다.

###### The BLA Benchmark: Investigating Basic Language Abilities of Pre-Trained Multimodal Models (https://aclanthology.org/2023.emnlp-main.356/)
- Anthology ID: 2023.emnlp-main.356 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사전 학습된 언어와 시각 모델들의 하향 작업 성능이 인지모형에 기반한 이미지-텍스트 상호작용을 제대로 이해하는 것인지에 대한 의문이 남아있습니다.
    2. 이 연구에서는 유치원 아이들도 일반적으로 이해할 수 있는 능력인 능동-수동태, 연결어 및 관계절을 얼마나 잘 처리하는지 알아보기 위해 다양한 기존 모델과 새로운 벤치마크인 BLA를 사용하여 평가하였습니다.
    3. 실험 결과, 대부분의 모델들은 구체적인 구문을 사용하여 세밀하게 조정하거나 문맥 학습 환경에서 약간의 향상만을 보였지만, 생성 모델인 BLIP2는 희망적인 결과를 보여주어 BLA를 평가 벤치마크로 사용하고 모델의 기본 언어 능력을 향상시킬 수 있는 가능성을 열었습니다.

###### RainProof: An Umbrella to Shield Text Generator from Out-Of-Distribution Data (https://aclanthology.org/2023.emnlp-main.357/)
- Anthology ID: 2023.emnlp-main.357 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 번역부터 챗봇까지 NLP 모델의 적절한 기능과 보안을 보장하기 위해 효과적인 제어 메커니즘을 구현하는 것이 중요하다. 이 논문은 OOD(Out-Of-Distribution) 감지를 위해 블랙박스 프레임워크에서 soft-probabilities을 활용하는 방법에 초점을 맞추었다.
    2. 기존의 OOD 감지 방법들은 대부분 인코더의 hidden features에 의존하는 데 반해, 이 논문은 내부 상태에는 접근하지 못하지만 soft-predictions에 접근할 수 있는 블랙박스 프레임워크에서 soft-probabilities를 활용한다.
    3. 실험 결과, RAINPROOF는 전통적인 OOD 감지 방법보다 태스크 특정 성능 측정과 더 일치하는 OOD 감지 방법을 제공한다는 것을 보여주고 있다.

###### KEPL: Knowledge Enhanced Prompt Learning for Chinese Hypernym-Hyponym Extraction (https://aclanthology.org/2023.emnlp-main.358/)
- Anthology ID: 2023.emnlp-main.358 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Hypernym-hyponym ('is-a') 관계를 모델링하는 것은 분류, 자연어 추론 및 관계 추출과 같은 많은 자연어 처리 (NLP) 작업에서 매우 중요합니다. 기존의 is-a 관계 추출 연구는 대부분 영어 환경에서 이루어지고 있으며, 언어 표현의 유연성과 고품질의 중국어 주석 데이터셋의 부족으로 인해 중국어 비구조화된 텍스트에서 이러한 관계를 정확하게 식별하는 것은 여전히 도전과제입니다."
    2. 이 문제를 해결하기 위해, 우리는 중국어 hypernym-hyponym 관계 추출을 위한 지식 향상 프롬프트 학습 (KEPL) 방법을 제안합니다. 우리의 모델은 Hearst와 같은 패턴을 사전 지식으로 활용하며, Dynamic Adaptor Architecture를 이용하여 텍스트에 대한 매칭 패턴을 선택하여 모델은 동시에 패턴과 텍스트를 임베딩합니다.
    3. 또한, 우리는 중국 hypernym-hyponym 관계 추출 데이터셋을 만들었으며, 이는 baike, 뉴스 및 We-media와 같은 세 가지 대표적인 시나리오를 포함하고 있습니다. 데이터셋에서의 실험 결과는 우리가 제안한 모델의 효율성과 효과성을 입증하였습니다.

###### Ditto: A Simple and Efficient Approach to Improve Sentence Embeddings (https://aclanthology.org/2023.emnlp-main.359/)
- Anthology ID: 2023.emnlp-main.359 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 pre-trained 언어 모델, 예를 들어 BERT에서 fine-tuning 없이 문장 표현에서의 간극 문제를 진단하는 연구가 이전에 이루어졌으며, 
    2. 우리의 분석 결과 BERT의 문장 임베딩은 아무런 정보가 없는 단어에 편향(bias)되어 있으며 이는 문맥 의미 유사도 작업에서의 성능을 제한한다. 
    3. 이러한 편향 문제를 해결하기 위해 우리는 단순하고 효율적인 비지도 학습 방법인 Diagonal Attention Pooling (Ditto)을 제안한다. Ditto는 pre-trained 모델에서 단어의 중요성을 모델 기반으로 가중치를 부여하고 가중치가 부여된 단어 표현의 평균을 문장 임베딩으로 계산하는 방법이다. Ditto는 매개변수를 추가하지 않고 학습을 요구하지 않으므로 다양한 pre-trained 모델에서 쉽게 적용될 수 있다. 실험 결과, Ditto는 anisotropy 문제를 완화시키고 STS 벤치마크에서 다양한 pre-trained 모델의 성능을 향상시킬 수 있다.

###### Preserving Knowledge Invariance: Rethinking Robustness Evaluation of Open Information Extraction (https://aclanthology.org/2023.emnlp-main.360/)
- Anthology ID: 2023.emnlp-main.360 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. NLP 모델들이 정보 추출과 같은 실제 세계에서도 성공적으로 적용될 수 있는데, 이를 위해 robustness가 필요하다. 하지만 이전 평가 벤치마크들은 주로 pairwise matching 정확성을 검증하는 데에 초점을 맞추어 왔고, robustness를 중요하게 평가하지 않았다.
    2. 이 논문에서는 open information extraction 모델들의 robustness를 실제 세계에서의 평가를 시뮬레이션하는 첫번째 벤치마크를 제시한다. 신택스와 의미적 분포가 다양하게 변할 수 있는 같은 의미를 가진 구조화된 지식을 포함하는 문장들로 이루어진 크리크로 구성된 대규모 테스트베드를 설계하고 주석을 달았다.
    3. 이 대규모 테스트베드를 이용하여 실제로 발표된 모델 및 대표적인 대형 언어 모델에 대한 실험을 수행한 결과, 기존의 성공적인 모델들이 최대 23.43 F1 스코어 감소와 같은 실망스러운 저하를 보였다.

###### Why Should This Article Be Deleted? Transparent Stance Detection in Multilingual Wikipedia Editor Discussions (https://aclanthology.org/2023.emnlp-main.361/)
- Anthology ID: 2023.emnlp-main.361 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 온라인 플랫폼의 콘텐츠 중재는 일반적으로 비투명하다. 하지만 위키피디아에서는 이러한 토의가 공개적으로 이루어지며, 편집자들은 콘텐츠 중재 정책을 사용하여 중재 결정을 설명할 것을 권장받는다.
    2. 본 논문에서는 위키피디아 편집자들의 토의와 그들의 이유를 포함한 독창적인 다국어 데이터셋을 구축한다. 이 데이터셋은 각 편집 결정에 대한 편집자의 입장 (유지, 삭제, 통합, 코멘트)과 명시된 이유, 그리고 콘텐츠 중재 정책을 포함한다.
    3. 우리는 입장과 해당 이유 (정책)를 고도의 정확도로 공동으로 예측할 수 있음을 보여주며, 이는 결정 과정에 투명성을 추가한다는 것을 보여준다. 또한 우리는 공동 예측 모델과 다국어 콘텐츠 중재 데이터셋을 공개하여 자동화된 투명한 콘텐츠 중재에 대한 추가 연구를 위해 제공한다.

###### Fast and Robust Early-Exiting Framework for Autoregressive Language Models with Synchronized Parallel Decoding (https://aclanthology.org/2023.emnlp-main.362/)
- Anthology ID: 2023.emnlp-main.362 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Autoregressive 언어 모델의 높은 추론 지연 문제를 해결하기 위해 이전 연구에서는 후속 토큰 생성의 복잡성을 기반으로 각 토큰에 대한 적응형 계산 경로를 할당하는 초기 종료 (early-exiting) 프레임워크를 제안했으나, 상태 복사 메커니즘 또는 많은 종료 경로로 인한 성능 저하 및 종료 신뢰 임계값에 대한 민감성과 같은 몇 가지 단점이 관찰되었다.
    2. 이에 우리는 Fast and Robust Early-Exiting (FREE) 프레임워크를 제안하여 얕은-깊은 모듈과 동기화 병렬 디코딩을 통합하였다.
    3. 우리의 프레임워크는 현재 토큰의 디코딩 과정을 이전에 조기 종료된 토큰과 동기화하여 빠른 추론을 가능하게 한다. 또한 병렬 디코딩을 통해 얕은 모델과 깊은 모델의 예측을 관찰할 수 있으므로, Beta 혼합 모형을 활용하여 적절한 신뢰 임계값을 결정하는 새로운 적응형 임계값 추정기를 제시한다. 우리는 다양한 생성 태스크에서 우리가 제안한 프레임워크의 우수성을 실험적으로 입증하였다.

###### End-to-end Task-oriented Dialogue: A Survey of Tasks, Methods, and Future Directions (https://aclanthology.org/2023.emnlp-main.363/)
- Anthology ID: 2023.emnlp-main.363 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. end-to-end task-oriented dialogue (EToD)은 모듈식 학습 없이 단계별로 대화 응답을 생성할 수 있어서 점점 더 인기를 끌고 있다. 
    2. 이 논문에서는 EToD 연구의 존재하는 접근 방식과 최근 동향을 요약하여 통합적인 관점을 제시한다.
    3. 이 논문은 EToD 연구 분야에서 폭발적인 발전을 위한 잠재적인 고간과 도전과제를 논의하며, 업계 연구자들이 최근 연구 동향에 직접 접근할 수 있는 공개 웹사이트를 구축한다.

###### Answering Questions by Meta-Reasoning over Multiple Chains of Thought (https://aclanthology.org/2023.emnlp-main.364/)
- Anthology ID: 2023.emnlp-main.364 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 현대적인 다중 점프 질문 답변 시스템은 종종 일련의 추론 단계, 즉 chain-of-thought (CoT)로 질문을 분석한 후 최종 답변을 도출한다. 그러나 종종 여러 개의 체인을 샘플링하여 최종 답변을 투표 기법으로 집계하고 중간 단계는 버린다.
    2. 본 논문에서는 Multi-Chain Reasoning (MCR)이라는 접근법을 소개하는데, 이는 대규모 언어 모델에게 각각의 추론 체인에 대해 메타 추론을 수행하고 답변을 평균낼 대신 그들의 답변을 집계하는 것이다.
    3. MCR은 다양한 추론 체인을 검토하고 정보를 혼합하며 설명을 생성하고 답변을 예측하기 위해 가장 관련 있는 사실을 선택하므로 성능이 강력한 기준에 비해 우수하다. 또한 MCR 설명은 고품질을 갖추어 사람이 답을 검증할 수 있도록 한다.

###### INSTRUCTSCORE: Towards Explainable Text Generation Evaluation with Automatic Feedback (https://aclanthology.org/2023.emnlp-main.365/)
- Anthology ID: 2023.emnlp-main.365 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 학습된 언어 생성 metric은 인간 판단과 높은 상관관계를 보이지만, 이들 metric은 판단의 명확한 설명을 제공하지 않으며 생성된 텍스트의 결함과 점수를 연결시키지 않는다.
    2. 이 한계를 해결하기 위해, 우리는 INSTRUCTSCORE라는 텍스트 생성을 위한 detailed explanation을 제공하는 평가 metric을 제시한다.
    3. LLaMA를 기반으로 하여 인간의 명시적 지시와 GPT-4의 내재적 지식을 동원하여 text evaluation metric을 fine-tuning하고, 생성된 텍스트에 대한 점수와 사람이 읽을 수 있는 진단 보고서를 생성한다.

###### Multi-level Contrastive Learning for Script-based Character Understanding (https://aclanthology.org/2023.emnlp-main.366/)
- Anthology ID: 2023.emnlp-main.366 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 스크립트에서의 캐릭터 이해 시나리오를 다루는데에 있어서, 우리는 캐릭터의 성격과 정체성을 그들의 발언으로부터 학습하는 것을 목표로 한다.
    2. 이 논문에서는 이러한 시나리오에서의 여러 가지 도전과제들을 분석하고, 캐릭터들의 전역 정보를 세밀하게 포착하기 위한 다중 수준 대비 학습 프레임워크를 제안한다.
    3. 실험 결과에서 우리의 방법이 성능을 상당히 향상시키는 것을 보여주며, 이 방법이 도전과제들에 대응하는 데에 효과적임을 깊이 있는 분석을 통해 보여준다.

###### CHEF in the Language Kitchen: A Generative Data Augmentation Leveraging Korean Morpheme Ingredients (https://aclanthology.org/2023.emnlp-main.367/)
- Anthology ID: 2023.emnlp-main.367 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 한국어 형태학적 변이는 자연어처리(NLP)에서 독특한 기회와 도전을 제공하며, 형태소 기반 문장 구성에 대한 고급 이해가 필요하다.
    2. 우리는 이를 고려하여 모포(blender)와 라벨 판별자를 사용하는 CHEF라는 방법을 제안하여 형태소와 기능 형태소의 조합을 통해 문장의 형태학적 변형을 재현한다.
    3. 우리의 제안 방법은 외부 데이터 사용 없이 한국어 다중 분류 데이터셋에서 모델 성능을 향상시키며, 대규모 언어 모델을 이용한 다른 augmentation 기법과 비슷한 결과를 보이는 것을 실험을 통해 확인하였다.

###### Automatic Debate Evaluation with Argumentation Semantics and Natural Language Argument Graph Networks (https://aclanthology.org/2023.emnlp-main.368/)
- Anthology ID: 2023.emnlp-main.368 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 전문적인 논쟁 및 토론에 대한 주석이 달린 데이터 부족으로 인해 보다 복잡한 자연어 처리 작업에 접근하는 것이 현실적으로 어려워졌다.
    2. 이 논문에서는 논쟁 이론, 변환기 기반 아키텍처, 신경 그래프 네트워크와 같은 개념들을 결합하여 이러한 토론에서 승리 자세를 자동으로 예측하는 혼합 메소드를 제안한다.
    3. 우리는 미 탐색된 자연어 논증의 자동 분석에 대한 새로운 기초를 마련할 만한 유망한 결과를 얻었다.

###### Transfer-Free Data-Efficient Multilingual Slot Labeling (https://aclanthology.org/2023.emnlp-main.369/)
- Anthology ID: 2023.emnlp-main.369 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 슬롯 라벨링은 태스크 지향 대화 시스템에서 중요한 구성 요소이나, 언어, 태스크, 도메인에 특화된다. 이 논문은 흔히 비현실적인 가정에서 벗어나서 영어로 된 주석 데이터를 전혀 사용하지 않고, 대상 언어로 직접 다양한 언어를 포함한 데이터효율적인 슬롯 라벨러를 구축하는 방법을 제시한다.
    2. 이 논문에서는 슬롯 라벨링을 위해 표준 다국어 문장 인코더를 유효한 슬롯 라벨러로 변환하는 데에 두 단계의 접근법을 제안한다. 첫 단계에서는 소수의 주석된 예제만을 가지고 문장 인코더를 과제 특정 스팬 인코더로 변환한다. 두 번째 단계에서는 슬롯 라벨을 토큰 분류에서 데이터 부담이 적은 스팬 분류로 재구성한다.
    3. 실험 결과는 이 방법의 효과와 강건성을 확인하였고, 최도의 어려운 전이 없는 푸샷 설정에서 특히 효과적이며, 태스크 지향 대화 시스템을 위한 데이터 효율적인 다국어 슬롯 라벨러를 빠르게 구축할 수 있는 길을 열어준다.

###### Towards Interpretable Mental Health Analysis with Large Language Models (https://aclanthology.org/2023.emnlp-main.370/)
- Anthology ID: 2023.emnlp-main.370 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. ChatGPT와 같은 대규모 언어 모델은 자동 정신 건강 분석에서 강력한 능력을 보이지만, 기존 연구는 불충분한 평가, 프롬프트 전략의 부재 및 LLM 설명 가능성 탐구 무시 같은 여러 제한 사항을 갖고 있다.
    2. 우리는 5가지 작업에 걸쳐 11개 데이터셋에서 LLM의 정신 건강 분석 및 감정 추론 능력을 포괄적으로 평가한다. 또한 LLM에게 각각의 결정에 대한 설명을 생성하도록 지시하여 해석 가능한 정신 건강 분석에 대한 연구를 진행한다. 생성된 설명의 품질을 평가하기 위해 엄격한 인간 평가를 전달하며, 이를 바탕으로 163개의 인간 평가된 설명을 가진 새로운 데이터셋을 구축한다.
    3. 결과에 따르면, ChatGPT는 맥락에서의 학습 능력이 강하지만, 여전히 고급 작업 특화 방법과는 상당한 차이가 있다. 감정적 단서와 전문가가 작성한 부족한 샷 예제를 통해 신중한 프롬프트 엔지니어링은 정신 건강 분석 성능을 효과적으로 향상시킬 수도 있다. 게다가, ChatGPT는 인간의 성능과 유사한 설명을 생성하여, 설명 가능한 정신 건강 분석에서 큰 잠재력을 보여준다.

###### Learning to Rank Generation with Pairwise Partial Rewards (https://aclanthology.org/2023.emnlp-main.371/)
- Anthology ID: 2023.emnlp-main.371 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. supervised maximum likelihood estimation 접근 방식의 한계를 극복하기 위해 강화학습을 조건부 텍스트 생성에 사용하는 것을 연구했다.
    2. 이러한 방식은 대규모 행동 공간과 지연된 보상이라는 어려움을 여전히 겪고 있다.
    3. 우리는 중간 상태에서 취한 중간 행동에 대한 부분적인 보상을 제공하는 방법을 제안하여 더 원하는 시퀀스를 생성하는 행동을 우선적으로 선택할 수 있도록 했다.

###### GreedyCAS: Unsupervised Scientific Abstract Segmentation with Normalized Mutual Information (https://aclanthology.org/2023.emnlp-main.372/)
- Anthology ID: 2023.emnlp-main.372 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 과학 논문의 요약문은 일반적으로 전제 (배경 및 관찰)와 결론을 모두 포함한다. 하지만 구조화되지 않은 요약문에서는 결론 정보가 명시적으로 표시되지 않기 때문에 과학적 요약문에서 결론을 자동으로 분할하는 것은 어려운 작업이다.
    2. 본 연구에서는 Abstract segmentation에 Normalized Mutual Information (NMI)을 사용하는 방법을 제시한다. 우리는 각각의 요약문을 문장의 순환 주기로 간주하고, 선행 전제와 강한 의미적으로 연결되는 결론을 가정하여 두 세그먼트 간의 NMI 점수를 탐욕적으로 최적화하여 두 개의 분할 경계를 배치한다.
    3. 구조화되지 않은 요약문에서는 제안한 비지도 학습 방법인 GreedyCAS가 모든 평가 메트릭에서 가장 우수한 성능을 보였으며, 구조화된 요약문에서는 GreedyCAS가 Pk를 기준으로 모든 베이스라인 방법을 능가하였다. NMI의 강한 상관관계는 abstract segmentation에 대한 NMI의 효과를 보여준다.

###### Spoiler Detection as Semantic Text Matching (https://aclanthology.org/2023.emnlp-main.373/)
- Anthology ID: 2023.emnlp-main.373 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 온라인에서 TV 쇼에 대한 토론에 참여하는 것은 스포일러를 피하기 위해 오랜 기간 동안 관련 콘텐츠를 소비하지 않아야 하는 경우가 많다. 
    2. 기존 스포일러 탐지 연구는 일반적인 스포일러로부터 시청자를 보호하는 데는 유망한 결과를 보이지만, 시청 중인 동안 콘텐츠를 제한하는 문제에 대해서는 다루지 못하고 있다. 
    3. 이 논문에서는 스포일러 일치 (spoiler matching)라는 과제를 제안하며, 특정 TV 쇼가 주어졌을 때 스포일러에 에피소드 번호를 할당하는 작업으로 문제를 해결한다.

###### Multimodal Embodied Plan Prediction Augmented with Synthetic Embodied Dialogue (https://aclanthology.org/2023.emnlp-main.374/)
- Anthology ID: 2023.emnlp-main.374 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 감각적인 작업 완료는 전체적으로 볼 때, 시뮬레이션 환경에서 요소 관점의 시각적 관찰과 자연어 지시에 기반하여 환경 동작을 예측하는 것이다.
    2. 우리는 agent의 동작이 더 해석 가능하도록 agent 동작을 추상화 된 더 높은 수준의 plan으로 예측하는 문제에 대한 변형을 제안한다.
    3. 우리는 multimodal transformer 모델이 이 문제에 대해 언어만 사용하는 모델을 능가하지만 오라클(plan)보다는 멀리 못하는 것을 보여준다.

###### GEM: Gestalt Enhanced Markup Language Model for Web Understanding via Render Tree (https://aclanthology.org/2023.emnlp-main.375/)
- Anthology ID: 2023.emnlp-main.375 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이전의 사전 학습 언어 모델들은 텍스트를 넘어서는 인식 가능한 웹 컨텐츠에 포함된 풍부한 정보를 무시한다.
    2. 이 연구에서는 HTML 외에도 시각, 레이아웃, 스타일과 같은 렌더링된 웹의 중요한 정보를 활용하기 위해 제슈탈 심리학 이론에서 영감을 받은 GEM(Language Model)을 제안한다.
    3. 실험 결과, GEM은 웹 질문응답 및 웹 정보 추출과 같은 여러 다운스트림 작업에서 우수성을 검증한다.

###### Abstractive Open Information Extraction (https://aclanthology.org/2023.emnlp-main.376/)
- Anthology ID: 2023.emnlp-main.376 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. OpenIE는 자유로운 텍스트에서 구조화된 정보를 추출하여 다른 하위 응용 프로그램에 사용하는 전통적인 NLP 작업이다. 기존의 OpenIE는 원시 텍스트에 나타나는 관계의 표면 형태를 추출하는 것에 초점을 맞추었으며 이를 추출형 OpenIE라고 한다. 이 접근 방식의 한 가지 주요한 단점은 암묵적인 의미적 관계(추론된 관계)를 추출할 수 없어 하위 응용 프로그램의 성능에 문제가 발생한다는 것이다.
    2. 본 논문에서는 추출형 OpenIE에서 표면 형태의 관계뿐만 아니라 추론된 관계도 포함시킨 새로운 추상적 OpenIE로 OpenIE 관계를 확장한다. 이 새로운 작업을 위해 새로운 추상적 OpenIE 학습 데이터셋과 추론된 관계를 추출할 수 있는 기준선 신경망 모델의 개발이 필요하다. 또한, 추상적 OpenIE 추출을 평가하기 위한 새로운 의미 기반 메트릭의 필요성을 보여준다.
    3. 복잡한 QA의 사례 연구를 통해 추상적 OpenIE의 효과를 입증한다.

###### CoSyn: Detecting Implicit Hate Speech in Online Conversations Using a Context Synergized Hyperbolic Network (https://aclanthology.org/2023.emnlp-main.377/)
- Anthology ID: 2023.emnlp-main.377 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사회적 미디어 사용자들 간의 온라인 대화가 급증하면서 다양한 인종과 인구에 영향을 주는 혐오 발언의 증가로 이어졌다. 그러나 대부분의 연구들은 명시적인 혐오 발언을 감지하는 데 초점을 맞추고 있어 간접적이거나 암시적인 혐오 발언을 감지하는 데 작은 로부터 찾는데 집중이 되어있다.
    2. 저자들은 implicit hate speech를 감지하기 위해 사용자와 대화 상황에서의 문맥을 명확히 편입한 CoSyn이라 불리는 신경망 모델을 제안한다. CoSyn은 이러한 외부 문맥을 인코딩하는 새로운 방법을 도입하고, 그들 사이의 상호작용을 포착하여 노이즈가 있는 문맥에서 가져올 정보의 양을 독립적으로 평가하는 새로운 맥락 상호작용 메커니즘을 채택한다.
    3. 실험 결과, CoSyn은 6개의 혐오 발언 데이터셋에서 implicit hate speech를 감지하는 데에서 모든 기준 모델을 능가하며, 절대적인 개선 폭이 1.24%에서 57.8%에 이른다.

###### CLEME: Debiasing Multi-reference Evaluation for Grammatical Error Correction (https://aclanthology.org/2023.emnlp-main.378/)
- Anthology ID: 2023.emnlp-main.378 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 문법 오류 교정(GEC) 시스템의 성능을 평가하는 것은 주관적인 요소가 많아 어려운 과제이다. 이 논문에서는 멀티 레퍼런스 평가 설정에서 GEC 시스템을 평가하기 위한 Chunk-LE 멀티 레퍼런스 평가(CLEME)를 제안한다. CLEME는 일관된 경계를 가진 청크 시퀀스를 구축하여 일관되지 않은 편집 경계로 인한 편향을 제거한다.
    2. CLEME를 사용하면 다중 레퍼런스가 있는 경우에도 단일 레퍼런스 평가 기준과 동일한 평가를 수행할 수 있으며, F0.5 점수를 통해 문법 오류의 경계를 파악하고 평가할 수 있다.
    3. 실험결과 CLEME는 다양한 레퍼런스 세트에서 GEC 시스템을 평가하는 데 효과적이며, 다른 레퍼런스 수와 주석 스타일에 따라 일관된 성능을 보인다는 것을 보여준다.

###### Dynamic Top-k Estimation Consolidates Disagreement between Feature Attribution Methods (https://aclanthology.org/2023.emnlp-main.379/)
- Anthology ID: 2023.emnlp-main.379 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 특징 귀속 점수는 텍스트 분류기의 예측을 사용자에게 설명하기 위해 k 개의 토큰을 강조하는 데 사용된다. 
    2. 이 논문에서는 특징 귀속 점수의 순차적 특성을 통해 보이는 최적의 k 토큰의 수를 결정하는 방법을 제안한다. 
    3. 연구 결과에 따르면, sequential properties를 활용하는 방법은 인간의 해석을 위해 특징 귀속 신호를 결합하는 데 유용하다는 것을 보여준다.

###### SentiStream: A Co-Training Framework for Adaptive Online Sentiment Analysis in Evolving Data Streams (https://aclanthology.org/2023.emnlp-main.380/)
- Anthology ID: 2023.emnlp-main.380 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 온라인 감성 분석은 소셜 미디어 모니터링, 고객 피드백 분석, 온라인 평판 관리와 같은 데이터 주도 어플리케이션에서 중요한 구성 요소로 부상했다. 
    2. 그러나 현재 방법론은 계속 진화하는 데이터 스트림을 효과적으로 다루기 어렵다. 
    3. 이 논문에서는 동적 데이터 스트림 내에서 효율적인 감성 분석을 위해 특별히 설계된 코트레이닝(co-training) 프레임워크인 sentistream을 제안한다.

###### HyperNetwork-based Decoupling to Improve Model Generalization for Few-Shot Relation Extraction (https://aclanthology.org/2023.emnlp-main.381/)
- Anthology ID: 2023.emnlp-main.381 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Few-shot relation extraction (FSRE)은 몇 개의 레이블 예제만을 사용하여 새로운 관계를 처리할 수 있는 모델을 훈련시키는 것을 목표로 한다. 
    2. 이 논문에서는 FSRE 모델의 클래스 분리를 조사한 결과, 상위 레이어가 관계에 특화된 지식을 학습하기 쉽다는 것을 발견하였다.
    3. 따라서 이 논문에서는 HyperNetwork 기반의 디커플링(Depouling) 접근법을 제안하여 FSRE 모델의 일반화 능력을 향상시키는 것을 목표로 한다.

###### Solving Hard Analogy Questions with Relation Embedding Chains (https://aclanthology.org/2023.emnlp-main.382/)
- Anthology ID: 2023.emnlp-main.382 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 단어들 간의 관련성 모델링은 어휘 의미론에서 중요한 주제이다. 일반적인 전략은 ConceptNet과 같은 지식 그래프(KG)를 활용하여 두 개념 간의 관계를 경로 집합으로 모델링하는 것이다.
    2. 그러나 KG는 고정된 관계 유형에 한정되어 있으며, 불완전하고 종종 노이즈가 있다. 또 다른 전략은 사전 훈련된 언어 모델에서 관계 임베딩을 추출하는 것이다. 그러나 이 방법은 직접적으로 관련되어 있지 않은 단어에는 적합하지 않으며 구조화된 도메인 지식을 쉽게 통합할 수 없다.
    3. 따라서, 이 논문에서는 경로로 관계를 모델링하면서 관계 임베딩을 사용하는 방법을 제안한다. 경로는 먼저 적절한 중간 단어를 식별한 다음, 정보가 있는 관계 임베딩을 얻을 수 있는 단어를 선택하여 얻는다. 우리의 제안된 표현은 어려운 유추 문제 해결에 유용하다는 것을 실험적으로 보여준다.

###### Modeling Empathic Similarity in Personal Narratives (https://aclanthology.org/2023.emnlp-main.383/)
- Anthology ID: 2023.emnlp-main.383 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사람들 간 의미 있는 연결은 종종 개인적인 서술에서 공유된 취약성과 감정적인 경험을 통해 육성된다. 이 논문에서는 NLP 분야에서 지배적으로 연구되어온 의미론적이거나 어휘적인 유사성이 아닌 "감정 공감"을 기반으로 개인 이야기의 유사성을 판별하는 새로운 과제를 소개한다.
    2. 이 연구는 사회 심리학의 통찰력을 활용하여 이야기의 주요 사건, 감정적 경로, 전반적인 교훈 또는 결론이라는 세 가지 요소를 기반으로 감정 공감성을 구체화하는 프레임워크를 제안한다. EmpathicStories라는 데이터셋을 생성하여 감정 공감성 특징들로 주석을 달고, 이를 이용하여 이야기 쌍의 감정 공감성을 계산하기 위한 모델을 fine-tuning하였다.
    3. 실험 결과, 이 모델은 의미론적 유사성 모델보다 자동 상관 및 검색 메트릭에서 성능이 우수함을 보였다. 150명의 참가자를 대상으로 한 사용자 실험에서도, 우리의 모델을 사용한 이야기 검색 결과에 사용자들이 더 공감하였음을 확인하였다. 이 연구는 인간 간의 연결과 감정 공감을 육성하기 위해 감정 공감 모델의 활용에 강력한 함의를 지니고 있다.

###### Tree Prompting: Efficient Task Adaptation without Fine-Tuning (https://aclanthology.org/2023.emnlp-main.384/)
- Anthology ID: 2023.emnlp-main.384 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 작은 규모의 언어 모델에 대해서는 기울기 기반 fine-tuning과 비교했을 때, prompt 사용은 정확성이 낮다. 
    2. Tree Prompting은 여러 개의 prompt-LM 호출을 연결하여 문제를 해결하기 위해 prompt의 의사 결정 트리를 구축하는 접근 방식이다. 
    3. Tree Prompting은 classification 데이터셋에서 기존 방법보다 더 나은 정확성을 보여주고 fine-tuning과 경쟁력을 가진다.

###### Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data (https://aclanthology.org/2023.emnlp-main.385/)
- Anthology ID: 2023.emnlp-main.385 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. ChatGPT와 같은 대화 모델은 탁월한 능력을 보여주고 다양한 분야에서 적극적으로 채용되고 있으나, 제한된 API를 통해서만 접근 가능하기 때문에 새로운 연구와 발전에는 장애물이 된다.
    2. 우리는 ChatGPT를 활용하여 자기 자신과 대화를 나누어 고품질의 멀티턴 대화 말뭉치를 자동으로 생성하는 파이프라인을 제안한다.
    3. 또한, 매개변수 효율적인 조정을 사용하여 오픈 소스인 LLaMA의 성능을 향상시키는 방식을 소개한다. 그 결과로 얻어진 Baize 모델은 잠재적인 위험을 최소화하는 경계선을 가진 멀티턴 대화에서 좋은 성능을 보여준다. 추가로, ChatGPT로부터의 피드백으로 Baize 모델의 성능을 개선하기 위한 새로운 기술인 Self-Distill with Feedback도 제안한다.

###### Empathy Intent Drives Empathy Detection (https://aclanthology.org/2023.emnlp-main.386/)
- Anthology ID: 2023.emnlp-main.386 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화 시스템에서 공감 표현을 인식하는 것은 사용자의 필요를 이해하는 데 매우 관련이 있기 때문에 필수적이다.
    2. 본 논문에서는 8가지 공감 의도 레이블로 healthy empathy detection 데이터셋 IEMPATHIZE와 TwittEmp를 수동으로 주석을 달아 두 가지 작업에 대한 공동 훈련을 수행한다.
    3. 실험 결과를 통해 우리의 프레임워크가 두 데이터셋에서 모든 기준을 능가한다는 것을 보여준다.

###### Adaptive End-to-End Metric Learning for Zero-Shot Cross-Domain Slot Filling (https://aclanthology.org/2023.emnlp-main.387/)
- Anthology ID: 2023.emnlp-main.387 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 슬롯 채우기(slot filling)는 딥러닝과 대용량 주석이 달린 데이터의 가용성 덕분에 큰 발전을 이루었으나, 훈련 중 본적 없는 새로운 도메인을 다루는 것은 중요한 도전 과제이다.
    2. 기존의 메트릭 기반 접근 방식은 두 단계의 파이프라인 방식을 사용해 문제를 해결하지만, 병렬 추론과 컨텍스트-프리 이산 레이블 임베딩 때문에 계산 효율성과 일반화 능력에 한계가 있다.
    3. 본 연구에서는 전형적인 메트릭 기반 방법을 재조명하여, 도전적인 제로샷 슬롯 채우기에 대한 새로운 적응형 end-to-end 메트릭 학습 방법을 제안하였다. 컨텍스트를 고려한 소프트 레이블 표현과 슬롯 수준 대조 표현 학습을 결합하여 데이터와 레이블의 변화 문제를 효과적으로 완화하는 구조형 학습 프레임워크를 제안하였다.

###### BasahaCorpus: An Expanded Linguistic Resource for Readability Assessment in Central Philippine Languages (https://aclanthology.org/2023.emnlp-main.388/)
- Anthology ID: 2023.emnlp-main.388 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자동 가독성 평가(Automatic Readability Assessment, ARA) 연구는 영어와 같은 고리소스 언어에서 모델의 성능을 향상시키기 위해 진행되어 왔다.
    2. 이 논문에서는 필리핀 낮은 리소스 언어에 대한 가독성 평가의 기존 코퍼스와 기준 모델을 확장하기 위한 BasahaCorpus를 소개하고 공개한다.
    3. 우리는 Hiligaynon, Minasbate, Karay-a, Rinconada와 같은 필리핀 센트럴 필리핀어 언어들로 작성된 짧은 허구 이야기의 코퍼스를 통해 ARA 모델을 훈련시킨다. 또한, 가족 트리 그룹에 속하는 언어의 배치를 활용하여 다중 언어 모델링 접근법을 제안한다.

###### ReTAG: Reasoning Aware Table to Analytic Text Generation (https://aclanthology.org/2023.emnlp-main.389/)
- Anthology ID: 2023.emnlp-main.389 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 테이블 요약 작업은 테이블이나 하이라이트된 특정 셀의 내용을 간결하고 정확하게 나타내는 텍스트를 생성하는 작업이다. 이 논문에서는 기존 모델들이 주로 테이블에 포함된 정보를 반복하는 기술적인 요약문을 생성한다는 문제를 지적하고 이에 대한 해결책으로 ReTAG라는 새로운 모델을 제안한다.
    2. ReTAG는 다양한 유형의 분석적인 추론력을 출력에 적용하기 위해 벡터 양자화를 사용하는 테이블과 추론에 민감한 모델이다. ReTAG는 기존 기준선에 비해 ToTTo와 InfoTabs에서 테이블 요약 작업을 수행하는데 있어서 PARENT metric에서 2.2%, 2.9%의 개선을 보인다.
    3. 사람 평가를 통해 ReTAG의 출력이 강력한 테이블 인식 모델에 비해 더 정확하고 분석적이라는 것을 확인할 수 있었다. ReTAG는 다중 테이블 요약 작업에서 최첨단 성능을 넘어설 수 있는 첫 번째 모델이다. 또한, 문장에 사용된 추론 카테고리를 각 데이터셋에 추출하여 기여하였다.

###### Beyond Factuality: A Comprehensive Evaluation of Large Language Models as Knowledge Generators (https://aclanthology.org/2023.emnlp-main.390/)
- Anthology ID: 2023.emnlp-main.390 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 큰 언어 모델들은 세계 지식 생성을 요청받을 때 정보 검색 기술을 능가하지만, 이러한 알고리즘을 사용하는 것의 사실 여부와 잠재적인 영향에 대한 걱정이 존재한다.
    2. 따라서 이 연구에서는 CONNER라는 종합적인 지식 평가 프레임워크를 소개하여 사실성, 관련성, 일관성, 정보성, 도움성 및 유효성 등 여섯 가지 관점에서 생성된 지식을 체계적으로 자동 평가할 것이다.
    3. 놀랍게도, 이 연구는 생성된 지식의 사실성이 낮더라도 다운스트림(Task-dependent) 작업에는 크게 영향을 미치지 않는다는 것을 밝혀냈다. 대신, 출력물의 관련성과 일관성이 사소한 사실적 오류보다 더 중요하다는 것을 보였다.

###### Compressing Context to Enhance Inference Efficiency of Large Language Models (https://aclanthology.org/2023.emnlp-main.391/)
- Anthology ID: 2023.emnlp-main.391 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 대형 언어 모델 (LLM)은 다양한 과제에서 장엄한 성과를 달성했으나, 긴 문서와 확장된 대화를 다루는 데 어려움을 겪고 있다.
    2. 이 논문에서는 Selective Context라는 방법을 제안하여 입력 문맥의 중복을 파악하고 제거하여 LLM의 추론 효율성을 향상시킨다.
    3. 실험 결과, Selective Context는 전체 문맥을 사용하는 경우와 비교하여 메모리 비용을 50% 감소시키며 응답 생성 시간을 32% 줄이고, 성능은 비슷한 수준을 유지한다는 것을 보여준다.

###### MoT: Memory-of-Thought Enables ChatGPT to Self-Improve (https://aclanthology.org/2023.emnlp-main.392/)
- Anthology ID: 2023.emnlp-main.392 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 대형 언어 모델들은 다양한 과제에서 놀라운 성능을 보였으나, 이들을 본질적으로 개선하기 위해서는 고품질 데이터셋이나 계산적으로 비싼 fine-tuning이 필요하다. 반면에 사람은 외부 자료 없이도 스스로 사고하고 기억을 통해 쉽게 스스로를 개선할 수 있다. 
    2. 본 논문에서는 주석이 달린 데이터셋이나 매개변수 업데이트 없이 대형 언어 모델이 **MoT**라 불리는 "추억의 메모리"를 통해 스스로 개선할 수 있는 프레임워크를 제안한다.
    3. 실험 결과, MoT를 통해 ChatGPT가 산술 추론, 상식 추론, 사실적 추론, 자연어 추론과 같은 능력을 크게 향상시킬 수 있으며, 각 구성 요소가 개선에 중요한 역할을 하고 MoT가 다양한 CoT 방법과 대형 언어 모델에 일관되게 개선을 이끌어낼 수 있음을 보여준다.

###### 4 and 7-bit Labeling for Projective and Non-Projective Dependency Trees (https://aclanthology.org/2023.emnlp-main.393/)
- Anthology ID: 2023.emnlp-main.393 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 우리는 구문 분석을 시퀀스 레이블링으로 표현하는 인코딩을 소개하였다. 이 인코딩은 하나의 단어 당 4비트 레이블 시퀀스로 모든 projective 의존성 트리를 표현 할 수 있다.
    2. 우리는 이를 통해 트리에서 레이블로의 일대일 매핑을 선형 시간 안에 인코딩 및 디코딩할 수 있다는 것을 보여주었다.
    3. 실험 결과, 우리의 7비트 인코딩은 이전에 최고 성능의 시퀀스 레이블링 인코딩보다 상당한 정확도 향상을 얻는다.

###### Can You Follow Me? Testing Situational Understanding for ChatGPT (https://aclanthology.org/2023.emnlp-main.394/)
- Anthology ID: 2023.emnlp-main.394 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. ChatGPT와 같은 채팅 모델의 경우 Situational Understanding (SU)가 필요하며, 그러한 채팅 모델의 SU 능력을 테스트하기 위한 새로운 합성 환경을 제안한다.
    2. ChatGPT는 환경 상태를 올바르게 추적하는 능력이 부족하며, 이는 비지속적인 인문 학습을 반영하는 모델의 성능 저하와 관련되어 있다.
    3. ChatGPT의 대화 기술에 대한 신뢰는 위험을 동반하며, ChatGPT의 성능을 평가하기 위한 테스트 환경과 관련 코드는 공개되어 있다.

###### Towards Reliable Misinformation Mitigation: Generalization, Uncertainty, and GPT-4 (https://aclanthology.org/2023.emnlp-main.395/)
- Anthology ID: 2023.emnlp-main.395 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Fake News에 대한 검증에 완벽한 분류가 불가능한 상황에서, 최근의 대형 언어 모델을 활용하여 정보의 진실성을 평가하기 위한 실용적인 도구를 만들기 위해 generalization, uncertainty에 초점을 맞추고 있는 연구다.
    2. 연구에서는 GPT-4가 다양한 setting과 언어에서 이전 방법보다 우수한 성능을 내는 것을 보였고, GPT-4와 RoBERTa-large가 실패 모드에서 차이점을 나타낸다는 사실을 밝혔다.
    3. 이 외에도 불확실성을 다루는 기술과 불가능한 예제를 감지하여 결과를 크게 개선하는 기술을 제안하였으며, 다양한 언어 모델, 온도, 프롬프팅, 버전 관리, 설명가능성, 웹 검색에 대한 결과를 논의하였다.

###### Advancements in Arabic Grammatical Error Detection and Correction: An Empirical Investigation (https://aclanthology.org/2023.emnlp-main.396/)
- Anthology ID: 2023.emnlp-main.396 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 문법 오류 수정은 영어에서 잘 연구된 문제이지만, 데이터 부족과 언어의 복잡성과 같은 도전 때문에 품사 풍부한 언어에서의 문법 오류 수정 연구는 제한되어 왔다.
    2. 이 논문에서는 새롭게 개발된 Transformer 기반의 사전 훈련된 시퀀스-투-시퀀스 모델을 사용하여 아랍어 문법 오류 수정 문제에 대한 최초의 결과를 제시한다.
    3. 우리는 또한 다중분류 아랍어 문법 오류 감지(GED) 작업을 정의하고, 다양한 장르를 포괄하는 세 개의 데이터셋에서 GED 정보를 보조 입력으로 사용하는 것이 GEC 성능을 개선하는 것을 보여준다.

###### HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models (https://aclanthology.org/2023.emnlp-main.397/)
- Anthology ID: 2023.emnlp-main.397 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델 (LLM)은 사실 또는 소스와 충돌하는 내용이나 검증할 수 없는 내용과 같은 환각을 생성하기 쉽다. 
    2. HalluEval 벤치마크를 통해 LLM의 환각 인식 능력을 평가하기 위해 생성 및 인간 주석이 달린 환각 샘플의 대규모 컬렉션을 도입한다. 
    3. ChatGPT는 특정 주제에서 검증할 수 없는 정보를 만들어내어 환각 콘텐츠를 생성할 가능성이 있다 (사용자 쿼리 약 19.5%). 게다가 기존 LLM은 텍스트 내의 환각을 인식하는 데 큰 어려움을 겪는다는 것이다.

###### Enabling Large Language Models to Generate Text with Citations (https://aclanthology.org/2023.emnlp-main.398/)
- Anthology ID: 2023.emnlp-main.398 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델 (LLMs)은 정보 검색에 널리 사용되는 도구로 등장했지만 생성된 결과물은 환각에 빠지기 쉽다. 
    2. 이 연구의 목표는 LLMs가 주장에 대한 사실적 인정과 검증 가능성을 향상시키기 위해 사람 평가와 상업용 검색 엔진에 의존하는 기존 방법보다 더 재현성 높은 벤치마크를 제안하는 것이다.
    3. ALCE라는 벤치마크를 사용하여 LLMs의 자동 인용 평가에 대한 첫 번째 벤치마크를 수행하고 있으며, 자동 평가 메트릭을 개발하여 인간 판단과의 강한 상관관계를 보여준다.

###### Revisiting Machine Translation for Cross-lingual Classification (https://aclanthology.org/2023.emnlp-main.399/)
- Anthology ID: 2023.emnlp-main.399 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기계 번역(Machine Translation, MT)은 크로스-언어 분류에 널리 사용되는데, 이는 테스트 세트를 영어로 번역하고 단일 언어 모델로 추론을 실행하거나 (translate-test) 훈련 세트를 대상 언어로 번역하고 멀티 리더한 모델을 세밀 조정(translate-train)하는 방식이다. 
    2. 기존의 연구는 MT보다는 멀티링구어 모델에 집중되어 왔으나, 더 강력한 MT 시스템을 사용하고 훈련과 추론 간의 불일치를 완화함으로써 translate-test가 이전보다 훨씬 우수한 성능을 발휘할 수 있다고 보여준다. 
    3. 다만, 최적의 접근 방식은 과제에 따라 다르므로, 서로 다른 과제와 접근 방식에 영향을 미치는 여러 가지 크로스-언어 전달 차이 요인을 식별하는 것이 중요하다. 이 연구는 크로스-언어 분류를 위한 멀티링구어 모델의 지배력에 의문을 제기하며, MT 기반 베이스라인에 더 많은 주목을 촉구한다.

###### Pre-Trained Language Models Augmented with Synthetic Scanpaths for Natural Language Understanding (https://aclanthology.org/2023.emnlp-main.400/)
- Anthology ID: 2023.emnlp-main.400 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인간 시선 데이터는 자연어 이해를 반영하는 인지적 정보를 제공한다. 
    2. 이 논문에서 제안한 모델은 synthetic scanpath generation을 활용하여 인간 시선 데이터 없이도 scanpath를 증강된 언어 모델에 통합시키는 모델을 개발하였다. 
    3. 실험 결과, proposed model은 원래 언어 모델보다 우수한 성능을 보이며, 실제 인간 시선 데이터로 증강된 언어 모델과 비교 가능한 성능을 달성하였다.

###### Counting the Bugs in ChatGPT’s Wugs: A Multilingual Investigation into the Morphological Capabilities of a Large Language Model (https://aclanthology.org/2023.emnlp-main.401/)
- Anthology ID: 2023.emnlp-main.401 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근엔 LLMs가 인간의 언어 능력과 비교되며 놀라운 언어 능력을 갖추게 되었지만, 최신 LLMs의 언어 능력에 대한 체계적인 조사는 상대적으로 적었으며, 대부분은 (i) 인간의 일반화능력을 고려하지 않고, (ii) 영어만을 중점적으로 다루며, (iii) 문법이나 의미론을 조사하며 단어형태로부터 발생하는 다른 능력은 무시되었다.
    2. 우리는 오히려 사람과 인과관계를 맺어 사물을 이해하지 못하는 능력을 갖추고 있음을 증명하는 ChatGPT의 형태론 능력에 대해 최초로 철저한 분석을 실시하였다. 
    3. 우리는 ChatGPT의 형태론 능력은 특히 영어에서 효과적인 시스템보다 현저히 낮은 성능을 보이는 것을 발견하였으며, 전반적으로, 우리의 결과는 형태론적인 측면에서 ChatGPT의 언어 능력에 대한 새로운 시각을 제공하며, 인간과 유사한 언어 능력이라는 주장은 이르고도 오도하는 것이라고 주장한다.

###### Adapt in Contexts: Retrieval-Augmented Domain Adaptation via In-Context Learning (https://aclanthology.org/2023.emnlp-main.402/)
- Anthology ID: 2023.emnlp-main.402 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. LLM은 few-shot 추론의 in-context 학습력을 갖추었으나, 실제 상황에서는 in-domain 데이터가 항상 이용 가능치 않아 cross-domain in-context 학습이 필요하다.
    2. 이 논문에서는 unsupervised domain adaptation 문제를 in-context 학습 방식으로 다루며, target 라벨을 사용하지 않고 source domain에서 target domain으로 언어 모델을 적응시킨다.
    3. 쿼리에 가장 유사한 cross-domain 요소들의 하위 집합을 검색하여 augmented cross-domain in-context 예제와 함께 대상 도메인 분포와 식별적 특징을 동시에 학습하여 언어 모델을 적응시킨다.

###### Understanding the Inner-workings of Language Models Through Representation Dissimilarity (https://aclanthology.org/2023.emnlp-main.403/)
- Anthology ID: 2023.emnlp-main.403 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 실제 응용에서 언어 모델을 적용함에 따라 모델의 신뢰도, 해석 가능성 및 투명성에 대한 이해는 중요한 문제로 대두되고 있다.
    2. 이 연구에서는 두 모델 내부 표현의 차이를 측정하는 기능인 representation dissimilarity measures가 언어 모델의 작동 원리를 이해하는 데 유용한 도구일 수 있다는 것을 보여준다.
    3. 우리의 결과는 차이 측정이 언어 모델의 내부 작동에 대한 통찰력을 제공하는 유망한 도구 집합이라는 것을 시사한다.

###### Efficient Classification of Long Documents via State-Space Models (https://aclanthology.org/2023.emnlp-main.404/)
- Anthology ID: 2023.emnlp-main.404 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 실제 상황에서 많이 나오는 긴 문서는 변환기 모델들의 기본적인 self-attention 모듈로 효율적으로 처리할 수 없는데, 이 논문에서는 이러한 문제를 해결하기 위해 상태 공간 모델(State-Space Models, SSMs)을 사용하여 처리하였다. 
    2. SSM을 사용한 모델과 self-attention 기반 모델을 비교하여, 이 논문에서는 이러한 모델들이 binary, multi-class, multi-label classification 등 다양한 긴 문서 분류 작업에서 효과적임을 실험적으로 보여주었다.
    3. 또한, SSM-pooler 모델을 소개하고 평균적으로 36% 더 효율적인 성능을 보이면서 입력 noise에 대해 더 강한 안정성을 나타내었다.

###### Dual-Feedback Knowledge Retrieval for Task-Oriented Dialogue Systems (https://aclanthology.org/2023.emnlp-main.405/)
- Anthology ID: 2023.emnlp-main.405 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 역할을 완수하기 위해 사용자 요청을 충족시키기 위해 필요한 관련 정보를 선택하기 위해 효과적인 지식 검색은 end-to-end task-oriented 대화 시스템의 성공을 보장하는 데 중요한 역할을 한다. 
    2. 현재의 접근법은 지식 검색과 응답 생성을 일반적으로 통합하는데, 이는 광범위한 지식 베이스를 다룰 때 확장성에 도전을 제기한다.
    3. 이 논문에서는 오픈 도메인 질의응답에서 영감을 받은 retriever-generator 구조를 제안하고, retriever를 사용하여 관련 지식을 검색하고 generator를 활용하여 시스템 응답을 생성한다.

###### Construction Artifacts in Metaphor Identification Datasets (https://aclanthology.org/2023.emnlp-main.406/)
- Anthology ID: 2023.emnlp-main.406 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 여러 암시적 비유 식별 데이터셋은 비유 표현이나 문맥을 완전히 무시함으로써 게임으로 조작될 수 있다는 것을 보여준다.
    2. 우리는 여러 데이터셋과 설정에서 이 가설을 검증하고, 완전한 정보 없이 언어 모델에 기반한 비유 식별 시스템이 완전한 문맥을 사용하는 시스템과 경쟁력을 갖을 수 있다고 보여준다.
    3. 이러한 결과는 데이터셋 구축 절차 때문에 긍정 및 부정 클래스에 원치 않는 편향을 도입하기 때문이다.

###### MAF: Multi-Aspect Feedback for Improving Reasoning in Large Language Models (https://aclanthology.org/2023.emnlp-main.407/)
- Anthology ID: 2023.emnlp-main.407 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어 모델은 다양한 자연어 태스크에서 높은 성능을 보여주지만, 자연어 추론과 같은 경우 잘못된 중간 추론 단계 생성, 수학적 오류 등의 문제가 있다. 
    2. 이 논문에서는 여러 종류의 오류에 대한 다양한 피드백 모듈을 통합하여 언어 모델의 성능을 향상시키는 **Multi-Aspect Feedback** 프레임워크를 제안한다. 
    3. 실험 결과, 이 방법을 사용하면 언어 모델의 추론 체인에서 발생하는 여러 오류를 해결하고, 수학 추론에서 최대 20%와 논리 함의에서 최대 18%의 성능 향상을 보였다.

###### Granularity Matters: Pathological Graph-driven Cross-modal Alignment for Brain CT Report Generation (https://aclanthology.org/2023.emnlp-main.408/)
- Anthology ID: 2023.emnlp-main.408 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자동 뇌 CT 보고서 생성은 두뇌 질환의 진단 효율과 정확성을 향상시킬 수 있다. 하지만 현재의 방법은 1) 세부적인 비정상성 인식을 위한 상세한 지도 정보가 부족한 이미지-텍스트 형식의 훈련 데이터에 의해 제한되고, 2) 시각-텍스트 정렬이 거칠게 결합되어 보고서 생성을 위한 복잡한 피처 표현을 초래하는 문제가 있다. 
    2. 우리는 정확하고 견고한 뇌 CT 보고서 생성을 위한 신규 경로 그래프 기반 교모달 정렬 (PGCA) 모델을 제안한다. 저희 방법은 섬세한 조직과 병변에 대한 시각적 단서를 배우고 텍스트 단어와 일치시키기 위해 병태 그래프를 구성하여 교모달 정렬을 효과적으로 해제한다.
    3. 그래프 내에서 핵심적인 병태 속성을 나타내는 이질적인 노드들을 도메인 지식과의 사전 정보를 통해 연결하고, 그래프 임베딩과 업데이트 모듈을 통해 시각적 피처를 섬세하게 정제하여 텍스트 단어와 일치시킨다. 방대한 실험 결과는 우리 방법의 타당성을 확인한다. 우리의 PGCA 모델은 뇌 CT 보고서의 자동 생성을 크게 향상시키고 최종적으로 두뇌 질환 진단에 기여할 것으로 기대한다.

###### Enhancing Structured Evidence Extraction for Fact Verification (https://aclanthology.org/2023.emnlp-main.409/)
- Anthology ID: 2023.emnlp-main.409 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 오픈 도메인 사실 검증은 청구 사실을 추출된 증거와 대조하여 확인하는 작업이다.
    2. 이전 모델들은 테이블 추출과 셀 선택의 단계에서 구조화된 증거의 재현율이 낮은 문제를 겪고 있다.
    3. 이 연구에서는 테이블의 행과 열 의미를 활용하여 구조화된 증거 추출의 정확도를 향상시키는 간단하면서도 효과적인 방법을 제안한다.

###### Rethinking Model Selection and Decoding for Keyphrase Generation with Pre-trained Sequence-to-Sequence Models (https://aclanthology.org/2023.emnlp-main.410/)
- Anthology ID: 2023.emnlp-main.410 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 키워드 생성(KPG)은 NLP에서 오래된 작업으로 널리 활용되고 있다. 그러나, 모델 선택과 디코딩 전략의 영향에 대한 체계적인 분석이 이루어지지 않아 임의로 결정되기도 한다.
    2. 이 논문에서는 seq2seq 기반 언어 모델의 선택과 디코딩 전략이 KPG에 미치는 영향을 체계적으로 분석하였다.
    3. 그 결과, 기본적으로 큰 모델 크기나 과제 특화적 adaptation은 매개 변수 효율성이 떨어지며, 도메인 내 사전 훈련과 과제 적응 결합은 일부적으로 일반화를 방해할 수 있음을 보여준다. 또한, DeSel 디코딩 알고리즘을 제안하여 greedy search보다 우수한 성능을 얻을 수 있다.

###### A Fair and In-Depth Evaluation of Existing End-to-End Entity Linking Systems (https://aclanthology.org/2023.emnlp-main.411/)
- Anthology ID: 2023.emnlp-main.411 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존 entity linking 시스템들의 평가는 특정 응용 분야에서 성능을 어떻게 발휘할지에 대해 거의 설명하지 않는다.
    2. 이 논문은 다양한 기존 end-to-end entity linker들을 의미 있는 방식으로 깊이 있는 평가하고 강점과 약점을 성격화하며, 재현성 측면에 대해서도 보고한다.
    3. 우리의 평가는 위에서 언급한 문제들을 다루는 데 어느 정도 애로사항이 있는 여러 유명한 벤치마크와 두 개의 새로운 벤치마크를 기반으로 한다.

###### A Multi-Task Dataset for Assessing Discourse Coherence in Chinese Essays: Structure, Theme, and Logic Analysis (https://aclanthology.org/2023.emnlp-main.412/)
- Anthology ID: 2023.emnlp-main.412 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "중국어 에세이 담론 일관성 코퍼스 (CEDCC)"는 담론 일관성을 평가하기 위한 다중 작업 데이터셋으로, 기존 연구는 담론 일관성의 고립된 측면에 초점을 맞추었다. CEDCC는 일관성 평가, 주제 연속성, 담론 관계를 통합하여 이러한 빈 공간을 채우는 데 기여하며, 상세한 주석을 통해 현실적인 텍스트의 세세한 면을 포착하여 중국어 담론 일관성 분석의 진전을 촉진한다.
    2. 우리의 기여는 CEDCC의 개발, 추가 연구를 위한 기준선의 확립, 그리고 일관성이 담론 관계 인식과 자동 에세이 점수에 미치는 영향을 시연하는 것이다.
    3. 이 데이터셋과 관련 코드는 https://github.com/cubenlp/CEDCC_corpus에서 이용할 수 있습니다.

###### SKD-NER: Continual Named Entity Recognition via Span-based Knowledge Distillation with Reinforcement Learning (https://aclanthology.org/2023.emnlp-main.413/)
- Anthology ID: 2023.emnlp-main.413 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. '지속적인 학습을 위한 개체명 인식(CL-NER)'은 모델이 이전에 학습한 개체 유형을 인식하는 능력을 유지하면서 새로운 개체 유형을 계속 학습할 수 있도록 하는 것을 목표로 한다. 하지만 이전에 학습한 개체 유형의 catastrophic forgetting 문제를 효과적으로 해결하는 현재의 전략은 실패하고 있다.
    2. 이 문제를 해결하기 위해 우리는 SKD-NER 모델을 제안한다. 이 모델은 개체기반 접근 방식을 기반으로 하며, 강화학습 전략을 혁신적으로 포함시켜 catastrophic forgetting에 대한 모델의 능력을 향상시킨다.
    3. 우리의 실험 결과는 우리의 모델이 CL-NER 작업의 성능을 현저하게 향상시키며, 최첨단 방법들을 앞지른다는 것을 보여준다.

###### Lifelong Sequence Generation with Dynamic Module Expansion and Adaptation (https://aclanthology.org/2023.emnlp-main.414/)
- Anthology ID: 2023.emnlp-main.414 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. lifelong sequence generation(LSG)은 지속적인 학습에서 모델을 일련의 생성 작업에 지속적으로 훈련시키는 것을 목표로 하며, 새로운 생성 패턴을 지속적으로 학습하면서도 이전 지식을 잊지 않는 것이다.
    2. 기존 LSG 방법들은 이전 지식 유지에 중점을 두고 있으며 과업간 지식 전이에 관심을 덜 가지고 있다. 
    3. DMEA는 과업 상관관계에 기초하여 새로운 지식을 습득하기 위한 동적 아키텍처 결정 및 새로운 과업에 대한 적응을 용이하게 하는 가장 유사한 이전 과업을 선택하는 기능을 제공한다.

###### When the Majority is Wrong: Modeling Annotator Disagreement for Subjective Tasks (https://aclanthology.org/2023.emnlp-main.415/)
- Anthology ID: 2023.emnlp-main.415 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기계 학습에서 전체 투표는 hate speech 탐지와 같은 작업에서 annotator 간의 의견 차이는 노이즈가 아닌 의견의 체계적 차이를 반영할 수 있다. 이에, 작은 그룹으로부터의 공격적인 문장인지를 판단하는 것이 중요하다. 
    2. 우리는 잠재적으로 공격적인 텍스트에 대한 개별 annotator의 등급을 예측하고, 이 정보를 텍스트의 예측된 대상 그룹과 결합하여 대상 그룹 구성원의 등급을 예측하는 모델을 구성한다. 
    3. 우리는 다양한 메트릭에서 성능을 향상시키며, 개별 annotator 등급 예측에서 22%의 기준선을 높이고, annotator 간 분산 예측에서는 33%의 성능 향상을 보였으며, 이는 모델의 불확실성 메트릭을 제공한다. 또한, annotator의 의견은 온라인 콘텐츠의 의견과 함께 demograhic 정보를 사용하여 예측할 수 있으며, invasive하지 않은 질문을 통해 annotator의 온라인 경험을 최소화하여 demograhic 정보 수집의 필요성을 줄일 수 있다.

###### Lazy-k Decoding: Constrained Decoding for Information Extraction (https://aclanthology.org/2023.emnlp-main.416/)
- Anthology ID: 2023.emnlp-main.416 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 본 논문은 구조화된 예측에서 확률적 모델을 개선하는 가능성을 탐구한다. 특히, 정보 추출을 위한 토큰 분류의 맥락에서 제약 조건 디코딩 방법과 모델을 결합한다.
    2. 디코딩 방법들은 제약 조건을 만족하는 라벨 할당을 찾으면서 전체 확률을 최대화한다.
    3. 실험 결과, 작은 모델을 사용할 때 특히 제약 조건 디코딩 방법이 모델의 성능을 크게 개선할 수 있음을 보여주었다.

###### Personalized Distillation: Empowering Open-Sourced LLMs with Adaptive Learning for Code Generation (https://aclanthology.org/2023.emnlp-main.417/)
- Anthology ID: 2023.emnlp-main.417 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 강력한 닫힌 소스 LLMs (ChatGPT, GPT-4)의 등장으로 닫힌 소스 LLMs의 능력을 작은 오픈 소스 LLMs에 전달하는 데 관심이 높아졌습니다.
    2. 기존의 전수 지식 추출 방법은 학생 모델이 배울 수 있도록 ChatGPT에게 명령과 답변 집합을 생성하도록 하는 것이었습니다.
    3. 그러나 이 논문에서는 학생 모델의 장점과 조건을 간과하지 않도록 개인화된 전수 과정을 설계하여 학생 모델에 대한 개인화된 학습을 가능하게 함으로써 표준적인 전수 방법을 능가하였습니다.

###### Do Language Models Have a Common Sense regarding Time? Revisiting Temporal Commonsense Reasoning in the Era of Large Language Models (https://aclanthology.org/2023.emnlp-main.418/)
- Anthology ID: 2023.emnlp-main.418 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 시계열 추론은 인간의 의사 소통과 이해에 있어 중요한 요소이지만, 큰 언어 모델에서는 아직까지 미개척된 분야이다. 이 논문에서는 큰 언어 모델 (LLM)의 시계열 추론 능력에 대한 첫 번째로 광범위한 벤치마킹을 제공한다. 
    2. 6개의 데이터셋에서 8개의 다른 언어 모델을 사용하여 3가지 서로 다른 프롬프팅 전략을 통해 본 모델을 평가했다.
    3. 시계열 작업의 다양한 범주에서의 성능을 세분화 조사하고, 이를 통해 모델의 시간적 측면에서 이벤트의 연속성, 순서, 진행을 이해하고 예측하는 능력을 분석하였다. 이를 통해 모델의 능력과 한계에 대한 포괄적인 참고 자료를 제공한다.

###### Comparing Styles across Languages (https://aclanthology.org/2023.emnlp-main.419/)
- Anthology ID: 2023.emnlp-main.419 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어 간 스타일 차이를 이해하는 것은 문화적으로 적절한 텍스트를 생성하기 위해 사람과 컴퓨터를 훈련하는데 유리하다.
    2. 이 논문에서는 다국어 언어 모델로부터 스타일적 차이를 추출하는 설명 프레임워크를 소개하고, 언어 간 스타일을 비교한다.
    3. 이 프레임워크는 언어별로 포괄적인 스타일 렉시콘을 생성하고, 언어 모델의 피처 중요도를 비교 가능한 어휘 범주로 통합하는 기능을 제공한다.

###### Event Causality Extraction via Implicit Cause-Effect Interactions (https://aclanthology.org/2023.emnlp-main.420/)
- Anthology ID: 2023.emnlp-main.420 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이벤트 인과관계 추출 (ECE)은 모델이 이벤트 간 인과관계를 캡처하기 위해 강력한 추론 능력을 가져야 하는데, 기존 연구는 인과성 추론에 중요한 단서를 제공할 수 있는 인과이벤트 사이의 상호작용을 충분히 활용하지 못했다.
    2. 우리는 이를 위해 Implicit Cause-Effect interaction (ICE) 프레임워크를 제안하여 ECE를 템플릿 기반의 조건부 생성 문제로 정의한다. 우리의 방법은 개념 추론에 관한 특권 정보 (ground truth event types and arguments)를 활용하여 암묵적인 이벤트 간 상호작용을 캡처하며, 테스트 단계에서 특권 정보의 부재를 완화하기 위해 지식 전달 기계를 도입한다.
    3. 또한, 선생님으로부터 학생으로의 지식 전이를 용이하게 하기 위해 Cause-Effect Optimal Transport (CEOT)라는 이벤트 수준의 정렬 전략을 설계하여 인과성 이벤트 유형과 인수의 의미적 상호작용을 강화한다. 실험 결과는 ICE가 ECE-CCKS 데이터셋에서 최고 수준의 성능을 달성한다는 것을 보여준다.

###### Evaluation of African American Language Bias in Natural Language Generation (https://aclanthology.org/2023.emnlp-main.421/)
- Anthology ID: 2023.emnlp-main.421 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 그동안, 음성인식이나 독성 감지와 같은 작업에서 African American Language (AAL)을 불리하게 하는 편향이 모델에서 발견되었지만, ChatGPT와 같은 언어 생성 모델에 대한 이러한 편향에 대해 조사된 바가 거의 없었습니다.
    2. 우리는 미국 교실에서 권장되는 "표준" 영어인 White Mainstream English (WME)와 비교하여 대규모 언어 모델의 AAL 이해도를 평가했습니다.
    3. 우리는 AAL 텍스트의 새로운 데이터셋을 기반으로 하여, 전처리된 LLMs 6개의 작업 성능 차이를 통해 방언적 편향에 대한 증거를 제시합니다.

###### A Systematic Study of Performance Disparities in Multilingual Task-Oriented Dialogue Systems (https://aclanthology.org/2023.emnlp-main.422/)
- Anthology ID: 2023.emnlp-main.422 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다국어 NLP의 핵심 목표는 세계의 다양한 언어에서 잘 작동하는 강건한 언어 기술을 달성하는 것이다. 이 논문에서는 다양한 다국어 task-oriented dialogue (ToD) 시스템 간의 성능 격차를 정량적으로 측정하고 분석한다.
    2. ToD task, pretrained 언어 모델, 대상 언어, ToD 주석 데이터 양 등 여러 요소에 따라 성능 격차가 발생하는 것을 실험을 통해 입증한다.
    3. 또한 현재의 ToD 시스템에서 적응 (adaptation) 및 내재적 편향 (intrinsic biases)이 존재함을 증명하고, 다양한 언어에서 ToD 데이터 수집 및 시스템 개발에 대한 실용적인 팁을 제공한다.

###### Cognate Transformer for Automated Phonological Reconstruction and Cognate Reflex Prediction (https://aclanthology.org/2023.emnlp-main.423/)
- Anthology ID: 2023.emnlp-main.423 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 역사적 언어학의 중심적인 문제 중 하나인 음운 복원은 자식 언어의 관찰된 공동어로부터 조상 언어의 원어를 결정하는 문제입니다.이 논문에서는 단백질 언어 모델인 MSA Transformer를 음운 복원 문제에 적용하여 모델의 성능을 향상시켰습니다.
    2. MSA Transformer는 다중 시퀀스 정렬을 입력으로 사용하여 여러 개의 관련된 언어 데이터에 적합한 모델입니다. 이 모델을 Cognate Transformer라고 명명하고, 연관된 과제 중 하나인 관련어 반영 예측에도 적용하였습니다.
    3. 실험 결과, Cognate Transformer는 기존 모델보다 음운 복원과 관련어 반영 예측 두 가지 과제에서 우수한 성능을 보였으며, 특히 마스킹된 단어 예측 작업에서 사전 훈련된 경우에 더 효과적인 것으로 나타났습니다.

###### Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning (https://aclanthology.org/2023.emnlp-main.424/)
- Anthology ID: 2023.emnlp-main.424 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 극단적 규모의 언어 모델들은 다양한 언어 태스크에서 탁월한 성능을 보이지만, 순수한 프롬프팅을 통해 이러한 언어 모델을 제어하는 정도는 제한적일 수 있다.
    2. IPA는 fine-tuning 없이도 GPT-3와 같은 언어 모델을 효율적으로 개선하는 방법으로, 경량의 정책 어댑터를 사용하여 임의의 사용자 목적을 최적화하기 위해 강화학습으로 훈련된 대규모 기본 모델을 디코딩 시간에 안내한다.
    3. 텍스트 생성과 같은 다섯 가지 어려운 태스크에서 IPA는 기본 언어 모델보다 지속적인 개선을 가져와 경쟁적인 베이스라인 방법들보다 우월한 결과를 보여준다. 또한, IPA를 사용하여 GPT-2를 개선할 경우 GPT-3를 능가할 수 있으며, GPT-3에서 IPA를 사용하는 경우 GPT-3보다 훨씬 높은 성능 향상을 보여준다. 이러한 유망한 결과는 IPA가 극단적 규모의 언어 모델에 대한 경량 대안으로서의 잠재력을 강조한다.

###### Weakly Supervised Semantic Parsing with Execution-based Spurious Program Filtering (https://aclanthology.org/2023.emnlp-main.425/)
- Anthology ID: 2023.emnlp-main.425 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 약한 지도로 시맨틱 파서를 훈련시킬 때의 오류 프로그램은 오랜 동안 도전 과업이었다. 
    2. 이 논문에서는 프로그램 실행 결과를 기반으로 한 도메인에 구애받지 않는 필터링 메커니즘을 제안한다. 
    3. 기존 약한 지도 시맨틱 파싱 프레임워크에 용이하게 적용할 수 있으며, Empirical evaluations을 통해 향상된 성능을 보였다.

###### Taxonomy Expansion for Named Entity Recognition (https://aclanthology.org/2023.emnlp-main.426/)
- Anthology ID: 2023.emnlp-main.426 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. NER(명명된 개체 인식) 모델을 학습하는 것은 주로 개체 유형의 분류 체계를 고정하는 것을 포함한다. 그러나 요구 사항이 변화하고 추가 개체 유형을 인식할 필요가 있는 경우가 발생할 수 있다.
    2. 기존의 방법은 기존과 추가 개체 유형을 포함하여 전체 데이터셋을 다시 주석을 달고 모델을 학습하는 것이다. 그러나 이 작업은 매우 수고롭다.
    3. 이 논문에서는 부분적으로 주석이 달린 데이터셋만 사용하는 새로운 접근 방식인 PLM(부분 레이블 모델)을 제안하고, 이 방법이 이전 연구에서 고려되지 않은 분류 체계 확장에도 일관되게 더 나은 성능을 보인다는 것을 실험을 통해 보여준다.

###### Rather a Nurse than a Physician - Contrastive Explanations under Investigation (https://aclanthology.org/2023.emnlp-main.427/)
- Anthology ID: 2023.emnlp-main.427 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. '*대비적 설명 (contrastive explanations)*'은 어떤 결정을 '*다른 결정과 대조하여*' 설명하는 것으로, 비대비적 설명보다 인간이 결정을 설명하는 방식과 더 비슷하다고 주장되었으나, 이 주장은 아직 실험적으로 검증되지 않았다.
    2. 본 논문에서는 SST2, DynaSent, BIOS, DBpedia-Animals라는 영어 텍스트 분류 데이터셋을 분석하고, RoBERTa, GPT-2, T5라는 세 가지 다른 모델에서 세 가지 다른 크기로 fine-tuning 및 설명을 추출한다. 또한, LRP, GradientxInput, GradNorm과 같은 세 가지 사후 설명가능성 방법을 적용한다.
    3. 결론적으로, 모델 기반 설명과 인간의 주관적 설명이 모두 대비적/비대비적 설정에서 높은 일치도를 보이며, 두 경우의 모델 기반 설명 모두 인간의 이유를 충분히 잘 설명한다는 결과를 실험적으로 발견하였다. 따라서, 인간이 대비적인 방식으로 결정을 설명하지 않을 수도 있다는 것을 밝혀냈다.

###### EtiCor: Corpus for Analyzing LLMs for Etiquettes (https://aclanthology.org/2023.emnlp-main.428/)
- Anthology ID: 2023.emnlp-main.428 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 일상 소통에서 etiquettes는 굉장히 중요한 부분이다. 이 논문에서는 5개의 지역에서 텍스트들을 모은 Etiquettes Corpus를 제안한다.
    2. Etiquettes Corpus는 지역별 social norms에 대한 LLM 지식과 이해를 평가하기 위한 실험 환경을 제공한다.
    3. 실험 결과, 최신 LLM들은 주로 양서권이 아닌 지역의 etiquettes를 이해하지 못하는 것으로 나타나고 있다.

###### An Investigation of LLMs’ Inefficacy in Understanding Converse Relations (https://aclanthology.org/2023.emnlp-main.429/)
- Anthology ID: 2023.emnlp-main.429 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델(LLM)은 구조적인 데이터-텍스트 변환과 의미 파싱과 같은 형식 언어 지향적인 작업에서 주목할만한 성과를 이루었다. 그러나 현재 벤치마크는 대부분 LLM의 사전 훈련 데이터 분포를 따르기 때문에, LLM이 실제로 형식 언어의 구조적 의미를 이해하는지에 대한 의문이 제기된다.
    2. 본 논문에서는 특정 사례인 반대 이진 관계(converse binary relation)에 대해 이 문제를 조사한다. 우리는 반대 관계에 초점을 맞춘 ConvRe라는 새로운 벤치마크를 소개하며, 이 벤치마크는 인기 있는 지식 그래프 완성 데이터셋에서 추출된 17개 관계와 1240개 트리플을 포함한다.
    3. 실험 결과는 LLM이 종종 단축학습을 하고 여전히 우리가 제안한 벤치마크에 대한 도전을 직면하고 있다는 것을 시사한다.

###### Towards Low-Resource Automatic Program Repair with Meta-Learning and Pretrained Language Models (https://aclanthology.org/2023.emnlp-main.430/)
- Anthology ID: 2023.emnlp-main.430 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자동 프로그램 수정(APR)은 수작업 디버깅 작업을 줄이고 개발자의 생산성을 향상시키기 위한 소프트웨어 개발에서 핵심적인 기술로 주목받고 있다. 그러나 실질적인 상황에서 소프트웨어 버그는 불균형 분포를 가지고 있고, APR 모델이 학습한 수정 지식은 주로 빈번한 오류 유형의 패턴만 포착하므로 드물게 발생하는 오류 유형을 다루기에 적합하지 않다.
    2. 우리는 이 한계를 해결하기 위해 저자원 APR의 새로운 과제를 조사하고, 코드 사전 훈련 언어 모델과 통합된 새로운 메타 학습 프레임워크인 Meta-APR을 제안한다. Meta-APR은 효율적인 일급 메타 학습 최적화를 통해 고자원 버그로부터 더 나은 오류별 지식을 학습함으로써 대상 저자원 버그에 대한 빠른 적응을 가능케 한다.
    3. CodeT5를 Meta-APR의 백본 모델로 채택하였지만, 어떤 신경망 모델에도 통합될 수 있는 모델 태환적인 프레임워크이다. 다양한 프로그래밍 언어에서 세 가지 벤치마크에 대한 실험 결과는 우리의 방법이 기존 DL 기반 APR 접근 방식보다 우수함을 검증하고 있다.

###### ZGUL: Zero-shot Generalization to Unseen Languages using Multi-source Ensembling of Language Adapters (https://aclanthology.org/2023.emnlp-main.431/)
- Anthology ID: 2023.emnlp-main.431 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. NLP 태스크에서의 제로샷 크로스-리질 전송 문제를 언어 어댑터 (LAs)를 사용하여 해결한다. 그러나 대부분의 이전 연구들은 단일 소스 (보통 영어)의 어댑터로 학습한 뒤, 대상 LA 또는 다른 관련 언어의 LA를 사용하여 테스트한다. 모델의 robustness를 높이기 위해 여러 언어 (언어적 또는 지리적으로 관련된)의 어댑터를 요구한다.
    2. LAs를 이용한 훈련은 unlabelled data를 필요로 하는데, 이는 저자들이 언급한 low resource unseen languages에서 바로 사용할 수 없는 문제를 발생시킨다. 
    3. ZGUL(Zero-shot Geographical and Unseen Languages)라는 새로운 신경 구조를 사용하여 여러 소스 언어의 어댑터를 이용해 효과적인 크로스-리질 전송을 실현하였고, 15개의 unseen target 언어에 대해 POS 태깅 및 NER 태스크에 대해 3.2 average F1 point의 성능 향상을 얻었음을 실험으로 입증하였다.

###### Log-FGAER: Logic-Guided Fine-Grained Address Entity Recognition from Multi-Turn Spoken Dialogue (https://aclanthology.org/2023.emnlp-main.432/)
- Anthology ID: 2023.emnlp-main.432 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다중 턴의 대화에서 세부 주소 엔터티 인식은 특히 어렵다. 주소의 다른 부분들은 여러 턴의 대화를 통해 분산되고, 이를 턴별로 추출하여 결합하는 것은 어렵다.
    2. 이 논문에서는 주소의 계층 구조 관계를 논리 규칙으로 정의하고, 확률적인 방식으로 적용하여 FGAER (Fine-grained address entity recognition)의 정확도를 향상시키는 로직 가이드 fine-grained address recognition(Log-FGAER) 방법을 제안한다.
    3. 또한, 우리는 라벨이 지정된 주소 엔터티로 말뭉치 대화 데이터셋을 ChatGPT를 사용하여 온톨로지 기반 데이터 증강 방법론을 제시한다. 실험 결과는 우리의 제안의 효과를 입증한다.

###### Unified Low-Resource Sequence Labeling by Sample-Aware Dynamic Sparse Finetuning (https://aclanthology.org/2023.emnlp-main.433/)
- Anthology ID: 2023.emnlp-main.433 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Named Entity Recognition, Relation Extraction, Semantic Role Labeling 등 다양한 sequence labeling 문제를 통합된 시퀀스-대-시퀀스 형식으로 정의하는 Unified Sequence Labeling은 대규모 언어 모델 지식을 구조화된 예측에 최대한 활용할 수 있는 기회를 제공한다.
    2. 그러나 이를 위해서는 베이스 pretrained 언어 모델에 알려지지 않은 특수한 형식에 맞게 포맷팅해야 하므로 타겟 포맷에 충분히 적용될 수 없는 데이터 제한 상황에서 사용성이 제한된다.
    3. 이 논문에서는 FISH-DIP라는 샘플-의존성을 고려한 동적 sparse 파일 튜닝 전략을 제안하여, 대량의 모델 파라미터 대신에 고품질 예측을 위한 적은 파라미터에 초점을 맞추는 동안 모델을 최적화하는 방법을 제시한다. 이 방법은 저자와 저성능 인스턴스를 우선적으로 개선함으로써 일련의 작업에서 최대 40%의 성능 향상을 보여준다.

###### On the Representational Capacity of Recurrent Neural Language Models (https://aclanthology.org/2023.emnlp-main.434/)
- Anthology ID: 2023.emnlp-main.434 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 연구는 시계열 신경망(RNN)을 기반으로 하는 언어 모델의 계산 표현력을 조사한다. 
    2. 제안된 방법은 실시간 계산을 수행하는 실제 RNN 언어 모델을 이용하여 결정론적인 확률적 튜링 머신(PTM)을 재현할 수 있다는 것을 보여준다. 
    3. 이 연구에서는 실제 시간 제한 하에서 RNN 언어 모델의 계산능력을 상한값과 하한값으로 제시한다.

###### A Mechanistic Interpretation of Arithmetic Reasoning in Language Models using Causal Mediation Analysis (https://aclanthology.org/2023.emnlp-main.435/)
- Anthology ID: 2023.emnlp-main.435 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 연구에서는 많은 언어 모델 (LMs) 에서의 수학적 추론에 관심을 가지고 있으나, 이러한 모델이 산술 과제와 관련된 정보를 어떻게 처리하고 저장하는지에 대한 이해는 제한적이다.
    2. 이 논문에서는 인과 중재 분석 프레임워크를 사용하여 산술 문제에 대한 Transformer 기반 LMs 의 기계적 해석을 제시하고, 특정 모델 구성 요소의 활성화에 개입함으로써 예측된 확률의 변화를 측정함으로써 특정 예측에 책임 있는 파라미터의 하위 집합을 식별한다.
    3. 실험 결과에 따르면 LMs는 중간 레이어에서 최종 토큰까지의 유의미한 정보를 어텐션 메커니즘을 통해 전달하여 입력을 처리하며, 그 정보는 MLP 모듈의 세트에 의해 처리되어 결과와 관련된 정보를 생성하고 잔류 데이터 스트림에 통합된다.

###### Benchmarking and Improving Text-to-SQL Generation under Ambiguity (https://aclanthology.org/2023.emnlp-main.436/)
- Anthology ID: 2023.emnlp-main.436 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 지금까지의 Text-to-SQL 변환 연구는 텍스트 쿼리마다 하나의 올바른 SQL이 있는 데이터셋을 기반으로 진행되었으나, 실제로 발생하는 자연어 쿼리는 겹치는 스키마 이름과 혼동스러운 관계 경로로 인해 의도한 SQL에 대한 중대한 모호함을 포함한다.
    2. 이 연구에서는 LexicalBeam이라는 새로운 디코딩 알고리즘을 제안하여 SQL 논리 공간을 탐색하는 데에 효과적이며, 관련된 인터페이스를 통해 사용자가 다른 해석에 대한 고려를 할 수 있는 환경을 제공한다.
    3. 이미지와 자연어 생성에서 많은 성과를 거둔 beam search 알고리즘들은 SQL 쿼리 생성에 있어서 유용하지 않은 토큰 수준의 다양성을 제공하여 원하는 결과를 얻지 못하게 한다는 것이다.

###### Non-autoregressive Text Editing with Copy-aware Latent Alignments (https://aclanthology.org/2023.emnlp-main.437/)
- Anthology ID: 2023.emnlp-main.437 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 텍스트 편집 분야에서는 Seq2Seq에서 Seq2Edit로의 패러다임 전환을 목표로 한다. 하지만 Seq2Edit 방법은 여전히 단어 생성의 유연성과 다른 언어로의 일반화와 같은 몇 가지 문제에 직면한다.
    2. 이 논문에서는 CTC 정렬을 통해 텍스트 편집 과정을 모델링하는 새로운 비자기방적 텍스트 편집 방법을 제안한다. 복사 작업을 편집 공간에 도입함으로써 텍스트 중첩을 효율적으로 관리할 수 있는 기능을 제공한다.
    3. GEC 및 문장 퓨전 작업에서의 실험 결과를 통해 제안한 방법이 기존의 Seq2Edit 모델보다 우수한 성능을 보이며, 4배 이상의 속도 개선을 달성한다는 것을 보여준다. 또한, 독일어와 러시아어에서의 일반화 능력을 잘 보여준다.

###### Translating away Translationese without Parallel Data (https://aclanthology.org/2023.emnlp-main.438/)
- Anthology ID: 2023.emnlp-main.438 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존 평가 메트릭은 MCQ의 교육적 가치를 고려하지 못하고 데이터셋에 있는 단어만 비교하여 평가하는데, 이 논문에서는 솔루션을 제안하여 실제 강의실에서 사용할 수 있는 자동 평가 메트릭인 KDA를 사용한다.
    2. 기존 augmentation 방법들은 spurious correlation에 영향을 받지만, 이 논문에서는 collective decision과 contrastive learning을 이용하여 counterfactual augmentation의 robustness를 향상시켰다.
    3. 번역된 텍스트는 원래 텍스트와는 다른 언어적 차이를 보이는데, 이 논문에서는 번역되어진 텍스트의 translationese를 줄이기 위해 translation-based style transfer를 사용한다.

###### Prompt-Based Monte-Carlo Tree Search for Goal-oriented Dialogue Policy Planning (https://aclanthology.org/2023.emnlp-main.439/)
- Anthology ID: 2023.emnlp-main.439 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 목표 지향형 대화를 위한 계획은 미래 대화 상호작용을 시뮬레이션하고 과업 진행을 추정하는 것을 필요로 한다. 
    2. 이 논문에서는 GDP-Zero라는 방법을 소개하여 모델 훈련 없이 목표 지향형 대화 정책 계획을 수행하는 방법을 제안한다. 
    3. GDP-Zero는 대화 과정에서 다양한 역할을 하는 큰 언어 모델을 활용하여 대화 정책을 설정하고 성능을 평가한 결과, ChatGPT보다 더 낮은 시간 동안 응답을 선호하고 상호작용 평가에서 더 설득력 있게 평가되었다.

###### UniMath: A Foundational and Multimodal Mathematical Reasoner (https://aclanthology.org/2023.emnlp-main.440/)
- Anthology ID: 2023.emnlp-main.440 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "자연어 처리(NLP) 분야에서는 상당한 진전이 있었지만, 기존 방법들은 다양한 수학 모드를 효과적으로 해석하고 처리하는 데 제한이 있다. 따라서 이 논문에서는 다중 모달 수학 추론 작업에 적합하고 통합된 UniMath 시스템을 소개한다."
    2. "UniMath는 산술, 기하학, 테이블 기반 수학의 복잡한 문제 해결에 대한 다중 모달 지원을 위해, fine-tuned T5 모델에 변분 오토인코더(VAE) 기반 이미지 토크나이저를 도입한다."
    3. "SVAMP, GeoQA, TableMWP의 다양한 데이터셋에서 모델을 공동으로 훈련하고 평가함으로써 UniMath는 최고 수준의 성능을 달성한다. 또한, MathQA와 Geo-Proving의 두 개의 추가 데이터셋에 적용하여 모델의 일반화 능력을 확인하였다."

###### CaseEncoder: A Knowledge-enhanced Pre-trained Model for Legal Case Encoding (https://aclanthology.org/2023.emnlp-main.441/)
- Anthology ID: 2023.emnlp-main.441 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 법적인 사례를 찾는 것은 현대 법률 정보 시스템에서 중요한 과정이다. 최근의 연구는 법적 사례 검색을 위해 일반 도메인에서 미리 학습한 언어 모델을 사용해왔지만, 일반 도메인 PLM을 사용하는 것에는 제한이 있다. 특히 이러한 모델은 법적 사례 문서에서의 법적 속성을 충분히 포착하지 못할 수 있다. 
    2. 이 문제를 해결하기 위해 우리는 CaseEncoder라는 법적 문서 인코더를 제안한다. CaseEncoder는 데이터 샘플링 및 사전 학습 단계에서 세밀한 법적 지식을 활용한다. 세밀한 법 조항 정보를 활용하여 양성 및 음성 예시를 선택하는 것으로 학습 데이터의 품질을 향상시킨다.
    3. 실험 결과, CaseEncoder는 일반 사전 학습 모델과 법적 사전 학습 모델을 모두 능가하여 zero-shot 법적 사례 검색에서 상당한 성능 향상을 이룩한다. CaseEncoder의 소스 코드는 https://github.com/Anonymous-EMNLP2023/CaseEncoder에서 찾을 수 있다.

###### HiddenTables and PyQTax: A Cooperative Game and Dataset For TableQA to Ensure Scale and Data Privacy Across a Myriad of Taxonomies (https://aclanthology.org/2023.emnlp-main.442/)
- Anthology ID: 2023.emnlp-main.442 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Large Language Models (LLMs)는 테이블 기반 질문-답변 작업에서 한계를 가지고 있으며, 이를 해결하기 위해 "HiddenTables"이라는 협력 게임을 제안한다.
    2. 이 게임은 LLM 에이전트의 능력을 평가하는 Oracle과 코드 생성 LLM Solver 사이에서 진행되며, 자연어 스키마를 기반으로 한다는 점에서 중요하다. 이 게임은 백엔드 데이터의 보안을 보장하고 있다.
    3. "HiddenTables"의 인프라를 사용하여 새로운 데이터셋 "PyQTax"를 만들었으며, 이는 116,671개의 질문-테이블-답변 쌍에 대한 세분화된 분석 및 다양한 질문 분류에 대한 레이블을 제공한다.

###### Causal Document-Grounded Dialogue Pre-training (https://aclanthology.org/2023.emnlp-main.443/)
- Anthology ID: 2023.emnlp-main.443 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 문서기반 대화 (DocGD)의 목표는 대화 맥락에 따라 지원 문서에서 근거를 제시하여 응답을 생성하는 것이다. 
    2. 기존의 DocGD 방법들은 인과관계를 명시적으로 포착하는 특별히 맞춤형 사전훈련 접근 방식 없이 일반적인 사전훈련 언어 모델에 의존하고 있는 것으로 나타났다.
    3. 이 논문에서는 인과 관계를 명확하게 포착하는 데 적합한 사전훈련 접근 방식을 제안하고 대규모 DocGD 사전훈련 말뭉치 구축을 위한 첫 번째 완전한 인과관계 데이터셋 구축 전략을 제시한다.

###### Accented Speech Recognition With Accent-specific Codebooks (https://aclanthology.org/2023.emnlp-main.444/)
- Anthology ID: 2023.emnlp-main.444 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 스피치 악센트는 최신 자동 음성 인식 (ASR) 시스템에 대한 중요한 도전 과제입니다. 소수 악센트에 대한 성능 저하는 ASR의 포용적인 적용을 방해하는 심각한 문제입니다.
    2. 이 논문에서는 훈련 가능한 코드북 집합을 사용하여 end-to-end ASR 시스템을 위한 독특한 악센트 적응 방법을 제안합니다. 이러한 코드북은 악센트별 정보를 포착하고 ASR 인코더 레이어에서 통합됩니다.
    3. 실험 결과, 우리의 제안된 방법은 훈련 중 본적이 있는 영어 악센트뿐만 아니라 훈련 중보지 않은 악센트에 대해서도 유의한 성능 향상을 보입니다.

###### Linking Surface Facts to Large-Scale Knowledge Graphs (https://aclanthology.org/2023.emnlp-main.445/)
- Anthology ID: 2023.emnlp-main.445 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 오픈 정보 추출(OIE) 방법은 ("주어", "관계", "목적어") 삼중체 형식으로 자연어 텍스트에서 사실을 추출한다. 그러나 이러한 사실들은 단순한 표면 형태에 불과하며, 그 모호함으로 인해 하위 작업에서의 사용이 어렵다. 
    2. 이 논문에서는 OIE의 높은 커버리지와 지식 그래프의 의미정밀도를 결합하기 위해 새로운 벤치마크와 평가 프로토콜을 제안한다. 
    3. 여러 가지 기준에서의 벤치마크 실험 결과, 기존 지식 그래프에 링크되지 않은 entities 및 predicates의 탐지가 정확한 링킹보다 어렵다는 것을 보여주었다. 이로써 이 어려운 작업에 대한 추가 연구 노력이 요구된다는 결론을 내렸다.

###### Sentiment Analysis on Streaming User Reviews via Dual-Channel Dynamic Graph Neural Network (https://aclanthology.org/2023.emnlp-main.446/)
- Anthology ID: 2023.emnlp-main.446 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 딥러닝 기술의 빠른 발전으로 사용자 리뷰의 감성 분석이 큰 성과를 이뤄냈으나, 기존 방법은 사용자와 제품에 대한 정적인 가정을 하고 시간에 따라 변하는 특성을 간과하고 있다.
    2. 본 논문에서는 시간에 따라 변하는 사용자와 제품의 특성을 모델링하기 위해 동적 그래프 신경망(DGNN)을 기반으로 한 이중 채널 프레임워크인 DC-DGNN을 제안한다.
    3. 실험 결과를 통해 제안된 방법의 우수성을 입증하였다.

###### DUMB: A Benchmark for Smart Evaluation of Dutch Models (https://aclanthology.org/2023.emnlp-main.447/)
- Anthology ID: 2023.emnlp-main.447 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. DUMB (Dutch Model Benchmark)는 저-규모, 중-규모 및 고-규모 작업에 대한 다양한 데이터셋을 포함한 언어 모델의 성능을 비교하는 벤치마크를 제시한다. 
    2. RER (상대적 에러 감소)은 DUMB의 언어 모델 성능을 강력한 기준선과 비교하여 다른 언어 모델을 평가할 때도 참조할 수 있도록 평가 지표를 제안하였다. 
    3. 실험 결과, 현재의 네덜란드어 모노링구얼 모델들은 성능이 낮으며, 더 큰 규모의 다른 아키텍처와 사전 학습 목적을 가진 네덜란드어 모델을 훈련시키는 것이 좋다는 것을 보여주었다.

###### OssCSE: Overcoming Surface Structure Bias in Contrastive Learning for Unsupervised Sentence Embedding (https://aclanthology.org/2023.emnlp-main.448/)
- Anthology ID: 2023.emnlp-main.448 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Contrastive learning은 비지도 문장 표현 학습에서 효과적인 방법으로 입증되었으나, 기존 방법은 표면 구조 편향(surface structure bias)에 취약하다. 
    2. 이 논문에서는 표면 구조와 의미론적 유사성을 기반으로 새로운 데이터셋을 제안하여 기존 모델을 체계적으로 조사하였다. 
    3. 또한, biased를 극복하기 위해 두 가지 측면에서 대응하였는데, 하나는 bias에 반대하는 데이터로 augmentation하는 것이고, 다른 하나는 catastrophic forgetting을 방지하기 위해 recall loss를 활용하여 단어 의미를 보존하는 것이다.

###### End-to-End Single-Channel Speaker-Turn Aware Conversational Speech Translation (https://aclanthology.org/2023.emnlp-main.449/)
- Anthology ID: 2023.emnlp-main.449 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 음성-텍스트 번역(ST) 시스템은 한 명의 화자의 발화를 훈련시키고, 여러 명의 화자가 대화하는 실제 시나리오에서는 일반화되지 않을 수 있다.
    2. 이 논문에서는 여러 화자 간의 대화가 포함된 단일 채널 멀티스피커 대화 ST를 다루는데, 이를 위해 자동 음성 인식, 음성 번역 및 화자 차례 감지를 결합하는 다중작업 훈련 모델을 제안한다.
    3. 실험 결과에서 다중 화자 조건에서 기존 ST 시스템에 비해 우수한 성능을 보여주는 반면, 싱글 스피커 조건에서는 유사한 성능을 달성한다. (scripts for data processing and model training도 공개한다)

###### A Fine-Grained Taxonomy of Replies to Hate Speech (https://aclanthology.org/2023.emnlp-main.450/)
- Anthology ID: 2023.emnlp-main.450 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 극을 멸시하는 것보다는 대대적인 카운터스피치가 적나라한 증가 방법으로 강조되고 있는데, 그런 대화에는 극혐하는 내용 혹은 대화의 창시자, 일반적인 요청, 이치에 맞는 반박, 욕설 등 다양한 유형이 있다.
    2. 카운터스피치의 효과, 즉 적대를 받아들일 확률은 이러한 유형에 달려있다. 
    3. 이 논문에서는 극혐하는 내용과 그에 대한 답변들에 대한 이론적으로 기초된 분류법과 새로운 말뭉치를 제시한다.

###### JointMatch: A Unified Approach for Diverse and Collaborative Pseudo-Labeling to Semi-Supervised Text Classification (https://aclanthology.org/2023.emnlp-main.451/)
- Anthology ID: 2023.emnlp-main.451 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "쓰지 않은 데이터를 사용할 수 있는 반지도 학습 텍스트 분류(SSTC)는 라벨 편향과 오류 누적 문제로 인해 관심을 받고 있다. 논문에서는 최근 반지도 학습과 노이즈를 학습하는 작업에서 영감을 얻어 이러한 도전에 대응하기 위한 종합적인 접근 방식인 JointMatch를 제안한다."
    2. "JointMatch는 현재 쉬운 클래스로의 모델 편향을 완화시키기 위해 다른 클래스의 학습 상태에 따라 클래스별 임계값을 적응적으로 조정하는 것과 상호 교육적 방식으로 서로 다르게 초기화된 두 네트워크를 활용하여 오류 누적 문제를 완화하는 것에 초점을 두고 있다."
    3. "벤치마크 데이터셋에서 수행한 실험 결과, JointMatch의 성능이 우수하며 평균적으로 5.13%의 향상을 달성한다. 특히, 5개 라벨 당 86%의 정확도로 극히 희소한 라벨 설정에서도 탁월한 결과를 보인다."

###### Simple Temporal Adaptation to Changing Label Sets: Hashtag Prediction via Dense KNN (https://aclanthology.org/2023.emnlp-main.452/)
- Anthology ID: 2023.emnlp-main.452 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사용자 생성 소셜 미디어 데이터는 온라인 토론에 영향을 미치는 새로운 트렌드와 개인 정보 삭제로 인해 지속적으로 변화한다. 그러나 전통적인 NLP 모델은 고정된 훈련 데이터에 의존하기 때문에 빈번하고 비용이 많이 드는 재훈련 없이는 시간적 변화에 대응할 수 없다.
    2. 본 논문에서는 hashtag 예측을 통해 장기간 변동성에 대한 연구를 수행하고, 재훈련이 필요없는 비매개변수적 밀집 검색 기술을 간단하면서도 효과적인 해결책으로 제안한다.
    3. 실험 결과, 우리의 방법은 시간적 분포 변화가 있는 최신 트위터 데이터셋에서 최고의 정적 매개변수 기준과 비교하여 64% 향상되었으며, 비용이 많이 드는 그래디언트 기반 재훈련을 회피할 수 있다. 또한, 데이터의 개인정보 보호 법에 따라 동적으로 삭제되는 사용자 데이터에도 적합하며 계산 비용과 성능 손실이 거의 없다.

###### Speak, Memory: An Archaeology of Books Known to ChatGPT/GPT-4 (https://aclanthology.org/2023.emnlp-main.453/)
- Anthology ID: 2023.emnlp-main.453 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 연구에서는 이름 채우기 맴버쉽 추론 질의를 통해 ChatGPT와 GPT-4가 알고 있는 책을 추론하기 위해 데이터 고려사항을 수행한다. 그 결과, OpenAI 모델은 다양한 저작권이 있는 자료들을 기억하고 있으며, 이 기억의 정도는 해당 책의 단락이 웹에서 얼마나 자주 나타나는지와 관련이 있다.
    2. 이러한 모델의 기억 능력은 문화 분석의 측정 타당성을 복잡하게 만들며, 테스트 데이터를 오염시켜 문제가 된다. 우리는 모델이 기억하는 책에 비해 기억하지 않은 책에서 다음 작업의 결과가 훨씬 좋은 것을 보여주며, 이는 훈련 데이터가 이미 알려져 있는 개방 모델에 대한 필요성을 뒷받침한다.
    3. 따라서 우리는 훈련 데이터가 알려진 개방 모델에 대한 지지를 제공하는 것이 타당하다 주장한다.

###### A Study on Accessing Linguistic Information in Pre-Trained Language Models by Using Prompts (https://aclanthology.org/2023.emnlp-main.454/)
- Anthology ID: 2023.emnlp-main.454 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 다중언어 언어 모델에서 언어적 정보에 접근할 수 있는지 연구하였으며, explicit한 문법 원리에 대한 인사이트를 얻기 위한 쉬운 방법이 없었다. 
    2. 이 논문에서는 prompting 기술을 사용하여 언어 모델이 명시적인 문법 원리에 접근할 수 있는지 테스트하고, 언어적 특징에 대한 접근 방법의 효과를 연구하였다. 
    3. 독일어, 아이슬란드어, 스페인어에 대한 실험결과, 어떤 언어적 속성은 prompting을 통해 접근할 수 있으며, 다른 언어적 속성은 더 어렵게 파악된다는 것을 보였다.

###### CiteBench: A Benchmark for Scientific Citation Text Generation (https://aclanthology.org/2023.emnlp-main.455/)
- Anthology ID: 2023.emnlp-main.455 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 과학은 이전 과학 논문에 기초하여 진전한다. 연구의 가속화로 인해 최근 개발 동향을 따라가고 이전 연구의 규모가 계속해서 증가하는 것은 어렵다. 이를 해결하기 위해, citation 텍스트 생성 작업은 인용할 논문들과 인용문맥이 주어졌을 때 정확한 텍스트 요약을 생성하기 위한 작업이다.
    2. citation 텍스트 생성은 인용된 문헌이 인용하는 논문에서 드물게 자주 나오는 텍스트의 개략적인 표현을 제공하므로, 여러 데이터를 통합하여 표준화된 평가를 가능하게 하는 CiteBench라는 벤치마크를 제안한다.
    3. 새로운 벤치마크를 활용하여 강력한 기준 선언들의 성능을 조사하고, 데이터 간의 전이 가능성을 테스트하며, 향후 연구를 지원하기 위해 citation 텍스트 생성 작업에 대한 새로운 통찰력을 제공한다.

###### From Heuristic to Analytic: Cognitively Motivated Strategies for Coherent Physical Commonsense Reasoning (https://aclanthology.org/2023.emnlp-main.456/)
- Anthology ID: 2023.emnlp-main.456 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Pre-trained language models (PLMs)는 언어 작업에서 훌륭한 성능을 보여주었지만, spurious correlations에 취약하며 가공된 정보를 생성하기도 한다. 이 연구에서는 과제와 무관한 정보를 줄이기 위해 사람과 유사한 숙고적인 추론체인을 사용하여 PLMs를 fine-tuning하고 in-context learning에 적용한다.
    2. Heuristic-Analytic Reasoning (HAR) 전략은 인간과 유사한 추론 전략을 모델에 적용하여 발전시켰으며, 정합성 있는 모델 판단을 위한 설명을 크게 개선시켰다. 
    3. 우리의 결과는 인간과 유사한 추론 전략이 PLM의 모델 판단의 일관성과 신뢰성을 개선하는 데 효과적일 수 있음을 시사한다.

###### A Challenging Multimodal Video Summary: Simultaneously Extracting and Generating Keyframe-Caption Pairs from Video (https://aclanthology.org/2023.emnlp-main.457/)
- Anthology ID: 2023.emnlp-main.457 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 본 논문은 사용 가능한 형태의 목록으로 영상의 핵심 씬을 요약하기 위한 모달 동영상 요약 과제 설정과 데이터셋을 제안한다.
    2. 이 과제는 영상에서 중요한 장면을 이미지(키프레임) 형태로 추출하고 각 키프레임의 상황을 설명하는 캡션을 생성하는 것을 목표로 한다.
    3. 이 작업은 실용적인 응용 프로그램으로 유용하며, 동시에 키프레임 선택 성능과 캡션 품질의 동시 최적화를 달성하기 위해 이전 키프레임과 이후 키프레임 및 캡션에 상호 종속성을 신중히 고려해야 하는 도전적인 문제이다.

###### Copyright Violations and Large Language Models (https://aclanthology.org/2023.emnlp-main.458/)
- Anthology ID: 2023.emnlp-main.458 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어 모델은 단순히 사실 뿐만 아니라 훈련 중에 본 텍스트의 장문을 기억할 수도 있다. 본 연구는 저작권 침해와 대규모 언어 모델 간의 문제를 verbatim memorization의 측면에서 탐색하며, 저작권을 가진 텍스트의 재배포 가능성에 초점을 맞춘다.
    2. 인기 있는 책과 코딩 문제 컬렉션을 대상으로 여러 언어 모델에 대한 실험을 진행하여, 언어 모델이 이러한 자료들을 얼마나 재배포하는지 보수적으로 확인한다.
    3. 본 연구는 저작권 규정을 준수하기 위해 자연어 처리 분야의 미래 개발에 대한 추가적인 검토와 잠재적인 영향에 대한 필요성을 강조한다.

###### Effects of sub-word segmentation on performance of transformer language models (https://aclanthology.org/2023.emnlp-main.459/)
- Anthology ID: 2023.emnlp-main.459 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자동 생성된 Multiple Choice Questions (MCQ)의 교육적 가치를 평가하기 위한 새로운 평가 메트릭인 Knowledge Dependent Answerability (KDA)가 제안되었다.
    2. KDA는 사람 조사를 기반으로 구축되며, 사후 학습 된 언어 모델을 사용하여 KDA_disc와 KDA_cont로 근사화된다.
    3. KDA_disc와 KDA_cont는 MCQ의 품질 측정에 강한 예측력을 가지며, 실제 교실 환경에서의 사용성과 강한 상관 관계를 가지고 있다.

###### Symbolic Planning and Code Generation for Grounded Dialogue (https://aclanthology.org/2023.emnlp-main.460/)
- Anthology ID: 2023.emnlp-main.460 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 큰 언어 모델 (LLMs)은 텍스트와 코드 처리 및 생성에서 우수한 성능을 보이지만, 목표에 대한 모델의 제어가 어려워 테스크 지향적인 다이얼로그에는 제한적으로 적용되고 새로운 grounding을 처리하는 데 실패한다. 
    2. 우리는 LLMs와 상징적인 계획 및 grounding 코드 실행을 결합한 모듈식이며 명확하게 설명 가능한 다이얼로그 시스템을 제안한다.
    3. 우리의 시스템은 LLM을 사용하여 대화 상대의 발언을 실행 가능한 코드로 전환하고 grounding을 수행하는 함수를 호출하는 역할을 하는 reader와 symbolic planner로 구성되어 있다. 이를 통해 우리의 시스템은 기존의 최첨단 기법을 크게 개선하였다고 평가받았다.

###### Universal Self-Adaptive Prompting (https://aclanthology.org/2023.emnlp-main.461/)
- Anthology ID: 2023.emnlp-main.461 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 현대의 대형 언어 모델(Large Language Model, LLM)은 인상적인 zero-shot과 few-shot 능력을 가지고 있으며 이러한 능력은 자주 불러내지만 실제로는 도움을 받지 못하고 있는 경우 일반적인 과제에서 기존 자동 프롬프트 설계 방법을 적용하기가 어렵기 때문에 여전히 보다 약한 성능을 보이고 있다.
    2. 본 연구에서는 Universal Self-Adaptive Prompting (USP)라는 zero-shot 학습에 특화된 자동 프롬프트 설계 접근 방식을 제시한다. USP는 라벨이 없는 일반적인 과제에서 작동하며 작은 양의 미표시 된 데이터와 추론만 가능한 LLM만으로도 사용할 수 있다.
    3. 실험 결과 USP는 다양한 자연어 이해, 생성 및 추론 작업에서 표준 zero-shot 베이스라인과 비교해 상당한 성능 향상을 보이며 종종 few-shot 베이스라인과 비교해 비슷하거나 우수한 성능을 보였다.

###### Somali Information Retrieval Corpus: Bridging the Gap between Query Translation and Dedicated Language Resources (https://aclanthology.org/2023.emnlp-main.462/)
- Anthology ID: 2023.emnlp-main.462 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 소말리아어 정보 검색에 대한 연구는 특화된 말뭉치의 부족으로 인해 조회 번역에 의존하고있다. 그러나 이 논문에서는 언어 전문가와 NLP 연구자와 협력하여 소말리아어 정보 검색을 위한 주석이 달린 말뭉치를 생성한다.
    2. 이 말뭉치는 다양한 온라인 사이트에서 수집된 2335개 문서로 구성되어 있으며, 이 말뭉치를 사용하여 의사-중요도 피드백 (PRF) 질의 확장 기법을 사용한 소말리아어 정보 검색 시스템을 개발한다.
    3. 이러한 소말리아어 데이터셋은 낮은 자원의 소말리아어에 대한 NLP 장벽을 극복할 수 있으며, 질문-답변 및 텍스트 분류와 같은 다양한 NLP 도구 및 응용 프로그램을 개발하는 데 도움이 될 뿐만 아니라 연구자들에게 새로운 기술과 접근법을 연구하고 개발할 수 있는 귀중한 자료를 제공합니다.

###### Beat LLMs at Their Own Game: Zero-Shot LLM-Generated Text Detection via Querying ChatGPT (https://aclanthology.org/2023.emnlp-main.463/)
- Anthology ID: 2023.emnlp-main.463 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 NLP 태스크에서 deep model의 정확성이 사람을 능가했지만 spurious pattern에 의존함으로써 robustness가 제한되고 있다. 
    2. 이 논문에서는 contrastive learning과 counterfactual augmentation을 활용하여 robustness를 향상시키는 방법을 제안하는데, "여러 개의" counterfactual을 생성하고, 집합적 의사 결정을 통해 각 단어의 인과관계를 robust하게 파악한다.
    3. LLM (Large Language Model)에 대한 우려에도 불구하고, 이 논문에서는 LLM이 생성한 텍스트를 탐지하기 위한 zero-shot black-box 방법을 제안하고, 다양한 데이터셋과 태스크에서 효과적으로 LLM이 생성한 텍스트를 감지할 수 있는 것을 실험적으로 보여준다.

###### Faithful Model Evaluation for Model-Based Metrics (https://aclanthology.org/2023.emnlp-main.464/)
- Anthology ID: 2023.emnlp-main.464 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 처리(NLP)에서는 통계적 유의성 검정을 통해 연구나 실험 결과가 우연히 발생한 것인지, 실제 관계를 나타내는 것인지를 판단한다.
    2. 유의성 검정 단계에서 핵심은 표본 분산에 따른 신뢰 구간을 추정하는 것인데, 기존 작업에서는 경험적인 모델을 사용하기 때문에 지표 모델 오차로 인한 분산 변화를 고려하지 않아 잘못된 결론을 낼 수 있다.
    3. 이 논문에서는 모델 기반 지표의 표본 분산을 계산할 때 지표 모델 오차를 고려하는 수학적 기반을 제시하고, 공개된 벤치마크 데이터셋과 제품 시스템에서의 실험을 통해 특정 실험에서 결론이 변경됨을 보여준다.

###### Content- and Topology-Aware Representation Learning for Scientific Multi-Literature (https://aclanthology.org/2023.emnlp-main.465/)
- Anthology ID: 2023.emnlp-main.465 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 처리 아키텍처 개발에서 representation learning은 중요한 요소인데, 기존 접근 방법들은 문장이나 문서 수준에서의 텍스트 정보 학습에 초점을 맞추었다. 이로인해 다중 문서 설정에서의 하류 응용 프로그램의 성능이 저하되는 문제가 생겼다.
    2. 이 논문에서는 다중 문서 수준으로 표현 학습을 확장한 SMRC2를 제안한다. 이 모델은 콘텐츠로부터의 잠재적 의미 정보와 토폴로지 네트워크로부터의 다양한 관련성 정보를 동시에 학습한다.
    3. 우리의 실험은 우리의 방법의 우수성과 효과를 입증하며, 과학적 다중 문헌 표현 학습에 대한 추가 연구를 촉진하기 위해 코드와 생물 의학 분야의 새로운 데이터 세트를 공개할 것이다.

###### Language Model Quality Correlates with Psychometric Predictive Power in Multiple Languages (https://aclanthology.org/2023.emnlp-main.466/)
- Anthology ID: 2023.emnlp-main.466 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 지식 기반 답변 가능성(KDA)이라는 새로운 자동 평가 메트릭을 제안하여 MCQ 생성의 교육적 가치를 평가한다.
    2. 공간적인 인과관계를 인지하기 위해 대체설적 augmentation과 대조적인 학습을 활용한 NLP 모델의 robustness를 개선하는 방법을 제안한다.
    3. 크로스언어적인 실험을 통해 대용량 LMs의 예측력과 사람의 독해 패턴 간에 유의미한 상관관계를 발견하였다.

###### Joint Entity and Relation Extraction with Span Pruning and Hypergraph Neural Networks (https://aclanthology.org/2023.emnlp-main.467/)
- Anthology ID: 2023.emnlp-main.467 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 정보 추출에서 중요한 작업인 Entity and Relation Extraction (ERE)은 최근 marker-based 파이프라인 모델이 최고 성능을 보이지만, 오류 전파 문제로 여전히 제약을 받는다.
    2. HGERE라는 Hypergraph neural network를 제안하여 오류 전파 문제를 완화하고 다중 entity와 relations간의 상호작용을 고려한다. 
    3. ACE2004, ACE2005, SciERC와 같은 벤치마크에서 수행된 실험 결과, HGERE가 이전의 최고 성능인 PL-marker보다 상당한 개선을 이루었다.

###### Have LLMs Advanced Enough? A Challenging Problem Solving Benchmark For Large Language Models (https://aclanthology.org/2023.emnlp-main.468/)
- Anthology ID: 2023.emnlp-main.468 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최신 언어 모델의 성능이 이전보다 더욱 향상되었지만, 본 논문에서는 LLM의 문제 해결 능력을 평가하기 위한 더욱 어려운 벤치마크 데이터셋인 JEEBench를 제시한다.
    2. JEEBench는 과학적인 지식이 필요한 515개의 고난도 수학, 물리학, 화학 문제를 포함하고 있으며, 이 문제를 해결하기 위해서는 깊은 도메인 지식 위에 기반한 장기적인 추리가 필요하다.
    3. 실험 결과에 따르면, 다양한 오픈소스와 사유 모델의 성능이 최대 40%에 불과하며, 가장 좋은 모델인 GPT-4의 실패 원인은 대수적 조작 오류, 추상적인 개념을 정확하게 수학적 식으로 전환하는 난이도 및 관련 도메인 특정 개념을 검색하는 데 실패하는 것이었다.

###### StrAE: Autoencoding for Pre-Trained Embeddings using Explicit Structure (https://aclanthology.org/2023.emnlp-main.469/)
- Anthology ID: 2023.emnlp-main.469 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 explicit structure을 엄격하게 따르고 tree-structured 표현에서 새로운 contrastive objective를 사용하여 multi-level representations을 효과적으로 학습하는 StrAE (Structured Autoencoder) framework을 제안한다.
    2. 다양한 형태의 구조에 대한 비교를 통해, 결과가 입력된 구조의 정보성(informativeness)에 직접적으로 기인함을 확인하고, 기존의 트리 모델의 경우 이러한 사실이 아니라는 것을 보여준다.
    3. StrAE를 개선하여 모델이 간단한 지역 병합 알고리즘을 사용하여 자체 구성 정의할 수 있도록 확장한 Self-StrAE는 명시적인 계층 구조와 유사한 성능을 보이고, explicit hierarchical compositions와 관련이 없는 기준선들보다 우수한 성능을 보인다.

###### WiCE: Real-World Entailment for Claims in Wikipedia (https://aclanthology.org/2023.emnlp-main.470/)
- Anthology ID: 2023.emnlp-main.470 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 파트-문장(support) 단위로 이루어진 fine-grained 텍스트 entailment 데이터셋인 WiCE를 제안하였다. GPT-3.5를 사용하여 claim을 아래 파트-문장으로 자동 분해하는 전략을 제안하고, 해당 전략이 다른 데이터셋에서도 entailment 모델의 성능을 향상시키는 것을 보였다.
    2. 기존 entailment 데이터셋으로부터 추출한 자연스러운 claim과 evidence 쌍을 사용하여 WiCE 데이터셋을 구축하였다.
    3. WiCE 데이터셋에 있는 진짜 claim들은 기존 모델이 다루기 어려운 검증 및 검색 문제를 포함하고 있음을 보였다.

###### Natural Disaster Tweets Classification Using Multimodal Data (https://aclanthology.org/2023.emnlp-main.471/)
- Anthology ID: 2023.emnlp-main.471 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 소셜 미디어 플랫폼은 의견 표명이나 정보 전달에 널리 이용되며, 재난 관련 작업에도 사용될 수 있다. 그러나 기존의 작업은 이미지나 텍스트와 같은 단일 모달리티에만 초점을 맞춘 것이 일반적이다. 
    2. 본 논문에서는 다중 모달 데이터셋을 다룰 수 있는 시스템을 개발하기 위해 다양한 모델을 탐구한다. 
    3. 다중 모달 트윗을 분류하는데 우수한 계산 효율성과 평가 성능을 가진 시스템을 개발하여 재난 관리를 지원하고 인도주의적 재앙의 상황을 파악하고 피해의 심각성과 유형을 평가하는 것을 목표로 한다.

###### On the Challenges of Using Black-Box APIs for Toxicity Evaluation in Research (https://aclanthology.org/2023.emnlp-main.472/)
- Anthology ID: 2023.emnlp-main.472 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 독성에 대한 인식은 시간이 지남에 따라 변화하며 지리 및 문화적 배경에 따라 다를 수 있다. 따라서 Perspective API와 같은 상용 블랙박스 독성 감지 API는 정적이 아니라 지속적으로 리트레이닝되어 약점과 바이어스를 해결한다.
    2. 이 논문에서는 독성을 억제하는 모델과 방법을 비교하는 연구 결과의 재현 가능성에 대한 영향을 평가한다. 논문은 상속된 자동 독성 점수에 의존한 연구는 부정확한 결과로 이어질 수 있다는 결과를 제시한다.
    3. Perspective API의 최신 버전으로 HELM의 모든 모델을 독성에 대해 점수를 다시 매기면 널리 사용되는 기반 모델들의 순위가 달라지는 것을 밝혀냈다. 연구들 간에 사과-사과 비교를 적용할 때 주의가 필요하며, 시간이 지남에 따른 독성 평가에 더 구조적인 접근이 필요하다는 주장이다.

###### RoBoCoP: A Comprehensive ROmance BOrrowing COgnate Package and Benchmark for Multilingual Cognate Identification (https://aclanthology.org/2023.emnlp-main.473/)
- Anthology ID: 2023.emnlp-main.473 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 고유어의 식별은 역사 언어학에서 기반적인 과정이며, 추가 연구의 기반이 된다. 로망스 언어를 위한 여러 cognate 데이터베이스가 있지만, 그들은 흩어져 있거나 불완전하며, 불확실한 정보를 가지고 있거나 가용성이 불확실하다.
    2. 본 논문에서는 로망스 언어의 고유어와 차용어에 기반한 포괄적인 데이터베이스를 제안한다. 우리는 루마니아어, 이탈리아어, 스페인어, 포르투갈어, 프랑스어의 전자 사전을 구문 분석하여 어떤 두 개의 로망스 언어 간에 고유어 쌍을 추출한다.
    3. 이 자원을 기반으로 우리는 머신러닝과 딥러닝 기반 방법을 적용하여 로망스 언어의 어떤 두 쌍에 대해서도 고유어를 자동으로 감지하는 강력한 벤치마크를 제안한다. 우리는 고유어의 자동 식별이 어려운 과제에 대해서 약 94% 정확도로 가능하다는 것을 발견했다.

###### Instructive Dialogue Summarization with Query Aggregations (https://aclanthology.org/2023.emnlp-main.474/)
- Anthology ID: 2023.emnlp-main.474 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존 대화 요약 방법들은 사용자의 특정 관심사를 고려하지 않고 요약을 생성하는데, 이는 사용자가 특정 주제나 측면에 집중하는 경우에 문제가 될 수 있다. 
    2. 이 논문에서는 instruction-finetuned 언어 모델의 발전을 통해 요약 방법을 향상시키기 위해 instruction-tuning을 대화에 도입하는 방법을 제안한다. 
    3. 실험 결과는 우리의 모델이 기존의 성능 경쟁 모델을 능가하며, 더 큰 모델보다도 좋은 통사성과 일반화 능력을 가진다는 것을 보여준다.

###### Semantic matching for text classification with complex class descriptions (https://aclanthology.org/2023.emnlp-main.475/)
- Anthology ID: 2023.emnlp-main.475 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 텍스트 분류기를 새로운 클래스에 적응시키는 것은 비용이 많이 드는 작업이다. 이전 연구들은 기존 클래스의 클래스 설명이나 라벨을 활용하여 이 문제를 해결해왔으나, 부족한 점이 여전히 존재한다.
    2. 이 논문은 텍스트 분류를 매칭 문제로 바라보고, 모델이 관련된 클래스 설명과 예제를 매칭시키는 방식으로 새로운 클래스에 대한 zero-shot과 few-shot 학습을 수행하는 방법을 제안한다.
    3. 실험 결과, 이 접근 방법은 복잡한 클래스 설명을 가진 텍스트 분류 작업에서 강력한 zero-shot 성능과 few-shot 샘플에 대한 확장성을 보여주며, 강력한 베이스라인 모델을 10-shot 설정에서 22.48% (평균 정밀도) 능가한다. 또한, Model-Agnostic Meta-Learning (MAML) 알고리즘을 zero-shot 매칭 설정으로 확장하여 zero-shot 성능을 4.29% 향상시킨다.

###### MADNet: Maximizing Addressee Deduction Expectation for Multi-Party Conversation Generation (https://aclanthology.org/2023.emnlp-main.476/)
- Anthology ID: 2023.emnlp-main.476 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다자간 대화(MPC)를 그래프 신경망을 사용하여 모델링하는 기존 방법은 대상자 레이블에 강한 의존성이 있으며, 각 발언이 반드시 "@" 또는 동등한 대상자 레이블과 함께 표시되어야 하는 이상적인 상황에만 적용할 수 있다.
    2. 우리는 MPC에서 흔한 대상자 레이블의 부족이라는 문제를 연구하기 위해, MPC 생성을 위한 이질적 그래프 신경망에서 대상자 연역 기대값을 극대화하는 MADNet을 제안한다.
    3. 실험 결과, 우분투 IRC 채널 벤치마크에서 MADNet이 MPC 생성 과제에서 다양한 기준선 모델보다 더 좋은 성능을 보여주며, 특히 일부 대상자 레이블이 누락된 더 일반적이고 어려운 설정에서 유용하게 사용됨을 보여준다.

###### GLEN: Generative Retrieval via Lexical Index Learning (https://aclanthology.org/2023.emnlp-main.477/)
- Anthology ID: 2023.emnlp-main.477 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Generative retrieval은 질의에 관련된 문서의 식별자를 직접 생성하는 문서 검색의 새로운 패러다임을 제시하며, 보조 색인 구조를 구축하지 않으면서 이점을 취한다."
    2. 기존 연구는 사전 훈련된 언어 모델과 식별자의 지식 간의 불일치와 학습과 추론 간의 차이라는 두 가지 주요 도전에 직면한다.
    3. 새로운 generative retrieval 방법인 GLEN은 동적 어휘 식별자를 효과적으로 활용하여 의미 있는 어휘 식별자와 질의와 문서 간의 관련 신호를 학습하고, 증가하지 않는 추가적인 오버헤드 없이 문서를 순위 매기는 데 식별자 가중치를 사용하는 충돌 방지 추론을 활용한다. NQ320k, MS MARCO 및 BEIR와 같은 다양한 기준 데이터셋에서 GLEN이 기존 generative retrieval 방법에 비해 최고 수준 또는 경쟁력 있는 성능을 달성하는 것을 실험 결과로 증명하였다.

###### Turn-Level Active Learning for Dialogue State Tracking (https://aclanthology.org/2023.emnlp-main.478/)
- Anthology ID: 2023.emnlp-main.478 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화 상태 추적(DST)은 과제 지향 대화 시스템에서 중요한 역할을 한다. 그러나 turn-by-turn으로 주석이 달린 대화 데이터를 수집하는 것은 비용이 많이 들고 비효율적이다. 
    2. 이 논문에서는 DST를 위한 새로운 turn-level active learning 프레임워크를 제안하여 주석을 달기 위해 대화에서 턴을 선택한다. 
    3. 제한된 레이블 예산을 고려한 실험 결과, 대화 턴의 선택적 주석이 효과적임을 보여준다. 또한, 우리의 접근 방식은 훨씬 적은 주석 데이터로 전통적인 훈련 접근 방식과 비교할 수 있는 DST 성능을 효과적으로 달성하며, 새로운 대화 데이터에 주석을 달기 위한 보다 효율적인 방법을 제공한다.

###### ReSee: Responding through Seeing Fine-grained Visual Knowledge in Open-domain Dialogue (https://aclanthology.org/2023.emnlp-main.479/)
- Anthology ID: 2023.emnlp-main.479 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 텍스트 기반 대화 시스템에 시각적 지식을 포함하는 것은 인간의 사고, 상상, 의사 소통 방식을 모방하는 잠재적인 방향이 되었다. 
    2. 그러나 기존의 다중모달 대화 시스템은 제한된 데이터셋의 규모와 품질 또는 시각적 지식의 대략적인 개념에 제한된다.
    3. 이 논문에서는 시각적 지식을 "턴-레벨"과 "개체-레벨"로 더 잘게 분리하고, 인터넷이나 대규모 이미지 데이터셋에서 향상된 시각 정보를 검색하여 정확성과 다양성을 높이는 새로운 패러다임을 제안한다.

###### Modeling Conceptual Attribute Likeness and Domain Inconsistency for Metaphor Detection (https://aclanthology.org/2023.emnlp-main.480/)
- Anthology ID: 2023.emnlp-main.480 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 유사한 속성의 공유가 메타포 표현에서 암시적 의미를 유추하는 데 중요하다는 것에 기반하여 메타포 탐지를 위한 Attribute Likeness and Domain Inconsistency Learning (AIDIL) 프레임워크를 제안한다.
    2. 속성 계층 구조 네트워크를 활용하여 원본과 대사 개념 사이의 유사한 속성을 찾고, 도메인 대조 학습 전략을 통해 원본과 대사 도메인의 의미적 불일치를 학습한다.
    3. 네 개의 데이터셋을 사용한 실험 결과, 제안하는 방법이 이전 최첨단 방법보다 우수한 성능을 보이며, 일반화 능력을 입증한다.

###### Referring Image Segmentation via Joint Mask Contextual Embedding Learning and Progressive Alignment Network (https://aclanthology.org/2023.emnlp-main.481/)
- Anthology ID: 2023.emnlp-main.481 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1.   referring image segmentation은 자연어 표현에 해당하는 이미지의 객체에 대한 픽셀 단위 마스크를 예측하는 작업이다. 기존의 cascade framework를 사용한 방법에서는 복잡한 문제를 여러 단계로 나누어 처리하지만, 특정 단계에서 가장 관련성이 높은 정보에 집중하며 이른 단계에서 전파된 오류를 수정하는 과제를 해결하지 못하는 한계가 있다.
    2. 이 논문에서는 JMCELN을 제안하였는데, 이는 Learnable Contextual Embedding과 Progressive Alignment Network (PAN)을 통합하여 Cascade Framework를 강화한 것이다. Learnable Contextual Embedding 모듈은 현재 마스크 예측 결과를 기반으로 추론 정보를 동적으로 저장하고 활용하여 더 나은 마스크 예측 정확도를 위해 관련 정보를 적응적으로 잡아내고 개선한다.
    3. 또한, Progressive Alignment Network (PAN)은 JMCELN의 핵심 부분으로 도입되었는데, 이는 이전 레이어의 출력을 현재 출력의 필터로 사용하여 서로 다른 단계에서의 예측 차이를 줄이는 역할을 한다. PAN은 예측을 반복적으로 정렬함으로써 Learnable Contextual Embedding이 추론에 더 구별력 있는 정보를 통합하도록 안내하여 예측 품질을 향상시키고 오류 전파를 줄인다.

###### Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study (https://aclanthology.org/2023.emnlp-main.482/)
- Anthology ID: 2023.emnlp-main.482 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 큰 디코더만 있는 언어 모델은 RETRO와 같은 retrieval을 사용하여 perplexity 면에서 크게 향상될 수 있으나, 텍스트 생성 품질과 downstream task 정확성에 대한 영향은 불분명하다. 
    2. 이 연구에서는 RETRO와 일반 GPT, 검색 향상 GPT를 fine-tuning 또는 inference 단계에서 비교하여 포괄적인 연구를 수행하였으며, 다음과 같은 새로운 결과를 얻었다. 
    3. RETRO는 degeneration (반복)이 훨씬 적고 신뢰할만한 데이터베이스를 사용할 경우에는 독성이 약간 낮으면서 사실적인 정확성이 더 높으며, 지식-집중적인 작업에서 GPT보다 우월한 결과를 보여준다.

###### SCITAB: A Challenging Benchmark for Compositional Reasoning and Claim Verification on Scientific Tables (https://aclanthology.org/2023.emnlp-main.483/)
- Anthology ID: 2023.emnlp-main.483 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 과학적 사실 검증 벤치마크는 크라우드소싱된 주장으로 인한 편향과 텍스트 기반 증거에 대한 지나친 의존 등의 문제점이 있다. 
    2. 이 연구에서는 진짜 과학 논문에서 왔으며, 구성적 추론이 필요한 1.2K개의 전문가 검증된 과학적 주장과 증거를 포함하는 과학적 테이블로 구성된 SCITAB라는 도전적인 평가 데이터셋을 제시한다.
    3. 우리의 분석은 테이블의 기반, 주장의 모호성 및 구성적 추론과 같은 SCITAB에 의해 제기된 독특한 문제들을 밝혀냈다.

###### Training Simultaneous Speech Translation with Robust and Random Wait-k-Tokens Strategy (https://aclanthology.org/2023.emnlp-main.484/)
- Anthology ID: 2023.emnlp-main.484 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 로우 레이턴시 상황에서 말 번역의 고품질 번역을 보장하기 위한 simultaneous speech translation (SimulST)은 오디오와 텍스트 간의 모달리티 차이로 인해 어려움을 겪고 있다.
    2. 이 논문에서는 Modality 간의 차이를 해결하기 위해 Montreal Forced Aligner (MFA)를 활용하여 acoustic encoder의 사전 학습을 하고, token-level 크로스-모달 정렬을 통해 SimulMT의 wait-k 정책이 SimulST에 적합하게 적응할 수 있도록 한다.
    3. 논문에서 제안하는 robust and random wait-k-tokens 전략을 사용하여, 단일 모델이 다양한 레이턴시 요구에 부합하고 추론 중에 발생하는 경계 정렬의 오류 누적을 최소화할 수 있는 것으로 실험 결과를 보여준다.

###### SCENE: Self-Labeled Counterfactuals for Extrapolating to Negative Examples (https://aclanthology.org/2023.emnlp-main.485/)
- Anthology ID: 2023.emnlp-main.485 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 부정 사례 (예를들어 부언 관계, 답을 할 수 없는 질문, 거짓된 주장 등)를 탐지하는 것은 많은 자연어 이해 문제에서 중요하고 어려운 측면이다. 그러나 도메인 특정성과 비용 문제로 인해 도전적인 부정 사례를 수동으로 수집하는 것은 어렵고 비용이 많이 든다. 이 논문에서는 SCENE(Self-labeled Counterfactuals for Extrapolating to Negative Examples)라는 자동 방법을 제안하여 모델이 도전적인 부정 사례를 감지하는 능력을 크게 향상시키는 훈련 데이터를 합성한다.
    2. 기존의 데이터 증강은 기존의 레이블에 대해 새로운 예제를 합성하지만, SCENE은 양성 예제만으로부터 부정 예제를 생성할 수 있다. SCENE은 양성 예제를 마스킹 인풀링 모델로 변형한 후, 자체 학습 휴리스틱에 따라 결과 예제가 부정인지 여부를 판단한다.
    3. SCENE은 답변 가능한 훈련 예제에만 접근하여 SQuAD 2.0와 같은 데이터셋에서 모델의 성능 차이 69.6%를 닫을 수 있으며, boolean 질문 응답과 텍스트 함의 인식으로 확장될 수 있으며, SQuAD에서 ACE-whQA로의 일반화를 향상시킨다.

###### Enhancing Code-Switching for Cross-lingual SLU: A Unified View of Semantic and Grammatical Coherence (https://aclanthology.org/2023.emnlp-main.486/)
- Anthology ID: 2023.emnlp-main.486 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 고-리소스 언어에서의 언어 이해(SLU)의 성공에도 불구하고, zero-shot 상황과 같은 저-리소스 환경에서 유사한 성능을 달성하는 것은 제한된 레이블된 훈련 데이터 때문에 현실적인 어려움이 남아있다.
    2. 우리는 zero-shot 크로스-언어 SLU를 향상시키기 위해 최근에 나온 방법들을 다루고 있으며, 고려하지 못한 토큰 수준의 의존성과 문맥 유사성을 고려한 새로운 메소드인 SoGo를 제안한다.
    3. 실험과 분석을 통해 SoGo가 MultiATIS++의 9개 언어에서 우수한 성능을 보인다는 것을 확인했다.

###### Task-Agnostic Low-Rank Adapters for Unseen English Dialects (https://aclanthology.org/2023.emnlp-main.487/)
- Anthology ID: 2023.emnlp-main.487 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델 (LLM)은 표준 미국 영어를 우위에 두고 균형이 맞지 않는 말뭉치로 훈련되었다. 그 결과, 다른 방언의 사용자는 이러한 기술과 상호 작용할 때 더 많은 실패를 경험한다. 이 연구는 언어 기술이 다양한 영어 방언을 수용하도록 설계되어야 하며 그 반대로 되어서는 안된다는 믿음을 공유한다.
    2. 기존의 방언 연구는 발전하고 새로운 방언들에 대해서 일관되게 확장할 수 있는 방법이 없다. 따라서 이 논문은 HyperLoRA라는 방법을 제안한다.
    3. HyperLoRA는 전문 언어학적 지식을 활용하여 하이퍼네트워크를 통해 리소스 효율적인 적응을 가능하게 한다. 방언별와 방언 간의 정보를 분리함으로써 HyperLoRA는 과제에 대한 일반화 능력을 향상시키고, 더 많은 파라미터 수에 대해 확장성이 높으며, 예측치가 없는 방언의 성능에서 가장 우수하거나 경쟁력 있는 성과를 달성한다.

###### Federated Learning of Large Language Models with Parameter-Efficient Prompt Tuning and Adaptive Optimization (https://aclanthology.org/2023.emnlp-main.488/)
- Anthology ID: 2023.emnlp-main.488 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Federation learning (FL)은 분산 데이터로 협업하는 모델 훈련을 가능하게 하는 유망한 패러다임이지만, 대규모 언어 모델의 훈련 과정은 주요 파라미터의 업데이트를 필요로 하므로 실제 상황에서 LLMs를 다루기 위한 FL 기술의 적용이 제한되고 있다. 
    2. 이 논문에서는 FedPepTAO라는 효율적이고 효과적인 FL을 위한 Parameter-efficient prompt Tuning 접근 방식을 제안한다. 
    3. Partial prompt tuning 및 adaptive optimization 기법을 통해 속도와 성능을 개선하고 비독립, 동일 분포가 아닌 분산 데이터로 발생하는 클라이언트 drift 문제를 해결한다.

###### TheoremQA: A Theorem-driven Question Answering Dataset (https://aclanthology.org/2023.emnlp-main.489/)
- Anthology ID: 2023.emnlp-main.489 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. GPT-4와 PaLM-2와 같은 최근의 LLMs는 GSM8K와 같은 기본 수학 문제를 90% 이상의 정확도로 해결하는 데 엄청난 발전을 이루었지만, 수학적 정리를 필요로 하는 더 어려운 수학 문제를 해결하는 능력은 아직 조사되지 않았다.
    2. 이 논문에서는 AI 모델이 과학 문제를 해결하기 위해 정리를 적용하는 능력을 평가하기 위해 설계된 첫 번째 정리 기반 질문-응답 데이터 세트인 TheoremQA를 소개한다.
    3. TheoremQA는 전문가들에 의해 담당 분야인 수학, 물리학, 전기 및 컴퓨터 공학, 금융에서 350개의 정리를 다루는 800개의 고품질 문제를 포함하고 있으며, 다양한 프롬프팅 전략(Chain-of-Thoughts, Program-of-Thoughts 등)으로 16개의 대형 언어 및 코드 모델의 평가를 수행하였다.

###### Scalable-DSC: A Structural Template Prompt Approach to Scalable Dialogue State Correction (https://aclanthology.org/2023.emnlp-main.490/)
- Anthology ID: 2023.emnlp-main.490 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Dialogue state error correction"은 대화 상태 추적(DST)의 오류 전파 문제를 완화하기 위해 제안된 방법인데, 이러한 접근 방식은 특정 DST 모델과 강하게 얽혀 있어 다른 DST 모델에 적용하기가 제한된다.
    2. 이를 해결하기 위해, 우리는 Scalable-DSC라는 방법을 제안하는데, 이는 잘못된 슬롯 값들을 어떤 DST 모델이 예측한 대화 상태에서 수정할 수 있다.
    3. 이를 위해 우리는 Structural Template Prompt (STP)를 제안하고, 미리 정의된 템플릿 옵션을 기반으로 정규화된 자연어 시퀀스로 예측된 대화 상태를 변환하여 수정된 대화 상태 시퀀스를 생성한다. 이러한 방법을 통해 우리의 모델은 MultiWOZ 2.0-2.4에서 최고의 결과를 얻었다.

###### Don’t Trust ChatGPT when your Question is not in English: A Study of Multilingual Abilities and Types of LLMs (https://aclanthology.org/2023.emnlp-main.491/)
- Anthology ID: 2023.emnlp-main.491 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델은 다양한 자연어 처리 (NLP) 태스크에서 뛰어난 자연어 이해 능력을 보여주었으며, 여러 언어에서의 능력도 입증되었다. 그러나 LLM의 다중 언어 능력 획득 방법과 언어별 성능의 차이에 대한 기본적인 질문들은 여전히 존재한다.
    2. 이 논문에서는 LLM의 다중 언어 능력을 질적과 양적 방식으로 평가하기 위한 체계적인 방법을 제안한다. 실험 결과는 GPT와 같은 LLM들이 다양한 언어 간에 배운 지식을 효과적으로 전달할 수 있으며, 번역 불변 (translation-equivariant) 태스크에서 일관된 결과를 보여준다는 것을 입증하였다. 
    3. 그러나 번역 변동 (translation-variant) 태스크에서 정확한 결과를 제공하기 어려우며, 이러한 경우 사용자의 신중한 판단이 요구된다.

###### M3Seg: A Maximum-Minimum Mutual Information Paradigm for Unsupervised Topic Segmentation in ASR Transcripts (https://aclanthology.org/2023.emnlp-main.492/)
- Anthology ID: 2023.emnlp-main.492 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 주제 분할(M3Seg)은 주제 경계를 탐지하고, 자동 음성 인식 변환(transcriptions)을 주제 의미에 의해 제한된 세그먼트로 분할한다. 
    2. 이 논문에서는 M3Seg라는 새로운 Maximum-Minimum Mutual information 패러다임을 제안하며, 양방향 데이터를 사용하지 않고 선형 주제 분할 수행한다.
    3. 실험 결과는 M3Seg의 효과를 입증하며, 다른 최신 방법보다 상당한 개선(18%-37%)을 보인다.

###### Empirical Study of Zero-Shot NER with ChatGPT (https://aclanthology.org/2023.emnlp-main.493/)
- Anthology ID: 2023.emnlp-main.493 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "이 논문은 ChatGPT와 명명된 entity 인식(NER) 태스크에 대한 zero-shot 정보 추출에서 LLM의 성능을 탐구한다. 논문에서는 LLM의 주목할만한 추론 능력에서 영감을 받아 NER에 맞게 맞춤형 추론 전략을 제안한다."
    2. "논문에서는 NER 태스크를 레이블별로 간단한 하위 문제로 분해하는 분해형 질문-응답 패러다임과, 구문적 augmentation을 제안한다. 제안된 메서드는 zero-shot NER에서 중요한 개선을 이루며, 중국어와 영어 데이터셋, 특정 도메인과 일반 도메인 시나리오를 포함한 7개의 벤치마크에서 효과적으로 작동한다."
    3. "또한 논문은 오류 유형에 대한 포괄적인 분석과 최적화 방향에 대한 제안을 제시하며, few-shot 환경과 다른 LLMs에서도 제안된 방법의 효과를 검증한다."

###### Automatic Prompt Optimization with “Gradient Descent” and Beam Search (https://aclanthology.org/2023.emnlp-main.494/)
- Anthology ID: 2023.emnlp-main.494 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델은 일반적인 목적의 에이전트로서 놀라운 성능을 보여주었지만, 그 성능은 번거로운 시행착오 노력을 통해 수작업으로 작성된 프롬프트에 매우 의존적이다.
    2. 우리는 ProTeGi라는 간단하고 비매개 변수적인 솔루션을 제안하여 이 문제를 해결한다. 이 알고리즘은 LLM API와 학습 데이터에 접근 가능한 것을 전제로 하여 프롬프트를 자동으로 개선하는데, 훈련 데이터를 미니배치로 사용하여 현재 프롬프트에 비판을 표현하는 자연어 "기울기"를 생성한다.
    3. 프롬프트의 개선은 그래디언트 강하 방법을 따르며, 빔 서치와 밴딧 선택 프로세스에 의해 안내된다. 이를 통해 ProTeGi 알고리즘은 기존의 프롬프트 편집 기법보다 우수한 성능을 보여주며, 데이터를 사용하여 모호한 작업 설명을 보다 정확한 주석 지침으로 재작성하여 초기 프롬프트의 성능을 최대 31% 개선할 수 있다.

###### Active Retrieval Augmented Generation (https://aclanthology.org/2023.emnlp-main.495/)
- Anthology ID: 2023.emnlp-main.495 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 큰 언어 모델은 언어를 이해하고 생성하는 능력이 뛰어나지만, 사실적이지 않은 결과물을 만들어내거나 환각을 일으킬 가능성이 있다. 
    2. 외부 지식 자원에서 정보를 검색하여 언어 모델을 보강하는 방법이 있는데, 이 논문에서는 지속적으로 정보를 수집하는 일반적인 시나리오에서 활용 가능한 메서드를 제안한다. 
    3. 제안된 FLARE 방법은 다음 문장의 예측을 사용하여 미래 내용을 예측하고, 이를 쿼리로 사용하여 신뢰도가 낮은 토큰을 포함하는 문장을 대체하기 위해 관련 문서를 검색한다. FLARE은 4개의 장문 기반 지식 생성 작업/데이터셋에서 우수한 결과를 보여주며, 우리 방법의 효과를 입증한다.

###### GD-COMET: A Geo-Diverse Commonsense Inference Model (https://aclanthology.org/2023.emnlp-main.496/)
- Anthology ID: 2023.emnlp-main.496 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. AI 시스템이 다양한 배경의 사용자를 위해 문화적으로 인식하도록 설계하는 것이 중요해지고 있다. 
    2. 이 논문에서는 GD-COMET이라는 지리적으로 다양한 문화를 고려한 공통 감각 추론 모델을 제안한다. 
    3. GD-COMET은 다양한 문화에 관련된 추론을 생성할 수 있으며, 인간 평가와 임무 평가를 통해 효과적임을 입증하고 있다.

###### Multi-level Adaptive Contrastive Learning for Knowledge Internalization in Dialogue Generation (https://aclanthology.org/2023.emnlp-main.497/)
- Anthology ID: 2023.emnlp-main.497 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "지식 기반 대화 생성은 외부 지식을 활용하여 문맥을 보완함으로써 텍스트 쇠퇴 문제를 완화하는 것을 목표로 한다. 그러나 모델은 종종 이러한 정보를 인간과 같은 방식으로 응답에 내재시키는 데 실패한다."
    2. "복사 스타일의 쇠퇴는 모델이 지식 세그먼트를 단순히 일반적인 응답에 삽입하기 때문에 발생하며, 이로 인해 생성된 응답은 지루하고 일관성이 없으며 상호 작용이 부족하다."
    3. "이 논문에서는 약한 가능성 목적의 주된 원인으로서의 복사 스타일의 쇠퇴를 파악하고, MACL (Multi-level Adaptive Contrastive Learning) 프레임워크를 제안하여 토큰 수준과 시퀀스 수준에서 쇠퇴 행동을 패널티로 부과하는 동적으로 부정적인 예시를 샘플링한다."

###### Enhancing Biomedical Lay Summarisation with External Knowledge Graphs (https://aclanthology.org/2023.emnlp-main.498/)
- Anthology ID: 2023.emnlp-main.498 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이전의 자동 요약 접근법들은 기술적인 독자를 위해 작성된 출처 기사에 완전히 의존하며, 모든 기술적 개념을 명시적으로 정의하거나 일반인 대상의 필요한 배경 정보를 모두 제공하지는 않는다.
    2. 우리는 바이오의학 요약 데이터셋인 eLife를 article-specific knowledge graph로 보강함으로써 이 문제를 해결한다.
    3. 우리의 결과는 그래프 기반의 도메인 지식을 통합하는 것이 요약 문장의 가독성을 크게 향상시키고 기술적 개념의 설명을 개선하여 요약에 상당한 이점을 제공할 수 있다는 것을 확인한다.

###### A Diffusion Weighted Graph Framework for New Intent Discovery (https://aclanthology.org/2023.emnlp-main.499/)
- Anthology ID: 2023.emnlp-main.499 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "새로운 의도 발견 (NID)은 알려진 의도와 함께 라벨이 없는 데이터에서 새로운 의도를 인식하는 것을 목표로 한다. 하지만 기존 방법들은 샘플들 간의 구조적 관계를 고려하지 않고 있어서, 품질과 수량 사이의 균형을 이루지 못하게 되어 새로운 의도 클러스터의 형성과 사전 학습 지식의 효과적인 전달을 방해한다."
    2. "우리는 데이터에 내재된 의미적 유사성과 구조적 관계를 포착하기 위해 새롭게 Diffusion Weighted Graph Framework (DWGF)을 제안한다. 이를 통해 더 충분하고 신뢰성 있는 지도 신호를 생성할 수 있다."
    3. "실험 결과, 우리의 방법은 여러 벤치마크 데이터셋에서 모든 평가 메트릭을 기준으로 최신 모델을 능가하는 것을 확인했다. 코드와 데이터는 공개될 예정이다."

###### A Self-enhancement Multitask Framework for Unsupervised Aspect Category Detection (https://aclanthology.org/2023.emnlp-main.500/)
- Anthology ID: 2023.emnlp-main.500 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 작은 seed words 집합을 사용하여 비지도 Aspect Category Detection 문제를 해결하려는 연구이다. seed words와 문장 사이의 유사성을 활용하여 aspect를 학습하는 방식이 최근 많이 연구되었으나, seed words의 품질에 제약을 받아 모델 성능이 저하되는 문제가 있다.
    2. 이를 해결하기 위해 저자들은 initial seed words의 품질을 자동적으로 향상시키고, 전체 데이터셋을 사용하는 대신 고품질의 문장을 자동 선택하는 간단한 프레임워크를 제안한다.
    3. 또한, Aspect Term Extraction과 Aspect Term Polarity를 동시에 학습하여 성능을 향상시키려고 한다. 실험 결과 제안한 프레임워크가 표준 데이터셋에서 강력한 기준에 비해 우수한 성능을 보여주었다.

###### DialCoT Meets PPO: Decomposing and Exploring Reasoning Paths in Smaller Language Models (https://aclanthology.org/2023.emnlp-main.501/)
- Anthology ID: 2023.emnlp-main.501 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Chain-of-Thought (CoT) prompting은 1000억개 이상의 매개변수를 가지는 모델들의 추론 능력을 향상시키는 데 성공했으나, 10억개 미만의 작은 언어 모델(SLMs)에서는 추론 과제의 성능에 소용이 없거나 오히려 해로웠다. 
    2. 이 논문에서는 작은 언어 모델(SLMs)의 추론 능력을 향상시키기 위해 대화 형식으로 중간 추론 단계를 생성하여 최종 답안을 안내하는 Dialogue-guided Chain-of-Thought (DialCoT)를 제안한다. 또한 Proximal Policy Optimization (PPO) 알고리즘을 통해 모델이 최적의 추론 경로를 선택하도록 최적화하여 추론 능력을 더욱 향상시킨다. 
    3. 4개의 산술 추론 데이터셋에서의 포괄적인 실험 결과, 우리의 방법은 최신 경쟁 모델들과 비교하여 상당한 성능 향상을 달성할 수 있음을 보여준다.

###### Recurrent Neural Language Models as Probabilistic Finite-state Automata (https://aclanthology.org/2023.emnlp-main.502/)
- Anthology ID: 2023.emnlp-main.502 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이전 연구들은 RNN 언어 모델의 표현 능력을 이해하기 위해 가중치가 없는 형식 언어를 인식하는 능력을 조사해왔다. 그러나 RNN 언어 모델은 가중치가 없는 형식 언어를 설명하지 않는다. 이 연구에서는 RNN 언어 모델이 표현할 수 있는 확률 분포의 클래스를 조사하여 그 능력을 직접적으로 이해할 수 있는 문장을 제시한다. 
    2. 연구 결과, 간단한 RNN은 확률 유한 상태 오토마타(probabilistic finite-state automata)의 하위 클래스와 동등하며, 이는 유한 상태 모델로 표현 가능한 확률 분포의 엄격한 부분집합을 모델링할 수 있다는 것을 보여준다.
    3. 또한, RNN을 사용하여 임의의 결정적 유한 상태 언어 모델을 표현하기 위해 𝛺\left(N |𝛴|\right) 개의 뉴런이 필요하다는 것을 보여준다. 이러한 결과는 RNN 언어 모델이 표현할 수 있는 확률 분포의 클래스를 특성화하는 첫 번째 단계로서, 그 능력과 제한을 이해하는 데 도움을 준다.

###### Revisiting Source Context in Nearest Neighbor Machine Translation (https://aclanthology.org/2023.emnlp-main.503/)
- Anthology ID: 2023.emnlp-main.503 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Nearest neighbor machine translation (kNN-MT)는 추가 예제로부터 유도된 추정치와 대상 토큰 확률을 보간하여 상당한 성능 향상을 이루어낸다" 하지만, 기존 연구는 유사한 예제를 검색할 때 소스 컨텍스트를 명시적으로 고려하지 않아 최적의 성능을 얻지 못할 수 있다고 주장한다. 
    2. 이를 해결하기 위해 저자들은 소스 컨텍스트의 역할을 복원하고, 소스 컨텍스트 강화를 통해 신경 기계 번역의 성능을 향상시키는 간단하고 효과적인 방법을 제안하였다.
    3. 실험 결과, 제안된 방법은 대표적인 kNN-MT 기준선에 통합될 수 있으며, 다양한 설정 및 도메인에서 이러한 강력한 기준선 대비 상당한 성능 향상을 보여준다.

###### Find-2-Find: Multitask Learning for Anaphora Resolution and Object Localization (https://aclanthology.org/2023.emnlp-main.504/)
- Anthology ID: 2023.emnlp-main.504 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다양한 multimodal 이해 tasks 에서 시각적과 언어적 표현에 발생하는 모호성을 해결하기 위해, 이 논문에서는 시각과 언어 정보를 통합하는 novel한 end-to-end joint multitask 학습 프레임워크를 제안한다. 
    2. 이를 위해, Visual-linguistic Ambiguity를 해결하기 위한 Find2Find 데이터셋을 제작하였으며, 이 데이터셋을 활용한 실험결과는 기존의 단일태스크보다 많은 성능의 개선을 보여준다.
    3. 이 논문은 시각-언어 정합의 문제를 바라보는 새로운 시각에서 multimodal understanding의 연구를 진행하고 있다.

###### Background Summarization of Event Timelines (https://aclanthology.org/2023.emnlp-main.505/)
- Anthology ID: 2023.emnlp-main.505 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기사 작성자는 키 이벤트를 강조하기 위해 타임라인을 작성하지만, 이벤트에 대한 역사적 맥락을 모르는 사용자들은 따라가기 어렵다. 
    2. 이 논문에서는 background news summarization이라는 과제를 소개하여 각 타임라인 업데이트에 관련된 이전 이벤트의 요약을 보충한다. 
    3. Fine-tuned된 Flan-T5와 GPT-3.5를 사용하여 강력한 성능을 보이며, Question-Answering 기반의 Background Utility Score를 제안하여 배경 요약의 품질을 평가한다.

###### Superlim: A Swedish Language Understanding Evaluation Benchmark (https://aclanthology.org/2023.emnlp-main.506/)
- Anthology ID: 2023.emnlp-main.506 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Superlim은 스웨덴어 언어 모델의 성능을 평가하기 위한 다중 업무 NLP 벤치마크 및 분석 플랫폼이며, 그 결과를 이루는 데이터셋, 업무, 리더보드를 설명하고 참조 구현에서 얻은 기준 결과를 보고한다. 
    2. 테스트된 모델은 어떤 업무에서도 최고 성능을 보이지 않으며, 이는 Superlim이 실제로 어려운 벤치마크라는 것을 시사하며 이는 벤치마크에 대한 원하는 품질이다.
    3. 가장 적절한 측정 방법 선택, 데이터셋 문서화 및 리더보드의 편리성과 투명성을 고려하는 등, 작은 언어를 위한 데이터셋을 만들 때 클래스함에 대한 도전적인 문제를 다루고 있다.

###### Reasoning with Language Model is Planning with World Model (https://aclanthology.org/2023.emnlp-main.507/)
- Anthology ID: 2023.emnlp-main.507 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델(Large language models, LLMs)은 Chain-of-Thought 스타일의 텍스트에 대해서는 뛰어난 추론 능력을 보여주었으나, 실행 계획 생성, 복잡한 수학 및 논리 추론과 같은 인간에게 쉬운 문제에는 여전히 어려움이 있다.
    2. 이 논문에서는 LLM의 한계를 극복하기 위해 Reasoning via Planning (RAP)라는 새로운 추론 프레임워크를 제안한다. RAP은 LLM을 세계 모델 및 추론 에이전트로 다목적으로 활용하고 Monte Carlo Tree Search(MCTS) 기반의 계획 알고리즘을 도입하여 넓은 추론 공간에서 전략적 탐색을 수행한다.
    3. 실험 결과, RAP은 실행 계획 생성을 포함한 다양한 어려운 추론 문제에서 CoT와 self-consistency를 기반으로 한 강한 베이스라인보다 우수한 결과를 나타내었으며, 예를 들어 LLaMA-33B에서 RAP은 GPT-4의 CoT와 비교하여 실행 계획 생성에서 상대적인 개선률 33%를 달성했다.

###### LLM-enhanced Self-training for Cross-domain Constituency Parsing (https://aclanthology.org/2023.emnlp-main.508/)
- Anthology ID: 2023.emnlp-main.508 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Cross-domain constituency parsing에서 self-training이 성공적으로 적용된다는 것이 증명되었으며, 이 연구에서는 이를 개선하기 위해 큰 언어 모델(LLM)을 사용하여 domain-specific raw corpus를 반복적으로 생성하는 방법을 제안한다.
    2. 구문 분석을 위해 LLM을 이용한 self-training은 LLM의 성능에 상관없이 기존 방법보다 우수한 성능을 보인다고 입증되었다.
    3. 또한, grammar rules과 신뢰도 기준을 사용하여 pseudo 데이터를 선택하면 cross-domain constituency parsing에서 가장 뛰어난 성능을 보인다.

###### Continual Named Entity Recognition without Catastrophic Forgetting (https://aclanthology.org/2023.emnlp-main.509/)
- Anthology ID: 2023.emnlp-main.509 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. CNER에서는 기존 모델에 새로운 entity type을 순차적으로 통합하면서 모델을 업데이트하지만 catastrophic forgetting 문제가 심각하게 발생한다. 이 논문에서는 트레이드 오프를 잘 조정하는 pooled feature distillation loss를 도입하여 기존 entity type의 지식을 보존하면서 새로운 entity type을 효과적으로 습득하여 catastrophic forgetting 문제를 완화시킨다.
    2. 추가로, semantic shift 문제로 인해 이전 entity type이 비-엔티티 타입으로 통합되는데 이를 해결하기 위해 confidence-based pseudo-labeling을 제안한다. 또한, 편향된 타입 분포 문제를 해결하기 위해 adaptive re-weighting type-balanced learning 전략을 제안한다.
    3. 다양한 데이터셋을 이용한 실험을 통해 이 방법이 이전 최첨단 기법보다 우수한 성능을 보이며, Micro F1 점수와 Macro F1 점수에서 평균적으로 각각 6.3%와 8.0%의 개선을 보인다.

###### DSI++: Updating Transformer Memory with New Documents (https://aclanthology.org/2023.emnlp-main.510/)
- Anthology ID: 2023.emnlp-main.510 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다른 연구들이 성능이 좋은데도 불구하고, 시간과 함께 문서 집합이 변화하는 경우에 DSI 모델을 성공적으로 적용하는 것은 여전히 개방된 문제이다.
    2. 이 연구에서는 DSI++라는 지속적인 학습 도전 과제를 소개하며, 이는 이전과 새로 색인된 문서에 관련된 질의에 대답할 수 있으면서 동시에 새로운 문서를 계속해서 색인할 수 있는 DSI에 대한 것이다.
    3. 다양한 모델과 문서 식별자 표현에 걸쳐 지속적인 색인을 수행하면 이전에 색인된 문서를 상당히 잊어버리는 경우가 발생한다는 것을 보여주고, 이를 완화하기 위한 두 가지 접근 방식을 조사한다. 이로 인해 DSI++에서의 잊어버리기를 상당한 정도로 완화시키고 평균 Hits@10을 경쟁하는 기준에 비해 +21.1% 향상시킨다.

###### Editing Common Sense in Transformers (https://aclanthology.org/2023.emnlp-main.511/)
- Anthology ID: 2023.emnlp-main.511 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 트랜스포머의 파라미터를 직접 편집하는 것은 다시 학습하지 않고 오픈 소스 트랜스포머 기반 모델을 업데이트할 수 있게 한다.
    2. 기존의 편집 방법은 하나의 정답이 있는 백과사전적인 지식에 대한 문장에 대해만 평가되었다. 그러나 다중 정답을 갖는 상식적인 지식에 대한 연구는 수행되지 않았지만, 트랜스포머의 신뢰성과 유용성을 향상시키는 데 중요하다.
    3. 이 논문에서는 상식 판단이 트랜스포머 안의 특정 파라미터와 인과적으로 연관되어 있는지 조사하고, 그 결과 에디팅 알고리즘인 MEMITCSK를 개발하여 상식적인 도메인에서 성능을 향상시켰습니다.

###### Air-Decoding: Attribute Distribution Reconstruction for Decoding-Time Controllable Text Generation (https://aclanthology.org/2023.emnlp-main.512/)
- Anthology ID: 2023.emnlp-main.512 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. CTG(Controllable text generation)은 원하는 속성을 가진 텍스트를 생성하는 것을 목표로 하고 있으나, 이 논문에서는 Attribute Collapse 현상을 처음으로 발견하였다. 이는 제어 강도가 임계 값을 초과하면 생성된 텍스트의 유창성이 급격히 하락하여 완전히 사용할 수 없게 만든다.
    2. 이 문제를 해결하기 위해, 우리는 Air-Decoding이라는 새로운 경량 디코딩 프레임워크를 제안한다. 이는 속성 단어와 속성이 아닌 단어 간의 가중치를 균형있게 조정하여 더 유창한 텍스트를 생성하기 위해 속성 분포를 재구성하는 것이 주요 아이디어이다.
    3. 여러 가지 CTG 태스크에서의 실험을 통해 우리의 방법이 새로운 최고 성능을 달성한다는 것을 입증하였다.

###### Homophone Disambiguation Reveals Patterns of Context Mixing in Speech Transformers (https://aclanthology.org/2023.emnlp-main.513/)
- Anthology ID: 2023.emnlp-main.513 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 트랜스포머는 음성 처리에서 핵심 아키텍처이지만, 음향 및 언어 구조에 대한 표현 방식에 대한 이해가 제한적이다. 
    2. 이 연구에서는 텍스트 모델을 위해 개발된 '문맥 혼합' 측정 방법을 음성 언어 모델에 적용하는 방법에 대해 조사한다.
    3. 우리는 트랜스포머 기반 음성 모델에서 이러한 통사적 힌트에 주의를 기울여 동음이의어를 구분하고 문법적 일치를 고려하여 정확한 전사를 식별하는 것을 발견했다.

###### Retrieval-Generation Alignment for End-to-End Task-Oriented Dialogue System (https://aclanthology.org/2023.emnlp-main.514/)
- Anthology ID: 2023.emnlp-main.514 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 지식 베이스(KB)에서 지식을 검색하기 위한 효율적인 retriever 개발은 특화된 과제를 효과적으로 처리하기 위한 task-oriented 대화 시스템에 중요하다. 
    2. 기존의 generative 모델들은 KB에서 검색된 레코드들 사이의 미묘한 차이를 구별하기 어렵기 때문에 생성된 응답의 품질이 좋지 않은 문제가 있다.
    3. 이 논문에서는 최대 마진 우도를 활용하여 지각적인 retriever를 훈련시키는 방법을 제안하며, 응답 생성에서의 신호를 사용하여 훈련한다. 또한, retrieved entity뿐만 아니라 다양한 meta knowledge를 활용하여 generator를 안내함으로써 지식의 활용을 향상시킨다.

###### IfQA: A Dataset for Open-domain Question Answering under Counterfactual Presuppositions (https://aclanthology.org/2023.emnlp-main.515/)
- Anthology ID: 2023.emnlp-main.515 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. KT에서 발생한 알고리즘 결함으로 휴대폰 15만 대가 교환될 예정이다.
    2. KT가 JANUS, JOOM, 인터파크등의 패스트트랙 메뉴를 제거하면서 발생한 결함은 5월부터 지급 앱을 충분히 지원하지 않게 되었다.
    3. 그래서 앱의 결함으로 사용자에게 피해가 발생할 경우 해피콜 상품권으로 배상할 예정이다.

###### How Do Large Language Models Capture the Ever-changing World Knowledge? A Review of Recent Advances (https://aclanthology.org/2023.emnlp-main.516/)
- Anthology ID: 2023.emnlp-main.516 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 현재 시대에는 큰 언어 모델 (LLM)들이 다양한 과제를 해결하는 데에서 인상적이지만, 배포 후 빠르게 구식화될 수 있다. 이 논문은 기존의 LLM이 항상 변화하는 세계 지식과 일치하도록 조정하는 최근 연구 동향을 종합적으로 검토한다. 
    2. 우리는 연구 작업을 체계적으로 분류하고 깊이 있는 비교와 논의를 제공한다. 
    3. 또한, 존재하는 도전과제를 논의하고 이 분야의 연구를 촉진하기 위한 미래 방향을 강조한다.

###### PreWoMe: Exploiting Presuppositions as Working Memory for Long Form Question Answering (https://aclanthology.org/2023.emnlp-main.517/)
- Anthology ID: 2023.emnlp-main.517 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. LFQA(long-form question answering)에서 정보 탐색 질문은 불명확성이나 가정의 오류로 인해 잘못된 정보를 제공할 수 있다. 
    2. 이 논문에서는 모든 종류의 정보 탐색 질문을 처리할 수 있는 통합된 방법 PreWoMe를 제안한다. 
    3. PreWoMe는 질문의 가정을 추출하고 이를 작업 메모리로 활용하여 피드백과 행동을 생성하는 것을 중점으로 하는데, 실험 결과 PreWoMe는 잘못된 질문 뿐만 아니라 일반적인 질문에 대해서도 효과적으로 처리할 수 있다.

###### Memorisation Cartography: Mapping out the Memorisation-Generalisation Continuum in Neural Machine Translation (https://aclanthology.org/2023.emnlp-main.518/)
- Anthology ID: 2023.emnlp-main.518 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 신경망을 훈련할 때 일부 데이터를 기억하면서 다른 데이터는 전혀 학습하지 않을 수 있다. 기억 현상은 좋다 나쁘다는 이진적인 특성으로 쉽게 표현할 수 없으며, 개별 데이터 포인트는 기억과 일반화 사이의 연속체에 위치한다.
    2. 우리는 신경기계번역(NMT) 모델을 대상으로 기억과 일반화 지도에 5백만 개의 데이터 포인트를 위치시키는 자원을 구축하기 위해 대조적인 기억 메트릭을 사용한다.
    3. 데이터 포인트의 특징과 모델의 per-datum 훈련 신호가 NMT에서의 기억에 예측적으로 작용하는 방식 및 이 지도의 하위 집합이 NMT 시스템의 성능에 미치는 영향에 대해 설명한다.

###### DecipherPref: Analyzing Influential Factors in Human Preference Judgments via GPT-4 (https://aclanthology.org/2023.emnlp-main.519/)
- Anthology ID: 2023.emnlp-main.519 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인간의 좋아하는 요소는 작업과 장르에 따라 다양하지만, 인간 판단에 가장 좋아하지 않는 요소들은 일관되며, 예를 들어, 결과물이 너무 간결하거나 초점을 벗어난 내용이나 가공된 사실을 포함한다.
    2. Bradley-Terry-Luce (BTL) 모델을 사용하여 인간 판단에 내재된 선호도를 밝혀준다.
    3. 이 연구 결과는 미래 LLMs의 행동을 조정하는 중요한 단계인 균형 잡힌 데이터셋 구성에 영향을 미친다.

###### Gender Biases in Automatic Evaluation Metrics for Image Captioning (https://aclanthology.org/2023.emnlp-main.520/)
- Anthology ID: 2023.emnlp-main.520 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 모델 기반 평가 메트릭(CLIPScore와 GPTScore 등)은 다양한 언어 생성 작업에서 인간 판단과 상당한 상관관계를 나타냈다. 그러나 이러한 메트릭이 공정성에 미치는 영향은 여전히 미개척 상태이다.
    2. 미리 학습된 모델들은 사회적 편견을 우연히 인코딩할 수 있으므로, 이러한 모델을 평가 목적으로 사용하면 편향을 계속해서 유지 및 증폭시킬 수 있다.
    3. 이 논문에서는 이미지 캡션 작업에서의 모델 기반 자동 평가 메트릭의 성별 편향에 대한 체계적인 연구를 수행하고, 사전 학습된 모델을 사용하는 것의 부정적인 결과와 평가 메트릭의 편향을 완화하는 방법을 제시한다.

###### QA-NatVer: Question Answering for Natural Logic-based Fact Verification (https://aclanthology.org/2023.emnlp-main.521/)
- Anthology ID: 2023.emnlp-main.521 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사실 점검 시스템은 증거에 기반하여 주장의 진위를 평가한다. 이 논문에서는 natural logic 연산자를 예측하기 위해 질문-답변 방식을 사용하는 방법을 제안한다.
    2. 이 방법은 instruction-tuned 언어 모델의 일반화 능력을 활용하여 주석이 달린 훈련 데이터의 필요성을 제거하고 결정론적 추론 시스템에 의존한다.
    3. 실험 결과, 이 방법은 다른 자연어 연산자 시스템에 비해 FEVER에서 4.3%의 정확도 향상을 보였으며, 또한 다나ish 검증 데이터셋에서도 주석을 더하지 않은 모델들을 능가하는 성능을 보였다.

###### Increasing Probability Mass on Answer Choices Does Not Always Improve Accuracy (https://aclanthology.org/2023.emnlp-main.522/)
- Anthology ID: 2023.emnlp-main.522 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사전 훈련된 언어 모델(LM)을 적용할 때 주어진 선택지 외의 어휘 토큰에도 확률이 지정되는데, 이러한 확률의 분포가 동일한 의미의 다른 형태에 걸쳐져 있는 것이 모델의 실제 성능을 과소평가하는 원인이 될 수 있다. 이를 "surface form competition" (SFC) 가설이라고 한다. 이 논문에서는 SFC의 영향을 처음으로 정량화하고 제한하는 수학적 형식을 제안한다.
    2. SFC를 줄이기 위한 간단한 방법을 찾아냈는데, 예를 들어 해당 답변 선택지를 프롬프트에 포함시키는 것과 단지 한 예제로만 인문학적 학습을 사용하여 주어진 답변 선택지에 대한 확률이 증가하도록 한다. 이 방법은 대부분의 경우에 SFC의 영향을 없앤다는 것을 보여준다.
    3. 3개의 다양한 데이터셋과 6개의 LMs에서의 실험을 통해 여러 가지 예상치 못한 결과를 확인할 수 있다. 예를 들어, SFC를 줄이기 위한 정규화 및 프롬프팅 방법은 일부 LMs에 대해 효과 없거나 성능을 떨어뜨릴 수 있다. 결론적으로 다중 선택 과제에 대해 LMs를 효과적으로 프롬프팅하기 위한 실용적인 통찰력을 제공한다.

###### Generating Data for Symbolic Language with Large Language Models (https://aclanthology.org/2023.emnlp-main.523/)
- Anthology ID: 2023.emnlp-main.523 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델 (LLMs)은 성능과 복잡성을 모두 가져오지만, 최근 작업에서는 LLMs를 작업 추론기가 아닌 데이터 생성기로 변환시키는 것이 시작되었습니다. 그러나 이러한 접근 방식은 주로 자연 언어 작업에만 적용되어 왔고, 복잡한 구조화된 출력을 가진 기호 언어 작업에 대해서는 아직 탐구되지 않았습니다.
    2. 우리는 SymGen이라는 기법을 제안합니다. 이 기법은 LLMs를 활용하여 다양한 주석 비용이 많이 드는 기호 언어 데이터를 생성합니다. SymGen은 생성을 이끄는 정보성 단서와 데이터의 정확성을 향상시키기 위한 합의 기반 검증기로 구성됩니다.
    3. 다양한 설정에서 6개의 기호 언어 작업에 대해 광범위한 실험을 수행하였습니다. LLMs와 비교하여 1% 크기의 작업 모델이 유사하거나 더 좋은 성능을 달성할 수 있으며, 추론 및 배포 비용을 크게 줄일 수 있음을 보여줍니다. 또한, 작업 모델을 훈련할 때 인간 주석 데이터 양의 10 배 이상의 효과가 있는 사람이 작성한 데이터와 동등한 효과가 있는 생성된 데이터를 보여주어 주석 작업의 상당한 양을 절약할 수 있습니다. SymGen은 주석 비용이 많이 드는 복잡한 작업을 위한 데이터 생성으로 한 발 더 나아가며, 코드는 URL에서 공개되었습니다.

###### IDTraffickers: An Authorship Attribution Dataset to link and connect Potential Human-Trafficking Operations on Text Escort Advertisements (https://aclanthology.org/2023.emnlp-main.524/)
- Anthology ID: 2023.emnlp-main.524 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인간 노예거래 문제는 온라인 광고와 관련이 있어 경찰에게 가해주는 어려움이 증가하고 있다. 이 문제를 해결하고자 이 논문에서는 인터넷 에스코트 시장에서 인간 노예거래 판매자를 식별하기 위한 데이터셋인 IDTraffickers을 소개한다.
    2. 우리는 DeCLUTR-small 모델을 훈련하여 저자 식별에 대한 벤치마크를 구축하였고, 폐쇄집합 분류 환경에서 0.8656의 Macro-F1 점수를 달성했다.
    3. 또한, 훈련된 분류기에서 추출한 스타일 표현을 활용하여 저자 확인을 수행하였고, 개방집합 순위 환경에서 평균 R-정밀도 점수 0.9852을 얻었다. 이러한 데이터셋과 벤치마크의 공개는 보다 효과적으로 에스코트 광고를 연결하고 노예거래 지표를 식별하는 강력한 접근법을 개발하기 위해 미래의 연구자들에게 도움을 줄 것으로 기대된다.

###### Evaluating Bias and Fairness in Gender-Neutral Pretrained Vision-and-Language Models (https://aclanthology.org/2023.emnlp-main.525/)
- Anthology ID: 2023.emnlp-main.525 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사전 학습된 기계 학습 모델은 기존 데이터의 편견을 지속시키고 심지어 강화하는 경향이 있는데, 이는 사용자 경험에 영향을 주는 불공정한 결과로 이어질 수 있다. 
    2. 이 논문에서는 사전학습과 세밀 조정 단계에서의 성별 편견을 측정하고 그 영향에 대해 연구한다. 
    3. 전체적으로 사전학습과 세밀 조정 사이에 성별 편향 증폭은 독립적인 것으로 나타난다. 또한 성별 중립적 데이터에 대한 지속적인 사전 학습이 VQAv2 및 검색 작업에서 공정성을 증가시키는 동시에 작업 성능에 큰 영향을 주지 않는 것을 발견했다.

###### Improving Dialogue Discourse Parsing via Reply-to Structures of Addressee Recognition (https://aclanthology.org/2023.emnlp-main.526/)
- Anthology ID: 2023.emnlp-main.526 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화 문맥 파싱은 대화의 관계 기반 구조를 반영하기 위해 대화 관계에 따라 의미 관계를 형성함으로써 데이터 희소성 문제를 완화한다. 
    2. 이전 연구들은 관련 작업 (예: 읽기 이해)과 함께 대화 문맥 파싱을 학습하는 다중 작업 접근법을 채택하여 일반화성을 제한하지만, 우리는 인접 작업(수신자 인식)과 대화 문맥 파싱을 통합하는 다중 작업 프레임워크를 제안한다.
    3. 실험 결과, 우리의 제안 방법은 Molweni와 STAC 데이터셋에서 SOTA 기준보다 우수한 성능을 보였으며, 코드는 https://github.com/yxfanSuda/RLTST 에서 사용 가능하다.

###### Improving Language Models’ Meaning Understanding and Consistency by Learning Conceptual Roles from Dictionary (https://aclanthology.org/2023.emnlp-main.527/)
- Anthology ID: 2023.emnlp-main.527 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 현재의 사전 훈련 언어 모델 (PLM)은 비인간적인 행동으로 인해 신뢰성이 떨어지고 있다. 
    2. 이 논문에서는 개념적 역할 이론을 기반으로 한 실제 접근 방식을 제안하여 PLM의 의미 인식 능력을 개선하여 모순된 행동 문제를 완화한다. 
    3. 실험 결과는 이 방법이 다양한 유형의 일관성을 동시에 개선하고 지식 통합을 효율적으로 가능하게 하며 다른 언어에도 적용하기 쉽다는 것을 보여준다.

###### DALE: Generative Data Augmentation for Low-Resource Legal NLP (https://aclanthology.org/2023.emnlp-main.528/)
- Anthology ID: 2023.emnlp-main.528 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. DALE은 저자들이 법률 NLP 분야에서의 저자들과의 작업에 있어 낮은 자원 환경(low-resource)에서의 유용하며 창의적인 데이터 증강(Data Augmentation) 프레임워크로 소개된다.
    2. DALE은 법률 문서에서 효과적인 데이터 증강을 생성함에 있어 다른 프레임워크에서 제시되는 도전과제들을 해결한다.
    3. DALE은 선행된 논문들이 가져온 방법들의 과제들을 극복하기 위해 저작자들이 개발한 생태계 특화 언어 모델에 기반한 자율적 텍스트 노이즈 제거 목적으로 사전 훈련되었다.

###### FedID: Federated Interactive Distillation for Large-Scale Pretraining Language Models (https://aclanthology.org/2023.emnlp-main.529/)
- Anthology ID: 2023.emnlp-main.529 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사용자 데이터 개인정보 보호에 대한 우려와 규제로 인해 분산 학습 패러다임이 필요하지만, 현재의 federated learning (FL)은 통신 오버헤드, 이질성 처리 불가능성, 흰색 상자 추론 공격 등의 중요한 한계가 있다.
    2. 따라서 이 논문에서는 이러한 한계를 완화하기 위해 FedID라는 새로운 기법을 제안한다. 이는 서버가 보유한 작은 양의 레이블 데이터를 사용하여 지식 전달 중 로컬 모델을 보완한다.
    3. 실험 결과, 우리의 제안한 FedID 프레임워크는 동질적이고 이질적인 federated 시나리오에서 최상의 결과를 얻을 수 있다.

###### trlX: A Framework for Large Scale Reinforcement Learning from Human Feedback (https://aclanthology.org/2023.emnlp-main.530/)
- Anthology ID: 2023.emnlp-main.530 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인간 피드백을 통한 강화 학습은 학습된 보상 모델을 바탕으로 대형 언어 모델을 인간의 기호와 더 잘 일치시키기 위해 온라인 최적화를 통해 인간 피드백을 활용한다. 
    2. 현재의 RLHF 패러다임은 대규모 아키텍처에 대한 구현과 확장에 어려움을 겪는다. 
    3. 본 논문에서는 70 억 개 이상의 파라미터를 가진 모델에 대해 RLHF fine-tuning을 위한 AutoRLHF 라이브러리를 제안하며, 다양한 유형의 분산 트레이닝 및 계산 및 메모리 절약 기능을 구현하여 다양한 컴퓨팅 리소스를 지원한다.

###### This is not a Dataset: A Large Negation Benchmark to Challenge Large Language Models (https://aclanthology.org/2023.emnlp-main.531/)
- Anthology ID: 2023.emnlp-main.531 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델 (LLMs)은 문법적 지식과 일반화 능력을 일부 보여주지만, 부정(negation)을 해석하는 데 실패한다. 
    2. LLMs는 긍정문을 분류하는 데 능숙하지만, 부정문에는 어려움을 겪고 부정에 대한 깊은 이해력이 부족하다는 것을 밝혀냈다.
    3. 부정 문장에 대한 모델의 성능을 향상시키기 위해 모델을 fine-tuning하는 것은 도움이 되지만, 부정 이해의 일반화 부족은 여전히 지속되며, 부정에 대한 언어 모델의 계속되는 도전을 강조한다.

###### MT2: Towards a Multi-Task Machine Translation Model with Translation-Specific In-Context Learning (https://aclanthology.org/2023.emnlp-main.532/)
- Anthology ID: 2023.emnlp-main.532 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 문장 수준 번역, 문서 수준 번역, 번역 메모리, 용어 제약 번역 등은 기계 번역에 중요한 역할을 한다. 그러나 이전 연구들은 각각의 작업을 해결하기 위해 별도의 모델이나 방법을 사용하여, 서로 다른 작업 간의 지식 전달을 방해하고 시스템 구축의 복잡성을 증가시킨다.
    2. 이 논문에서는 사전 훈련된 언어 모델의 기계 번역 과제에서의 잠재력을 탐색하고, 여러 번역 작업을 통합하는 Multi-Task Machine Translation (MT2) 모델을 제안한다.
    3. 우리는 모델 훈련을 위해 문맥 학습을 수행하는 새로운 In-Context Learning (ICL) 패러다임을 설계하였으며, 문맥 정보를 통합하여 성능을 개선하는 문맥 학습 작업으로 모든 번역 작업을 모델링할 수 있다. 또한, 검색 및 정렬 방법과 두 가지 문맥 종속적인 훈련 전략을 채택하여 모델이 번역에 있어 문맥 정보를 더 잘 이해하고 활용할 수 있도록 한다. 실험 결과는 우리 모델의 우수한 성능과 제안한 방법의 효과를 입증한다.

###### CleanCoNLL: A Nearly Noise-Free Named Entity Recognition Dataset (https://aclanthology.org/2023.emnlp-main.533/)
- Anthology ID: 2023.emnlp-main.533 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. CoNLL-03 corpus은 명명된 entity 인식(NER)에서 가장 잘 알려진 벤치마크 데이터셋으로 알려져 있지만, 이 데이터는 주석 오류, 불완전함 및 불일치를 포함하여 이전의 연구에서 문제점으로 지적되고 있다.
    2. 이 논문에서는 자동 일관성 체크를 사용하여  English CoNLL-03의 모든 라벨의 7.0%를 수정하는 종합적인 다시 라벨링 작업을 제안한다.
    3. 실험적 평가에서, 우리의 데이터에서 state-of-the-art 접근법은 F1-score (97.1%)을 달성하는데, 이 데이터는 주석 노이즈로 인해 잘못 계산된 정확한 예측의 비율이 47% 에서 6% 으로 줄어든 것으로 나타난다.

###### Disentangling Transformer Language Models as Superposed Topic Models (https://aclanthology.org/2023.emnlp-main.534/)
- Anthology ID: 2023.emnlp-main.534 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 주제 모델링은 토픽의 질을 일괄성 측정으로 측정하는데, Neural Topic Models(NTM)에서 기계가 학습한 주제를 디코더 가중치로 추론한다. 그러나, Transformer-based Language Models(TLM)에서는 가설화된 합성 속성으로 인해 최종 logit은 해석이 불가능하게 된다고 한다.
    2. 이 연구에서는 TLM을 여러 일관된 주제와 연결시킬 수 있는 가중치 기반의 접근 방식을 제안하여 TLM을 해석 가능하게 만드는 방법을 제안하고, GPT-2 모델에서 Wikipedia 코퍼스를 사용하여 이를 실현할 수 있다는 것을 실험적으로 보여주었다. 
    3. 또한, 제안한 방법론을 LLaMA 모델에 적용하여 주제를 분리하고 분석할 수 있다고 제안한다.

###### Conversational Semantic Parsing using Dynamic Context Graphs (https://aclanthology.org/2023.emnlp-main.535/)
- Anthology ID: 2023.emnlp-main.535 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문에서는 대화 기록의 맥락에서 사용자 발화를 실행 가능한 논리 형태(Sparql 등)로 인터랙티브하게 매핑하는 대화적 의미 파싱 작업을 다룬다.
    2. 우리는 동적으로 생성되는 서브그래프를 활용하여 발화와 그 맥락에 대한 정보를 표현하는데, 이 서브그래프는 노드의 개수가 발화마다 다르다.
    3. 실험 결과, 동적 맥락 모델링이 정적 접근 방식에 비해 성능이 우수하며, 단순하고 복잡한 질문 모두에서 성능 향상을 보여줌을 확인하였다.

###### Not all quantifiers are equal: Probing Transformer-based language models’ understanding of generalised quantifiers (https://aclanthology.org/2023.emnlp-main.536/)
- Anthology ID: 2023.emnlp-main.536 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Transformer 기반 언어 모델(TLM)의 행동에 일반화된 양자가 어떻게 영향을 미치는지에 대한 연구는 종종 논리적으로 정의된 작업을 활용하지 않아 일반화된 양자의 논리적 중요성을 정확하게 포착하지 못했다는 문제가 있다.
    2. 이 논문에서는 논리적으로 정의된 텍스트 강조 (textual entailment) 문제를 활용하여 다양한 일반화된 양자가 TLM에 어떤 영향을 미치는지 조사한다. 
    3. 결과적으로, TLM은 일반적으로 가장 일반적인 일반화된 양자의 논리적 의미를 이해할 수 있지만, 다른 양자들은 TLM에 다양한 방식으로 영향을 준다는 것을 밝혀냈다.

###### Structure-aware Knowledge Graph-to-text Generation with Planning Selection and Similarity Distinction (https://aclanthology.org/2023.emnlp-main.537/)
- Anthology ID: 2023.emnlp-main.537 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 지식 그래프(Knowledge graph)-텍스트(KG-to-text) 생성 작업은 입력 지식 그래프에서 유래된 복잡한 정보를 정확하게 전달하는 일관적이고 매력적인 문장을 합성하는 것을 목표로 한다. 
    2. 이 작업에서의 주요 도전 과제 중 하나는 다양한 KG 및 대상 텍스트의 구조 사이의 간극을 줄이면서 입력 KG의 세부 정보를 보존하는 것이다. 
    3. 본 논문에서는 pre-trained language models와 graph structure-aware 모듈을 효율적으로 통합하는 새로운 접근 방식을 제안한다.

###### SOUL: Towards Sentiment and Opinion Understanding of Language (https://aclanthology.org/2023.emnlp-main.538/)
- Anthology ID: 2023.emnlp-main.538 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 감성 분석은 자연어 처리의 잘 알려진 과제로서, 감성 극성 분류는 가장 인기있고 대표적인 태스크 중 하나이다. 그러나 pretrained language model의 성공에도 불구하고, 그들은 종종 감성 분석의 더 넓은 복잡성을 잡아내지 못한다.
    2. 이 문제를 해결하기 위해, Sentiment and Opinion Understanding of Language (SOUL)이라는 새로운 태스크를 제안한다. SOUL은 Review Comprehension (RC)와 Justification Generation (JG)이라는 두 가지 서브태스크를 통해 감성 이해를 평가한다.
    3. 실험 결과는 SOUL이 작은 language model과 큰 language model 모두에 대해 어려운 태스크임을 보여주며, 인간의 성능과 비교하여 최대 27%의 성능 차이를 보인다. 또한, 전문가와 GPT-4를 사용한 평가는 작은 language model이 추론 기반의 이유 생성에서의 한계를 강조한다.

###### Regulation and NLP (RegNLP): Taming Large Language Models (https://aclanthology.org/2023.emnlp-main.539/)
- Anthology ID: 2023.emnlp-main.539 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 자연어 처리와 인공 지능 분야에서의 과학적 혁신은 가장 빠른 속도로 진행되고 있다. 
    2. 이 논문에서는 현재 AI 안전성과 AI 윤리 운동에 의해 주도되는 편향된 이야기에 지배되는 AI 규제 및 거버넌스에 관한 중요한 논쟁이 있다고 주장한다. 
    3. 그리고 NLP 연구에서는 현재 위험 평가에 대한 논의가 증가하고 있으나 과학적 기초가 부족하여 이와 관련된 규제에 대한 연구의 신뢰성을 저해하고 있다고 주장한다.

###### MedEval: A Multi-Level, Multi-Task, and Multi-Domain Medical Benchmark for Language Model Evaluation (https://aclanthology.org/2023.emnlp-main.540/)
- Anthology ID: 2023.emnlp-main.540 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. MedEval은 의료 분야의 언어 모델 개발을 촉진하기 위한 다중 수준, 다중 과제 및 다중 도메인 의료 벤치마크다. 이 데이터셋은 8가지 검사 방법으로부터 35개의 인체 부위에 걸친 정보를 제공하며, 전문가 주석을 통해 다양한 수준에서의 데이터 활용과 다양한 작업을 지원한다.
    2. 우리는 의료 분야에 대응된 기본 모델부터 ChatGPT와 같은 대형 언어 모델까지 10가지 일반 및 도메인 특화된 언어 모델을 zero-shot 및 fine-tuning 설정에서 체계적으로 평가했다.
    3. 이 연구를 통해 우리는 대형 언어 모델의 활용에 있어 instruction tuning의 중요성과 의료 분야에서의 강점과 한계에 대한 유용한 통찰력을 제공한다.

###### Seeing through the mess: evolutionary dynamics of lexical polysemy (https://aclanthology.org/2023.emnlp-main.541/)
- Anthology ID: 2023.emnlp-main.541 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 단어는 여러 의미를 가질 수 있다. 예를 들어, 단어 "mess"는 음식을 제공하는 장소이거나 혼란스러운 상황을 나타낼 수 있다. 이 연구에서는 다의성(polysemy)로 이어지는 기작을 조사하기 위해 어휘 의미의 진화에 대한 수학적 모델을 제안하고 분석한다.
    2. 이 모델에서는 어휘 처리와 전달에 영향을 미치는 요인들인 단어 빈도, 비준수주의(non-conformism), 의미 구별력을 고려하고 있다.
    3. 낮은 빈도, 비준수주의 사용을 선호하는 경향, 그리고 높은 의미 구별력이 다의성을 유지하는 여러 의미가 생성될 수 있는 조건임을 수학적으로 증명하였으며, 영어 단어의 의미 발전을 다루는 역사 언어 데이터로 이러한 예측을 통계적으로 검증하였다.

###### Are Embedded Potatoes Still Vegetables? On the Limitations of WordNet Embeddings for Lexical Semantics (https://aclanthology.org/2023.emnlp-main.542/)
- Anthology ID: 2023.emnlp-main.542 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 지식 베이스 임베딩 (KBE) 모델은 WordNet을 포함한 지식 베이스의 구조적 정보를 인코딩하는 데에 널리 사용되는데, 기존의 문헌은 주로 link prediction을 평가하는 것에 초점을 맞추어 왔으며, 모델의 의미적 능력을 탐구하는 것을 소홀히 했다.
    2. 본 논문에서는 WordNet의 KBE 모델이 link prediction에서의 성능과 의미 정보를 인코딩하는 능력 사이에 잠재적인 연결이 없을 수 있다고 조사하고, 현재의 평가 프로토콜의 한계를 강조한다.
    3. 결과적으로, WN18RR 벤치마크에서 성능이 우수한 KBE 모델 중 일부는 두 가지 의미적 태스크 및 두 가지 후속 태스크에서 부적절한 결과를 나타내고 있으며, 이는 KBE 모델의 의미적 능력을 평가하기 위한 link prediction 벤치마크의 무력함을 보여주며, 더 효과적인 평가 접근 방식의 필요성을 제시한다.

###### Evaluation Metrics in the Era of GPT-4: Reliably Evaluating Large Language Models on Sequence to Sequence Tasks (https://aclanthology.org/2023.emnlp-main.543/)
- Anthology ID: 2023.emnlp-main.543 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델들의 평가는 불안정하고 일관성 없는 상황이며, 자동 평가 메트릭의 품질은 생성 모델의 발전 속도에 따라 따라가지 못하고 있다.
    2. 우리는 여러 개의 벤치마크 (text summarisation, text simplification, GEC)에서 여러 개의 LLMs 를 automatic과 human 평가를 통해 초기 형태의 성능 평가를 제공함으로써 현재 모델의 성능을 향상시키고자 한다. 
    3. 우리는 ChatGPT가 대부분의 메트릭에서 인간 평가자들에게 따르면 다른 인기 있는 모델보다 일관적으로 더 우수한 성능을 보이지만, 전통적인 자동 평가 메트릭을 사용할 때는 훨씬 저조한 점수를 얻는 것으로 나타냈다.

###### Event-Location Tracking in Narratives: A Case Study on Holocaust Testimonies (https://aclanthology.org/2023.emnlp-main.544/)
- Anthology ID: 2023.emnlp-main.544 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 본 연구는 이야기 이해의 공간적 차원에 초점을 맞추며, 이야기 텍스트에서의 사건 위치 추적(task)을 제안한다고 한다. 이 작업은 이야기가 진행됨에 따라 발생하는 위치의 연속열을 추출하는 것을 목표로 한다.
    2. 이 위치 추적(task)을 위해 다양한 수준의 컨텍스트 인식을 가지는 구조를 제안하고, 좁은 컨텍스트에서 강력한 방법을 적용하는 등 다양한 기준선 비교를 통해 성능을 평가한다.
    3. 홀로코스트 피난민의 증언을 테스트 케이스로 삼아, 이 데이터셋을 산업화수단으로 연구하는 것의 도덕적, 역사적 중요성을 주장하며, 더 많은 문맥을 인식하는 모델이 보다 정확한 위치 연속열을 생성할 수 있음을 실험 결과로 입증한다.

###### Dialogizer: Context-aware Conversational-QA Dataset Generation from Textual Sources (https://aclanthology.org/2023.emnlp-main.545/)
- Anthology ID: 2023.emnlp-main.545 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "대화형 질문응답(ConvQA)에서의 데이터 부족 문제를 해결하기 위해, 대화 채우기(dialog inpainting) 방법이 제안되었다. 그러나 원래의 대화 채우기 모델은 대화 복원(task)에만 초점을 맞춰 학습되기 때문에, 질문-답변 정렬의 부족한 학습으로 인해 문맥적 연관성이 낮은 질문을 생성하게 된다."
    2. "따라서 저희는 Dialogizer라는 새로운 프레임워크를 제안한다. 이 프레임워크는 텍스트 소스로부터 고문맥 연관성을 가진 ConvQA 데이터셋을 자동으로 생성할 수 있는 능력을 갖추고 있다."
    3. "우리의 프레임워크를 사용하여 다중 도메인의 문서를 기본 소스로 활용하여 4개의 ConvQA 데이터셋을 생성하였으며, 다양한 메트릭을 사용한 자동 평가 및 인간 평가를 통해, 우리의 프레임워크가 기준선 대화 채우기 모델보다 더 높은 품질의 데이터셋을 생성하는 능력을 검증하였다."

###### Learning to Predict Task Transferability via Soft Prompt (https://aclanthology.org/2023.emnlp-main.546/)
- Anthology ID: 2023.emnlp-main.546 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사전 훈련된 언어 모델을 중간 단계 작업에 미세 조정(fine-tuning)하는 것은 대상 작업의 성능을 크게 향상시킬 수 있지만, 성공적인 전이를 위한 소스 작업을 효율적으로 찾는 방법은 아직 충분히 연구되지 않았다.
    2. 우리는 전이 가능성(transferability)을 예측하기 위해 유사도 점수 함수를 학습하는 것을 제안한다. 소프트 프롬프트를 과업 특정 정보를 요약한 과업 임베딩으로 취급하여 테스크 쌍을 무작위로 샘플링하여 점수 함수를 훈련시킨다.
    3. 실험 결과, 우리의 방법은 효율적으로 전이 학습에 유용한 소스 작업을 식별한다는 것을 보여준다.

###### Chain-of-Questions Training with Latent Answers for Robust Multistep Question Answering (https://aclanthology.org/2023.emnlp-main.547/)
- Anthology ID: 2023.emnlp-main.547 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Chain-of-Questions"은 서브 질문을 생성하고 답하는 방식으로 다단계 질문에 대한 강력한 답변을 제공할 수 있는 프레임워크이다. 
    2. 우리는 인간이 주석을 단 질문 분해 의미 표현(QDMR)에서 서브 질문에 대한 지도를 얻지만, QDMR에는 서브 질문에 대한 주석된 답변이 포함되어 있지 않다. 
    3. 이를 극복하기 위해, 우리는 서브 답변을 잠재 변수로 취급하고, Hard-EM과 MAPO의 동적 혼합을 통해 서브 답변을 추론하는 새로운 방법을 제안한다.

###### Mirror: A Universal Framework for Various Information Extraction Tasks (https://aclanthology.org/2023.emnlp-main.548/)
- Anthology ID: 2023.emnlp-main.548 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 정보 추출 (IE) 태스크 간의 지식 공유는 다양한 데이터 형식과 태스크 변이 때문에 언제나 어려움이 되어왔습니다. 이 논문에서는 IE 문제를 다양한 IE 태스크에 대한 통합된 multi-slot tuples 으로 재구성하고 다양한 IE 태스크에 대한 범용 프레임워크로 Mirror를 제안합니다.
    2. 기존 IE 태스크를 multi-span 순환 그래프 추출 문제로 바꾸고, 포괄적인 그래프 디코딩 알고리즘을 사용하여 모든 범위를 한 번에 추출하는 방법을 제안합니다. 이 그래프 구조는 놀랄만큼 유연하며 복잡한 IE 작업 뿐만 아니라 기계 독해 및 분류 작업도 지원합니다.
    3. 전이학습을 위해 57개의 데이터셋으로 모델 사전훈련을 수행한 후, 8개의 하위 태스크에서 30개의 데이터셋에 대한 실험을 진행하였고, SOTA (State-of-the-Art) 시스템과 비교하여 우수한 호환성을 나타냈습니다. 소스 코드, 모델 가중치 및 사전훈련된 코퍼스는 https://github.com/Spico197/Mirror 에서 제공됩니다.

###### “Mistakes Help Us Grow”: Facilitating and Evaluating Growth Mindset Supportive Language in Classrooms (https://aclanthology.org/2023.emnlp-main.549/)
- Anthology ID: 2023.emnlp-main.549 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 선생님들의 성장 마인드셋 지원 언어 (GMSL)는 시간이 흐름에 따라 기술을 향상시킬 수 있다고 강조하는 이론이 학업 성취 격차를 크게 줄이고 학생들의 학습 결과를 향상시킬 수 있다는 것이 입증되었다. 
    2. 하지만 대부분의 선생님들은 GMSL을 적용하기 어려워 이 분야에서 효과적인 코칭이 부족한 상황이다. 
    3. 우리는 대형 언어 모델 (LLMs)이 GMSL 사용을 지원하기 위한 자동화된 개인화 된 코칭을 제공할 수 있는지 조사한다.

###### Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text (https://aclanthology.org/2023.emnlp-main.550/)
- Anthology ID: 2023.emnlp-main.550 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 Large Language Models (LLMs)는 여러 작업에서 놀라운 성능을 보이지만, 이들의 내부 작업 방식에 대해서는 여전히 많은 불명확한 점이 남아 있다.
    2. 우리는 이 논문에서, 많은 순차적인 변경을 겪었을 때 LLM의 복원력에 대한 실험적인 통찰력을 제시한다.
    3. 실험 결과에서는 GPT-4를 비롯한 몇 가지 고급 LLM들이 단어의 첫글자와 마지막 글자만 유지되면 의미를 잘 이해할 수 있다는 typoglycemia 현상과 유사한 능력을 보임을 확인하였다.

###### Detecting and Mitigating Hallucinations in Multilingual Summarisation (https://aclanthology.org/2023.emnlp-main.551/)
- Anthology ID: 2023.emnlp-main.551 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 신뢰할만한 자동 요약 모델을 위해서는, hallucination(환상) 문제를 해결해야 한다. 특히 저자들은 low-resource 언어에서 cross-lingual transfer 요약을 할 경우, 신뢰도를 평가하기 위한 새로운 메트릭인 mFACT를 개발하여, 세계적으로 유명한 다수의 faithful metric 기반으로 영어를 제외한 다른 언어의 신뢰성을 측정하고자 한다.
    2. 저자들은 mFACT가 다른 대안 메트릭과 비교하여 hallucination을 감지하는 데 가장 적합하다는 것을 다국어로 여러 실험을 통해 입증하였다. 
    3. 또한, 저자들은 크로스-언어 전송에서의 hallucination 문제를 완화하기 위한 간단하고도 효과적인 방법을 제안하며, 이는 강한 기준인 MAD-X와 같은 크로스-언어 전송을 위한 대안 모델과 비교했을 때, 성능과 신뢰성 모두에 큰 향상을 가져왔다고 보여주었다.

###### Exploring Linguistic Probes for Morphological Inflection (https://aclanthology.org/2023.emnlp-main.552/)
- Anthology ID: 2023.emnlp-main.552 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 현재의 형태소 변화(cross-linguistic)에 대한 컴퓨터 모델링 연구는 대개 언어 독립적인 데이터 분할 알고리즘을 사용하고 있다. 본 논문에서는 이 접근 방식을 보완하기 위해 유형별형태현 시스템(conjugational classes)과 특징 집합(feature sets)의 형태론적 일반화 측면을 테스트하기 위한 언어별 조사 방법을 제안한다.
    2. 이 조사 방법을 영어, 스페인어, 스와힐리어와 같이 형태론적 특징이 다른 세 가지 언어에 적용한 결과, 세 개의 형태소 변화 시스템이 철자 및 음운론적 자료를 통해 다른 일반화 전략을 사용한다는 증거를 발견하였다.
    3. 이러한 조사 방법을 통해 유형별형태현 시스템과 특징 집합에 대한 언어별 일반화 전략의 차이를 밝힘으로써, 형태소 변화에 대한 언어 간 컴퓨터 모델링 연구의 발전에 기여할 수 있다.

###### AMR Parsing with Causal Hierarchical Attention and Pointers (https://aclanthology.org/2023.emnlp-main.553/)
- Anthology ID: 2023.emnlp-main.553 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에는 번역 기반의 AMR 파서가 그들의 간단함과 효과적인 성능으로 인해 인기를 얻고 있다. 그러나 이러한 간단함은 AMR 그래프의 구조적 지역성을 무시하고, 상호 참조를 나타내기 위해 불필요한 토큰을 도입하는 단점을 갖고 있다.
    2. 본 논문에서는 AMR 파싱의 새로운 목표 형태와 CHAP라는 새로운 모델을 소개하며, 인과적인 계층적 어텐션과 포인터 메커니즘을 갖춘 CHAP를 Transformer 디코더에 구조를 통합할 수 있도록 설계되었다.
    3. 실험 결과, 추가 데이터 없이 수행한 실험에서 기준 모델보다 우수한 성능을 보여주었다.

###### FLatS: Principled Out-of-Distribution Detection with Feature-Based Likelihood Ratio Score (https://aclanthology.org/2023.emnlp-main.554/)
- Anthology ID: 2023.emnlp-main.554 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 실제 응용에서 NLP 모델이 OOD (out-of-distribution) 인스턴스를 감지하는 것은 중요하다.
    2. 기존의 OOD 감지 방법은 많지만 대부분 경험적이다고 주장하며, 이 논문에서는 OOD-ness를 측정하기 위해 외부 분포 \mathcal Pout 와 내부 분포 \mathcal Pin 간의 likelihood ratio를 사용한다.
    3. FLATS는 likelihood ratio를 기반으로 한 OOD 감지를 위한 원칙적인 해결책으로, pout(x) 추정을 통해 다른 OOD 감지 방법을 향상시킬 수 있다는 것을 실험으로 보였다.

###### Self-Evolution Learning for Mixup: Enhance Data Augmentation on Few-Shot Text Classification Tasks (https://aclanthology.org/2023.emnlp-main.555/)
- Anthology ID: 2023.emnlp-main.555 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 텍스트 분류 작업에서는 라벨링 된 데이터가 한정되어있는 few-shot 시나리오를 자주 만나며, 데이터 부족 문제를 해결하는 것이 중요하다. 
    2. 이 논문에서는 텍스트 분류에서 데이터 augmentation을 위해 적응적이고 모델 친화적인 pseudo 샘플을 생성할 수 있는 self-evolution learning (SE) 기반의 mixup 접근 방식을 제안한다. 
    3. 실험 결과, SE가 다양한 mixup 방법에 일관되고 큰 향상을 가져옴을 보여주었고 딥한 분석을 통해 SE가 모델의 일반화 능력을 향상시킨다는 것을 입증하였다.

###### IC3: Image Captioning by Committee Consensus (https://aclanthology.org/2023.emnlp-main.556/)
- Anthology ID: 2023.emnlp-main.556 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이미지 캡셔닝 모델들은 보통 하나의 "가장 좋은" 이미지 캡션을 생성하도록 훈련되지만, 이는 캡션에서 가능한 세부 정보의 일부만에 초점을 맞추고 다른 유용한 정보를 무시하게 만든다. 
    2. 이 논문에서는 "IC3"라는 새로운 방법론을 소개하여 여러 주석 작성자의 시각에서 고수준의 세부 정보를 포착하는 단일 캡션을 생성한다. 
    3. 실험 결과, IC3로 생성된 캡션은 기준 모델을 사용한 캡션보다 더욱 도움이 되는 것으로 판명되었고, IC3는 최고 수준의 자동 추출 시스템의 성능을 최대 84% 향상시킬 수 있었다.

###### SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models (https://aclanthology.org/2023.emnlp-main.557/)
- Anthology ID: 2023.emnlp-main.557 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 언어 생성 모델인 GPT-3와 같은 LLM은 다양한 유저 입력에 대해 매우 유창한 답변을 생성할 수 있지만, 거짓된 사실과 비현실적인 주장을 할 수 있어 신뢰성을 떨어뜨릴 수 있다.
    2. 본 논문에서는 외부 데이터베이스 없이 검증 모듈을 통해 black-box 모델의 답변을 사실 여부로 확인할 수 있는 "SelfCheckGPT"를 제안한다.
    3. 실험 결과, SelfCheckGPT는 비현실적인 문장과 사실적인 문장을 감지하고 사실성을 평가하는데 있어 다른 방법들보다 더 높은 성능을 보여주었다.

###### Fair Without Leveling Down: A New Intersectional Fairness Definition (https://aclanthology.org/2023.emnlp-main.558/)
- Anthology ID: 2023.emnlp-main.558 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 교차하는 민감한 그룹이 존재하는 분류(setting)에서 intersectional group fairness 문제를 고려한다. 기존의 공정성 척도들의 단점을 보여주고, 절대적 및 상대적인 성능을 결합하는 새로운 정의인 𝛼-Intersectional Fairness를 제안한다.
    2. 이 새로운 정의는 differential fairness 개념의 일반화로 볼 수 있으며, 제안된 정의의 여러 가지 바람직한 특성과 다른 공정성 척도들과의 관계를 분석한다.
    3. 이 논문에서 제안된 정의를 사용하여 여러 인기있는 fair machine learning 접근 방식들을 벤치마크하고, 간단한 기준표에 비해 어떠한 개선도 이루어지지 않음을 보여준다. 결과는 이전 정의로 측정된 공정성의 증가가 "하향 조정" 효과를 숨기고 있다고 밝혀진다. 즉, 가장 우수한 그룹의 성능이 저하됨으로써 최악의 성능을 개선하지 못한다.

###### Revisiting Instruction Fine-tuned Model Evaluation to Guide Industrial Applications (https://aclanthology.org/2023.emnlp-main.559/)
- Anthology ID: 2023.emnlp-main.559 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Instruction Fine-Tuning (IFT)은 대규모 언어 모델(LLM)의 zero-shot 능력을 강화하는 강력한 패러다임이지만, 이로 인해 새로운 평가 메트릭의 요구사항이 발생한다. 
    2. 우리는 LLM 기반 메트릭이 이러한 요구 사항에 잘 적응되는 것을 보여주고, 실제 산업 환경에서 나타나는 task-specialization 전략의 trade-off를 정량화하기 위해 이를 활용한다. 
    3. 우리의 연구 결과는 실제 IFT 모델 배포에 대한 실용적인 통찰력을 제공한다.

###### CLAD-ST: Contrastive Learning with Adversarial Data for Robust Speech Translation (https://aclanthology.org/2023.emnlp-main.560/)
- Anthology ID: 2023.emnlp-main.560 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "레이블되지 않은 텍스트를 기반으로 훈련된 MT 모델은 소음이 섞인 ASR 출력을 번역할 때 강건성이 부족하여 전반적으로 번역 품질이 저하된다. 우리는 대상 언어의 깨끗한 버전에 노이즈 입력의 표현을 근접시킴으로써 하향식 MT 모델의 강건성 문제를 해결한다."
    2. "이를 위해 대립적인 예제를 활용하여 ASR 출력과 해당 인간 트랜스크립트를 짝지은 대입적인 학습 방법을 도입하여 네트워크 파라미터를 최적화한다."
    3. "또한, MT 로그-우도 손실과 대입적 손실을 교대로 사용하여 훈련을 안정화시키는 교육 전략을 도입한다. 이 방법은 깨끗한 텍스트의 번역 품질에 영향을 주지 않으면서 영어-독일어 및 영어-프랑스어 음성 번역에서 최대 3 BLEU 점수의 상당한 향상을 이끌어냈다."

###### M2DF: Multi-grained Multi-curriculum Denoising Framework for Multimodal Aspect-based Sentiment Analysis (https://aclanthology.org/2023.emnlp-main.561/)
- Anthology ID: 2023.emnlp-main.561 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에 주목받은 MABSA (Multimodal Aspect-based Sentiment Analysis)는 세밀한 Sentiment Analysis 작업인데 기존의 연구들은 주로 이미지 정보를 활용하여 성능을 향상시키려고 하지만, 데이터셋에는 텍스트와 관련이 없는 많은 노이즈 이미지들이 있어 모델 학습에 부정적인 영향을 줄 수 있다고 한다.
    2. 이 논문은 데이터를 수정하지 않고 노이즈 이미지의 부정적인 영향을 감소시킬 수 있는 방법을 연구한다. 
    3. Curriculum Learning의 아이디어를 활용하여, 데이터의 순서를 조정함으로써 노이즈 제거를 실현하는 M2DF (Multi-grained Multi-curriculum Denoising Framework)를 제안하였고, 실험적인 결과에서 이 프레임워크가 MABSA 의 세 가지 서브 태스크에서 최신 연구들을 일관되게 능가한다고 보여졌다.

###### Detection of Multiple Mental Disorders from Social Media with Two-Stream Psychiatric Experts (https://aclanthology.org/2023.emnlp-main.562/)
- Anthology ID: 2023.emnlp-main.562 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 "Mental Disease Detection (MDD)" 연구는 하나의 장애만을 감지하는 것에 초점을 두고 있어, 병이 동시에 발생할 수 있는 것을 간과하고 있다. 
    2. 우리는 모든 병의 공통된 단서를 학습하면서도 각각의 병마다 특정성을 포착하는 MDD 프레임워크를 제안한다.
    3. 텍스트와 증상 기능을 동시에 처리하는 two-stream 아키텍처는 두 가지 모드의 강점을 결합하여 지식 기반의 설명력을 제공한다. 희귀 클래스에서 특히 10% 이상의 감지 성능을 향상시킬 수 있는 것으로 실험 결과를 보여준다.

###### Understanding the Role of Input Token Characters in Language Models: How Does Information Loss Affect Performance? (https://aclanthology.org/2023.emnlp-main.563/)
- Anthology ID: 2023.emnlp-main.563 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Pre-trained language models (PLMs)가 언어에 대해 어떤 것을 학습하는지 이해하는 것은 자연어처리에서 여전히 고민되고 있는 문제이다. 
    2. 이 논문에서는 입력 토큰 문자의 정보 손실이 PLMs의 성능에 미치는 영향을 연구하였는데, 단 하나의 문자만 사용하여 pre-training한 모델조차도 일반적인 NLU 벤치마크와 probing tasks에서 높은 성능을 유지하는 것을 발견하였다. 
    3. 예를 들어, 토큰의 첫 번째 문자만 사용하여 pre-training한 모델은 SuperGLUE와 GLUE 태스크에서 각각 전체 토큰 모델의 약 90%와 77%의 성능을 유지한다.

###### Improved Unsupervised Chinese Word Segmentation Using Pre-trained Knowledge and Pseudo-labeling Transfer (https://aclanthology.org/2023.emnlp-main.564/)
- Anthology ID: 2023.emnlp-main.564 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 미지도 중국어 단어 분할(UCWS)은 사전에 훈련된 언어 모델에서 언어학적 지식을 사용하여 parameter-free 접근 방식을 통해 진전을 이루었다. 그러나 이러한 접근 방식은 단어 분할을 수행하기 위해 사전에 훈련된 언어 모델을 여러 번 추론해야 하므로 훈련 시간이 증가하는 문제가 있다.
    2. 이 논문에서는 훈련 효율성을 유지하면서 UCWS 성능을 향상시키기 위한 새로운 방법을 제안한다.
    3. 실험 결과, 기존 접근 방식에 비해 훈련 시간을 크게 줄이며 8가지 UCWS 작업에서 최고 수준의 성능을 달성하는 것을 입증한다.

###### EasyQuant: An Efficient Data-free Quantization Algorithm for LLMs (https://aclanthology.org/2023.emnlp-main.565/)
- Anthology ID: 2023.emnlp-main.565 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 언어 모델의 크기가 커서 실제 적용에는 많은 제약이 있는데, 이 논문에서는 데이터에 독립적인 양자화 기법을 제안하여 일반화 성과를 보장한다.
    2. EasyQuant라는 훈련 없이 수행되는 가중치만을 양자화하는 알고리즘을 제안한다. 가중치와 양자화 범위의 outlier를 처리하여 양자화 오류를 줄인다.
    3. EasyQuant은 훈련 데이터에 의존하지 않으므로 양자화된 언어 모델의 일반화 성능을 안전하게 보장하며, 병렬로 구현된다는 장점이 있다. 이 논문은 데이터에 의존하지 않는 방식에서 거의 손실 없이 양자화를 수행한 첫 번째 연구이며, 데이터 의존적인 방법보다 10배 빠르게 실행할 수 있다.

###### Polar Ducks and Where to Find Them: Enhancing Entity Linking with Duck Typing and Polar Box Embeddings (https://aclanthology.org/2023.emnlp-main.566/)
- Anthology ID: 2023.emnlp-main.566 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. DUCK은 entity linking 기법 중에서도 밀집 검색(dense retrieval) 기반의 방법으로 효율성이 뛰어나지만, 임베딩 공간의 구조에 민감하기 때문에 생성 모델에 비해 한계가 있다. 이 논문에서는 DUCK이라는 접근 방식을 소개하며 entity의 구조적인 정보를 임베딩 공간에 주입하는 것을 제안한다.
    2. 우리는 프로그래밍 언어에서의 "덕 타이핑"을 영감으로 하여 entity의 유형을 그래프 상에서 다른 entity와의 관계에 기반하여 정의한다.
    3. 실험 결과, DUCK 방법은 표준 entity disambiguation 목표 검증에서 새로운 최고 성능을 달성하며, 다른 타입 감지 기법을 능가하고, 파라미터가 18배 더 많은 생성 모델과 같은 결과를 보여준다.

###### APrompt: Attention Prompt Tuning for Efficient Adaptation of Pre-trained Language Models (https://aclanthology.org/2023.emnlp-main.567/)
- Anthology ID: 2023.emnlp-main.567 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델의 계속적인 성장으로 인해 새로운 작업에 대해 세밀하게 튜닝하는 과정이 매우 매개변수 집약적이 되었다. 
    2. 우리는 APrompt라는 새로운 Attention Prompt 튜닝 방법을 제안하여 대규모 사전 훈련 언어 모델을 효과적이고 효율적으로 적응시킨다. 
    3. 실험 결과는 우리의 방법이 다양한 규모의 사전 훈련 모델에서 최신 기준 모델과 전체 튜닝 방법을 능가한다는 것을 일관되게 보여준다.

###### What’s “up” with vision-language models? Investigating their struggle with spatial reasoning (https://aclanthology.org/2023.emnlp-main.568/)
- Anthology ID: 2023.emnlp-main.568 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 vision-language 모델들은 강력하지만, 그들은 "오른쪽"과 "왼쪽" 등의 기본적인 공간 관계를 신뢰할 수 있는 방식으로 구분할 수 있을까? 
    2. 우리는 기존의 VQAv2와 같은 데이터셋보다 객체의 공간적인 관계를 더 정확하게 분리하여 모델의 공간적인 추론 능력을 수치화하기 위해 세 가지 새로운 corpus를 제작하였다.
    3. 우리는 18개의 VL 모델을 평가하였는데, 그 결과 모든 모델들이 성능이 낮았다. 따라서 우리는 이러한 놀라운 행동의 원인에 대해 연구하였으며, 향후 연구에 도움이 되고자 우리의 데이터와 코드를 공개하였다.

###### IBADR: an Iterative Bias-Aware Dataset Refinement Framework for Debiasing NLU models (https://aclanthology.org/2023.emnlp-main.569/)
- Anthology ID: 2023.emnlp-main.569 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 일반적으로 사용되는 NLU (자연어 이해) 모델의 편향 제거 방법은 수동 데이터 분석에 많이 의존하여 모든 잠재적인 편향된 특징을 전부 다룰 수 없다. 
    2. 본 논문에서는 IBADR이라는 반복적인 편향 인식 데이터셋 개선 프레임워크를 제안하여 편향을 사전에 정의하지 않고도 NLU 모델의 편향을 제거한다. 
    3. 실험 결과와 깊은 분석을 통해 IBADR이 기존의 데이터셋 개선 방법에 비해 우수한 성능을 보여주며 SOTA에 도달하면서 모델 중심적인 방법과 호환될 수 있음을 보여준다.

###### Learning Preference Model for LLMs via Automatic Preference Data Generation (https://aclanthology.org/2023.emnlp-main.570/)
- Anthology ID: 2023.emnlp-main.570 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최신의 대형 언어 모델은 호 hallunciantion, 고정관념(stereotype) 등과 같은 문제점들이 있으나, 그 성능을 향상시키기 위해서는 preference model을 학습하는 것이 중요하다. 
    2. 그러나 이러한 preference model의 학습은 인간에 의해 어노테이트된 데이터에 의존하므로 다양성과 확장성이 제한된다.
    3. 본 논문에서는 "자동 생성된" 데이터로부터 preference model을 학습하는 방법을 제안하며, 해당 방법은 자연어처리 모델이 동시에 인간의 선호도를 배우고 인간의 가치와 일치하는 방법을 가능케 한다는 것을 보여준다.

###### Multilingual k-Nearest-Neighbor Machine Translation (https://aclanthology.org/2023.emnlp-main.571/)
- Anthology ID: 2023.emnlp-main.571 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "k-nearest-neighbor 기계 번역은 캐시된 예제들의 데이터 스토어를 생성하여 기계 번역의 품질을 크게 향상시켰다. 그러나 이러한 향상은 고자원 언어 쌍에서만 가능하며, 저자원 언어에 대해서는 여전히 도전과제이다."
    2. "우리는 여러 언어의 표현을 하나의 데이터 스토어로 결합하여 이 문제를 해결한다. 실험 결과, 저자원 번역의 품질뿐만 아니라 고자원 번역의 품질을 상당히 향상시키는 것이 일관적으로 관찰되었다."
    3. "언어 간 유사성을 이용하여 데이터 스토어를 생성함으로써 크기가 1/4로 줄이고 5.3배의 속도 향상을 달성할 수 있다는 것을 실험을 통해 보여주었다."

###### Understanding Computational Models of Semantic Change: New Insights from the Speech Community (https://aclanthology.org/2023.emnlp-main.572/)
- Anthology ID: 2023.emnlp-main.572 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 우리는 현재의 언어 사용 커뮤니티를 언어적으로 묘사하는 널리 사용되는 의미 변화 모델의 서술적 타당성을 조사했다. 우리는 퀘벡 영어에서의 접촉 유발 의미 변화라는 사회언어학적 문제에 초점을 맞춰 모델을 검증하기 위해 타입 수준과 토큰 수준의 워드 임베딩, 실증적 언어적 특성, 모트리올에서 온 15명의 화자들의 수용 가능성 평가 및 질적 의견을 분석했다. 결과적으로, 전산적 접근 방식의 전반적인 타당성을 확인하였지만 다양한 의미 변화 추정량의 보완재적 성격과 실제적 문제점을 강조하였다. 알려진 바에 의하면, 이 연구는 의미 변화 모델을 사용하여 기술되는 언어 사용 커뮤니티와 실질적으로 관련짓는 첫 번째 연구이다.
    2. 우리는 컴퓨터적 접근 방식의 의미 변화 모델들이 현대의 언어 사용 커뮤니티의 언어적 특성을 제대로 설명하는지 조사했다. 퀘벡 영어에서 발생하는 접촉 유발 의미 변화에 초점을 맞추고, 40개의 대상 단어를 타입 수준과 토큰 수준의 워드 임베딩, 경험적 언어적 특성, 몬트리올에서 왔다는 15명의 화자들의 수용 가능성 평가 및 질적 의견을 분석했다. 결과는 전반적으로 컴퓨터적 접근 방식의 타당성을 확인하며, 다양한 의미 변화 추정량의 필요성과 실제적 문제를 강조한다.
    3. 우리는 현대의 언어 사용 커뮤니티의 언어적 특성을 설명하는 널리 사용되는 의미 변화 모델의 기술적 타당성을 조사했다. 우리는 퀘벡 영어의 사회언어학적 문제에서의 접촉으로 인한 의미 변화에 집중하고, 타입 수준과 토큰 수준의 워드 임베딩, 경험적 언어적 특성, 몬트리올에서 온 15명의 화자들의 수용 가능성 평가 및 질적 의견을 분석하였다. 결과는 컴퓨터적 접근 방식의 전반적인 타당성을 확인하면서도 다양한 의미 변화 추정량의 상호 보완재성과 실용적 문제를 강조한다.

###### Causal Reasoning through Two Cognition Layers for Improving Generalization in Visual Question Answering (https://aclanthology.org/2023.emnlp-main.573/)
- Anthology ID: 2023.emnlp-main.573 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 VQA(Vision Question Answering) 모델들은 단일 모달 (unimodal) 측면을 개선하는데 주력하고 있어서 학습 분포를 벗어난 문맥에서 이미지의 질문에 대답하는 능력이 제한적이다.
    2. 본 논문에서는 양방향 인과 추론을 강조하여 다중 모달 (multimodal) 예측을 개선하는 CopVQA라는 모델을 제안한다.
    3. CopVQA는 다양한 시각화 기법을 사용하여 다중 모달 예측을 개선하고, 인과 추론의 역할을 강조하여 VQA의 성능과 일반화 능력을 향상시킨다. 또한, 모델 크기의 1/4로 경량화한 상태에서 PathVQA 데이터셋에서 우수한 정확도를 달성한다.

###### StructGPT: A General Framework for Large Language Model to Reason over Structured Data (https://aclanthology.org/2023.emnlp-main.574/)
- Anthology ID: 2023.emnlp-main.574 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 대형 언어 모델 (LLM)이 구조화된 데이터에 대해 추론 능력을 통합적으로 개선하기 위한 것이다.
    2. StructGPT라고 불리는 IRR (Iterative Reading-then-Reasoning) 프레임워크를 개발하여 구조화된 데이터를 기반으로하는 질문-답변 과제를 해결한다.
    3. 실험 결과, 구조화된 세 가지 유형의 데이터에서 StructGPT가 LLM의 성능을 크게 개선시켜주었다.

###### Modeling Legal Reasoning: LM Annotation at the Edge of Human Agreement (https://aclanthology.org/2023.emnlp-main.575/)
- Anthology ID: 2023.emnlp-main.575 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 일반적인 언어 생성 모델은 document class-prediction 태스크를 수행하기 위해 사용되는데, 현재까지의 연구들은 단순한 classification 태스크에 대해서만 검증을 진행하고 있다. 본 논문에서는 법적 추론을 포함한 매우 복잡한 태스크에 대한 LMs의 성능을 실험적으로 검증하였다.
    2. 총 8명의 법조계 전문가로 구성된 팀이 레이블링한 미국 연방 대법원 판례 데이터셋을 활용하여 다양한 LMs의 성능을 실험적으로 평가하였다.
    3. 실험 결과, 사람들에게 제시된 주어진 지시사항에 대해서 LMs의 성능이 낮게 나타났고, 잘 동작하는 모델은 LEGAL-BERT 모델과 같은 fine-tuning된 in-domain 모델이었다. 실험 결과는 법학 분야에서 generative LMs의 사용에 대해 주의를 요구하며, 인간 주석을 포함한 전통적인 분류 방법의 지속적인 중요성을 강조한다.

###### Model-tuning Via Prompts Makes NLP Models Adversarially Robust (https://aclanthology.org/2023.emnlp-main.576/)
- Anthology ID: 2023.emnlp-main.576 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 NLP 연구에서는 기존의 다음과 같은 절차를 따르는데, 미세조정된 언어 모델 위에 MLP (다층 퍼셉트론)을 올려 downstream 태스크에 사용하는데 이런 모델은 적은 대량 공격에도 취약하다.
    2. 그래서 본 논문에서는 MVP (Model-tuning Via Prompts)라는 알터너티브 방법을 제안하고, 실제로 이 방법이 공격 반대로 더 강한 방어력을 보인다는 것을 보였다. 
    3. MVP는 MLP 대신 입력에 prompt template을 추가하고 텍스트 채움/완성 방식을 통해 예측한다. MVP는 기존 방법에 비해 평균 8%의 성능 개선을 보여주었으며, adversarial training과 결합하면 더 큰 향상을 보이게 된다.

###### Learning Co-Speech Gesture for Multimodal Aphasia Type Detection (https://aclanthology.org/2023.emnlp-main.577/)
- Anthology ID: 2023.emnlp-main.577 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 뇌손상으로 발생하는 언어 장애인 실명-,와 전미크(aphasia)와 같은 특정한 aphasia 유형을 정확하게 식별하는 것은 효과적인 치료를 위해 중요한데, 이를 감지하기 위한 방법 개발에는 미비한 점이 있다.
    2. 이 연구에서는 동시에 발생하는 손동작(co-speech gestures)을 분석할 때의 식별력을 갖는 화제 정보를 생성하는 다중 모달 그래프 신경망을 제안한다.
    3. 실험 결과 gesture 기능이 acoustics 기능보다 우수함을 보여주었으며, 기존 방법에 비해 우수한 성능 (F1 84.2%)을 달성했다.

###### STINMatch: Semi-Supervised Semantic-Topological Iteration Network for Financial Risk Detection via News Label Diffusion (https://aclanthology.org/2023.emnlp-main.578/)
- Anthology ID: 2023.emnlp-main.578 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 상용 뉴스는 자동 금융 위험 감지에 풍부한 의미론적 내용과 적시성 있는 정보를 제공하지만, 비싼 대규모 주석과 훈련 데이터의 희박함으로 인해 상용 뉴스의 전체적인 활용에 제약이 있다.
    2. 논문에서는 상용 뉴스-기업 지식 그래프(NEKG)와 함께 반지도 학습 기법인 STINMatch를 제안하여 위험 감지 향상을 강화한다. 
    3. 제안된 모델은 레이블 상관 행렬과 상호 일관성 규제 기술을 텍스트와 그래프 모듈의 반복 학습 프레임워크에 통합하여 레이블 확산 및 위상 구조를 따르는 문서 수준 의미론과 레이블 상관 관계 간의 깊은 상호 작용을 가능하게 한다.

###### Centering the Margins: Outlier-Based Identification of Harmed Populations in Toxicity Detection (https://aclanthology.org/2023.emnlp-main.579/)
- Anthology ID: 2023.emnlp-main.579 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 AI 모델 평가 방법은 특정 인구 하위 그룹 간의 성능 차이를 찾아보는 것인데, 이는 취약한 그룹을 중심으로 하지만, 교차하는 부분 그룹이나 여러 그룹 간에 공유되는 피해의 패턴을 감추는 위험이 있다.
    2. 이 논문에서는 장애 연구와 관련 학문의 틀을 활용하여 가장자리 (margins)에 초점을 맞추어 독성 탐지 도메인에서 "가장자리"를 구현한다.
    3. 이 연구 결과, 인구 통계 아웃라이어의 경우 모델 성능이 일관되게 나빠지며, 텍스트 아웃라이어 또한 예외값에 비해 성능이 더 나쁘다는 것을 발견하였다. 따라서 예외 분석은 더 크고 다양한 교차 그룹에서 겪는 피해를 발견하는 데 특히 유익하다.

###### Describe Me an Auklet: Generating Grounded Perceptual Category Descriptions (https://aclanthology.org/2023.emnlp-main.580/)
- Anthology ID: 2023.emnlp-main.580 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인간 화자는 인스턴스 수준에서 추상화된 지각적 개념에 대한 설명을 생성할 수 있다. 추가로, 이러한 설명은 다른 화자들이 해당 개념의 임시 표현을 배우는 데 사용될 수 있다.
    2. 본 논문에서는 다중 모달 언어 모델에서 범주 수준의 지각적 Grounding을 테스트하기 위한 프레임워크를 소개한다.
    3. 설명 모델의 성능 문제를 인식하고, 이러한 문제가 범주 수준에서 언어를 적절하게 구체화하지 못함에 기인한다는 주장을 한다.

###### Revisiting Automated Topic Model Evaluation with Large Language Models (https://aclanthology.org/2023.emnlp-main.581/)
- Anthology ID: 2023.emnlp-main.581 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 토픽 모델은 대용량의 텍스트 컬렉션을 이해하는 데 도움을 준다. 그러나 그 출력을 자동으로 평가하고 최적의 토픽 수를 결정하는 것은 오랜 동안의 과제이며, 현재까지 효과적인 자동화된 해결책이 없다. 이 논문은 이러한 작업에 대해 대형 언어 모델(Large Language Models, LLMs)을 사용하는 것을 제안한다.
    2. LLMs는 기존의 자동 메트릭보다 더 강한 인간 판단과 잘 상관되는 토픽을 적절하게 평가한다. 그러나 평가 작업의 설정은 중요한데, LLMs는 단어 세트의 일관성 평가에서는 더 좋은 성능을 보이고 intrusion detection에서는 성능이 떨어진다.
    3. 또한, LLMs는 합리적인 토픽 수를 결정하는 데 도움이 될 수 있다. 연구 질문을 LLM의 프롬프트에 통합시켜 사용하면 최적의 토픽 수를 추정하는 데 도움이 된다.

###### ORCHID: A Chinese Debate Corpus for Target-Independent Stance Detection and Argumentative Dialogue Summarization (https://aclanthology.org/2023.emnlp-main.582/)
- Anthology ID: 2023.emnlp-main.582 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화 에이전트는 몇 년 동안 계속해서 주목받고 있으며, 최근의 대형 언어 모델 (LLM)의 진전으로 인해 이러한 트렌드가 더욱 촉진되었다. 
    2. 대립 감지 (stance detection)와 대화 요약 (dialogue summarization)은 논쟁적인 대화를 포함하는 응용 시나리오에서 대화 에이전트의 핵심 작업 두 가지이다. 
    3. 중국어의 언어 자료 부족으로 인해 이러한 작업에 대한 연구가 제한되어 있다. 이 문제를 해결하기 위해 우리는 첫 번째 중국어 데이터 집합인 ORCHID (Oral Chinese Debate)를 제안한다.

###### On the Benefits of Learning to Route in Mixture-of-Experts Models (https://aclanthology.org/2023.emnlp-main.583/)
- Anthology ID: 2023.emnlp-main.583 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Switch Transformer"와 같은 MoE (Mixture-of-Expert) Transformer 모델은 모델 크기를 확장하면서 계산 시간을 일정하게 유지하는 데 성공했다. 
    2. 우리는 이러한 모델의 핵심 요소인 라우터가 토큰을 똑똑하게 라우팅하는 능력이 MoE 모델에 상당한 이점을 제공한다는 이론적 및 경험적 증거를 제시한다. 
    3. 실제 데이터에 대한 실험에서도 학습 가능한 라우터가 비학습 가능한 라우터보다 상당한 이점을 제공함을 관찰했다.

###### SEAHORSE: A Multilingual, Multifaceted Dataset for Summarization Evaluation (https://aclanthology.org/2023.emnlp-main.584/)
- Anthology ID: 2023.emnlp-main.584 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 요약 시스템의 신뢰할 수 있는 자동평가는 다면적이고 주관적인 특성 때문에 어렵다. 특히 영어 외의 언어에서는 인간평가 데이터가 부족하여 어려움이 있다.
    2. 이 연구는 다국어이고 다면적인 요약 평가를 위한 데이터셋 SEAHORSE를 소개한다. SEAHORSE에는 6개의 언어, 9개의 시스템, 4개의 데이터셋을 포함한 96,000개의 요약과 인간평가 결과가 있으며, 텍스트 품질의 6가지 측면(comprehensibility, repetition, grammar, attribution, main ideas, conciseness)으로 평가된다.
    3. SEAHORSE를 활용하여 학습된 메트릭은 여러 도메인에서 좋은 성능을 달성하였으며, 이 데이터셋과 메트릭은 다국어 및 다면적 요약 평가에 대한 향후 연구를 위해 공개되었다.

###### Query2doc: Query Expansion with Large Language Models (https://aclanthology.org/2023.emnlp-main.585/)
- Anthology ID: 2023.emnlp-main.585 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "query2doc"는 희소하고 밀집한 정보 검색 시스템의 성능을 향상시키기 위한 간단하면서도 효과적인 쿼리 확장 접근 방법을 제안한다.
    2. 제안된 방법은 큰 언어 모델 (LLM)을 활용하여 의사문서를 생성한 다음, 생성된 의사문서를 사용하여 쿼리를 확장한다.
    3. 실험 결과, query2doc은 모델 파인튜닝 없이도 BM25의 성능을 3%에서 15% 향상시키며, 상위 성능 검색기에도 도메인 내 및 도메인 외 결과에 이점을 제공한다.

###### We Need to Talk About Reproducibility in NLP Model Comparison (https://aclanthology.org/2023.emnlp-main.586/)
- Anthology ID: 2023.emnlp-main.586 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 실제 NLP 태스크의 여러 모델을 비교할 때 NLP 연구자들은 자주 재현성 문제를 마주하게 된다. 많은 연구들에서 표준 데이터 분할은 재현 가능하고 신뢰할 수 없는 결론을 도출하게 되는 문제가 있으며, 이를 해결하기 위해 더 랜덤한 반복을 사용하는 방법도 시도되었다.
    2. 그러나 NLP 모델 간의 비교에서 재현성의 개선은 데이터 분할 전략에 의해 발생하는 추정기와 재현성의 관계에 대한 조사의 부족으로 제한되어 있다.
    3. 이 연구에서는 모델의 비교에서 재현성을 결론에 관한 확률적 함수로 정의하고, 재현성이 모델 성능 추정기의 신호 대 잡음 비율에 의해 정성적으로 지배된다는 것을 이론적으로 설명한다. 따라서 제안된 방법을 사용하여 NLP 모델을 비교하는 것을 권장한다.

###### Explore-Instruct: Enhancing Domain-Specific Instruction Coverage through Active Exploration (https://aclanthology.org/2023.emnlp-main.587/)
- Anthology ID: 2023.emnlp-main.587 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Instruction-tuning은 다양성을 개선함으로써 크기가 더 작은 작업 스펙트럼을 다룰 수 있는 모델을 만들 수 있지만, 기존 데이터는 개별 도메인의 불 충분한 커버리지로 인해 세부적인 이해와 상호작용이 제한된다. 따라서 우리는 Explore-Instruct라는 새로운 접근법을 제안하여 Large Language Models (LLMs)를 통해 도메인별 instruction-tuning 데이터의 커버리지를 향상시키는 활동적 탐색을 실시한다."
    2. "Explore-Instruct은 대표적인 도메인 사용 사례 위에 구축되었으며, 탐색 알고리즘을 이용하여 다양하고 도메인 중심적인 instruction-tuning 데이터를 얻는다."
    3. "우리의 결과는 도메인 별 커버리지를 개선하는 이 접근법의 효과를 검증하고, 도메인별 데이터를 사용하는 기존의 베이스라인을 포함한 여러 곳에서 상당한 발전을 이루었다는 것을 보여준다."

###### Practical Computational Power of Linear Transformers and Their Recurrent and Self-Referential Extensions (https://aclanthology.org/2023.emnlp-main.588/)
- Anthology ID: 2023.emnlp-main.588 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. RNN 아키텍처의 계층 구조를 고려한 연구에서, 선형화된 어텐션을 사용하는 자동회귀 Transformer인 LTs는 RNN과 동등한 기능을 하면서도 self-attention 네트워크로 표현될 수 있다는 것을 밝혔다.
    2. 표준 Transformer에 관한 잘 알려진 결과들이 LTs/FWPs에도 그대로 적용될 수 있다는 것을 보였다.
    3. 자세한 실험을 통해 재귀적인 FWPs와 자기 참조 가중치 행렬과 같은 최근의 FWP 확장이 LT의 특정한 제한을 극복하고, 예를들어 Parity 문제에서 일반화를 가능하게 한다는 것을 보였다.

###### InterFair: Debiasing with Natural Language Feedback for Fair Interpretable Predictions (https://aclanthology.org/2023.emnlp-main.589/)
- Anthology ID: 2023.emnlp-main.589 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. NLP 모델에서의 디바이스(bias) 제거 방법은 기존에는 민감한 속성 (예: 성별 또는 인종)과 관련된 정보를 제거하는 데 초점을 맞췄다. 
    2. 우리는 대신 이러한 민감한 정보를 피해하는 대신 설명과 함께 "공정하게" 사용해야 한다고 주장한다. 
    3. 두 가지 상호작용 설정에서 우리는 사용자의 피드백을 통해 작업 성능과 편향 완화 간에 더 나은 공정한 균형을 달성할 수 있다는 것을 보여주었다.

###### Just Adjust One Prompt: Enhancing In-Context Dialogue Scoring via Constructing the Optimal Subgraph of Demonstrations and Prompts (https://aclanthology.org/2023.emnlp-main.590/)
- Anthology ID: 2023.emnlp-main.590 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 현대 대형 언어 모델(Large Language Models, LLMs)을 챗봇으로 사용하는 것은 환영, 공감 부족 등의 문제를 가지고 있다. 이러한 문제를 식별하는 것은 챗봇의 성능 향상에 도움이 된다.
    2. 기존 LLM 기반의 metric은 특정 데이터셋을 선택하고 각각의 evaluation dimension(일관성, 정보성 등)에 맞는 훈련 작업을 개발하는 것을 요구한다. 이는 시간이 많이 소요되며 새로운 evaluation dimension에 대해 반복적으로 수행되어야 할 수도 있다.
    3. 우리는 대화 평가의 다양한 요구 사항에 효율적이고 유연하게 적응할 수 있는 차원에 구애받지 않는 점수 매기는 방법을 제안한다. 우리의 방법은 LLM의 in-context learning(ICL) 능력을 최대한 활용하여 인간의 평가 결과로부터 학습한다.

###### Multilingual estimation of political-party positioning: From label aggregation to long-input Transformers (https://aclanthology.org/2023.emnlp-main.591/)
- Anthology ID: 2023.emnlp-main.591 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Scaling analysis는 정치적 주체(예: 정치인 또는 정당)에 대해 (일반적으로 긴) 텍스트 집합(예: 국회 연설 또는 선거 선언문)을 기반으로 정의된 척도에 따라 점수를 매기는 컴퓨터 정치학 기술이다. 
    2. 이 연구에서는 정당 선언문에 대한 자동 스케일링 분석의 두 가지 접근 방식인 라벨 집계와 원시 텍스트에서 직접 스케일링 값을 계산하는 Transformer 기반 모델을 구현하고 비교한다. 
    3. 41개 국가와 27개 언어에 걸친 Comparative Manifestos Project 데이터셋의 분석 결과, 최신 모델을 통해 효율적으로 처리할 수 있으며, 라벨 집계가 가장 좋은 결과를 도출한다.

###### ART: rule bAsed futuRe-inference deducTion (https://aclanthology.org/2023.emnlp-main.592/)
- Anthology ID: 2023.emnlp-main.592 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 추론 기반 미래 이벤트 결론 도출을 위해 시각적 현상(비디오)과 규칙 기반 전제를 기반으로 올바른 미래 이벤트를 결론 짓는 ART (rule bAsed futuRe-inference deducTion)를 제안한다.
    2. 다양한 원격 감지 공용 지식을 활용하여 ARTNet을 개발하였고, ARTNet은 대상 비디오 캐릭터를 식별하고 미래 이벤트와 관련된 시각적 단서를 인지하는 방식으로 작동한다. 
    3. 실험적 연구를 통해 시각적 관찰을 통한 타당한 추론에 대한 ARTNet의 합리성과 기존 방법에 대한 효과성을 검증하였다.

###### EpiK-Eval: Evaluation for Language Models as Epistemic Models (https://aclanthology.org/2023.emnlp-main.593/)
- Anthology ID: 2023.emnlp-main.593 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인공지능 시대에서는 대형 언어 모델의 역할이 점점 중요해지고 있다. 그러나 이러한 모델들이 다양한 학습 문서로부터 지식을 효과적으로 통합하는 능력은 아직 탐구되지 않았다.
    2. 본 논문에서는 LLMs의 이러한 정보 통합 능력을 조사한 최초의 연구를 제시한다. 이를 위해 LLMs의 능력을 평가하기 위한 새로운 질문-답변 벤치마크인 EpiK-Eval을 도입했다.
    3. 다양한 LLMs에 대한 평가 결과, 이 영역에서 상당한 약점이 드러났다. 불충분한 학습 목표의 본질에 기인한 것으로 보인다. 그 결과, 지식 통합을 개선하기 위한 방법을 추진하여 LLMs의 전반적인 효과성과 성능을 대폭 향상시킬 수 있다고 주장한다.

###### From Dissonance to Insights: Dissecting Disagreements in Rationale Construction for Case Outcome Classification (https://aclanthology.org/2023.emnlp-main.594/)
- Anthology ID: 2023.emnlp-main.594 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 법적 NLP에서의 Case Outcome Classification(COC)은 정확성 뿐만 아니라 신뢰성과 설명 가능성도 갖추어야 한다. 기존의 설명 가능한 COC 연구는 단일 전문가의 주석에 한정되어 있다.
    2. 이 논문에서는 국제 인권법 분야에서의 두 전문가의 약한 합의를 바탕으로한 새로운 데이터셋 RaVE를 수집하여 그들의 분쟁을 연구하고, COC특수 부분 범주를 보완하는 데 사용된다.
    3. 이 연구는 법적 NLP에서 사례의 사실과 관련된 측면을 식별하는 것을 중심으로하는 벤치마크 데이터셋을 작성하는 데 있어서 간과된 복잡성을 밝히고 있다.

###### On Bilingual Lexicon Induction with Large Language Models (https://aclanthology.org/2023.emnlp-main.595/)
- Anthology ID: 2023.emnlp-main.595 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다국어 NLP의 핵심 과제인 BLI(Bilingual Lexicon Induction)는 아직 크로스-언어 단어 표현 계산에 의존하고 있는데, 이 논문에서는 최신 세대의 큰 언어 모델 (LLM)이 이를 보완할 수 있는 잠재력을 검토하고 있다.  
    2. 이 논문은 multilingual LLM(mLLM)에 대해 제공과 세밀한 조정(fine-tune)을 통해 BLI를 수행할 수 있는지 그 방법과, 기존의 접근 방식과 어떻게 구분될 수 있는지 연구하고 있다. 
    3. 연구 결과는 mLLM에 대한 zero-shot prompting, few-shot in-context prompting, 그리고 표준적인 BLI에 특화된 fine-tuning의 성능을 실험적으로 검증하여, mLLM이 강력한 BLI 능력을 보여주고 있다는 것을 보여준다.

###### Statistical Depth for Ranking and Characterizing Transformer-Based Text Embeddings (https://aclanthology.org/2023.emnlp-main.596/)
- Anthology ID: 2023.emnlp-main.596 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Transformer 기반 텍스트 임베딩의 인기로 인해 이러한 임베딩의 분포를 측정하기 위한 통계 도구가 필요하다. 따라서 본 논문에서는 문장을 중심으로 한 텍스트 임베딩 (TTE) depth를 측정하기 위한 통계적 방법과 이를 자연어처리 파이프라인에서 모델링과 분포적 추론에 활용하는 방법을 제안한다. 
    2. 우선 TTE depth와 관련된 rank sum test를 정의하고, 두 개의 말뭉치가 임베딩 공간에서 유의미하게 다른지 여부를 확인하기 위해 사용한다. 
    3. 그리고 TTE depth와 해당 rank sum test를 사용하여 합성된 데이터와 인간이 생성한 데이터 간의 분포 차이를 측정하여 최근의 합성 데이터 증강 방법이 인간이 생성한 텍스트와 유의미한 분포 변화를 일으키는 것을 보여준다.

###### CRaSh: Clustering, Removing, and Sharing Enhance Fine-tuning without Full Large Language Model (https://aclanthology.org/2023.emnlp-main.597/)
- Anthology ID: 2023.emnlp-main.597 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에는 대규모 언어 모델의 일반화 능력 향상을 위해 인스트럭션 튜닝이 효과적으로 인식되었으나, 공개적으로 접근 가능한 중앙 언어 모델을 개인적인 인스트럭션 데이터로 튜닝하는 경우, 개인 정보 보호 문제가 필연적이다.
    2. 이 논문은 Offsite-Tuning (OFT)에 초점을 맞추고, centralized LLMs와 downstream emulators 사이에서 transformer 블록을 전송하는 대표적인 기술이다. 
    3. 연구 결과, LLM의 레이어에서 독특한 모듈 구조가 나타나며, 튜닝과 중간 예측 사이에서 미묘하지만 중요한 표현에 변화가 있다는 사실을 밝혀냈다. 이를 바탕으로 CRaSh를 제안하여 OFT의 성능을 대폭 향상시켰다.

###### From Multilingual Complexity to Emotional Clarity: Leveraging Commonsense to Unveil Emotions in Code-Mixed Dialogues (https://aclanthology.org/2023.emnlp-main.598/)
- Anthology ID: 2023.emnlp-main.598 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화 중 감정을 이해하는 것은 인간의 소통에서 중요한 요소로, Emotion Recognition in Conversation(ERC)을 위한 NLP 연구를 촉발시킨다. 이 연구의 동기는 언어 혼용 대화에서의 감정적인 다이내믹스를 이해하는 것이 상대적으로 덜 연구되었다는 것이다.
    2. 우리는 감정적 지능이 세상적인 지식을 포함하는 것이라고 인식하며, 단순한 정보를 대화의 맥락과 통합해 감정을 깊게 이해할 수 있는 혁신적인 접근법을 제안한다.
    3. 우리의 실험 결과는 상식을 ERC에 체계적으로 통합함으로써 상당한 성능 향상을 얻을 수 있음을 보여주며, 양적 평가와 질적 분석은 우리의 가설의 타당성을 뒷받침하며, ERC에서의 상식 통합의 중요성을 또한 확인한다.

###### Large Language Models are biased to overestimate profoundness (https://aclanthology.org/2023.emnlp-main.599/)
- Anthology ID: 2023.emnlp-main.599 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. GPT-4와 다른 LLMs(대형 언어 모델)에 대한 연구에서, 일상적인, 동기 부여, 의사 강조한 문장의 심오성을 판단하는 능력을 인공지능 모델들이 인간과 유사한 추론 능력을 가졌는지 여부가 논쟁 중이다.
    2. 모든 유형의 문장과 유형에 상관없는 확인기법을 사용하여 LLMs와 사람들 간에 문장 간의 상관관계가 있었다는 것을 발견했다.
    3. 그러나, LLMs는 비문 같은 문장의 심오함을 과장 평가했으며, Tk-instruct는 문장의 심오함을 예외적으로 과소평가했다. 몇 가지 샷 학습 방법은 LLMs 평가를 사람들과 가깝게 만들었다. 또한, RLHF로 인한 잠재적인 편향에 대한 통찰력을 제공하며, 이는 문장의 심오함을 과장 평가하는 편향 증가를 유발한다.

###### SummEdits: Measuring LLM Ability at Factual Reasoning Through The Lens of Summarization (https://aclanthology.org/2023.emnlp-main.600/)
- Anthology ID: 2023.emnlp-main.600 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 LLMs (Large Language Models)를 실제 환경에서 사용하면, 사실적인 불일치(factual inconsistencies)를 효과적으로 감지할 수 있는 방법이 사실 정보의 확산을 줄이고 모델의 결과에 대한 신뢰를 향상시키는 데 중요하다. 
    2. 우리는 기존 평가 척도의 문제점을 발견하여 inconsistency detection benchmark에 대한 새로운 프로토콜을 제안하였고, 이를 10개 도메인에 대해 구현한 SummEdits 벤치마크에 적용하였다. 
    3. 대부분의 LLM은 SummEdits에서 성능이 무작위 수준에 가까우며, 최고의 모델인 GPT-4도 인간의 성능 추정치보다 8% 낮은 성능을 보여주고 있어 LLM의 사실 추론 능력과 불일치 감지 능력의 한계를 보여준다.

###### DIVE: Towards Descriptive and Diverse Visual Commonsense Generation (https://aclanthology.org/2023.emnlp-main.601/)
- Anthology ID: 2023.emnlp-main.601 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "인간 수준의 시각적 이해를 위해, 시각적 공통 감각 생성은 이미지를 넘어서는 시각적 추론을 생성하는 데 도입되었다. 그러나 현재의 시각적 공통 감각 생성 연구는 기술적이고 다양한 추론 생성을 생각해내는 중요한 인지 능력을 간과하고 있다."
    2. "이 논문에서는 생성된 추론의 기술성과 다양성을 향상시키기 위한 새로운 시각적 공통 감각 생성 프레임워크인 DIVE를 제안한다."
    3. "실험 결과는 DIVE가 기존 모델들에 비해 기술성과 다양성 측면에서 뛰어나며, 독특하고 새로운 추론 생성에 우수한 품질을 보인다는 것을 확인하였다. 또한, 인간 평가를 통해 DIVE가 기술성과 다양성에서 인간 판단과 일치하는 것을 확인하였다."

###### Towards Conceptualization of “Fair Explanation”: Disparate Impacts of anti-Asian Hate Speech Explanations on Content Moderators (https://aclanthology.org/2023.emnlp-main.602/)
- Anthology ID: 2023.emnlp-main.602 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 AI 설명 가능성과 공정성의 교차점에서의 연구는 설명이 공정성 지표에 의해 측정된 사람과 AI의 작업 성능을 향상시킬 수 있는지에 초점을 맞추고 있다. 
    2. 우리는 "공정성"을 가진 설명이 무엇인지를 정의하고, 특정 인구에 부정적인 영향을 미치지 않는 설명을 제시한다. 
    3. 우리는 정확성과 라벨링 시간뿐만 아니라 설명이 다른 사용자 그룹에 미치는 심리적 영향(metal discomfort, stereotype activation, 그리고 perceived workload)을 포함한 여러 메트릭을 사용하여 "공정한 설명"의 새로운 평가 방법을 제안한다.

###### Bridging Background Knowledge Gaps in Translation with Automatic Explicitation (https://aclanthology.org/2023.emnlp-main.603/)
- Anthology ID: 2023.emnlp-main.603 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 번역은 사람들이 다른 언어로 작성된 콘텐츠를 이해하는 데 도움이 된다. 그러나 필요한 배경 지식이 없는 사람들에게는 정확한 문장 번역만으로는 충분하지 않을 수 있다.
    2. 본 논문에서는 언어 간 질문-응답 프레임워크에서 질문에 더 정확한 답변을 할 수 있도록 도와줄 수 있는 explicitation을 자동으로 생성하는 기술을 소개한다.
    3. 이를 위해, Wikipedia에서 수집한 데이터셋인 WikiExpl을 사용하여 인간 번역자들에 의해 명확하게 표시된 explicitation을 자동으로 생성하는 기술을 소개한다.

###### A Quality-based Syntactic Template Retriever for Syntactically-Controlled Paraphrase Generation (https://aclanthology.org/2023.emnlp-main.604/)
- Anthology ID: 2023.emnlp-main.604 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 SPG 모델들은 인간이 주석을 달거나 잘 선택된 문법 템플릿과 함께 사용될 때 유리한 성과를 보이지만, 이런 템플릿을 얻는 것은 실제 적용을 방해하는 어려움이 있다.
    2. 이 논문에서는 생성될 패러프레이즈의 품질에 기반하여 템플릿을 검색하는 Quality-based Syntactic Template Retriever(QSTR)를 제안한다. 또한, 한 문장에 대해 여러 개의 패러프레이즈가 필요한 상황에서 동질성을 희생시키지 않고 다양성을 높일 수 있는 Diverse Templates Search(DTS) 알고리즘도 제안한다.
    3. 실험 결과, QSTR은 고품질 패러프레이즈를 생성하는 기존의 검색 방법을 크게 능가하며, reference-free 지표에서에서는 인간 주석과 비교 가능한 성과를 보인다. 또한, 데이터 증강을 위해 생성된 패러프레이즈를 사용한 인간 평가 및 하위 태스크 성능은 QSTR과 DTS 알고리즘의 잠재력을 실제 상황에서도 보여준다.

###### Beyond Shared Vocabulary: Increasing Representational Word Similarities across Languages for Multilingual Machine Translation (https://aclanthology.org/2023.emnlp-main.605/)
- Anthology ID: 2023.emnlp-main.605 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다국어 신경 기계 번역 (MNMT)에서 공유 어휘를 사용하는 것은 일반적인 방법이다. 공유 어휘는 간단한 설계에 더해, 일치하는 의미를 가지는 경우 지식을 전달하는데 중요한 역할을 한다. 그러나 서로 다른 문자 체계를 사용할 때 같은 단어가 적으면 transfer가 억제된다.
    2. 이 논문에서는 이 문제를 완화하기 위해 임베딩을 구축하기 위한 다시 매개화된 방법을 제안한다. 구체적으로, 우리는 단어 등급 동치류를 통해 단어 수준의 정보 전달 경로를 정의하고, 그래프 네트워크를 사용하여 언어 간에 단어 임베딩을 통합한다.
    3. 실험 결과, 우리의 방법은 임베딩의 의미가 다국어로 잘 맞아 떨어지고, 고저 리소스 MNMT에서 확실한 BLEU 개선을 달성하며, 추가적인 학습 가능한 매개 변수는 1.0% 미만이며 계산 비용은 제한적으로 증가하나 추론 시간은 기준선과 동일하다.

###### Quantifying the redundancy between prosody and text (https://aclanthology.org/2023.emnlp-main.606/)
- Anthology ID: 2023.emnlp-main.606 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 회화의 중요한 측면을 전달하는 운율(prosody)과 단어 사이의 정보 관계는 아직 잘 알려져 있지 않다.
    2. 이 연구에서는 큰 언어 모델(Large Language Models, LLMs)을 사용하여, 운율과 단어 사이의 중복된 정보량을 추정한다.
    3. 연구 결과, "intensity, duration, pauses, and pitch contours"와 같은 여러 운율적 특징들이 단어와 중복된 정보를 가지고 있음을 보여준다.

###### CRoW: Benchmarking Commonsense Reasoning in Real-World Tasks (https://aclanthology.org/2023.emnlp-main.607/)
- Anthology ID: 2023.emnlp-main.607 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 자연어처리(NLP) 공감 판단 연구에서는 많은 새로운 데이터셋과 벤치마크가 생성되었지만, 대부분의 데이터셋은 실제 NLP 시스템이 해결하는 실제 과제와 관련이 없는 인공적인 시나리오에서 공감 판단 도전 과제를 구성한다.
    2. 이 연구에서는 CRoW라고 불리는 수동으로 정리된 다중 작업 벤치마크를 제공하여 모델이 실제 세계의 NLP 작업에 공감 판단을 적용하는 능력을 평가한다.
    3. CRoW를 사용하여 물리적, 시간적, 사회적 추론과 같은 다양한 차원의 공감지식에서 NLP 시스템의 성능을 연구하였으며, 인간과 비교했을 때 NLP 시스템의 성능 차이가 크며, 공감 판단은 실제 과제 설정에서 해결되어야 할 문제임을 보여주었다.

###### A Video Is Worth 4096 Tokens: Verbalize Story Videos To Understand Them In Zero Shot (https://aclanthology.org/2023.emnlp-main.608/)
- Anthology ID: 2023.emnlp-main.608 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 광고 및 스토리 비디오와 같은 멀티미디어 콘텐츠는 창의성과 여러 가지 모드의 풍부한 결합을 보여줍니다. 이 논문에서는 이러한 모델링 결합을 위해 장문 비디오를 자연어로 표현하여 생성하고, 생성된 이야기에 대한 비디오 이해 작업을 원본 비디오가 아닌 이야기에 적용하는 방법을 제안합니다.
    2. 이 연구는 제로샷 학습만으로도 만족스러운 성능을 가진 감독 학습 모델을 개발하기 어려운 멀티미디어 도메인의 문제를 해결하기 위해, 대규모 언어 모델(Large Language Models, LLMs)를 활용합니다.
    3. 연구 결과 제로샷 방법을 사용하더라도, 동영상 이해 작업에서 감독된 기준선 대비 크게 향상된 결과를 얻을 수 있으며, 컴퓨팅 사회과학에서 중요한 심리 전략 식별에 대한 첫 번째 데이터 세트를 공개합니다.

###### Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning (https://aclanthology.org/2023.emnlp-main.609/)
- Anthology ID: 2023.emnlp-main.609 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 큰 언어 모델(Large Language Models)은 다양한 작업을 수행하기 위해 자기 학습을 하는 것이라는 연구 결과를 통해 자신이 주어진 context에서 학습하는 방법의 작동 메커니즘을 조사했다. 
    2. 탐색 결과로, 레이블 단어는 앵커로 작용하며, 레이블 단어의 의미 정보가 얕은 계산 레이어의 처리 중에 결합되고 레이블 단어에서 합쳐진 정보가 최종 예측의 참고로 작용한다는 것을 밝혀냈다.
    3. 이 연구를 바탕으로, 앵커 가중치 조정 방법을 소개하여 ICL 성능을 향상시키고, 추론 과정을 가속화하기 위한 예시 압축 기법 및 GPT2-XL에서 ICL 오류를 진단하기 위한 분석 프레임워크를 제안한다.

###### Prompting Scientific Names for Zero-Shot Species Recognition (https://aclanthology.org/2023.emnlp-main.610/)
- Anthology ID: 2023.emnlp-main.610 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 교육적 가치를 고려하지 않은 기존 평가 메트릭은 MCQ 생성의 학습 평가에 제약이 있다.
    2. 우리는 지식 종속 가능성(KDA)이라는 새로운 메트릭을 제안하여 MCQ의 대답 가능성을 측정하고 대상 사실의 학생 지식을 평가한다.
    3. 실험 결과, KDA_disc와 KDA_cont는 실제 강의 세팅에서의 사용성과 강한 상관관계가 있음을 보여준다.
    
    1. 최근의 NLP 모델은 높은 정확성을 보이지만, spurious pattern에 의존하여 robustness가 제한되는 문제가 있다.
    2. 기존 augmentation 방법들은 spurious correlation에 영향을 받는데, 이 논문에서는 "여러 개의" counterfactual을 생성하여 robust하게 인과관계를 파악하는 방법을 제안한다.
    3. 실험 결과, 집합적 의사 결정 방법을 통해 기존 방법에 비해 더 robust한 성능과 다양한 차원에서 향상된 성능을 얻을 수 있다.
    
    1. 일반적인 대상 사물인 이미지를 zero-shot 방식으로 인식하는 CLIP과 같은 VLM의 특화된 개념, 예를 들어, 새, 식물, 동물의 종을 고유하게 인식하는 방법에 대한 연구는 적다.
    2. 이 논문에서는 CLIP을 통한 zero-shot 종 인식에서 라틴어나 그리스어로 된 과학 이름을 사용한 프롬프트의 성능이 낮다고 보고한다.
    3. 대신에, 우리는 과학 이름을 영어로 번역하여 프롬프트에 사용함으로써 성능을 향상시킬 수 있음을 보고한다.

###### Active Learning for Natural Language Generation (https://aclanthology.org/2023.emnlp-main.611/)
- Anthology ID: 2023.emnlp-main.611 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 생성(NLG) 분야는 수작업 주석이 매우 비싸고 시간이 많이 소요되므로 레이블이 지정된 데이터의 심각한 부족으로 고통받고 있다.
    2. 이 논문에서는 NLG에 대한 active learning (AL)을 첫 번째 체계적인 연구로 제안하며, 다양한 작업과 여러 가지 선도적인 선택 전략을 고려한 강력한 instruction-tuned 모델을 활용한다.
    3. 기존의 AL 전략의 성능은 일관성이 없으며, 일부 경우에서는 무작위 예제 선택의 기준선을 뛰어넘을 수 있지만, 다른 경우에는 그렇지 않다는 사실을 발견하였다. 그리고 분류와 생성 시나리오 간에 몇 가지 주목할만한 차이점을 강조하고, 기존의 AL 전략의 선택 동작을 분석한다. 이러한 연구 결과는 생성 작업에 AL을 적용하기 위한 새로운 접근 방식을 탐구하는 동기를 부여한다.

###### Re3Dial: Retrieve, Reorganize and Rescale Conversations for Long-Turn Open-Domain Dialogue Pre-training (https://aclanthology.org/2023.emnlp-main.612/)
- Anthology ID: 2023.emnlp-main.612 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화 모델의 장거리 맥락 활용 능력이 한계가 있다. 이를 해결하기 위해 우리는 기존의 짧은 대화를 재구성하여 수십억 개의 장대화를 자동으로 구축할 수 있는 Retrieve, Reorganize and Rescale framework (Re3Dial)을 제안한다. 
    2. Re3Dial은 세션 리트리버를 사용하여 의미론적 및 담화적 관계를 통해 멀티턴 대화를 포착하고, 이를 바탕으로 응답 생성에 활용한다. 
    3. 여러 개의 대화를 재구성하여 장거리 대화를 구축하는 Re3Dial은 대화 모델의 맥락 파악 능력을 크게 향상시키며 동시에 보다 합리적이고 유익한 응답을 생성할 수 있다. 이를 위해 우리는 Re3Dial을 위한 툴킷과 데이터를 공개할 것이다.

###### MultiTurnCleanup: A Benchmark for Multi-Turn Spoken Conversational Transcript Cleanup (https://aclanthology.org/2023.emnlp-main.613/)
- Anthology ID: 2023.emnlp-main.613 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 불플루언시 검출 모델은 한 명의 화자로부터 나오는 각각의 말투에 초점을 맞추고 있다. 그러나 실제 회화 텍스트에서는 여러 턴에 걸쳐 발생하는 다양한 불연속 현상이 있기 때문에, 기존의 모델로는 식별할 수 없다. 
    2. 이 연구는 회화 텍스트를 위한 혁신적인 다중 턴 청소 작업과 새로운 데이터셋인 MultiTurnCleanup을 제안함으로써 이러한 현상에 대응한다. 
    3. 고품질 데이터셋을 수집하기 위해 데이터 라벨링 스키마를 설계하고, 실험적 평가를 위해 미래 연구의 벤치마크로 두 가지 모델링 접근 방식을 활용한다.

###### Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models (https://aclanthology.org/2023.emnlp-main.614/)
- Anthology ID: 2023.emnlp-main.614 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어 모델 API는 최근 연구 프로토타입에서 상용 제품으로 진화하여 다국어 기능을 갖춘 제품으로 제공되고 있다. 그러나 토큰 처리량에 따라 API 사용자에게 요금이 부과되는데, 토큰이란 것은 훈련 데이터와 모델에 따라 다르며, 다른 언어로 동일한 정보를 전달하기 위해서는 토큰 수에 큰 차이가 있다.
    2. 이 논문에서는 다양한 언어로 구성된 다국어 벤치마크에서 OpenAI 언어 모델 API의 비용과 유틸리티에 대한 체계적인 분석을 실시하였다.
    3. 분석 결과, API가 지원하는 많은 언어 사용자들이 비싼 가격을 지불하면서도 좋지 않은 결과를 얻고 있다는 것을 보여주었다. 이들 사용자들은 원래 API가 접근성이 떨어지는 지역에 살고 있다. 이러한 분석을 통해 언어 모델 API의 가격 정책에 대한 투명성을 높이고, 공정하게 만들기 위해 API 제공 업체들을 독려하고자 한다.

###### Characterizing Mechanisms for Factual Recall in Language Models (https://aclanthology.org/2023.emnlp-main.615/)
- Anthology ID: 2023.emnlp-main.615 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어 모델은 사전 훈련된 기억한 사실들과 주어진 문맥에서 나타나는 새로운 정보를 통합해야 하는데, 이 두 소스는 일치하지 않을 수 있으며 어떻게 모델이 이러한 충돌을 해소할지 불확실하다.
    2. 이 연구에서는 세계 수도에 대한 정보를 질의하는 데이터셋을 사용하여, 분포적인 결정 요소와 메커니즘적인 결정 요소를 조사하였다.
    3. 표현적 결정 요소인 head attribution을 사용하여, 모델이 메모리스한 답변 또는 문맥 속 답변을 사용하는 attention head를 식별하고, 이러한 head의 값을 조절하여 모델의 동작을 제어할 수 있다는 것을 입증하였다.

###### MULTITuDE: Large-Scale Multilingual Machine-Generated Text Detection Benchmark (https://aclanthology.org/2023.emnlp-main.616/)
- Anthology ID: 2023.emnlp-main.616 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 LLMs가 영어 이외의 언어로 납득할만한 텍스트를 생성하는 능력과 다국어 환경에서 기계 생성 텍스트 감지기의 성능에 대한 연구가 부족하다.
    2. 우리는 MULTITuDE라는 새로운 벤치마킹 데이터셋을 소개하여 11개 언어 (ar, ca, cs, de, en, es, nl, pt, ru, uk, and zh)에서 생성된 74,081개의 인증 및 기계 생성 텍스트로 구성되어 있다. 이 벤치마크를 통해 우리는 제로샷(통계적 및 블랙박스)와 파인튜닝된 감지기의 성능을 비교한다.
    3. 이 연구에서는 다국어성을 고려하여 이 감지기들이 보지 않은 언어 (언어적으로 유사한 언어 및 다른 언어)와 보지 않은 LLMs에 얼마나 일반화되는지 그리고 여러 언어에서 훈련되었을 때 감지기의 성능이 향상되는지를 평가한다.

###### Revisiting Block-based Quantisation: What is Important for Sub-8-bit LLM Inference? (https://aclanthology.org/2023.emnlp-main.617/)
- Anthology ID: 2023.emnlp-main.617 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델 (LLMs)의 추론은 많은 계산 및 메모리 자원이 필요하다. 본 논문에서는 8비트에 중점을 둔 기존 LLM 양자화와는 달리, LLM 레이어의 통계 및 학습 특성을 탐구하고 LLM 양자화의 병목 현상을 숫자 스케일링 오프셋에 돌려놓는다고 주장한다.
    2. 그래서 우리는 LLMs에 대한 블록 양자화 방법을 적용하여 계산 경로에 대한 추가적인 처리 없이 단순히 산술적으로 숫자 스케일링 오프셋을 감소시킴으로써 이 문제에 대처합니다. 
    3. 우리의 실험 결과는 기존 8비트 양자화보다 산술 밀도에서 2.5배, 메모리 밀도에서 1.2배 우수한 성능을 보여주며, 다운스트림 작업에서 거의 손실이 없는 4비트 LLM의 성능을 구현하는 것과 같은 하위-8비트 LLM 양자화에 대한 인사이트를 제공한다.

###### Whispering LLaMA: A Cross-Modal Generative Error Correction Framework for Speech Recognition (https://aclanthology.org/2023.emnlp-main.618/)
- Anthology ID: 2023.emnlp-main.618 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 자동 음성 인식에서 생성적 오류 교정을 위한 새로운 교차 모달 융합 기술을 소개한다. 
    2. 우리의 방법론은 음향 정보와 외부 언어 표현을 함께 사용하여 정확한 음성 전사 맥락을 생성한다.
    3. ASR 성능을 향상시키기 위해 초기화 기술과 파라미터 효율적 알고리즘을 사용하는 우리의 접근 방식은 n-best Oracle 대비 37.66%의 단어 오류율(WER) 성능 향상을 보여준다.

###### Reducing Sequence Length by Predicting Edit Spans with Large Language Models (https://aclanthology.org/2023.emnlp-main.619/)
- Anthology ID: 2023.emnlp-main.619 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 대규모 언어 모델(Large Language Models)은 다양한 작업에서 놀라운 성능을 보여주며 큰 관심을 받고 있다. 하지만 이러한 모델들은 문법 오류 교정이나 형식성 스타일 변환과 같은 지역 시퀀스 전이 작업에서는 입력 텍스트와 출력 텍스트의 차이가 최소하기 때문에 변화 없이 입력 텍스트를 단순히 복사하는 경향이 있다. 이 논문에서는 이러한 문제를 해결하기 위해 원본 텍스트에 대한 편집 범위를 예측하여 대상 시퀀스의 길이와 계산 비용을 줄일 수 있는 방법을 제안한다. 
    2. 제안된 방법은 LLM(Large Language Models)에 대한 instruction tuning을 적용하여 편집 범위의 감독 데이터를 사용한다. 실험 결과, 제안된 방법은 줄어든 대상 텍스트 길이에도 불구하고, 요약, 형식성 스타일 변환, 문법 오류 교정, 텍스트 단순화와 같은 4가지 작업에서 기준 모델과 비교할 만한 성능을 달성한다. 
    3. 또한, 제안된 방법과 함께 작업별 세부 튜닝을 수행한 결과, 이 4가지 작업에서 최고 성능을 달성한 것을 보고하였다.

###### Instruct and Extract: Instruction Tuning for On-Demand Information Extraction (https://aclanthology.org/2023.emnlp-main.620/)
- Anthology ID: 2023.emnlp-main.620 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대용량 언어 모델은 지시 따르기 능력로 더 많은 사용자에게 오픈되었으나, 대부분의 작업 특정 시스템은 비전문가 사용자를 위한 long-tail ad hoc 추출 사용 사례에 잘 맞지 않는다. 
    2. 이 논문에서는 On-Demand Information Extraction이라는 새로운 패러다임을 제안하여 실제 사용자의 개인화된 요구를 충족시키기 위한 작업을 소개한다. 
    3. 우리의 벤치마크인 InstructIE에서 ODIE를 개발하여 umaple-size의 기존 오픈소스 모델보다 상당히 우수한 성능을 보여준다는 평가 결과를 보여주었다.

###### Rethinking the Evaluation for Conversational Recommendation in the Era of Large Language Models (https://aclanthology.org/2023.emnlp-main.621/)
- Anthology ID: 2023.emnlp-main.621 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 대형 언어 모델 (LLM)의 성공은 사용자 요구를 충족하기 위해 자연어 대화에 의존하는 강력한 대화식 추천 시스템 (CRS)을 개발하는 데 많은 잠재력을 보여주었습니다. 이 논문에서는 CRS에 ChatGPT를 활용하는 연구에 착수하며, 기존의 평가 프로토콜의 부족함을 밝혀냅니다. 이는 인간이 주석으로 표시한 ground-truth 항목과의 일치를 지나치게 강조하고 CRS의 상호작용적 성격을 간과할 수 있습니다.
    2. 이러한 제한을 극복하기 위해 우리는 LLM 기반 사용자 시뮬레이터를 활용한 대화형 평가 접근법인 iEvaLM을 제안합니다. 우리의 평가 접근법은 다양한 시스템-사용자 상호작용 시나리오를 시뮬레이션할 수 있습니다.
    3. 두 개의 공개 CRS 데이터셋을 사용한 실험을 통해 우리는 기존의 평가 프로토콜에 비해 상당한 개선을 보여줍니다. 또한, 설명 가능성의 평가를 강조하며, ChatGPT는 추천에 대한 설득력 있는 설명 생성을 보여줍니다. 우리의 연구는 CRS에 LLM의 미개척된 잠재력에 대한 깊은 이해에 기여하며, LLM 기반 CRS에 대한 보다 유연하고 현실적인 평가 접근법을 제공합니다.

###### ReCEval: Evaluating Reasoning Chains via Correctness and Informativeness (https://aclanthology.org/2023.emnlp-main.622/)
- Anthology ID: 2023.emnlp-main.622 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 태스크에서 다단계 추론 능력은 매우 중요하지만, 좋은 추론 체인이 무엇이고 이를 어떻게 평가해야 하는지는 여전히 불확실하다.
    2. 기존 방법들은 추론 체인이 올바른 결론으로 이어질 수 있는지만 확인하는데 초점을 맞추고 있는데, 이러한 답변 중심의 접근은 추론의 품질과 답을 예측하기 위한 부적절한 바이어스를 혼동시킬 수 있다.
    3. 따라서 본 논문에서는 이러한 문제를 해결하기 위해 추론 체인을 최종 답변으로의 의미론적 증명으로 평가하는 ReCEval (Reasoning Chain Evaluation) 방법을 제안하고, 이를 통해 기존 방법들보다 향상된 성능을 얻을 수 있다는 것을 실험적으로 입증하였다.

###### Expand, Highlight, Generate: RL-driven Document Generation for Passage Reranking (https://aclanthology.org/2023.emnlp-main.623/)
- Anthology ID: 2023.emnlp-main.623 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에는 랭킹 모델을 위해 대규모 언어 모델(LLMs)을 기반으로 가상 훈련 데이터를 생성하는 것이 주목받고 있다. 이 논문에서는 데이터 증강의 새로운 관점을 제안하여 쿼리로부터 가상 문서를 생성하는 방법을 소개한다.
    2. DocGen 파이프라인은 LLMs의 few-shot 기능을 활용하여 가상 문서 생성을 수행한다. 이를 위해 (i) 쿼리 확장, (ii) 원래 쿼리 강조, (iii) 쿼리와 관련성이 높을 것으로 예상되는 가상 문서 생성 순서로 진행된다.
    3. DocGen-RL은 가상 문서의 쿼리와의 관련성을 보상으로 여기고 강화학습(RL)을 활용하여 DocGen 파이프라인을 최적화하는 방법을 제안한다. DocGen 파이프라인과 DocGen-RL은 기존의 InPars와 같은 데이터 증강 방법을 크게 능가하는 것을 실험적으로 입증하였다.

###### Transformer-based Live Update Generation for Soccer Matches from Microblog Posts (https://aclanthology.org/2023.emnlp-main.624/)
- Anthology ID: 2023.emnlp-main.624 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 수 많은 다양한 라이브 트윗들의 시퀀스에서 적절한 스포츠 업데이트를 생성하는 것은 어려웠으나, 트윗과 함께하는 생중계 스포츠 시청 경험이 인기를 얻고 있다. 
    2. 본 논문에서는 축구 경기에 초점을 맞추어, 사용자가 원 raw 트윗들로부터 경기 진행 상황을 실시간으로 파악하고 경기의 흥미를 즐길 수 있는 시스템을 구축하는 것에 초점을 두고 있다. 
    3. 우리의 제안된 시스템은 대규모 사전 학습된 언어 모델을 기반으로 하며, 업데이트 수를 제어하는 메커니즘과 중복 및 유사한 업데이트의 중복성을 줄이는 메커니즘을 포함하고 있다.

###### Make Every Example Count: On the Stability and Utility of Self-Influence for Learning from Noisy NLP Datasets (https://aclanthology.org/2023.emnlp-main.625/)
- Anthology ID: 2023.emnlp-main.625 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 현재 NLP에서 데이터셋의 크기가 점점 커지면서 성과 향상에 있어 데이터의 품질이 병목이 되는 경우가 많다. 
    2. 이 논문에서는 태스크에 대해 독립인 (task-agnostic) self-influence 점수를 이용하여 데이터 정제를 수행하고, 이 방법이 자연스러운 이상값을 잡아내는 데 얼마나 효과적인지 연구하였다. 
    3. 자기 영향에 기반한 데이터 정제가 기계 번역, 질문 응답, 텍스트 분류 등에서 성능 향상을 얼마나 가져오는지를 연구하였다.

###### Appraising the Potential Uses and Harms of LLMs for Medical Systematic Reviews (https://aclanthology.org/2023.emnlp-main.626/)
- Anthology ID: 2023.emnlp-main.626 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 의료 체계적 문헌고찰(Medical systematic reviews)은 건강 관련 결정과 정책 결정에 핵심적인 역할을 한다. 그러나 이러한 문헌고찰 작성은 시간이 많이 소요되어 고품질이고 최신의 증거 요약이 제한된다.
    2. 최근 LLMs의 발전은 이 문제를 해결하기 위해 필요한 문헌고찰들을 필요에 따라 자동으로 생성할 수 있는 잠재력을 제공한다. 그러나, LLMs는 man. hallucination(환각)이나 omission(생략)에 의해 정확하지 않고 잘못된 텍스트를 생성하기도 한다.
    3. 이 연구에서는 국제적인 체계적 문헌고찰 전문가들과의 16번의 인터뷰를 통해 의료 증거분석 문맥에서 LLMs의 유용성과 위험을 규명하고, 이에 따라 생물의학적 LLMs의 엄격한 평가 기준을 제시한다.

###### PromptST: Abstract Prompt Learning for End-to-End Speech Translation (https://aclanthology.org/2023.emnlp-main.627/)
- Anthology ID: 2023.emnlp-main.627 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 음성-텍스트 번역 (S2T) 모델에서 음성과 텍스트 특징을 어떻게 통합하는지에 대한 이해에 첫걸음을 내딛었다.
    2. S2T 모델의 상단 인코더 층이 언어 지식을 효율적으로 학습하지 못하여 번역 정확성에 중요한 영향을 미친다는 것을 밝혀냈다.
    3. 이를 바탕으로 우리는 S2T 모델의 상위 인코더 층에 간단한 플러그인 프롬프트 학습 전략을 제안하여 보다 추상적인 표현력을 갖춘 PromptST 모델을 개발하였다.

###### Text Rendering Strategies for Pixel Language Models (https://aclanthology.org/2023.emnlp-main.628/)
- Anthology ID: 2023.emnlp-main.628 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 픽셀 기반 언어 모델은 이미지로 렌더링된 텍스트를 처리하여 어떤 스크립트든 다룰 수 있기 때문에, 여는 어휘 언어 모델링에 유망한 접근법이다. 그러나 최근의 접근법은 거의 동일한 입력 패치를 생성하는 텍스트 렌더러를 사용하는데, 이는 입력 표현에서 중복이 발생하여 다운스트림 작업에 부적합할 수 있다.
    2. 본 논문에서는 PIXEL 모델(Rust et al., 2023)에서 텍스트를 렌더링하는 네 가지 접근법을 조사하고, 단순한 문자 바이그램 렌더링이 문장 수준 작업에서 성능을 향상시키면서도 토큰 수준이나 다국어 작업에서의 성능을 희생시키지 않는 것을 발견하였다.
    3. 이 새로운 렌더링 전략은 또한 원래의 86M 파라미터 모델과 동등한 성능을 발휘하는 22M 파라미터로 더 컴팩트한 모델을 훈련할 수 있게 한다. 문자 바이그램 렌더링은 일관된 개선된 모델을 제공하지만, 패치 빈도 편향에 의해 주도되는 이방성적인 패치 임베딩 공간을 보여주며, 이미지 패치 기반 및 토큰화 기반 언어 모델 사이의 연결을 강조한다.

###### APoLLo : Unified Adapter and Prompt Learning for Vision Language Models (https://aclanthology.org/2023.emnlp-main.629/)
- Anthology ID: 2023.emnlp-main.629 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Vision-Language Pretrained (VLP) 모델의 성능에 있어 입력 텍스트 프롬프트의 선택은 매우 중요하며, 이 논문에서는 Adapter와 Prompt 학습을 결합한 APoLLo라는 통합된 다중 모달 접근 방법을 제안한다.
    2. 우리의 방법은 VLP 모델이 소수의 데이터로 fine-tuning 될 때 일반화 능력을 크게 향상시킬 수 있다. 양 모달리티 간의 정렬을 강화하기 위해 학습 가능한 cross-attention 기반의 어댑터 레이어를 도입하고, 데이터 증가를 위해 증가된 입력을 받는 각 인코더 브랜치 간의 일관성을 강조한다.
    3. 우리의 방법은 새로운 클래스에 대한 일반화, 데이터셋 간 평가, 보이지 않는 도메인 변화에 대한 평가 등 세 가지 대표적인 작업에서 향상된 성능을 보여준다. 실제로, APoLLo는 10 개의 다양한 이미지 인식 데이터셋에 대해 MaPLe (SOTA) 대비 최대 6.03%의 상대적 이득을 얻는다.

###### SAMRank: Unsupervised Keyphrase Extraction using Self-Attention Map in BERT and GPT-2 (https://aclanthology.org/2023.emnlp-main.630/)
- Anthology ID: 2023.emnlp-main.630 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. SAMRank는 사전 훈련된 언어 모델의 self-attention 맵 만을 사용하여 구 어구의 중요도를 결정하는 새로운 비지도 키워드 추출 방법을 제안한다. 
    2. 이전의 방법들은 문맥화 임베딩을 사용하여 단어, 문장 및 문서 간의 의미적 유사성을 포착하였으나, 이러한 방법은 임베딩의 이방성 특성으로 인해 의미적 유사성 측정에 최적화되지 않을 수 있다.
    3. 이 논문에서는 BERT와 GPT-2와 같은 사전 훈련된 언어 모델의 self-attention 맵을 활용하여 구 어구의 중요도를 산출하고, 이를 통해 키워드 추출을 수행하는 SAMRank는 임베딩에 의존하지 않고도 키워드 추출이 가능한 것을 실험적으로 입증하였다.

###### Contrastive Learning for Inference in Dialogue (https://aclanthology.org/2023.emnlp-main.631/)
- Anthology ID: 2023.emnlp-main.631 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인퍼런스, 특히 포함되지 않은 정보를 컴플리먼트로 전달하기 위한 추론 과정은 대화에서 중요하다. 
    2. 최근 대형 언어 모델들은 추론 작업에서 굉장한 진전을 보이고 있으나 모든 정보가 대화 맥락에 포함되지 않은 추론에서는 논리적 추론에 비해 성능이 뒤쳐진다.
    3. 이 논문에서 작성자들은 모델의 동작을 시맨틱 정보 갭에 의해 정의된 작업 난이도에 따라 분석하였다. 우리는 의사결정 트리 기반의 대화 데이터셋을 이용하여 언어 모델의 성능을 분석하고, 모델이 어떻게 추론을 수행하는지 자세히 살펴 보았다.

###### Editing Large Language Models: Problems, Methods, and Opportunities (https://aclanthology.org/2023.emnlp-main.632/)
- Anthology ID: 2023.emnlp-main.632 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. trainable한 LLM을 구축하는 것은 가능하지만, 그들의 relevancy를 유지하고 에러를 수정하는 방법론은 난해하다. 
    2. 해당 논문에서는 LLM을 효율적으로 특정 도메인 내에서 수정하면서 다른 input에 대한 성능을 저하시키지 않는 방법에 대해 깊이 있는 탐구를 제공한다. 
    3. 또한, 효과성과 실용성에 대한 소중한 통찰력을 제공하여 특정 작업이나 문맥에 가장 적합한 방법을 선택하는 데에 도움을 주기 위해 새로운 벤치마크 데이터셋을 구축하였다.

###### MarkQA: A large scale KBQA dataset with numerical reasoning (https://aclanthology.org/2023.emnlp-main.633/)
- Anthology ID: 2023.emnlp-main.633 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 지식 베이스로부터의 질문 응답에 있어서 연속된 숫자형 질문들은 아직 다뤄지지 않은 분야다. 논문에서는 복잡한 숫자 판단을 필요로 하는 NR-KBQA라는 새로운 과제를 제안한다.
    2. Numerical reasoning 질문들의 추론 과정을 파이썬 형식인 PyQL로 표현하는 통합형식을 디자인했다. NR-KBQA 개발을 촉진하기 위해 작은 시드 집합을 통해 자동으로 생성된 MarkQA라는 대규모 데이터셋을 제공한다.
    3. MarkQA 데이터셋에서 수행되는 최신 QA 방법의 실험 결과는 KBQA에서의 복잡한 숫자 판단이 큰 어려움을 겪고 있다는 것을 보여준다.

###### Comparing Biases and the Impact of Multilingual Training across Multiple Languages (https://aclanthology.org/2023.emnlp-main.634/)
- Anthology ID: 2023.emnlp-main.634 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 바이어스 및 공평성 연구는 한 언어 안에서 사회적 바이어스를 주로 다루고 있으며, 몇 가지 속성 (예: 성별, 인종)에 대해 분석하고 있다. 
    2. 그러나 바이어스는 각 언어마다 다르게 나타날 수 있다. 그래서 각 언어와 속성 내에서의 바이어스를 분석하는 것이 중요하다. 
    3. 본 논문에서는 이탈리아어, 중국어, 영어, 히브리어, 스페인어를 대상으로 전반적인 센티먼트 분석 작업에 대한 바이어스 분석을 제시하고, 다국어 데이터와 단일 언어 데이터로 모델을 훈련시킬 때 바이어스가 어떻게 영향을 받는지 조사한다.

###### HutCRS: Hierarchical User-Interest Tracking for Conversational Recommender System (https://aclanthology.org/2023.emnlp-main.635/)
- Anthology ID: 2023.emnlp-main.635 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 대화형 추천 시스템은 사용자로부터 모든 속성에 대한 명시적인 답변 (예/아니오)을 요구하여 사용자의 지식이나 관심에 상관없이 사용자 경험과 의미 일관성을 저하시킬 수 있다. 
    2. 본 논문에서는 실용적이고 사용자 친화적이며 설명 가능한 대화형 추천 시스템 프레임워크인 HutCRS를 제안한다. HutCRS는 대화를 계층적 관심 트리로 표현하며, 사용자가 선호하는 측면을 식별하여 관련 속성에 대해 물어보거나 아이템을 추천한다.
    3. 또한, 우리는 결정 과정을 통합하는 Hierarchical-Interest Policy Learning (HIPL) 모듈을 개발하여 어떤 측면에 대해 질문하고 언제 속성을 물어보거나 아이템을 추천할지 결정한다. 더 나아가, 속성 수준의 피드백 결과를 분류하여 사용자의 상호작용 데이터에 제시되지 않은 특정 정보 (예 : 사용자가 수락하지만 과거 데이터에 나타나지 않은 속성 인스턴스)를 포착하는 시스템 능력을 향상시킨다.

###### Large Language Models Meet Open-World Intent Discovery and Recognition: An Evaluation of ChatGPT (https://aclanthology.org/2023.emnlp-main.636/)
- Anthology ID: 2023.emnlp-main.636 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. OOD intent discovery와 GID (일반화된 인텐트 탐지) 작업은 task-oriented dialogue (TOD) 시스템에 매우 중요한 역할을 하는데, 이러한 작업들을 fine-tuning 기반의 모델로 다루는 기존의 방법들이 있다. 이 논문에서는 ChatGPT의 OOD intent discovery와 GID 능력에 대해 종합적으로 평가하고, ChatGPT의 장단점을 요약하고 설명한다.
    2. ChatGPT는 zero-shot settings에서 일관된 이점을 보이지만, fine-tuned 모델과 비교했을 때 아직도 불리한 면이 있다는 것을 알 수 있다.
    3. 여러 가지 분석 실험을 통해 LLMs(대형 언어 모델)이 직면한 도메인 특화 이해, 군집화, 상황 속 교차 도메인 학습과 같은 과제들에 대해 정리하고 논의하며, 이러한 도전과제를 해결하기 위한 미래 방향에 대한 경험적인 안내를 제공한다.

###### The Distributional Hypothesis Does Not Fully Explain the Benefits of Masked Language Model Pretraining (https://aclanthology.org/2023.emnlp-main.637/)
- Anthology ID: 2023.emnlp-main.637 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 본 논문은 masked language modeling의 사전학습 목적함수를 Distributional Hypothesis의 관점에서 분석한다.
    2. 작은 데이터로부터의 효율성 향상과, 사전학습된 모델의 일반화 능력이 pretraining 데이터의 distributional 속성에 부여될 수 있는지를 조사한다.
    3. 합성 데이터셋을 통해, distributional property가 masked language models의 효율성을 개선시키지만, 일반화 능력에 완벽하게 설명할 수는 없다는 것을 보여준다.

###### Simple and Effective Input Reformulations for Translation (https://aclanthology.org/2023.emnlp-main.638/)
- Anthology ID: 2023.emnlp-main.638 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존 언어 모델은 미세조정 입력 컨텍스트로부터 학습하는데, 이 연구에서는 언어 모델을 미세조정할 때 입력 형태를 변경하여 언어 모델의 강점을 활용하여 성능을 향상시키는 방법을 제안한다.
    2. 이 방법은 데이터 수준의 수정으로 진행되며, 추가적인 학습 데이터 수집이나 추론 시간에 데이터 수정이 필요하지 않는다.
    3. 이 방법은 단일 언어 쌍 번역 작업 또는 다국어 번역 작업에도 적용될 수 있으며, 실험 결과로는 3.5 chrF++까지의 성능 향상을 보였다.

###### Pointwise Mutual Information Based Metric and Decoding Strategy for Faithful Generation in Document Grounded Dialogs (https://aclanthology.org/2023.emnlp-main.639/)
- Anthology ID: 2023.emnlp-main.639 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 문서에 기반한 대화에 사용되는 딥러닝 기반 생성 모델에서 주요한 우려사항은 생성된 응답이 기초 문서에 충실하지 않을 수 있다는 것이다.
    2. 기존의 자동 메트릭은 생성된 응답과 문서의 내용 사이의 유사도를 측정하지만, 이러한 자동 메트릭은 사람의 판단과 일치하지 않는다.
    3. 이 논문에서는 응답의 충실성을 측정하기 위해 새로운 메트릭을 제안하고, 이 메트릭을 응답 생성 과정에 적용하여 더 충실한 응답을 예측하는 새로운 디코딩 기술을 제안한다.

###### The ACL OCL Corpus: Advancing Open Science in Computational Linguistics (https://aclanthology.org/2023.emnlp-main.640/)
- Anthology ID: 2023.emnlp-main.640 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. ACL OCL은 ACL Anthology에서 파생된 학술 코퍼스로, 계산언어학 분야의 오픈 과학 연구를 돕기 위해 제공된다.
    2. 이 코퍼스는 메타데이터, PDF 파일, 인용문 그래프 및 추가적인 구조화된 전체 텍스트를 제공하며, 더 큰 지식 자원 (Semantic Scholar)에 섹션, 그림 및 링크가 있는 형태로 이전 버전의 ACL Anthology를 통합 및 개선한다.
    3. ACL OCL은 7개의 연대를 아우르고, 73,000개의 논문과 210,000개의 그림을 포함하며, 컴퓨터 언어학에서의 추세를 관찰하는 데 적용된다. 예를 들어, "구문 분석, 태깅 및 청킹"에 대한 관심이 줄고 있고, "자연어 생성"에 대한 관심이 소리댄다는 사실을 발견할 수 있다.

###### Using Artificial French Data to Understand the Emergence of Gender Bias in Transformer Language Models (https://aclanthology.org/2023.emnlp-main.641/)
- Anthology ID: 2023.emnlp-main.641 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 많은 연구는 신경 언어 모델이 직접 감독 없이도 다양한 언어적 속성을 학습할 수 있는 능력을 보여주고 있다.
    2. 본 연구는 신경 모델이 단어의 성별과 사용 규칙과 같은 언어적 속성을 어떻게 발견하는지라는 덜 연구된 주제를 탐색하기 위한 초석을 제공한다.
    3. 우리는 프랑스어를 기반으로 한 PCFG로 생성된 인공 말뭉치를 사용하여 훈련 데이터에서 성별 분포를 정확하게 제어하고, 언제 모델이 성별 정보를 올바르게 포착하거나 그와 반대로 성별 편향이 나타나는지를 결정하는 것을 제안한다.

###### Learning to Rank Context for Named Entity Recognition Using a Synthetic Dataset (https://aclanthology.org/2023.emnlp-main.642/)
- Anthology ID: 2023.emnlp-main.642 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 pre-trained transformer 기반 모델들은 명명된 개체 인식 (NER)을 매우 높은 정확도로 수행할 수 있지만, 전체 소설과 같은 긴 문서에 적용할 때 범위가 제한되는 문제가 남아 있다. 
    2. 이 문제를 완화하기 위한 해결책은 문서 수준에서 관련된 맥락을 검색하는 것이다. 그러나 이러한 과업에 대한 감독이 존재하지 않기 때문에 비감독 방식에 안주해야 한다.
    3. 대신에, 우리는 Alpaca라는 instruction-tuned large language model (LLM)을 사용하여 합성된 맥락 검색 훈련 데이터셋을 생성하기를 제안한다. 이 데이터셋을 사용하여 NER에 대한 관련 맥락을 찾을 수 있는 BERT 기반의 신경망 맥락 검색 모델을 훈련시킨다. 우리는 우리의 방법이 40권의 소설의 첫 장으로 구성된 영어 문학 데이터셋에서 NER 과업의 검색 베이스라인보다 우수한 성과를 보여준다.

###### Improving Diversity of Demographic Representation in Large Language Models via Collective-Critiques and Self-Voting (https://aclanthology.org/2023.emnlp-main.643/)
- Anthology ID: 2023.emnlp-main.643 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델의 다양성은 중요한 과제인데, 사용자의 prompt가 명확하지 않을 때 모델이 암묵적인 가정을 따르거나 특정 인종이나 문화의 그룹이 생성된 응답에서 보이지 않거나 사라질 수 있다. 
    2. 본 논문에서 언어 모델 세대에서 다양성의 문제를 형식화하고, 다양성을 측정하는 메트릭을 제안한다. 
    3. 실험 결과에서, 새로운 CCVS 프롬프팅 기술이 다양성을 향상시키는데 효과적이며 기존 기법들보다 큰 효율을 보인다는 것을 확인했다.

###### Hidding the Ghostwriters: An Adversarial Evaluation of AI-Generated Student Essay Detection (https://aclanthology.org/2023.emnlp-main.644/)
- Anthology ID: 2023.emnlp-main.644 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델들이 텍스트 생성 과제에서 놀라운 능력을 발휘하고 있지만, 이러한 모델들의 활용은 표절, 가짜 뉴스의 확산, 교육 과정에서의 문제 등과 같은 내재적인 위험을 수반한다. 
    2. 이 논문은 주로 학생의 글쓰기에 대한 문맥에서 적대적인 왜곡에 대한 효과적인 탐지기의 효과에 대해 연구한다. 
    3. 실험 결과, 기존의 탐지기들은 간단한 자동 적대적 공격을 우회하면서도 검출 가능성을 크게 낮출 수 있는 단어 대체 및 문장 대체 왜곡 방법을 탐구하였다.

###### Contextual Interaction for Argument Post Quality Assessment (https://aclanthology.org/2023.emnlp-main.645/)
- Anthology ID: 2023.emnlp-main.645 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에는 자연어 논쟁의 질을 평가하는 것에 대한 관심이 높아졌다. 기존 접근 방식은 개별 논쟁 포스트의 질을 평가하는 데에 중점을 두었지만, 질 차이가 미묘한 논쟁을 효과적으로 구별하기에는 부족한 경우가 많다.
    2. 이 논문은 상대적 질을 모델링하기 위한 두 가지 대체 방법을 다룬다. 이 방법들은 1) argument들 간의 복잡한 상호작용을 포착하는 감독된 대조학습과 2) in-context 예제로 LLMs를 더욱 풍부하게 만드는 방법이다.
    3. IBM-Rank-30k 데이터셋을 통해 광범위한 평가와 분석을 거쳐, 대조적인 논쟁 품질 평가 방법이 최첨단 기준 모델들보다 우수함을 입증한다. 그러나 in-context 예제를 사용한 LLMs는 높은 품질의 논쟁 포스트를 식별하는 데에 탁월한 능력을 보여주지만, 품질 차이가 미묘한 논쟁 포스트간 구별 능력은 제한적이다.

###### Pre-training Intent-Aware Encoders for Zero- and Few-Shot Intent Classification (https://aclanthology.org/2023.emnlp-main.646/)
- Anthology ID: 2023.emnlp-main.646 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 과제 지향형 대화 시스템에서 IC(Intent classification)은 중요한 역할을 한다. 하지만 충분한 어노테이션(example) 없이 IC 모델을 훈련시키면 일반적으로 일반화 능력이 부족하다. 
    2. 이 논문에서는 IC 작업에 적합한 임베딩을 생성하기 위해 의도의 pseudo label로 대조 학습(contrastive learning)을 사용하는 텍스트 인코더의 신규 사전학습(pre-training) 방법을 제안한다.
    3. 이러한 사전학습 전략을 적용함으로써, PIE 모델은 네 개의 IC 데이터셋에서 zero-shot 및 one-shot 설정에서 이전 최고 성능의 사전학습 텍스트 인코더 대비 최대 5.4%와 4.0% 높은 정확도를 달성한다.

###### Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations (https://aclanthology.org/2023.emnlp-main.647/)
- Anthology ID: 2023.emnlp-main.647 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 고품질 training data의 수집과 정리는 우수한 성능을 가진 텍스트 분류 모델을 개발하는 데 매우 중요하지만, 그것은 종종 상당한 비용과 시간 투자를 동반한다. 
    2. 최근에는 대용으로 LLM (Large Language Model)이 생성한 합성 데이터를 사용하는 것을 탐구한 연구자들도 있다. 
    3. 하지만 LLM이 생성한 합성 데이터의 효과는 서로 다른 분류 작업에 따라 일관되지 않다.

###### GazeVQA: A Video Question Answering Dataset for Multiview Eye-Gaze Task-Oriented Collaborations (https://aclanthology.org/2023.emnlp-main.648/)
- Anthology ID: 2023.emnlp-main.648 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 엑소센트릭과 에고센트릭 비디오를 사용한 비디오 질의 응답 (VQA)은 인간-로봇 상호작용 및 협업 연구에서의 새로운 시도이다. 
    2. 특히 에고센트릭 비디오의 경우 눈동자 동선 정보를 활용하여 사용자의 의도를 이해하는데 도움이 될 수 있다.
    3. 본 논문에서는 사용자들이 질문을 할 때 눈동자 동선 정보가 캡처된 GazeVQA라는 이름의 새로운 테스크 지향 VQA 데이터셋을 구축하였고, 이 데이터셋을 활용해 AssistGaze라고 불리는 AI 모델을 제안하였다.

###### People Make Better Edits: Measuring the Efficacy of LLM-Generated Counterfactually Augmented Data for Harmful Language Detection (https://aclanthology.org/2023.emnlp-main.649/)
- Anthology ID: 2023.emnlp-main.649 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. NLP 모델의 robustness는 사회적 컴퓨팅 작업에서 중요하며, spurious feature에 강건해야 한다. 
    2. 이전 연구들은 counterfactual data augmentation을 사용하여 spurious feature에 대한 의존성을 줄이기 위해 노력했다. 
    3. 이 논문에서는 Polyjuice, ChatGPT, Flan-T5를 사용하여 자동으로 CADs를 생성하고, 수동으로 생성된 CADs와 비교하여 모델의 robustness를 향상시키는지 평가한다.

###### Unraveling Feature Extraction Mechanisms in Neural Networks (https://aclanthology.org/2023.emnlp-main.650/)
- Anthology ID: 2023.emnlp-main.650 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 신경망의 학습 매커니즘을 이해하기 위해 Neural Tangent Kernels (NTKs)를 기반으로 한 이론적 접근법을 제안하였다. 이를 통해 그들의 내부 메커니즘에 대한 통찰을 더 깊게 파악할 수 있다.
    2. 우리는 이 방법을 여러 기본 모델에 적용하여 그들이 gradient descent 과정에서 훈련 데이터로부터 획득한 통계적 특징과 최종 결정에 어떻게 이를 적용하는지를 밝혀냈다.
    3. 또한, 우리는 활성화 함수의 선택이 특징 추출에 영향을 줄 수 있음을 발견하였으며, self-attention과 CNN 모델은 n-gram 학습에 제약이 있을 수 있지만 곱셈 기반 모델은 이 영역에서 뛰어나다는 것을 알 수 있었다.

###### CAPSTONE: Curriculum Sampling for Dense Retrieval with Document Expansion (https://aclanthology.org/2023.emnlp-main.651/)
- Anthology ID: 2023.emnlp-main.651 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 디얼 인코더는 밀집 검색에서 주로 사용되는 구조이지만, 쿼리와 문서 간의 상호작용을 완전히 포착하지 못해 두고 있다.
    2. 우리는 교육 중 가짜 쿼리를 사용하여 생성된 쿼리와 진짜 쿼리 간의 관련성을 진화하도록 가중치를 점점 더 주는 커리큘럼 샘플링 전략을 제안한다.
    3. 이를 통해 밀집 검색 모델은 문서뿐만 아니라 쿼리에도 관심을 기울여 고품질의 쿼리-인포메이션 문서 표현을 얻을 수 있으며, 관련성에 기초한 기존 모델보다 우수한 성능을 보여줍니다.

###### Balance Act: Mitigating Hubness in Cross-Modal Retrieval with Query and Gallery Banks (https://aclanthology.org/2023.emnlp-main.652/)
- Anthology ID: 2023.emnlp-main.652 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다중 모달 검색에서 나타나는 중심성 문제(hubness problem)를 해결하기 위한 후처리 솔루션을 제안한다. 이 논문에서는 검색 성능을 저하시키는 동안 일부 갤러리 데이터 포인트가 빈번하게 검색되는 현상인 hubness 문제를 이론적으로 설명하고, 이를 해결하기 위해 역동적 절편 인발 softmax와 유사성 정규화 방법을 제안한다.
    2. 기존의 연구는 쿼리 샘플만 활용하여 중심성 문제를 완화하기 위한 시도를 했으나, 이 논문에서는 쿼리와 갤러리 샘플을 모두 활용하여 중심성의 발생 빈도를 줄이는 새로운 Dual Bank Normalization (DBNorm) 프레임워크를 제안한다.
    3. 실험 결과, 이 방법은 다양한 언어 기반 벤치마크에서 우수한 성능을 보여 주어진 hubness 문제와 검색 성능 향상에 이전 방법들보다 우월한 성능을 보인다.

###### E-CORE: Emotion Correlation Enhanced Empathetic Dialogue Generation (https://aclanthology.org/2023.emnlp-main.653/)
- Anthology ID: 2023.emnlp-main.653 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 감정적인 대화 시스템 구현을 위해서는 공감 심리를 이끌어내는 것이 중요하다. 하지만 기존의 방법은 감정 레이블을 독립적으로 다루기 때문에 대화 속 감정의 상호관계를 무시하고 정확한 감정 인지와 적절한 응답 생성에 어려움이 있다. 
    2. 이 논문에서는 감정 상호관계를 강화시킨 공감 대화 생성 프레임워크를 제안한다. 다양한 해상도에서 문맥 기반 감정 상호작용을 포착하기 위해 다중 해상도 감정 그래프를 고안하고 감정 상호관계를 모델링한다.
    3. 실험 결과, 우리의 모델이 공감 인지와 표현에서 우수한 성능을 보여줌을 보여준다.

###### What do Deck Chairs and Sun Hats Have in Common? Uncovering Shared Properties in Large Concept Vocabularies (https://aclanthology.org/2023.emnlp-main.654/)
- Anthology ID: 2023.emnlp-main.654 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "개념은 다양한 응용분야에서 중요한 역할을 한다. 문맥 없이 개념을 모델링해야 하는 경우, 이전 연구는 language model에서 문맥을 제거한 개념 임베딩을 요약하여 사용했다. 그러나 개념은 다양한 관점에서 모델링될 수 있으며, 개념 임베딩은 주로 계층 구조를 포착한다. 이 문제를 해결하기 위해, 우리는 잠재적으로 큰 개념 어휘 사전에서 서로 공통점을 가진 다른 개념을 식별하는 전략을 제안한다."
    2. "우리는 다른 개념들과 공유하는 속성을 기반으로 개념을 표현한다. 이 개념 모델링 방법의 실용성을 보이기 위해, 우리는 어려운 다중 라벨 분류 문제인 ultra-fine entity typing 작업을 고려한다. 우리는 공유 속성을 라벨 집합에 추가함으로써 이 작업에 대한 최첨단 모델의 성능을 향상시킬 수 있음을 보여준다."
    3. "라벨 셋을 공유 속성으로 보강함으로써 ultra-fine entity typing 작업에 대한 최첨단 모델의 성능을 향상시킬 수 있다."

###### ALDi: Quantifying the Arabic Level of Dialectness of Text (https://aclanthology.org/2023.emnlp-main.655/)
- Anthology ID: 2023.emnlp-main.655 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 아랍어 텍스트는 현대 표준 아랍어(MSA)와 일상 소통에 사용되는 아랍어다이아렉트(DA)의 혼합체로 이루어져 있으며, 이러한 다양성을 처리하기 위해 이전 연구는 문장 또는 토큰 수준에서 어법 식별(DI)에 초점을 맞추어왔다.
    2. 그러나 DI는 과제를 이진형으로 처리하지만, 우리는 아랍어 사용자들이 어법의 다양성을 지각하기 때문에 이를 문장 수준에서 진행하며 연속된 언어 변수로 처리해야 한다고 주장한다.
    3. 우리는 글 수준에서 데이터셋을 만들었고, 해당 데이터셋으로 학습된 모델이 일련의 다언어와 다양한 장르에 대해 신뢰성 있게 다이어릭트 수준을 파악할 수 있으며, 이는 기존의 DI 시스템보다 세분화된 인식을 제공한다는 것을 자세한 분석을 통해 보여준다.

###### 3DRP-Net: 3D Relative Position-aware Network for 3D Visual Grounding (https://aclanthology.org/2023.emnlp-main.656/)
- Anthology ID: 2023.emnlp-main.656 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "3D visual grounding은 자유형태의 언어로 된 설명을 통해 3D 포인트 클라우드에서 대상 객체를 지역화하는 것을 목표로 한다. 본 논문에서는 상대적인 공간 관계를 효과적으로 포착하고 객체 속성을 강화하는 3D Relative Position-aware Network (3DRP-Net)라는 관계 인식 원스테이지 프레임워크를 제안한다."
    2. "3DRP-Net은 3D 상대적 위치 Multi-head Attention (3DRP-MA) 모듈을 제안하여 객체 쌍의 문맥에서 다른 방향으로부터 상대적 관계를 분석하고, 문장에서 언급된 특정한 객체 관계에 집중할 수 있다."
    3. "ScanRefer, Nr3D/Sr3D 세 가지 벤치마크에서 수행된 광범위한 실험 결과, 우리의 방법이 일반적으로 모든 최첨단 방법을 능가함을 보여준다."

###### Goal-Driven Explainable Clustering via Language Descriptions (https://aclanthology.org/2023.emnlp-main.657/)
- Anthology ID: 2023.emnlp-main.657 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 unsupervised clustering은 사용자의 목표를 고려하지 않고 클러스터의 의미를 설명하지 않습니다.
    2. 본 논문에서는 "목표 지향적 설명과 함께하는 클러스터링" (GoalEx) 이라는 새로운 방법을 제안합니다. 이 방법은 목표와 설명을 자유 형식의 언어로 표현하며, 목표와 관련된 설명을 정확하게 제공합니다.
    3. GoalEx는 기존 방법보다 더 정확하고 목표 관련된 설명을 생성하며, 자동 및 인간 평가에서 좋은 성능을 보입니다.

###### Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models (https://aclanthology.org/2023.emnlp-main.658/)
- Anthology ID: 2023.emnlp-main.658 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최종 목표가 다른 언어 배경을 가진 사용자들이 동일한 모델에서 일관된 피드백을 받을 수 있게 하는 것인데, 다양한 다국어 Pretrained Language Models (PLMs)에서 사실적인 지식의 cross-lingual 일관성(CLK)을 연구한다.
    2. 저자들은 RankC(Ranking-based Consistency) 메트릭을 제안하여 정확도와는 독립적으로 언어 간 지식 일관성을 평가한다.
    3. 모델 크기가 증가하면 대부분의 언어에서 사실적인 probing accuracy가 높아지지만, cross-lingual 일관성은 향상되지 않는다는 결론을 도출하였으며, 새로운 사실적인 연관이 PLMs에 삽입될 때, 이는 영어와 고 RankC 점수를 가진 언어로만 전달된다는 결과를 발견하였다.

###### Learning from Mistakes via Cooperative Study Assistant for Large Language Models (https://aclanthology.org/2023.emnlp-main.659/)
- Anthology ID: 2023.emnlp-main.659 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델 (LLM)은 자체 피드백을 바탕으로 생성을 개선하는 잠재력을 보여줬지만, LLM 자체의 피드백이 정확하지 않아 이점을 제한하고 있다.
    2. "Study Assistant for Large LAnguage Model (SALAM)"이라는 새로운 프레임워크를 제안하여 보조 에이전트를 통해 주요 LLM이 상호작용적 협력을 통해 실수로부터 배울 수 있도록 돕는다.
    3. 실험 결과, SALAM은 세 가지 LLM에서 높은 난이도의 프레임워크를 사용하여 BBH에서 최대 6.6의 정확도 향상 및 BBQ에서 최대 12.6의 정확도 향상을 이끌어냈다.

###### Bridging the Digital Divide: Performance Variation across Socio-Economic Factors in Vision-Language Models (https://aclanthology.org/2023.emnlp-main.660/)
- Anthology ID: 2023.emnlp-main.660 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 현재 AI 모델들의 놀라운 성능에도 불구하고, 이러한 모델들이 실제로 영향을 받을 특정 그룹에서 어떻게 수행되는지에 대한 평가는 종종 제공되지 않는다.
    2. 소수의 그룹 중에서도 저소득 가구의 데이터는 데이터 수집과 모델 평가에서 종종 간과된다.
    3. 우리는 최신 비전-언어 모델(CLIP)의 성능을 수입 수준에 따라 다른 가구 이미지 데이터셋(DollarStreet)에서 평가하고 결과로서 다양한 주제와 국가에 걸쳐 가난한 그룹의 성능이 부유한 그룹보다 일관되게 낮다는 것을 보여준다.

###### Conceptor-Aided Debiasing of Large Language Models (https://aclanthology.org/2023.emnlp-main.661/)
- Anthology ID: 2023.emnlp-main.661 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사전 교육된 대형 언어 모델은 사회적 편견을 반영하는데, 우리는 conceptors를 사용하여 이러한 편견을 제거하는 방법을 제안한다. conceptor 후처리는 GLUE 벤치마크에서 이전 방법들보다 우수한 debiasing 성과를 보여주며, 성능 저하 없이 편견을 줄일 수 있다.
    2. 또한, conceptor-intervened BERT (CI-BERT)라는 새로운 아키텍처를 제안하였는데, 과거 방식에 비해 bias를 효과적으로 제거하지만, 언어 모델의 정확도를 낮춘다.
    3. 우리는 편견 서브스페이스를 신중하게 구성하는 것의 중요성도 보여주었는데, 편견이 있는 단어 목록에서 이상값을 제거하고, OR 연산을 통해 결합한 후 보다 깔끔한 문장에서의 임베딩을 계산하여 가장 좋은 결과를 얻었다.

###### AMR Parsing is Far from Solved: GrAPES, the Granular AMR Parsing Evaluation Suite (https://aclanthology.org/2023.emnlp-main.662/)
- Anthology ID: 2023.emnlp-main.662 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. AMR parsing에 대한 챌린지 세트인 GrAPES와 함께 제시된 평가 메트릭을 소개한다. 기존 AMR 평가 메트릭인 Smatch에서 AMR 파서는 높은 점수를 얻고 있지만, 이는 AMR 파싱이 해결된 것을 의미하지 않는다. 이 연구에서는 GrAPES를 통해 AMR 파서를 다양한 문제에 대해 평가하고 기존 파서의 능력과 한계를 상세히 드러내었다.
    2. GrAPES는 관심 있는 실용적, 기술적, 언어적 현상 등 다양한 현상에 대해 AMR 파서를 테스트하는 평가 세트를 제공한다. 36개의 카테고리는 본적이 있는 라벨부터 구조적 일반화, 상호 참조까지 다양한 현상을 포함하고 있다.
    3. GrAPES를 통해 현재 AMR 파서의 능력과 부족한 점을 깊이 있게 드러내었다고 말한다.

###### Rethinking and Improving Multi-task Learning for End-to-end Speech Translation (https://aclanthology.org/2023.emnlp-main.663/)
- Anthology ID: 2023.emnlp-main.663 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다중작업 학습에 의해 ST(음성 번역)의 끝-끝 성능을 크게 향상시켰지만, 보조 작업들이 ST 작업과 얼마나 일관성이 있는지, 이 접근법이 얼마나 도움이 되는지는 철저히 연구되지 않았다. 
    2. 이 논문에서는 다른 시간과 모듈을 고려하여 다른 작업들간의 일관성을 조사한다. 텍스트 인코더는 주로 cross-modal 변환을 돕지만, 음성에서의 노이즈는 텍스트와 음성 표현 간의 일관성을 저해한다.
    3. 또한, 길이와 표현의 차이를 완화하여 모달 간 격차를 줄이는 개량된 다중작업 학습 (IMTL) 접근법을 ST 작업에 제안한다. MuST-C 데이터셋에서 실험을 진행한 결과, 우리의 방법이 최신 기법과 비교했을 때 최고 성능을 달성함을 보여주었다. 또한, 추가 데이터를 사용하면 MuST-C의 영어-스페인어 작업에서 현재 최고 성능 기법의 20.8%의 학습 시간으로 새로운 최고 성능을 달성하였다.

###### AD-NLP: A Benchmark for Anomaly Detection in Natural Language Processing (https://aclanthology.org/2023.emnlp-main.664/)
- Anthology ID: 2023.emnlp-main.664 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 딥러닝 모델은 이상 탐지 연구에 대한 관심을 불러일으켰다. 텍스트 이상 탐지에 대한 방법들은 흔히 레이블된 데이터셋에서 일부 클래스를 다운샘플링하여 만든 아드혹한 이상 설정에 대해 강력한 실험 결과를 보였다. 
    2. 하지만 이로 인해 재현성 문제와 특정 이상을 검출하는 데에는 성공하지만 더 복잡한 상황에서는 인식하지 못하는 바이어스가 있는 모델이 만들어진다. 
    3. 이 논문에서는 텍스트 이상 탐지로 자연스럽게 표현될 수 있는 종류의 다양한 이상을 검출하기 위한 통합 벤치마크를 제공하고, 얕은 기준선과 최신 신경망 접근법 2가지를 평가하고 분석하여 신경망 모델이 이상 탐지 작업을 수행할 때 배우는 지식에 대한 통찰력을 제공한다.

###### Enhancing the Ranking Context of Dense Retrieval through Reciprocal Nearest Neighbors (https://aclanthology.org/2023.emnlp-main.665/)
- Anthology ID: 2023.emnlp-main.665 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 희소 주석은 밀집 검색 모델의 훈련에 지속적인 도전을 제기한다. 이 논문에서는 이러한 문제를 완화하기 위해 evidence-based label smoothing이라는 새로운 방법을 소개한다. 
    2. 이 방법은 훈련 과정에서 가짜 음성(negatives)으로 사용되는 미분류된 관련 문서에 높은 관련성을 할당함으로써 모델에 패널티를 주지 않고 잘못된 음성에 높은 관련성을 할당하는 문제를 완화한다. 
    3. 실험 결과, 이 방법은 밀집 검색 모델의 랭킹 효과를 향상시키는 데 효과적이며, 레이블 스무딩 및 후처리에서도 사용할 수 있다는 것을 보여준다.

###### Cross-Lingual Cross-Target Stance Detection with Dual Knowledge Distillation Framework (https://aclanthology.org/2023.emnlp-main.666/)
- Anthology ID: 2023.emnlp-main.666 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Stance detection은 텍스트에서 사용자의 태도를 특정 대상에 대해 파악하는 것이며, 영어로 진행된 과거 연구들이 대부분이었다. 그러나 대부분의 비-영어 언어에서는 데이터 저조 문제(low-resource)로 인해 cross-lingual stance detection이 제안되었다.
    2. 이 논문에서는 cross-lingual cross-target stance detection이라는 새로운 과제를 제안하고, dual knowledge distillation을 사용한 최초의 연구를 개발한다.
    3. 실험결과, 우리의 방법은 경쟁력 있는 기준들에 비해 훨씬 효과적임을 보여준다.

###### PRESTO: A Multilingual Dataset for Parsing Realistic Task-Oriented Dialogs (https://aclanthology.org/2023.emnlp-main.667/)
- Anthology ID: 2023.emnlp-main.667 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Google Assistant, Alexa, Siri와 같은 시스템이 일상생활에서 널리 사용되면서 과제 지향 대화에 대한 연구 관심이 증가했지만, 사용자의 다양한 문제점을 현실적으로 포착한 데이터셋의 부족으로 연구 영향력이 제한되었다. 
    2. 우리는 PRESTO라는 공개 데이터셋을 소개하여 현실적인 대화를 파싱하는 데 어려움을 제공한다. PRESTO는 불안정성, 코드 스위칭, 개정과 같은 실제 NLU 과제에서 발생하는 다양한 도전 요소를 포함하고 있다. 
    3. 저자들은 mT5 모델 기반의 기준선 결과를 통해 PRESTO에 존재하는 대화 현상이 모델링하기 어려움을 보여주었고, 특히 low-resource 설정에서 그 난이도가 더 두드러진다는 것을 입증했다.

###### An Iteratively Parallel Generation Method with the Pre-Filling Strategy for Document-level Event Extraction (https://aclanthology.org/2023.emnlp-main.668/)
- Anthology ID: 2023.emnlp-main.668 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 문서 수준 이벤트 추출(DEE) 태스크에서는 문서에 여러 이벤트 레코드와 역할이 포함되므로, 이벤트 레코드들을 정확하게 추출하는 것은 큰 도전이다. 
    2. 기존 방법은 역할을 auto-regressively (자기회귀적) 생성하기 때문에 주어진 생성 순서가 필요한 EDAG(엔티티 기반 방향성 비순환 그래프) 생성 방법을 제시한다.
    3. 본 논문에서는 역할들을 병렬로 생성하여 순서 선택을 피하고, 이전 결과를 활용하기 위해 이벤트 레코드들을 반복적으로 생성하는 IPGPF(Pre-Filling 전략이 있는 반복적 병렬 생성 방법)을 제안한다.

###### CoMPosT: Characterizing and Evaluating Caricature in LLM Simulations (https://aclanthology.org/2023.emnlp-main.669/)
- Anthology ID: 2023.emnlp-main.669 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근엔 사회과학 실험이나 대중 의견 조사와 같은 상황에서 LLM을 사용하여 특정 인구군의 응답을 모방하는데 인간 행동의 세세한 면을 잡아내기 위해 노력해 왔습니다. 그러나 이러한 LLM 시뮬레이션의 품질을 논의하거나 평가할 수 있는 방법이 현재까지는 없습니다.
    2. 또한, 이러한 LLM 시뮬레이션들이 모션을 잘 반영하지 못하고 다양한 차원의 사람을 포착하지 못하여 고정 관념을 유지시키는 우려가 커지고 있습니다.
    3. 따라서 우리는 CoMPosT라는 프레임워크를 제시하며, LLM 시뮬레이션의 네 가지 차원인 Context, Model, Persona, Topic을 빠짐없이 분석하는데 사용합니다. 우리는 이 프레임워크를 통해 기존 LLM 시뮬레이션 작업에서의 '개별화'와 '과장표현'이라는 두 가지 기준을 사용하여 시뮬레이션의 카리커처 수준을 평가합니다. 우리는 GPT-4에서 일부 인구군(정치적 및 억압 받는 그룹) 및 주제에 대한 시뮬레이션의 카리커처 정도를 평가하였습니다.

###### Reduce Human Labor On Evaluating Conversational Information Retrieval System: A Human-Machine Collaboration Approach (https://aclanthology.org/2023.emnlp-main.670/)
- Anthology ID: 2023.emnlp-main.670 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화형 정보 검색 (CIR) 시스템의 평가는 주석 작업에 상당한 인적 노동을 필요로 하는 어려운 작업이다. CIR 시스템의 평가를 위해 인력을 효율적으로 활용하는 방법을 연구하는 데 많은 노력을 기울여야 한다.
    2. 우리는 CIR 평가에 활성 테스팅을 도입하여 HomCoE라는 새로운 방법을 제안한다. 이 방법은 일부 데이터를 인간의 주석 작업에 전략적으로 선택하고, 평가 결과를 보정하여 평가 편향을 제거한다. 이로써 CIR 시스템을 적은 인적 노동으로 정확하게 평가할 수 있다.
    3. 우리의 방법은 인적 노동의 1% 미만을 소비하며, 95%에서 99%의 일치율과 인간 평가 결과를 달성한다는 실험 결과를 보여준다. 이는 다른 기준과 비교하여 우리의 방법의 우수성을 강조한다.

###### BERTie Bott’s Every Flavor Labels: A Tasty Introduction to Semantic Role Labeling for Galician (https://aclanthology.org/2023.emnlp-main.671/)
- Anthology ID: 2023.emnlp-main.671 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문에서는 기존의 말뭉치, WordNet 및 종속 구문 분석을 활용하여 수동 통사 역할 지정 시스템을 훈련하기 위한 첫 번째 개신어 데이터셋을 구축하여 NLP 자원을 확장하는 노력을한다.
    2. 우리는 고도로 복잡한 문장을 의미론적으로 파싱할 때 성능을 향상시키는 새로운 전처리 방법인 동사 인덱싱을 도입한다.
    3. 전이 학습을 사용하여 자원과 동사 인덱싱 방법을 테스트하고, 결과는 동사 인덱싱 효과가 사전 훈련 및 세부조정이 되는 경우에 더 크게 나타났지만, 세부조정 중에만 사용하는 경우에도 개선이 눈에 띄게 있음을 보여준다.

###### Program Translation via Code Distillation (https://aclanthology.org/2023.emnlp-main.672/)
- Anthology ID: 2023.emnlp-main.672 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 소프트웨어 버전 이전 및 프로그램 번역은 대형 코드베이스의 수명주기에서 중요하고 비용이 많이 드는 부분이다. 그러나 프로그램 번역을 위해 병렬 코퍼스를 사용하는 기존의 기계 번역은 맞춰진 데이터가 없기 때문에 실현 가능하지 않다.
    2. 이 연구에서 우리는 Code Distillation (CoDist)이라는 새로운 모델을 제안하여 언어에 중립적인 중간 표현에서 코드의 의미적 및 구조적 동등성을 포착한다.
    3. 우리의 방법은 CodeXGLUE 및 TransCoder GeeksForGeeks 번역 벤치마크에서 최첨단 성능을 달성하며, TransCoder-ST와 비교하여 평균 절대 증가율이 12.7%이다.

###### FaMeSumm: Investigating and Improving Faithfulness of Medical Summarization (https://aclanthology.org/2023.emnlp-main.673/)
- Anthology ID: 2023.emnlp-main.673 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 의료 텍스트의 요약은 충실성을 유지하며 소스 입력과 일치하도록 되어야 하는데, 이는 의료 분야에서의 안전성과 효율성에 있어 중요하지만 연구가 부족한 주제이다.
    2. 현재의 요약 모델은 의료 입력 텍스트에 대해 종종 충실하지 않은 결과물을 생성한다는 사실을 밝혀냄.
    3. 의료 지식을 기반으로 사전 훈련된 언어 모델을 미세 조정함으로써 충실성을 개선하는 FaMeSumm 프레임워크를 소개한다. FaMeSumm은 충실한 요약과 충실하지 않은 요약의 디자인된 집합에 대해 대조적 학습을 수행하고, 의료 용어와 그 문맥을 포함하여 충실한 의료 용어의 생성을 촉진한다.

###### Grammar-Constrained Decoding for Structured NLP Tasks without Finetuning (https://aclanthology.org/2023.emnlp-main.674/)
- Anthology ID: 2023.emnlp-main.674 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델(LMs)은 높은 성능을 보이지만 원하는 출력 형식을 정확하게 따르지 않을 때 복잡한 출력 구조를 신뢰성 있게 생성하는 데 어려움이 있다. 
    2. 본 논문에서는 의미 추출, entity disambiguation, constituency parsing 등 다양한 task에서 Grammar Constrained Decoding (GCD)을 사용하여 LMs의 성능을 향상시키고 유연성을 제공하는 방법을 제안한다. 
    3. 결과적으로 grammar 제약이 있는 LMs는 기존의 LMs보다 성능이 우수하며 task별로 fine-tuning된 모델을 능가한다고 한다.

###### Systematic word meta-sense extension (https://aclanthology.org/2023.emnlp-main.675/)
- Anthology ID: 2023.emnlp-main.675 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 동의어의 의미는 예측 가능하고 생산적인 방식으로 자주 변하기 때문에, 기존 의미 사이의 규칙성을 일반화하여 새로운 의미를 파생시키는 것은 비격상 표현과 같은 비문학 언어 사용의 자동 처리에 중요하다. 
    2. 우리는 SWORME라는 새로운 과제를 소개하여 언어 모델이 기존 의미와 규칙적인 의미 관계를 가지는 새로운 의미를 확장하는 능력을 평가하고 개선한다. 
    3. 우리는 단어 의미 확장을 위한 새로운 유추 기반 방법을 제안하고, 이 방법은 점진적인 의미 변경부터 비문학적인 의미 확장에 이르기까지 언어 모델의 체계성을 향상시키는 데 효과적임을 보여준다.

###### Evaluating Evaluation Metrics: A Framework for Analyzing NLG Evaluation Metrics using Measurement Theory (https://aclanthology.org/2023.emnlp-main.676/)
- Anthology ID: 2023.emnlp-main.676 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 생성(NLG) 모델 평가에서 주요 도전 과제로서, 평가 메트릭의 설계와 평가에 대한 문제를 다루고 있다. 기존의 자동 평가 메트릭의 한계와 현재의 인간 평가 방법에서 발생하는 잡음을 인식하고, 교육 테스트 설계의 기초인 측정 이론을 기반으로 한 MetricEval이라는 프레임워크를 제안한다.
    2. 이 프레임워크는 측정 오차의 원인을 형식화하고, 경험적 데이터를 기반으로 평가 메트릭을 평가하기 위한 통계 도구를 제공한다. 이를 통해 메트릭의 불확실성을 측정하여 결과를 더 잘 해석할 수 있다.
    3. MetricEval을 통해 요약을 위한 평가 메트릭 세트를 분석하고, 인간 평가에서 혼합된 타당성 구조와 LLM 기반 메트릭의 신뢰성과 관련된 문제를 파악하는 사용 사례를 제시하고자 한다. 이를 통해 견고하고 효과적인 NLG 모델의 발전을 위해 타당하고 신뢰할 수 있는 메트릭의 설계, 평가, 해석을 촉진하고자 한다.

###### Revisiting the Knowledge Injection Frameworks (https://aclanthology.org/2023.emnlp-main.677/)
- Anthology ID: 2023.emnlp-main.677 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에는 GPT와 같은 대형 언어 모델이 큰 영향력을 갖게 되었지만, 외부 지식을 활용하여 도메인별 작업에 더 적합하게 조정하는 방법에 대한 문제를 완전히 해결하지 못했다. 
    2. 선행 연구들 중 많은 연구들이 해당 지식을 텍스트 샘플에 주입하기 위해 구축된 정렬 휴리스틱에 의존하지만, 무작위로 선택된 지식을 주입하는 것이 정렬된 지식과 비교했을 때 비슷하거나 더 좋은 결과를 보인다는 문제가 있다. 
    3. 이 논문에서는 다양한 이전 작업들에서 발견된 이 문제를 철저히 조사하고, 가장 중요한 해결 방법 중 하나로 LLM에 주입할 외부 지식의 가지치기와 정제에 대한 기초적인 강조를 제안한다. 이 기법을 지식 주입 프레임워크와 최신 LLM에 통합함으로써 도메인 적응형 LLM의 성능을 향상시킬 수 있다는 것을 보여준다.

###### We Are What We Repeatedly Do: Inducing and Deploying Habitual Schemas in Persona-Based Responses (https://aclanthology.org/2023.emnlp-main.678/)
- Anthology ID: 2023.emnlp-main.678 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화 기술의 많은 실제 응용에서는 특정 개발자 지정 페르소나에 따라 응답을 생성해야 하는데, 최근의 대형 언어 모델에서 다양한 페르소나를 추출할 수 있지만, 이러한 모델의 가시성과 예측 불가능성으로 인해 명시적 형태로 페르소나를 지정할 수 있는 것이 바람직하다. 
    2. 이전 연구에서는 페르소나를 일회성의 자기지식 조각 집합으로 표현하고, 대화 시스템이 생성에 사용하기 위해 검색해왔다. 
    3. 하지만 실제 인간 대화에서는 페르소나가 풍부한 스토리 형태의 내러티브를 통해 드러나는 경우가 많은데, 이러한 주관적인 지식은 일상적인 지식을 포함한다. 이 논문에서는 명시적 스키마 표현을 사용하여 이러한 일상적인 지식을 포착하고, 대화 생성에 relevant한 스키마를 검색하여 대형 언어 모델이 페르소나 기반의 응답을 생성하도록 조건을 제공하는 접근 방식을 제안한다.

###### Zero-shot Faithfulness Evaluation for Text Summarization with Foundation Language Model (https://aclanthology.org/2023.emnlp-main.679/)
- Anthology ID: 2023.emnlp-main.679 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 생성 모델의 요약 정확도가 크게 향상되었지만, 여전히 충실성 문제가 있다. 
    2. 이 논문에서는 중간 규모의 foundation 언어 모델을 사용하여 zero-shot 충실성 평가를 진행한다. 
    3. 실험 결과, FFLM (Faithfulness based on Language Model)은 ChatGPT보다 약 24배 적은 파라미터로 모순 감지 및 충실성 평가에서 경쟁력 있는 결과를 보이고 있다.

###### TaskWeb: Selecting Better Source Tasks for Multi-task NLP (https://aclanthology.org/2023.emnlp-main.680/)
- Anthology ID: 2023.emnlp-main.680 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 NLP 분야에서는 다양한 task를 대량으로 학습시킬 때 더 좋은 일반화 성능을 보이는 모델들이 많이 개발되었지만, task간의 관계와 새로운 task에 도움이 되는 훈련 task를 선택하는 방법에 대해서는 잘 이해되지 않았다.
    2. 본 논문에서는 task 간의 관계를 알아내는 것이 pair-wise task transfer를 통해 새로운 task를 학습하는데 도움이 되는 source task를 선택하는데 어떻게 도움이 될 수 있는지 조사하였다.
    3. TaskWeb이라는 큰 규모의 벤치마크를 제공하고, TaskWeb을 활용하여 source task를 선택하고 multi-task 학습을 위한 유용한 훈련 task의 부분 집합을 선택하는 TaskShop이라는 새로운 방법을 제안한다.

###### Improving Bias Mitigation through Bias Experts in Natural Language Understanding (https://aclanthology.org/2023.emnlp-main.681/)
- Anthology ID: 2023.emnlp-main.681 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 데이터셋 내에 있는 편향성은 모델이 in-distribution 데이터에서 높은 성능을 보이지만 out-of-distribution 데이터에서는 성능이 저하되는 원인이 됩니다. 
    2. 우리는 bias experts라고 불리는 이진 분류기를 도입한 새로운 debiasing 프레임워크를 제안하여 이 문제를 해결합니다. 
    3. 실험 결과, 우리의 방법은 auxiliary 모델의 편향성 파악 능력을 향상시키며, 결과적으로 다양한 challenge 데이터셋에서 최첨단 모델을 능가하는 성과를 보였습니다.

###### Semi-supervised multimodal coreference resolution in image narrations (https://aclanthology.org/2023.emnlp-main.682/)
- Anthology ID: 2023.emnlp-main.682 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 본 논문에서는 이미지와 긴 설명 텍스트가 짝 지어진 다중 모달 코레퍼런스 해결에 대해 연구하였다. 다중 모달 콜레퍼런스 해결은 세부적인 이미지-텍스트 매칭 문제, 설명 언어의 내재적인 모호성, 대규모 주석화된 훈련 세트의 부족으로 인해 중요한 도전 요소를 가지고 있다.
    2. 본 논문에서는 이미지-설명 쌍을 활용하여 다중 모달 문맥에서 코레퍼런스와 설명 지지를 해결하는 데이터 효율적인 반지도 학습 접근 방식을 제시한다.
    3. 실험 결과, 제안된 접근 방식이 코레퍼런스 해결과 설명 지지의 과제에서 강력한 기준선보다 양적, 질적으로 더 우수한 성능을 보여주었다.

###### A Predictive Factor Analysis of Social Biases and Task-Performance in Pretrained Masked Language Models (https://aclanthology.org/2023.emnlp-main.683/)
- Anthology ID: 2023.emnlp-main.683 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 pretrained Masked Language Models(MLM)의 사회적 편향성과 관련되는 여러 가지 요소들을 연구한다.
    2. 모델의 크기, 훈련 데이터의 크기, 훈련 과제, 훈련 데이터의 도메인, 토큰화, 프리트레인 데이터에 포함된 언어 등 여러 요소가 사회적 편향성에 영향을 미치는지에 대한 연구이다.
    3. 연구 결과는 토큰화나 모델의 목표 등 이전 연구에서 간과되었던 중요한 요소들에 대한 정보를 제공한다.

###### Argument-based Detection and Classification of Fallacies in Political Debates (https://aclanthology.org/2023.emnlp-main.684/)
- Anthology ID: 2023.emnlp-main.684 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 잘못된 추론을 사용하는 허위 논증인 Fallacies는 때로는 정치적인 논의에서 사용되며, 공공 의견과 정책 결정에 부정확한 결론과 무효한 추론을 야기할 수 있다. 
    2. 이 논문에서는 허위 논증을 자동으로 감지하고 분류하는 두 가지 기여를 제안한다. 첫째, U.S. 대통령 토론의 최신 Trump-Biden 토론을 포함하여 Fallacies로 주석 달린 ElecDeb60To16 데이터셋을 확장한다. 둘째, Transformers 모델을 기반으로 한 신경망 아키텍처를 정의함으로써 허위 논증 감지 및 분류 작업을 수행한다. 
    3. 실험 결과는 텍스트 표현에 transformer 생성 기법을 비텍스트 기능과 결합함으로써 이점을 보여준다.

###### Collaborative Generative AI: Integrating GPT-k for Efficient Editing in Text-to-Image Generation (https://aclanthology.org/2023.emnlp-main.685/)
- Anthology ID: 2023.emnlp-main.685 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최신 T2I 모델의 발전에도 불구하고, 사용자가 만족할 만한 이미지를 받으려면 반복적으로 입력 프롬프트를 편집해야 하는 문제가 있어 시간과 노력이 많이 소요된다.
    2. 본 논문에서는 GPT-k와 같은 대규모 언어 모델의 문장 생성 능력을 활용하여 T2I 생성을 위한 프롬프트 편집 과정을 개선하기 위한 가능성을 탐구한다. 
    3. 실험 결과, GPT-k 모델은 수정자를 추가하는 데 보다 집중하고 사람들은 단어와 구문을 대체하는 경향이 있으며, 주제에 대한 변경도 포함된다는 것을 확인했다. GPT-k 모델이 제안하는 수정사항을 받아들이면 남아 있는 편집 비율이 20-30% 감소할 수 있다는 것을 실험결과로 보였다.

###### SpEL: Structured Prediction for Entity Linking (https://aclanthology.org/2023.emnlp-main.686/)
- Anthology ID: 2023.emnlp-main.686 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Entity linking은 텍스트 일부를 온톨로지나 지식 소스에 연결하여 구조화된 데이터를 생성하는 연구 분야인데, 이 논문에서는 각각의 토큰을 entity로 분류하고, 토큰 예측을 종합하는 structured prediction을 entity linking에 다시 적용하는 방법을 제안한다.
    2. SpEL (Structured prediction for Entity Linking)은 entity linking 작업에 structured prediction을 적용하기 위해 새로운 아이디어인 정제된 fine-tuning 단계, 컨텍스트에 민감한 예측 종합 전략, 모델의 출력 어휘 크기 축소 및 훈련과 추론 과정에서의 토큰화 불일치 문제를 해결하는 솔루션으로 성능이 뛰어나다고 결과를 보여준다.
    3. AIDA benchmark 데이터셋에 대해 SpEL이 Wikipedia entity linking에서 state-of-the-art를 능가하는 성능을 보이며, 파라미터 수와 추론 속도면에서 계산 효율성이 매우 높다.

###### Architectural Sweet Spots for Modeling Human Label Variation by the Example of Argument Quality: It’s Best to Relate Perspectives! (https://aclanthology.org/2023.emnlp-main.687/)
- Anthology ID: 2023.emnlp-main.687 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 처리에서 많은 주석 작업들은 객관적인 레이블에 대한 서로 다른 유효하고 정당한 관점이 있을 수 있는 주관적인 특성을 가지고 있다. 이러한 특성은 판단 예측에서도 적용되며, 단일 실제 값의 부여가 의심스러울 수 있다. 동시에, 주장의 뒷받침되는 일반적으로 인정되는 개념들이 존재한다. 
    2. 각 주석 작업자별로 레이블을 예측하지만 서로 다른 주석 작업자 사이의 관계를 모델링하는 레이어를 포함하는 모델 아키텍처는 장점이 있다.
    3. 주관성에 대한 접근 방식에서 개별적 관점을 관련시키는 것이 유익할 수 있음을 보여준다.

###### Explicit Planning Helps Language Models in Logical Reasoning (https://aclanthology.org/2023.emnlp-main.688/)
- Anthology ID: 2023.emnlp-main.688 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다양한 자연어 처리 작업에서 언어 모델은 놀라운 성능을 보여 왔으나, 이 논문에서는 LEAP이라는 새로운 시스템을 제안한다. 이 시스템은 논리적 추론을 수행하고 추론 과정에 명시적인 계획을 통합하여 미래 결과를 고려한 이익 추론을 할 수 있다. 또한 희미한 특징으로부터 시스템을 보호하기 위한 교육 전략을 제안한다.
    2. 작은 T5 모델을 사용한 LEAP 시스템은 GPT-3와 비교했을 때 약 1B의 인자 수로 GPT-3의 175 배 작은 반면에 경쟁력 있는 성능을 보인다. GPT-3.5를 사용한 경우에는 PrOntoQA 데이터셋에서도 chain-of-thought 접근법보다 더 나은 성능을 보인다.
    3. 명시적 계획은 시스템의 성능에 중요한 역할을 하는 것을 보이기 위해 포괄적인 실험을 수행했다.

###### clembench: Using Game Play to Evaluate Chat-Optimized Language Models as Conversational Agents (https://aclanthology.org/2023.emnlp-main.689/)
- Anthology ID: 2023.emnlp-main.689 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최신 작업에서는 "Situated Language Understanding Agents"의 체계적 평가 방법론을 제안하였으며, "상황에 맞는 언어 이해 에이전트"는 언어 및 비언어적 맥락에서 작동하는 에이전트들을 의미한다.
    2. 이 논문에서는 LLMs (Large Language Models)이 (시뮬레이터로) 이러한 에이전트들로 이해될 수 있다는 주장을 하고 있는데, 이 연결을 통해 LLMs의 평가를 게임 형태의 제약된 설정에서 수행함으로써 의미있게 할 수 있을지에 대해 탐구한다.
    3. 실제 채팅에 최적화된 LLMs는 게임 플레이 지시를 일정 수준의 성공으로 따를 수 있는 능력을 가지며, 게임의 목표를 얼마나 잘 달성하는지에 따라게임 플레이의 질도 개발 주기에 따라 향상되는 것을 확인하였다. 비교적 단순한 예시 게임들에 대해서도 측정 지표들은 아직 포화되지 않았으며, 이 제안된 도구가 여전히 진단적 가치를 가질 것으로 추측된다.

###### Explaining with Contrastive Phrasal Highlighting: A Case Study in Assisting Humans to Detect Translation Differences (https://aclanthology.org/2023.emnlp-main.690/)
- Anthology ID: 2023.emnlp-main.690 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 NLP 모델의 예측을 설명하는 방법으로 "어떤 토큰이 이 예측에 기여한 것인가?" 에 대답하는 것보다 "두 입력 사이의 어떤 차이가 이 예측을 설명하는가?" 에 대답하는 것이 더 유용하다고 주장한다.
    2. 저자들은 phrase alignment guided erasure를 통해 시맨틱 분기 모델의 예측을 설명하는 contrastive phrasal highlights 생성 기법을 소개한다.
    3. 실험 결과, 이 방법은 유명한 사후 주목 기법보다 크로스-언어적 시맨틱 차이에 대한 인간의 이유와 더 일치하며, 사람들이 인간 번역과 중요한 기계 번역 오류에서 세밀한 의미 차이를 잘 감지하는 데 도움이 되었다.

###### Polyglot or Not? Measuring Multilingual Encyclopedic Knowledge in Foundation Models (https://aclanthology.org/2023.emnlp-main.691/)
- Anthology ID: 2023.emnlp-main.691 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 연구에서는 foundation model들이 다양한 언어적 맥락에서 백과사전적 지식을 회상할 수 있는 능력을 평가하였다.
    2. 20개 언어로 이루어진 303k개의 사실적 연결과 대조적 사실들을 포함한 데이터셋을 구축하고, 다국어 테스트에서 5개의 모델을 평가하였다.
    3. LLaMA 모델이 다국어와 영어 전용 테스트에서 가장 높은 점수를 달성하였으나, LLaMA의 에러 분석에서는 영어 이외의 언어에서의 사실 회상 능력의 제한과 사실 대상의 위치와 성별과 관련된 어려움이 나타났다. 이러한 결과로 현재의 foundation 모델들은 다국어에는 아직 멀었다는 것을 시사한다.

###### Anchoring Fine-tuning of Sentence Transformer with Semantic Label Information for Efficient Truly Few-shot Classification (https://aclanthology.org/2023.emnlp-main.692/)
- Anthology ID: 2023.emnlp-main.692 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Few-shot 분류는 강력한 기술이지만, 훈련에는 상당한 계산 능력과 데이터가 필요하다. 이 논문에서는 AncSetFit이라는 효율적인 방법을 제안하며, 작은 모델 크기와 클래스 당 2-8개의 훈련 인스턴스만으로도 적은 데이터 상황에서 좋은 성능을 얻을 수 있다.
    2. AncSetFit은 fine-tuning에 Sentence Transformer 모델을 사용하며, 문장 임베딩을 통해 작업과 레이블 정보를 가지고 앵커링한다. 이를 통해 contrastive learning과 triplet loss를 사용하여 같은 클래스의 훈련 인스턴스가 임베딩 공간에서 자신의 텍스트 의미 레이블 정보와 가장 가까워지도록 하여 서로 다른 클래스의 인스턴스를 더 강하게 임베딩 한다.
    3. AncSetFit은 SST-5, 감정 탐지, AG News 데이터에서 적은 데이터 상황에서 기존 방법들과 비교하여 강한 성능을 얻었으며, 한 클래스 당 단 두 개의 예제만으로도 좋은 성능을 보였다.

###### UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and Distillation of Rerankers (https://aclanthology.org/2023.emnlp-main.693/)
- Anthology ID: 2023.emnlp-main.693 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 많은 정보 검색 작업들에서 fine-tuning을 위해 큰 양의 라벨링된 데이터셋이 필요하지만, 이러한 데이터셋은 종종 이용 불가하고, 도메인 변화로 인해 실제 응용에 대한 유효성이 빠르게 감소할 수 있다. 
    2. 이 논문에서는 대규모 언어 모델 (LLM)을 사용하여 저렴하게 많은 수의 합성 쿼리를 생성하는 방법을 개발하고 제시한다. 
    3. 제안된 기법은 zero-shot 정확도를 향상시키며, 표준 재순위 메서드보다 매우 낮은 대기 시간을 달성한다.

###### TATA: Stance Detection via Topic-Agnostic and Topic-Aware Embeddings (https://aclanthology.org/2023.emnlp-main.694/)
- Anthology ID: 2023.emnlp-main.694 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 패시지의 태도 감지는 인터넷에서 다양한 태도와 믿음을 이해하는 데 중요하다. 그러나 주어진 주제에 대한 패시지의 태도는 종종 해당 주제에 달려 있기 때문에 보이지 않은 주제에 일반화되는 태도 감지 모델을 만드는 것은 어렵다. 
    2. 우리는 contrastive learning과 뉴스 기사로 구성된 라벨이 없는 데이터셋을 사용하여 일반적인 주제를 위한 임베딩과 특정 주제를 위한 임베딩을 학습하여 하향식 태도 감지에 사용하는 방법을 제안한다. 
    3. 전체 TATA 모델에서 이러한 임베딩을 결합하여 여러 공개적인 태도 감지 데이터셋에서 최고 수준의 성능을 달성한다.

###### Data Similarity is Not Enough to Explain Language Model Performance (https://aclanthology.org/2023.emnlp-main.695/)
- Anthology ID: 2023.emnlp-main.695 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델은 많은 다운스트림 태스크에서 높은 성능을 보이지만 모든 태스크에는 아니다. 이 논문에서는 다운스트림 태스크의 성능과 사전 학습 데이터의 유사성과의 상관관계를 확인하기 위해 Pile과 C4 사전 학습 데이터셋을 사용하여 대규모 비교를 실시하였다.
    2. 유사성과 성능은 멀티링귀얼 데이터셋에서 상관관계를 보이지만, 다른 벤치마크에서는 유사성 측정 지표들에 해당하는 정확도나 서로의 상관관계와 상관없다는 의외의 결과를 얻었다.
    3. 이는 사전 학습 데이터와 다운스트림 태스크 사이의 관계가 흔히 예상되는 것보다 더 복잡할 수 있다는 것을 시사한다.

###### Zero-shot Sharpness-Aware Quantization for Pre-trained Language Models (https://aclanthology.org/2023.emnlp-main.696/)
- Anthology ID: 2023.emnlp-main.696 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 메모리 오버헤드를 줄이고 추론을 가속화하기 위한 양자화는 특히 대규모 사전 훈련 언어 모델 (PLM) 시나리오에서 유망한 접근 방법입니다. 그러나 보안 및 개인 정보 보호 문제로 인해 원래의 훈련 데이터에 액세스 할 수 없으므로 zero-shot 양자화의 수요가 나타났습니다.
    2. 최신 zero-shot 양자화 방법 중 대부분은 주로 컴퓨터 비전 작업에만 적용되며, 생성적 적대적 학습 과정에서의 과적합 문제를 간과하여 부적절한 성능을 보입니다.
    3. 이 논문에서는 ZSAQ 프레임워크를 제안하여 다양한 PLM의 zero-shot 양자화를 위한 새로운 zero-shot sharpness-aware quantization (ZSAQ) 알고리즘을 제안합니다. 이 알고리즘은 양자화 정확성과 모델 일반화를 개선하기 위해 minimax 문제를 최적화하는 것을 목표로합니다.

###### Deciphering Stereotypes in Pre-Trained Language Models (https://aclanthology.org/2023.emnlp-main.697/)
- Anthology ID: 2023.emnlp-main.697 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 Transformer 기반의 사전 학습 언어 모델에 존재하는 인종/민족적 스테레오 타입들을 다루고, 해당 편향이 어떻게 인코딩되는지에 대한 이해를 깊게 하기 위한 목적을 가지고 있다.
    2. 이를 위해, 우리는 모델 프로빙과 텍스트 분석을 결합한 방법으로 PLM의 스테레오타입 인코딩 행동을 조사하기 위한 쉽게 사용할 수 있는 프레임워크를 제시한다.
    3. 우리의 연구 결과는 PLM 내의 일부 어텐션 헤드가 스테레오타입을 인코딩하는 데 주로 관여하며, 이러한 어텐션 헤드에 대한 어텐션 맵을 통해 특정 소수 집단에 대한 스테레오타입을 식별할 수 있음을 보여준다. 이러한 통찰력을 활용하여, 우리는 PLM의 편향을 없애기 위한 어텐션 헤드 가지치기 방법을 제안한다.

###### An “Integrative Survey on Mental Health Conversational Agents to Bridge Computer Science and Medical Perspectives” (https://aclanthology.org/2023.emnlp-main.698/)
- Anthology ID: 2023.emnlp-main.698 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 정신 건강 대화 에이전트(a.k.a. 챗봇)는 정신 건강 문제를 겪는 사람들에게 접근 가능한 지원을 제공할 수 있는 잠재력을 가지고 있어 널리 연구되고 있다.
    2. 이전에 진행된 설문 조사는 주로 컴퓨터 과학이나 의학 분야에서 발표된 논문들을 고려하여 이분화를 초래하고 두 분야 간 유익한 지식 공유를 어렵게 만들었다.
    3. 이 연구에서는 PRISMA 프레임워크를 사용하여 컴퓨터 과학과 의학 분야에서 발표된 534편의 논문을 검토하고 관련된 특징과 실험적 설계 기법을 가진 136개의 주요 논문을 밝혀냈다.

###### Do LLMs Understand Social Knowledge? Evaluating the Sociability of Large Language Models with SocKET Benchmark (https://aclanthology.org/2023.emnlp-main.699/)
- Anthology ID: 2023.emnlp-main.699 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. LLM은 구어, 문맥, 추론과 같은 다양한 NLP 태스크에서 잘 수행되었으나, 사회적 언어 이해를 어떻게 측정할지에 대한 기준이 부족하다. SocKET은 사회적 지식을 테스트하는 58개의 NLP 태스크로 구성된 신뢰할 수 있는 벤치마크이다.
    2. 해당 벤치마크를 사용하여 현재 모델들은 중간 성능을 달성하지만, 다른 유형과 카테고리의 태스크 간에 업무 이전이 가능하며, 이는 이론에서 예측되었다.
    3. zero-shot 평가를 통해 사전 훈련된 모델이 이미 사회적 언어 이해의 일부 기능을 가지고 있으며, 한 카테고리의 태스크에 대한 학습은 다른 카테고리에서의 zero-shot 테스트 성능을 향상시킬 수 있음을 보여준다.

###### Interventional Rationalization (https://aclanthology.org/2023.emnlp-main.700/)
- Anthology ID: 2023.emnlp-main.700 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "선택적인 서술은 신경망의 해석성을 향상시키기 위해 입력의 부분집합 (rationales) 을 선택하여 예측 결과를 설명하는 것이다. 기존 방법들은 아직도 데이터의 연관성(spurious correlations)에 의존하여 서술을 구성하고 예측을 한다는 문제가 있다."
    2. "본 연구에서는 인과 이론에 영감을 받아 인과 서술을 발견하기 위해 interventional rationalization (Inter-RAT)를 개발한다. 구조적인 인과 모델을 사용하여 입력, 서술, 결과 간의 인과관계를 분석하고, 인과관계에서 confounder를 식별하여 입력과 서술, 서술과 결과 간의 spurious correlations을 발견한다."
    3. "또한, 인과적 수식 개입 방법을 제안하여 들어오는 방향의 역방향 조정을 통해 입력과 서술 사이의 spurious correlations을 제거한다. 이를 통해 우리는 선택된 서술과 결과 사이의 연관성을 제거하면서 서술의 희소성 제약의 한계를 분석하고 이 연관성을 제거한다."

###### Don’t Take This Out of Context!: On the Need for Contextual Models and Evaluations for Stylistic Rewriting (https://aclanthology.org/2023.emnlp-main.701/)
- Anthology ID: 2023.emnlp-main.701 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 문체적 텍스트 재작 방법과 평가 메트릭은 문장 수준에서 작동하기 때문에 텍스트의 넓은 문맥을 무시하면 일반적이고 모호하며 일관성 없는 재작을 선호할 수 있다. 
    2. 이 논문에서는 문장이 나타나기 전의 텍스트 문맥을 문체적 텍스트 재작의 재작과 평가 단계에 통합하는 방법을 조사하고, 원래 문장과 문맥적 일관성을 결합한 새로운 평가 메트릭인 CtxSimFit를 소개한다. 
    3. 비문맥적과 문맥적 재작을 호의하는 것을 비교적으로 실험한 결과, 인간은 문맥적 재작을 비문맥적인 재작보다 훨씬 적합하고 자연스러워 평가하여, 기존의 문장 수준 자동 평가 메트릭 (ROUGE, SBERT 등)은 인간에 의한 선호와 상관 관계가 낮음을 보였다.

###### Axiomatic Preference Modeling for Longform Question Answering (https://aclanthology.org/2023.emnlp-main.702/)
- Anthology ID: 2023.emnlp-main.702 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. ChatGPT나 GPT-4와 같은 대형 언어 모델의 놀라운 능력은, 인간의 선호도를 보상 모델에 인코딩하여 강화학습하고자 하는 과정에서 부분적으로 유래한다.
    2. 이 논문에서는 인간의 선호도에 대한 가이드라인을 식별하고 이를 유지하기 위해 다양한 선호 신호를 생성하기 위한 공리적인 프레임워크를 개발한다.
    3. 이 프레임워크를 사용하여 긴 형식의 질문에 대한 답변의 점수를 매기기 위한 모델을 훈련시켰고, 이 모델은 GPT-4보다 더 자주 인간의 선호도와 일치하는 결과를 나타냈다.

###### Countering Misinformation via Emotional Response Generation (https://aclanthology.org/2023.emnlp-main.703/)
- Anthology ID: 2023.emnlp-main.703 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사회적 보정은 소셜미디어 플랫폼(SMP)에서의 거짓 정보 확산에 대한 신뢰성 있는 방법이다. 
    2. 기존의 작업에서 거짓 정보를 사회적 보정하는 데 사실 확인자가 간접적으로 참여하지만 소셜 미디어 커뮤니케이션에서 흔히 사용되는 스타일과 기법과 통합된 참여는 시도한 적이 없다. 
    3. 이 논문에서는 VerMouth라는 첫 번째 대형 데이터 세트를 제시하고, 이 데이터 세트를 사용하여 훈련 된 모델이 출력 품질과 일반화 능력 측면에서 상당한 개선을 보여주는 포괄적인 실험을 제공한다.

###### Seq2seq is All You Need for Coreference Resolution (https://aclanthology.org/2023.emnlp-main.704/)
- Anthology ID: 2023.emnlp-main.704 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 coreference resolution 작업에서는 task-specific 모델이 최고의 성능을 내기 위해 필수적이라고 주장한다. 그러나 이 연구에서는 그런 모델이 필요하지 않다는 설득력 있는 증거를 제시한다.
    2. 연구자들은 사전 학습된 seq2seq transformer 모델을 finetuning하여 coreference 주석을 인코딩하는 태그된 시퀀스로 입력 문서를 매핑하는 방법을 사용한다. 이렇게 간단한 모델이 문헌에서 최고의 coreference 시스템에 근접하거나 그보다 우수한 성능을 보여준다.
    3. 더 간단한 seq2seq 모델 버전을 고려하여 태그된 구간만 생성하는 방법도 높은 성능을 보이며, 모델 크기, 감독 비율, 시퀀스 표현 선택 등이 성능에 중요한 영향을 미침을 분석 결과로 보여준다.

###### Integrating Language Models into Direct Speech Translation: An Inference-Time Solution to Control Gender Inflection (https://aclanthology.org/2023.emnlp-main.705/)
- Anthology ID: 2023.emnlp-main.705 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 스피치 번역 시스템은 말하는 사람을 지칭하는 단어를 번역할 때 기본 남성 성적인 것이나 오해를 일으킬 수 있는 음성 특성에 의존해서는 안 된다. 대신 스피커의 선호에 따라 성별을 할당해야 한다.
    2. 기존의 해결책들은 효과적이지만, 성별으로 라벨링된 ST 데이터에서 전용 모델을 재훈련해야 하는 등 실제적으로 적용하기 어렵다.
    3. 본 논문에서는 ST에서 스피커와 관련된 성별 변형을 제어하기 위한 첫 번째 추론 시점 솔루션을 제안한다. 실험결과, 해당 솔루션은 기본 모델 및 훈련 시 최적화 전략에 비해 여성형에 대해 최대 31.0점 및 1.6점의 성별 정확도 향상을 보였다. 음성 특성이 해당 성별과 충돌하는 어려운 상황에서는 훨씬 큰 향상 (최대 32.0 및 3.4)이 있었다.

###### StoryAnalogy: Deriving Story-level Analogies from Large Language Models to Unlock Analogical Understanding (https://aclanthology.org/2023.emnlp-main.706/)
- Anthology ID: 2023.emnlp-main.706 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인류 추론에 있어서 서사 간 유추는 중요하다. 이 논문에서는 사람들이 유추를 인식하고 생성하는 능력을 평가하기 위해, StoryAnalogy라는 대규모 스토리 수준의 유추 말뭉치를 구축하였다.
    2. 제안한 평가는 유추 식별과 생성의 첫번째 평가로서, 문장 임베딩 모델에게 어려운 성과를 보였다. ChatGPT와 LLaMa와 같은 최신 규모의 언어 모델도 식별 성능에서 인간의 성능을 따라잡지 못하였다.
    3. 또한, StoryAnalogy의 데이터가 LLMs에서 유추 생성의 품질을 향상시킬 수 있다는 것을 관찰했으며, fine-tuned FlanT5-xxl 모델은 zero-shot ChatGPT와 비교 가능한 성능을 보였다.

###### Beyond Detection: A Defend-and-Summarize Strategy for Robust and Interpretable Rumor Analysis on Social Media (https://aclanthology.org/2023.emnlp-main.707/)
- Anthology ID: 2023.emnlp-main.707 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 소셜 미디어의 영향력이 증가함에 따라 가짜 뉴스에 노출될 가능성이 높아지고 있다. 이 논문에서는 텍스트 콘텐츠와 전파 경로를 분석하여 소셜 미디어에서 가짜 뉴스를 탐지하는 방법을 제안한다. 
    2. 기존의 탐지 모델들은 응답 레벨에서 흔히 관측되는 악의적인 공격을 고려하지 않고 있으며, 해석 가능성도 떨어진다. 
    3. 이 논문에서 제안하는 DAS 프레임워크는 비슷한 의견을 공유하는 응답을 걸러내고 추출 및 요약 방식으로 각 대화 스레드의 응답 게시물을 요약하여 다중 관점의 예측 설명을 제공한다.

###### Crystal: Introspective Reasoners Reinforced with Self-Feedback (https://aclanthology.org/2023.emnlp-main.708/)
- Anthology ID: 2023.emnlp-main.708 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이전의 관점의 연속성(chain-of-thought) 및 그 변형과 같은 기존의 공통 감성 추론 방법은 공통 감성 추론에 필요한 "introspective"한 지식을 포착하기에 부족하며, 생성과 활용 사이의 상호 적응을 설명하는 데 어려움이 있다. 
    2. 이 논문에서는 **Crystal**이라는 새로운 방법을 제안하여 감성 추론에 필요한 introspection과 knowledge-grounded 추론 모드를 상호 점검하고 조정한다. 
    3. 실험 결과는 Crystal이 표준 감독 지도 기법 및 chain-of-thought 초집악 방식보다 우수한 성능을 보이며 공통 감성 추론 과정의 투명성을 향상시킨다는 것을 보여준다.

###### DiffS2UT: A Semantic Preserving Diffusion Model for Textless Direct Speech-to-Speech Translation (https://aclanthology.org/2023.emnlp-main.709/)
- Anthology ID: 2023.emnlp-main.709 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. diffusion generative models가 이미지 생성에서 큰 성공을 거두었지만, 특히 번역과 같은 음성 생성 작업에 효과적으로 적용하는 것은 어려운 문제이다.
    2. 저밀도 음성 데이터의 경우, 변환된 이산적인 음성 단위 sequence는 대응되는 텍스트 전사보다 훨씬 더 긴데, 이는 기존 자기 회귀 모델에 큰 도전 과제를 제기한다.
    3. 이 논문에서는 연속적인 음성 표현 공간에서 정확한 확산 과정을 적용하고, 이산적인 음성 단위 공간에서 역확산 과정을 적용하여 새로운 확산 모델을 제안한다.

###### BioFEG: Generate Latent Features for Biomedical Entity Linking (https://aclanthology.org/2023.emnlp-main.710/)
- Anthology ID: 2023.emnlp-main.710 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 생물의학 텍스트 처리에서 필수적인 과제인 생물의학 entity linking은 많은 경우에 드문 생물 기관들이라는 특성으로 인해 어렵다. 이러한 미처 개념하지 않은 entity들을 이해하는 데 제한이 있어 전통적인 생물의학 entity linking 모델들은 여러 종류의 링킹 오류가 발생한다.
    2. 본 논문에서는 BioFEG라는 새로운 latent feature generation 프레임워크를 제안한다. 이 프레임워크는 도메인 지식을 활용하여 생성적 적대 신경망을 훈련시켜 미처 개념하지 않은 entity들에 대한 latent 시맨틱 feature를 생성한다. 이러한 feature를 활용하여 모델은 드문 entity가 관련된 모호한 언급에 대해 보다 정확한 링킹 결정을 내릴 수 있게 된다.
    3. 두 개의 벤치마크 데이터셋에서의 실험을 통해 우리가 제안한 프레임워크의 우수성을 입증하였다.

###### TRIGO: Benchmarking Formal Mathematical Proof Reduction for Generative Language Models (https://aclanthology.org/2023.emnlp-main.711/)
- Anthology ID: 2023.emnlp-main.711 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 언어 생성 모델의 추론 능력을 탐구하기 위해 자동 정리 증명 (ATP)이 매력적인 도메인이 되었다. 그러나, 기존 ATP 벤치마크는 주로 상징적 추론에 초점을 맞추었고, 복잡한 숫자 조합 추론을 포함하지 않았다.
    2. 이 논문에서는 TRIGO라는 ATP 벤치마크를 제안한다. 이 벤치마크는 모델이 단계별로 증명을 하여 삼각함수 표현식을 간소화하는 능력을 요구하며, 또한 공식의 추론 능력과 숫자 항들을 조작, 그룹화, 인수분해하는 능력을 평가한다.
    3. 우리는 웹에서 삼각함수 표현식과 그 간소화된 형태를 수집하고, 이를 수동으로 간소화하는 과정을 주석 처리하고, "Lean" 공식 언어 시스템으로 번역한다. 또한, 주석 처리된 샘플에서 추가적인 예제를 자동으로 생성하여 데이터셋을 확장한다.

###### Physician Detection of Clinical Harm in Machine Translation: Quality Estimation Aids in Reliance and Backtranslation Identifies Critical Errors (https://aclanthology.org/2023.emnlp-main.712/)
- Anthology ID: 2023.emnlp-main.712 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기계 번역(MT)의 실용 적인 사용에서 사용자들은 출력에 얼마나 의존해야 하는지를 결정하기 위한 번역 품질에 대한 정보가 부족하다. 
    2. 품질 평가 연구의 진전은 MT 품질을 자동으로 평가할 수 있는 기법을 제공하지만, 이러한 기법들은 어느 특정한 사용 환경 외부에서 사람의 판단과 비교하여 평가되는 경우가 주로다.
    3. 이 논문에서는 비상실에서의 응급실 퇴원 지시서를 사용하여 품질 평가 피드백을 실제 고위험 의료 환경에서 인간 연구로 평가한다. 품질 평가를 기반으로 한 적절한 의존 및 backtranslation은 QE만으로는 감지할 수 없는 임상적으로 더 위험한 오류를 의사들이 감지하는 데 도움이 된다.

###### Vicarious Offense and Noise Audit of Offensive Speech Classifiers: Unifying Human and Machine Disagreement on What is Offensive (https://aclanthology.org/2023.emnlp-main.713/)
- Anthology ID: 2023.emnlp-main.713 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 욕설 감지는 콘텐츠 모더레이션의 중요한 요소이지만, 욕설에 대한 판단은 주관적일 수 있다. 이 논문은 실제 사회 웹 정치적 담론에서 머신과 인간 모더레이터가 어떻게 욕설에 대해 의견 차이를 가지는지 조사한다.
    2. 연구 결과, 모더레이터(인간 및 머신) 간의 의견 차이가 크며, 정치적 성향을 기반으로 다른 인간 판정자가 어떻게 응답할지 예측하는 것은 어렵다는 것을 보여준다.
    3. 자연스러운 노이즈의 조합으로 모더레이션 결과가 크게 다르며, 정치적 성향과 민감한 문제는 일인칭 및 간접적인 욕설에 모두 영향을 미친다.

###### Generating Summaries with Controllable Readability Levels (https://aclanthology.org/2023.emnlp-main.714/)
- Anthology ID: 2023.emnlp-main.714 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 읽기 가능성은 텍스트를 이해하기 쉬운 정도를 나타내며, 텍스트의 복잡성, 주제 및 독자의 배경 지식 등 여러 요인이 영향을 미친다. 
    2. 이 논문에서는 세밀한 제어를 통해 특정 읽기 가능성 수준에서 요약을 생성하는 기술을 연구한다. 
    3. CNN/DM 데이터셋을 기반으로 한 실험 결과, 우리의 생성 방법은 다양한 읽기 가능성 메트릭과 인간 판단을 통해 읽기 가능성 제어를 크게 개선시키며, 요약에서 제어 가능한 읽기 가능성에 대한 강력한 기준을 제시한다.

###### mAggretriever: A Simple yet Effective Approach to Zero-Shot Multilingual Dense Retrieval (https://aclanthology.org/2023.emnlp-main.715/)
- Anthology ID: 2023.emnlp-main.715 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다국어 정보 검색(MLIR)은 인간 주석이 필요하여 데이터 생성이 많은 노력을 요구하는 난해한 작업이다. 이 논문에서는 mAggretriever를 소개하는데, 이 모델은 사전 훈련된 다국어 transformer (mBERT와 XLM-R)의 의미적 및 어휘적 특징을 효과적으로 활용하여 밀집 검색(dense retrieval)을 수행한다. 
    2. mAggretriever는 근사 마스킹 언어 모델 예측을 사용하여 어휘적 특징을 계산하는데, 이를 통해 훈련 및 추론 효율성을 향상시킨다. 이를 통해 mAggretriever는 영어 훈련 데이터에만 fine-tuning 된 경우에도 대규모 MLIR 훈련 데이터로 추가 훈련을 받은 기존 최첨단 다국어 밀집 검색 모델보다 우수한 성능을 보인다. 
    3. 추가적으로, 이 논문에서는 mAggretriever의 코드를 url에서 확인할 수 있다.

###### CodeFusion: A Pre-trained Diffusion Model for Code Generation (https://aclanthology.org/2023.emnlp-main.716/)
- Anthology ID: 2023.emnlp-main.716 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 마치 마지막 한 줄만 수정 가능한 개발자처럼, 이 논문에서는 자연어로부터의 코드 생성 모델에서 이전 토큰을 다시 고려하기 어렵다는 한계를 극복하기 위해 CodeFusion을 제안한다.
    2. CodeFusion은 완전한 프로그램을 반복적으로 노이즈를 제거하며 생성하기 때문에 이전에 생성된 토큰을 쉽게 재고려할 수 있으며, Bash, Python, Microsoft Excel 조건부 서식 (CF) 규칙에 대한 자연어에서 코드로의 생성 작업에서 우수한 성능을 보인다.
    3. CodeFusion은 자연어와의 조화를 잘 유지하여, top-1 정확성은 상위 방법들과 비슷하지만, top-3 및 top-5 정확성에서 상위 방법들보다 우수한 성능을 보인다.

###### CESAR: Automatic Induction of Compositional Instructions for Multi-turn Dialogs (https://aclanthology.org/2023.emnlp-main.717/)
- Anthology ID: 2023.emnlp-main.717 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Instruction-based multitasking(지시 중심의 다중작업)은 다중 턴 대화 애플리케이션에서 대형 언어 모델의 성공에 중요한 역할을 한다. 그러나 공개적으로 사용 가능한 대형 언어 모델은 ChatGPT와 같은 최신 모델에 비해 복잡한 지시 사항과 여러 제약 조건을 가진 경우 성능이 떨어진다.
    2. 본 논문에서는 복잡한 지시사항을 포함하는 대규모 집합을 사용하여 이러한 격차를 좁히는 것이 중요하다는 가설을 세운다. 다중 턴 대화 애플리케이션에 초점을 맞추어, CESAR라고 불리는 새로운 프레임워크를 제안한다.
    3. CESAR를 InstructDial과 함께 사용하여 구성적인 지시(language)를 포함하는 복합 작업(composite tasks)을 도출하는 방법을 개발하였다. 이에 따라 InstructDial++이라는 새로운 벤치마크가 생성되었으며, 이를 활용하여 63개 데이터셋, 86개 기본 작업 및 68개의 복합 작업을 포함하였다.

###### VECHR: A Dataset for Explainable and Robust Classification of Vulnerability Type in the European Court of Human Rights (https://aclanthology.org/2023.emnlp-main.718/)
- Anthology ID: 2023.emnlp-main.718 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 취약성을 인식하는 것은 필요한 지원을 제공하기 위해 개인을 권한을 부여하는 데 중요하다. 하지만 취약성의 개념은 ECtHR에서는 알려져 있지 않으며, NLP 연구가 이에 대하여 다루지 않았다.
    2. 따라서, 우리는 VECHR이라는 새로운 전문가 주석이 달린 다중 라벨 데이터셋을 제안하여 취약성 유형 분류와 설명 근거를 포함하여 ECtHR에서의 연구를 가능하게 한다.
    3. 우리의 결과는 예측 성능과 모델과 전문가 간의 제한된 일치로 인해 작업의 난이도를 보여준다. 또한, 모델의 out-of-domain 데이터 처리에 대한 강건성을 분석하고 전체적으로 제한된 성능을 관찰한다.

###### ACQUIRED: A Dataset for Answering Counterfactual Questions In Real-Life Videos (https://aclanthology.org/2023.emnlp-main.719/)
- Anthology ID: 2023.emnlp-main.719 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다중모달 카운터팩트럴 추론은 AI 시스템에게 중요하지만 도전적인 능력이다. 이는 비전과 언어 입력을 기반으로 가상의 상황의 결과를 예측하는 것을 의미하며, 이를 통해 AI 모델은 실패로부터 학습하고 가정적인 시나리오를 탐색할 수 있다.
    2. 그러나 실제 세계의 다양한 시나리오와 추론 차원에서 모델의 일반화 능력을 신뢰할 수 있는 벤치마크로 삼기 어렵게 만드는 합성 환경이나 특정 유형의 이벤트에 대한 접근만 가능한 몇 개의 데이터셋만 존재한다.
    3. 이 논문에서는 ACQUIRED라는 비디오 질의응답 데이터셋을 개발하여 실제 다양성에 초점을 맞추고, 물리적, 사회적, 시적 등 세 가지 추론 차원을 포괄적으로 평가할 수 있는 신뢰할 수 있는 벤치마크를 제공한다.

###### From Parse-Execute to Parse-Execute-Refine: Improving Semantic Parser for Complex Question Answering over Knowledge Base (https://aclanthology.org/2023.emnlp-main.720/)
- Anthology ID: 2023.emnlp-main.720 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 실행 가능한 논리 형식으로 질문을 파싱하는 것은 지식 기반 질문-답변(KBQA)에서 탁월한 결과를 보여주었지만, 복잡한 KBQA는 복잡한 다단계 추론을 수행해야 하는 더 어려운 작업입니다. 
    2. 이 논문에서는 간단한 파싱-실행-개선 패러다임을 통해 의미 파서의 추론 능력을 풀어낼 수 있는 방법을 탐구합니다. 
    3. 제안된 PER-KBQA는 복잡한 추론 작업의 능력을 크게 향상시킬 수 있는 것을 벤치마크 데이터셋 상의 실험을 통해 보여줍니다.

###### Reward-Augmented Decoding: Efficient Controlled Text Generation With a Unidirectional Reward Model (https://aclanthology.org/2023.emnlp-main.721/)
- Anthology ID: 2023.emnlp-main.721 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델은 다양한 하위 응용 프로그램에서 효과적이나 종종 문제가되는 텍스트를 생성한다. 
    2. 우리는 보상 증강 디코딩(Reward-Augmented Decoding, RAD)을 소개하여 언어 모델이 특정 속성을 가진 텍스트를 생성하도록 유도하는 텍스트 생성 절차를 제안한다.
    3. 우리의 실험 결과는 RAD가 생성 절차만 변경하는 기존 방법들보다 우수한 성능을 보이고 언어 모델 재학습이 필요한 최신 방법들과도 성능이 일치함을 보여준다. 또한 RAD가 매우 큰 언어 모델에서 효과적이며 최소한의 컴퓨팅 오버헤드를 유발하는 것을 검증한다.

###### CORE: A Few-Shot Company Relation Classification Dataset for Robust Domain Adaptation. (https://aclanthology.org/2023.emnlp-main.722/)
- Anthology ID: 2023.emnlp-main.722 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. CORE는 회사 관계와 비즈니스 엔티티에 초점을 맞춘 few-shot relation classification (RC)을 위한 데이터셋으로, 회사 Wikipedia 페이지에서 추출한 12가지 관계 유형의 4,708개 인스턴스와 해당 텍스트 증거를 포함하고 있다. 
    2. CORE 데이터셋은 회사 이름과 비즈니스 엔티티로 인해 다양한 정보가 연결되기 때문에 few-shot RC 모델에 대한 도전을 제공한다. 
    3. CORE 데이터셋에 대한 실험 결과, 기존 도메인에서 훈련된 모델은 CORE에 적응하기 어려워 성능 차이가 크다는 것을 확인했다. 또한 CORE에 훈련된 모델은 영역 일반화에 대한 중요성을 강조하면서 가짜 관련 동사와 같은 표면적인 단서에 의존하지 않고 문맥적 뉘앙스에 집중할 수 있게 해준다는 것을 발견했다.

###### Models See Hallucinations: Evaluating the Factuality in Video Captioning (https://aclanthology.org/2023.emnlp-main.723/)
- Anthology ID: 2023.emnlp-main.723 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 비디오 캡션은 비디오에 대한 자연어로 이벤트를 설명하는 것을 목표로 하지만, 모델이 생성하는 문장들 중 56%가 사실적 오류를 포함하고, 기존 평가 메트릭은 인간의 사실성 주석과 거의 상관관계가 없음을 발견했다.
    2. 우리는 비디오 캡션에서 사실성의 인식이 중요한 문제임을 보여주기 위해 인간 평가와 사실성 주석을 바탕으로 비디오 캡션의 사실성을 재평가하기 위한 약한 지도학습 모델 기반 메트릭인 FactVC를 제안하였다.
    3. FactVC는 이전 메트릭보다 비디오 캡션의 사실성 평가에서 뛰어난 성능을 보였다.

###### Back Transcription as a Method for Evaluating Robustness of Natural Language Understanding Models to Speech Recognition Errors (https://aclanthology.org/2023.emnlp-main.724/)
- Anthology ID: 2023.emnlp-main.724 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 말하는 대화 시스템에서, 음성 인식 시스템의 성능이 자연어 이해 모델의 성능을 저하시킬 수 있다. 
    2. 본 논문에서는 음성 인식 오류가 NLU 모델의 성능에 미치는 영향을 조사하기 위한 방법을 제안한다. 
    3. 제안된 방법은 역전사 절차와 NLU 모델의 성능에 영향을 주는 오류들을 세분화하는 기술을 결합한 것이다.

###### Cabbage Sweeter than Cake? Analysing the Potential of Large Language Models for Learning Conceptual Spaces (https://aclanthology.org/2023.emnlp-main.725/)
- Anthology ID: 2023.emnlp-main.725 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Conceptual Spaces" 이론은 개념의 의미를 나타내는 인식-언어 인지 프레임워크로, 실제 체감적인 특징들과 대응되는 품질 차원들의 집합으로 구성된다. 이 논문에서는 대형 언어 모델(Large Language Models, LLMs)이 개념 공간을 배우는 데에 활용될 수 있는 가능성을 탐구한다.
    2. 실험 결과, LLMs는 어느 정도 의미 있는 표현을 학습하는 데에 사용될 수 있음을 보여준다. 그러나 BERT 계열의 세밀하게 조정된 모델은 GPT-3 모델보다 작은 크기에도 불구하고 일치하거나 더 나은 성능을 발휘할 수 있다.
    3. 이러한 결과는 큰 규모의 모델보다 작은 모델이 문제에 특화된 표현을 더 잘 학습한다는 점에서 흥미로운 결과를 제시한다.

###### Can Language Models Understand Physical Concepts? (https://aclanthology.org/2023.emnlp-main.726/)
- Anthology ID: 2023.emnlp-main.726 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어 모델(LMs)이 상호작용과 실체 세계에서 중요한 전제조건인 물리 개념을 이해할 수 있는지 알 수 없다. 
    2. 이 연구에서는 객체의 형태와 재료와 같은 시각적 개념과 물리적 상호작용을 통해 습득한 개념과 같은 조건을 다루는 벤치마크 VEC를 설계한다.
    3. CLIP 및 BLIP과 같은 시각적으로 향상된 LMs는 체감개념에 대한 인간 수준의 이해력을 얻는 반면, 일부 기본 개념은 스케일 업에서 적용되지 않는다. VEC에 VLMs의 체감지식을 전달하는 증류 방법을 제안하고, 스케일 업 매개변수와 비교할 수 있는 성능 향상을 달성한다.

###### SPT: Learning to Selectively Insert Prompts for Better Prompt Tuning (https://aclanthology.org/2023.emnlp-main.727/)
- Anthology ID: 2023.emnlp-main.727 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 프롬프트 튜닝 방법은 최적의 프롬프트 레이어를 수동으로 선택하는데 제한이 있었고, 프롬프트 튜닝의 잠재력을 활용하지 못했다. 본 연구에서는 학습 가능한 확률 게이트로 제어되는 프롬프트를 중간 레이어에 삽입함으로써 적절한 프롬프트 레이어를 선택하는 Selective Prompt Tuning (SPT) 프레임워크를 제안한다.
    2. 또한 SPT-DARTS라는 새로운 이중 최적화 프레임워크를 제안하여 학습 가능한 게이트를 더 잘 최적화하고 학습된 프롬프트 레이어 설정의 최종 프롬프트 튜닝 성능을 개선할 수 있다.
    3. 실험 결과, SPT 프레임워크는 전체 데이터와 소량 데이터 상황에서 이전의 최고 성능 모델인 PETuning과 비교하여 더 나은 성능을 보여준다.

###### Once Upon a Time in Graph: Relative-Time Pretraining for Complex Temporal Reasoning (https://aclanthology.org/2023.emnlp-main.728/)
- Anthology ID: 2023.emnlp-main.728 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 우리의 물리적 세계는 시간이 지남에 따라 지속적으로 변화하며, 사전 훈련된 언어 모델이 텍스트의 시간적 맥락을 이해하고 추론하는 데 어려움을 겪는다. 
    2. 이 연구에서는 시간과 지식의 관련성이 다른 지식 간의 시간 의존성을 추론하는 다운스트림 태스크를 위해 강화시키는 기존 방법들의 한계를 극복하기 위해 그래프 구조를 활용한다.
    3. 실험 결과 RemeMo는 다양한 설정에서 여러 시간적 질문-답변 데이터셋에서 기준선인 T5보다 우수한 성능을 보였으며, 추가 분석 결과 RemeMo가 장거리 복잡한 시간적 종속성을 모델링하는 데 특히 효과적인 것으로 나타났다.

###### Expository Text Generation: Imitate, Retrieve, Paraphrase (https://aclanthology.org/2023.emnlp-main.729/)
- Anthology ID: 2023.emnlp-main.729 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 설명서 문서는 복잡한 정보를 독자에게 전달하는 중요한 도구이지만, 손으로 설명서 텍스트를 작성하는 것은 콘텐츠 계획, 다양한 출처에서 사실 확보, 사실을 명확하게 종합적으로 결합하는 능력이 필요하기 때문에 어려운 과정이다.
    2. 우리는 이러한 부담을 줄이기 위해, 지식 소스를 지능적으로 탐색하여 토픽에 대한 정확하고 스타일 일관성 있는 설명서 텍스트를 자동으로 생성하기 위한 "설명서 텍스트 생성" 과제를 제안한다.
    3. 우리는 retrieval-augmented 모델의 한계를 극복하고, 콘텐츠 계획, 사실 확보 및 문장 재구성을 반복하는 IRP라는 프레임워크를 개발하여 이 과제를 해결한다. 우리는 새롭게 수집한 세 가지 다양한 데이터셋에서의 실험을 통해, IRP가 독자에게 정확한 정보를 제공하는 사실적이고 조직화된 설명서 텍스트를 생성한다는 것을 보여준다.

###### Large-scale similarity search with Optimal Transport (https://aclanthology.org/2023.emnlp-main.730/)
- Anthology ID: 2023.emnlp-main.730 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Wasserstein 거리(Wasserstein distance)는 확률 분포를 비교하기 위한 강력한 도구로 NLP에서 문서 분류 및 검색에 널리 사용된다." 
    2. "WMD는 다양한 NLP 작업에서 우수한 성능을 보이지만, 계산 비용이 크고 대규모 분포 비교에 적합하지 않다는 한계점이 있다." 
    3. "본 연구에서는 Wasserstein 거리를 기반으로 하는 간단하고 효과적인 최근접 이웃 검색 방법을 제안하였으며, 해당 근사 방법은 기존의 Wasserstein 거리와 비교 가능한 성능을 가지고 있으며 기존 방법보다 3개 차원 빠르게 계산할 수 있다는 것을 실험을 통해 입증하였다."

###### Enhancing Textbooks with Visuals from the Web for Improved Learning (https://aclanthology.org/2023.emnlp-main.731/)
- Anthology ID: 2023.emnlp-main.731 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 교과서는 고품질 교육을 학생에게 전달하는 주요 매체 중 하나이다. 그러나 많은 교과서는 학생 학습을 지원하기 위한 흥미로운 시각 자료가 부족하다.
    2. 본 논문에서는 비전-언어 모델의 효과성을 조사하여 웹에서 교과서를 자동으로 이미지로 향상하는 방법을 제시한다.
    3. 수학, 과학, 사회과학 및 비즈니스 분야의 e-교과서 데이터셋을 수집하고, 웹 이미지를 교과서에 적절하게 할당하는 일치 최적화 문제로 설정하여 그 효과를 검증하였다.

###### Continual Event Extraction with Semantic Confusion Rectification (https://aclanthology.org/2023.emnlp-main.732/)
- Anthology ID: 2023.emnlp-main.732 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 개설학습 추출에서 annotation의 갱신으로 인해 semantic confusion이 생기고 event type들 사이의 불균형 문제가 악화되는 것을 관찰하였다.
    2. 우리는 semantic confusion을 완화하기 위해 문장마다 가짜 라벨을 만들고 이전 모델로부터 transfer learning을 통해 pivotal knowledge를 전달하는 새로운 모델을 제안한다.
    3. 실험 결과, 우리의 모델은 기존 모델들보다 뛰어나며 불균형 데이터에 효과적이다.

###### An Empirical Study of Translation Hypothesis Ensembling with Large Language Models (https://aclanthology.org/2023.emnlp-main.733/)
- Anthology ID: 2023.emnlp-main.733 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델 (LLM)은 종종 생산된 결과물이 신뢰성이 없거나 환각하는 경우가 있는데, 이 논문에서는 가설 앙상블링이 LLM 기반 기계 번역의 품질을 어떻게 개선하는지 조사한다.
    2. 우리는 ChatGPT, LLaMA, Alpaca와 같은 LLM에서 생성된 가설에 대한 여러 기법을 실험하며 다양한 차원에서 포괄적인 연구를 제공한다. 
    3. 결과는 MBR 디코딩이 매우 효과적인 방법이며, 적은 수의 샘플을 사용하여 번역 품질을 개선할 수 있으며, 단순 샘플링 온도와 가설 다양성 간의 관계에 대한 instruction tuning이 강력한 영향을 미친다는 것을 보여준다.

###### FedTherapist: Mental Health Monitoring with User-Generated Linguistic Expressions on Smartphones via Federated Learning (https://aclanthology.org/2023.emnlp-main.734/)
- Anthology ID: 2023.emnlp-main.734 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 정신과 의사들은 환자의 언어 사용을 통해 정신질환을 진단하지만, 기존의 정신 건강 모니터링 시스템은 데이터 프라이버시로 인해 활동, 앱 사용 및 위치와 같은 대체 기능을 사용한다.
    2. 우리는 FedTherapist라는 모바일 정신 건강 모니터링 시스템을 제안한다. 이 시스템은 연합 학습을 통해 연속적인 음성과 키보드 입력을 개인 정보 보호 방식으로 활용한다.
    3. 우리는 여러 모델 디자인을 탐색하고, on-device 언어 모델 훈련의 복잡성을 극복하기 위해 FedTherapist의 성능과 부하를 비교하여지루하고 소음이 많은 텍스트를 효과적으로 활용하기 위한 Context-Aware Language Learning (CALL) 방법론을 제안한다.

###### Visually-Situated Natural Language Understanding with Contrastive Reading Model and Frozen Large Language Models (https://aclanthology.org/2023.emnlp-main.735/)
- Anthology ID: 2023.emnlp-main.735 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 대형 언어 모델(Large Language Models, LLMs)의 발전으로 시각적 영역에 대한 응용 프로그램의 연구가 급증했으나 텍스트가 풍부한 이미지에서의 성능은 여전히 개선이 필요하다.
    2. 이 논문에서는 Cream이라는 새로운 신경 아키텍처를 제안하여 기존 방법에서 자주 간과되는 복잡한 세부사항을 포착하여 LLMs의 언어-이미지 이해 능력을 향상시킨다.
    3. Cream은 시각 및 보조 인코더를 결합하여 이미지 내에서 시각적으로 배치된 맥락 내의 언어 정보를 보다 효과적으로 이해하며, 시각과 언어 이해 사이의 격차를 줄여 더 정교한 문서 인텔리전스 어시스턴트의 개발을 도모한다.

###### Continual Learning for Multilingual Neural Machine Translation via Dual Importance-based Model Division (https://aclanthology.org/2023.emnlp-main.736/)
- Anthology ID: 2023.emnlp-main.736 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다국어 신경망 기계 번역(MNMT)의 지속적인 목표는 이전 훈련 데이터에 접근하지 않고도 모델을 지속적으로 새로운 언어 쌍을 지원하거나 기존 언어 쌍을 개선하는 것이다.
    2. 기존 방법들은 기존과 새로운 언어 쌍 사이에서 타협을 통해 catastrophic forgetting을 방지하는 데 초점을 두지만, 이는 두 가지 번역 작업에 대해 최적의 성능을 보여주지 않는다.
    3. 이 논문에서는 이 문제를 완화하기 위해 모델 파라미터를 두 부분으로 나눌 수 있는 이중 중요도 기반 모델 분할 방법을 제안한다. 이를 통해 기존 번역 작업에 대한 책임을지는 Fine-tuned된 모델을 만들고 새로운 훈련 데이터로 새로운 번역 작업에 대한 external 파라미터를 추가하고 이를 재조정한다.

###### SimCSE++: Improving Contrastive Learning for Sentence Embeddings from Two Perspectives (https://aclanthology.org/2023.emnlp-main.737/)
- Anthology ID: 2023.emnlp-main.737 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 드롭아웃 잡음을 다루고 특징 결함을 해결하기 위해 조금 더 나은 대조 학습을 제안한다.
    2. 먼저, 이 논문은 부정적인 짝에서의 드롭아웃 잡음이 모델 성능에 영향을 미치는 것을 확인하고, 이러한 잡음을 다루기 위한 간단하고 효과적인 방법을 제안한다.
    3. 두 번째로, 특징 결함의 현재 솔루션에서의 랭크 병목현상을 파악하고, 이 문제를 해결하기 위해 차원별 대조 학습 목적을 제안한다.

###### Unlearn What You Want to Forget: Efficient Unlearning for LLMs (https://aclanthology.org/2023.emnlp-main.738/)
- Anthology ID: 2023.emnlp-main.738 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델들은 텍스트 데이터의 사전 학습과 기억을 통해 큰 발전을 이루고 있으나, 이 과정은 개인 정보 보호 문제 및 데이터 보호 규정 위반에 취약할 수 있다.
    2. 이 논문에서는 데이터 제거 후 모델 전체를 재학습하지 않으면서 개별 사용자와 관련된 데이터를 모델에서 쉽게 제거할 수 있는 효율적인 unlearning 프레임워크를 제안한다.
    3. 실험 결과는 제안된 방법이 최신 기준보다 효과적임을 보여 주었다.

###### Simplicity Level Estimate (SLE): A Learned Reference-Less Metric for Sentence Simplification (https://aclanthology.org/2023.emnlp-main.739/)
- Anthology ID: 2023.emnlp-main.739 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 문장 단순화에 대한 자동 평가는 여전히 어려운 문제이다. 대부분의 인기 있는 평가 메트릭은 단순화로부터 파생된 단어들과 유사한 단어들만 비교하기 때문에 단순성을 평가하기에는 제한적이다. 
    2. 우리는 "SLE"라는 새로운 학습된 평가 메트릭을 제안하여 간결성에 중점을 두었으며, 인간의 판단과의 상관관계 측면에서 거의 대부분의 기존 메트릭보다 우수한 성능을 보인다. 
    3. 이를 통해 우리는 실제 사용되지 않은 도메인에 대한 성능을 테스트하는 것이 어려운 단순화 작업에 대한 자동 평가의 한계를 극복할 수 있다는 것을 보여준다.

###### Precedent-Enhanced Legal Judgment Prediction with LLM and Domain-Model Collaboration (https://aclanthology.org/2023.emnlp-main.740/)
- Anthology ID: 2023.emnlp-main.740 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 법적 판단 예측은 법적 AI에서 점점 중요해지고 있는 과제로, 사건 사실 설명에 대한 판단을 예측하는 것이다. 이 연구에서는 이전과 같은 사실을 가진 선행 사례들이 국가 법제에서 추후 사건의 판단에 기초가 되기 때문에 선행 사례들의 활용 가능성을 탐구하는 것이 가치가 있다고 말한다.
    2. LLMs (large language models)과 domain-specific models을 사용하여 LJP 과제를 해결하기 위해 PLJP(precedent-enhanced LJP) 프레임워크를 제안한다. domain models은 후보 라벨을 제공하고 적절한 선행 사례를 효율적으로 찾아내는 역할을 하고, large models은 선행 사례를 고려하여 최종 판단을 내린다.
    3. 실제 데이터셋에서의 실험을 통해 PLJP의 효과를 입증하였고, LLM과 도메인 모델의 협력이 가능한 다른 수직 도메인으로 일반화할 수 있는 유망한 방향성을 보여준다.

###### FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation (https://aclanthology.org/2023.emnlp-main.741/)
- Anthology ID: 2023.emnlp-main.741 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 큰 언어 모델에서 생성된 장문 텍스트의 사실성을 평가하는 것은 어렵다. 따라서 이 논문에서는 생성된 결과를 일련의 원자적 사실들로 나누고, 신뢰할 수 있는 지식 출처에 의해 지원되는 원자적 사실의 백분율을 계산하는 새로운 평가 척도인 FACTSCORE를 제안한다.
    2. 큰 규모의 언어 모델-InstructGPT, ChatGPT 그리고 retrieval-augmented PerplexityAI-에서 생성된 사람 전기기록들을 FACTSCORE로 평가하여 분석한 결과 ChatGPT는 58%에 불과하다는 것을 보여주었다. 또한, 인간 평가 비용을 절감하기 위해 retrieval과 강한 언어 모델을 사용하여 FACTSCORE를 추정하는 자동 모델을 제시하였다.
    3. 이 자동 메트릭을 사용하여 최근 13개의 언어 모델 6,500개의 생성 결과를 평가하였고, 인간 평가비용은 26,000달러가 소요될 뻔한 상황에서 GPT-4와 ChatGPT가 다른 공개 모델보다 사실적이며, Vicuna와 Alpaca가 가장 좋은 공개 모델임을 발견하였다. FACTSCORE는 pip install factscore로 사용 가능하다.

###### Calc-X and Calcformers: Empowering Arithmetical Chain-of-Thought through Interaction with Symbolic Systems (https://aclanthology.org/2023.emnlp-main.742/)
- Anthology ID: 2023.emnlp-main.742 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 언어 모델들은 많은 태스크에서 높은 성능을 보이지만, 산술 연산이 필요한 태스크에서 사실적인 오류를 낼 가능성이 높다. 
    2. 본 논문에서는 "Calc-X"라는 새로운 데이터셋을 만들어 계산기의 적절한 사용법을 언어 모델에게 가르치는 방법을 제안한다.
    3. Calc-X를 사용하여 오픈소스 계산기 사용 모델을 훈련시키고, 기존 언어 모델과 비교하여 정확도를 거의 2배 향상시킬 수 있었다는 결과를 보였다.

###### CoF-CoT: Enhancing Large Language Models with Coarse-to-Fine Chain-of-Thought Prompting for Multi-domain NLU Tasks (https://aclanthology.org/2023.emnlp-main.743/)
- Anthology ID: 2023.emnlp-main.743 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Chain-of-Thought" 프롬프팅은 추론 태스크에서 인기가 있지만, 자연어 이해(NLU)에서의 큰 언어 모델에 적용은 미개척되어 있다.
    2. LLM(대형 언어 모델)의 다단계 추론을 기반으로 하는 "Coarse-to-Fine Chain-of-Thought(CoF-CoT)" 접근 방식을 제안한다. 이 방식은 NLU 태스크를 여러 추론 단계로 분해하여 LLM이 다양한 단위에서 필수적인 개념을 학습하고 활용할 수 있도록 한다.
    3. 또한, 우리는 의미론적 기반의 Abstract Meaning Representation(AMR) 구조적 지식을 중간 단계로 활용하여 발언의 뉘앙스와 다양한 구조, 그리고 그들 사이의 연결을 파악한다. 이러한 접근법은 제로샷 및 퓨샷 다중 도메인 설정에서 LLM이 다중 단계 NLU 태스크에 적응하는 데 효과적으로 작용함을 입증하였다.

###### When Language Models Fall in Love: Animacy Processing in Transformer Language Models (https://aclanthology.org/2023.emnlp-main.744/)
- Anthology ID: 2023.emnlp-main.744 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 생물학적 속성을 텍스트에서 학습한 언어 모델들은 일상 속에서 발생하는 보다 일반적인 생명체에 대해서는 사람과 유사한 방식으로 동작한다. 
    2. 그러나 이 모델들은 적절하지 않은 문맥에서의 생명체에 대한 처리에서 사람보다는 성능이 떨어진다.
    3. 이 연구는 텍스트만을 통해 생물학적 속성을 학습하는 언어모델들도 세밀한 문맥 정보로부터 어떻게 배울 수 있는지를 보여준다.

###### Improving Unsupervised Relation Extraction by Augmenting Diverse Sentence Pairs (https://aclanthology.org/2023.emnlp-main.745/)
- Anthology ID: 2023.emnlp-main.745 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 무지도 관계 추출(Unsupervised relation extraction, URE)은 수동 주석이나 사전에 기존 지식 베이스를 필요로 하지 않고 원시 텍스트에서 이름이 명시된 개체 간의 관계를 추출하는 것을 목표로 한다.
    2. URE 연구에서는 대조적 학습 전략에 많은 관심을 기울였지만, 다양한 양의 대조적 쌍과 적절한 손실 함수 탐색이 무시된 경우가 많다.
    3. 이 논문에서는 문장 내 다양한 쌍의 증강과 문장 간 쌍 추출을 통해 양의 쌍의 다양성을 증가시키고 대조적 학습의 식별력을 강화하는 AugURE을 제안하였다. 또한, 관계 표현 학습에 있어서 기존의 노이즈-대조적 추정(NCE) 손실의 한계를 확인하고 문장 쌍에 대한 마진 손실을 적용하는 것을 제안한다. NYT-FB와 TACRED 데이터셋에서의 실험 결과, 제안된 관계 표현 학습과 간단한 K-Means 군집화는 최고의 성능을 달성하였다.

###### Paraphrase Types for Generation and Detection (https://aclanthology.org/2023.emnlp-main.746/)
- Anthology ID: 2023.emnlp-main.746 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 현재 paraphrase 생성 및 탐지 방법은 언어의 복잡한 특성을 무시하고 단일한 유사도 점수에 의존한다. 이 논문은 paraphrase 유형을 고려하여 이러한 결함을 보완하기 위해 두 가지 새로운 과제를 제안한다.
    2. 현재 기술들은 이진 분류(scenario), 즉 paraphrased or not의 경우에는 잘 수행하지만, 미세한 paraphrase 유형을 포함하는 것은 상당한 도전이다.
    3. paraphrase 유형을 파악하는 것은 paraphrase 모델 개발 및 미래의 과제 해결을 위한 새로운 패러다임을 열 수 있다고 생각된다.

###### Target-to-Source Augmentation for Aspect Sentiment Triplet Extraction (https://aclanthology.org/2023.emnlp-main.747/)
- Anthology ID: 2023.emnlp-main.747 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Aspect Sentiment Triplet Extraction (ASTE)은 사용자가 작성한 리뷰에서 관점 수준의 의견과 감정을 추출하는 sentiment analysis의 중요한 과제이다. ASTE의 세밀성으로 인해 주석 작업 비용이 높아지고, 주석된 데이터의 부족으로 기존 방법의 성능이 제한되었다. 이 논문에서는 데이터 증강을 활용하여 이 문제를 해결한다."
    2. "기존의 증강 방법들은 휴리스틱 규칙이나 언어 모델을 사용하여 기존 샘플의 입력 문장을 수정하는 방식인데, ASTE와 같은 세밀한 작업에 이러한 방법을 적용하는 것은 다양한 증강된 샘플을 생성하면서 수정된 문장과 원래 레이블 간의 일치를 유지하는 것에 어려움이 있다."
    3. "따라서 이 논문에서는 ASTE를 위한 타겟-소스 증강 방법을 제안한다. 저희 방법은 레이블과 문법적 템플릿을 혼합하여 새로운 문장을 직접 생성할 수 있는 generator를 학습하는 데 초점을 맞춘다. 이 generator를 사용하여 다양한 증강 샘플을 생성할 수 있으며, 생성된 문장의 품질을 보장하기 위해 순조성과 일치성 판별기를 도입하여 생성된 문장에 피드백을 제공하고 이를 강화 학습 프레임워크를 통해 generator를 최적화한다. 실험 결과, 우리의 방법은 기존 ASTE 모델의 성능을 크게 향상시킨다."

###### PAC-tuning: Fine-tuning Pre-trained Language Models with PAC-driven Perturbed Gradient Descent (https://aclanthology.org/2023.emnlp-main.748/)
- Anthology ID: 2023.emnlp-main.748 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사전 학습된 언어 모델(PLM)을 downstream 태스크에 fine-tuning하는 것은 대규모 최적화 문제이며, 훈련 알고리즘의 선택은 훈련된 모델의 일반화 성능에 큰 영향을 미친다. PAC-tuning은 두 단계로 구성되어 있으며, PAC-Bayes training을 기반으로 하여 적절한 모수 분포를 학습한다. PAC-tuning은 파라미터에 학습된 분산의 노이즈를 주입하여 gradient를 수정하고, perturbed gradient descent(PGD)의 변형을 사용하여 모델을 훈련시킨다. 
    2. 과거에는 몇 개의 훈련 데이터로 큰 모델에 적용할 때 PAC-Bayes bound가 엄격하지 않을 수 있어서 few-shot scenario에서 PAC-Bayes training이 어려웠다. 
    3. 5개의 GLUE 벤치마크 태스크를 통해 실험한 결과, PAC-tuning은 fine-tuning 과제에 대한 도전에 성공하고 강력한 베이스라인 방법들을 큰 폭으로 능가하며, 현재 Adam optimizer로 훈련하는 경우에도 PAC training을 적용할 수 있는 잠재력을 더욱 확인시켜준다.

###### Emergence of Abstract State Representations in Embodied Sequence Modeling (https://aclanthology.org/2023.emnlp-main.749/)
- Anthology ID: 2023.emnlp-main.749 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. sequence modeling을 통한 결정은 언어 모델의 성공을 모방하기 위해 사용되며, 이 논문에서는 Embodied agent의 행동을 예측하는 Token으로 모델링한다. 하지만 이러한 모델이 환경 상태 정보를 나타내는 내부 표현을 형성하는지 여전히 불분명하다.
    2. 이 논문에서는 BabyAI 환경에서 언어에 의존한 탐색 과제를 수행하는 Sequence 모델 Transformer를 구축하여, 추상적인 상태 표현의 출현을 조사한다.
    3. 실험 결과 중간 환경 레이아웃이 훈련된 모델의 내부 활성화로부터 상당히 재구성될 수 있으며, 언어 명령이 재구성 정확도에 영향을 준다는 것을 보여준다. 이러한 결과는 Sequence 모델링을 통해 상태 표현의 많은 주요 특징이 출현할 수 있다는 것을 시사하며, 복잡한 결정을 내리는 영역에 Sequence 모델링을 적용하는 의사결정을 낙관적으로 지지한다.

###### Accelerating Toeplitz Neural Network with Constant-time Inference Complexity (https://aclanthology.org/2023.emnlp-main.750/)
- Anthology ID: 2023.emnlp-main.750 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Toeplitz Neural Networks (TNN)는 많은 sequence modeling 태스크에서 뛰어난 성능을 보이는 것으로 알려져 있으며, 일반적으로 사용되는 Transformer-based 모델보다 우수한 결과를 제공하면서 log-linear space-time 복잡성을 가진다. 하지만, State Space Models (SSM)은 언어 모델링에서 TNN에 비해 성능이 낮지만 일정한 추론 복잡성을 가진다.
    2. 본 논문에서는 TNN과 SSM의 장점을 결합하기 위해 TNN을 SSM으로 변환하여 추론 중에 SSM과 같은 일정한 추론 복잡성을 가지도록 한다.
    3. 이를 위해 변환 과정을 최적화 문제로 정의하고 클로즈드폼 솔루션을 제공한다. 또한, 대상 방정식을 Vandermonde 선형 시스템 문제로 변환하고 Discrete Fourier Transform (DFT)를 사용하여 효율적으로 해결하는 방법을 보여준다. 이 방법은 훈련을 필요로하지 않으며 수치적 안정성을 유지한다. 또한, LongConv-based 모델에도 적용할 수 있다.

###### Dissecting Recall of Factual Associations in Auto-Regressive Language Models (https://aclanthology.org/2023.emnlp-main.751/)
- Anthology ID: 2023.emnlp-main.751 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Transformer 기반 언어 모델에서는 사실적인 지식을 파라미터로 포함시킬 수 있다. 이전 연구들은 사실적인 연관성이 어디에 저장되어 있는지를 살펴봤지만, 추론 중에 내부적으로 어떻게 검색되는지에 대해서는 거의 알려져있지 않다.
    2. 이 논문에서는 정보 전달을 통해 이 질문에 대한 답을 예측하기 위해 모델이 subject와 relation에 대한 정보를 어떻게 집계하는지를 조사한다.
    3. 연구 결과, 지식이 LMs 내부적으로 어떻게 저장되고 추출되는지에 대한 종합적인 관점을 도입하여 지식의 지역화 및 편집에 대한 미래 연구를 용이하게 한다.

###### StereoMap: Quantifying the Awareness of Human-like Stereotypes in Large Language Models (https://aclanthology.org/2023.emnlp-main.752/)
- Anthology ID: 2023.emnlp-main.752 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 큰 언어 모델은 훈련 데이터에 존재하는 유해한 연관성을 부여하고 유지시킵니다. 이 논문에서는 StereoMap이라는 이론적인 기반을 제안하여 이들이 사회적 집단에 대해 어떻게 인식하는지 알아낼 수 있습니다.
    2. StereoMap은 사회적인 차원인 온기(Warmth)와 능력(Competence)을 사용하여 LLM의 인식을 매핑합니다.
    3. 결과적으로, LLM은 사회적인 집단에 대해 다양한 인식을 갖고 있으며, 온기와 능력의 차원에서 혼합적인 평가로 특징 짓습니다. 또한, LLM의 판단에 영향을 미치는 기저 요인을 밝히기 위해 그들의 추론을 분석한 결과, LLM은 사회적 불평등에 대한 인식을 보여주며, 이를 지원하기 위해 통계 데이터와 연구 결과를 인용합니다.

###### Select, Prompt, Filter: Distilling Large Language Models for Summarizing Conversations (https://aclanthology.org/2023.emnlp-main.753/)
- Anthology ID: 2023.emnlp-main.753 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. ChatGPT와 같은 큰 언어 모델은 텍스트 요약과 같은 특정 자연어 생성 작업이나 특정 도메인에서 사용하기에 비용이 많이 들 수 있다. 
    2. 작은 언어 모델을 특정 작업에 맞게 세밀하게 fine-tuning하는 것은 유망한 대안이다. 그러나 이를 위한 고품질의 훈련 데이터를 구하는 것은 매우 비용이 많이 든다. 
    3. 이 논문에서는 지식 축약(KD)을 통해 약한 지도 데이터를 생성하고, 이를 통해 ChatGPT를 축약하고 작은 언어 모델에 대해 요약 작업을 성공적으로 수행할 수 있음을 보였다.

###### Human Raters Cannot Distinguish English Translations from Original English Texts (https://aclanthology.org/2023.emnlp-main.754/)
- Anthology ID: 2023.emnlp-main.754 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Translationese"는 번역된 텍스트에만 나타나는 언어적 특징을 말하는데, translationese를 구분하기 위한 자동 분류기들은 높은 정확성을 가지고 있으나 사람들의 정확성은 잘 연구되지 않았다. 
    2. 이 연구에서는 사람들이 텍스트를 원문인지 번역된 영어인지 어떻게 판별하는지와 그 과정에서 어떤 특징들을 고려하는지를 알아보기 위해 원문과 번역된 영어 텍스트에 대한 인간 평가를 수행하였다.
    3. 결과적으로, 판별자의 모국어나 텍스트의 원본 언어에 상관없이 사람들은 번역되었는지 원문인지를 구별하지 못하며 의견이 일치하지 않는다는 결론이 나왔다. 이 연구 결과는 번역 연구와 번역ese 분류기의 평가에 중요한 통찰력을 제공한다.

###### Impressions: Visual Semiotics and Aesthetic Impact Understanding (https://aclanthology.org/2023.emnlp-main.755/)
- Anthology ID: 2023.emnlp-main.755 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "아름다움과 미적 영향은 다를까요? 시각적 중요성은 효과적인 커뮤니케이션 능력의 반영일까요?"  Impression이라는 새로운 데이터셋을 통해 이미지의 의미 구성에 스타일이 주제뿐만 아니라 의미를 형성하는 데에도 중요한 역할을 한다는 주장을 제시한다. 기존의 이미지 캡셔닝 데이터셋은 최신 아키텍처가 이미지의 인상이나 해석을 모델링할 수 있는 능력을 갖출 수 있도록 설계되지 않았다는 점을 인정하며, 이를 보완하기 위해 이미지 분석 기술에 영감을 받은 주석 작업을 설계하여 1,440개의 이미지-캡션 쌍과 4,320개의 고유한 주석을 수집한다.
    2. 기존의 다중모달 이미지 캡셔닝과 조건부 생성 모델들은 실제 인간의 응답을 시뮬레이션하는 데 어려움을 겪는다는 것을 보여준다.
    3. 그러나 이 데이터셋은 미세 조정(fine-tuning) 및 피우-샷(few-shot) 적응을 통해 이들의 이미지의 인상과 미적 평가를 모델링하는 능력을 크게 향상시킨다.

###### DNA: Denoised Neighborhood Aggregation for Fine-grained Category Discovery (https://aclanthology.org/2023.emnlp-main.756/)
- Anthology ID: 2023.emnlp-main.756 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 가늠성 레이블 데이터로부터 미세한 범주를 발견하는 것은 미세한 분석 요구와 높은 주석 비용 사이의 격차를 좁히는 것이다. 
    2. 이 논문에서는 semantic structure를 임베딩 공간으로 인코딩하기 위해 노이즈를 제거한 이웃 집합(DNA)이라는 자기-지도적인 프레임워크를 제안한다. 
    3. 실험 결과로, 우리의 방법은 더 정확한 이웃을 검색하고, 다른 모델들보다 더 나은 결과를 보여준다.

###### Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models (https://aclanthology.org/2023.emnlp-main.757/)
- Anthology ID: 2023.emnlp-main.757 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. prompt 기반 학습은 few-shot 설정에서 특히 NLP 태스크에서 최고의 성능을 보이는데, 이에 대한 공격으로는 backdoor attacks가 있다. 이 논문에서는 prompt를 트리거로 사용하여 외부 트리거를 필요로 하지 않는 새로운 백도어 공격 방법인 ProAttack을 제안한다.
    2. ProAttack은 훼손된 샘플의 정확한 라벨링을 보장하며, 트리거로 인한 이상한 문장 표현을 최소화하여 백도어 공격의 은밀성을 향상시킨다.
    3. ProAttack은 풍부한 리소스와 few-shot 텍스트 분류 과제에서 다양한 실험을 통해 합리적인 성능을 보여주었다. 특히, rich-resource 설정에서는 외부 트리거 없이도 clean-label 백도어 공격 벤치마크에서 최고의 공격 성공률을 달성했다.

###### UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation (https://aclanthology.org/2023.emnlp-main.758/)
- Anthology ID: 2023.emnlp-main.758 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델은 인상적인 능력을 갖고 있지만, 모델 특화 fine-tuning이나 태스크 특정 prompt engineering의 필요성으로 일반화에 어려움을 겪을 수 있다.
    2. 우리는 다양한 태스크에서 튜닝되었지만 보이지 않는 태스크 유형에 대해 테스트되는 경량이고 다용도의 retrieves를 자동으로 제공하는 UPRISE (Universal Prompt Retrieval for Improving zero-Shot Evaluation)를 제안한다. 
    3. 우리는 또한 UPRISE가 ChatGPT에서 환각 문제를 완화하는 것을 실험으로 보여주며, 가장 강력한 LLM을 개선할 잠재력을 암시한다.

###### KRLS: Improving End-to-End Response Generation in Task Oriented Dialog with Reinforced Keywords Learning (https://aclanthology.org/2023.emnlp-main.759/)
- Anthology ID: 2023.emnlp-main.759 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 과제 지향적 대화(TOD)에서 강화학습(Reinforcement Learning) 알고리즘은 과제 관련 메트릭에 대한 응답을 직접 최적화하기 위해 모델을 훈련시킨다. 그러나 강화학습은 자동회귀적인 시퀀스 생성 과정이 느리기 때문에 탐색을 수행해야 하는데 이는 시간이 많이 소요된다. 우리는 오프라인 환경에서 TOD 성능을 향상할 수 있는 더 효율적인 RL 기반 알고리즘을 개발하였다.
    2. 우리는 훈련된 언어 모델(LM)을 사용하여 더 빠른 생성 절차를 사용하며, 강화학습을 위한 세부적인 보상 함수를 도입하여 대화에서 각 생성된 토큰의 중요성과 의미적 유사성을 측정함으로써 모델이 핵심 정보를 학습하도록 돕는다.
    3. MultiWoZ 데이터셋에서의 실험 결과, 새로운 훈련 알고리즘인 KRLS(Keywords Reinforcement Learning with Next-word Sampling)는 자동회귀 생성을 사용하는 표준 RL 알고리즘과 비교하여 훈련 시간을 15% 줄이면서 엔드투엔드 응답 생성 과제에서 최고 성능을 달성한다.

###### Large Language Models Only Pass Primary School Exams in Indonesia: A Comprehensive Test on IndoMMLU (https://aclanthology.org/2023.emnlp-main.760/)
- Anthology ID: 2023.emnlp-main.760 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델(Large Language Models, LLMs)은 주로 대규모 멀티리굴 텍스트로 사전학습되지만, 이들의 추론 능력과 현실 세계 지식은 주로 영어 데이터셋을 기반으로 평가된다.
    2. 이 연구에서는 인도네시아 언어와 문화 분야에서의 LLM 능력을 평가하기 위해 IndoMMLU라는 첫 번째 멀티태스크 언어 이해 기준을 제안한다.
    3. "GPT-3.5는 오직 인도네시아 초등학교 수준에만 통과할 뿐, 인도네시아의 지역 언어와 문화에 대한 제한적인 지식을 갖고 있다."

###### Let’s Sample Step by Step: Adaptive-Consistency for Efficient Reasoning and Coding with LLMs (https://aclanthology.org/2023.emnlp-main.761/)
- Anthology ID: 2023.emnlp-main.761 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Self-Consistency 기법은 LLM에서 출력되는 결과의 정확성을 향상시킬 수 있는 대표적인 방법이다. 그러나 기존 Self-Consistency 기법은 질문마다 일정한 수의 샘플을 생성하는 반면, 더 나은 방법은 현재까지 생성된 샘플들 간의 일치 정도에 따라 사용 가능한 예산을 비균등하게 분배하는 것이다.
    2. 본 논문에서는 Lightweight stopping criterion을 사용하여 동적으로 각 질문마다 샘플의 수를 조절하는 비용 효율적이고 모델에 구애 받지 않는 기법인 Adaptive-Consistency를 소개한다. 
    3. 3개의 LLM과 17개의 추론 및 코드 생성 데이터셋에서의 실험 결과 Adaptive-Consistency는 평균적으로 정확도 하락이 0.1% 미만이면서 샘플 예산을 최대 7.9배로 감소시키는 것을 보여준다.

###### Bridging Information-Theoretic and Geometric Compression in Language Models (https://aclanthology.org/2023.emnlp-main.762/)
- Anthology ID: 2023.emnlp-main.762 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어 모델(LM)이 인간의 언어를 정확하게 모델링하기 위해서는 방대하고 무한한 정보를 상대적으로 적은 차원으로 압축해야 한다. 
    2. 이 논문에서는 (pre-trained) LMs의 압축을 geometric한 관점과 정보 이론적인 관점에서 분석하는 것을 제안한다. 
    3. 언어 데이터의 내재 기하 차원은 LMs에서의 코딩 길이를 예측하는데 중요한 역할을 한다는 것을 보이고, 언어 데이터의 높은 압축은 그 데이터에 대한 빠른 적응을 예측하는 것을 확인한다.

###### Pre-training Language Models for Comparative Reasoning (https://aclanthology.org/2023.emnlp-main.763/)
- Anthology ID: 2023.emnlp-main.763 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 비교 추론은 개체, 개념 또는 엔티티를 비교하여 결론을 도출하는 과정으로, 이는 기본적인 인지 능력이다. 본 논문에서는 비교 추론 능력을 향상시키기 위해 언어 모델을 사전 훈련하기 위한 새로운 프레임워크를 제안한다.
    2. 비교 추론이 필요한 NLP 작업에 대한 기존 방법들은 비용이 많이 드는 수동 데이터 라벨링과 다른 작업에 대한 한정적인 일반화 능력 등의 문제가 있다.
    3. 이 연구에서는 구조화된 데이터와 비구조화된 데이터를 모두 활용하여 확장 가능한 텍스트 기반 개체 비교 데이터 수집 기법을 도입하고, 비교 추론에 관한 세 가지 새로운 목표를 가진 언어 모델 사전 훈련 프레임워크를 제안한다. 이 프레임워크는 저자들의 평가를 통해 매우 좋은 성능을 보여주었으며, 특히 데이터 부족한 상황에서 비교 추론 능력을 크게 향상시켰다.

###### Improved Pseudo Data for Machine Translation Quality Estimation with Constrained Beam Search (https://aclanthology.org/2023.emnlp-main.764/)
- Anthology ID: 2023.emnlp-main.764 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기계 번역 품질 추정은 참고 번역문이 없는 경우 기계 번역의 품질을 추정하는 중요한 작업이다.  
    2. 기존의 pseudo data 솔루션은 pseudo label이 부정확하거나 실제 번역과 다른 경우 불만족스러운 결과를 가져온다.  
    3. 이 논문에서는 CBSQE를 사용하여 pseudo 데이터를 생성하고, supervised 및 unsupervised 상황에서 강력한 성능을 보였다고 주장한다.

###### Text Embeddings Reveal (Almost) As Much As Text (https://aclanthology.org/2023.emnlp-main.765/)
- Anthology ID: 2023.emnlp-main.765 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 텍스트 임베딩은 원본 텍스트에 대한 개인 정보를 얼마나 많이 노출시키는가? 우리는 밀집 텍스트 임베딩에서 원래 텍스트를 재구성하는 embedding inversion 문제를 조사했다. 
    2. 우리는 이 문제를 controlled generation으로 구체화하여 텍스트를 생성하는 방식으로 접근했고, 임베딩에 의존하는 단순한 모델보다 반복적으로 텍스트를 수정하고 재 임베딩하는 멀티 스텝 방법이 32 토큰의 텍스트 입력의 92%를 정확하게 복구할 수 있다는 것을 발견했다.
    3. 우리는 두 개의 최첨단 임베딩 모델에서 텍스트 임베딩을 디코드하는 방법을 모델에 학습시키고, 또한 우리의 모델이 임상 기록 데이터 세트에서 중요한 개인 정보 (전체 이름)를 복구할 수 있다는 것을 보여줬다.

###### AutoTrial: Prompting Language Models for Clinical Trial Design (https://aclanthology.org/2023.emnlp-main.766/)
- Anthology ID: 2023.emnlp-main.766 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 약 개발을 위해 임상시험은 중요하다. 이 논문에서는 자연어 모델을 사용하여 임상 임검 의 자격 조건을 설계하는 AutoTrial 메소드를 제안한다.
    2. AutoTrial은 (1) 이전 임상 임검의 조건을 고려하고, (2) 명시적인 사고의 체인(rational)으로 실행결과를 이해할 수 있으며, (3) 고급 지침(instruction tuning)을 통해 조건을 제어 가능하다. 
    3. 약 70,000개의 임상시험에서 수행된 실험에서, AutoTrial은 적절한 기준을 만족시키며 일관된 조건 텍스트를 생성하고 GPT-3.5 보다 약 60% 우세한 평가결과를 보였다.

###### Faster Minimum Bayes Risk Decoding with Confidence-based Pruning (https://aclanthology.org/2023.emnlp-main.767/)
- Anthology ID: 2023.emnlp-main.767 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최소 베이즈 위험 (MBR) 디코딩은 어떤 유용성 함수에 대한 모델 분포의 가장 높은 기대 효용을 가지는 가설을 출력한다. 그러나 MBR을 위한 표준 샘플링 기반 알고리즘은 beam search보다 훨씬 계산 비용이 많이 들며, 많은 수의 샘플 및 유틸리티 함수의 호출이 필요하므로 적용 범위가 제한된다. 
    2. 이 논문에서는 우리는 부트스트랩 샘플링으로 얻은 신뢰도 추정치에 따라 가장 높은 유틸리티를 가지지 않을 것으로 예상되는 가설을 제거하며, 유틸리티를 추정하는 데 사용되는 샘플 수를 점진적으로 증가시키는 MBR 알고리즘을 제안한다.
    3. chrF ++ 및 COMET을 유틸리티/평가 메트릭으로 사용하여 세 가지 언어 쌍에 대한 실험에서 우리의 접근법의 효과를 입증하였다.

###### Enhancing Generative Retrieval with Reinforcement Learning from Relevance Feedback (https://aclanthology.org/2023.emnlp-main.768/)
- Anthology ID: 2023.emnlp-main.768 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에 도입된 end-to-end generative retrieval은 문서 검색 방법에서의 중요한 변화이며, 특정 질의에 대한 응답으로 관련 문서 식별자 (docid)를 직접 생성하기 위해 differentiable search indexes를 활용한다. 
    2. 이러한 접근 방식은 두 가지 주요 도전에 직면하고 있다: (i) 토큰 수준의 확률적 최적화와 더 넓은 문서 수준의 관련성 평가 간의 불일치, (ii) 전반적인 순위 품질을 희생하고도 최상위 결과에 과도하게 초점을 맞추는 문제. 
    3. 이러한 도전을 극복하기 위해, 우리는 generative retrieval 모델을 제안하며, relevance feedback으로부터의 강화학습을 통해 토큰 수준의 docid 생성을 문서 수준의 관련성 평가와 일치시키기 위해 노력한다.

###### Multi-Source Probing for Open-Domain Conversational Understanding (https://aclanthology.org/2023.emnlp-main.769/)
- Anthology ID: 2023.emnlp-main.769 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화 이해와 생성은 오픈 도메인 대화 시스템의 성공에 매우 중요합니다. 미리 학습된 생성 대화 모델은 유창한 응답 생성에서 상당한 진전을 이루었지만, 사람들은 대화의 문맥 정보를 이해하고 효과적으로 모델링하는지 판단하기 어렵습니다.
    2. 이 연구에서는 여러 가지 상황에 적용 가능한 다양한 대화 이해 기술을 수행하기 위해 다양한 소스로부터의 특징들을 종합하는 "Multi-Source Probing (MSP)" 방법을 제안합니다.
    3. 실험 결과는 오픈 도메인 대화 모델이 중간 숨겨진 상태에서 의미 정보를 인코딩할 수 있으며, 다양한 규모와 구조의 모델이 다른 대화 이해 능력을 가지고 있음을 보여줍니다.

###### Hallucination Mitigation in Natural Language Generation from Large-Scale Open-Domain Knowledge Graphs (https://aclanthology.org/2023.emnlp-main.770/)
- Anthology ID: 2023.emnlp-main.770 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이전 연구들은 지식 그래프 트리플을 위한 자연어 설명을 생성할 때, 소규모의 사람 주석이 달린 데이터셋이나 mostly star graphs와 같은 다양성이 제한된 데이터셋을 사용하였다. 이 논문은 이러한 제한적인 데이터셋 대신 대규모, 오픈 도메인 상황을 고려한 GraphNarrative 데이터셋을 제시한다.
    2. Transformer 기반 사전 훈련된 언어 모델을 세밀하게 조정하는 것이 그래프-텍스트 모델들 사이에서 최고 성능을 보였지만, 이 방법은 정보 환각이라는 문제가 있다. 즉, 생성된 텍스트에 입력 그래프에 없는 가공된 사실들이 포함될 수 있다.
    3. 이 논문에서는 GraphNarrative에서 그래프-문장 쌍을 가지고, 문장의 종속성 파스 트리를 활용하여 해당 그래프에 없는 부분을 제거하는 새로운 방법을 제안한다. 이 방법을 GraphNarrative 및 기존 데이터셋 위에서 학습한 모델을 사용하여 실험한 결과가 검증되었다.

###### Multi-Source Multi-Type Knowledge Exploration and Exploitation for Dialogue Generation (https://aclanthology.org/2023.emnlp-main.771/)
- Anthology ID: 2023.emnlp-main.771 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다양한 유형의 지식이 부족한 Open-domain multi-turn 대화 생성을 위한 과제가 있다. 기존 모델들은 특정 유형의 대화 지식을 식별하고 해당 데이터셋을 사용하여 훈련하는 것에 주로 초점을 맞추었으나, 이러한 접근 방식은 일반화 능력이 제한되고 계산 리소스 요구가 증가하는 결과를 가져온다.
    2. 이 논문에서는 여러 종류의 다양한 데이터셋을 활용하여 LLMs에서 multi-source multi-type 지식을 탐색하고 이를 대화 응답 생성에 활용하는 KnowEE라는 프레임워크를 제안한다.
    3. 자동 및 수동 평가 결과 모두, 우리의 프레임워크가 다중 소스 다중 유형 지식을 탐색하고 활용하여 일관된, 정보성 높은, 유창한 응답을 생성하는 데 효과적임을 검증한다.

###### Focus Your Attention (with Adaptive IIR Filters) (https://aclanthology.org/2023.emnlp-main.772/)
- Anthology ID: 2023.emnlp-main.772 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 어텐션에 앞서 입력 시퀀스를 처리하기 위해 동적인 Infinite Impulse Response (IIR) 필터를 사용하는 새로운 레이어를 제안한다. 상태-공간 레이어와 비교하여 파라미터 수가 적고 입력 크기와 시간 복잡도가 서브-2차 방식으로 성능 또한 우수하다.
    2. 동적 적응 필터는 입력 시퀀스의 관련 요소에 주목하도록 하며, 선형 시스템 이론에 기반하여 설계되었다.
    3. Heyna, GPT2, Mega와 같은 레이어에 비해 적은 파라미터 수로 여러 개의 장거리 시퀀스 문제에 대한 성능을 향상시켰다.

###### Identifying Statements Crucial for Awareness of Interpretive Nonsense to Prevent Communication Breakdowns (https://aclanthology.org/2023.emnlp-main.773/)
- Anthology ID: 2023.emnlp-main.773 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 원격 대화 중 청취자가 일부 발언을 놓치면 의사소통 장애가 발생하는데, "SCAINs" 라고 불리는 중요한 발언을 식별함으로써 이러한 장애를 예방하는 것을 목표로 한다.
    2. SCAINs를 식별하기 위해, 원래의 대화에서 두 개 연속 발언을 생략하고 다음 발언을 보다 구체화하는 텍스트를 생성하여 대화를 만들어내는 독특한 접근법을 채택한다. 
    3. 우리는 missing 정보를 처리하여 누락된 정보를 시뮬레이션하는 것이라는 점에서 제안한 방법의 독창성을 강조하며, 대화 데이터셋을 사용하여 SCAIN의 효과를 검증한다.

###### Multilingual Large Language Models Are Not (Yet) Code-Switchers (https://aclanthology.org/2023.emnlp-main.774/)
- Anthology ID: 2023.emnlp-main.774 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 여러 언어 대형 언어 모델인 LLM은 zero-shot이나 few-shot prompting 방법을 통해 최신 성능을 보여주었지만, 코드 스위칭 (CSW) 환경에서의 잠재력에 대한 연구는 아직 미탐한 영역이다.
    2. 본 논문에서는 다양한 multilingual LLM의 성능을 감정 분석, 기계 번역, 요약 및 단어 수준 언어 식별과 같은 네 가지 태스크를 기준으로 평가했다.
    3. 결과적으로, zero-shot이나 few-shot prompting 방법을 통해 일부 태스크에서는 promising한 결과를 보이지만, 그 크기가 훨씬 작은 fine-tuned 모델과는 비교할 때 성능이 낮았다. 현재의 multilingual LLM은 코드 스위칭 텍스트에 대한 능숙함을 내포하지 않는다고 주장하며 이 간극을 해소하기 위한 미래 연구를 촉구한다.

###### Reinforced Target-driven Conversational Promotion (https://aclanthology.org/2023.emnlp-main.775/)
- Anthology ID: 2023.emnlp-main.775 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화형 어시스턴트의 제품 홍보를 위해 사용자와 적극적으로 소통하는 능력은 매우 중요하다. 그러나 기존 대화 추천 방법들은 사용자 선호도 획득에 너무 초점을 맞추고, 사용자를 지정된 아이템 수용으로 유도하기 위한 전략적 계획을 무시하기 때문에, 매력적인 응답과 함께 특정 아이템을 홍보하는 데 실패한다.
    
    2. 이 논문에서는 대화형 홍보를 위해 강화학습 기반의 타깃 중심 대화형 프로모션 (RTCP) 프레임워크를 제안한다. RTCP는 균형 잡힌 게이팅 메커니즘을 통해 단기 및 장기 계획을 통합한다. 이를 위해 지식 기반의 다중 헤드 어텐션을 사용하여 대화 액션을 예측하고 강화학습 보상에 따라 가이드한다. RTCP는 또한 액션에 기반한 프리픽스 튜닝을 사용하여 관련된 응답을 생성한다.
    
    3. 실험 결과는 우리 모델이 자동 측정 지표와 인간 평가 모두에서 최신 모델보다 우수한 성능을 보였음을 보여준다. 또한, RTCP는 전체 모델 재학습 없이 프리픽스 매개변수를 업데이트함으로써 새로운 시나리오에 빠르게 적응하는 능력을 갖추고 있다.

###### Identification of Multimodal Stance Towards Frames of Communication (https://aclanthology.org/2023.emnlp-main.776/)
- Anthology ID: 2023.emnlp-main.776 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 멀티미디어 문서에서 커뮤니케이션 프레임은 종종 나타나며, 작가가 텍스트에 이미지를 추가할 때 일어날 수 있다. 이 논문에서는 텍스트와 이미지 간의 상호작용을 통해 커뮤니케이션 프레임에 대한 작가의 태도를 자동으로 탐지하는 방법을 소개한다.
    2. 기존에는 텍스트만 처리하므로 멀티미디어 문서에 대한 태도 주석이 없는 문제로 인해 해당 방법은 적용되지 않았다.
    3. MMVax-Stance 데이터셋은 11,300개의 멀티미디어 문서와 113개의 커뮤니케이션 프레임에 대한 태도 주석을 포함하고 있으며, 이를 통해 텍스트와 이미지 간의 상호작용을 통해 커뮤니케이션 프레임에 대한 태도를 예측하는 모델을 실험하였다.

###### Unsupervised Sounding Pixel Learning (https://aclanthology.org/2023.emnlp-main.777/)
- Anthology ID: 2023.emnlp-main.777 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사운드 소스의 위치 파악은 cross-modal alignment의 어려움 때문에 어려운 과제이다. 이 논문에서는 비지도 학습 방법을 사용하여 픽셀 수준의 사운드 소스 위치 파악을 가능하게 하는 USPL(Unsupervised Sounding Pixel Learning) 접근법을 제안한다.
    2. 비지도 교차 모달 대응을 실현하기 위해 오디오-비디오 특징을 정렬하는 mask augmentation 기반의 다중 인스턴스 비교 학습을 설계한다.
    3. 시각 의미 관계 학습을 통해 인접 좌표 피쳐의 상호 픽셀 관계를 탐색하는 Unsupervised Sounding Map Refinement (SMR) 모듈을 제안한다.

###### LM vs LM: Detecting Factual Errors via Cross Examination (https://aclanthology.org/2023.emnlp-main.778/)
- Anthology ID: 2023.emnlp-main.778 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 현대 언어 모델(LM)의 중요한 약점은 사실적으로 틀린 텍스트를 생성하는 경향이 있어, 사용성이 제한된다. 
    2. 이 논문에서는 법률에서의 참을 찾는 메커니즘에서 영감을 받아, 실수된 주장을 자동으로 감지하는 LM의 사실성 평가 프레임워크를 제안한다. 
    3. 실험 결과, 우리의 방법은 기존 방법들과 비교해 성능이 우수하며, 다른 LMs와의 상호작용을 통해 사실적인 오류를 포착하는 것이 가능함을 보여준다.

###### Large Language Models: The Need for Nuance in Current Debates and a Pragmatic Perspective on Understanding (https://aclanthology.org/2023.emnlp-main.779/)
- Anthology ID: 2023.emnlp-main.779 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 현재의 대형 언어 모델은 문법적으로 올바르고 유창한 텍스트를 생성하는 능력에서 비할 데 없다. 하지만 이러한 모델의 능력에 대한 논의는 많이 이루어졌지만, 깊이 있는 고찰은 뒤처지고 있다. 
    2. 이 논문에서는 대형 언어 모델의 능력에 대한 비판 중 일부를 비판적으로 평가하고, LLM이 통계적 패턴뿐만 아니라 형태적이고 기능적 언어 역량을 습득할 수 있다는 것을 보여준다. 
    3. 또한, LLM의 "실제" 이해와 의도에 관한 문제를 탐구하고 인간의 언어 학습에 대해 영감을 줄 수 있는 LLM의 사회적 관점에 대해 논의한다.

###### PIEClass: Weakly-Supervised Text Classification with Prompting and Noise-Robust Iterative Ensemble Training (https://aclanthology.org/2023.emnlp-main.780/)
- Anthology ID: 2023.emnlp-main.780 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. weakly-supervised text classification은 각 target class의 label name만을 supervision으로 사용하여 classifier를 학습시키는데, 이는 인간의 주석 작업을 크게 줄여준다. 하지만 기존 방법은 keyword matching을 통해 pseudo labels을 생성하는데, 이러한 방식은 context에 따라 keyword의 의미가 다를 수 있고, 일부 텍스트는 어떤 키워드도 가지고 있지 않을 수 있기 때문에 noisy하고 부적절한 pseudo labels을 유발할 수 있는 두 가지 한계가 있다.
    2. 이 논문에서는 PIEClass라는 새로운 방법을 제안하는데, 이는 contextualized text understanding을 기반으로 한 static keyword matching을 넘어 pre-trained language models (PLM)의 zero-shot prompting을 사용하여 pseudo labels을 획득하는 module과, 서로 규제하는 두 가지 PLM fine-tuning 방법을 활용하여 iterative하게 classifier를 학습하고 pseudo labels을 업데이트하는 noise-robust ensemble training module로 구성된다.
    3. 실험 결과, PIEClass는 7개의 기준 데이터셋에서 기존 강력한 기준 모델보다 전반적으로 더 우수한 성능을 보이며, 감성 분류 작업에서는 fully-supervised classifier와 유사한 성능을 달성한다.

###### MeaeQ: Mount Model Extraction Attacks with Efficient Queries (https://aclanthology.org/2023.emnlp-main.781/)
- Anthology ID: 2023.emnlp-main.781 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 처리에서 모델 추출 공격에 대해 연구하고, 반복적으로 오픈 API를 쿼리하여 피해 모델을 도용하려는 공격자를 조사한다. 
    2. 이 논문에서는 제한된 쿼리 예산 설정에 초점을 맞추고, 공개된 비어노테이션 데이터 소스에서 무작위 샘플링이나 액티브 러닝 기반 샘플링 전략을 채택하는 방법들을 제시한다.
    3. MeaeQ라는 새로운 방법을 제안하여, 문제 도메인 특정 데이터셋이 아닌 공개 텍스트 말뭉치에서 문제와 관련된 데이터를 필터링하고, 군집 기반 데이터 축소 기술을 사용하여 공격을 위한 대표적인 데이터를 얻는다.

###### The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning (https://aclanthology.org/2023.emnlp-main.782/)
- Anthology ID: 2023.emnlp-main.782 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 100B 미만의 parameter를 가진 작은 Language model (LMs)은 chain-of-thought reasoning 태스크를 해결하는 데 있어서 큰 LMs보다 성능이 나쁘다. 이 논문에서는 작은 LMs에게도 step-by-step reasoning 능력을 부여하기 위해 CoT rationales를 사용하여 instruction tuning을 제안한다. 
    2. CoT Collection이라는 새로운 instruction-tuning 데이터셋을 소개하고, 이를 사용하여 Flan-T5 (3B & 11B)를 CoT fine-tuning한다면 작은 LMs도 unseen tasks에서 더 나은 CoT 능력을 갖게 된다고 보여준다.
    3. 또한, CoT Collection을 사용한 instruction tuning은 LMs가 4개의 도메인에 대한 few-shot learning 능력도 강화시키며, 문제 해결 능력에서 ChatGPT를 능가하는 결과를 얻을 수 있다.

###### Explaining Interactions Between Text Spans (https://aclanthology.org/2023.emnlp-main.783/)
- Anthology ID: 2023.emnlp-main.783 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 이해 (NLU) 과제에서는 입력의 서로 다른 부분의 토큰 범위를 능력있게 추론하는 것이 중요하다. 하지만 기존의 하이라이트 기반 설명은 인접한 토큰 또는 튜플 사이의 상호작용 뿐만 아니라 개별적으로 중요한 기능을 식별하는 데 주로 초점을 맞추고 있다. 
    2. 이 논문에서는 NLI 및 FC 두 NLU 작업에 대한 사람의 범위 상호작용 설명의 다중 주석가 데이터 세트인 SpanEx를 소개한다.
    3. 또한, 그들을 사람의 추론 과정과 비교하여 여러 개의 세팅된 대형 언어 모델의 결정 과정을 연구하고, 무지로 추출하는 새로운 커뮤니티 탐색 기반의 비지도 방식을 제시한다.

###### Predictive Chemistry Augmented with Text Retrieval (https://aclanthology.org/2023.emnlp-main.784/)
- Anthology ID: 2023.emnlp-main.784 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 화학 분야에서 예측 모델을 향상시키기 위해 자연어 설명을 사용하는 것에 초점을 맞추고 있다.
    2. 기존의 화학정보학 모델은 주로 문헌에서 수작업으로 추출된 구조화된 데이터로 훈련된다.
    3. 본 논문에서는 TextReact라는 새로운 방법을 소개하는데, 이 방법은 문헌에서 검색된 텍스트 설명을 사용하여 예측 화학에 직접 보완을 한다.

###### System Combination via Quality Estimation for Grammatical Error Correction (https://aclanthology.org/2023.emnlp-main.785/)
- Anthology ID: 2023.emnlp-main.785 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. gramatical error correction (GEC) 모델의 성능 평가를 위해 품질 추정 모형이 개발되었지만 기존 모형들은 좋은 수정과 나쁜 수정을 구별하는 데 문제가 있다. 
    2. GRECO라는 새로운 품질 추정 모델을 제안하여 수정된 문장의 품질을 더 정확하게 추정할 수 있다고 보여주었다. 
    3. GRECO를 활용하여 여러 GEC 시스템의 출력을 결합하는 방법을 제안하였고, 다양한 범용성을 가진 방법들로 성능을 높일 수 있다고 보여주었다.

###### Rethinking Negative Pairs in Code Search (https://aclanthology.org/2023.emnlp-main.786/)
- Anthology ID: 2023.emnlp-main.786 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에는 contrastive learning이 소프트웨어 개발의 효율성과 효과성을 위한 코드 검색 모델의 fine-tuning에서 핵심 요소로 자리잡았다. 
    2. 그러나 InfoNCE의 negative sample에 대한 문제들로 인해 representation learning이 저하될 수 있다. 
    3. 우리는 Soft-InfoNCE라는 간단하고 효과적인 손실 함수를 제안하여 이러한 문제들을 해결하였다.

###### Question Answering as Programming for Solving Time-Sensitive Questions (https://aclanthology.org/2023.emnlp-main.787/)
- Anthology ID: 2023.emnlp-main.787 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 질문-답변(QA)은 우리의 세상에 대한 지식 습득에 핵심적인 역할을 하는데, 실제로 답은 질문에 대한 시간 제약이 변경될 때 완전히 다를 수 있다. 
    2. 기존 LLMs는 표면적인 텍스트 의미에 기반한 엄밀한 추론을 수행하지 못하므로 위의 문제는 여전히 큰 도전이 될 수 있다. 
    3. 따라서 LLMs에게 직접적으로 질문에 답을 하도록 요구하는 대신, 우리는 QAaP라는 새로운 접근 방식을 제안하고자 한다. 이를 통해 LLMs의 능력을 활용하여 다양하게 표현된 텍스트를 구조화된 코드로 변환하고, 프로그래밍을 통해 여러 후보 중 가장 잘 맞는 답변을 선택하도록 한다.

###### Joint Geometrical and Statistical Domain Adaptation for Cross-domain Code Vulnerability Detection (https://aclanthology.org/2023.emnlp-main.788/)
- Anthology ID: 2023.emnlp-main.788 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 코드 취약성 감지 작업에서, label-rich 소스 도메인에서 훈련된 탐지기는 타겟 도메인에서의 라벨링된 훈련 데이터의 부족으로 인해 정확한 예측을 제공하지 못한다. 
    2. 우리는 Mutual Nearest Neighbor Contrastive Learning을 도입하여 소스 도메인과 타겟 도메인을 기하학적으로 조정하고, 각 도메인의 개별적인 의미적 특징을 분리할 수 있는 새로운 크로스-도메인 코드 취약성 감지 프레임워크인 MNCRI을 제안한다. 
    3. 확장된 실험을 통해 MNCRI가 최신 크로스-도메인 코드 취약성 감지 방법들보다 훨씬 뛰어난 성능을 보여준다는 것을 입증하였다.

###### Revisiting Sparse Retrieval for Few-shot Entity Linking (https://aclanthology.org/2023.emnlp-main.789/)
- Anthology ID: 2023.emnlp-main.789 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Entity linking은 지식 베이스에서 모호한 언급과 해당 엔티티를 연결하는 것을 목표로 한다. 특정 도메인에 대한 부족한 레이블된 데이터로 인한 문제가 주요한 어려움 중 하나이다.
    2. 한정된 양의 도메인 내 레이블된 데이터만 사용 가능한 상황에서 dense retriever의 성능이 크게 저하된다고 한다.
    3. 본 논문에서는 sparse retrieval 방법을 재검토하고 ELECTRA 기반의 키워드 추출기를 제안하여 언급 문맥을 정리하고 더 좋은 질의 표현을 구성한다.

###### Controlling Pre-trained Language Models for Grade-Specific Text Simplification (https://aclanthology.org/2023.emnlp-main.790/)
- Anthology ID: 2023.emnlp-main.790 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 텍스트 단순화 시스템은 글의 내용을 보존하면서 읽기 쉽게 재작성한다. 하지만 읽는 이의 읽기 쉬움에 대한 기준은 의도된 독자에 따라 달라진다.
    2. 이 논문에서는 텍스트 간소화 시스템의 합리성과 단순성에 영향을 미치는 다양한 제어 기법의 영향을 이해하기 위해 실험을 진행하였다.
    3. 이를 바탕으로, 특정 학년 수준에 맞추기 위해 텍스트를 단순화하기 위해 필요한 편집 작업을 개별적으로 예측하는 간단한 방법을 제안하였다. 이 접근 방식은 코퍼스 수준의 탐색 기반 휴리스틱과 비교하여 단순화된 텍스트의 품질을 향상시킨다.

###### CLEVR-Implicit: A Diagnostic Dataset for Implicit Reasoning in Referring Expression Comprehension (https://aclanthology.org/2023.emnlp-main.791/)
- Anthology ID: 2023.emnlp-main.791 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 VL(Vision-Language) 모델은 다양한 교차 모달(Cross-Modal) 작업인 REC(Referring Expression Comprehension)에서 높은 성공을 거두고 있는데, 이러한 모델들은 대규모 이미지-텍스트 쌍으로 사전 훈련을 거친 뒤 후속 작업에서 성능을 미세조정한다. 하지만, 암묵적 텍스트(implicit text)가 포함된 작업에서는 어려움을 겪으며, 모델이 암묵적 텍스트와 이미지의 객체를 정확히 매핑하기 어렵다.
    2. 이 논문에서는 REC 작업을 위한 CLEVR-Implicit 데이터셋을 제안하고, VL 모델이 암묵적 텍스트를 처리하는 성능을 향상시키기 위해 "Transforming Implicit text into Explicit text (TIE)" 방법을 소개한다.
    3. 실험 결과, TIE 방법을 사용하여 VL 모델의 암묵적 텍스트 성능이 37.94% 크게 향상되었다.

###### “Are Your Explanations Reliable?” Investigating the Stability of LIME in Explaining Text Classifiers by Marrying XAI and Adversarial Attack (https://aclanthology.org/2023.emnlp-main.792/)
- Anthology ID: 2023.emnlp-main.792 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. LIME은 AI 설명가능성 (XAI) 프레임워크에서 가장 널리 인용되는 도구 중 하나이며, 핵심적인 머신러닝 응용 분야 (예: 건강관리 및 금융) 에 통합되어 있다. 하지만 텍스트 데이터의 특수한 제약으로 인해 LIME의 안정성은 아직 충분히 탐구되지 않았다.
    2. 본 논문에서는 먼저 텍스트 데이터에서 LIME의 고유한 불안정성을 평가하여 기준을 마련하고, 그런 다음 텍스트 입력을 왜곡하고 설명을 조작하는 XAIFooler라는 혁신적인 알고리즘을 제안한다. 이는 LIME의 안정성을 텍스트 왜곡 최적화 문제로 탐구한다.
    3. XAIFooler는 텍스트 의미론과 원래 예측을 보존하기 위한 제약 조건을 준수하며, 설명 유사성 측정을 위한 모든 요구 사항을 충족시키기 위해 Rank-biased Overlap (RBO)를 도입한다. 실제 텍스트 데이터셋에서의 광범위한 실험 결과, XAIFooler는 설명의 의미론적 보존성이 높은 LIME 조작 능력에서 모든 기준점을 큰 비율로 능가한다.

###### CQE: A Comprehensive Quantity Extractor (https://aclanthology.org/2023.emnlp-main.793/)
- Anthology ID: 2023.emnlp-main.793 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 수량은 금융, 비즈니스, 의학, 과학과 같은 분야에서 사실적인 정보를 설명하는 데 필수적이다. 그러나 다른 정보 추출 방법에 비해 텍스트에 포함된 양 추출 및 표현 방법을 설명하는 연구는 몇 개뿐이다.
    2. 본 논문에서는 텍스트 데이터에서 포괄적인 수량 추출 프레임워크를 제안한다. 이 프레임워크는 값과 단위의 조합, 수량의 동작 (상승 또는 하강) 및 수량에 관련된 개념을 효과적으로 탐지한다.
    3. 우리의 프레임워크는 의존성 구문 분석과 단위 사전을 사용하며, 검출된 수량의 적절한 정규화 및 표준화를 제공한다. 평가를 위한 새로운 데이터셋을 사용하여, 우리의 프레임워크가 다른 시스템보다 우수한 성능을 보이고, 발견된 수량과 관련된 개념을 탐지하는 첫 번째 시스템임을 보여준다.

###### Context Compression for Auto-regressive Transformers with Sentinel Tokens (https://aclanthology.org/2023.emnlp-main.794/)
- Anthology ID: 2023.emnlp-main.794 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Transformer 기반 LLMs에서 attention module의 이차 복잡성은 generation 도중에 계산량의 대부분을 차지하게 되며, 효율적인 메모리 사용과 추론 지연에 심각한 문제를 야기한다.
    2. 우리는 지정된 토큰 span의 중간 활성화를 점진적으로 압축하여 이후 context 처리 시 메모리 및 계산 비용을 줄이는 plug-and-play 접근법을 제안한다.
    3. 도메인 내 언어 모델링과 zero-shot open-ended document generation에서의 실험 결과, 우리의 방법이 효율성, n-gram 매칭 및 의미적 유사성 측면에서 sparse attention을 능가함을 보여준다.

###### A Unified View of Evaluation Metrics for Structured Prediction (https://aclanthology.org/2023.emnlp-main.795/)
- Anthology ID: 2023.emnlp-main.795 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 여러 구조적 예측 태스크 (예: 이벤트 및 관계 추출, 구문 및 의미 파싱)에 대한 다양한 평가 메트릭을 하나로 통합하는 개념적인 프레임워크를 제시한다. 
    2. 우리의 프레임워크는 이러한 태스크의 출력을 특정 데이터 유형의 객체로 표현하고, 공통 하위 구조의 매칭을 통해 메트릭을 유도한다.
    3. 우리는 이러한 프레임워크를 통해 여러 태스크에 대한 평가 메트릭을 간결하게 표현할 수 있음을 보여주며, 새로운 메트릭은 출력 구조를 기반으로 자연스럽게 유도될 수 있다고 보여준다.

###### A Deeper (Autoregressive) Approach to Non-Convergent Discourse Parsing (https://aclanthology.org/2023.emnlp-main.796/)
- Anthology ID: 2023.emnlp-main.796 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 온라인 소셜 플랫폼은 정보 공유와 다중 참여 대화에 활기를 불어넣는 장소로 이용된다. 그러나 대부분의 대화 분석 프레임워크는 많은 온라인 플랫폼에서 흔하게 나타나는 논쟁적인 대화를 분석하기에는 적합하지 않다.
    2. Zakharov et al. (2021)에서 소개된 새로운 다중 라벨 체계를 이용하여 논쟁적인 대화 파싱을 위한 통합 모델을 제안한다. 이 모델은 이전 대화 발화를 제외한 다른 추가 입력을 요구하지 않는다.
    3. 우리는 GRN 레이어와 비대칭 손실 함수를 통해 RoBERTa backbone을 fine-tuning하여 제안한 아키텍처가 대화 파싱에서 우수한 성과를 보이는 것을 확인하였다. 이를 통해 대화의 동적 이해를 깊게 하는 도구의 개발을 촉진시킬 수 있다.

###### We are Who We Cite: Bridges of Influence Between Natural Language Processing and Other Academic Fields (https://aclanthology.org/2023.emnlp-main.797/)
- Anthology ID: 2023.emnlp-main.797 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 처리(NLP)는 세계에 상당한 영향을 주려고 한다. 그러나 이에 따른 위험도 상당하다. 이러한 위험에 대처하기 위해서는 다양한 연구 분야와의 포괄적인 협력이 필요하다. 그러나 지금까지 관련 분야들과 NLP 사이의 협력 상태에 대한 연구는 거의 이루어지지 않았다.
    2. 이 논문에서는 NLP와 23개의 연구 분야간의 상호작용 정도를 측정한 결과를 제시하고 있다. NLP 논문, NLP 논문에서 다른 논문들로 향하는 인용, 다른 논문에서 NLP 논문으로의 인용을 분석한 결과를 바탕으로, NLP의 타 연구 분야와의 협력은 시간이 흐름에 따라 점점 감소하고 있다는 것을 보여주고 있다.
    3. NLP는 점점 특정 분야에 치우쳐 있고, 컴퓨터 과학 분야에서 다른 분야로의 인용이 매우 적다는 것을 알 수 있다. 이러한 결과는 NLP가 다양한 분야와의 협력을 반영해야 하는 시급성을 강조하고 있다.

###### Ties Matter: Meta-Evaluating Modern Metrics with Pairwise Accuracy and Tie Calibration (https://aclanthology.org/2023.emnlp-main.798/)
- Anthology ID: 2023.emnlp-main.798 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Kendall의 tau는 기계 번역(MT) 평가 메트릭이 개별 번역을 얼마나 잘 평가하는지 메타-평가하는 데 자주 사용되는데, 이제 문제는 묶음 (ties)를 어떻게 처리해야 하는지라는 것이다. 
    2. 기존의 변형들은 묶음을 처리하는 방식 때문에 약점을 가지고 있고, 때로는 게임이 가능하다는 문제가 있다.
    3. 우리는 묶음 예측에 대한 정확도를 고려하는 비교적 정확함 (pairwise accuracy) 버전으로 메타-평가를 제안하고, 묶음을 자동으로 도입하여 메트릭 점수 간의 공정한 비교를 가능하게 하는 tie calibration 절차를 도입한다. 이러한 수정이 메트릭 성능의 공정한 순위 평가를 제공한다는 이유와 실험적 증거를 제시한다.

###### SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization (https://aclanthology.org/2023.emnlp-main.799/)
- Anthology ID: 2023.emnlp-main.799 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사회적 대화 분야에서 데이터 부족은 오랫동안 문제였다. 이 논문에서는 공개적으로 제공되는 첫 백만 단위의 고품질 사회적 대화 데이터셋인 SODA를 제안한다.
    2. SODA는 지식 그래프를 통해 사회적 상식 지식을 맥락화하여 대규모 언어 모델에서 사회적 상호작용을 포함하고 있다.
    3. SODA를 이용하여 COSMO라는 대화 모델을 학습시키고, COSMO는 이전의 최고 성능 대화 모델들보다 더 자연스럽고 일관성 있으며, 때로는 사람이 작성한 골드 응답보다 선호받는다는 것을 실험적으로 확인하였다.

###### Multi-view Contrastive Learning for Entity Typing over Knowledge Graphs (https://aclanthology.org/2023.emnlp-main.800/)
- Anthology ID: 2023.emnlp-main.800 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 지식 그래프 entity typing (KGET)은 지식 그래프 내 entity의 유형을 추론하는 것을 목표로 한다. 기존 방법들은 neighbor와 entity의 유형에 의해 제공된 지식을 효과적으로 인코딩하는 데 초점을 맞추지만, 유형이 함께 클러스터링 될 수 있는 방식에서 제공되는 의미적 지식을 무시한다. 
    2. 본 논문에서는 Multi-view Contrastive Learning for knowledge graph Entity Typing (MCLET)라는 혁신적인 방법을 제안한다. MCLET은 클러스터를 통해 제공되는 coarse-grained 지식을 entity와 유형 embedding에 효과적으로 인코딩한다.
    3. 실험 결과, MCLET이 기존의 최신 기술과 비교하여 강력한 성능을 보여준다.

###### MailEx: Email Event and Argument Extraction (https://aclanthology.org/2023.emnlp-main.801/)
- Anthology ID: 2023.emnlp-main.801 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 본 논문에서는 첫번째로 "MailEx"라는 대화식 이메일 스레드에서 이벤트 추출을 수행하기 위한 데이터셋을 제안한다. 
    2. 이 데이터셋은 이메일 도메인에서 10개의 이벤트 유형과 76개의 인수를 포함하는 새로운 태그 분류 체계를 제안한다. 
    3. 실험을 통해 fine-tuned sequence labeling, fine-tuned generative extraction 및 few-shot in-context learning의 세 가지 접근 방식을 비교하고, 동기적으로 작동하는 것이 얼마나 도전적인지 보여주었다.

###### Optimized Tokenization for Transcribed Error Correction (https://aclanthology.org/2023.emnlp-main.802/)
- Anthology ID: 2023.emnlp-main.802 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 발음의 변화, 오디오 조건의 악화 및 라벨이 부족한 데이터 등에 직면한 음성 인식 시스템의 어려움을 극복하기 위해 반복적인 에러를 수정하는 후처리 단계가 필요하다. 
    2. 이 논문에서는 실제 트랜스크립트 에러로부터 착안해 에러 분포를 사용한 합성된 데이터만을 사용하여 모델을 훈련하는 것이 성능을 크게 향상시킬 수 있다는 것을 실험적으로 보여준다. 
    3. 또한, BPE tokenizer의 어휘에 언어별 조정을 적용함으로써 훈련 데이터의 분포에 적응하는 동시에 트랜스크립트 에러의 지식을 유지하는 균형을 이룰 수 있다고 제안한다.

###### Beware of Model Collapse! Fast and Stable Test-time Adaptation for Robust Question Answering (https://aclanthology.org/2023.emnlp-main.803/)
- Anthology ID: 2023.emnlp-main.803 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사전 학습 언어 모델 (PLM)은 질문 답변 (QA)에서 큰 성공을 거두었지만, 실제 응용에서의 강건성은 아직 충분치 않아 분포 변화에 대응하기 힘들다. 
    2. 이 논문에서는 테스트 시간 적응 (TTA)이 모델 붕괴를 유발하는 이유를 조사하고 QA의 균형 잡히지 않은 레이블 분포가 그 원인임을 발견하였다. 
    3. Anti-CF를 제안하여 TTA의 안정성과 신뢰성을 향상시키는데 성공하였으며, 다양한 분포 변화 시나리오와 사전 학습 언어 모델에서 좋은 결과를 얻을 수 있음을 실험으로 입증하였다.

###### Generative Adversarial Training with Perturbed Token Detection for Model Robustness (https://aclanthology.org/2023.emnlp-main.804/)
- Anthology ID: 2023.emnlp-main.804 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 일반적인 적대적 학습 방법들은 임베딩 표현에 노이즈를 주지만, 실제 텍스트 기반의 공격은 이산적인 토큰으로 노이즈를 주므로, 임베딩 표현과 텍스트 토큰 간의 간극이 존재하여 적대적 학습의 효과가 제한될 수 있다.
    2. 이 논문에서는 이 간극을 메꾸는 새로운 생성 적대적 학습 프레임워크를 제안한다. 이 프레임워크는 경사 기반 학습, 적대적 샘플 생성, 토큰 노이즈 탐지를 통합하며, 토큰 수준의 지도 및 샘플 활용 효율성 향상을 제공한다.
    3. AdvGLUE 벤치마크의 다섯 개 데이터셋에서 수행된 실험 결과, 이 프레임워크가 모델의 robustness를 크게 향상시키며, 평균 정확도에서 ChatGPT의 최고 성능을 10% 능가한다.

###### Multi-Task Knowledge Distillation with Embedding Constraints for Scholarly Keyphrase Boundary Classification (https://aclanthology.org/2023.emnlp-main.805/)
- Anthology ID: 2023.emnlp-main.805 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 학술 논문의 중요한 키워드를 식별하고 사전에 정의된 클래스 (태스크, 프로세스, 물질 등)에 대해 분류하는 학술 키워드 경계 분류 작업을 위한 새로운 임베딩 제약 조건을 제안한다. 
    2. 이 논문은 기존의 단일 작업 모델 (teachers)과 다중 작업 모델 (student) 간의 임베딩 공간에서의 유사성을 강제하는 다중 작업 지식 전달에 대한 새로운 임베딩 제약 조건을 제안한다. 
    3. 실험 결과는 제안한 접근법이 이전의 연구 및 강력한 베이스라인보다 학술 논문 데이터셋에서 성능이 우수함을 보여준다.

###### Set Learning for Generative Information Extraction (https://aclanthology.org/2023.emnlp-main.806/)
- Anthology ID: 2023.emnlp-main.806 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 Information Extraction (IE)에서 sequence-to-sequence (Seq2Seq) 모델을 사용하기 시작했으나, 구조화된 객체들의 성질로 인해 순서 바이어스(order bias)가 있는 문제가 있다.
    2. 이 논문에서는 구조화된 객체들의 순열을 고려하여 집합 확률을 최적화하는 set learning 접근 방식을 제안한다.
    3. 실험 결과, 이 방법은 기존의 IE 프레임워크에서도 효과를 보여주며 다양한 작업과 데이터셋에서 일관적으로 성능을 향상시킨다.

###### Large Language Models and Multimodal Retrieval for Visual Word Sense Disambiguation (https://aclanthology.org/2023.emnlp-main.807/)
- Anthology ID: 2023.emnlp-main.807 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Visual Word Sense Disambiguation (VWSD)는 텍스트의 문맥에서 모호한 단어의 의미를 더 잘 나타내는 이미지를 후보 집합에서 찾는 도전적인 과제이다."
    2. 이 논문에서는 다양한 접근 방식을 적용하여 이 흥미로운 과제를 해결하기 위한 중요한 단계를 밟는다. 
    3. 문제를 텍스트-텍스트 및 이미지-이미지 검색, 그리고 질문-답변(QA)로 변환하여 관련 모델의 능력을 완벽히 탐구한다.

###### Be Selfish, But Wisely: Investigating the Impact of Agent Personality in Mixed-Motive Human-Agent Interactions (https://aclanthology.org/2023.emnlp-main.808/)
- Anthology ID: 2023.emnlp-main.808 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 협상 대화 시스템을 설계하는 자연스러운 방법은 self-play 강화학습을 통해 원한다. 그러나 이 방법은 협상에서 타협의 가치를 배우지 못하는 결함이 있는 시스템을 만들어 제안 양상을 표현하지 못한다.
    2. 본 논문에서는 협상 이론에 근거하여 훈련 절차를 수정하여 각각 다른 성격을 가진 에이전트를 설계하고 인간 파트너와의 성능을 분석하여 selfish agent를 제안한다.
    3. selfish agent는 자신의 성능을 최대화하면서 타협을 방지하여 자신과 협상 상대에게 가치를 창출하는 방식으로 좋은 성능을 보여주었다. 이러한 결과는 미래에 성공적인 협상 대화 시스템을 설계하는 데에 영향을 끼칠 것으로 기대된다.

###### Doolittle: Benchmarks and Corpora for Academic Writing Formalization (https://aclanthology.org/2023.emnlp-main.809/)
- Anthology ID: 2023.emnlp-main.809 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 학문적 글쓰기의 질을 향상시키는 것은 의미있지만 어려운 과제이다. 기존의 언어 개선 방법들은 문법 오류나 부적절한 단어 사용과 같이 고립된 문장 내에서의 국한된 언어적 특징에 초점을 맞추고 있다.
    2. 이 논문에서는 학문적 글쓰기의 전반적인 품질을 향상시키기 위해 Academic Writing Formalization (AWF) 이라는 더 일반적인 작업을 제안한다. 이를 위해 비-병렬 데이터셋인 Doolittle을 만들고, metric-oriented reinforcement learning (MORL) 기법을 사용하여 기존 언어 모델을 개선시킨다.
    3. 실험 결과, 기존의 텍스트 전환 모델과 문법 오류 수정 모델은 일부 AWF 측면을 다루지만 인간 수행 성능과는 상당한 차이가 있다. 반면, MORL 기법을 적용한 언어 모델은 bet과 ChatGPT와 견줄만한 향상된 성능을 보이지만 Doolittle의 정답 학문적 텍스트와는 아직 미세한 차이가 있다.

###### Token Prediction as Implicit Classification to Identify LLM-Generated Text (https://aclanthology.org/2023.emnlp-main.810/)
- Anthology ID: 2023.emnlp-main.810 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존 방식과 달리 새로운 접근법으로 텍스트 생성과 관련된 대규모 언어 모델을 식별하는 방법을 소개한다. 
    2. 이 방법은 기본 언어 모델에 추가적인 분류 레이어를 추가하는 것이 아닌, 분류 작업을 다음 토큰 예측 작업으로 바꾸어 기본 언어 모델을 직접 feine-tune 하는 방식이다. 
    3. 실험 결과는 우리의 방법이 텍스트 분류 작업에서 우수한 성능을 보이며, 간단하고 효율적인 것을 강조하고 있다. 우리의 모델이 추출한 피처에 대한 해석적 연구는 명시적인 분류기가 없더라도 여러 LLMs의 서로 다른 쓰기 스타일을 구별하는 능력을 나타낸다.

###### On Evaluation of Bangla Word Analogies (https://aclanthology.org/2023.emnlp-main.811/)
- Anthology ID: 2023.emnlp-main.811 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 기존의 방글라(Bangla) 단어 임베딩의 품질을 평가하기 위한 벤치마크 데이터셋을 제시한다. 방글라는 세계에서 7번째로 많이 사용되는 언어이지만, 신뢰할만한 NLP 모델을 개발하는 것은 여전히 어렵다. 따라서 방글라 단어 임베딩의 품질을 평가하고 향후 연구를 이끌어가기 위한 벤치마크 데이터셋을 개발하는 것이 중요하다. 
    2. 우리는 방글라 단어 유추 문제를 위한 새로운 평가 데이터셋을 소개하고, 다양한 최신 임베딩 모델을 실험해보았다. 그 결과, 현재의 방글라 단어 임베딩 모델은 두 데이터셋 모두에서 높은 정확도를 달성하기 어려움을 보여주었다. 이는 다국어 NLP 연구에서 상당한 미흡함을 보여준다. 
    3. 따라서 방글라 단어 임베딩의 품질 향상을 위해 이러한 문제를 극복하기 위한 추가적인 연구가 필요하다.

###### Reconstruct Before Summarize: An Efficient Two-Step Framework for Condensing and Summarizing Meeting Transcripts (https://aclanthology.org/2023.emnlp-main.812/)
- Anthology ID: 2023.emnlp-main.812 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 회의는 보통 여러 참가자와 긴 대화가 포함되어 있어 중복되고 사소한 내용을 포함하는데, 이러한 도전을 극복하기 위해 효과적이고 효율적인 회의 요약을 위한 Reconstruct before Summarize (RbS)라는 2단계 프레임워크를 제안한다. 
    2. RbS는 회의 대본을 재구성하여 필수적인 내용을 주석을 달아 활용하는 self-supervised 패러다임을 먼저 사용하고, RPB(Relative Positional Bucketing) 알고리즘을 통해 (기존의) 요약 모델이 요약을 생성할 수 있도록 한다. 
    3. 우리의 제안된 RPB는 추가적인 재구성 과정에도 불구하고, 입력을 크게 압축하여 전통적인 요약 방법에 비해 빠른 처리와 메모리 소비를 줄일 수 있다. 함께 수행한 방법의 효과적이고 효율적인 평가 및 분석을 통해 우리의 방법이 이전의 최고 수준의 접근법보다 더 우수한 성능을 보인다는 것을 검증하였다.

###### XLM-V: Overcoming the Vocabulary Bottleneck in Multilingual Masked Language Models (https://aclanthology.org/2023.emnlp-main.813/)
- Anthology ID: 2023.emnlp-main.813 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 다국어 언어 모델은 100개 이상의 언어에 걸쳐 공유하는 하나의 어휘집에 의존한다. 그러나 이 어휘집 병목현상은 XLM-R과 같은 다국어 모델의 표현 능력을 제한하고 있다.
    2. 이 논문에서는 서로 어휘 중복이 거의 없는 언어들 사이에서 토큰 공유를 강조하지 않고, 각 언어에 충분한 커버리지를 얻기 위해 어휘 용량을 할당하는 방식으로 대규모 다국어 어휘를 확장하는 새로운 접근 방식을 소개한다.
    3. 이 개선된 어휘를 활용하여 XLM-V라는 백만 토큰 어휘를 사용하는 다국어 언어 모델을 훈련시켰고, XNLI, MLQA, XQuAD, TyDiQA 및 WikiAnn과 같은 다양한 작업에서 XLM-R보다 우수한 성능을 보였다. 특히 저자원 언어 작업에서 XLM-R 대비 MasakhaNER에서 11.2%, Americas NLI에서는 5.8%의 절대적인 성능 향상을 보였다.

###### Character-LLM: A Trainable Agent for Role-Playing (https://aclanthology.org/2023.emnlp-main.814/)
- Anthology ID: 2023.emnlp-main.814 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델(Large language models, LLMs)은 사람의 지시를 이해하고 고품질의 텍스트를 생성할 수 있는 능력을 갖고 있기 때문에 인간 행동을 시뮬레이션하는 에이전트로 사용될 수 있다. 
    2. 이 논문에서는 LLM이 단순한 인간 행동보다 더 높은 형태로 사람을 시뮬레이션할 수 있는지를 알아보기 위해, 제한된 프롬프트 대신 특정 인물의 프로필, 경험 및 감정 상태를 갖는 에이전트를 훈련시키는 방법을 제안한다. 
    3. 실험 결과는 훈련된 에이전트를 인터뷰하고 에이전트가 자신의 캐릭터와 경험을 기억하는지를 평가하는 테스트 환경을 구축하여 효과를 평가하였으며, 흥미로운 관찰 결과를 제시하여 인간의 시뮬레이션에 도움이 되는 방향으로 발전시킬 수 있다.

###### Natural Language Decompositions of Implicit Content Enable Better Text Representations (https://aclanthology.org/2023.emnlp-main.815/)
- Anthology ID: 2023.emnlp-main.815 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사람들이 텍스트를 해석할 때, 언어 자체를 벗어나는 추론에 의존한다. 이 논문에서는 이러한 관찰을 바탕으로 의미를 고려한 텍스트 분석 방법을 소개한다.
    2. 큰 규모의 언어 모델을 사용하여 observed한 텍스트와 추론적으로 관련된 명제들의 집합을 생성하고, 이로 인해 생성된 내용의 타당성을 사람들의 판단을 통해 확인한다.
    3. 이러한 내재적인 내용을 명시적으로 표현하면, 주장의 유사성을 평가하거나 의견 데이터의 의미를 추론하는 등의 다양한 문제 상황에서 유용하게 활용될 수 있다.

###### A Scalable Framework for Table of Contents Extraction from Complex ESG Annual Reports (https://aclanthology.org/2023.emnlp-main.816/)
- Anthology ID: 2023.emnlp-main.816 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "회사의 ESG (환경, 사회, 지배구조) 연차 보고서을 구조화하는 것은 효과적인 Table of Contents (ToC) 추출의 핵심입니다."
    2. "이 논문에서는 초기 트리 구조를 구축한 다음 노드 하나씩 독립적으로 모델링하여 적절한 작업을 수행하는 새로운 ToC 추출 프레임워크를 제안합니다."
    3. "실험 결과, 우리의 방법이 이전 최첨단 베이스라인보다 우수한 성능을 보여주며 실행 시간의 일부분만 사용하여 처리 가능함을 입증하였습니다."

###### Semantic Space Grounded Weighted Decoding for Multi-Attribute Controllable Dialogue Generation (https://aclanthology.org/2023.emnlp-main.817/)
- Anthology ID: 2023.emnlp-main.817 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "사용자의 성격, 감정, 대화 행위와 같은 다양한 속성으로 chatbot의 발화 생성을 제어하는 것은 실용적으로 유용하지만 연구되지 않은 문제이다."
    2. "우리는 DASC라는 새로운 프레임워크를 제안한다. 이는 가중치 기반 디코딩 패러다임으로 강력한 제어성을 가지고 속성 의미 공간에서의 근거화를 통해 성능 향상을 이끈다."
    3. "실험 결과, DASC는 3 가지 측면의 동시 제어로 발화 생성 작업에서 높은 제어 정확도를 달성할 수 있으며, 분포에서 벗어난 강인성 테스트에서도 흥미로운 및 합리적으로 이치에 맞는 응답을 생성한다."

###### How do languages influence each other? Studying cross-lingual data sharing during LM fine-tuning (https://aclanthology.org/2023.emnlp-main.818/)
- Anthology ID: 2023.emnlp-main.818 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다국어 언어 모델(MLM)은 다른 언어의 데이터에서 학습되어 개별 언어의 표현이 다른 언어의 데이터의 도움을 받을 수 있는 모델이다. 
    2. 이 논문에서는 TracIn이라는 훈련 데이터 속성(TDA) 방법을 사용하여 개별 언어의 테스트 예측에 가장 영향력 있는 훈련 샘플을 분석하여 MLM의 크로스-언어 공유 메커니즘을 새로운 관점에서 분석한다. 
    3. 이 연구에서는 MLM이 fine-tuning 동안 다른 언어의 데이터에 의존하는 것을 발견하였고, 테스트 언어 자체의 데이터로 습득된 지식을 보강하고 보완하는데 다른 언어의 훈련 샘플이 도움이 된다는 결과를 얻었다.

###### COFFEE: Counterfactual Fairness for Personalized Text Generation in Explainable Recommendation (https://aclanthology.org/2023.emnlp-main.819/)
- Anthology ID: 2023.emnlp-main.819 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어 모델이 우리의 디지털 생활에 점점 통합됨에 따라, 개인화된 텍스트 생성(PTG)은 다양한 응용 분야에서 중요한 구성 요소로 부상하고 있다. 
    2. 그러나 PTG 모델의 학습에 사용되는 사용자 작성 텍스트의 편향은 언어적인 품질의 다른 수준을 사용자의 보호된 특성과 연결시킬 수 있으며, 모델은 이러한 편향을 상속받아 사용자의 보호된 속성과 관련하여 텍스트를 생성함으로써 불공평한 대우를 유발할 수 있다.
    3. 이 논문에서는 PTG의 공정성을 모색하고, 개인화된 설명 생성에 대한 공정성을 달성하는 일반적인 프레임워크를 제안한다. 초록에서 제안한 방법은 다양한 실험과 인간 평가를 통해 효과적임을 입증하였다.

###### NameGuess: Column Name Expansion for Tabular Data (https://aclanthology.org/2023.emnlp-main.820/)
- Anthology ID: 2023.emnlp-main.820 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델의 최근 발전으로 데이터베이스 산업을 포함한 여러 산업에서 혁신이 이루어지고 있다. 그러나 대량의 테이블 데이터를 처리할 때 일반적인 문제점 중 하나는 약어로 된 열 이름의 널리 사용되는 것으로, 이는 데이터 검색, 접근 및 이해 과제에서 성능에 부정적인 영향을 미칠 수 있다.
    2. 이 문제를 해결하기 위해 우리는 NameGuess라는 새로운 작업을 소개하였는데, 이는 데이터베이스 스키마에 사용되는 열 이름을 자연어 생성 문제로 확장하는 것이다. 우리는 새로운 데이터 제작 방법과 실제 테이블에서 추출한 예제를 포함한 사람에 의해 주석이 달린 평가 벤치마크를 사용하여 38.4K 개의 약어-확장 열 쌍의 학습 데이터셋을 생성하였다.
    3. 이 논문에서는 NameGuess의 동의어성과 모호성과 같은 복잡성에 대응하기 위해 테이블 내용과 열 헤더 이름에 의존하는 자기회귀 언어 모델을 개선하여 인간 수준의 성능을 달성하였고, 향후 가능성을 확인하기 위해 다양한 LLMs에 대한 포괄적인 분석을 수행하였다.

###### BLESS: Benchmarking Large Language Models on Sentence Simplification (https://aclanthology.org/2023.emnlp-main.821/)
- Anthology ID: 2023.emnlp-main.821 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 대형 언어 모델(Large Language Models, LLMs)의 텍스트 단순화(Text Simplification) 작업에서 최근 최첨단 모델들의 성능을 평가하는 BLESS 벤치마크를 제시한다.
    2. 여러 가지 사이즈, 구조, 사전 훈련 방법 및 접근성을 가진 44개 모델을 선정하여 위키피디아, 뉴스 및 의학과 같은 다양한 도메인의 세 가지 테스트 세트에서 평가한다.
    3. 이 평가는 자동적인 메트릭 뿐 아니라 다양한 모델들이 수행한 일반적인 수정 작업의 유형에 대한 대규모의 양적 조사 및 일부 모델 출력물에 대한 수동적인 질적 분석을 포함한다.

###### To Build Our Future, We Must Know Our Past: Contextualizing Paradigm Shifts in Natural Language Processing (https://aclanthology.org/2023.emnlp-main.822/)
- Anthology ID: 2023.emnlp-main.822 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어처리 (NLP)는 방법론, 자금 조달, 대중 인식에 영향을 미치는 비판적인 변화의 시기에 있다. 이 논문에서는 과거를 더 잘 이해하여 미래를 형성하는 방법을 알아보고자 한다.
    2. 우리는 26명의 NLP 연구자와 심층적인 인터뷰를 통해 문화, 인센티브, 인프라 등이 NLP 분야를 형성하는 요소를 연구했다. 
    3. 우리는 NLP 분야의 변화에 대한 주기적인 패턴 및 벤치마크 문화와 소프트웨어 인프라의 변화와 같은 다양한 변화를 확인하고, 과거와 현재에 대한 연구를 통해 앞으로의 방향에 대한 공유된 비전과 우려를 논의한다.

###### PALS: Personalized Active Learning for Subjective Tasks in NLP (https://aclanthology.org/2023.emnlp-main.823/)
- Anthology ID: 2023.emnlp-main.823 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 주관적인 NLP 문제에 대해 개인화된 솔루션을 활용할 수 있다. 학습된 모델은 각 독자에 대해 독립적으로 내용에 대한 지각을 추론한다. 훈련 데이터를 얻기 위해 일반적으로 텍스트를 사용자에게 무작위로 할당하여 주석을 달아야 하는데, 이는 비용이 많이 들고 효율성이 떨어진다.
    2. 개인화된 문맥에서 더 나은 개인마다 선호하는 학습을 위해 active learning 패러다임을 처음으로 적용하는 것을 제안한다. 이는 관련성이 더 높은 훈련 샘플을 선택하여 주석 작업을 완화하는 것을 목표로 한다.
    3. 새로운 개인화된 활동 학습 기법(PALS)을 제시한다. 이 기법은 학습자 개인의 선호도에 대한 문맥에서 텍스트의 관련성을 판단하는 새로운 다섯 가지 측정 지표를 사용한다. 이 기법은 aggression과 toxicity로 개별적으로 라벨링된 Wiki 토론 텍스트와 Unhealthy Conversations 데이터셋에서 검증되었다. PALS 기법은 무작위 선택보다 30% 이상 우수한 결과를 보여준다. 또한 우수한 품질을 유지하면서 필요한 주석 수를 줄이기 위해 사용될 수 있다.

###### ViStruct: Visual Structural Knowledge Extraction via Curriculum Guided Code-Vision Representation (https://aclanthology.org/2023.emnlp-main.824/)
- Anthology ID: 2023.emnlp-main.824 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최신 VLM(Vision-Language Model)은 객체 간의 관계와 같은 구조적 지식 추출에서는 여전히 성능이 제한적이다.
    2. 이 논문에서는 ViStruct라는 VLM을 훈련시키기 위한 훈련 프레임워크를 제안한다. 프로그래밍 언어의 내재된 구조를 활용하여 시각적 구조 정보를 표현한다.
    3. ViStruct는 시각적 구조를 점진적으로 이해하기 위해 과정 기반 학습을 도입하고, 시각적 이벤트 구조와 같은 복잡한 구조 이해에 하위 수준의 지식이 기여할 수 있다는 가정을 제시한다.

###### LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models (https://aclanthology.org/2023.emnlp-main.825/)
- Anthology ID: 2023.emnlp-main.825 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대용량 언어 모델 (LLMs)은 놀라운 능력으로 인해 다양한 응용 분야에서 사용되고 있다. (CoT) prompting 및 in-context learning (ICL)과 같은 기술의 발전으로 LLM에 전달되는 프롬프트는 점점 길어지고 수만 개의 토큰을 초과하기도 한다.
    2. 이 논문에서는 고압축률에서도 의미적 일관성을 유지하기 위한 예산 컨트롤러, 압축 내용 간의 상호 의존성을 더 잘 모델링하기 위한 토큰 수준의 반복 압축 알고리즘, 그리고 언어 모델 사이에서 분포 정렬을 위한 instruction tuning 기반의 메소드를 포함하는 특허 압축 방법을 제안한다.
    3. GSM8K, BBH, ShareGPT 및 Arxiv-March23와 같이 다양한 시나리오에서 수행된 실험과 분석을 통해 제안된 접근 방식이 최첨단 성능을 발휘하며 성능 손실이 거의 없이 최대 20배 압축이 가능하다는 것을 보여준다.

###### EXPLAIN, EDIT, GENERATE: Rationale-Sensitive Counterfactual Data Augmentation for Multi-hop Fact Verification (https://aclanthology.org/2023.emnlp-main.826/)
- Anthology ID: 2023.emnlp-main.826 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에 자동 다중 점프 사실 검증 작업이 큰 관심을 받고 있다. 그러나 이러한 잘 설계된 모델들은 도메인 이외의 데이터에서 성능이 좋지 않다. 
    2. 우리는 라벨을 뒤집어 생성하면서 복잡한 논리적 관계를 보존하는 언어적으로 다양하고 논리적인 카운터팩처얼을 생성하기 위해 "Explain-Edit-Generate" 아키텍처를 통한 합리적인 방법을 개발함으로써 이러한 한계를 극복한다. 
    3. 실험 결과, 우리의 접근 방식이 SOTA 기준을 능가하며, 언어적으로 다양한 카운터팩처얼 데이터를 유지하면서 논리적인 관계를 깨지 않고 생성할 수 있다는 것을 보여준다.

###### An Exploration of Left-Corner Transformations (https://aclanthology.org/2023.emnlp-main.827/)
- Anthology ID: 2023.emnlp-main.827 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "왼쪽 꼭짓점 변환은 context-free 문법에서 왼쪽 재귀를 제거하여 간단한 기술로 문법을 위에서 아래로 구문 분석 가능하게 만드는 중요한 단계입니다."
    2. 본 논문은 semiring-weighted production rule을 지원하고, 이동할 수 있는 왼쪽 꼭짓점을 더 세밀하게 제어하기 위해 이전의 왼쪽 꼭짓점 변환 방법을 일반화합니다.
    3. 실험을 통해 GLCT의 효율성과 9개 언어의 문법에서 왼쪽 재귀를 제거하는 능력을 확인하였습니다.

###### Characterizing and Verifying Scientific Claims: Qualitative Causal Structure is All You Need (https://aclanthology.org/2023.emnlp-main.828/)
- Anthology ID: 2023.emnlp-main.828 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 과학적 명제는 현상 또는 변수 간의 잠재적인 관계에 대한 임시의 진술이기 때문에 그들은 과학적인 명제 검증의 범주에서 연구 질문이나 가설의 구체적인 형태로 시작된다. 
    2. 이 논문은 과학적인 명제 검증에서 풀어야 할 과제에 대해 깊이있게 탐구하며, 과학적 명제에 내재된 인과구조 정보를 간과하고 있어 인과추론의 포괄적인 체인을 만들지 못한다고 주장한다.
    3. 우리는 풍부한 인과구조를 헤체로 형성하고, 주로 원인 요인들 간의 인과 추론을 용이하게 하기 위해 관심 요인에 대한 엄격한 관찰과 양방향 주의 기반의 그래프 신경망을 제안한다.

###### FOCUS: Effective Embedding Initialization for Monolingual Specialization of Multilingual Models (https://aclanthology.org/2023.emnlp-main.829/)
- Anthology ID: 2023.emnlp-main.829 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 높은 자원을 가진 언어로 미리 훈련된 모델 가중치를 시작점으로 사용하면, 특히 저자원 언어에 대해 고품질 언어 모델을 얻기 위한 데이터와 계산 필요성을 줄일 수 있다. 하지만, 대상 언어에 특화된 새로운 토크나이저를 사용하려면 소스 모델의 임베딩 행렬을 전이할 수 없다.
    2. 본 논문에서는, FOCUS라는 새로운 임베딩 초기화 방법을 제안한다. 이 방법은 소스 모델의 임베딩 행렬에 포함된 정보를 기반으로 새로운 토크나이저를 위한 임베딩 행렬을 효과적으로 초기화한다.
    3. 실험 결과, FOCUS는 무작위 초기화와 이전 연구에 비해 언어 모델링과 다양한 하위 작업(NLI, QA, NER)에서 우수한 성능을 보였다.

###### ByteSized32: A Corpus and Challenge Task for Generating Task-Specific World Models Expressed as Text Games (https://aclanthology.org/2023.emnlp-main.830/)
- Anthology ID: 2023.emnlp-main.830 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 연구에서는 언어 모델이 과학적이고 상식적인 추론 태스크의 명확하고 해석 가능하며 대화식인 세계 모델을 생성하는 능력을 조사한다. 이를 실행하기 위해, 20,000줄의 파이썬 코드로 이루어진 ByteSized32라는 텍스트 게임 데이터셋을 소개한다.
    2. 실험 결과로, GPT-4 모델이 이러한 게임을 템플릿으로 사용하여 새로운 주제에 대한 게임을 28%의 경우에 성공적으로 생성할 수 있는 것을 보여준다. 
    3. 또한, 게임의 진실성, 기술적 유효성, 태스크 사양 준수도 및 이김 여부 등을 평가하기 위한 자동화된 메트릭을 소개하여 전문가의 평가와 높은 일치도를 보여준다.

###### Skill-Based Few-Shot Selection for In-Context Learning (https://aclanthology.org/2023.emnlp-main.831/)
- Anthology ID: 2023.emnlp-main.831 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. In-context learning은 몇 가지 예제를 제공하여 대규모 언어 모델을 하위 작업에 적응시키는 패러다임인데, 이 때 적절한 예제를 선택하는 few-shot selection이 중요하다. 
    2. 기존의 기반 임베딩 방법은 타깃 작업에 중요하지 않은 surface natural language 특징에 쉽게 영향을 받을 수 있는 문제를 해결하기 위해 Skill-KNN을 제안했다.
    3. Skill-KNN은 모델을 학습하거나 미세 조정할 필요 없이 입력 데이터를 최적화하여 효과적으로 few-shot selection을 수행하며, 다양한 데이터셋과 backbone 모델에서 기존 방법들보다 우수한 성능을 보였다.

###### MaNtLE: Model-agnostic Natural Language Explainer (https://aclanthology.org/2023.emnlp-main.832/)
- Anthology ID: 2023.emnlp-main.832 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 설명 기법인 LIME과 달리, MaNtLE은 예측의 내부 추론을 자연어로 설명하는 모델이다.
    2. MaNtLE은 수천 개의 합성 분류 작업을 활용하여 신뢰할 수 있는 자연어 설명을 생성한다.
    3. 실험 결과, MaNtLE로 생성된 설명은 평균적으로 LIME과 Anchors보다 최소 11% 더 신뢰성이 있으며, 사람 평가에서도 MaNtLE을 이용한 설명을 통해 모델의 동작을 더 정확하게 예측할 수 있다는 것을 보여준다.

###### PTP: Boosting Stability and Performance of Prompt Tuning with Perturbation-Based Regularizer (https://aclanthology.org/2023.emnlp-main.833/)
- Anthology ID: 2023.emnlp-main.833 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 연구에서 prompt tuning이 downstream 자연어 이해 태스크에서 fine-tuning보다 언어 모델의 성능을 더 잘 활용할 수 있음을 보여주었다. 그러나 기존의 prompt tuning 방법은 훈련 불안정성 문제가 있으며, 랜덤 시드에 따른 점수의 분산이 크다.
    2. 이 논문에서는 prompt tuning의 불안정성을 해결하기 위해 주어진 데이터의 작은 변화가 손실 계면에 큰 변동을 일으키는 이전적 경향을 발견하고, 이를 완화하기 위해 왜곡 기반 규제기법을 소개한다.
    3. 실험 결과, 이러한 규제기법을 적용한 PTP 방법은 prompt tuning의 훈련 불안정성을 크게 완화하고 성능을 향상시킨다고 보여진다. 또한, 기존의 prompt tuning 방법들보다 SuperGLUE와 FewGLUE 벤치마크에서 각각 1.94%와 2.34%의 성능 향상을 이룬다.

###### Ling-CL: Understanding NLP Models through Linguistic Curricula (https://aclanthology.org/2023.emnlp-main.834/)
- Anthology ID: 2023.emnlp-main.834 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 우리는 심리언어학 및 언어 습득 연구에서의 언어 복잡성에 대한 특성화를 활용하여 NLP 태스크를 해결하기 위해 모델이 학습하는 언어적 지식을 이해하기 위해 데이터 기반 교육과정을 개발한다.
    2. 우리의 접근 방식은 데이터, 언어 복잡성에 대한 기존 지식, 그리고 모델이 훈련 중에 보이는 행동을 기반으로 한 언어 교육과정을 개발하는 것에 있다.
    3. 우리의 교육 과정 학습 접근법은 여러 벤치마크 NLP 데이터셋의 평가를 통해 각 태스크를 해결하기 위해 필요한 도전과 추론을 나타내는 언어 지표(지수) 세트를 식별한다. 이 작업은 NLP의 모든 영역에서 향후 연구에 지침을 제공하며, 언어 복잡성을 연구 및 개발 프로세스의 초기에 고려할 수 있도록 한다. 또한, 우리의 연구는 NLP의 표준과 공정한 평가를 검토할 필요성을 제기한다.

###### Towards Unsupervised Recognition of Token-level Semantic Differences in Related Documents (https://aclanthology.org/2023.emnlp-main.835/)
- Anthology ID: 2023.emnlp-main.835 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 두 문서 간의 의미적 차이를 자동으로 강조하는 것은 다양한 응용 분야에 유용할 수 있다. 우리는 의미적 차이를 인식하는 것을 토큰 수준의 회귀 작업으로 정의하고, 마스크된 언어 모델에 의존하는 세 가지 비지도 학습 접근법을 연구한다.
    2. 우리의 연구 결과는 단어 정렬 및 문장 수준 비교 학습을 기반으로 한 접근 방식이 골드 레이블과 강력한 연관성을 가지고 있다는 것을 보여준다.
    3. 하지만 모든 비지도 학습 접근법은 여전히 큰 개선余地을 남겨두고 있다.

###### Towards a Better Understanding of Variations in Zero-Shot Neural Machine Translation Performance (https://aclanthology.org/2023.emnlp-main.836/)
- Anthology ID: 2023.emnlp-main.836 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다국어 기계번역은 지식 공유를 촉진하지만 zero-shot 번역의 품질이 낮은 경우가 많다. 이 논문에서는 zero-shot 번역 품질의 변동성에 관한 연구를 제시하고, 번역 방향에 따라 예측 가능한 결과를 얻을 수 있다는 것을 발견하였다.
    2. 목표 언어의 번역 품질, 어휘의 중복성, 언어적 특성은 zero-shot 번역 성능의 변동성에 영향을 미치는 세 가지 요소로 확인되었다.
    3. 학습 모델의 크기가 작을 경우, 언어가 속한 언어 가족이나 쓰기 체계도 zero-shot 번역에 영향을 준다. 또한 off-target 문제는 성능의 불충분함을 나타내는 증상으로, zero-shot 번역 문제를 해결하기 위해서는 더 많은 노력이 필요하다.

###### SEER : A Knapsack approach to Exemplar Selection for In-Context HybridQA (https://aclanthology.org/2023.emnlp-main.837/)
- Anthology ID: 2023.emnlp-main.837 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 복합적인 문맥에서의 질문 답변은 비구조화된 텍스트와 구조화된 테이블로부터 정보를 다양한 방식으로 결합해야하는 복잡한 과제입니다.
    2. 이 논문에서는 대규모 언어 모델이 소수의 exemplar를 기반으로 예측을 수행하는 인 콘텍스트 학습에 대한 효과적인 exemplar 선택 방법인 SEER를 제안합니다.
    3. SEER는 Knapsack 정수 선형 프로그램으로 exemplar 선택을 수행하며, 다양성 제약과 용량 제약을 고려하여 적절한 exemplar 집합을 선택할 수 있습니다.

###### Conversation Chronicles: Towards Diverse Temporal and Relational Dynamics in Multi-Session Conversations (https://aclanthology.org/2023.emnlp-main.838/)
- Anthology ID: 2023.emnlp-main.838 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어처리 분야에서, 오픈 도메인 챗봇은 중요한 연구 주제로 등장하였다. 그러나 기존의 오픈 도메인 챗봇 연구의 주요한 한계는 단일 세션 대화에만 초점을 두고, 여러 연속적 세션에서의 문맥적 정보를 이해할 필요성을 간과한다는 것이다.
    2. 이 논문에서는 타임 인터벌과 발화자 간의 관계가 포함된 긴 시간 동안의 대화 설정을 구현하기 위해 Conversation Chronicles라는 새로운 1M 개의 멀티-세션 대화 데이터셋을 소개한다.
    3. 이 데이터를 활용하여 학습된 ReBot이라는 대화 모델은 630M개의 파라미터만을 사용하여 긴 시간 동안의 문맥을 잘 이해하며 높은 인간 참여 점수를 보여준다.

###### DueT: Image-Text Contrastive Transfer Learning with Dual-adapter Tuning (https://aclanthology.org/2023.emnlp-main.839/)
- Anthology ID: 2023.emnlp-main.839 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 대조적 학습을 통해 구축된 비전 및 언어 모델에 대한 새로운 전이 학습 방법인 DueT을 제안한다. DueT은 이미지와 텍스트 인코더에 어댑터를 삽입하여, 유니모달 말뭉치로 사전 학습 된 모델을 초기화한 후 고정시킨다.
    2. DueT은 오직 이러한 어댑터만 학습하여, 학습 가능한 파라미터의 수를 줄이고 효율적인 학습을 가능하게 한다.
    3. 더 나아가, DueT의 어댑터는 일반적인 어댑터와는 달리 게이팅 메커니즘을 갖추어, 사전 학습된 유니모달 인코더에서 획득한 지식의 전이와 연결을 효과적으로 수행하면서, 잊혀지지 않도록 한다. DueT은 영어와 일본어 도메인에서의 0-샷 이미지 및 텍스트 검색에서 간단한 미세조정, 이미지 인코더 고정 및 텍스트 인코더 학습만 하는 기존 방법, 그리고 LoRA 기반 어댑터 방법보다 정확성과 파라미터 효율성 면에서 성능이 우수하다.

###### Towards a Unified Conversational Recommendation System: Multi-task Learning via Contextualized Knowledge Distillation (https://aclanthology.org/2023.emnlp-main.840/)
- Anthology ID: 2023.emnlp-main.840 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화식 추천 시스템에서 (Conversational Recommendation System) 추천 및 대화 모듈을 별도로 사용하는 것은 추천 결과와 생성된 응답간의 불일치를 초래한다. 
    2. 이를 해결하기 위해, 이 논문에서는 단일 모델이 추천과 대화 과제를 동시에 학습하는 다중 과제 학습을 제안한다. 
    3. 실험 결과, 본 학습 방법을 사용하여 추천 성능을 대폭 향상시킬 수 있으며 유창성을 향상시키고 다양성 측면에서도 유사한 결과를 달성할 수 있다는 것을 보여준다.

###### CLAIR: Evaluating Image Captions with Large Language Models (https://aclanthology.org/2023.emnlp-main.841/)
- Anthology ID: 2023.emnlp-main.841 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이미지 캡션의 기계 생성 평가는 유의미성, 시각적 구조, 객체 상호작용, 다양성 및 특이성과 같은 다양한 유사성 측면을 고려해야 하는 도전적인 과제이다.
    2. 기존 방법들은 특정 측면을 캡처하려고 노력하지만, 인간의 판단과 밀접하게 일치하는 전체적인 점수를 제공하지는 못한다.
    3. 이 논문에서는 CLAIR이라는 새로운 방법을 제안하는데, 이는 대규모 언어 모델의 zero-shot 언어 모델링 능력을 활용하여 후보 캡션을 평가한다. CLAIR은 기존 방법과 비교하여 인간의 평가와 강한 상관관계를 보여준다.

###### MoPe: Model Perturbation based Privacy Attacks on Language Models (https://aclanthology.org/2023.emnlp-main.842/)
- Anthology ID: 2023.emnlp-main.842 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 연구는 대형 언어 모델이 학습 데이터에 있는 민감한 정보를 무심코 노출시킬 수 있다고 보여주고 있다. 
    2. 이 논문에서는 모델의 파라미터에 노이즈를 추가하고, 로그 우도의 하강을 측정하여 사전 훈련된 언어 모델의 학습 데이터에 주어진 텍스트가 있는지 신뢰성 있게 확인할 수 있는 새로운 메서드인 MoPe를 제안한다.
    3. 70M에서 12B까지의 다양한 크기의 언어 모델에 대해 MoPe가 기존의 손실 기반 공격과 최근 제안된 불안정성 기반 방법보다 더 효과적임을 실험적으로 보여준다.

###### q2d: Turning Questions into Dialogs to Teach Models How to Search (https://aclanthology.org/2023.emnlp-main.843/)
- Anthology ID: 2023.emnlp-main.843 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 언어 모델의 대화 기능 중 하나는 주어진 대화 응답의 기반 정보를 독립적으로 검색할 수 있는 능력이다. 그러나 모델이 검색 질의 방법을 학습시키기 위한 훈련 데이터 확보는 시간과 자원이 많이 소요된다.
    2. 본 논문에서는 정보 탐색 대화를 질문에서 생성하는 자동 데이터 생성 파이프라인인 q2d를 제안한다.
    3. 실험 결과, 우리는 기존 방법과 비교해 인간이 작성한 대화 데이터와 유사한 품질의 자동 생성 대화를 생성할 수 있다는 것을 보여주었다.

###### Aligning Large Language Models through Synthetic Feedback (https://aclanthology.org/2023.emnlp-main.844/)
- Anthology ID: 2023.emnlp-main.844 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 큰 언어 모델(Large Language Models, LLMs)의 인간적 가치와의 조화를 이루는 것은 ChatGPT와 같은 프로프라이터리 LLMs로부터의 인간의 신호와 피드백, 혹은 확연한 인간 어노테이션에 의존하기 때문에 점점 더 중요해지고 있다.
    2. 본 연구에서는 상당한 양의 인간 어노테이션 없이도, 인공적인 피드백을 활용한 새로운 맵핑 학습 프레임워크를 제안한다. 
    3. 실험 결과, 우리의 모델인 ALMoST는 InstructGPT나 인간 어노테이션만을 사용하여 훈련된 최근 오픈소스 모델들보다 맵핑 벤치마크에서 뛰어난 성능을 보이고, 인간 평가에서도 다른 모델들에 비해 55.0%와 58.5%의 선호도를 가졌다.

###### You Told Me That Joke Twice: A Systematic Investigation of Transferability and Robustness of Humor Detection Models (https://aclanthology.org/2023.emnlp-main.845/)
- Anthology ID: 2023.emnlp-main.845 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자동 유머 감지는 대화형 인공지능에게 매우 관련 있는 작업이다. 그러나 지금까지는 영어 데이터셋만 존재하고, 해당 데이터셋에서 훈련된 모델이 얼마나 일반화되고 실제 상황에서 작동하는지에 대한 연구가 부족하다.
    2. 이 연구에서는 기존 데이터셋을 자세히 분석하고, 각각의 데이터셋에서 RoBERTa 기반 및 나이브 베이즈 분류기를 훈련하고 나머지 데이터셋에서 테스트함으로써 이러한 공백을 채우고자 한다.
    3. 훈련 및 테스트를 동일한 데이터셋에서 수행하면 좋은 결과를 얻을 수 있지만, 모델의 전이성은 크게 다르다. 전체적으로 서로 다른 출처의 농담이 포함된 데이터셋에서 훈련된 모델은 더 높은 전이성을 보이며, 훈련 데이터의 양은 더 적은 영향을 미친다.

###### Reading Order Matters: Information Extraction from Visually-rich Documents by Token Path Prediction (https://aclanthology.org/2023.emnlp-main.846/)
- Anthology ID: 2023.emnlp-main.846 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 다중 모달 사전 훈련 모델은 시각적으로 풍부한 문서에서의 정보 추출을 크게 향상시켰으나, 실제 세계의 스캔된 문서에서는 OCR 시스템에 의해 인식된 텍스트가 제대로 정렬되지 않는 독서 순서 문제가 있다. 이러한 독서 순서 문제를 해결하기 위해 우리는 Token Path Prediction (TPP)을 제안한다. 
    2. TPP는 문서 내에서 토큰 시퀀스로서 entity mentions을 예측하는 간단한 예측 방법으로, 문서 레이아웃을 토큰의 완전한 방향 그래프로 모델링하고 entity로서 그래프 내의 토큰 경로를 예측한다.
    3. 또한, 스캔된 문서에 대한 NER의 벤치마크 데이터셋을 수정하여 실제 상황을 반영할 수 있도록하며, 실험 결과는 우리의 방법의 효과를 보여주고 문서에 대한 다양한 정보 추출 작업에 대한 보편적인 솔루션이 될 수 있는 잠재력을 제시한다.

###### Empower Nested Boolean Logic via Self-Supervised Curriculum Learning (https://aclanthology.org/2023.emnlp-main.847/)
- Anthology ID: 2023.emnlp-main.847 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 문장 생성 모델이 갖는 인지 능력을 평가하기 위해 해당 논문은 boolean 로직에 초점을 맞춘다. 은 random selector만 하는 것으로 나타났으며 이를 개선하기 위해 Curriculum Logical Reasoning (Clr) 방법론을 제안한다.
    2. Clr 방법은 훈련 데이터를 점차적으로 복잡한 논리 패턴으로 증강하여 모델의 일반화 능력을 향상시키는 self-supervised learning method이다.
    3. 실험 결과 boolean 로직은 일반적인 논리적인 태스크를 개선시키는 좋은 기반이 되며 Clr은 보다 어렵고 복잡한 논리 패턴을 학습할 수 있는 능력을 제공한다.

###### The Sentiment Problem: A Critical Survey towards Deconstructing Sentiment Analysis (https://aclanthology.org/2023.emnlp-main.848/)
- Anthology ID: 2023.emnlp-main.848 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 우리는 sentiment analysis (SA)에 대한 사회기술적 측면을 조사하기 위해 응용, 모델 및 데이터셋에 대해 비판적으로 접근한 189편의 피어 리뷰 논문을 조사했습니다.
    2. 사회기술적 시스템에서 SA가 중요한 요소로 자리잡아 사회 및 기술적 사용자에게 영향을 미침을 인식하고 이를 기반으로 조사를 진행했습니다.
    3. 우리의 연구는 금융, 정부, 의학 등과 같은 분야에서 이 용어에 대한 별개의 개념화를 드러내며, 명확한 정의와 프레임워크의 부재로 인한 잠재적인 도전과 편향이 존재한다고 보여줍니다. 이 문제를 해결하기 위해, 우리는 도덕 시트를 제안하여 SA의 공정한 활용을 지원하기 위해 실무자들에게 안내할 수 있습니다.

###### Poisoning Retrieval Corpora by Injecting Adversarial Passages (https://aclanthology.org/2023.emnlp-main.849/)
- Anthology ID: 2023.emnlp-main.849 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 적대적 사용자가 훈련 쿼리와 유사도를 최대화하기 위해 이산 토큰을 왜곡하여 적은 수의 적대적 패턴을 생성하는 새로운 dense retrieval 시스템 공격을 제안한다.
    2. 공격자가 본 적이 없는 쿼리에 대해 이러한 적대적 패턴을 검색 결과로 인출하는 데 이 공격이 매우 효과적인 것을 보여준다.
    3. 더 놀랍게도, 이 적대적 패턴은 도메인 밖의 쿼리와 공격 성공률이 높은 코퍼스에 직접적으로 적용될 수 있으며, 금융 문서나 온라인 포럼에서 제기된 질문의 94% 이상을 오도할 수 있다.

###### DADA: Dialect Adaptation via Dynamic Aggregation of Linguistic Rules (https://aclanthology.org/2023.emnlp-main.850/)
- Anthology ID: 2023.emnlp-main.850 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 대규모 언어 모델은 주로 표준 미국 영어에 초점을 맞추고 있어 다른 영어 방언에 적용할 때 성능이 크게 저하되는 문제가 있다.
    2. 이 논문에서는 DADA(Dialect Adaptation via Dynamic Aggregation)라는 모듈식 방법을 제안하며, 이를 통해 SAE로 훈련된 모델에 다양한 방언에 대한 강건성을 부여한다.
    3. DADA의 구성적 아키텍처는 특정 방언 변형에 대한 대상적 적응뿐만 아니라 다양한 방언에 대한 동시 적응을 가능하게 한다는 것을 보여주고 있다.

###### Clustering Pseudo Language Family in Multilingual Translation Models with Fisher Information Matrix (https://aclanthology.org/2023.emnlp-main.851/)
- Anthology ID: 2023.emnlp-main.851 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다중 언어 번역 연구에서는 언어 가족의 이해와 활용이 매우 중요하지만, 조상 가족에 기반한 언어들의 클러스터링은 모델의 훈련 단계에서 사용된 데이터셋의 변동으로 인해 최적의 결과를 얻기 어렵다. 
    2. 이 논문에서는 언어쌍이 모델 파라미터에 유사한 영향을 미치는 경우, 언어간 유사성을 보여주는 pseudo language families를 소개한다. 
    3. 실험 결과에서는 이 pseudo language families를 사용하면 기존의 언어 가족보다 낯선 언어 쌍에 대한 다중 언어 번역 모델을 적응시키는 데 성능이 향상되었다고 보여졌다.

###### Unifying Discrete and Continuous Representations for Unsupervised Paraphrase Generation (https://aclanthology.org/2023.emnlp-main.852/)
- Anthology ID: 2023.emnlp-main.852 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Unsupervised paraphrase generation"은 다양한 NLP 응용에서 이점을 얻을 수 있는 어려운 작업이다. 
    2. 현재의 unsupervised 방법들은 주로 번역 또는 무디파잉을 활용하는데, 이는 번역 말뭉치가 필요하며 표면 구조에서 원래 문장과 지나치게 유사한 패러프레이즈를 생성한다. 
    3. 이 논문에서는 번역 데이터에 의존하지 않고 서로 다른 표면 구조에서 다양한 가닥의 pseudo-paraphrases를 생성하는 self-supervised pseudo-data construction 방법을 제안하고, 의미와 entity를 이산 및 연속 변수로 인코딩하여 유사성을 제어하고 정확한 entity를 유지할 수 있는 unsupervised paraphrasing 모델을 제안한다.

###### The Benefits of Label-Description Training for Zero-Shot Text Classification (https://aclanthology.org/2023.emnlp-main.853/)
- Anthology ID: 2023.emnlp-main.853 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사전 훈련된 언어 모델은 훈련 데이터에서 의미적 지식을 전달하여 downstream 태스크에서 특정 레이블 집합을 분류함으로써 zero-shot 텍스트 분류를 개선시켰다. 
    2. 이 논문에서는 최소한의 노력으로 zero-shot 정확도를 더 향상시키는 방법을 제안한다. 
    3. 텍스트 데이터 대신 레이블을 언어로서 설명하는 소량의 fintuning 데이터를 활용하여 다양한 주제와 감성 데이터셋에서 zero-shot보다 17-19% 높은 정확도를 보인다.

###### Multilingual Pixel Representations for Translation and Effective Cross-lingual Transfer (https://aclanthology.org/2023.emnlp-main.854/)
- Anthology ID: 2023.emnlp-main.854 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 픽셀 표현을 사용하여 다국어 기계 번역 모델을 효과적으로 학습하는 방법을 도입하고 보여줍니다.
    2. 단어 부분 표현과 비교하여 픽셀 표현을 사용하면 언어와 문자 스크립트의 다양한 범위에 대해 성능이 향상되는 것을 실험적으로 보여줍니다.
    3. 픽셀 표현의 다양한 특성과 여러 스크립트 간 및 내부에서의 매개 변수 공유를 탐색하여 어떤 상황에서 양호한 전이를 이뤄낼 수 있는지 파악합니다.

###### Finding Authentic Counterhate Arguments: A Case Study with Public Figures (https://aclanthology.org/2023.emnlp-main.855/)
- Anthology ID: 2023.emnlp-main.855 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존 연구들은 세부 개인에 대한 혐오적 컨텐츠에 대항하는 카운터 혐오(Counterhate) 인수를 제공하기 어렵다. 
    2. 본 연구에서는 여러 он라인 기사에서 가져온 54,816개의 혐오적 트윗-문단 쌍으로 이루어진 코퍼스를 제시한다.
    3. 온라인 기사에서 인수를 찾는 것은 인수를 지지하지 않는 주장을 만들 수 있는 카운터 혐오 발생 방법에 비해 효과적인 대안이 될 수 있음을 보여준다.

###### Can We Edit Multimodal Large Language Models? (https://aclanthology.org/2023.emnlp-main.856/)
- Anthology ID: 2023.emnlp-main.856 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문에서는 multimodal Large Language Models (LLMs)를 편집하는 데 중점을 둔다. Single-modal LLMs를 편집하는 것보다 multimodal 모델 편집은 더 어렵고, 편집 과정에서 더욱 신중한 고려가 필요하다.
    2. 이를 위해, 우리는 multimodal LLMs를 편집하고 평가하기 위한 새로운 벤치마크인 MMEdit를 구축하고 혁신적인 메트릭을 제공한다.
    3. 우리는 다양한 모델 편집 기준에 대한 포괄적인 실험을 수행하고, multimodal LLM의 다른 구성 요소를 편집하는 것의 영향을 분석한다. 기존의 베이스라인은 일부 경우에는 multimodal LLMs를 편집할 수 있지만 효과는 여전히 만족스럽지 못하며, 이 작업의 어려움을 나타낸다.

###### Exploring Discourse Structure in Document-level Machine Translation (https://aclanthology.org/2023.emnlp-main.857/)
- Anthology ID: 2023.emnlp-main.857 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존 문서 수준 기계 번역(DocMT) 방법의 성능이 만족스럽지 못한 이유는 긴 범위의 정보를 활용하기 어렵기 때문이다.
    2. 이 논문에서는 문맥의 구조를 활용하여 문서 수준 기계 번역에서 성능을 향상시키는 방법을 제안한다.
    3. 실험 결과, RST-Att 모델이 이전 연구보다 더 나은 성능을 보여주며, 담화 정보를 활용한다는 것을 입증한다.

###### ClusterLLM: Large Language Models as a Guide for Text Clustering (https://aclanthology.org/2023.emnlp-main.858/)
- Anthology ID: 2023.emnlp-main.858 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "ClusterLLM"는 ChatGPT와 같은 instruction-tuned 큰 언어 모델의 피드백을 활용하는 텍스트 클러스터링 프레임워크이다. 기존의 unsupervised 방법과 비교했을 때, ClusterLLM은 (1) LLM의 기능을 활용하여 새로운 능력을 갖게 되면서, (2) 텍스트 명령 및 주석 데이터를 통해 사용자의 클러스터링 선호도를 이해할 수 있다는 이점이 있다. 
    2. ChatGPT에 하드 트리플렛 질문을 주어 작은 embedder에 대한 세밀한 튜닝이 가능하며, 비용 효율적으로 ChatGPT를 쿼리할 수 있다고 실험적으로 보여준다.
    3. 의사 결정된 세부사항으로부터 연속성이 가장 큰 클러스터 계층 구조를 튜닝함으로써, ChatGPT의 답변과 일관성이 가장 큰 클러스터링 세부성을 얻을 수 있다. ClusterLLM은 14개 데이터셋에서 클러스터링 품질을 일관되게 향상시키는 것을 보여주며, 데이터셋 당 평균 비용은 약 $0.6 수준이다.

###### CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code (https://aclanthology.org/2023.emnlp-main.859/)
- Anthology ID: 2023.emnlp-main.859 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. NL→Code 모델의 한계 중 하나는 생성된 출력을 신뢰할 수 있는 방식으로 평가하는 것이다. 이 논문에서는 BERTScore를 기반으로한 새로운 code generation 평가 메트릭인 CodeBERTScore를 제안한다.
    2. CodeBERTScore는 BERTScore와 달리 생성된 토큰뿐만 아니라 생성된 코드 이전의 자연어 입력을 인코딩하여, 생성된 코드와 주어진 자연어 컨텍스트의 일관성을 모델링한다.
    3. CodeBERTScore는 인간의 선호도와 기능적인 정확성과 더 높은 상관관계를 가지며, 높은 점수를 받은 코드는 인간에게 선호되고 실행시 정확하게 작동하는 경향이 있다.

###### Learn and Consolidate: Continual Adaptation for Zero-Shot and Multilingual Neural Machine Translation (https://aclanthology.org/2023.emnlp-main.860/)
- Anthology ID: 2023.emnlp-main.860 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 다국어 기계번역 (MNMT) 모델은 한 모델에서 여러 개의 번역 방향을 다룰 수 있고, 훈련에 없던 언어쌍 사이에서도 zero-shot 번역을 할 수 있지만, 어떤 언어쌍에 대해서는 상대적으로 번역 품질이 낮다. 
    2. 본 논문에서는 제한된 새 데이터가 도착할 때 supervised 및 zero-shot 번역 모두에 대해 MNMT 모델을 지속적으로 업데이트하는 방법을 제안한다.
    3. 실험 결과 및 추가 분석에서, 우리의 방법이 초기에 성능이 약했던 번역 방향에서 기존의 MNMT 모델의 성능을 효과적으로 개선하고, 원래 성능이 좋았던 번역 방향에서의 성능 강화를 통해 실제 상황에서의 유연성을 제공함을 보여준다.

###### e-THERAPIST: I suggest you to cultivate a mindset of positivity and nurture uplifting thoughts (https://aclanthology.org/2023.emnlp-main.861/)
- Anthology ID: 2023.emnlp-main.861 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 정신건강 환자들을 위한 전 세계적으로 접근 가능한 대화 시스템은 필수적인데, 이를 위해서는 사용자의 성별, 연령, 페르소나, 감정 등에 따라 맞는 말을 할 수 있어야 한다. 이 논문에서는 이 목표를 위해, 사용자의 프로파일과 속성에 맞는 응답을 생성하는 새로운 대화 시스템인 "e-THERAPIST"를 제안한다. 
    2. 저자들은 PsychoCon이라고 불리는 특별한 대화 데이터셋을 구성했고 이는 (i) 대화 수준에서 - 사용자의 프로파일 정보 (성별, 나이, 페르소나)와 치료사의 심리치료 접근 방식을 포함하고 있고 (ii) 문장 수준에서 - 사용자의 감정과 치료사의 예의와 대인관계 행동을 포함하고 있다.
    3. 논문에서는 정확한 예의롭고 대인관계적 행동을 익히기 위한 새로운 보상 모델을 고안했으며, 이를 사용하여 PsyCon에서 e-THERAPIST를 학습하는데 사용했다. 실험 결과로, 제안된 e-THERAPIST의 각 구성 요소의 효과성을 검증하였고, 이가 심리치료 환경에 대한 잠재적 영향력을 나타냈다.

###### AfriSenti: A Twitter Sentiment Analysis Benchmark for African Languages (https://aclanthology.org/2023.emnlp-main.862/)
- Anthology ID: 2023.emnlp-main.862 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 아프리카는 6개 이상의 언어 계열에서 2,000개 이상의 언어가 존재하며 모든 대륙 중 언어 다양성이 가장 높다. 하지만 아프리카 언어에 대해 NLP 연구가 매우 부족하다.
    2. 이 논문에서는 아프리카 언어에 대한 고품질 주석된 데이터셋인 AfriSenti를 소개한다. 이 데이터셋은 14개의 아프리카 언어에 대한 110,000개 이상의 트윗을 포함하고 있으며, 이를 기반으로 한 센티멘트 분석 벤치마크를 제시한다.
    3. 이 논문은 AfriSenti 데이터셋에 대한 베이스라인 실험 결과와 그 유용성에 대해 논의하고 있다.

###### Quantifying Character Similarity with Vision Transformers (https://aclanthology.org/2023.emnlp-main.863/)
- Anthology ID: 2023.emnlp-main.863 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 레코드링크는 다른 소스로부터의 데이터를 연결해야하는 많은 사회과학 연구에 필수적이며, 현재 사용되고 있는 문자열 매칭 방법은 구현과 확장에 유리하지만 정확도가 저조하다. 
    2. 본 연구에서는 Vision Transformers (ViT)를 사용하여 OCR을 통해 생성된 문서들에서 문자 치환 비용을 측정하기 위한 기반 방법을 개발한다. 
    3. 모델은 보편적인 문자 유사도를 학습하고 자원이 제한된 상황에서도 적용 가능하며, 3,000년 전의 중국 고대 문자에 대한 유사도도 표현할 수 있다.

###### Syllogistic Reasoning for Legal Judgment Analysis (https://aclanthology.org/2023.emnlp-main.864/)
- Anthology ID: 2023.emnlp-main.864 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델(Large Language Models, LLMs)의 놀라운 발전으로 인해 법적 판단 보조 도구가 빠르게 발전하고 있지만, 신뢰할 수 있는 법적 판단 분석 결과없이 모델이 생성한 결과를 신뢰하기는 어렵다.
    2. 법적 판단 분석을 위해 법조 인지 연구자들은 논리주의 추론을 이용하여 소송 당사자의 주장을 선택하고 평가하는 것이 일반적이지만, 법적 판단 분석을 위한 논리주의 추론의 발전은 자원의 부족으로 인해 방해받고 있다.
    3. 이 논문에서는 법적 판단 분석을 위한 대규모 논리주의 추론 데이터셋을 구축하고, 대형 언어 모델을 벤치마크로 선택하여 그들의 법적 판단 분석 능력을 깊이 있는 분석을 수행한다.

###### Improving Transformer-based Program Repair Model through False Behavior Diagnosis (https://aclanthology.org/2023.emnlp-main.865/)
- Anthology ID: 2023.emnlp-main.865 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 딥러닝 모델을 활용한 자동 프로그램 복구에 대한 연구는 최근 큰 관심을 받고 있다. 그러나 현재 이 분야의 연구들은 모델의 잘못된 동작을 탐지하고 수정하는 것에 대한 조사가 부족하다.
    2. 이 논문에서는 transformer 기반의 프로그램 복구 모델의 잘못된 동작을 진단하고 수정하기 위한 방법론을 제안한다. 이를 위해 모델의 동작을 측정하는 행동 벡터, 잘못된 동작을 식별하는 행동 판별자 (BeDisc), 그리고 잘못된 동작을 수정하는 두 가지 방법을 제안한다.
    3. 대규모 실험을 통해 BeDisc는 86.6%의 불균형 정확도로 잘못된 동작을 분류할 수 있었으며, 첫 번째 처리 방법인 초기 중단은 60.4%의 잘못된 동작을 제거하면서 97.4%의 복구 정확도를 유지했고, 두 번째 처리 방법인 가림막 우회는 상위 1위 복구 정확도를 평균 40.5% 향상시켰다는 결과를 보였다. 이 실험 결과는 프로그램 복구 모델에서 잘못된 동작을 조사하는 것이 중요함을 보여준다.

###### SUT: Active Defects Probing for Transcompiler Models (https://aclanthology.org/2023.emnlp-main.866/)
- Anthology ID: 2023.emnlp-main.866 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자동 프로그램 번역의 현재 모델들은 여전히 기본적인 구문 오류를 범하는데, 특히 소스 언어에 없는 문법 요소가 있는 경우 더 많이 발생한다.
    2. 우리는 프로그래밍 언어 번역을 위한 BLUE, CodeBLUE, 연산 정확도와 같은 메트릭이 이러한 문제를 보여주지 못한다고 지적하고 새로운 메트릭을 도입한다.
    3. 우리는 정확성과 테스트 점수에 대한 해석 가능한 평가 메커니즘을 포함한 SUT(Syntactic Unit Tests)라는 새로운 활성 결함 접근 스위트를 개발하였고, 실험 결과로 ChatGPT와 같은 강력한 모델도 이러한 기본 유닛 테스트에서 실수를 저지른다는 것을 보여주었다.

###### KCTS: Knowledge-Constrained Tree Search Decoding with Token-Level Hallucination Detection (https://aclanthology.org/2023.emnlp-main.867/)
- Anthology ID: 2023.emnlp-main.867 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델은 인간 수준의 자연어 생성 능력을 보여주었으나, 그들이 잘못된 정보를 생성하는 문제인 '환각' 문제는 그들의 배치에 중대한 위험을 야기한다.
    2. 이 문제를 해결하기 위한 일반적인 방법은 관련 지식을 검색하고 해당 지식으로 언어 모델을 fine-tuning하는 것이다. 그러나 이 메서드는 훈련 비용이 매우 높으며, 멀티태스킹 모델에서 치명적인 잊어버림을 일으킬 수 있다.
    3. 이 논문에서는 지식 제약 디코딩 방법인 KCTS (Knowledge-Constrained Tree Search)를 제안한다. KCTS는 지식 분류기 점수와 MCTS (Monte-Carlo Tree Search)를 사용하여 언어 모델이 각 디코딩 단계에서 기준 지식과 일치하는 텍스트를 생성하도록 안내한다.

###### CRUSH4SQL: Collective Retrieval Using Schema Hallucination For Text2SQL (https://aclanthology.org/2023.emnlp-main.868/)
- Anthology ID: 2023.emnlp-main.868 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존 Text-to-SQL 생성기는 대화 내용에서 전체 스키마를 인코딩해야 하는데, 이는 열 천 개 이상의 컬럼을 가진 대형 데이터베이스에서는 고비용이거나 실용적이지 않다. 
    2. 논문에서는 효과적인 검색을 위해 두 단계로 진행되는 프로세스를 제안하고, LLM을 사용하여 쿼리에 대답할 충분한 후보 스키마를 생성하여 대량 검색 결과의 일부를 추출한다.
    3. 존재하지 않는 스키마 하위집합에 대한 벤치마크를 도입하고, 제안한 방법이 SOTA retrieval 기반 augmentation 방법보다 더 높은 recall을 달성한다는 것을 보여준다.

###### This Reads Like That: Deep Learning for Interpretable Natural Language Processing (https://aclanthology.org/2023.emnlp-main.869/)
- Anthology ID: 2023.emnlp-main.869 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 프로토타입 학습은 해석 가능한 결정을 위한 머신 러닝 방법으로, 새로운 데이터를 분류하기 위해 학습된 프로토타입과의 유사성을 활용한다. 이 논문은 컴퓨터 비전에 주로 적용되던 프로토타입 네트워크를 자연어 처리에 확장하는 것을 제안한다.
    2. 우리는 사전 학습된 문장 임베딩의 정보적인 차원에 초점을 맞춘 가중 유사도 측정을 도입하여 유사성 계산을 개선하는 방법을 제안한다.
    3. 또한, 프로토타입과 입력 문장으로부터 예측에 관련 있는 단어를 추출하는 후처리 설명 기능을 제안하고, 이전의 프로토타입 기반 방법에 비해 예측 성능과 설명의 충실성을 향상시키는 것을 실험적으로 입증한다.

###### Incorporating Structured Representations into Pretrained Vision & Language Models Using Scene Graphs (https://aclanthology.org/2023.emnlp-main.870/)
- Anthology ID: 2023.emnlp-main.870 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 시각과 언어 모델(VLMs)은 다양한 과제에서 놀라운 제로샷 성능을 보여주었지만, 구성적인 장면 이해와 같은 측면을 전부 포착하기는 어렵다고 최근 연구들이 보여주었다.
    2. 시각적 측면에서는 "SG Component"를 이미지 트랜스포머에 도입하여 SG 정보를 예측하도록 학습하고, 텍스트 측면에서는 SG를 활용하여 장면의 다양한 구성 요소를 강조하는 미세한 캡션을 생성한다.
    3. 우리의 방법은 작은 SG 데이터셋에서도 사전 훈련된 VLMs의 구조적 이해를 향상시킬 수 있음을 보여주고, ZS 능력이 약간 감소하는 것 외에도 여러 인기 있는 VLMs의 성능을 향상시킨다.

###### TLM: Token-Level Masking for Transformers (https://aclanthology.org/2023.emnlp-main.871/)
- Anthology ID: 2023.emnlp-main.871 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Transformer 모델에서 attention mechanism을 상속 받은 structured dropout (attention dropout, DropHead 등) 방법들이 제안되었는데, 이 논문은 overfitting을 줄이기 위해 구조 수준이 아닌 token-level에서 regularization을 수행하기 위한 새로운 scheme을 제안한다.
    2. Token-Level Masking (TLM) training strategy를 제안하여 self-attention의 연결을 정규화하는데 효과적이고 구현하기 쉬운 두 가지 masking 기법을 개발하였다.
    3. TLM의 일반성과 효과성을 다양한 NLP task에서 평가한 결과, attention dropout과 DropHead에 비해 일관적으로 우수한 성능을 보이며, 예를 들어 GLUE에서 BERT-large와 함께 0.5 포인트 성능을 향상시켰다.

###### Addressing NER Annotation Noises with Uncertainty-Guided Tree-Structured CRFs (https://aclanthology.org/2023.emnlp-main.872/)
- Anthology ID: 2023.emnlp-main.872 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 실제 NER 데이터셋은 주석 오류, 일관성 부재, 주관적 표현으로 인해 소음이 많이 발생한다. 이러한 소음은 기존 지도 학습 방법에 대한 중대한 도전 과제를 제공한다.
    2. 우리는 NER에 대해 소음을 해결하기 위한 새로운 통합된 접근 방식을 제시한다. 우리의 방법은 NER을 구성 트리 구문 분석 문제로 간주하며, 불확실성 평가를 위해 트리 구조화된 CRFs를 활용한다.
    3. 네 개의 실제 데이터셋에 대한 광범위한 실험을 통해 우리의 모델이 부분적이고 잘못된 주석 오류를 해결하는 데 탁월한 성능을 보인다는 것을 입증한다. 특히, 90% 주석 소음이 있는 극단적인 시나리오에서도 우리의 모델은 뛰어난 성과를 보인다.

###### Hi Guys or Hi Folks? Benchmarking Gender-Neutral Machine Translation with the GeNTE Corpus (https://aclanthology.org/2023.emnlp-main.873/)
- Anthology ID: 2023.emnlp-main.873 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 특히 문법적 성별 언어로의 번역에서 성별 평등은 우리의 커뮤니케이션 방식에 내재되어 있으며, 기계 번역에서는 종종 남성 중심 및 성별 고정관념적인 표현을 사용하여 성별 불평등을 유지한다. 
    2. 우리의 연구는 포용적인 언어에 대한 요구를 해결하기 위해 영어에서 이탈리아어로의 성별 중립적인 번역에 집중하여, 이를 위한 벤치마크를 제안하고 자동 평가 방법을 탐구한다. 
    3. GeNTE라는 자연스러운, 양방향 테스트 세트를 소개하며, 기존 기준 기반 평가 접근 방식을 살펴보고 한계를 강조하고 성별 중립적인 번역을 평가하기에 더 적합한 비교용 없는 방법을 제안한다.

###### Multilingual Holistic Bias: Extending Descriptors and Patterns to Unveil Demographic Biases in Languages at Scale (https://aclanthology.org/2023.emnlp-main.874/)
- Anthology ID: 2023.emnlp-main.874 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "HolisticBias 데이터셋의 다국어 확장인 Multilingual HolisticBias를 소개한다. 이 데이터셋은 50개 언어에 걸쳐 분산된 20,459개의 문장으로 구성되어 있으며, 13개의 인구통계적 축으로 분류된다. Multilingual HolisticBias는 다양한 언어에서 인구통계적 불균형을 밝히고, 그에 대한 완화 방안을 정량화하는데 사용될 목적으로 만들어진다."
    2. "연구 결과, 영어로부터 다른 언어로의 번역은 남성을 인용했을 때 여성을 인용한 경우보다 평균적으로 8 spBLEU 더 우수한 번역 품질을 보인다. 그리고 XX-to-EN 방향으로, 소스 입력이 성별(남성 또는 여성)만 다른 경우 남성 번역이 여성 번역보다 평균 4 spBLEU 더 우수하다는 것을 비교 분석하였다."
    3. "문장을 공통 다국어 문장 표현 공간에 임베딩할 때 대부분의 언어에서 남성 번역이 영어 중립 문장에 대해 여성 번역보다 더 가깝다는 것을 확인하였다."

###### GlobalBench: A Benchmark for Global Progress in Natural Language Processing (https://aclanthology.org/2023.emnlp-main.875/)
- Anthology ID: 2023.emnlp-main.875 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어처리 시스템의 성능 차이는 리소스 할당의 불균형과 소수 언어에 대한 최적의 인센티브 부족으로 설명될 수 있다. 
    2. 이 논문에서는 이러한 문제를 해결하기 위해 모든 언어의 모든 NLP 데이터셋의 진행 상황을 동적으로 추적하는 GlobalBench를 소개한다. 
    3. GlobalBench는 정확성 뿐만 아니라 언어별 유용성과 균등성을 추적하여 언어 기술이 세계 인구에 어떻게 제공되고 있는지 다각도로 보여주며, 소수 언어에 집중한 연구 노력을 장려한다.

###### DetGPT: Detect What You Need via Reasoning (https://aclanthology.org/2023.emnlp-main.876/)
- Anthology ID: 2023.emnlp-main.876 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 컴퓨터 비전 분야에서는 대형 언어 모델의 발전으로 인해 상당한 발전이 있었다. 이 논문에서는 구체적인 객체 이름에 의존하는 기존 객체 검출 방법과는 달리, 우리의 접근법은 자연어 지시문을 사용하여 시스템과 상호작용할 수 있는 "추론 기반 객체 검출"이라는 새로운 패러다임을 제안하고 있다.
    2. 제안된 방법은 사용자의 지시문과 시각적인 장면의 문맥 내에서 추론을 수행하고, 개방 어휘 객체 검출기를 활용하여 관심 대상을 자동으로 찾을 수 있다. 예를 들어, 사용자가 "차가운 음료수"를 원한다고 표현하면, DetGPT는 이미지를 분석하여 냉장고를 식별하고, 일반적인 냉장고 내용에 대한 지식을 활용하여 음료수의 위치를 찾을 수 있다.
    3. 이러한 유연성은 로봇공학, 자동화, 자율주행 등 다양한 분야에 적용 가능한 시스템을 만들 수 있게 한다. 저자들은 제안된 패러다임과 DetGPT가 더 정교하고 직관적인 인간-기계 상호작용의 잠재력을 보여준다고 말하며, 이를 통해 더 다양하고 상호작용적인 객체 검출 시스템을 개발할 수 있는 방향으로 기여할 것을 희망한다.

###### Language Models with Rationality (https://aclanthology.org/2023.emnlp-main.877/)
- Anthology ID: 2023.emnlp-main.877 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 큰 언어 모델(Large Language Models, LLM)은 문제해결 능력은 있으나, 내재된 "신념(beliefs)"이 답과 어떻게 연결되는지는 항상 명확하지 않다. 이러한 해석의 부재는 LLM의 보편적 사용에 방해가 된다. 
    2. 이 논문에서는 모델의 신념과 추론적 관계를 명시화하고, 모순을 해결하여 일관된 신념 네트워크에서 따라야 하는 해설 체인(chain-of-thought)을 통해 답을 지원한다. 
    3. REFLEX(Rational, Self-Reflecting Layer)라고 불리는 우리의 방법론은 LLM 위에 합리적이고 자기 반성적인 계층을 추가함으로써 모델 신념을 명확히 하고 모순을 해결한다. 이로써 일관된 신념 체계에서 온전한 해설 체인을 통해 지원되는 답을 도출한다.

###### Self-Improvement of Non-autoregressive Model via Sequence-Level Distillation (https://aclanthology.org/2023.emnlp-main.878/)
- Anthology ID: 2023.emnlp-main.878 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Non-autoregressive Transformer (NAT) 모델은 빠른 추론 속도를 가지고 있지만, NAT 모델의 본질적인 다중성(multi-modality) 문제 때문에 성능이 저하된다."
    2. "기존 작업들은 이 문제를 해결하기 위해 Autoregressive Transformer (AT) 모델이 생성한 압축된 데이터로 원시 데이터의 타겟을 대체하는 것으로 흔히 개선한다."
    3. "이 논문에서는 NAT 모델 자체에 의해 압축된 데이터를 생성하는 Sequence-Level Self-Distillation (SLSD) 방법을 제안한다. 이 방법은 추가적인 교사 네트워크를 필요로하지 않고, 같은 유형의 NAT 모델에서 생성된 자기압축 데이터를 사용하여 다른 NAT 모델에 적용할 수 있다."

###### Mitigating Temporal Misalignment by Discarding Outdated Facts (https://aclanthology.org/2023.emnlp-main.879/)
- Anthology ID: 2023.emnlp-main.879 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델은 사전 훈련 중 보았던 방대한 정보를 유지할 수 있지만, 이러한 지식이 날이 지나 황폐해질 수 있으며 업데이트하기 어렵다. 
    2. 따라서 우리는 지식이 얼마동안 유효할지 예측하는 FDP (Fact Duration Prediction)를 제안하여 모델이 구식 정보를 말하는 것을 피하고 최신 지식을 찾아야 하는 예측을 할 수 있도록 했다.
    3. 또한, 우리는 Fact Duration 모델링이 업계에서 핵심적인 임무를 담당하는 지식 기반 작업에서 보정을 향상시키는 것을 실험을 통해 보여주었다.

###### Open-world Semi-supervised Generalized Relation Discovery Aligned in a Real-world Setting (https://aclanthology.org/2023.emnlp-main.880/)
- Anthology ID: 2023.emnlp-main.880 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 관심을 받는 Open-world Relation Extraction (OpenRE)은, 기존 접근법에서는 미분류된 데이터의 모든 인스턴스가 새로운 클래스에 속한다고 가정하여 실용성을 제한하는 경향이 있다.
    2. 우리는 OpenRE 설정이 실제 데이터의 특성과 더 일치하도록해야한다고 주장한다. 
    3. 이를 위해 우리는 KNoRD라는 방법을 제안하는데, 이는 미분류 데이터에서 암묵적 및 명시적으로 표현된 관계를 효과적으로 분류하는것에 대해 알려준다.

###### IEKG: A Commonsense Knowledge Graph for Idiomatic Expressions (https://aclanthology.org/2023.emnlp-main.881/)
- Anthology ID: 2023.emnlp-main.881 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존 연구들은 대용어 표현 (IE)을 이해하기 위해 PTLMs에 대용어를 포함한 문장으로 fine-tuning을 하는 것이었지만, 이 논문에서는 IEs의 비유적 해석을 위한 일반 상식 지식 그래프인 IEKG를 구축하여 PTLMs를 지식 모델로 변환한다.
    2. 실험 결과들은 다양한 PTLMs가 IEKG로 KM로 변환될 수 있다는 것을 보여준다. IEKG의 품질과 훈련된 KMs의 능력은 자동 및 인간 평가를 통해 검증된다. 
    3. 자연어 이해 애플리케이션을 통해 PTLM에 IEKG의 지식을 주입하면 IE 이해 능력이 향상되고 훈련 중에 보지 못한 IEs에 대해서도 일반화할 수 있음을 보여준다.

###### Bias Neutralization in Non-Parallel Texts: A Cyclic Approach with Auxiliary Guidance (https://aclanthology.org/2023.emnlp-main.882/)
- Anthology ID: 2023.emnlp-main.882 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Wikipedia와 많은 뉴스 사이트에 적용되고 있는 객관성은 많은 대형 언어 모델들의 가이드라인이자 목표다. 하지만, 기존 방법들은 평행 텍스트(편향된 문장과 편향이 없는 문장)을 훈련 데이터로 사용하며 새로운 도메인으로의 전이 성능이 좋지 않으며 중요한 편향 독립적 문맥을 잃을 수 있다.
    2. 이 논문에서는 새로운 접근인 FairBalance을 제안하는데, 이는 평행 텍스트 없이 편향 중립화를 가능하게 하는 사이클 일관성 적대 신경망을 사용하며, 모델 디자인은 편향 독립적인 콘텐츠를 보존하고, 부가적인 가이드를 통해 편향 유발 단어의 열을 강조해서 편향 중립화 품질을 향상시킨다.
    3. 다양한 실험 결과는 FairBalance가 다른 방법에 비해 주관적 편향 중립화를 크게 개선하는 것을 보여준다.

###### Fighting Fire with Fire: The Dual Role of LLMs in Crafting and Detecting Elusive Disinformation (https://aclanthology.org/2023.emnlp-main.883/)
- Anthology ID: 2023.emnlp-main.883 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 대규모 언어 모델 (LLM)은 큰 영향력을 가지고 있지만 악용 가능성에 대한 우려가 있다. 이 논문에서는 "파이어(Fire)로 불(Fire)을 끄는" 전략을 제안하여 사람이 작성하거나 LLM이 생성한 잘못된 정보에 맞서는 방법을 제시한다.
    2. 먼저, GPT-3.5-turbo를 사용하여 진실과 위조된 LLM 생성 콘텐츠를 만든다. 그런 다음 cloze-style prompt에 zero-shot in-context semantic reasoning 기법을 적용하여 진실과 위조된 게시글 및 뉴스 기사를 구분한다.
    3. 실험에서는 GPT-3.5-turbo가 이전의 맞춤형 및 fine-tuned 디스인포메이션 탐지기에서 관찰된 감소와 달리 in-distribution 및 out-of-distribution 데이터셋에서 일관적으로 68-72%의 정확도를 달성하는 것을 관찰했다.

###### SMoP: Towards Efficient and Effective Prompt Tuning with Sparse Mixture-of-Prompts (https://aclanthology.org/2023.emnlp-main.884/)
- Anthology ID: 2023.emnlp-main.884 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존 방법과 달리 SMoP는 짧은 소프트 프롬프를 사용하여 효율적인 학습과 추론을 할 수 있으며, 성능의 향상을 유지한다.
    2. SMoP는 다양한 데이터 하위 집합을 처리하는 여러 개의 짧은 소프트 프롬프를 학습하는 게이팅 메커니즘을 사용한다.
    3. 실험 결과, SMoP는 기준선 방법보다 더 나은 성능을 보여주며, 학습 및 추론 비용을 줄일 수 있다.

###### BRAINTEASER: Lateral Thinking Puzzles for Large Language Models (https://aclanthology.org/2023.emnlp-main.885/)
- Anthology ID: 2023.emnlp-main.885 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어 모델들의 성공은 NLP 커뮤니티에서 인공지능적인 상식 기능을 필요로 하는 작업에 대한 관심을 끌었지만, 전형적인 상식 연관성과 다른 논리를 요구하는 문제인 lateral thinking puzzles은 아직 관심을 받지 못하고 있다.
    2. 본 논문에서는 lateral thinking 역량과 상식 연관성을 파악하는 BrainTeaser라는 다중선택형 QA 과제를 개발하였다.
    3. 실험 결과 instruction 모델과 상식 모델 모두 인간의 성능과 큰 차이를 보였으며, adversarial format에 대한 일관성을 고려했을 때 차이가 더욱 컸다는 것을 보여주었다.

###### When are Lemons Purple? The Concept Association Bias of Vision-Language Models (https://aclanthology.org/2023.emnlp-main.886/)
- Anthology ID: 2023.emnlp-main.886 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 비전-언어 모델인 CLIP과 같은 모델들은 영상 분류와 이미지-텍스트 검색에서 탁월한 성능을 보이지만, 더 세부적인 영상-언어 대응이 필요한 Visual Question Answering (VQA)와 같은 태스크에서는 성능이 나오지 않는다. 
    2. 이 논문에서는 이러한 이유에 대해 연구하고, 모델들이 보이는 Concept Association Bias (CAB)라는 현상을 VQA에 적용하는데 어려움을 일으키는 원인으로 제시한다. 
    3. CAB는 모델이 입력을 개념들의 모음으로 취급하고, 다른 부족한 개념을 모드간적으로 채우려고 시도하여 예상치 못한 zero-shot 예측을 만들어내는 경향을 가진다는 것을 실험을 통해 보여준다.

###### What Comes Next? Evaluating Uncertainty in Neural Text Generators Against Human Production Variability (https://aclanthology.org/2023.emnlp-main.887/)
- Anthology ID: 2023.emnlp-main.887 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 생성(NLG) 과제에서는 어떤 입력에 대해 여러 의사소통 목표가 가능하며, 각 목표는 다양한 방식으로 단어로 표현될 수 있다. 이 논문에서는 인간의 생성변이를 데이터 불확실성과 연결하여 분석하고, 생성 시스템의 불확실성을 조사하기 위해 예측된 확률 분포와 디코딩 알고리즘에 기반한 출력 문자열 공간을 조사한다. 
    2. 테스트 입력에 대해, 생성자의 다양성에 대한 맞춤법을 측정하여 NLG 모델과 디코딩 전략을 분석한다. 
    3. 이를 통해, 여러 샘플과 가능한 경우 다중 참조를 통해 생성자를 검사함으로써 모델의 불확실성 표현에 대한 이해 수준을 증가시킬 수 있다는 것을 보여준다.

###### Text Representation Distillation via Information Bottleneck Principle (https://aclanthology.org/2023.emnlp-main.888/)
- Anthology ID: 2023.emnlp-main.888 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 사전 훈련 언어 모델(PLM)은 텍스트 표현 분야에서 큰 성공을 보였으나, 컴퓨팅 비용과 고차원 표현의 문제로 실제 적용에 있어서 중요한 도전 과제가 되고 있다.
    2. 이 논문에서는 큰 모델을 작은 표현 모델로 전달하는 효과적인 방법인 지식 전달 (Knowledge Distillation) 기법인 IBKD를 제안한다.
    3. IBKD는 정보 병목 (Information Bottleneck) 원리에서 영감을 받아, 선생 모델과 학생 모델 간의 최종 표현 간 상호 정보량을 최대화하고, 동시에 학생 모델의 표현과 입력 데이터 간의 상호 정보량을 감소시키는 것을 목표로 한다. 이를 통해, 학생 모델은 중요한 학습 정보를 보존하면서 불필요한 정보를 피하므로 과적합의 위험을 줄일 수 있다.

###### Let GPT be a Math Tutor: Teaching Math Word Problem Solvers with Customized Exercise Generation (https://aclanthology.org/2023.emnlp-main.889/)
- Anthology ID: 2023.emnlp-main.889 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문에서는 대규모 언어 모델에서(math word problem solving capabilities) 학생 모델로 양자화하는 새로운 접근방식을 제시한다. 
    2. 우리의 접근 방식은 학생 모델의 약점을 고려하여 맞춤형 학습 경험을 제공하기 위해 교육 과학 원리(지식 추적, 맞춤형 학습)와 일치하는 목표 중심의 문제들을 생성하는 방식으로 설계되었다. 
    3. 실험 결과는 우리의 방법이 LLMs (예: GPT-3와 PaLM)보다 정확성에서 훨씬 우수한 성능을 보이며, 매우 적은 파라미터를 사용한다는 것을 나타내고 있다. 또한, 우리의 방법론 내의 다양한 구성 요소들의 효능을 입증하기 위해 포괄적인 분석을 제공한다.

###### FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions (https://aclanthology.org/2023.emnlp-main.890/)
- Anthology ID: 2023.emnlp-main.890 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Theory of mind (ToM) 평가는 현재 상호작용성이 없는 이야기를 사용하여 모델을 테스트하는 것에 초점을 맞추고 있다.
    2. 우리는 정보 불균형 대화적 맥락에서 질문에 답변하는 것을 통해 ToM을 엄격하게 테스트하는 새로운 벤치마크인 FANToM을 소개한다.
    3. 우리는 FANToM이 최신 LLMs에 대해 도전적인 것을 보여주고, 순차적 추론 또는 파인튜닝에도 인간보다 성능이 현저히 떨어진다.

###### Exploring the Boundaries of GPT-4 in Radiology (https://aclanthology.org/2023.emnlp-main.891/)
- Anthology ID: 2023.emnlp-main.891 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 큰 규모 언어 모델 (LLM)의 성공은 도메인과 응용 분야에 걸친 통합적인 기반 모델로 자연어 처리 패러다임을 크게 변경하였다. 본 논문에서는 GPT-4, 지금까지 가장 강력한 LLM,를 방사선학 보고서를 기반으로 하는 텍스트 기반 응용 애플리케이션에서 최신의 방사선학 전용 모델과 성능을 비교하여 평가한다. 
    2. 다양한 프롬프트 전략을 탐구하고, GPT-4를 다양한 방사선학 작업에 대해 평가한 결과, GPT-4는 현재의 최고 방사선학 모델과 비교하여 우수한 성능을 보여주거나 동등한 성능을 보여준다.
    3. GPT-4는 방사선학에 대한 지식 수준이 충분하며, 복잡한 문맥에서 세세한 도메인 지식이 필요한 경우에 가끔씩 오류가 발생한다는, 인증된 방사선과사의와의 광범위한 오류 분석을 통해 보인다.

###### A Frustratingly Easy Post-Training Quantization Scheme for LLMs (https://aclanthology.org/2023.emnlp-main.892/)
- Anthology ID: 2023.emnlp-main.892 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델을 포함한 대규모 인공지능 모델에서 효율적인 추론은 성능을 향상시키기 위해 매개변수 수가 계속 증가함에 따라 중요해졌다. 
    2. 본 논문에서는 메모리 및 컴퓨팅 병목 현상을 해결함으로써, 인퍼런스 중에 계산 부담을 완화하기 위한 양자화 방법을 제안한다. 줄어든 비트 수로 모델을 표현하면서, DRAM 액세스 빈도를 최소화하고 밀도 높은 행렬 형식을 통해 연산 병렬성을 완전히 활용하여 양자화된 모델은 엔드 투 엔드 지연 시간을 낮추고 자원 활용을 최적화한다. 
    3. Z-Fold라고 불리는 단순한 사후 학습 양자화 방법을 제안한다. 이 방법은 대규모 언어 모델에서 널리 사용되는 Transformer 구조의 특징을 완전히 활용한다.

###### A Comprehensive Evaluation of Biomedical Entity Linking Models (https://aclanthology.org/2023.emnlp-main.893/)
- Anthology ID: 2023.emnlp-main.893 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 바이오 의학 entity linking(BioEL)은 문서에 언급된 entity를 UMLS나 MeSH와 같은 의학 데이터베이스의 항목에 연결하는 과정이다. 
    2. 이 연구에서는 최근 9가지 최첨단 biomedical entity linking 모델을 통합된 프레임워크 아래에서 포괄적으로 평가하였다. 
    3. 평가 결과, 현재의 방법들은 유전자와 단백질을 올바르게 연결하는 데 어려움이 있으며, 맥락을 링크 결정에 효과적으로 통합하는 데 어려움이 있는 것으로 나타났다.

###### Exploring Jiu-Jitsu Argumentation for Writing Peer Review Rebuttals (https://aclanthology.org/2023.emnlp-main.894/)
- Anthology ID: 2023.emnlp-main.894 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 문제의 핵심은 심층모델들이 surface-level 추론을 반박하는 대신에 underlying beliefs와 world views에 기반한 "attitude roots"와 "attitude themes"를 파악하여 대응하는 것이 더 효과적일 수 있다는 것이다.
    2. 이 논문은 Jiu-Jitsu와 마찬가지로 기존의 논리를 무효화시키는 대신에 상대방의 태도와 테마를 파악하고 그에 알맞은 반박을 선택하는 Jiu-Jitsu argumentation을 사용하여 "attitude and theme-guided rebuttal generation"을 소개한다.
    3. 기존의 피어 리뷰 데이터셋에 attitude roots, attitude themes, 및 canonical rebuttals을 추가하여 end-to-end attitude and theme-guided rebuttal generation 및 두 가지 하위 태스크의 성능을 평가한다.

###### LIMIT: Language Identification, Misidentification, and Translation using Hierarchical Models in 350+ Languages (https://aclanthology.org/2023.emnlp-main.895/)
- Anthology ID: 2023.emnlp-main.895 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. NLP 태스크에 대한 deep model의 정확성은 뛰어나지만, spurious pattern에 의존하는 한계로 인해 robustness가 제한된다고 보고되고 있다. 
    2. 기존의 데이터 증강 기법들은 spurious correlation에 영향을 받는다는 문제가 있는데, 이 논문에서는 "여러 개"의 counterfactual을 생성하여 더 robust한 supervision을 제공함으로써 매우 다양한 영역에서 성능을 개선할 수 있는 방법을 제안한다. 
    3. MCS-350 데이터셋을 통해 저자들은 언어 탐지를 위한 새로운 hierarchical model인 LIMIT을 제안하고, 이 모델은 오류를 55% (from 0.71 to 0.32) 개선하는 동시에 저자들의 새로운 benchmark인 FLORES-200에서도 40% (from 0.23 to 0.14) 개선하는 결과를 보였다.

###### FreeAL: Towards Human-Free Active Learning in the Era of Large Language Models (https://aclanthology.org/2023.emnlp-main.896/)
- Anthology ID: 2023.emnlp-main.896 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다양한 NLP 태스크에 대한 고품질 레이블된 데이터 수집은 시간과 노력이 많이 드는 작업이다. 본 연구에서는 큰 언어 모델 (LLM) 시대에서 어노테이션 비용을 감소시키는 방법을 탐구한다.
    2. FreeAL이라는 혁신적인 협력 학습 프레임워크를 제안하여 LLM으로부터 태스크별 지식을 상호작용적으로 추출하고 걸러낸다.
    3. 다양한 실험 결과에서 FreeAL은 인간의 감독 없이 SLM과 LLM의 제로샷 성능을 크게 향상시킴을 보여준다.

###### API-Assisted Code Generation for Question Answering on Varied Table Structures (https://aclanthology.org/2023.emnlp-main.897/)
- Anthology ID: 2023.emnlp-main.897 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 테이블 기반 질의응답 (TableQA)에서의 실행 가능한 프로그램 생성은 다양한 테이블 구조에 대한 적응이 어려운 문제였으나, 본 논문에서는 (1) Pandas 데이터 프레임을 다중 인덱스로 표현하는 통합 테이블QA 프레임워크, (2) 강력한 질의 언어로써의 Python, 그리고 (3) NL 질문을 Pandas 데이터 프레임에서 실행 가능한 Python 프로그램으로 변환하기 위한 few-shot prompting을 제안한다.
    2. 또한, 복잡한 관계형 질문에 대한 응답을 위해, 우리의 프레임워크는 Python 프로그램에서 호출할 수 있는 사용자 정의 API를 허용한다. 
    3. 본 논문에서는 관계형, 다중 테이블, 계층적 행렬 형태의 테이블을 다루는 네 가지 TableQA 데이터셋으로 실험을 수행하였고, 과거 최고 수준 시스템보다 뛰어난 성능 향상을 얻었다.

###### Data Factors for Better Compositional Generalization (https://aclanthology.org/2023.emnlp-main.898/)
- Anthology ID: 2023.emnlp-main.898 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 진단용 데이터 세트인 SCAN과 COGS는 scratch로 학습된 모델의 성능이 매우 낮음을 보여주고 있다. 그러나 더 크고 일반적인 데이터 세트에서 학습된 최신 모델들은 더 나은 일반화 능력을 보여준다. 
    2. 본 논문에서는 이런 모순을 해소하기 위해 데이터 세트의 규모, 패턴 복잡성, 예제 난이도 등 다양한 데이터 요소를 가진 Transformer 모델들을 학습시켜 실증적 분석을 수행한다. 
    3. 이를 통해 데이터 세트의 복잡성이 여러 다른 일반화 도전 과제에 대해 더 나은 일반화 성능을 보여주는 것을 발견하고, 단어 관계를 더 효과적으로 이해할 수 있도록 더 다양한 예제를 제공하고 예제 반복 빈도를 감소시켜 일반화 능력을 향상시킨다는 것을 알아내었다.

###### ChatEdit: Towards Multi-turn Interactive Facial Image Editing via Dialogue (https://aclanthology.org/2023.emnlp-main.899/)
- Anthology ID: 2023.emnlp-main.899 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 대화를 통한 얼굴 이미지 편집을 탐구하며, ChatEdit 벤치마크 데이터셋을 제공하여 이 문맥에서의 이미지 편집과 대화 능력을 평가한다. 
    2. ChatEdit는 CelebA-HQ 데이터셋을 기반으로 구축되었으며, 이미지에 대한 사용자 편집 요청에 대응하는 다중 턴 대화를 포함하고 있다. 
    3. 우리는 사용자 요청을 추적하고 응답을 생성하기 위한 대화 모듈과 이미지를 해당 요청에 맞게 편집하기 위한 이미지 편집 모듈로 구성된 프레임워크를 제안하며, 기존의 방식과 달리 에러 적립 및 속성 잊기 문제를 완화하기 위해 이전 턴의 출력을 조작하는 대신 전체 대화 기록에서 현재 턴의 사용자 요청을 직접 추적하고 초기 이미지를 편집한다.

###### Bridging Continuous and Discrete Spaces: Interpretable Sentence Representation Learning via Compositional Operations (https://aclanthology.org/2023.emnlp-main.900/)
- Anthology ID: 2023.emnlp-main.900 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 문장 임베딩 모델은 문장의 의미 유사도와 같은 유용한 속성을 캡처하기 위해 문장을 벡터 표현으로 인코딩하지만, 문장의 구성적 의미는 문장 유사도 외에도 문장 융합 또는 차이와 같은 구성 작업을 통해 해석될 수 있다. 
    2. 이 연구에서는 구성적인 문장 의미가 임베딩 공간에서 구성적인 작업으로 직접 반영될 수 있는지 조사한다. 
    3. 우리는 문장 임베딩 공간에서 구성적인 문장 작업을 지원하는 해석 가능한 문장 임베딩을 학습하기 위한 end-to-end 프레임워크인 InterSent를 제안한다.

###### Outlier Dimensions Encode Task Specific Knowledge (https://aclanthology.org/2023.emnlp-main.901/)
- Anthology ID: 2023.emnlp-main.901 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델(Large Language Model, LLM)의 표현은 소수의 차원이 지나치게 높은 분산으로 지배된다고 알려져 있다. 
    2. 우리는 fine-tuning이 outlier dimensions에 어떤 영향을 미치는지 조사하였고, 1) pre-training에서 발생한 outlier dimensions가 fine-tuned 모델에서도 지속되며 2) 단일 outlier dimension이 downstream tasks을 최소 오류율로 완료할 수 있음을 보였다. 
    3. 우리의 결과는 outlier dimensions이 중요한 task-specific knowledge를 인코딩할 수도 있으며, downstream 모델의 결정에는 단일 outlier dimension의 표현 값이 영향을 미칠 수 있다는 것을 시사한다.

###### Hi-ArG: Exploring the Integration of Hierarchical Argumentation Graphs in Language Pretraining (https://aclanthology.org/2023.emnlp-main.902/)
- Anthology ID: 2023.emnlp-main.902 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 지식 그래프는 지식을 저장하고 표현하는 구조이며, 최근의 연구들은 이를 언어 모델의 다양한 응용에 도움을 주는 능력에 대해 논의하고 있다.
    2. 해당 논문에서는 텍스트-그래프 멀티모달 모델 GreaseArG와 그래프 정보를 사용한 새로운 pre-training 프레임워크를 소개하며, 그래프를 활용하는 두 가지 접근 방식을 제안한다.
    3. 실험 결과, GreaseArG는 동일 규모의 언어 모델보다 이러한 태스크에서 뛰어난 성능을 보이며, 그래프 정보를 추가적인 pre-training 동안 사용하는 것은 기본 언어 모델의 성능을 개선할 수 있다는 것을 보여준다.

###### Biomedical Named Entity Recognition via Dictionary-based Synonym Generalization (https://aclanthology.org/2023.emnlp-main.903/)
- Anthology ID: 2023.emnlp-main.903 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 바이오 의학 자연어 처리에서 생체명 개체 인식은 핵심 과제 중 하나이다. 이 논문은 개체 인식을 위해 사전 기반 접근 방법을 제안하며, 이러한 방법은 주어진 사전을 기반으로 개체를 추출한다. 그러나 기존의 사전 기반 접근 방법은 주어진 사전에 나열되지 않은 동의어를 식별하는 데 어려움이 있다. 
    
    2. 본 연구에서는 입력 텍스트에 포함된 의학 개념을 스팬 기반 예측을 사용하여 인식하기 위한 SynGen 프레임워크를 제안한다. 이 방법은 동의어 일반화 오류를 최소화하기 위해 (1) 동의어 거리 조절자와 (2) 노이즈 개입 조절자라는 두 가지 규제항을 도입한다. 
    
    3. 실험 결과를 통해 SynGen이 이전의 사전 기반 모델보다 뛰어난 성능을 보여주고, 동의어 일반화 오류의 한계를 상세히 분석하였다.

###### GNAT: A General Narrative Alignment Tool (https://aclanthology.org/2023.emnlp-main.904/)
- Anthology ID: 2023.emnlp-main.904 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 알고리즘적 시퀀스 정렬은 문서 쌍 사이에서 공유되는 유사한 세그먼트를 식별하며, 많은 NLP 태스크에서 기본적인 역할을 한다. 하지만 번역이나 서술의 서로 먼 버전과 같은 내러티브 사이의 유사성을 인식하는 것은 어렵다. 특히 요약본과 축약본은 원래 소설보다 훨씬 짧은 길이이기 때문이다.
    2. 우리는 생물 정보학에서의 Smith-Waterman 알고리즘과 현대적인 텍스트 유사성 메트릭을 결합하는 일반적인 내러티브 정렬 접근법을 개발했다. 우리는 정렬 점수의 배경이 Gumbel 분포에 맞아 매칭의 유의성에 대한 엄격한 p-값을 정의할 수 있도록 한다.
    3. 우리는 요약과 책 정렬, 번역된 책 정렬, 짧은 이야기 정렬, 그리고 표절 감지라는 서로 다른 길이의 문서를 가진 네 개의 문제 도메인에서 일반적인 내러티브 정렬 도구(GNAT)를 적용하고 평가하여 우리의 방법의 성능과 효과를 입증하였다.

###### Self-Ensemble of N-best Generation Hypotheses by Lexically Constrained Decoding (https://aclanthology.org/2023.emnlp-main.905/)
- Anthology ID: 2023.emnlp-main.905 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 생성을 개선하기 위해 N-best 가설을 앙상블하는 방법을 제안하였다. 기존의 연구들은 N-best 후보들을 명시적으로 재정렬하여 생성 품질을 향상시키는데 성공하였다. 하지만 이러한 연구들은 더 높은 품질의 가설이 존재한다고 가정한다. 
    2. 우리는 이 가정을 보다 실용적으로 확장하여 N-best 내에서 부분적으로 더 높은 품질의 가설이 존재하지만 전체 문장은 완벽하지 않을 수 있다고 가정했다. 
    3. 이 논문에서는 이러한 높은 품질의 조각들을 결합하여 단일 최고 품질의 문장보다 더 높은 품질의 출력을 얻을 수 있다고 제안하고, 이를 위해 N-best 가설을 얻고 토큰 수준의 품질 평가를 수행하였다. 그리고 최종 출력에 포함되어야 할 토큰과 포함되지 말아야 할 토큰을 디코딩 과정에서 어휘 제약으로 적용하였다.

###### UniChart: A Universal Vision-language Pretrained Model for Chart Comprehension and Reasoning (https://aclanthology.org/2023.emnlp-main.906/)
- Anthology ID: 2023.emnlp-main.906 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 차트는 복잡한 데이터를 시각적으로 표현하고 해석하는 데 널리 사용되지만, 자연어를 사용한 차트 기반 데이터 분석을 위한 기존 방법들은 차트 구조를 명시적으로 모델링하지 않고 언어나 시각-언어 태스크에 대해 사전 학습에 의존하고 있다.
    2. 이 논문에서는 다양한 주제와 시각 스타일을 포함하는 큰 규모의 차트 코퍼스를 구축하고, 차트 이해와 추론을 위한 사전 훈련 모델 UniChart를 제안한다.
    3. UniChart는 차트의 관련 텍스트, 데이터 및 시각 요소를 인코딩하고, 차트에 기반한 텍스트 생성을 위해 차트-기반 텍스트 디코더를 사용한다. 사전 훈련된 UniChart는 다양한 하위 태스크에서 최고의 성능을 보이며, 이전 방법보다 뛰어난 일반화 능력을 가지고 있다.

###### Merging Experts into One: Improving Computational Efficiency of Mixture of Experts (https://aclanthology.org/2023.emnlp-main.907/)
- Anthology ID: 2023.emnlp-main.907 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어 모델의 크기를 확장하면 NLP 태스크에서 혁신적인 발전이 있을 수 있지만, 이는 컴퓨팅 비용이 증가하는 대가와 함께 온다. 
    2. 이 논문에서는 여러 개의 전문가 중에서 하나의 전문가를 활성화하여 계산 비용을 줄이는 Sparse Mixture of Experts (MoE) 방법을 제안한다. 
    3. 토큰 수준의 MEO의 효율성과 성능을 향상시키는 토큰 수준 어텐션 블록을 제안하며, 그러한 방법이 GLUE 벤치마크에서 최적의 성적을 보여주었다.

###### Distance-Based Propagation for Efficient Knowledge Graph Reasoning (https://aclanthology.org/2023.emnlp-main.908/)
- Anthology ID: 2023.emnlp-main.908 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 지식 그래프 완성은 (KGs)지식 그래프에서 보이지 않는 엣지를 예측하여 새로운 사실을 발견하는 것을 목표로 한다. 
    2. 최근에는 경로 정보를 집계하는 방법들이 제안되어 이 문제를 해결하고 있다. 그러나, 이러한 방법들은 효율성 문제로 시달리고 있다.
    3. 본 논문에서는 태그넷(TAGNet)을 소개하여 효율적인 정보 전파를 가능하게 한다. 다양한 KG 데이터셋에서 성능을 가져가면서 전달된 메시지 수를 90%까지 줄일 수 있음을 실험으로 입증하였다.

###### What to Read in a Contract? Party-Specific Summarization of Legal Obligations, Entitlements, and Prohibitions (https://aclanthology.org/2023.emnlp-main.909/)
- Anthology ID: 2023.emnlp-main.909 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 법적 계약서의 핵심 의무, 권리, 금지사항을 검토하고 이해하는 것은 계약서의 길이와 도메인 특수성으로 인해 지루한 작업일 수 있다.
    2. 이 논문에서는 당사자별 추출 요약(party-specific extractive summarization)을 통해 계약서의 의무와 권리를 빠르게 검토하고 이해를 돕는 새로운 작업을 제안한다.
    3. 이를 위해 임차계약서에서 추출된 의무, 권리 및 금지사항에 대한 파티별로 구성된 데이터셋을 사용하여 파티별 계약 요약을 생성한다.

###### Enhancing Computation Efficiency in Large Language Models through Weight and Activation Quantization (https://aclanthology.org/2023.emnlp-main.910/)
- Anthology ID: 2023.emnlp-main.910 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델(Large Language Models)은 자연어 처리 태스크에서 뛰어난 성능을 보이지만, 많은 파라미터와 연산량으로 인해 배포가 제한되는 경우가 많다.
    2. 본 논문은 4-bit weight와 8-bit activation(W4A8) 양자화를 통해 계산 효율성을 향상시키는 후처리 양자화(post-training quantization)에 초점을 맞추고 있다.
    3. AQAS와 SLAC 두 가지 혁신적인 방법을 제시하여 가중치와 활성화의 결합 효과를 고려하고, 보정 시퀀스 길이를 목표 작업에 맞추어 PTQ를 향상시키는 것을 보여준다.

###### CP-BCS: Binary Code Summarization Guided by Control Flow Graph and Pseudo Code (https://aclanthology.org/2023.emnlp-main.911/)
- Anthology ID: 2023.emnlp-main.911 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 바이너리 함수에 대한 요약문을 자동으로 생성하는 것은 매우 가치있는 작업이지만, 저수준 언어 (어셈블리 코드)의 실행 동작과 의미를 인간이 읽을 수 있는 자연어로 번역하는 것은 어려운 작업이다.
    2. 기존의 어셈블리 코드 이해 작업은 주로 함수 이름을 생성하는 것에 초점을 맞추어 왔지만, 여전히 혼동을 줄 수 있는 다양한 약어들을 포함하고 있어 이를 극복하기 위해 바이너리 함수에 대한 완전한 요약 생성에 초점을 맞춘다.
    3. CP-BCS라고 불리는 제안된 프레임워크는 제어 흐름 그래프와 의사 코드를 활용하여 전문가 지식을 통해 바이너리 함수의 실행 동작과 논리 의미를 포괄적으로 학습하고 이를 개선할 수 있다는 결과를 보여준다.

###### Assessing Step-by-Step Reasoning against Lexical Negation: A Case Study on Syllogism (https://aclanthology.org/2023.emnlp-main.912/)
- Anthology ID: 2023.emnlp-main.912 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델 (LLMs)은 CoT (chain-of-thought) 프롬프팅과 같은 단계별 추론 지시에 기초하여, 이러한 모델이 CoT 스타일 추론을 얼마나 강력하게 수행하는지 알아보는 것이 중요하다.
    2. 이 연구에서는 언어 모델의 단계별 추론 능력을 부정이라는 어려운 언어 현상에 초점을 맞춰 조사한다. 이를 위해 가상의 개체를 기준으로 많은 조절된 설정을 도입하여 모델의 논리적 추론 능력을 평가한다.
    3. 우리는 몇몇 최신 LLM들이 CoT 스타일 추론을 수행할 때 어휘적 부정 (예: possible→impossible)에 대해 강력하지 못하며, 결과는 각 LLM 패밀리마다 독특한 한계를 강조한다.

###### Chain-of-Thought Tuning: Masked Language Models can also Think Step By Step in Natural Language Understanding (https://aclanthology.org/2023.emnlp-main.913/)
- Anthology ID: 2023.emnlp-main.913 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Chain-of-Thought (CoT)은 Large Language Models (LLMs)가 복잡한 작업을 중간 단계의 자연어형식으로 멀티스텝 추론을 통해 단계적으로 풀 수 있도록 안내하는 기술이다. CoT는 LLMs이 단계별로 생각할 수 있게 한다. 하지만, 많은 Natural Language Understanding (NLU) 태스크에서도 단계별 생각이 필요하지만, LLMs는 소규모 Masked Language Models (MLMs)보다 성능이 낮다. 이 논문에서는 LLMs에서 MLMs로 CoT를 이전시키기 위해 prompt tuning에 기반한 two-step 추론 프레임워크인 Chain-of-Thought Tuning (CoTT)을 제안한다.
    2. CoT를 바탕으로 한 CoTT의 two-step 프레임워크는 MLMs가 작업 분해를 구현할 수 있게 해주고, prompt tuning을 통해 중간 단계가 자연어 형식으로 사용될 수 있다. 이를 통해 CoT의 성공을 MLMs을 통해 NLU 태스크로 확장할 수 있다.
    3. CoTT의 효과를 검증하기 위해 계층적 분류(hierarchical classification)와 관계 추출(relation extraction) 두 가지 NLU 태스크에서 실험을 수행하였으며, 결과는 CoTT가 기준 모델보다 우수한 성능을 달성하며 최첨단 수준의 성능을 보여준다.

###### Large Language Models are Complex Table Parsers (https://aclanthology.org/2023.emnlp-main.914/)
- Anthology ID: 2023.emnlp-main.914 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. GPT-3.5 기반의 일반적인 QA 작업에 중점을 둔 QA 연구들이 복잡한 테이블 QA의 독특한 도전 요소들을 간과하고 있다. 
    2. 이 논문에서는 복잡한 테이블 QA에 대응하기 위해 GPT-3.5를 활용하여 테이블을 튜플 형태로 재구성하고 대화형 프롬프트 디자인을 적용하는 방식을 제안한다. 
    3. 실험 결과, 우리의 접근 방식은 HiTAB와 AIT-QA라는 복잡한 테이블 QA 데이터셋에서 이전 연구에 비해 우월한 성능을 보여주며 SOTA 성능을 기록하였다.

###### R2H: Building Multimodal Navigation Helpers that Respond to Help Requests (https://aclanthology.org/2023.emnlp-main.915/)
- Anthology ID: 2023.emnlp-main.915 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인공지능 네비게이션 도우미 에이전트는 환경 인식과 대화 능력을 통해 사용자를 알 수 없는 지역에서 안내하는 데에 매우 중요하다. 이 연구에서는 기존의 다중 모달 대화 지향 임베디드 데이터셋을 활용하여 도움 요청에 응답할 수 있는 네비게이션 도우미 에이전트 개발을 촉진하기 위한 새로운 벤치마크인 R2H를 소개한다. 
    2. 이 R2H 벤치마크에는 대화 히스토리를 기반으로 정보성 있는 응답을 생성하는 능력을 평가하는 "Respond to Dialog History (RDH)"와 작업 수행자와의 일관된 협력 과정에서 응답의 효과성과 효율성을 평가하는 "Respond during Interaction (RdI)"라는 두 가지 작업이 포함되어 있다.
    3. 또한, "SeeRee"라고 명명된 시각적 정보를 볼 수 있고 응답할 수 있는 혁신적인 task-oriented 다중 모달 응답 생성 모델을 fine-tuning하거나, 제로샷 방식으로 다중 모달 대형 언어 모델을 사용하여 네비게이션 도우미 에이전트를 구축하는 두 가지 접근 방식에 대해 탐구했다. 이를 자동 벤치마크와 인간 평가를 기반으로 분석하였다.

###### Speech-enriched Memory for Inference-time Adaptation of ASR Models to Word Dictionaries (https://aclanthology.org/2023.emnlp-main.916/)
- Anthology ID: 2023.emnlp-main.916 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대부분의 시험에서 ASR 모델의 성능은 탁월하지만 희귀 단어에서는 만족스럽지 않다.
    2. 우리는 새로운 추론 알고리즘을 제안하여 특정 도메인의 용어와 일치시켜 ASR 모델의 예측을 개선한다.
    3. 우리의 실험에서는 희귀 단어 인식을 크게 개선할 수 있는 것으로 나타났다.

###### Generative Table Pre-training Empowers Models for Tabular Prediction (https://aclanthology.org/2023.emnlp-main.917/)
- Anthology ID: 2023.emnlp-main.917 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 table pre-training의 주제에는 상당한 연구 관심이 집중되고 있지만, table pre-training을 이용하여 태블라 예측의 성능을 향상시키는 방법은 여전히 열린 과제이다.
    2. 우리는 TapTap을 제안하여 table pre-training을 활용하고 처음으로 모델을 강화시켜 태블라 예측을 수행하는데 사용한다. 
    3. TapTap은 대량의 실제 세계 태블라 데이터로 사전 훈련을 수행한 후, 고품질의 합성 테이블을 생성하여 태블라 데이터와 관련된 다양한 응용 분야에서 사용할 수 있다.

###### Learning to Describe for Predicting Zero-shot Drug-Drug Interactions (https://aclanthology.org/2023.emnlp-main.918/)
- Anthology ID: 2023.emnlp-main.918 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 음용된 약의 상호작용(adverse drug-drug interactions, DDIs)은 동시 투약의 효과를 약화시켜 건강 관리에 큰 도전을 제기한다. 
    2. 기존 DDI 예측 방법은 새로운 약의 경계를 초과하는 경우 상호작용을 잡아내지 못할 수 있다. 
    3. 이 논문에서는 새로운 약에 대한 정확한 DDI 예측을 위해 DrugBank, PubChem과 같은 온라인 데이터베이스에서 얻은 텍스트 정보를 기반으로 TextDDI 접근법을 제안한다.

###### A Simple Baseline for Knowledge-Based Visual Question Answering (https://aclanthology.org/2023.emnlp-main.919/)
- Anthology ID: 2023.emnlp-main.919 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 연구들은 외부 데이터베이스와 LLM을 통해 명시적 지식과 암묵적 지식을 효과적으로 활용하여 외부 지식이 필요한 질문에 대답하는 것의 중요성을 강조하고 있다. 그러나 이러한 접근 방식은 복잡한 파이프라인으로 구성되어 GPT-3 API에 많이 의존한다는 단점이 있다.
    2. 본 논문의 주요 기여는 간단하고 재현성이 높은 파이프라인을 제안하는 것이다. 이 파이프라인은 질문에 관련된 캡션을 문맥 정보로 사용하는 효율적인 in-context learning에 기반한다.
    3. 우리의 방법은 훈련 과정이 필요 없으며 외부 데이터베이스나 API에 접근할 필요가 없지만, OK-VQA와 A-OK-VQA 데이터셋에서 최첨단 정확도를 달성한다.

###### Unveiling the Essence of Poetry: Introducing a Comprehensive Dataset and Benchmark for Poem Summarization (https://aclanthology.org/2023.emnlp-main.920/)
- Anthology ID: 2023.emnlp-main.920 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자연어 처리 분야의 연구는 창의적인 언어 생성에서 상당한 발전이 있었지만, 언어 모델이 창의적인 언어의 의도된 의미를 해석할 수 있는지에 대한 질문은 여전히 답이 없다.
    2. 시는 깊은 의미를 지니고 있기 때문에, 시의 요약은 단순한 문장의 의미만을 고려한다면 의도와 메시지를 잃어버릴 수 있기 때문에 도전적인 작업이다.
    3. 이 논문에서는 'Poem Summarization'이라는 자연어 이해 분야의 새로운 작업을 제안하고, 이 작업을 위한 첫 번째 데이터셋 'PoemSum'을 소개하며, 최신의 요약 모델들의 성능을 벤치마킹하고 그 한계점에 대해 관찰 결과를 제시한다.

###### Privacy Implications of Retrieval-Based Language Models (https://aclanthology.org/2023.emnlp-main.921/)
- Anthology ID: 2023.emnlp-main.921 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 검색 기반 언어 모델은 외부 데이터 스토어에서 검색된 텍스트를 통합함으로써 인터프리터블성, 사실성 및 적응성이 향상되었다. 그러나, 검색 기반 언어 모델이 개인 데이터 유출에 어떤 영향을 미치는지에 대해서는 여전히 불명확하다.  
    2. 이 논문에서는 개인 정보가 중요한 도메인에서 유용성과 개인정보 보호 사이의 균형을 찾기 위해 최적의 설계와 훈련 절차를 탐색하기 위한 개인 정보 유출의 초기 연구를 제시한다. 
    3. 실험 결과, kNN-LM은 개인 데이터 스토어로부터 개인 정보가 유출될 가능성이 파라메터 모델보다 크다는 것을 발견했으며, 개인 정보가 텍스트에서 명확하게 탐지될 때는 간단한 살균 단계만으로 위험성을 제거할 수 있다는 것을 알아냈다.

###### IMTLab: An Open-Source Platform for Building, Evaluating, and Diagnosing Interactive Machine Translation Systems (https://aclanthology.org/2023.emnlp-main.922/)
- Anthology ID: 2023.emnlp-main.922 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. IMTLab은 최신 모델을 이용하여 IMT 시스템을 빠르게 구축하고, 시스템의 약점을 진단할 수 있는 오픈 소스의 end-to-end 대화형 기계 번역(IMT) 시스템 플랫폼이다. 
    2. IMTLab은 전체 대화형 번역 과정을 인간이 참여하는 task-oriented 대화로 다루며, 고품질 및 오류없는 번역을 위해 인간의 개입을 명시적으로 포함할 수 있다. 
    3. 시뮬레이션 및 수동 실험을 통해 IMTLab을 활용하여 다른 IMT 시스템을 체계적으로 평가해 본 결과, BiTIIMT이 더 나은 대화 경험과 함께 수정 비용을 비슷하게 달성하는 반면, prefix-constrained decoding 방법이 end-to-end 평가에서 가장 낮은 편집 비용을 얻는다는 것을 알 수 있었다.

###### Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents (https://aclanthology.org/2023.emnlp-main.923/)
- Anthology ID: 2023.emnlp-main.923 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 LLM(대형 언어 모델)은 정보 검색(IR)에서 대체로 생성 기능을 활용하였으나, 본 논문에서는 기존 IR 벤치마크에서 최신 지식을 검색할 수 있는 능력을 검증하기 위한 새로운 테스트 세트인 NovelEval을 수집하였다.
    2. 또한, 실제 응용에서 효율성을 향상시키기 위해 ChatGPT의 순열 증류 방법을 사용하여 작고 특화된 모델로 ChatGPT의 순위 지정 능력을 전달하는 가능성을 탐구하였다.
    3. 만들어진 440M 순위 지정 모델은 3B 지도 모델보다 BEIR 벤치마크에서 우월한 결과를 보여주었다.

###### DiNeR: A Large Realistic Dataset for Evaluating Compositional Generalization (https://aclanthology.org/2023.emnlp-main.924/)
- Anthology ID: 2023.emnlp-main.924 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 구성적 일반화 데이터셋은 합성 생성으로 인해 자연어 다양성이 부족한 문제가 있다.
    2. 이 논문에서는 DiNeR(DIsh NamE Recognition) 과제를 제시하여 식품, 동작, 맛의 다양한 조합으로 이루어진 음식 이름을 인식하는 모델을 만들기 위한 중국어 데이터셋을 만들었다. 
    3. 이 작업은 구성적 일반화에 대한 힘든 과제와 이를 해결하기 위한 기준선 방법 및 음식 이름 인식의 문맥에서 구성적 일반화에 대한 통찰력을 제공한다.

###### Can Pre-trained Vision and Language Models Answer Visual Information-Seeking Questions? (https://aclanthology.org/2023.emnlp-main.925/)
- Anthology ID: 2023.emnlp-main.925 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사전 훈련된 비전 및 언어 모델은 시각적인 정보만으로 답변이 불가능하고 지식에 기반한 정보를 요구하는 질문에 대답할 수 있는 능력을 가지고 있는지 여전히 분명하지 않다.
    2. 이 연구에서는 공통 감각적 지식으로만 대답할 수 없는 정보 탐색을 위한 시각적인 질문에 대한 데이터셋인 InfoSeek를 소개한다.
    3. InfoSeek를 사용하여 다양한 사전 훈련된 시각적 질문 응답 모델을 분석하고, 성능을 향상시키기 위해 정확한 시각적 엔티티 인식을 활용하는 방법을 보여준다.

###### EDeR: Towards Understanding Dependency Relations Between Events (https://aclanthology.org/2023.emnlp-main.926/)
- Anthology ID: 2023.emnlp-main.926 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 관계 추출은 NLP와 IR에서 중요한 작업인데, 이전 연구는 이벤트 간의 계층, 시간 및 인과관계에 초점을 맞추었다. 그러나 이들은 문법과 의미론에서 이벤트가 독립적이라고 가정하기 때문에 이벤트 간의 상호 의존성을 인식하지 못한다.
    2. 이를 해결하기 위해 우리는 인간 주석으로 된 Event Dependency Relation 데이터셋 (EDeR)을 소개한다. 이 데이터셋은 OntoNotes 데이터셋의 문서 샘플에 주석을 달아 구성되어 있다.
    3. 우리는 EDeR의 이벤트 의존성 관계 예측을 위한 기준선 접근 방법을 조사하고, 이벤트 의존성 관계를 인식하는 것이 의미역 라벨링 및 공조참조 해결과 같은 중요한 NLP 작업에 도움이 될 수 있음을 보여준다.

###### It Ain’t Over: A Multi-aspect Diverse Math Word Problem Dataset (https://aclanthology.org/2023.emnlp-main.927/)
- Anthology ID: 2023.emnlp-main.927 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 수학 워드 프로블럼은 자연어 이해와 논리적 추론이 필요한 복잡한 작업이다. 이전 연구들은 다양한 MWP 데이터셋을 제공했지만, 문제 유형, 어휘 사용 패턴, 언어, 중간 솔루션에 대한 주석 등 다양성이 부족하다.
    2. 이 논문은 DMath (다양한 수학 워드 프로블렘)이라는 새로운 데이터셋을 소개하여, 문제 유형, 어휘 사용 패턴, 언어, 중간 솔루션 등에서 다양성을 제공한다.
    3. 실험 결과, DMath 데이터셋은 대형 언어 모델의 능력을 평가하기 위한 새로운 기회를 제공하며, 예를 들어 GPT-4는 DMath 데이터셋에서 약 75%의 정확도만을 달성한다고 보여주었다.

###### Dr ChatGPT tell me what I want to hear: How different prompts impact health answer correctness (https://aclanthology.org/2023.emnlp-main.928/)
- Anthology ID: 2023.emnlp-main.928 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문은 ChatGPT가 건강 정보 탐색에 사용될 때 다른 프롬프트가 모델의 동작에 미치는 중요한 영향을 조사한다. 특히, 건강과 같이 부정확한 답변이 심각한 결과를 초래할 수 있는 도메인에서, ChatGPT와 같은 큰 언어 모델(LLMs)에 대한 모델 동작을 이해하는 것이 매우 중요하다.
    2. TREC Misinformation 데이터셋을 사용하여, 우리는 ChatGPT를 실증적으로 평가하여 그 효과성을 보여주고, 프롬프트에 포함된 지식이 답변의 정확성을 해치는 모델 편향을 밝힌다.
    3. 이 연구는 생성형 대형 언어 모델에 기반한 보다 견고하고 투명한 질문-답변 시스템 개발에 중요한 영향을 미친다. 프롬프트, raw 결과 파일 및 수동 분석은 https://github.com/ielab/drchatgpt-health_prompting 에서 공개되어 있다.

###### kNN-LM Does Not Improve Open-ended Text Generation (https://aclanthology.org/2023.emnlp-main.929/)
- Anthology ID: 2023.emnlp-main.929 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문에서는 interpolation 기반의 retrieval-augmented language model (LM)의 생성 품질을 연구한다. 
    2. 이러한 방법들은 kNN-LM을 포함하여 언어 모델의 다음 단어에 대한 예측 분포와 주어진 접두사에 대한 가장 관련성이 높은 retrieval들로 구성된 분포를 보간한다.
    3. 우리는 automatic evaluation metrics (예: MAUVE)와 human evaluation을 통해 측정한 대로 open-ended 생성 품질에서 상응하는 개선이 없다는 것을 발견하였으며, 추가적으로 base LM에 비해 perplexity이 증가하고 retrieval 분포의 엔트로피도 증가되는 등의 문제를 발견하였다.

###### Towards A Unified View of Sparse Feed-Forward Network in Pretraining Large Language Model (https://aclanthology.org/2023.emnlp-main.930/)
- Anthology ID: 2023.emnlp-main.930 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 스케일업을 위해 S-FFN(Mixture-of-Experts와 같은)은 입력에 의존하여 일부 FFN 파라미터만 활성화함으로써 훈련 및 추론 비용을 유지하면서 일반화 성능을 향상시킵니다.
    2. 본 논문에서는 이러한 S-FFN의 주요 구조 선택 가능성인 메모리 블록 크기와 메모리 블록 선택 방법을 분석하고, 효과와 효율성에 대한 통찰을 제공합니다.
    3. 평균된 숨은 상태로 블록을 선택하는 Avg-K 선택 방법이 기존 MoE 구조보다 낮은 혼돈도(perplexity)를 달성하는 것을 발견했습니다.

###### Exploring the Impact of Model Scaling on Parameter-Efficient Tuning (https://aclanthology.org/2023.emnlp-main.931/)
- Anthology ID: 2023.emnlp-main.931 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Parameter-efficient tuning (PET) 메소드는 훈련에 필요한 파라미터를 최소화하여 매우 큰 pre-trained language models (PLMs) 을 효과적으로 구동하는데 도움이 된다. 하지만 작은 PLM의 경우, PET 메소드 간에 성능 차이가 난다. 모델의 규모가 커질수록, 성능 차이는 크게 줄어든다."
    2. "우리는 규모 확장이 PET 메소드의 디자인 차이에 미치는 영향을 완화시키는지에 대해 탐구하기 위해 더 유연한 Arbitrary PET (APET) 메소드를 도입한다. 우리의 조사 결과, 모델 규모가 튜닝 파라미터의 위치에 미치는 영향을 완화시키고, 적은 수의 튜닝 파라미터를 최적화함으로써 전체 파라미터 fine-tuning과 성능을 비교 가능한 수준의 성능을 달성할 수 있도록 한다."
    3. "놀랍게도, 우리는 튜닝 방법이 각기 다른 작업에서 무작위 추측 성능을 능가하는데 필요한 튜닝 파라미터의 수가 비슷하다는 것을 관찰했다. 이 연구 결과는 모델 규모가 PET에 미치는 영향을 이해하는 데 도움이 되며, 서로 다른 규모의 PLM에 대해 더 효과적이고 효율적인 PET 메소드를 설계하는 데 도움이 된다."

###### STAIR: Learning Sparse Text and Image Representation in Grounded Tokens (https://aclanthology.org/2023.emnlp-main.932/)
- Anthology ID: 2023.emnlp-main.932 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이미지 및 텍스트 검색은 비전 및 언어 분야에서 다양한 실제 응용 프로그램을 가진 핵심 작업 중 하나이다. 이 논문에서는 CLIP 모델을 확장하여 텍스트와 이미지를 sparse한 토큰 공간으로 매핑하는 sparse semantic representation을 구축한다. 이 모델은 dense representation보다 더 강력하며, 기존의 정보 검색 시스템과 쉽게 통합할 수 있을 뿐만 아니라, COCO-5k 텍스트 → 이미지 및 이미지 → 텍스트 검색에서 이전의 CLIP 모델보다 상당한 성능 향상을 이룩한다.
    2. 기존의 텍스트 벡터 임베딩은 dense한 표현 영역에서 유사성을 측정하는 반면, 이 논문에서 제안하는 sparse한 semantic representation은 토큰 공간에서 이미지와 텍스트를 매핑하여 사용한다. 이렇게 구성된 STAIR 모델은 dense한 표현보다 더 나은 성능을 보여주며, 서로 다른 작업에서도 더 우수한 결과를 달성한다.
    3. STAIR 모델은 이미지넷 제로샷 및 선형 프로빙과 같은 작업에서 CLIP보다 더 나은 성능을 보였으며, 이러한 sparse한 표현은 기존의 정보 검색 시스템에 쉽게 통합할 수 있다.

###### Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting (https://aclanthology.org/2023.emnlp-main.933/)
- Anthology ID: 2023.emnlp-main.933 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Idioms은 일상 언어에서 흔하지만, 그 의미가 부분들의 의미로부터 유도되지 않기 때문에 번역자에게 도전이 된다. 그러나 기계 번역 시스템은 여전히 Idiomatic 표현을 번역하는 것에 어려움을 겪고 있다. 
    2. 이 논문에서는 Idiomatic 번역과 관련된 문제들을 간단한 방식으로 설명함으로써 Machine Translation 모델들이 Idiomatic 번역을 올바르게 수행하기 위한 기준점(tipping point)을 발견하였다.
    3. 이 논문에서는 Idiomatic 표현을 포함한 데이터셋을 만들고, 훈련시에 이 데이터를 활용하는 기법을 제안하여 기존의 번역 모델의 정확성을 상당히 향상시킬 수 있는 것을 확인하였다.

###### CoRec: An Easy Approach for Coordination Recognition (https://aclanthology.org/2023.emnlp-main.934/)
- Anthology ID: 2023.emnlp-main.934 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존 방법들은 문장에서 협조어를 식별하고 협조 경계를 인식하기 위해 문법 파서에 의존하지만, 최신 문법 파서는 긴 복잡한 문장에서 특히 에러가 날 가능성이 높고 느리다. 
    2. 이 논문에서는 COordination RECognizer (CoRec)라는 pipeline 모델을 제안하여 문제를 효과적으로 해결한다. 
    3. 다양한 도메인의 데이터셋에서의 실험 결과는 제안된 방법의 효과적이고 효율적임을 보여주며, 추가 실험 결과는 CoRec이 downstream task에 긍정적인 영향을 주어 최신 Open IE 모델의 성과를 향상시킨다는 것을 보여준다.

###### A linear time approximation of Wasserstein distance with word embedding selection (https://aclanthology.org/2023.emnlp-main.935/)
- Anthology ID: 2023.emnlp-main.935 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Wasserstein distance는 문서 간의 중복성을 측정하는 강력한 도구이지만, cubic time을 필요로 하기 때문에 계산 비용이 큰 문제입니다."
    2. "논문에서는 feature selection과 tree approximation 접근법을 결합하여 고차원 문제를 처리하는 방법을 제안합니다."
    3. "실험 결과, 제안된 방법을 사용하여 문서 분류 작업에서 높은 성능을 달성하였습니다."

###### Exchange-of-Thought: Enhancing Large Language Model Capabilities through Cross-Model Communication (https://aclanthology.org/2023.emnlp-main.936/)
- Anthology ID: 2023.emnlp-main.936 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 Large Language Models (LLMs)는 복잡한 추론 태스크에서 Chain-of-Thought 기술을 통해 중요한 발전을 이루어왔으나, 그들의 추론은 종종 내재적인 이해력으로 제한되어 외부적인 통찰력이 부족하다. 
    2. 이를 해결하기 위해 우리는 문제 해결 도중에 모델 간의 교류를 가능케 하는 Exchange-of-Thought(EoT)라는 새로운 프레임워크를 제안한다. 
    3. 우리는 이 논문에서 각 패러다임에 따른 EoT의 커뮤니케이션 동적 및 양적 측면을 자세히 알아보며, 잘못된 추론 체인의 위험을 상쇄하기 위해 믿을 만한 신뢰도 평가 메카니즘을 구현한다.

###### Conversation Understanding using Relational Temporal Graph Neural Networks with Auxiliary Cross-Modality Interaction (https://aclanthology.org/2023.emnlp-main.937/)
- Anthology ID: 2023.emnlp-main.937 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 감정 인식은 인간 대화 이해에 중요한 작업이다. 언어, 음성 및 얼굴 표정과 같은 다중 모달 데이터 개념과 함께 더 도전적인 과제가 된다. 
    2. 기존 접근 방식은 대화에서 각 문장에 대한 감정 레이블을 예측하기 위해 전역 및 로컬 context 정보를 사용하고 있다. 
    3. 이 논문에서는 CORECT라는 새로운 신경망 프레임워크를 제안하여 대화 수준의 다중 모달 상호작용과 문장 수준의 시간적 종속성을 효과적으로 포착한다.

###### Connecting degree and polarity: An artificial language learning study (https://aclanthology.org/2023.emnlp-main.938/)
- Anthology ID: 2023.emnlp-main.938 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "우리는 사전 훈련된 언어 모델들에서 새로운 언어적 일반화 현상을 조사했습니다. 저향(adverbs)으로 표현되는 정도 수정자들 (예: 조금, 매우, 굉장히) 에 초점을 맞춰서, 수정자의 정도가 문장의 극성 감지 민감도와 관련이 있는지를 테스트하고자 했습니다."
    2. "이 연결을 조사하기 위해, 우리는 심리언어학의 인공언어학 파라다임을 신경 언어 모델에 적용했습니다. 우리의 실험 결과는, BERT가 예전부터 관찰된 언어들과 일치하게 일반화한다는 것을 시사합니다. 즉, 낮은 정도의 수정자는 긍정 극성을 선호한다는 주요한 언어적 연구들과 일치합니다."
    3. "고로, 이 연구는 사전 훈련된 언어 모델들이 단어의 정도 의미와 극성 민감도를 연결짓는 기존 언어적 관찰들을 일반화하는 경향을 갖는다는 것을 보여줍니다."

###### Prompting with Pseudo-Code Instructions (https://aclanthology.org/2023.emnlp-main.939/)
- Anthology ID: 2023.emnlp-main.939 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근에는 자연어 지시를 사용하여 대용량 언어 모델의 능력을 효과적으로 활용하는 방법으로 주목받고 있다. 그러나 자연어의 내재된 모호성 때문에, 퍼즈도 코드와 같이 모호성이 적은 지시를 사용하면 성능을 향상시킬 수 있는 가능성이 있다.
    2. 이 논문에서는 퍼즈도 코드 지시로 프롬프팅하는 것이 사전 훈련된 언어 모델의 성능을 향상시키는 데 도움이 되는지 탐구한다. 다양한 분류, QA, 생성 언어 작업에 대한 132가지 다른 작업의 퍼즈도 코드 프롬프트 데이터셋을 수동으로 생성하고, 이러한 프롬프트를 자연어 프롬프트와 함께 사용하여 BLOOM, CodeGen 두 언어 모델 계열에서 성능을 연구했다.
    3. 실험 결과, 퍼즈도 코드 지시를 사용하면 분류 작업에서 F1 점수의 평균 증가율이 7-16 포인트이고, 모든 작업에서 ROUGE-L 점수를 12-38% 향상시켰다. 코드 코멘트, 독스트링, 퍼즈도 코드에 인코딩된 구조적 단서가 모두 성능 향상에 기여한다는 설명적 실험 연구도 포함되어 있다.

###### CRAB: Assessing the Strength of Causal Relationships Between Real-world Events (https://aclanthology.org/2023.emnlp-main.940/)
- Anthology ID: 2023.emnlp-main.940 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이 논문에서는 사건의 원인과 결과에 대해 추론하는 것을 이해하기 위해서는 복잡한 인과관계의 네트워크를 이해할 수 있는지 알 수 없다.
    2. CRAB라는 causal reasoning 평가 벤치마크 데이터셋을 소개하여 여러 언어 모델의 성능을 측정한다.
    3. 실험 결과, 모델들은 단순한 선형 인과관계 체인보다 복잡한 인과구조에서는 인과 추론에 대해 더 부족한 성능을 보였다.

###### NORMSAGE: Multi-Lingual Multi-Cultural Norm Discovery from Conversations On-the-Fly (https://aclanthology.org/2023.emnlp-main.941/)
- Anthology ID: 2023.emnlp-main.941 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사회문화적 시나리오에서 사용 가능한 행동에 대해 이해하고 추론하기 위해서는 규범에 대한 지식이 필요합니다. 규범에 대한 대부분의 컴퓨터 연구는 한 문화를 중심으로 진행되며, 비대화식 환경에서 수동으로 구축된 데이터셋을 사용합니다.
    2. 우리는 NormSage라는 새로운 프레임워크를 제안하여 다중 언어 대화에서 문화 특정 규범을 자동으로 추출합니다. NormSage는 대화에서 후보 규범을 직접 추출하고, 정확성과 관련성을 확인하기 위해 설명 가능한 자체 검증을 제공하는데 GPT-3 프롬프팅을 사용합니다.
    3. 포괄적인 실험 결과는 NormSage가 다중 언어 대화 (영어와 중국어)에서 고품질 문화 지각 규범을 추출하기 위한 접근 방식의 잠재력을 보여줍니다. 또한, 우리의 관련성 검증은 텍스트 설명과 함께 대화에 대한 규범 준수 및 위반을 평가하는 데 확장될 수 있습니다. NormSage는 생성된 설명이 사람이 작성한 품질과 일치하는 94.6%의 AUC를 달성합니다.

###### A State-Vector Framework for Dataset Effects (https://aclanthology.org/2023.emnlp-main.942/)
- Anthology ID: 2023.emnlp-main.942 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근의 DNN 기반 시스템의 성공은 훈련에 사용된 고품질 데이터셋의 영향이 크다. 그러나 데이터셋의 영향과 데이터셋 간 상호작용에 대한 연구는 아직 충분히 이루어지지 않았다.
    2. 우리는 상태 벡터 프레임워크를 제안하여 데이터셋의 영향을 체계적으로 연구할 수 있게 한다. 이 프레임워크는 이상적인 프로빙 테스트 결과를 기반으로 벡터 공간을 형성한다.
    3. 우리는 일부 자주 사용되는 언어 이해 데이터셋의 중요한 영향이 특정한 언어적 요소에 집중되어 있는 것을 보여준다. 또한 "spill-over" 효과를 관찰하였는데, 이는 의도한 작업과는 관련이 없어 보이는 차원에서 모델에 영향을 미칠 수 있다.

###### Challenges in Context-Aware Neural Machine Translation (https://aclanthology.org/2023.emnlp-main.943/)
- Anthology ID: 2023.emnlp-main.943 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 문맥 지속적인 신경 기계 번역에 대한 이해는 문장 수준의 문맥 이상의 정보를 활용하여 문장 간 의사소통 종속성을 해결하고 문서 수준의 번역 품질을 향상시키는 패러다임을 가능하게 했지만, 대부분의 연구는 문장 수준의 시스템보다 크게 개선되고 있다고 단언할 수 없다.
    2. 이 연구에서는 문헌 수준의 번역에 관련된 여러 핵심적인 문제들을 조사하고 제시한다. 이로 인한 문제점이 의사소통 현상, 문맥 사용, 모델 구조 및 문서 수준 평가와 관련되어 있다.
    3. 이러한 문제를 해결하기 위해, 우리는 문서 수준 번역에 대해 더 실제적인 설정을 제안하며, 이를 위해 중국어-영어 소설의 새로운 데이터셋을 수집하여 향후 연구를 촉진한다.

###### Task-Adaptive Tokenization: Enhancing Long-Form Text Generation Efficacy in Mental Health and Beyond (https://aclanthology.org/2023.emnlp-main.944/)
- Anthology ID: 2023.emnlp-main.944 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 우리는 downstream task의 세부 사항에 맞게 생성 파이프라인을 조정하고, 정신건강 분야에서의 긴형식 생성을 향상시키기 위해 과제적응적 토큰화(task-adaptive tokenization)를 제안한다.
    2. 우리의 과제적응적 토큰화 접근법은 인지과학의 통찰에서 영감을 받아, 과제별 데이터를 기반으로 최적화된 샘플링 확률로 여러 결과에서 가변적인 세그멘테이션을 샘플링한다.
    3. 중국어와 영어의 심리학적 질문 응답 과제에서의 광범위한 실험을 통해, 우리의 과제적응적 토큰화 접근법이 성능 향상에 유의미한 기여를 하며 최대 60% 적은 토큰을 사용한다는 것을 알아냈다. 매우 큰 언어 모델과 함께 이러한 토큰화 접근법을 사용할 때 유망한 결과를 얻을 수 있다는 사전 실험 결과가 있다.

###### FACTIFY3M: A benchmark for multimodal fact verification with explainability through 5W Question-Answering (https://aclanthology.org/2023.emnlp-main.945/)
- Anthology ID: 2023.emnlp-main.945 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 소셜 미디어 플랫폼에서 매일 32억 장의 이미지와 72만 시간의 비디오가 공유되는 상황에서, 다중형식의 가짜 뉴스를 대규모로 탐지하기 위해서는 효율적인 사실 검증이 필요하다.
    2. 이 논문은 FACTIFY 3M이라는 데이터셋을 소개하는데, 이는 다중형식 가짜 뉴스 데이터셋을 통해 사실 검증 도메인의 영역을 넓히고, 5W 질문-답변 개념을 통해 설명 가능성을 제공한다.
    3. 이 데이터셋의 주요 특징은 텍스트 단언문, ChatGPT로 생성된 패러프레이즈 된 단언문, 연관된 이미지, 안정적인 확산 생성 추가 이미지, 픽셀-레벨 이미지 히트맵, 5W 질문-답변 쌍, 그리고 가짜 뉴스 이야기 등이다.

###### Building Multi-domain Dialog State Trackers from Single-domain Dialogs (https://aclanthology.org/2023.emnlp-main.946/)
- Anthology ID: 2023.emnlp-main.946 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존 multi-domain 대화 상태 추적(DST) 모델은 다양한 도메인의 대화에 기반을 두고 있어 도메인 관계를 정의하고 데이터를 수집하는 데 많은 수동 노력이 필요하다. 이를 대응하는 것은 도메인 조합이 없는 대화로부터 multi-domain DST 모델을 구축할 수 있도록 한 divide-and-conquer(DAC) DST 패러다임과 multi-domain 대화 합성 프레임워크를 제안한다. 
    2. DAC 패러다임은 multi-domain 대화를 DST를 위해 여러 개의 단일 도메인 대화로 분할하여, 모델이 보이지 않은 도메인 조합을 가진 대화에 대해 더 일반화할 수 있도록 한다. 
    3. 대화 합성 프레임워크는 여러 개의 관련이 있는 단일 도메인 대화를 하나의 multi-domain 대화로 병합하고, 도메인 간 관계를 모방하기 위해 대화를 수정한다. 이러한 합성된 대화는 DST 모델이 도메인 간 지식 전달을 포착하는 데 도움을 준다.

###### Specialist or Generalist? Instruction Tuning for Specific NLP Tasks (https://aclanthology.org/2023.emnlp-main.947/)
- Anthology ID: 2023.emnlp-main.947 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델 (LLM)이 다양한 자연어 처리 (NLP) 작업을 동시에 수행할 수 있는 잠재력이 광범위한 연구의 주제이다. 
    2. 본 논문에서는 일반화된 가이드라인 튜닝을 통합하는 것이 전문가 모델 구축에 기여할 수 있는지를 조사한다. 
    3. 실험 결과, 일반화된 가이드라인 튜닝이 특화된 작업의 성능을 꾸준히 향상시키는데 효과적이며, 특히 작업 특정 학습 데이터가 제한된 경우에 더욱 두드러진다. 그러나 사실적인 지식을 필요로 하는 작업에서는 시각화된 정보를 포함한 일반화 데이터가 모델의 성능에 부정적인 영향을 미치는 것으로 나타났다.

###### Making Large Language Models Better Data Creators (https://aclanthology.org/2023.emnlp-main.948/)
- Anthology ID: 2023.emnlp-main.948 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델(LLMs)은 NLP 분야에서 성능을 크게 향상시켰지만, 비용, 응답 속도, 제어 능력 또는 개인 정보 보호 및 보안 문제로 인해 실전 응용에는 여전히 어려움이 있다. 이 논문에서는 LLM을 사용하여 데이터 생성하는 통합 파이프라인을 제안하며, 이는 단일 포맷 예제만으로도 다양한 작업에 적용 가능하다.
    2. 실험에서는 지시를 따르는 LLM이 비용 효율적인 데이터 생성자로 작용하며, 이러한 데이터로 훈련된 모델이 분포 밖 평가에서 (최대 17.5%까지) 인간이 레이블링한 데이터보다 더 나은 성능을 보이는 동시에 분포 내 작업에서 비슷한 성능을 유지한다.
    3. 이러한 결과는 실제 세계에서 배포되는 NLP 시스템의 탄탄성에 중요한 시사점을 제공한다.

###### Hallucination Detection for Generative Large Language Models by Bayesian Sequential Estimation (https://aclanthology.org/2023.emnlp-main.949/)
- Anthology ID: 2023.emnlp-main.949 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Big Language Models (LLMs)은 자연어 생성 분야에서 현저한 발전을 이루었으나, LLMs의 부정확하거나 비실제적인 컨텐츠 생성 ("hallucinations") 경향은 여전히 큰 도전 과제이다.
    2. 현재의 환각 탐지 방법은 많은 양의 관련 자료 검색이 필요하여 응답 시간이 증가하는 문제가 있다.
    3. 우리는 통계적 의사 결정 이론과 베이지안 순차분석을 활용하여 환각 탐지 과정에서 비용과 이익 사이의 트레이드 오프를 최적화하는 독특한 프레임워크를 소개한다.
    
    1. "Automatic MCQ generation"은 교사들의 학생 평가 시간을 크게 줄임으로써 중요한 교육 수단이 될 수 있지만, 기존 MCQ 평가 메트릭은 생성된 MCQ가 교육적인 가치를 지니는지 판단할 수 없기 때문에 제한적이다.
    2. 이 논문에서는 "지식 종속 가능성(KDA)"라고 불리는 새로운 평가 메트릭을 제안하여 MCQ의 대답 가능성과 대상 사실의 학생 지식 평가 능력을 측정한다. 
    3. 실험 결과 KDA_disc와 KDA_cont는 "KDA"와 "실제 강의실 세트에서의 사용성"과 강한 상관관계를 가지며, n-gram 기반 유사성 메트릭과 함께 사용할 때 다양한 MCQ 품질 지표에 대해 강한 예측력을 보인다.
    
    1. 최근의 deep모델은 NLP 태스크에서 뛰어난 성능을 보이지만 특정 패턴에 의존하므로 robustness가 한계가 있다. 
    2. 이 논문에서는 Contrastive Learning과 counterfactual augmentation을 활용하여 강건성(robustness)을 높이기 위한 방법을 제안한다.
    3. 기존의 augmentation 방법과는 달리 여러 개의 counterfactual을 합성하여 예측 분포를 통해 인과 관계를 신뢰할 수 있으며, 이를 통해 counterfactual의 강건성, 도메인 간 일반화, 희소 데이터 일반화의 세 가지 측면에서 큰 개선을 얻었다.

###### Guideline Learning for In-Context Information Extraction (https://aclanthology.org/2023.emnlp-main.950/)
- Anthology ID: 2023.emnlp-main.950 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 큰 언어 모델은 단지 지시사항과 몇 가지 입출력 예시에 의해 조건이 주어짐으로써 새로운 작업을 수행할 수 있으며, 어떠한 파라미터도 최적화하지 않습니다. 이를 In-Context Learning (ICL)이라고 합니다.
    2. 그러나 In-Context Information Extraction (IE)의 성능은 일반적으로 최신의 지도학습 전문 모델보다 뒤쳐지는 편입니다. 이는 작업 설명의 불명확함이 주요한 원인입니다.
    3. 이 논문에서는 In-Context IE를 위한 Guideline Learning (GL) 프레임워크를 제안하여 몇 가지 오류 사례를 기반으로 가이드라인을 자동으로 생성하고, 추론 중에 도움이 되는 가이드라인을 검색해 더 나은 ICL을 실현합니다. 또한, GL의 효율성을 향상하기 위해 자기 일관성 기반의 액티브 러닝 방법을 제안합니다. 실험 결과이벤트 추출과 관계 추출에서 GL은 In-Context IE의 성능을 크게 향상시킬 수 있습니다.

###### Open Information Extraction via Chunks (https://aclanthology.org/2023.emnlp-main.951/)
- Anthology ID: 2023.emnlp-main.951 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존 OIE 시스템들은 문장을 토큰으로 나누고 토큰 범위를 튜플 관계와 인자로 인식한다. 이 논문에서는 문장을 청크(Chunk) 시퀀스로 인식하고, 청크 범위를 튜플의 관계와 인자로 인식하는 방법인 Sentence as Chunk sequence (SaC) 를 제안한다.
    2. 청크로 나누는 것이 토큰으로 나누는 것보다 OIE에 더 적합한 속성을 가지고 있다고 주장하며, CoNLL 청크, OIA 간단한 구 묶음, 명사구, 그리고 SpanOIE의 범위로 나누는 네 가지 옵션을 평가한다.
    3. 또한 SaC 위에 간단한 end-to-end BERT 기반 모델인 Chunk-OIE를 제안하여 문장 청크화와 튜플 추출을 수행하는데, 해당 모델은 다양한 OIE 데이터셋에서 최고 성능을 보이며, SaC가 OIE 작업에 이점을 제공함을 나타낸다.

###### Rethinking Word-Level Auto-Completion in Computer-Aided Translation (https://aclanthology.org/2023.emnlp-main.952/)
- Anthology ID: 2023.emnlp-main.952 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 컴퓨터 지원 번역에서 단어 수준 자동 완성(WLAC)은 중요한 역할을 한다. 기존 연구들은 복잡한 모델 구조를 설계하는데 초점을 두었지만 이 논문은 다른 관점에서 접근하여 어떤 종류의 단어가 좋은 자동 완성인지에 대한 기준을 제시한다.
    2. 우리는 이 기준에 만족하지 못하는 기존의 WLAC 모델들이 많다는 것을 발견하였고, 이를 개선하기 위한 효과적인 방법을 제안한다.
    3. 실험을 통해 우리의 접근 방식이 WMT2022의 WLAC 공유 작업에 제출된 최고 성능 시스템보다 우수한 성능을 발휘하는 것을 보여주었다.

###### Automatic Transcription of Handwritten Old Occitan Language (https://aclanthology.org/2023.emnlp-main.953/)
- Anthology ID: 2023.emnlp-main.953 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 신경망 기반 접근법은 고자원 언어나 표준화된/기계로 작성된 텍스트에 대한 Handwritten Text Recognition (HTR)에서 유망한 결과를 보여주었으나, 낮은 자원 언어에 적용하는 것은 효과가 제한되는 문제점을 가지고 있다.
    2. 우리는 Transformer 아키텍처를 활용하여 Old Occitan 언어의 손글씨 텍스트를 인식하는 혁신적인 HTR 접근법을 제안한다.
    3. 제한된 데이터를 고려하여, 우리는 텍스트와 이미지 데이터에 대한 복잡한 데이터 증강 기법을 개발하고, Swin 이미지 인코더와 BERT 텍스트 디코더를 결합하여 모델을 구성한다. 실험 결과, 우리의 접근법은 Old Occitan HTR의 최신 기술 모델, TrOCR과 Google Cloud Vision과 같은 상용 애플리케이션을 포함하여 다른 모델들보다 우수한 성능을 보인다.

###### CorefPrompt: Prompt-based Event Coreference Resolution by Measuring Event Type and Argument Compatibilities (https://aclanthology.org/2023.emnlp-main.954/)
- Anthology ID: 2023.emnlp-main.954 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "이벤트 핵심 참조 (ECR)는 동일한 현실 세계 이벤트를 가리키는 이벤트 언급을 클러스터로 그루핑하는 것을 목표로 한다."
    2. "기존 방법들은 '인코딩 먼저, 그리고 스코어링' 프레임워크를 채택하여 핵심 참조 판단이 이벤트 인코딩에 의존하는 문제가 있다."
    3. "우리는 CorefPrompt 라는 기법을 제안하여 ECR을 클로즈 스타일의 MLM (Masked Language Model) 과제로 변환하고, 단일 템플릿 내에서 동시적으로 이벤트 모델링과 핵심 참조 구분을 수행할 수 있도록 한다."

###### Anaphor Assisted Document-Level Relation Extraction (https://aclanthology.org/2023.emnlp-main.955/)
- Anthology ID: 2023.emnlp-main.955 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다문장 문서 내에서 분산된 entity 간의 관계를 식별하는 문제에는 기존 방법들이 다양한 entity 사이의 내부 구조와 외부 상호작용을 모델링하기 위해 이질적인 문서 그래프를 구축하는 것에 초점을 맞추고 있다.
    2. 하지만 기존 방법들은 추론에 중요한 역할을 하는 anaphor를 무시하고, 문서나 문장을 중간 노드로 활용하여 문장간 entity 상호작용을 암묵적으로 이루고 있다. 
    3. 우리는 이러한 문제를 해결하기 위해 Anaphor-Assisted (AA) framework를 제안하였으며, 널리 사용되는 데이터셋에서 실험 결과 우리의 모델이 새로운 state-of-the-art 성능을 달성한다는 것을 보였다.

###### FinEntity: Entity-level Sentiment Classification for Financial Texts (https://aclanthology.org/2023.emnlp-main.956/)
- Anthology ID: 2023.emnlp-main.956 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 금융 도메인에서는 특정 금융 엔티티에 대한 감성 분석을 정확하게 수행하는 것이 중요하다. 이를 위한 공개 데이터셋은 현재로서는 알려진바가 없다.
    2. 이 논문에서는 금융 뉴스에서 금융 엔티티 범위와 그들의 감성 (긍정, 중립, 부정)을 주석으로 달아놓은 entity-level 감성 분류 데이터셋인 "FinEntity"를 소개한다. 
    3. 추가로, "FinEntity"를 기반으로 BERT, FinBERT, ChatGPT 등 여러 사전 훈련된 모델들을 entity-level 감성 분류에서 벤치마크하였다.

###### All Things Considered: Detecting Partisan Events from News Media with Cross-Article Comparison (https://aclanthology.org/2023.emnlp-main.957/)
- Anthology ID: 2023.emnlp-main.957 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대중 의견은 뉴스 매체가 제공하는 정보에 의해 형성되며, 이 정보 또한 매체의 이념적 기호에 의해 형성될 수 있다. 본 논문은 동일한 이야기에 대한 여러 기사를 비교하여 이념적 기사의 기울기를 예측하는 잠재 변수 기반의 프레임워크를 개발하여 매체의 이념적 이벤트의 포함 또는 생략에 의해 의도된 영향을 조사한다. 
    2. 실험을 통해 이념적 이벤트 선택의 존재를 검증하고, 기사의 일치와 문서 간 비교가 경쟁적인 기준에 비해 이념적 이벤트와 기사의 이념을 더 잘 탐지한다는 것을 보였다.
    3. 우리의 결과는 객관성과 비정치성의 강한 규범을 가진 주류 매체에서도 존재하는 고수준의 미디어 편향을 드러낸다.

###### Rationale-Enhanced Language Models are Better Continual Relation Learners (https://aclanthology.org/2023.emnlp-main.958/)
- Anthology ID: 2023.emnlp-main.958 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 연속적인 관계 추출(CRE)은 새롭게 나타나는 관계들의 시퀀스를 학습할 때 치명적인 잊어버림(catastrophic forgetting) 문제를 해결하기 위한 것인데, 최근 연구에서는 치명적인 잊어버림이 미래의 유사한 관계에 대해 모델이 강건하지 못하다는 것을 발견하였다.
    2. 이 문제를 해결하기 위해 우리는 대규모 언어 모델에서 생성된 관계 분류 결과의 설명을 CRE 작업에 도입한다. 특히, 현재 관계를 강건하게 학습하기 위해 다중 작업 원리 튜닝 전략을 제안하며, 또한 유사한 관계를 구별하기 위해 대조적인 원리 재생 모듈을 사용한다.
    3. 두 개의 표준 벤치마크에서의 실험 결과에서 우리의 방법이 최신 CRE 모델보다 우수한 성능을 보였다.

###### BanglaAbuseMeme: A Dataset for Bengali Abusive Meme Classification (https://aclanthology.org/2023.emnlp-main.959/)
- Anthology ID: 2023.emnlp-main.959 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 소셜 미디어 플랫폼의 사용 증가로 인해 온라인 학대 문제도 급증하고 있다. 
    2. 이 논문은 낮은 자원 환경에서 폭력적인 밈 (Meme)을 탐지하고 표시하기 위한 모델을 개발하는 것이 중요하다고 강조하고 있다. 
    3. 텍스트와 시각 정보를 모두 활용하는 multimodal 모델이 단일 모달 모델보다 우수한 성능을 보이며, 제안된 모델 중 가장 우수한 성능을 보이는 모델은 macro F1 점수가 70.51이다.

###### ScanDL: A Diffusion Model for Generating Synthetic Scanpaths on Texts (https://aclanthology.org/2023.emnlp-main.960/)
- Anthology ID: 2023.emnlp-main.960 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 독서 중의 눈 움직임은 인간의 언어 처리에 대한 인지 메커니즘을 연구하는 심리 언어학 연구에서 중요한 역할을 한다. 얼마 전까지는 인과관계 모델로 눈 움직임 데이터를 생성했지만, 최근 데이터 기반의 기계 학습 기반 기법이 더 적합하다고 입증되었다.
    2. 해당 논문에서는 이산적인 시퀀스-투-시퀀스 확산 모델인 ScanDL을 제안하여 텍스트에 대한 합성 스캔 패스를 생성한다. 사전 훈련된 단어 표현을 활용하여 자극 텍스트와 고정 시퀀스를 함께 임베딩함으로써 두 입력 간의 다중 모달 상호작용을 포착한다. 
    3. 데이터셋 내부 및 데이터셋 간의 평가를 통해 ScanDL이 최고의 스캔 패스 생성 방법보다 우수한 성과를 보여준다는것을 보였고, 인간과 유사한 독서 행동을 나타내는 능력이 있다는 것을 보여주는 심리 언어학적 분석도 수행한다.

###### From Values to Opinions: Predicting Human Behaviors and Stances Using Value-Injected Large Language Models (https://aclanthology.org/2023.emnlp-main.961/)
- Anthology ID: 2023.emnlp-main.961 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 현실적인 시나리오에서 사람들의 의견을 예측할 수 있다면, 정치나 마케팅 등 다양한 분야에서 도움이 될 수 있다. 그러나 유럽 사회조사처럼 대규모 설문조사를 실시하는 것은 막대한 비용이 발생할 수 있다. 
    2. 이를 대비하기 위해, 우리는 핵심 인간 가치가 개인의 결정과 행동에 미치는 영향에 대한 이전 연구를 활용하여, 가치 주입된 대형 언어 모델을 사용하여 의견과 행동을 예측하는 것을 제안한다.  
    3. 실험 결과, 가치 주입된 언어 모델은 기준 모델보다 훨씬 우수한 예측 결과를 보이며, 의견과 행동을 예측하는 데에 가치 주입된 언어 모델을 사용하는 것이 기준 접근법보다 좋을 수 있다는 결과를 제시한다.

###### Analyzing Film Adaptation through Narrative Alignment (https://aclanthology.org/2023.emnlp-main.962/)
- Anthology ID: 2023.emnlp-main.962 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 소설은 종종 영화로 채택되지만 두 가지 미디어 간의 차이로 인해 영화 스크립트에서는 소스 텍스트를 일부 삭제해야 하는 경우가 많다.
    2. 이 연구에서는 Smith-Waterman 로컬 정렬 알고리즘과 SBERT 임베딩 거리를 결합하여 장면과 책 단위 사이의 텍스트 유사성을 측정하는 Narrative Alignments를 구성함으로써 이 스크린 어댑테이션 프로세스를 연구한다.
    3. 우리는 이러한 정렬을 사용하여 40개의 영화 어댑테이션을 자동 분석하여 (i) 어댑테이션의 충실성, (ii) 대화의 중요성, (iii) 서술 순서의 보존, 및 (iv) Bechdel 테스트를 반영하는 성별 표현 문제들에 대한 통찰을 얻었다.

###### Inverse Scaling Can Become U-Shaped (https://aclanthology.org/2023.emnlp-main.963/)
- Anthology ID: 2023.emnlp-main.963 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어 모델의 규모를 키우면 downstream task의 성능도 향상되지만, 일부 task에서는 모델 규모가 커짐에 따라 성능이 떨어졌을 때 이는 사람의 선호와 일치하지 않는 행동을 독려할 수 있다는 것을 나타낸다.
    2. 이 연구에서는 역 비례하는 성능을 보이는 task들을 자세히 살펴보았다. 연구에서는 540B 파라미터를 가진 모델을 사용하여 훈련 시간도 Inverse Scaling Prize에서 평가한 것보다 다섯 배 더 길게 훈련했다. 결과적으로 역 비례하는 task 중 4개만이 남았고, 6개의 task는 U자형 비례로 성능이 일정 규모까지 하락한 후 다시 증가하는 형태였다.
    3. 이러한 U자형 비례는 McKenzie et al. (2023)에서 관찰된 역 비례하는 경향이 더 큰 모델에 대해서는 계속 유지되지 않을 수도 있다는 것을 시사한다. 이는 충분히 큰 모델만이 방해 task를 피할 수 있는 영향으로 해석된다.

###### Nearest Neighbor Machine Translation is Meta-Optimizer on Output Projection Layer (https://aclanthology.org/2023.emnlp-main.964/)
- Anthology ID: 2023.emnlp-main.964 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Nearest Neighbor Machine Translation (kNN-MT)"은 사전 훈련된 Neural Machine Translation(NMT) 모델과 도메인 특정 토큰 검색을 통합하여 도메인 적응 작업에서 큰 성공을 거두었지만, 그 이유는 철저히 조사되지 않았다. 
    2. 이 논문에서는 kNN-MT의 작동 메커니즘에 대한 새로운 통찰력을 제공하여, NMT의 출력 projection 레이어에서 경사 하강법을 암묵적으로 수행하는 효율적인 기술로서의 특수한 경우임을 보여준다.
    3. 또한, 여러 도메인 실험과 단어 수준 분석을 통해 kNN-MT와 전체 모델 fine-tuning 간의 성능 차이를 조사하고 찾아낸 결과를 소개한다.

###### Variance Matters: Detecting Semantic Differences without Corpus/Word Alignment (https://aclanthology.org/2023.emnlp-main.965/)
- Anthology ID: 2023.emnlp-main.965 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 본 논문에서, 우리는 두 개의 corpus에 나오는 단어들 사이의 의미적 차이를 발견하기 위한 방법을 제안한다.
    2. 제안된 방법들은 이전 방법들과 달리 단어와/또는 corpus 간의 정렬을 필요로 하지 않는다.
    3. 이 방법들은 이전의 최고 성능 시스템과 견줄 만한 결과를 보여주며, 문서 크기의 불균형에도 강인하며, 드물게 나타나는 단어들의 의미적 차이를 탐지하고, 두 corpus 비교에서 한 corpus에 의미가 빠진 단어들을 찾는 데 효과적이다.

###### MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter (https://aclanthology.org/2023.emnlp-main.966/)
- Anthology ID: 2023.emnlp-main.966 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 언어 모델 (LM)은 다양한 1D 텍스트 관련 작업에서 인상적인 분자 이해 능력을 보여주었지만, 인간 전문가의 핵심 능력인 2D 그래프 인지를 내재적으로 부족하고 있다. 이런 갭을 메우기 위해 MolCA를 제안한다. MolCA는 크로스모달 프로젝터와 유니모달 어댑터를 사용하여 LM (Galactica)가 텍스트 및 그래프 기반의 분자 내용을 이해할 수 있게 한다.
    2. MolCA는 그래프 인코더의 표현 공간과 LM의 텍스트 공간을 연결하는 Q-포머로 구현된 크로스모달 프로젝터를 사용한다.
    3. 이전 연구들은 크로스모달 대조 학습을 통해 LM과 그래프 인코더를 결합하였으나, MolCA는 LM의 개방형 텍스트 생성 능력을 보존하며 2D 그래프 정보를 보완하여 더욱 효과적으로 작동한다.

###### A Training-Free Debiasing Framework with Counterfactual Reasoning for Conversational Emotion Detection (https://aclanthology.org/2023.emnlp-main.967/)
- Anthology ID: 2023.emnlp-main.967 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 이야기에서 기분 인식 (ERC) 데이터셋에는 레이블 편향, 확률이 높은 클래스에 편향되는 문제와 특정 중립 단어나 발화자와 클래스 간의 과도한 상관관계로 인한 불공정한 예측이 존재한다.
    2. 이 논문에서는 ERC에서 발생하는 이러한 데이터셋 편향을 해결하기 위해 훈련 과정 없이 예측할 때 작동하는 Training-Free Debiasing (TFD) 프레임워크를 제안한다.
    3. TFD는 데이터를 균형화하거나 모델 구조를 수정하지 않고, 간단하고 실험적으로 견고한 원소 별 뺄셈 연산을 사용하여 모델에서 편향을 제거하는 방법이다.

###### Self-ICL: Zero-Shot In-Context Learning with Self-Generated Demonstrations (https://aclanthology.org/2023.emnlp-main.968/)
- Anthology ID: 2023.emnlp-main.968 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대형 언어 모델은 몇 개의 입출력 데모로도 목표 작업에 대해 놀랄만한 in-context learning (ICL) 능력을 보여주었다. 이 논문에서는 training 코퍼스에서 대표적인 데모를 선택하기 위해 다양한 방법이 제안되었지만, 실제 사용자들은 대개 데모 풀에 접근할 수 없는 상황이므로, Self-ICL이라는 간단한 프레임워크를 소개하여 zero-shot ICL을 수행하는 LMs의 내재적 능력을 활용한다. 
    2. Self-ICL은 테스트 입력을 받은 후, 모델을 가짜 입력을 생성하도록 유도하고, zero-shot prompting을 통해 가짜 입력에 대한 가짜 라벨을 예측한다. 마지막으로, 가짜 입력-라벨 쌍을 데모로 사용하여 테스트 입력에 대한 ICL을 수행한다. 
    3. BIG-Bench Hard 태스크 23개에 대한 평가 결과, Self-ICL은 평균 정확도와 head-to-head 비교에서 zero-shot 기준을 능가했다. 또한, zero-shot chain-of-thought와 함께 Self-ICL을 사용하면 실제 데모를 사용한 결과와 비교 가능한 성과를 얻을 수 있다.

###### Learning Knowledge-Enhanced Contextual Language Representations for Domain Natural Language Understanding (https://aclanthology.org/2023.emnlp-main.969/)
- Anthology ID: 2023.emnlp-main.969 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 지식 향상된 사전 훈련 언어 모델 (KEPLM)은 대규모 지식 그래프 (KG)에서 지식 사실을 주입하여 다양한 하위 NLP 태스크의 성능을 향상시킬 수 있다. 그러나 관계형 트리플로 KEPLM을 사전 훈련시키는 기존 방법은 충분한 도메인 그래프 의미 부족으로 인해 도메인 체계에 적응하기 어렵다.
    2. 이 논문에서는 엔티티 사이의 암묵적인 그래프 구조를 포착하여 다양한 폐쇄 도메인에 대한 지식 강화 언어 표현 학습 프레임워크인 KANGAROO를 제안한다.
    3. 실험에서 KANGAROO는 폐쇄 도메인에서 다양한 지식 고려 NLP 태스크에서 다양한 KEPLM 훈련 패러다임보다 우수한 성능을 보였다.

###### ScdNER: Span-Based Consistency-Aware Document-Level Named Entity Recognition (https://aclanthology.org/2023.emnlp-main.970/)
- Anthology ID: 2023.emnlp-main.970 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 문서 수준의 NER (Named Entity Recognition) 접근 방식은 정확하고 일관된 예측을 위해 단어 기반의 key-value memory를 통해 전역 정보를 사용한다.
    2. 그러나 단어 수준에서 전역 정보를 사용할 경우 동일한 단어가 다른 토큰 시퀀스에서 나타나고 다른 레이블을 가지는 경우에는 잡음을 도입할 수 있다.
    3. 이 논문에서는 적응적인 스팬 수준의 전역 특징 퓨전을 통해 더 정확하고 일관된 예측을 위한 두 단계로 구성된 문서 수준의 NER 모델인 ScdNER를 제안한다.

###### MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions (https://aclanthology.org/2023.emnlp-main.971/)
- Anthology ID: 2023.emnlp-main.971 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델 (LLM)에 저장된 정보는 빠르게 날아감으로써 처음부터 다시 훈련하는 것은 종종 불가능하다. 따라서 모델 가중치를 업데이트하여 새로운 사실을 주입하는 기술이 등장했다.
    2. 기존의 평가 패러다임은 수정 된 사실의 회수만 검증하기 때문에 매우 제한적이다. 그러나 한 가지 사실을 변경하면 모델의 관련된 믿음에도 변화가 발생해야 한다. 
    3. 이 논문에서는 사실이 수정된 경우 답이 변경되어야하는 문제를 평가하는 MQuAKE (Multi-hop Question Answering for Knowledge Editing) 벤치마크를 제안한다. MeLLo라는 간단한 메모리 기반 접근 방식을 제안하여 이전 모델 편집자보다 큰 폭으로 성능이 향상됨을 보여준다.

###### Stance Detection on Social Media with Background Knowledge (https://aclanthology.org/2023.emnlp-main.972/)
- Anthology ID: 2023.emnlp-main.972 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 소셜 미디어 플랫폼에서 대중 의견을 배우기 위해 특정 대상/주제에 대한 사용자의 입장을 파악하는 것은 중요한 방법이다. 
    2. 기존 연구들은 맥락에서 대상에 대한 입장을 결정하기 위해 맥락에서 대상에 대한 입장 정보를 학습하는 데 초점을 맞추었다. 
    3. 본 논문에서는 대상의 배경 지식을 고려하여 더 나은 입장 검출을 수행하는 새로운 접근 방식을 제안한다. 실험 결과로는 KASD가 대상 내/외 제약에서 최고 수준의 성능을 달성한다는 것을 보여준다.

###### Vision-Enhanced Semantic Entity Recognition in Document Images via Visually-Asymmetric Consistency Learning (https://aclanthology.org/2023.emnlp-main.973/)
- Anthology ID: 2023.emnlp-main.973 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 시각적 요소인 폰트, 배경, 색상, 바운딩 박스 위치 및 크기 등이 사전에 정의된 카테고리에 속하는 의미 있는 엔티티를 식별하는 것은 어려운 작업이다.
    2. 기존 모델은 강한 교차 모달 감독 신호로 시각 인코더를 훈련시키나, 이는 비문자적 특징을 캡처하는 능력에 제약을 가지고 성능이 좋지 않다.
    3. 이 논문에서는 색상 우선순위를 포함시켜 세밀한 시각 및 레이아웃 특징을 더 잘 포착할 수 있는 새로운 VANCL(Visually-Asymmetric coNsistenCy Learning) 접근 방식을 제안하고, 실험 결과를 통해 우리의 방법의 효과를 입증한다.

###### NormDial: A Comparable Bilingual Synthetic Dialog Dataset for Modeling Social Norm Adherence and Violation (https://aclanthology.org/2023.emnlp-main.974/)
- Anthology ID: 2023.emnlp-main.974 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사회적 규범은 대인간 의사소통에 근본적으로 영향을 미친다. 이 연구에서는 사회적 규범 준수와 위반의 턴별 어노테이션을 가진 중국과 미국 문화에 대한 고품질의 dyadic 대화 데이터셋인 NormDial을 제안한다.
    2. 우리의 데이터셋은 사회적 규범 준수 감지 작업을 소개하며, 전문가 어노테이션된 사회적 규범을 가지고 사람-모델 협업 파이프라인을 통해 중국어와 영어로 합성적으로 생성된다.
    3. 인간 평가와 기존의 대규모 언어 모델의 성능 평가를 통해 우리의 생성 대화가 고품질임을 보여주며, 이 작업에 대한 기존 대규모 언어 모델의 성능을 평가한다. 우리의 연구 결과는 언어와 문화를 아우르는 대화 맥락에서 사회적 규범의 세밀한면을 이해하기 위한 새로운 방향을 제시한다.

###### ClimateBERT-NetZero: Detecting and Assessing Net Zero and Reduction Targets (https://aclanthology.org/2023.emnlp-main.975/)
- Anthology ID: 2023.emnlp-main.975 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 지속가능한 약속에 대한 정보를 평가하는 것은 어렵기 때문에, 우리는 기업과 국가의 순수제로 및 감축목표를 자동으로 탐지하기 위한 도구를 개발했다.
    2. 전문가 주석이 달린 3.5K개의 텍스트 샘플로 데이터셋을 구축하고, ClimateBERT-NetZero라는 자연어 분류기를 훈련시켜 순수제로 및 감축목표를 포함하는 텍스트를 감지하는 모델을 공개하였다.
    3. 이 모델을 활용하여 기존의 질의응답(Q&A) 모델과 결합하여 순수제로 및 감축목표의 목표분석에 사용할 수 있으며, 분기별 소득 통화 대화 내용에서 통신 패턴이 시간에 따라 어떻게 변화하는지 분석하는 데 활용할 수 있다는 것을 보여준다.

###### Leap-of-Thought: Accelerating Transformers via Dynamic Token Routing (https://aclanthology.org/2023.emnlp-main.976/)
- Anthology ID: 2023.emnlp-main.976 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Transformers의 계산 효율성은 자원이 제한된 환경이나 실시간 응용 프로그램에서의 배포를 방해하는 오랜 문제였다. 
    2. 본 논문에서는 그 문제를 완화하기 위해 계산 효율성에 큰 기여를 하는 sequence length에 초점을 맞추어 덜 중요한 토큰들을 점진적으로 제거하는 Leap-of-Thought (LoT)이라는 새로운 토큰 축소 방법을 소개한다. 
    3. 이를 통해 LoT은 25배 더 빠른 추론 시간을 달성하면서도 정확도의 큰 손실 없이 모든 토큰에 접근할 수 있는 특징을 갖추게 된다.

###### Reinforcement Replaces Supervision: Query focused Summarization using Deep Reinforcement Learning (https://aclanthology.org/2023.emnlp-main.977/)
- Anthology ID: 2023.emnlp-main.977 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Query-focused Summarization (QfS)는 질의에 기반하여 문서에서 요약을 생성하는 시스템을 다룬다. 우리는 강화학습 (RL)이 자연어생성 문제에 있어 지도학습 (SL)보다 강한 성능을 선보인다는 점에 착안하여, QfS 작업에 RL 기반 접근법을 사용한다. 또한, Transformer에서 RL을 사용할 때 발생할 수 있는 Teacher Forcing의 충돌도 해결한다."
    2. "우리는 ROUGE, BLEU, 의미 유사성을 기반으로 학습된 다중 Policy Gradient 네트워크를 개발하였으며, 이는 벤치마크 데이터셋 (ELI5)에서 ROUGE-L 메트릭에 대한 State-of-the-Art 접근법보다 10 포인트의 개선을 이끌어냈다."
    3. "또한, 우리는 기존에 DebatePedia에 특화된 베이스라인과 비교될 수 있는 결과를 도출하는 제로샷 환경에서도 우리의 접근법의 성능을 보여주었다. 이를 위해 새로운 패시지 임베딩 방법과 함께 더 나은 의미 유사성 보상을 제안하였으며, 마지막으로 QfS와 Long-form Question Answering 연구를 위한 골드 스탠다드 테스트 데이터셋도 기여하였다."

###### Fair Text Classification with Wasserstein Independence (https://aclanthology.org/2023.emnlp-main.978/)
- Anthology ID: 2023.emnlp-main.978 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 그룹 공정은 텍스트 분류에서 중요한 연구 주제로, 여성 대 남성과 같은 민감한 그룹 간의 공정한 대우를 달성하는 것은 여전히 도전과제이다.
    2. 이 논문에서는 모델 아키텍처에 무관한 신경망 텍스트 분류에서 편견을 완화하기 위한 새로운 방법을 제시한다.
    3. 우리의 접근 방식은 민감한 속성에 대한 주석을 훈련 및 테스트 데이터에서 요구하지 않는다는 점에서 기존 방법에 비해 현실적인 시나리오에 더 적합하며, 공정성-정확성 trade-off 관점에서 기존 방법과 비교해서 유사하거나 더 나은 결과를 보여준다.

###### TacoPrompt: A Collaborative Multi-Task Prompt Learning Method for Self-Supervised Taxonomy Completion (https://aclanthology.org/2023.emnlp-main.979/)
- Anthology ID: 2023.emnlp-main.979 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자동 주제 분류를 위한 새로운 방법인 TacoPrompt는 기존의 overfitting 문제와 subtask 결과에 대한 영향을 고려하지 않는 문제를 해결하기 위해 collaborative multi-task prompt learning을 제안한다. 
    2. TacoPrompt은 prompt learning 기법을 사용하여 불균형한 학습 샘플에서 non-leaf attachment 능력을 효과적으로 학습하고, 결과 문맥을 설계하여 최종 예측과 subtask 결과 간의 관계를 강화하여 multi-task 학습을 개선한다. 
    3. 실험 결과, TacoPrompt는 세 가지 데이터셋에서 최신 주제 분류 성능을 달성하였으며, 코드는 https://github.com/cyclexu/TacoPrompt에서 확인할 수 있다.

###### An Attribution Method for Siamese Encoders (https://aclanthology.org/2023.emnlp-main.980/)
- Anthology ID: 2023.emnlp-main.980 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 시아미즈 인코더 모델인 ST와 같은 모델들이 입력에 어떤 측면에 집중하는지에 대해 잘 알려져 있지 않다. 그 이유는 ST들이 단일 입력을 처리하는 것이 아닌 두 입력을 비교하기 때문에 각각의 특성에 대해 예측을 할 수 없기 때문이다. 
    2. 이 논문은 다중 입력을 가진 모델에 대해 통합 그래디언트의 원리를 일반화하여 시아미즈 인코더에 대한 로컬 어트리뷰션 방법을 유도한다. 이 방법은 특성 쌍에 대한 어트리뷰션 형태이며, ST의 경우 토큰-토큰 행렬로 축소될 수 있다.
    3. 이 방법은 통합된 자코비안의 도입과 통합 그래디언트의 유리한 형식적 특성을 계승하며, 모델의 전체 계산 그래프를 고려하며 실제 예측에 수렴될 것임이 보장된다. 실험 결과 ST의 경우 일부 토큰 쌍이 예측을 지배할 수 있으며, ST는 주로 명사와 동사에 집중하고 있다는 것을 나타낸다. 그러나 정확한 예측을 위해서는 대부분의 토큰과 품사에도 주의를 기울여야 한다.

###### Global Voices, Local Biases: Socio-Cultural Prejudices across Languages (https://aclanthology.org/2023.emnlp-main.981/)
- Anthology ID: 2023.emnlp-main.981 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인간 편향은 문화, 언어, 사회적 경계를 가로지르며 널리 퍼져 있다. 이 연구에서는 Word Embedding Association Test (WEAT)를 24개 언어로 확장하여 언어 모델의 편향에 대한 보다 포괄적인 연구를 진행하고, 각 언어의 문화적인 컨텍스트를 살피면서 그 영향에 대해 조사한다.
    2. 특히 우리는 독다발성, 장애주의 등 다양한 편향 차원에 대한 연구를 진행하며 인도의 언어 풍경에 대해 자세한 지역 편향 분석도 수행한다.
    3. 더불어 임베딩 방법의 광범위한 비교를 통해 이러한 사회적 편향의 중요성과 새로운 차원을 강조하며, 보다 공정한 언어 모델을 위해 이러한 문제를 해결해야 함을 강조한다.

###### Graph vs. Sequence: An Empirical Study on Knowledge Forms for Knowledge-Grounded Dialogue (https://aclanthology.org/2023.emnlp-main.982/)
- Anthology ID: 2023.emnlp-main.982 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Knowledge-grounded dialogue"는 대화 기록과 외부 지식 소스를 기반으로 정보를 제공하는 작업이다. 이 작업에서는 주로 annotated knowledge graph와 website에 있는 지식 텍스트 두 가지 형태의 지식이 사용된다. 이 논문에서는 이러한 두 가지 지식 형태의 장단점과 상호 효과, 그리고 지식의 few-shot 성능에 관한 실험과 연구를 통해 기본 원칙과 결정 요소를 구분하기 위해 핵심적인 세 가지 질문에 답을 찾으려고 한다. 
    2. 적절한 지식 형태의 선택, 지식과 모델 선택 사이의 상호작용 정도, 그리고 지식의 few-shot 성능 등의 주요 질문에 대한 근거를 통해 미래 연구의 방향과 표준에 대한 결론적인 해결책과 합리적인 제안을 제시한다.
    3. 실험 결과에 기반한 통계적인 증거와 함께, 미래 연구의 방향과 표준에 대한 결론적인 해결책과 합리적인 제안을 제시한다.

###### Are Compressed Language Models Less Subgroup Robust? (https://aclanthology.org/2023.emnlp-main.983/)
- Anthology ID: 2023.emnlp-main.983 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대규모 언어 모델의 추론 비용을 줄이기 위해 모델 압축은 점점 더 사용되고 있으나, 데이터셋의 레이블과 속성에 의해 정의된 소수의 하위 그룹에 대한 강인성은 잘 알려져 있지 않다.
    2. 이 논문에서는 18가지 다른 압축 방법과 설정이 BERT 언어 모델의 하위 그룹 강인성에 미치는 영향을 조사한다.
    3. 우리는 최악의 그룹 성능이 모델 크기만큼이 아니라 사용된 압축 방법에 따라 달라짐을 보여주며, 모델 압축이 항상 소수 그룹 성능을 악화시키지는 않는다는 것을 발견했다.

###### Length Does Matter: Summary Length can Bias Summarization Metrics (https://aclanthology.org/2023.emnlp-main.984/)
- Anthology ID: 2023.emnlp-main.984 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 요약 작업에 대한 메트릭 개발은 복잡하고 종종 주관적인 작업이다. 하지만 기존의 요약 메트릭은 생성된 요약의 길이에 편향성이 존재한다는 것을 밝혀냈다.
    2. 많은 메트릭이 긴 요약을 선호하며 다른 요인들을 고려해도 긴 요약을 더 선호한다는 실험 결과를 보였다.
    3. 이 문제를 해결하기 위해 베이지안 정규화 기술을 도입하여 이러한 편향성을 줄일 수 있다고 보여주었다. 이러한 방식은 요약의 일관성 측면에서 인간의 직감과 대부분의 메트릭 사이의 조화를 크게 향상시킨다.

###### NL2TL: Transforming Natural Languages to Temporal Logics using Large Language Models (https://aclanthology.org/2023.emnlp-main.985/)
- Anthology ID: 2023.emnlp-main.985 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 공학 응용 프로그램에서 시스템에 대한 복잡한 상위 명세를 엄격하게 지정하기 위해 Temporal Logic (TL)을 사용할 수 있다. 그러나 자연어 (NL)와 TL 간의 번역은 데이터셋의 부족과 다양한 응용 분야에서의 일반화 가능한 모델의 부재로 인해 소홀히 여겨진다.
    2. 이 논문에서는 LLMs (Large Language Models)를 여러 단계에서 사용하여 NL에서 TL로의 정확하고 일반화 가능한 변환 프레임워크를 제안한다. 
    3. LLMs와 인간 주석을 조합하여 NL-TL 쌍 데이터셋을 생성하는 프레임워크를 개발하고, 23K 개의 NL-TL 쌍 데이터셋을 게시한다. 그리고 더 나은 일반화 성능을 위해 T5 모델을 미세 조정한다.

###### Reformulating NLP tasks to Capture Longitudinal Manifestation of Language Disorders in People with Dementia. (https://aclanthology.org/2023.emnlp-main.986/)
- Anthology ID: 2023.emnlp-main.986 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 치매는 의사소통을 방해하는 언어 장애와 관련이 있다. 이 연구에서는 중간 크기의 사전 학습 언어 모델을 사용하여 자연어 처리 작업과 관련된 언어 패턴에 집중하도록 강제하며 언어 장애 패턴을 자동으로 학습한다. 
    2. 실험 결과, 문맥 정보를 포함하고 언어 패턴을 향상시키는 NLP 작업은 성능에 이점을 제공한다는 것을 보여준다. 
    3. 제안된 디지털 언어 장애 표지자는 치매 환자들의 언어를 강하고 신뢰할 수 있게 특성화하여 기존의 언어 접근법보다 우수한 성능을 보여준다.

###### Elevating Code-mixed Text Handling through Auditory Information of Words (https://aclanthology.org/2023.emnlp-main.987/)
- Anthology ID: 2023.emnlp-main.987 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 코드 혼합 데이터의 인기 증가와 함께 이러한 유형의 데이터를 처리하는 방법에 대한 필요성이 높아지고 있는다. 그러나 현재의 언어 모델은 주로 단어의 의미적 표현에 초점을 두고 청각적 음성 특징을 무시하므로, 코드 혼합 텍스트의 철자 변화를 처리하기 어렵다.
    2. 본 논문에서는 SOUNDEX의 단어 청각 정보를 활용하여 코드 혼합 텍스트 데이터를 처리하는 언어 모델을 효과적으로 생성하는 접근 방식을 제안한다. 이 접근 방식은 SOUNDEX 표현 (SAMLM)을 포함하는 마스크된 언어 모델링을 기반으로하며, 사전 훈련 모델에 입력 데이터를 제공하는 새로운 방법을 포함한다.
    3. 실험 결과, 우리의 새로운 언어 모델링 접근 방식 (SAMLM)은 코드 혼합 분류 작업에서 적대적 공격에 대한 강도가 향상되었으며, 코드 혼합 작업에 대한 인기 있는 기준보다 더 좋은 분류 결과를 제공한다.

###### Predict and Use: Harnessing Predicted Gaze to Improve Multimodal Sarcasm Detection (https://aclanthology.org/2023.emnlp-main.988/)
- Anthology ID: 2023.emnlp-main.988 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "유머는 사실적인 내용과 억양, 표정, 대화의 문맥, 언어 능력 및 인지 능력과 같은 개인적 특성에 따라 복잡한 언어 구조를 가지고 있다. 이 연구에서는 대화 형태의 다중 모달 유머 감지 성능을 향상시키기 위해 합성의 시선 데이터 활용을 제안한다."
    2. 기존의 다중 모달 대화 데이터셋인 MUStARD++에 시선 특징을 추가하여 성능을 평가하였으며, 사람을 통해 데이터 일부에 대한 시선 특징을 수집하고 나머지 데이터에 대해서는 다양한 시선 특징 예측 방법을 조사하였다.
    3. 수집된 시선 특징과 예측된 데이터를 결합하여 학습한 모델이 MUStARD++ 데이터셋에서 SoTA 성능을 달성하였으며, 유머 감지에 대한 예측 및 활용 모델은 처음으로 공개되었다.

###### Fine-grained Medical Vision-Language Representation Learning for Radiology Report Generation (https://aclanthology.org/2023.emnlp-main.989/)
- Anthology ID: 2023.emnlp-main.989 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 방사선학적 이미지를 입력으로 받아 의료 보고서 생성을 목표로 하는 방사선 보고서 생성에서 기존 연구들은 일반적으로 이미지의 시각적 표현을 추출하기 위해 사전 훈련된 비전 인코더에 의존하였습니다. 
    2. 본 연구에서는 시각과 텍스트 모달리티 간의 간극을 효과적으로 해소하기 위해 페노타입에 의존한 의료 시각-언어 표현 학습 프레임워크를 제안합니다. 
    3. 기존 방법과 달리 우리의 접근법은 이미지를 전체 보고서와 대조시키는 대신 이미지를 보고서 내의 각 문장과 대조하여 더 세부적인 표현을 학습하며, 이 학습된 세부 표현은 방사선 보고서 생성의 성능을 향상시킬 수 있습니다.

###### ViT-TTS: Visual Text-to-Speech with Scalable Diffusion Transformer (https://aclanthology.org/2023.emnlp-main.990/)
- Anthology ID: 2023.emnlp-main.990 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. TTS(Text-to-speech) 기술은 DDPM (Denoising Diffusion Probabilistic Models)의 등장으로 성능이 크게 향상되었지만, 오디오의 인지 품질은 내용, 음높이, 리듬, 에너지뿐만 아니라 물리적 환경에도 영향을 받는다. 이 연구에서는 ViT-TTS라는 첫 번째 시각적 TTS 모델을 제안하여 시각 정보를 포함하여 고 품질의 오디오를 생성함으로써 AR 및 VR의 실용적인 응용 프로그램에 새로운 기회를 제공한다.
    2. 우리는 시각-텍스트 인코더와 노이즈 제거 디코더를 강화하기 위한 자가 지도 학습 프레임워크를 도입하고, 시각적인 장면 정보를 학습하기 위해 매개변수와 용량 측면에서 확장 가능한 확산 트랜스포머 (diffusion transformer)를 활용한다.
    3. 실험 결과, ViT-TTS는 시각적 장면의 가시성에 관계없이, 단순한 시스템 및 기준선보다 우수한 신문 기록을 달성하며, 저 자원 데이터에서도 (1시간, 2시간, 5시간) 풍부한 자원 기준선과 비교 가능한 결과를 달성한다.

###### Consistency Analysis of ChatGPT (https://aclanthology.org/2023.emnlp-main.991/)
- Anthology ID: 2023.emnlp-main.991 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. ChatGPT의 신뢰성과 신뢰성에 대한 의심을 조사한 논문이다. ChatGPT는 언어 이해와 추론 능력이 향상되었지만, 논리적으로 일관된 예측을 자주 만들지 못한다는 결과가 나타났다.
    2. 이 논문은 특히 의미적 일관성과 부정, 대칭 및 추이성과 같은 속성에 주목하여 ChatGPT와 GPT-4의 논리적으로 일관된 행동에 대한 신뢰성을 조사한다. 
    3. 실험을 통해 prompt 설계, few-shot learning 및 큰 언어 모델 (LLM)의 사용이 일관성 문제를 해결하는 궁극적인 해결책이 아님을 확인하였다.

###### Do Differences in Values Influence Disagreements in Online Discussions? (https://aclanthology.org/2023.emnlp-main.992/)
- Anthology ID: 2023.emnlp-main.992 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 온라인 토론에서 의견 차이는 일반적이다. 의견 차이는 일부 조건에서 협력을 촉진하고 토론의 품질을 향상시킬 수 있다. 
    2. 본 논문에서는 차이점에 따른 의견 차이를 예측하기 위해 최신 모델을 사용하고, 예측된 가치를 합산하여 가치 프로필을 만드는 방법을 제안한다. 
    3. Human-annotated agreement labels로 평가한 결과, 가치 프로필의 차이는 특정 경우에 의견 차이와 관련이 있다는 것을 발견하였고, 의견 예측에 가치 정보를 포함시키면 성능이 향상됨을 확인하였다.

###### Automated Fact-Checking in Dialogue: Are Specialized Models Needed? (https://aclanthology.org/2023.emnlp-main.993/)
- Anthology ID: 2023.emnlp-main.993 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 이전 연구에서는 독립적인 주장에 대한 사실 확인 모델이 대화에서 제기된 주장에 대해 어려움을 겪는 것으로 나타났다. 이 문제에 대한 해결책으로 대화 데이터 위에 모델을 fine-tuning 하는 것이 제안되었다.
    2. 그러나 각 use case마다 별도의 모델을 만드는 것은 실용적이지 않으며, 대화를 위한 모델 fine-tuning은 일반적인 사실 확인에 대한 성능을 저하시킨다는 것을 보여주었다.
    3. 이러한 도전을 극복하기 위해, 대화를 위해 학습된 모델로 적합하게 대화를 처리하기 위해 검색 적응 및 대화형 입력 변환과 같은 기술을 제안한다. 이러한 기술을 적용한 일반적인 사실 확인 모델이 최신 대화 모델과 경쟁력을 유지하면서 독립적인 주장에 대한 성능을 유지할 수 있는 것을 보여준다.

###### A Digital Language Coherence Marker for Monitoring Dementia (https://aclanthology.org/2023.emnlp-main.994/)
- Anthology ID: 2023.emnlp-main.994 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 주관하지 않은 치매 진단 및 관리를 위해 spontaneous language를 사용하여 디지털 마커를 도출하는 방법이 급부상하고, 유망하며 비침투적인 방법이 되었다.
    2. 디지털 일관성 마커를 도입하여 치매 환자의 인지 변화를 모니터링하는 비용 효율적이고 사람이 이해할 수 있는 디지털 마커를 캡처하는 방법을 제안한다.
    3. 이 연구에서는 짧은 기록된 이야기에서 말의 논리적 일관성을 학습하기 위한 새로운 과제를 제시하고 다양한 신경 접근법을 조사한다. 이 연구는 치매와 건강한 대조군 간의 일관성 패턴을 비교하고 세 가지 임상 생체 마커와의 장기간 평가를 통해 제안된 디지털 일관성 마커의 신뢰성을 조사한다.

###### Detecting Spoilers in Movie Reviews with External Movie Knowledge and User Networks (https://aclanthology.org/2023.emnlp-main.995/)
- Anthology ID: 2023.emnlp-main.995 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 영화 리뷰 플랫폼은 영화 산업과 일반인에게 큰 영향을 주는데, 스포일러 리뷰는 사용자 경험을 크게 해치고 있다. 이전 연구들은 리뷰 내용에 초점을 맞추었지만, 실질적인 스포일러 탐지를 위해서는 영화에 관한 사실과 지식, 사용자 행동 등을 고려해야 한다.
    2. 따라서 이 논문에서는 큰 규모의 스포일러 탐지 데이터셋과 포괄적이며 최신의 영화 지식 디비를 확보하였고, 이를 이용한 스포일러 탐지 모델인 MVSD를 제안한다. MVSD는 영화에 대한 외부 지식과 사용자의 리뷰 플랫폼 활동을 고려하는 모델로, 다양한 데이터 소스와 다중 속성을 모델링하기 위해 세 가지 연결된 이질적 정보 네트워크를 구축한다.
    3. 실험 결과, MVSD는 스포일러 탐지 데이터셋에서 기술적으로 성능이 향상되었고, 외부 지식과 사용자 상호작용의 도입으로 검증 가능한 스포일러 탐지가 가능하다는 것을 보여준다.

###### Joyful: Joint Modality Fusion and Graph Contrastive Learning for Multimoda Emotion Recognition (https://aclanthology.org/2023.emnlp-main.996/)
- Anthology ID: 2023.emnlp-main.996 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 다중 모달 감정인식은 인간-기계 상호작용에서 사용되는 각 발화의 감정을 여러 모달리티에서 인식하는 것을 목표로 한다. 하지만 현재의 그래프 기반 방법들은 대화에서의 전역적인 문맥적 특징과 개별 모달의 다양한 특징을 동시에 묘사하는 데 실패한다. 
    2. 이 논문에서는 Joyful이라는 다중 모달 감정인식을 위한 모달리티 퓨전과 그래프 대조 학습을 동시에 최적화하는 방법을 제안한다. 특히, 글로벌 문맥 및 개별 모달 특징 간의 깊은 상호작용과 융합을 제공하는 새로운 다중 모달 퓨전 메커니즘을 설계한다.
    3. 세 개의 벤치마크 데이터셋에서의 실험 결과는 Joyful이 모든 베이스라인과 비교하여 최고 성능을 달성했음을 보여준다. (SOTA performance)

###### HyperRank: Hyperbolic Ranking Model for Unsupervised Keyphrase Extraction (https://aclanthology.org/2023.emnlp-main.997/)
- Anthology ID: 2023.emnlp-main.997 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 웹 상의 문서 개수가 급격히 증가함에 따라, 해당 문서에서 핵심 키워드를 정확하게 추출하는 모델에 대한 수요가 증가하고 있다. 
    2. 본 논문에서는 일반적으로 후보 키워드는 복잡한 문법 및 의미 정보가 내재된 잠재적인 계층 구조를 갖고 있고, 후보 키워드와 문서 간의 관계 역시 계층 구조를 이루기 때문에, 이러한 계층 구조를 고려하는 것이 중요하다. 
    3. 기존의 모델들이 이러한 계층 구조를 간과하여 잘못된 키워드 추출 결과를 만드는 문제를 해결하기 위해, 본 논문은 HyperRank라는 새로운 하이퍼볼릭 랭킹 모델을 제안하였고, 실험 결과 이 모델이 최근의 최고 성능 모델들보다 우수한 성능을 보여준다.

###### Assessing the influence of attractor-verb distance on grammatical agreement in humans and language models (https://aclanthology.org/2023.emnlp-main.998/)
- Anthology ID: 2023.emnlp-main.998 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "주어와 동사간에 위치한 attractor noun은 복잡한 행동을 유발한다. 'The girl near the boys likes climbing.' 이 문장에서 attractor (boys)와 동사 (likes) 간의 grammatical number가 일치하지 않아 문맥상 불가능한 전이 확률을 만든다."
    2. 인공 신경망 모델과 인간의 성능을 비교해 보았고, attractor가 동사에 더 가까워지면 양측 다 실수를 더 많이 하지만, 인간은 주로 attractor의 간섭을 극복할 수 있다. 또한, attractor와 동사 사이의 거리가 반응 시간에도 선형적인 영향을 미친다는 것을 보고했다. 
    3. 이 논문에서는 adjacent words 간의 전이 확률 계산이 근접 효과 (proximity effect)에 영향을 줄 수 있다는 가설을 제시하였다. 그러나 cue-based model과 같은 전통적인 attraction 모델로 이 현상을 설명하는 것은 충분하다고 주장하며, 새로운 연구의 길을 열 수 있다고 주장한다.

###### Federated Meta-Learning for Emotion and Sentiment Aware Multi-modal Complaint Identification (https://aclanthology.org/2023.emnlp-main.999/)
- Anthology ID: 2023.emnlp-main.999 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 소비자들이 구매한 상품 또는 서비스에 대한 불만을 자동으로 감지하는 것은 기업과 온라인 상인들에게 매우 중요하다. 기존의 고객 불만 식별 연구는 텍스트에만 국한되어 있으며, 리뷰와 함께 이미지를 사용하는 것이 더 나은 불만 식별을 위한 단서를 제공할 수 있다는 중요성을 강조한다.
    2. 고객의 감정상태가 불만 표현에 큰 영향을 미치기 때문에, 감정과 감성이 불만 식별에 미치는 영향도 조사되어야 한다. 
    3. 이 논문에서는 아마존 웹사이트에 게시된 제품 리뷰와 이미지의 다중 모달 불만 데이터셋을 사용하여, 감정 인식과 감성 분석을 보조 과제로 고려하는 다중 모달 다중 태스크 프레임워크를 제안하였으며, 실험 결과는 제안된 접근법이 기준과 최신 기법을 따른 경우에 비해 더 우수한 성능을 보여준다.

###### Semantic Similarity Models for Depression Severity Estimation (https://aclanthology.org/2023.emnlp-main.1000/)
- Anthology ID: 2023.emnlp-main.1000 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 우울 장애는 전 세계적으로 심각한 공중 보건 문제이지만 공중 보건 시스템은 증례 탐지와 진단에 제한된 용량을 가지고 있다. 
    2. 이 논문은 사회적 미디어를 통해 얻은 대중 정보를 활용하여 빠른 스크리닝을 위한 컴퓨터 기반 방법을 제시한다. 
    3. Reddit 기반 벤치마크에서 우리의 방법을 평가한 결과, 우울 수준 측정을 향상시킨다.

###### Hop, Union, Generate: Explainable Multi-hop Reasoning without Rationale Supervision (https://aclanthology.org/2023.emnlp-main.1001/)
- Anthology ID: 2023.emnlp-main.1001 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 설명 가능한 멀티합 질문응답 시스템은 응답뿐만 아니라 응답을 도출하는 데 사용되는 입력 문장의 부분집합인 rationales(유의성을 가진 문장)을 식별한다. 기존의 방법들은 응답과 rationales에 대한 감독이 필요하다는 문제점이 있다.
    2. 이 논문은 rationales 감독 없이 설명 가능한 멀티합 QA 시스템을 교육하는 확률적 접근법을 제안한다. 모델이 문서 간 상호작용과 문서 내 문장 간의 상호작용을 파악할 수 있도록 rationales을 집합으로 명시적으로 모델링한다.
    3. 실험 결과, 이 방법은 이전 방법보다 rationales 선택에서 더 정확하며, 응답 예측에서는 유사한 정확도를 유지한다.

###### To Split or Not to Split: Composing Compounds in Contextual Vector Spaces (https://aclanthology.org/2023.emnlp-main.1002/)
- Anthology ID: 2023.emnlp-main.1002 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 독일어 명사 합성어의 표현에 서브워드 토큰화가 미치는 영향을 조사하였다. 명사 합성어는 두 개 이상의 요소로 이루어져 있지만, 종종 형태론적으로 동기부여되거나 의미 있는 단위로 토큰화되지 않는다.
    2. BERT 모델의 변형과 토큰화 전략을 도메인 특정 제한된 시간 경과 데이터에 적용하여, 가려진 언어 모델링 작업과 합성성 예측에 의존하는 평가 스위트를 도입하였다.
    3. 우리는 합성어를 요소로 분할하면 가장 일관된 개선을 얻을 수 있었다.

###### ToolWriter: Question Specific Tool Synthesis for Tabular Data (https://aclanthology.org/2023.emnlp-main.1003/)
- Anthology ID: 2023.emnlp-main.1003 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Tabular question answering (TQA)은 자연어와 반 구조화된 데이터의 공동 추론을 요구하여 신경망 모델에 대한 도전적인 설정을 제시한다.
    2. 이 논문에서는 ToolWriter를 제안하여 쿼리별 프로그램을 생성하고 언제 어떤 프로그램을 적용할지 판단하여 테이블을 변환하고 TQA 모델의 능력에 맞추도록 한다.
    3. ToolWriter로 행 필터링 도구를 생성하는 것은 WikiTableQuestions 및 WikiSQL의 최고 성능을 향상시키며, 긴 테이블에서 가장 많은 성능 향상을 얻을 수 있다는 것을 보여준다.

###### Interactive Text-to-SQL Generation via Editable Step-by-Step Explanations (https://aclanthology.org/2023.emnlp-main.1004/)
- Anthology ID: 2023.emnlp-main.1004 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. SQL과 같은 데이터베이스 언어에 익숙하지 않은 사용자들은 데이터베이스의 분석력을 충분히 발휘할 수 없다. 
    2. 이 논문에서는 사용자가 직접 단계별 질의문 설명을 편집하여 오류를 수정할 수 있는 새로운 상호작용 메커니즘을 소개한다. 
    3. 실험 결과와 사용자 연구를 통해 이 방법은 다른 SOTA 접근법들보다 더 우수한 성능을 보여준다.

###### CoCo: Coherence-Enhanced Machine-Generated Text Detection Under Low Resource With Contrastive Learning (https://aclanthology.org/2023.emnlp-main.1005/)
- Anthology ID: 2023.emnlp-main.1005 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "Machine-Generated Text (MGT) 감지는 최근 인간의 글 쓰기 스타일을 모방하는 텍스트 생성 모델의 오용을 방지하는 중요한 작업이다. 기존 방법들은 텍스트 시퀀스를 그대로 사용하고, 사전 학습된 모델을 cross-entropy 손실과 함께 fine-tuning하지만, 이러한 방법들은 텍스트의 언어적 구조를 고려하지 못한다. 또한, 방대한 양의 텍스트 데이터가 온라인에 존재하는 것을 감안할 때, 저자원(low-resource) 문제를 해결할 능력이 부족하다."
    2. "우리는 의미 연결성(coherence)을 기반으로 한 대조 학습 모델인 CoCo를 제안하여 저자원 시나리오에서 MGT를 탐지한다. 언어적 기능을 활용하기 위해 의미 연결정보를 그래프 형태로 텍스트 표현에 인코딩한다. 또한, 우리는 대조 학습 프레임워크를 사용하여 데이터 자원이 불충분한 상황에서 단순 샘플로 인해 발생할 수 있는 성능 하락을 방지하기 위해 개선된 대조 손실을 제안한다."
    3. "두 개의 공개 데이터셋과 두 개의 자체 구축 데이터셋을 사용한 실험 결과, 우리의 접근 방식이 최신 언어 모델에서 생성된 MGT를 이전 모델에서 생성된 MGT보다 더 쉽게 탐지할 수 있다는 것을 놀랍게도 발견했다. 그리고 이러한 역설적 현상에 대한 몇 가지 초기 설명을 제시했다. 모든 코드와 데이터셋은 공개되어 있다."

###### AnyTOD: A Programmable Task-Oriented Dialog System (https://aclanthology.org/2023.emnlp-main.1006/)
- Anthology ID: 2023.emnlp-main.1006 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "우리는 AnyTOD라는 zero-shot task-oriented dialog (TOD) 시스템을 제안하는데, 이 시스템은 처음 보는 과제나 도메인에 대해 zero-shot으로 적응이 가능하다. TOD를 언어 모델 (LM)에 의해 실행되는 프로그램으로 본다. 이를 위해 신경 기호로 구성된 접근 방식을 채택하였다."
    2. "AnyTOD는 대화 중 발생하는 이벤트를 기억하는 신경망 기반의 LM과 대화 정책을 실행하는 심볼릭 프로그램을 사용하여 작동한다. 이를 통해 초기 학습 없이 새로운 스키마와 프로그램에 일반화할 수 있으며, 데이터 주석 및 모델 학습 요구를 크게 줄일 수 있다."
    3. "우리는 STAR, ABCD 및 SGD 벤치마크에서 최고의 결과를 보여주었으며, MultiWOZ에 대한 zero-shot 전이 능력과 같은 저자원 환경에서 강력한 제로샷 전이 능력을 증명하였다. 또한, 업데이트된 STAR 데이터셋인 STARv2를 공개하여 end-to-end TOD 모델의 제로샷 과제 전이를 벤치마킹하였다."

###### Can LMs Generalize to Future Data? An Empirical Analysis on Text Summarization (https://aclanthology.org/2023.emnlp-main.1007/)
- Anthology ID: 2023.emnlp-main.1007 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 최근 pre-trained 언어 모델들이 기존 요약 데이터셋에서 유망한 결과를 도출하고 있으나, 이러한 모델들의 강력한 성능은 pre-training과 fine-tuning 과정에서 기록된 매개지식에 의존할 가능성이 높다. 
    2. 본 연구에서는 2010년부터 2022년까지의 데이터 샘플을 포함한 새로운 벤치마크인 TempoSum을 제안하여 시간에 따른 요약 모델의 일반화 능력을 이해한다. 
    3. 인간 평가 결과를 통해 pre-trained 요약 모델에 저장된 매개지식이 미래 데이터에서 생성된 요약문의 충실성에 상당한 영향을 미치는 것을 확인하였으며, 기존의 충실성 증진 방법은 미래 데이터에 대한 요약 모델의 충실성을 신뢰성 있게 개선하지 못한다는 결론을 도출하였다.

###### Zero-Shot Multi-Label Topic Inference with Sentence Encoders and LLMs (https://aclanthology.org/2023.emnlp-main.1008/)
- Anthology ID: 2023.emnlp-main.1008 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 본 논문에서는 최신 Sentence Encoder와 Large Language Model (LLM)을 사용하여 "definition-wild zero-shot topic inference"라는 어려운 작업에 대해 포괄적인 연구를 수행하였다. 
    2. 7개의 다양한 데이터셋에서 수행한 실험에서, ChatGPT-3.5와 PaLM과 같은 LLM이 다른 LLM인 BLOOM과 GPT-NeoX와 비교해 더 우수한 일반성을 보였다. 
    3. 또한, BERT 기반의 전통적인 Sentence Encoder인 Sentence-BERT는 PaLM을 능가하며, ChatGPT-3.5와 유사한 성능을 달성하였다.

###### TaskDiff: A Similarity Metric for Task-Oriented Conversations (https://aclanthology.org/2023.emnlp-main.1009/)
- Anthology ID: 2023.emnlp-main.1009 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화형 디지털 어시스턴트의 인기로 인해 향상된 사용자 경험과 맞춤형 응답 생성을 위해 대화형 데이터를 활용할 수 있다. 
    2. ChatGPT와 같은 대규모 언어 모델을 사용하여 이러한 어시스턴트를 구축하는 것은 프롬프트 공학과 평가 방법에 대한 추가적인 주의가 필요하다.
    3. TaskDiff는 고유한 대화형 특징을 활용하지 않으므로 문제 지향 대화에 효과적이지 않은 기존의 유사도 메트릭을 보완하기 위해 대화 구성 요소(호출, 의도, 슬롯)와 그 분포를 사용하여 유사도를 계산하는 새로운 대화기반 유사도 메트릭을 제안한다.

###### Not all Fake News is Written: A Dataset and Analysis of Misleading Video Headlines (https://aclanthology.org/2023.emnlp-main.1010/)
- Anthology ID: 2023.emnlp-main.1010 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 악의적인 내용들이 많아지면서 온라인에서 정보를 탐색하는 것이 어려워졌고, 가짜 또는 오해를 일으키는 텍스트를 감지하는 데 많은 노력이 기울여져왔지만, 다중모달 데이터셋에는 상대적으로 적은 관심이 있었다.
    2. 이 논문에서는 기존 자료를 보완하기 위해, 사람들이 동영상 제목이 해당 동영상의 내용을 충분히 나타내는지 여부를 판단한 다중모달 비디오 잘못된 헤드라인 (VMH) 데이터셋을 제공한다.
    3. 데이터셋 수집 및 주석 작업을 마친 후, 우리는 잘못된 헤드라인을 탐지하기 위한 다중모달 기준선을 분석했으며, 주석 작업 과정에서 주석 작성자의 배경과 동영상의 내용의 상호작용을 더 잘 이해할 수 있었다.

###### Learning From Free-Text Human Feedback – Collect New Datasets Or Extend Existing Ones? (https://aclanthology.org/2023.emnlp-main.1011/)
- Anthology ID: 2023.emnlp-main.1011 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 오늘날의 챗봇과 가상어시스턴트는 최신 정보를 반영하고 매력적이며 사회적으로 인정받기 위해 오류 수정, 새로운 지식, 대체 응답과 같은 자유롭게 임의의 텍스트를 이용하여 지속적으로 학습해야한다.
    2. 그러나 이러한 데이터로부터 학습하는 방법에 대한 연구를 위한 주석이 달린 데이터는 희소하다.
    3. 이 논문에서는 MultiWoZ, PersonaChat, Wizards-of-Wikipedia 등 다양한 유형의 인기있는 대화 데이터셋의 오류와 사용자 응답 유형을 조사하여 필요한 주석과의 연장성을 평가한다.

###### Euphemistic Abuse – A New Dataset and Classification Experiments for Implicitly Abusive Language (https://aclanthology.org/2023.emnlp-main.1012/)
- Anthology ID: 2023.emnlp-main.1012 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "우리는 은어적 학대를 파악하는 과제를 다루며, 일반적인 학대적 발언을 다른 형태로 바꾸는 과제에 대해 소개한다. 이를 위해 크라우드소싱을 통해 새로운 데이터셋을 생성하였으며, 학대가 아닌 데이터의 생성에 특히 신경을 썼다."
    2. "우리는 과거의 데이터셋에서 학습된 분류기들이 이러한 학대를 감지하는 데 덜 효과적임을 실험을 통해 보여준다."
    3. "우리는 기존 데이터셋과 GPT-3 모델의 자동 생성 데이터를 결합한 분류기가 가장 좋은 자동 결과를 나타내고, 또한 상징적인 리엥귀스틱 현상을 나타내는 몇 가지 수동 추출 특징을 결합한 분류기도 제시한다."

###### Exploring Distributional Shifts in Large Language Models for Code Analysis (https://aclanthology.org/2023.emnlp-main.1013/)
- Anthology ID: 2023.emnlp-main.1013 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. "CodeT5, Codex, ChatGPT"과 같은 대형 언어 모델이 도메인 범위를 벗어나는 데이터에 대해 어떻게 일반화되는지 체계적으로 연구했습니다. 
    2. "code summarization"과 "code generation"이라는 두 가지 기본적인 응용에 대해 연구했습니다. 
    3. multitask 학습과 few-shot finetuning을 결합하면 적은 데이터에서도 강력한 성능을 달성할 수 있다는 것을 실험적으로 보여주었습니다.

###### ATHENA: Mathematical Reasoning with Thought Expansion (https://aclanthology.org/2023.emnlp-main.1014/)
- Anthology ID: 2023.emnlp-main.1014 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 수학 문제를 해결하기 위해서는 모델이 인간 언어 표현을 바라보는 렌즈, 문제의 표현 방법에 따라 달라진다. 현실 세계의 경우 마찬가지로 같은 수학적 연산에 대해 다양한 방법이 존재하기 때문에 이러한 방법이 더욱 중요해진다.
    2. 이 논문에서는 인간의 사고 확장 메커니즘을 신경망 전파(Neural Network Propagation) 형태로 모방하는 Attention-based THought Expansion Network Architecture (ATHENA)를 제안한다.
    3. 실험 결과, ATHENA는 훈련 예제의 정보성이 제한되었을 때에도 다양한 질문에 강력한 성능을 발휘하여 이상적인 모델에 한 걸음 더 가까워졌다는 것을 보여준다.

###### A Benchmark for Reasoning with Spatial Prepositions (https://aclanthology.org/2023.emnlp-main.1015/)
- Anthology ID: 2023.emnlp-main.1015 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 공간적 추론은 인간의 인지 과정에서 기본적인 구성 요소이며, 물리적 및 추상적 개념에 대한 표현, 기초 및 추론에 사용된다. 
    2. 우리는 공간 전치사 특성이 있는 문장의 추론 속성을 평가하는 새로운 벤치마크를 제안한다. 
    3. 우리의 결과는 작고 큰 모델들 간, 그리고 프롬프트와 언어에 따라 성능에 상당한 변동성을 보이지만, 어떤 모델도 인간의 성능에 도달하지 못한다는 것을 보여준다.

###### TIMELINE: Exhaustive Annotation of Temporal Relations Supporting the Automatic Ordering of Events in News Articles (https://aclanthology.org/2023.emnlp-main.1016/)
- Anthology ID: 2023.emnlp-main.1016 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 시간적 관계 어노테이션을 통한 temporal relation extraction은 inter-annotator 합의도 낮고, 문단 간 관계나 동사가 아닌 이벤트를 배제하는 문제가 있다.
    2. 본 논문에서는 기준에 따라 temporal relations을 명확하게 어노테이션할 수 있는 새로운 주석 체계를 제안한다.
    3. 또한, 문서 내의 long-distance 관계와 동사가 아닌 이벤트를 포함한 temporal relations 어노테이션을 자동화하는 방법을 제안하여 annotator의 시간과 수작업을 줄일 수 있는 새로운 데이터셋인 TIMELINE corpus를 도출하였다.

###### Mitigating Over-Generation for Unsupervised Keyphrase Extraction with Heterogeneous Centrality Detection (https://aclanthology.org/2023.emnlp-main.1017/)
- Anthology ID: 2023.emnlp-main.1017 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 키워드 추출 모델에서 over-generation 오류가 발생하는데, 이는 문서 내에 자주 나타나는 단어를 포함하고 있기 때문에 후보 키워드를 올바르게 키워드로 결정하지만, 동시에 동일한 단어를 포함한 다른 후보를 잘못된 키워드로 출력하는 것이다. 이 문제를 완화하기 위해 우리는 동일한 후보 각각에 대한 중요성 점수로서 이질적 그래프 내에서 암시적 및 명시적 중심성을 동시에 식별하는 새로운 CentralityRank 방법을 제안한다.
    2. CentralityRank는 입력 문서 내용을 충분히 활용하여 구문 이외의 의미 노드도 포함하도록 그래프를 구성하며, 후보 키워드 간의 상호 관계를 강화하는 중개자 역할을 한다.
    3. 우리는 후보 키워드의 위치 정보를 활용하여 후보 키워드의 중요성에 영향을 주는 새로운 적응형 경계 정보를 제안한다. 광범위한 실험 결과는 CentralityRank가 최근의 최첨단 비지도 키워드 추출 기준과 비교하여 성능이 우수함을 보여준다.

###### Towards Interpretable and Efficient Automatic Reference-Based Summarization Evaluation (https://aclanthology.org/2023.emnlp-main.1018/)
- Anthology ID: 2023.emnlp-main.1018 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 신경망 자동 메트릭의 채택을 위해 해석 가능성과 효율성은 중요한 고려 사항이다. 
    2. 이 논문에서는 원본 텍스트에서 기본 정보 단위를 추출한 뒤, 추출된 단위를 다른 텍스트 시퀀스와 비교하는 두 단계 평가 파이프라인을 기반으로 한 요약 평가를 위한 강력한 자동 메트릭을 개발한다. 
    3. 이 논문에서는 고도로 해석 가능한 두 단계 메트릭과 효율성과 해석 가능성 사이의 균형을 이룬 단계 메트릭을 개발하였다.

###### MAUD: An Expert-Annotated Legal NLP Dataset for Merger Agreement Understanding (https://aclanthology.org/2023.emnlp-main.1019/)
- Anthology ID: 2023.emnlp-main.1019 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 법적 텍스트의 독해는 길고 복잡한 법조 및 전문 가이드의 부족으로 인해 특히 어려운 작업일 수 있다. 이 도전에 대응하기 위해 MAUD라는 벤치마크로써 사용될 수 있는 전문가 주석이 달린 독해 데이터셋을 소개한다.
    2. MAUD에는 39,000개 이상의 예시와 총 47,000개 이상의 주석이 달려있다. Transformer 모델을 fine-tune한 결과, 대부분의 질문에서 모델의 성능이 랜덤보다 훨씬 우수한 결과를 보여주지만, 여전히 상당한 개선의 여지가 있는 경우도 존재한다.
    3. MAUD는 법률 전문가 및 NLP 커뮤니티 모두에게 유용한 벤치마크로서 가치가 있다.

###### PK-ICR: Persona-Knowledge Interactive Multi-Context Retrieval for Grounded Dialogue (https://aclanthology.org/2023.emnlp-main.1020/)
- Anthology ID: 2023.emnlp-main.1020 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 대화 시스템에서 관련된 persona나 지식을 식별하는 것은 대화 응답 생성에 있어서 중요하다. 하지만, 최근 연구는 개별적인 맥락에서 대부분 이루어져 왔기 때문에 다중 맥락 대화 작업에서는 부족하다. 
    2. 우리는 주어진 대화에 대해 persona와 지식을 동시에 식별하는 Dual Context Identification task를 정의하였다. 이는 복잡한 다중 맥락 대화 설정에서 중요할 수 있다. 
    3. 우리는 대화의 모든 맥락을 동시에 활용하는 새로운 grounding retrieval 방법을 개발하였고, neural QA retrieval 모델을 활용하여 계산 비용을 줄일 수 있다. 또한, 데이터 augmentation과 관련된 의미론적으로 다른 샘플들에 대한 순위 성능을 측정하는 새로운 null-positive rank test를 제안한다.

###### More Than Spoken Words: Nonverbal Message Extraction and Generation (https://aclanthology.org/2023.emnlp-main.1021/)
- Anthology ID: 2023.emnlp-main.1021 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 비언어적 메시지 (NM)는 대화를 위한 핵심적인 역할을 하지만 기존의 대화 이해나 생성 과제에는 포함되지 않아 암묵적인 지식으로 간주된다. 이 논문은 문서에서 NM을 추출하고 말된 문장에 대한 NM을 생성하는 작업을 소개한다.
    2. 이전 연구들은 NM을 괄호로 둘러싼 영화 스크립트와 같은 상대적으로 작고 잘 구조화된 말뭉치에서만 NM을 추출하는데 초점을 두어 추출의 어려움을 크게 줄였다.
    3. 이 논문에서는 무구조 말뭉치에서 NM을 추출할 수 있도록 중국 소설을 기반으로 첫 번째 NM 추출 데이터셋을 주석을 부여하고 이를 사용하여 NM 생성을 향상시키는 반지도 학습을 수행한다.

###### Can language models learn analogical reasoning? Investigating training objectives and comparisons to human performance (https://aclanthology.org/2023.emnlp-main.1022/)
- Anthology ID: 2023.emnlp-main.1022 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 단어 임베딩 평가 방법인 비유가 NLP에서 일반적이기는 하지만, 비유 추론이 수행 가능한 과제인지 여부를 알아보는 것도 흥미롭다. 
    2. 이 논문에서는 인간의 비유 추론을 평가하는 데 사용되는 것들보다 일반적인 비유를 학습하는 몇 가지 방법을 실험해보았다. 
    3. 우리의 실험에서는 모델이 소량의 데이터에서도 비유 추론을 학습할 수 있음을 보여주었으며, 인간의 기준과 모델의 성능을 비교하였을 때 모델의 성능이 인간과 유사하게 나타났다.

###### FAME: Flexible, Scalable Analogy Mappings Engine (https://aclanthology.org/2023.emnlp-main.1023/)
- Anthology ID: 2023.emnlp-main.1023 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 유추(analogy)는 인간의 인지 능력 중 하나로, 새로운 상황에서 우리는 종종 다른 도메인의 이전 경험을 전이한다. 그러나 대부분의 컴퓨터 유추 연구는 복잡하고 수동으로 구성된 입력에 크게 의존한다.
    2. 이 연구에서는 Entity의 이름만을 매핑하기 위해 요구하는 입력 요구를 완화한다. 우리는 자동으로 상식적 표현을 추출하고 이를 사용하여 Entity 간의 매핑을 식별한다.
    3. 우리의 프레임워크는 부분적인 유추를 처리하고 새로운 Entity를 제안할 수 있다. 또한, 우리의 방법은 쉽게 해석 가능하므로 사용자는 특정 매핑이 선택된 이유를 이해할 수 있다. 실험 결과, 우리 모델은 2x2 유명한 문제의 81.2% (근사 수준 50%)을 정확하게 매핑한다. 더 큰 문제에서는 77.8%의 정확도를 달성한다. 또 다른 실험에서 우리는 우리의 알고리즘이 인간의 성능을 능가하며, 자동으로 제안된 새로운 Entity는 인간이 제안한 것과 유사하다는 것을 보여준다.

###### A Self-training Framework for Automated Medical Report Generation (https://aclanthology.org/2023.emnlp-main.1024/)
- Anthology ID: 2023.emnlp-main.1024 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 의료 리포트 생성은 의료 인공지능 태스크에서 중요한 역할을 하는데, 의료 이미지에서 정확한 임상 소견을 자동으로 생성함으로써 의사의 작업을 줄인다. 
    2. 기존 방법들은 이미지-리포트 쌍 데이터셋에 의존하기 때문에, 의사가 레이블링한 데이터셋을 활용하기 어렵다. 
    3. 이 논문에서는 비레이블링된 의료 이미지와 참조 없는 평가 메트릭을 활용하여 작은 규모의 의료 리포트 생성 데이터셋을 보완하는 self-training framework인 REMOTE를 소개한다.

###### A Picture is Worth a Thousand Words: Language Models Plan from Pixels (https://aclanthology.org/2023.emnlp-main.1025/)
- Anthology ID: 2023.emnlp-main.1025 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 계획 수립은 현실 세계 환경에서 장기 과제를 수행하는 인공 에이전트의 중요한 능력이다. 본 연구에서는 미리 훈련된 언어모델(PLM)을 사용하여 체감 시각적 환경에서 텍스트 지시에 대한 계획 시퀀스를 추론하는 방법을 탐색한다.
    2. 기존의 PLM 기반 계획 방법은 텍스트로써의 관찰이 입력되거나, 지시문만으로부터 계획을 추론하거나, 시각적 환경에 대한 정보를 제한적인 방식으로 결합한다. 
    3. 대조적으로, 본 논문에서는 관찰을 PLM의 입력으로 직접 인코딩함으로써 PLM이 정확하게 계획을 수립할 수 있음을 보여준다. 이 간단한 방법은 ALFWorld 및 VirtualHome 벤치마크 실험에서 이전 접근법보다 우수한 결과를 보여준다.

###### Interpreting and Exploiting Functional Specialization in Multi-Head Attention under Multi-task Learning (https://aclanthology.org/2023.emnlp-main.1026/)
- Anthology ID: 2023.emnlp-main.1026 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. Transformer 기반 모델들은 다양한 downstream 태스크에서 초인적인 성능을 보이지만, 그들이 학습한 메커니즘은 여전히 알려지지 않아 흑박 상자로 간주되고 전체적으로 사용된다.
    2. 이 연구는 다중 작업 훈련 시 multi-head attention module이 비슷한 기능 분리를 발전시키는지 알아보기 위해 기능 특화에 대한 정도를 양적으로 평가하는 해석 방법을 소개한다. 
    3. 또한, 기능 특화를 증가시키고 다중 작업 학습에서 부정적인 정보 전달을 완화하기 위해 간단한 다중 작업 훈련 방법을 제안하며, 이 방법은 파라미터를 추가하지 않은 채로 다중 작업 학습과 전이 학습에서 성능을 향상시킨다는 실험 결과가 보여졌다.

###### Multilingual Previously Fact-Checked Claim Retrieval (https://aclanthology.org/2023.emnlp-main.1027/)
- Anthology ID: 2023.emnlp-main.1027 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 팩트 체커들은 사실 확인이 필요한 온라인 콘텐츠의 양에 많은 어려움을 겪고 있다. NLP는 조사 대상 콘텐츠와 관련된 이미 있는 팩트 체크를 검색하여 그들을 지원할 수 있다. 
    2. 본 논문에서는 이전에 팩트 체크된 클레임 검색을 위한 새로운 다국어 데이터셋을 소개한다. 
    
    3. 이 데이터셋은 27개 언어로 된 28,000개의 소셜 미디어 게시물과 39개 언어로 된 206,000개의 전문 팩트 체커가 작성한 팩트 체크, 그리고 이 두 그룹 사이의 31,000개의 연결로 구성되어 있다.

###### ALCAP: Alignment-Augmented Music Captioner (https://aclanthology.org/2023.emnlp-main.1028/)
- Anthology ID: 2023.emnlp-main.1028 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 음악 캡션에는 오디오와 가사의 상호 작용을 간과하지만, 이 연구에서는 오디오와 가사 간의 다중 모달 정렬을 학습하는 방법을 소개하여 더 깊은 교차 모달 일치성을 실현하고 높은 품질의 캡션을 생성합니다.
    2. 기존의 전통적인 방법들은 음악의 오디오나 가사 중 하나를 우선하였으나, 이 논문에서는 음악의 오디오와 가사 간의 복합적인 상호 작용을 고려합니다.
    3. 실험 결과, 이 방법은 두 가지 음악 캡션 데이터셋에서 새로운 최고 성능을 달성하는 것을 보입니다.

###### Do Transformers Parse while Predicting the Masked Word? (https://aclanthology.org/2023.emnlp-main.1029/)
- Anthology ID: 2023.emnlp-main.1029 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사전 훈련된 언어 모델들은 비지도 학습 중에 파스 트리와 같은 언어 구조를 임베딩에 인코딩한다는 것이 입증되었다. 이 연구는 realistic한 임베딩 차원, 헤드 수 등의 트랜스포머 구조가 파싱 또는 근사 파싱이 가능한지 알아보고자 한다.
    
    2. 마스킹 된 언어 모델인 BERT나 RoBERTa는 영어 PCFG (문법)에 대해 Inside-Outside 알고리즘을 근사적으로 실행할 수 있다는 것을 보여준다. 또한, Inside-Outside 알고리즘은 PCFG 기반의 데이터에 대해 마스킹 언어 모델링 손실에 대한 최적의 알고리즘이다.
    
    3. PCFG에 기반하여 사전 훈련된 모델들에 대해 탐사 실험을 실시하여 근사적인 파스 트리와 Inside-Outside 알고리즘이 계산하는 근사적인 스팬 확률을 복구할 수 있음을 보여주며, 마스킹 언어 모델링이 이 알고리즘에 대한 암묵적인 편향을 가지고 있다는 것을 시사한다.

###### Composable Text Controls in Latent Space with ODEs (https://aclanthology.org/2023.emnlp-main.1030/)
- Anthology ID: 2023.emnlp-main.1030 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 실세계 텍스트 응용 프로그램은 텍스트 제어 연산을 다양하게 구성하는 경우가 많다. 이 논문에서는 저차원 및 미분 가능성을 갖는 텍스트 잠재 벡터 공간에서 효율적인 샘플러를 개발하여 텍스트 연산을 효율적으로 수행한다. 
    2. 사전 학습된 언어 모델 (예: GPT2)을 효율적으로 적응시켜 저차원 잠재 공간에 연결하고, 이를 통해 원하는 텍스트 시퀀스를 디코드한다. 
    3. 실험 결과는 이러한 연산자를 결합하여 고품질 텍스트를 생성하거나 수정하는 데 성공하였으며, 생성 품질과 효율성 면에서 이전 방법보다 크게 개선되었다.

###### P5: Plug-and-Play Persona Prompting for Personalized Response Selection (https://aclanthology.org/2023.emnlp-main.1031/)
- Anthology ID: 2023.emnlp-main.1031 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. persona-grounded retrieval-based chatbots의 사용은 맞춤 대화를 위해 중요하지만 다음과 같은 여러 가지 도전 과제가 있다.
    2. 본 논문에서는 persona 정보가 없는 경우 표준 open-domain chatbot으로 기능하는 plug-and-play persona prompting 방법을 제안한다.
    3. 실험 결과, zero-shot 모델은 원래의 persona와 개정된 persona에서 각각 이전 최첨단 시스템과 비교하여 1.95와 3.39점씩 향상되었다.

###### Reader: Model-based language-instructed reinforcement learning (https://aclanthology.org/2023.emnlp-main.1032/)
- Anthology ID: 2023.emnlp-main.1032 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 우리는 언어로 부분적으로 지정된 정확한 월드 모델들을 구축하는 방법과 그 모델들에 대한 환경 변화와 불확실성에서의 계획을 어떻게 수립할 수 있는지 탐구한다.
    2. 우리는 언어로 기술된 규칙 집합과 목표 그리고 관측치를 고려하여 환경 불확실성을 반영하면서 우리의 정책을 일반화하는 도전적인 강화학습 과제 RTFM을 해결하기 위해 처음으로 모델 기반 강화학습 접근법을 제안한다.
    3. 우리는 기존의 모델-프리 모델과 비교하여 RTFM의 여덟 가지 변형에서 우리의 모델 기반 접근법의 우수한 성능과 샘플 효율성을 입증한다. 또한, 우리는 에이전트의 계획을 검사할 수 있는 방법을 보여주어 더 인터프리터블한 에이전트로의 진전을 나타낸다.

###### Adapting Offline Speech Translation Models for Streaming with Future-Aware Distillation and Inference (https://aclanthology.org/2023.emnlp-main.1033/)
- Anthology ID: 2023.emnlp-main.1033 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 스트리밍 음성 번역에는 다른 지연 시간 요구사항을 충족하기 위해 완전한 발화로 훈련된 단일 오프라인 모델을 사용하는 방법이 일반적이다. 그러나 부분적인 입력을 사용하는 스트리밍 추론에 완전한 발화로 훈련된 모델을 사용하면 일치 문제가 발생한다.
    2. 그래서 이 논문에서는 스트리밍 입력에 맞춰 오프라인 ST 모델을 적응시키는 새로운 방법인 FAST를 제안한다. FAST는 미래 정보를 trainable 마스크 임베딩을 통해 통합하는 Future-Aware Inference (FAI) 전략과 완전한 음성의 근사치로부터 스트리밍 입력에 미래 정보를 전달하는 Future-Aware Distillation (FAD) 프레임워크를 포함한다.
    3. 실험 결과는 FAST가 강력한 기준 모델보다 번역 품질과 지연 시간 간의 상충관계를 더 잘 달성한다는 것을 보여준다. 또한, 광범위한 분석 결과는 FAST가 오프라인 훈련과 온라인 추론 사이의 일치 문제를 효과적으로 완화시키는 것을 보여준다.

###### Relation-aware Ensemble Learning for Knowledge Graph Embedding (https://aclanthology.org/2023.emnlp-main.1034/)
- Anthology ID: 2023.emnlp-main.1034 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 지식 그래프 임베딩은 자연어 처리의 기본 작업 중 하나이며, 다양한 방법이 제안되어 다양한 의미 패턴을 탐색하고 있다. 
    2. 본 논문에서는 존재하는 방법을 관계를 고려한 방식으로 종합하여 앙상블을 학습하는 것을 제안한다. 
    3. 실험 결과는 제안된 방법이 효과적으로 관계를 고려한 앙상블 가중치를 효율적으로 탐색하고 최신 임베딩 성능을 달성한다는 것을 보여준다.

###### GenEx: A Commonsense-aware Unified Generative Framework for Explainable Cyberbullying Detection (https://aclanthology.org/2023.emnlp-main.1035/)
- Anthology ID: 2023.emnlp-main.1035 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 사회적인 미디어와 온라인 커뮤니케이션의 급부상으로 사이버 괴롭힘 문제가 중요성을 얻으면서, 동일 언어를 사용하는 언어에서 사이버 괴롭힘을 탐지하는 더 효과적인 모델을 개발하기 위한 연구가 진행되고 있다. 
    2. 그러나 code-mixed 언어와 이와 관련된 설명 가능성에 대한 이해에 큰 공백이 있다. 
    3. 이 논문에서는 code-mixed 언어에서의 설명 가능한 사이버 괴롭힘 탐지를 위한 새로운 벤치마크 데이터셋인 BullyExplain을 제시하고, GenEx라는 새로운 통합 생성 프레임워크를 소개한다.

###### Document-Level Machine Translation with Large Language Models (https://aclanthology.org/2023.emnlp-main.1036/)
- Anthology ID: 2023.emnlp-main.1036 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. ChatGPT와 같은 Large language models (LLMs)는 문서 수준의 기계 번역에서 현업 MT 시스템보다 우수한 성능을 보이고 있다.
    2. GPT-3.5와 GPT-4는 강력한 장문 텍스트 모델링 기능을 활용하여, 인간 평가에서 상업용 MT 시스템들보다 우수한 성능을 보여준다.
    3. GPT-4는 GPT-3.5보다 언어적 지식을 파악하는 능력이 더 뛰어나다.

###### Multilingual Simplification of Medical Texts (https://aclanthology.org/2023.emnlp-main.1037/)
- Anthology ID: 2023.emnlp-main.1037 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 자동 텍스트 간소화는 복잡한 텍스트의 단순한 버전을 생성하는 것을 목표로 한다. 이 작업은 일반인들이 최신 의료 연구 결과에 접근하기 어려운 의료 분야에서 특히 유용하다.
    2. 기존 작업들은 단일 언어 설정에만 초점을 맞추었기 때문에, 다국어 간소화를 통해 이러한 한정성을 극복하고 여러 언어로 복잡한 텍스트를 간소화한다.
    3. 본 논문에서는 영어, 스페인어, 프랑스어, 페르시아어 4개 언어로 의료 분야를 위한 첫 번째 문장 정렬된 다국어 텍스트 간소화 데이터셋인 MultiCochrane을 소개하고, 인간 평가와 분석을 통해 이러한 언어들로 학습된 모델을 평가하며, 여러 가지 도전과제를 발견하였다.

###### When Reviewers Lock Horns: Finding Disagreements in Scientific Peer Reviews (https://aclanthology.org/2023.emnlp-main.1038/)
- Anthology ID: 2023.emnlp-main.1038 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 현재까지 과학 출판의 효과성은 심사 과정의 강점에 달려있다. 그러나 저명한 인공지능 (AI) 학회에서 발표를 위해 심사를 필요로 하는 논문의 수가 늘어남에 따라, 편집자/의장은 심사자들 간의 의견차를 해소하기 위해 상당한 노력을 기울이고 있다.
    2. 본 논문에서는 주어진 논문에서 심사자들 간의 모순을 자동으로 식별하는 새로운 작업을 소개한다. ContraSciView라는 종합적인 리뷰 쌍 모순 데이터셋을 제공하며, 리뷰 쌍에서 모순된 의견을 탐지하는 베이스라인 모델을 제안한다.
    3. 본 논문은 심사자들 간의 갈등을 자동으로 식별하는 첫 번째 시도로, 이를 위한 데이터셋과 코드를 공개한다.

###### Argue with Me Tersely: Towards Sentence-Level Counter-Argument Generation (https://aclanthology.org/2023.emnlp-main.1039/)
- Anthology ID: 2023.emnlp-main.1039 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기존의 대조적 주장 생성 연구는 주로 문단 수준의 생성에 초점을 맞추었으나, 이 논문에서는 문장 수준의 대조적 주장 생성을 다루고 있다.
    2. 다양한 대조적 주장의 특성은 n-gram 기반 메트릭만으로 모델 성능을 평가하는 데 어려움을 겪게 한다.
    3. ArgTersely 벤치마크 데이터셋과 Arg-Judge 평가자를 사용하여 대조적 주장 생성 과제에서 제안된 프레임워크와 평가자를 통해 경쟁력 있는 성능을 보였다.

###### JASMINE: Arabic GPT Models for Few-Shot Learning (https://aclanthology.org/2023.emnlp-main.1040/)
- Anthology ID: 2023.emnlp-main.1040 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. GPT와 같은 autoregressive 모델에 대한 연구는 영어 중심적이어서, 다양한 언어와 문화적 배경에서의 잠재력과 사회적 영향에 대한 우리의 이해에 심각한 공허함이 있다.
    2. 이 논문에서는 4억 명 이상의 인구를 가진 다양한 어종과 사회적 편협이 존재하는 아랍어를 다루며, JASMINE이라는 강력한 아랍어 autoregressive Transformer 언어 모델을 소개한다.
    3. JASMINE은 235GB의 텍스트 데이터로 사전 훈련된 총 300만-67억 parameter 크기의 모델들을 포함하고 있으며, 사회적 편견, 해로움 및 독성을 포함한 종합적인 아랍어 autoregressive 모델의 자동 및 인간 평가 벤치마크를 설계하여 공개한다.

###### NLI4CT: Multi-Evidence Natural Language Inference for Clinical Trial Reports (https://aclanthology.org/2023.emnlp-main.1041/)
- Anthology ID: 2023.emnlp-main.1041 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 진단 결정을 지원하기 위해 어떻게 의학적 근거를 해석하고 검색할 수 있을까요? 이 논문은 personalized medicine 개발에 필요한 정보를 담고 있는 Clinical trial reports (CTR)를 해석하기 위해 Natural Language Inference (NLI)를 사용하는 새로운 자원을 제안합니다.
    2. 기존의 NLI 모델은 의약 분야의 복합성을 제대로 반영하지 못하고 성능이 좋지 않았습니다. 이 논문은 이러한 한계를 극복하기 위해 NLI4CT라는 CTR에 대한 추론과 관련된 팩트 검색을 포함하는 새로운 작업을 설계했습니다.
    3. 이 작업에 대한 베이스라인 실험을 제공하며, 대회 리더보드와 웹사이트를 통해 도전적인 데이터셋에 대한 추가 연구를 격려하기 위해 CodaLab와 GitHub에서 관련 자원들을 공개하였다.

###### Addressing Linguistic Bias through a Contrastive Analysis of Academic Writing in the NLP Domain (https://aclanthology.org/2023.emnlp-main.1042/)
- Anthology ID: 2023.emnlp-main.1042 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 학술 논문의 네이티브한 표현에 대한 심사위원의 의견이 게재 확률에 영향을 미치는 것이 잘 알려져 있으며, 네이티브가 아닌 영어 사용자들의 스트레스와 불안감도 많이 겪고 있다. 
    2. 본 논문은 NLP 분야에서 이러한 문제가 어떻게 발생할 수 있는지에 대해 조사하고, 다양한 언어적 배경을 가진 저자들이 텍스트의 어휘, 형태, 구문 및 일관성 측면에서 어떻게 차이를 보이는지를 통계적으로 분석한다. 
    3. 이번 분석을 통해 이 논문에서 검토한 다양한 말뭉치에서 많은 특성이 크게 차이가 나타나는 것을 확인할 수 있다. 이는 언어적 편향의 가능성을 나타낸다. 따라서, 저자들에게 공평성과 포용성을 향상시키기 위해 학술 저널과 학회에게 가이드라인 및 리소스에 대한 권고안을 제시한다.

###### RobustGEC: Robust Grammatical Error Correction Against Subtle Context Perturbation (https://aclanthology.org/2023.emnlp-main.1043/)
- Anthology ID: 2023.emnlp-main.1043 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 문법 오류 수정(GEC) 시스템은 사람들의 일상적인 글쓰기 작업을 지원하는 데 중요한 역할을 한다. 그러나 사용자가 입력을 약간 수정한 경우에는 초기에 잘 작동하더라도 오류를 수정하지 못하는 GEC 시스템을 만날 수 있다. 이상적인 사용자 경험을 위해 신뢰할 수 있는 GEC 시스템은 관련 없는 문맥 변화와 마주칠 때 일관된 정확한 제안을 할 수 있는 능력, 즉 문맥의 강건성을 갖추어야 한다.
    2. 본 논문에서는 GEC 시스템의 문맥 강건성을 평가하기 위해 설계된 벤치마크인 RobustGEC를 소개한다. RobustGEC는 5,000개의 GEC 케이스로 구성되며, 각각 하나의 원본 오류 수정 문장 쌍과 인간 주석가들이 주의 깊게 작성한 다섯 개의 변형이 포함되어 있다.
    3. RobustGEC를 활용하여 최신 GEC 시스템들은 여전히 문맥 변화에 대한 강건성이 충분하지 않다는 것을 밝히고, 이 문제를 완화하기 위한 간단하면서도 효과적인 방법을 제안한다.

###### Detecting Propaganda Techniques in Code-Switched Social Media Text (https://aclanthology.org/2023.emnlp-main.1044/)
- Anthology ID: 2023.emnlp-main.1044 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 홍보는 특정 일정을 촉진하기 위해 대중의 의견과 마인드에 영향을 주는 커뮤니케이션 형태이다. 이 논문에서는 저자들이 다양한 언어의 혼합인 코드 스위칭된 텍스트에서 홍보 기술을 감지하는 새로운 작업을 제안한다.  
    2. 저자들은 영어와 로만 우르두어 사이에서 코드 스위칭을 하는 1,030개의 텍스트로 구성된 말뭉치를 만들고 20가지 홍보 기법에 대해 표시를 해놓은 세트업에 대한 실험을 수행한다. 
    3. 저자들은 실험 결과로 다양한 실험들을 정확하게 모델링하고 적절한 fine-tuning 전략을 사용하는 것이 중요하다는 것을 확인하고, 코드 및 데이터셋을 공개할 계획이라고 밝힌다.

###### Speech Recognition and Meaning Interpretation: Towards Disambiguation of Structurally Ambiguous Spoken Utterances in Indonesian (https://aclanthology.org/2023.emnlp-main.1045/)
- Anthology ID: 2023.emnlp-main.1045 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 인도네시아에서는 세 번째로 인구가 많음에도 불구하고, 구어 언어 기술의 개발은 여전히 개선이 필요하다. 대부분의 음성 인식 시스템은 여전히 모호한 문장으로 구성된 정확한 단어별 전사만 가능한데, 사람들은 청자들은 주로 음성의 리듬적 특성을 사용하여 다른 해석을 전달한다.
    2. 이 연구에서는 인도네시아어 구조적으로 모호한 발화를 구조적으로 명확한 텍스트로 변환하는 것을 목표로 한다. 뉴트리지스틱 스펙트로그램과 F0, 에너지를 이용한 제안된 캐스케이드 방식의 시스템은 79.6%의 모호해결 정확도를 달성하였다.
    3. 이 연구에서는 인도네시아어 음성-텍스트 변환을 위해 인도네시아어 음성 말뭉치를 수집하고, 사람들이 텍스트와 음성 형태로 제시된 구조적으로 모호한 문장을 어떻게 명확화하는지에 대한 조사를 실시하였다.

###### Target-Agnostic Gender-Aware Contrastive Learning for Mitigating Bias in Multilingual Machine Translation (https://aclanthology.org/2023.emnlp-main.1046/)
- Anthology ID: 2023.emnlp-main.1046 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. 기계 번역에서의 성적 편향은 중요한 문제이며, 언어간 기계 번역 모델의 성적 편향 문제에 대한 bias mitigation 방법을 제안한다.
    2. 제안하는 Gender-Aware Contrastive Learning (GACL) 방법은 명시적 성적 남/여 단어를 포함하지 않는 상황에서 비대칭적 문제들에 대한 성향 완화 방법이다.
    3. 실험 결과로, GACL은 성별 정확도를 크게 향상시키고 번역 성능을 저해시키지 않으면서도 성별에 관련된 정보를 전달하고 다른 대상 언어의 성별 정확성에도 도움이 된다고 보여준다.

###### Code-Switching Metrics Using Intonation Units (https://aclanthology.org/2023.emnlp-main.1047/)
- Anthology ID: 2023.emnlp-main.1047 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing 
- Summary: 
    1. NLP에서의 code-switching(CS) metric은 단어 수준의 단위로 정의되어 있어 실제 양언(bilingual) 코드스위칭 행동과 맞지 않다.
    2. 이 논문은 CS 확률과 다중언어성(Multilinguality)이라는 두 개의 metric을 적용하여 이중 언어의 발화를 분석하고, 음성 세그먼트를 NLP 작업의 기본 토큰으로 사용한다.
    3. 결과적으로, 이 논문은 NLP 작업에 대한 코드스위칭 dataset이 개발될 때 분석 단위에 대한 재고가 필요함을 제안한다.

## Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts
###### Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts (https://aclanthology.org/2023.emnlp-tutorial.0/)
- Anthology ID: 2023.emnlp-tutorial.0 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts 
- Summary: 
    요약문을 생성할 수 없습니다.

###### NLP+Vis: NLP Meets Visualization (https://aclanthology.org/2023.emnlp-tutorial.1/)
- Anthology ID: 2023.emnlp-tutorial.1 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts 
- Summary: 
    1. 자연어 처리(NLP)와 시각화(Vis)는 인간의 의사소통에서 강력한 모드이다. 이 튜토리얼은 이 두 모드를 밀접하게 통합하는 것을 목표로 한다.
    2. 이 튜토리얼은 NLP와 Vis를 결합한 두 가지 주요 작업에 초점을 맞춰 소개한다: (i) NLP를 Vis에 적용하는 방법과 (ii) 시각화 기법을 활용하여 복잡한 NLP 모델을 효과적으로 해석하고 설명하는 방법.
    3. 튜토리얼은 NLP+Vis의 연구 중요성을 동기부여하고 NLP와 Vis 기법을 결합한 연구 주제에 대한 개요를 제공한다. 또한 NLP에 대한 최신 딥러닝 모델 및 시각화 기법의 적용 방법을 소개하고, NLP와 Vis의 교차 영역에서의 다양한 응용 과제에 초점을 맞출 것이다.

###### Security Challenges in Natural Language Processing Models (https://aclanthology.org/2023.emnlp-tutorial.2/)
- Anthology ID: 2023.emnlp-tutorial.2 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts 
- Summary: 
    1. 최근의 대형 자연어 처리 모델은 놀라운 성능을 가지고 있기 때문에 다양한 응용 프로그램에서 사용되고 있다. 그러나 이러한 모델의 보안 문제로 인해 블랙박스 기계 학습 모델의 보급이 제한되고 있다.
    2. 이 자습서에서는 NLP 연구에서의 새로운 보안 문제인 후문(Backdoor) 공격, 개인 데이터 유출 및 모방성(Imitation) 공격에 대해 다룬다.
    3. 이러한 위협은 위협적인 사용 시나리오, 공격 방법론 및 방어 기술과 함께 소개됩니다.

###### Designing, Evaluating, and Learning from Humans Interacting with NLP Models (https://aclanthology.org/2023.emnlp-tutorial.3/)
- Anthology ID: 2023.emnlp-tutorial.3 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts 
- Summary: 
    1. 최신 자연어 처리(NLP) 연구의 빠른 진보와 함께, 인간과 상호작용해야 하는 다양한 도메인에 적용 가능한 NLP 모델이 등장하고 있다. 이 튜토리얼은 모델과 인간 간의 상호작용을 연구하기 위한 주요 고려 사항과 효과적인 접근 방법을 체계적으로 제공하고자 한다. 특히 일반 사용자와 도메인 전문가들이 NLP 기술에 익숙하지 않으면서도 NLP 모델을 사용하거나 협업하는 경우에 초점을 맞추고 있다.
    2. 이 튜토리얼은 인간 중심의 사용성 평가를 수행하여 모델이 인간과 상호작용할 수 있는 능력을 확보하는 방법, 사용자 인터페이스와 상호작용 메커니즘을 설계하여 일반 사용자들이 NLP 모델에 쉽게 접근할 수 있는 방법, 인간과의 상호작용을 통해 NLP 모델을 학습하고 개선하는 방법을 다룬다.
    3. 이 튜토리얼은 HCI의 최선의 실천 방법을 기반으로 토론을 전개하며, 현재의 도전과 미래 방향성을 강조한다.

###### LLM-driven Instruction Following: Progresses and Concerns (https://aclanthology.org/2023.emnlp-tutorial.4/)
- Anthology ID: 2023.emnlp-tutorial.4 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts 
- Summary: 
    1. 자연어 처리(NLP)의 진보는 주로 task-specific 레이블된 예제들의 대규모 셋을 최적화하는 기계 학습에 의해 이루어져왔다. 하지만 이러한 학습 패러다임은 새로운 작업을 다룰 때 기계들이 인간과 같은 능력을 가지는 것을 제한하며, 작업 지침에 따른 몇 가지 예제만으로 새로운 작업을 해결할 수 있는 인간의 능력이 있다. 
    2. 이 레이블에 기반한 학습 방법이 새로운 작업에 제한을 가지는 경우 예제들을 대량으로 준비하는 것이 어려울 수 있다. 따라서 작업 지침은 새로운 작업에 대한 지도 자료로 활용될 수 있는 새롭고 유망한 자원이다.
    3. 이 튜토리얼은 낮은 샷(scenario) 상황에서 NLP 일반화를 위한 AI와 ML 기술에 관심있는 연구자와 실무자를 대상으로 한다. 특히 작업 지침 기반의 NLP 연구에 대한 다양한 주제를 다루며, 작업 지침이 무엇이며, 데이터셋 생성과 시스템 평가 과정은 어떻게 진행되며, 작업 지침을 어떻게 인코딩하는지, 몇몇 작업 지침이 왜 더 잘 작동하는지에 대해 다루고 있다.

###### Mitigating Societal Harms in Large Language Models (https://aclanthology.org/2023.emnlp-tutorial.5/)
- Anthology ID: 2023.emnlp-tutorial.5 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts 
- Summary: 
    1. 최근의 다양한 연구들은 언어 기술이 사회적으로 가질 수 있는 피해에 대해 강조하고 있다. 그러나 지금까지 구체적인 문맥에서 발생하는 피해의 위험성을 감지하고 완화하기 위한 기술적 접근법의 통합적인 유형을 개발한 연구는 없었다. 
    2. 이 논문은 최근 작성된 설문 조사를 기반으로 이와 같은 유형을 제안하고 있다. 
    3. 이 자습서를 통해 NLP 연구자들과 엔지니어들에게 사전 훈련된 언어 생성 모델의 안전 위험을 완화하기 위한 실용적인 도구를 제공하고자 한다.

###### Creative Natural Language Generation (https://aclanthology.org/2023.emnlp-tutorial.6/)
- Anthology ID: 2023.emnlp-tutorial.6 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts 
- Summary: 
    1. GPT-3, GPT-4, Claude와 같은 대형 언어 모델들은 텍스트 요약, 기계 번역과 같은 여러 자연어 생성 작업에서 성능이 탁월하지만, 이러한 모델들은 이야기, 시, 비유 언어의 다양한 형태와 같은 창의성을 중심으로 한 개방형 작업에는 적합하지 않다.
    2. 이 튜토리얼은 창의적인 언어 생성에 대한 중요하고 현저한 연구 분야에 대한 인식을 제고하고, 언어 생성에 초점을 맞춘 동시에 다중 모달 생성 (예: 이미지 캡션, 시각적인 비유)에도 조금 다뤄낸다.
    3. 문장 수준 및 긴 텍스트 형태의 창의적인 언어 생성에 대한 최근 연구 결과를 검토하고, 창의적 언어 생성 시스템 구축의 중요성과 어려움, 콘텐츠 계획, 도메인 지식, 창의성 특정 휴리스틱을 어떻게 통합하는지, 그리고 창의적인 텍스트 생성에 대한 평가 방법 개선에 대해 소개한다. 그리고 어떻게 AI의 최근 발전이 창의력을 갖춘 미래의 업무 환경을 형성하는지에 대해 다룬다.

## Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations
###### Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations (https://aclanthology.org/2023.emnlp-demo.0/)
- Anthology ID: 2023.emnlp-demo.0 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Fabricator: An Open Source Toolkit for Generating Labeled Training Data with Teacher LLMs (https://aclanthology.org/2023.emnlp-demo.1/)
- Anthology ID: 2023.emnlp-demo.1 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 대부분의 NLP 태스크는 지도 학습으로 모델링되어 효과적인 모델을 훈련시키기 위해 레이블이 달린 훈련 데이터가 필요하다. 
    2. 이 논문에서는 zero-shot 학습을 통해 데이터셋을 생성하는 새로운 패러다임을 탐구하고 이를 위해 오픈소스 Python 툴킷인 Fabricator를 제안한다.
    3. Fabricator는 일반적인 데이터셋 생성 워크플로우를 구현하고 텍스트 분류, 질문 응답, 개체 인식 등 다양한 NLP 태스크를 지원하여 연구자들에게 재현 가능한 데이터셋 생성 실험을 돕고 실무자들이 이 접근법을 활용해 하위 태스크에 대한 모델을 훈련하는 데 도움을 준다.

###### End-to-End Evaluation for Low-Latency Simultaneous Speech Translation (https://aclanthology.org/2023.emnlp-demo.2/)
- Anthology ID: 2023.emnlp-demo.2 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 최근에는 그래서 실제 상황에서 이러한 다양한 방법을 평가하는 것이 중요해졌다. 그러나 현재로서는 시스템의 특정 측면만 평가되고 종종 다른 방법을 비교하기 어렵다.
    2. 우리는 현실적인 상황에서 저지연 음성 번역의 다양한 측면을 수행하고 평가하기 위한 첫 번째 프레임워크를 제안한다. 
    3. 이 프레임워크를 사용하여 여러 저지연 음성 번역 방법을 비교하고, 번역 품질과 지연시간을 자동으로 평가하며, 사용자에게 저지연 모델의 출력을 보여주는 웹 인터페이스를 제공한다.

###### CHATREPORT: Democratizing Sustainability Disclosure Analysis through LLM-based Tools (https://aclanthology.org/2023.emnlp-demo.3/)
- Anthology ID: 2023.emnlp-demo.3 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 기업의 지속가능한 운영에 대한 실질적인 조치를 취하고 있는가? 이를 알아보기 위해서는 기업의 지속가능성 보고서의 밀도높고 정보가 풍부한 내용을 분석해야 한다. 
    2. 하지만, 이러한 보고서의 거대한 양과 복잡성으로 인해 인간에 의한 분석은 매우 비용이 든다. 
    3. 본 논문은 ChatReport라고 불리는 대화형 언어 모델 기반의 시스템을 소개하고, 이를 통해 기업의 지속가능성 보고서 분석을 자동화하는 도구를 개발하였다.

###### RaLLe: A Framework for Developing and Evaluating Retrieval-Augmented Large Language Models (https://aclanthology.org/2023.emnlp-demo.4/)
- Anthology ID: 2023.emnlp-demo.4 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. "Retrieval-augmented large language models (R-LLMs)"는 사전 훈련된 대형 언어 모델(LLMs)과 정보 검색 시스템을 결합하여 사실 기반 질문 답변의 정확성을 향상시키는데 사용된다.
    2. "RaLLe" 프레임워크는 R-LLMs의 개발, 평가, 최적화를 용이하게 하는 오픈 소스 툴이다. 이를 통해 개발자는 R-LLMs를 쉽게 개발하고 평가하며, 손으로 만든 프롬프트를 개선하고 개별 추론 과정을 평가하고, 전체 시스템 성능을 정량적으로 측정할 수 있다.
    3. RaLLe을 활용하여 개발자들은 지식 중심 생성 작업에서 R-LLMs의 성능과 정확성을 향상시킬 수 있다.

###### VIST5: An Adaptive, Retrieval-Augmented Language Model for Visualization-oriented Dialog (https://aclanthology.org/2023.emnlp-demo.5/)
- Anthology ID: 2023.emnlp-demo.5 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 대규모 언어 모델들의 등장으로, 자연어를 통해 직관적으로 데이터와 상호작용할 수 있는 새로운 방법이 나타나고 있다. 
    2. 그러나 기존 시각화 시스템 대부분은 특정 도메인 데이터를 분석하고 도메인 특화 시각화 도구와 라이브러리를 조작하기 위해 특별히 설계된 대화 에이전트에 의존하고 있다. 
    3. 이 논문에서는 VIST5라는 시각화 지향적 대화 시스템을 제안하는데, 이는 응용 프로그램 도메인에 대한 쉬운 적응성과 언어 조작 가능한 시각화 라이브러리 기능의 응용 프로그램 간 쉬운 이식성에 중점을 둔다.

###### H2O Open Ecosystem for State-of-the-art Large Language Models (https://aclanthology.org/2023.emnlp-demo.6/)
- Anthology ID: 2023.emnlp-demo.6 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 대형 언어 모델(Large Language Models, LLM)은 AI에 혁명을 일으키고 있지만, 편향된, 개인적인, 저작권이 있는 또는 유해한 텍스트의 존재와 같은 여러 가지 중요한 위험을 내포하고 있다. 
    2. 이 논문은 LLM을 개발하고 테스트하기 위한 완전한 오픈 소스 생태계를 소개한다. 
    3. h2oGPT라는 7에서 70억 개의 매개 변수로 미세 조정된 LLM 패밀리와 최신 기술을 사용하여 LLM을 효과적으로 미세 조정, 평가 및 배포하기 위한 프레임워크 및 no-code GUI인 H2O LLM Studio를 소개한다.

###### Koala: An Index for Quantifying Overlaps with Pre-training Corpora (https://aclanthology.org/2023.emnlp-demo.7/)
- Anthology ID: 2023.emnlp-demo.7 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 최근 언어 모델의 사전 학습 데이터가 후속 작업에서 어떤 역할을 하는지 파악하는 것에 더 많은 관심이 기울여지고 있다. 그러나 대규모 사전 학습 코퍼스에 대한 분석을 지원하는 공개 도구가 없다. 
    2. 이 논문에서는 손실 없는 압축된 접미사 배열과 고효율 압축률 및 검색 지원을 사용하여 대규모 사전 학습 코퍼스에 대한 검색 가능한 인덱스인 Koala를 소개한다. 
    3. Koala를 사용하면 현재 및 미래의 기준과 LLM의 출력에서 기억의 정도를 평가하고, 수사적 분석을 수행할 수 있다.

###### Sudowoodo: A Chinese Lyric Imitation System with Source Lyrics (https://aclanthology.org/2023.emnlp-demo.8/)
- Anthology ID: 2023.emnlp-demo.8 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. MCQ 생성 평가는 기존 메트릭인 BLEU, ROUGE, METEOR이 교육적 가치를 고려하지 못하는 문제가 있다.
    2. 논문은 KDA를 측정하는 새로운 자동 평가 메트릭을 제안한다.
    3. Human evaluation을 통해 KDA_disc와 KDA_cont가 강의실에서의 사용성과 강한 상관관계를 가진 것을 보였다.
    
    1. 최근 deep model들이 NLP 태스크에서 super-human 정확성을 보이지만, spurious pattern에 의존해서 robustness가 제한된다.
    2. 논문은 contrastive learning과 counterfactual augmentation을 활용하여 robustness를 개선하기 위해 연구하였다.
    3. Empirical 결과, collective decisions를 사용한 접근은 task model bias에 덜 민감하며 일반화 성능과 모델의 robustness를 향상시키는 것을 확인하였다.
    
    1. 기존 가사 생성 연구는 키워드, 운율 등을 활용하여 정확한 가사 생성에 집중했지만, 기존 가사 스타일과 내용을 모방하여 새로운 가사를 쓰는 lyrics imitation은 평행 corpus의 부재로 인해 어려운 과제이다.
    2. 이 논문에서는 중국어 가사 모방 시스템인 Sudowoodo를 소개한다. 기존 가사를 기반으로 새로운 가사를 생성할 수 있는 system이다.
    3. Sudowoodo는 키워드 기반 lyrics 모델을 사용하여 병렬 corpus를 구축하는 새로운 framework를 제안하며, 인퍼런스 과정에서 후처리 모듈을 사용하여 생성된 가사의 품질이 높은 것을 선택한다. 또한, 음악 정보를 활용하여 가사와 음악을 조합하여 song을 형성한다. Human evaluation 결과, Sudowoodo 시스템은 더 나은 가사 모방 성능을 보였다.

###### ConvLab-3: A Flexible Dialogue System Toolkit Based on a Unified Data Format (https://aclanthology.org/2023.emnlp-demo.9/)
- Anthology ID: 2023.emnlp-demo.9 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 과업지향 대화(TOD) 시스템은 항공편 예약이나 레스토랑 찾기와 같은 다양한 과제를 안내하는 디지털 어시스턴트로 작동한다. 
    2. 기존 툴킷들은 사용자 친화적인 경험과 함께 다양한 데이터, 모델 및 실험 환경을 제공하는 데 한계가 있다.
    3. 이 연구에서는 이러한 한계를 극복하기 위해 ConvLab-3를 소개하며, ConvLab-3는 통합된 데이터 포맷과 강화학습(RL) 도구를 통해 강력한 대화 정책의 빠른 개발 및 평가를 지원한다.

###### FLEEK: Factual Error Detection and Correction with Evidence Retrieved from External Knowledge (https://aclanthology.org/2023.emnlp-demo.10/)
- Anthology ID: 2023.emnlp-demo.10 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. LLM이나 인간에 의해 생성 된 텍스트 정보의 사실적인 오류를 감지하는 것은 의사 결정에 도움을 주기 위해 중요하다.
    2. 기존 LLM의 답변에 의지하기 어려운 이유는 LLM이 외부 지식에 대한 주장을 예측할 수 없게 만들며, 사람들도 글을 쓸 때 사실적인 오류를 범할 수 있기 때문이다.
    3. 우리는 텍스트에서 사실적인 주장을 자동으로 추출하고, 외부 지식 소스에서 증거를 수집하여 각 주장의 사실성을 평가하고, 수집 된 증거를 사용하여 식별 된 오류에 대한 수정을 제안하는 프로토타입 도구를 제시한다.

###### YATO: Yet Another deep learning based Text analysis Open toolkit (https://aclanthology.org/2023.emnlp-demo.11/)
- Anthology ID: 2023.emnlp-demo.11 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. "우리는 심층학습을 이용한 텍스트 분석을 위한 사용하기 쉬운 오픈소스 툴킷인 YATO를 소개한다. YATO는 기존의 사용성이 낮은 툴킷과 플랫폼과는 달리 가볍고 사용자 친화적이며, 여러 학문 분야의 연구원들에게 적합하다."
    2. "YATO는 계층 구조로 설계되어서 전통적인 신경망, 사전 학습 언어 모델, 사용자 정의 신경망 특징들을 자유롭게 조합할 수 있도록 지원한다."
    3. "YATO의 유연성과 사용 편의성 덕분에 최신 자연어처리 모델의 빠른 재현과 개선을 도와주며, 자연어처리 기술의 학문 간 응용을 촉진할 수 있다."

###### Spacerini: Plug-and-play Search Engines with Pyserini and Hugging Face (https://aclanthology.org/2023.emnlp-demo.12/)
- Anthology ID: 2023.emnlp-demo.12 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. Spacerini는 Pyserini 툴킷과 Hugging Face를 통합하여 상호작용적인 검색 엔진의 구축과 배포를 원활하게 하는 도구로, IR 전공자가 아닌 사람들에게 최신의 sparse와 dense retrieval 모델을 보다 쉽게 이용하고 배포 노력을 최소화 한다.
    2. 이는 NLP 연구원들이 훈련 말뭉치를 질적 분석을 통해 더 잘 이해하고 검증하고 싶어하는 경우, Pyserini 생태계에 통합된 새로운 검색 모델을 시연하고 싶어하는 IR 연구원들, 그리고 다른 연구원의 작업을 재현하려는 제3자들에게 유용하다.
    3. Spacerini는 로컬 및 원격에서 검색 엔진을 로드, 전처리, 인덱싱, 배포하는 유틸리티를 포함하고 있으며, Spacerini로 생성된 13개의 검색 엔진 포트폴리오를 통해 다양한 사용 사례를 보여준다.

###### Adapters: A Unified Library for Parameter-Efficient and Modular Transfer Learning (https://aclanthology.org/2023.emnlp-demo.13/)
- Anthology ID: 2023.emnlp-demo.13 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. Adapters는 parameter-efficient하고 모듈화된 transfer learning을 대규모 language model에 제공하는 오픈 소스 라이브러리이다. 
    2. 10가지 다양한 어댑터 메소드를 통합해서 제공하여 사용 편의성과 유연한 구성을 제공한다. 
    3. Adapters는 복잡한 어댑터 구성을 설계할 수 있는 컴포지션 블록을 통해 어댑터 모듈성을 활용할 수 있으며, 다양한 NLP 태스크에서의 성능을 평가한 결과 기존의 fine-tuning에 비해 우수한 성능을 보여준다.

###### INTELMO: Enhancing Models’ Adoption of Interactive Interfaces (https://aclanthology.org/2023.emnlp-demo.14/)
- Anthology ID: 2023.emnlp-demo.14 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 이 논문에서는 개발자들이 사용자 인터페이스와 실시간 RSS 소스의 기사를 언어 모델에 적용하기 쉽도록 도와주는 INTELMO 라이브러리를 제안한다.
    2. 이 라이브러리는 공통 NLP 작업을 카테고리화하고 기본 스타일 패턴을 제공하여 최소한의 코드 수정으로 인터페이스를 생성하는 과정을 간소화하면서 직관적인 사용자 경험을 제공한다.
    3. 또한, INTELMO는 다중 granularity 계층적 추상화를 사용하여 개발자에게 세밀하고 유연한 인터페이스 제어를 제공한다. INTELMO는 https://intelmo.github.io에서 문서가 제공되며 계속해서 개발 중이다.

###### Humanoid Agents: Platform for Simulating Human-like Generative Agents (https://aclanthology.org/2023.emnlp-demo.15/)
- Anthology ID: 2023.emnlp-demo.15 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 컴퓨터 시뮬레이션을 통해 원자, 분자, 세포의 연구에 도움이 된 것처럼, 사람과 유사한 에이전트들의 실제감 있는 시뮬레이션은 인간의 행동을 연구하는 데에 유용한 도구가 될 수 있다.
    2. 우리는 Humanoid Agents라는 시스템을 제안하는데, 이는 Basic needs (예: 배고픔, 건강, 에너지), Emotion, 그리고 Closeness in Relationships와 같은 3가지 System 1 처리 요소를 도입하여 생성적 에이전트들이 사람과 더 비슷한 행동을 할 수 있도록 안내한다.
    3. 우리의 시스템은 다양한 설정에 대해 확장 가능하며, 동시에 사람의 행동에 영향을 주는 다른 요소 (예: 공감, 도덕적 가치, 문화적 배경)에 대해서도 확장 가능하다. 또한 Unity WebGL 게임 인터페이스를 통한 시각화와 상호작용형 분석 대시보드를 포함하고 있다.

###### TP-Detector: Detecting Turning Points in the Engineering Process of Large-scale Projects (https://aclanthology.org/2023.emnlp-demo.16/)
- Anthology ID: 2023.emnlp-demo.16 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 이 논문은 대형 프로젝트의 엔지니어링 과정에서 전환점(turning points)을 감지하는 새로운 작업을 소개한다. 이를 위해 관련된 뉴스 스트림의 시퀀스를 다중 인스턴스 윈도우로 처리하여 전환점 윈도우에 나타나는 전환 패턴을 식별한다.
    2. 효과적으로 변화의 진행을 포착하기 위해 깊은 다중 인스턴스 학습(MIL) 프레임워크를 채택하고 다중 인스턴스 순위 손실을 사용한다.
    3. 실험결과는 우리가 제안한 방법이 기준선 방법에 비해 구축한 데이터셋에서 효과적임을 일관되게 보여준다. 이 방법론은 실제 구현되어 사용되고 그 기능성을 보여주기 위한 데모 비디오도 제공되며, 코드와 데이터셋은 GitHub에서 이용할 수 있다.

###### CLEVA: Chinese Language Models EVAluation Platform (https://aclanthology.org/2023.emnlp-demo.17/)
- Anthology ID: 2023.emnlp-demo.17 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 중국어 Large Language Models (LLMs)의 지속적인 등장으로, 모델의 성능을 평가하는 방법이 점점 중요한 문제가 되었다.
    2. 현재 중국어 LLMs의 평가에서는 전체적인 성능을 철저히 평가하는 종합적인 벤치마크의 부재, 비표준화되고 비교할 수 없는 프롬프트 절차, 그리고 확산의 위험이 주요한 도전 과제로 작용한다.
    3. 우리는 ganzeyi portal 사이트같은 플랫폼이 있다. 이 플랫폼은 다양한 차원에서 LLMs의 성능을 체계적으로 평가하기 위해 표준화된 워크플로우를 사용하며 경쟁력 있는 리더보드를 정기적으로 업데이트한다. 이러한 플랫폼은 오염을 완화하기 위해 새로운 데이터의 상당 부분을 선별하고, 각 리더보드 순서마다 고유한 하위 집합이 보장되는 샘플링 전략을 개발한다. 사용자는 몇 번의 마우스 클릭과 모델 API를 통해 적은 코딩으로 철저한 평가를 수행할 수 있는 사용하기 쉬운 인터페이스를 통해 지원된다. 23가지 중국어 LLMs를 대상으로 한 대규모 실험은 CLEVA 플랫폼의 효과를 입증하였다.

###### DOPA METER – A Tool Suite for Metrical Document Profiling and Aggregation (https://aclanthology.org/2023.emnlp-demo.18/)
- Anthology ID: 2023.emnlp-demo.18 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. DOPA METER는 서체, 장르, 스타일 등의 다양한 문체 범주로 쓰인 언어를 계량적으로 조사하는 도구로, 언어 프로파일링에 관련된 어휘, 구문, 의미적 특징을 다루는 120개의 지표를 기반으로 한다.
    2. DOPA METER는 사용자의 요구에 맞게 맞춤형 시각화 도구를 사용하여 점수를 요약, 비교 및 집계할 수 있다.
    3. 우리는 DOPA METER의 응용 시나리오를 소개하면서 이 도구의 활용 가능성을 보여준다.

###### Muted: Multilingual Targeted Offensive Speech Identification and Visualization (https://aclanthology.org/2023.emnlp-demo.19/)
- Anthology ID: 2023.emnlp-demo.19 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 웹상에서는 혐오, 폭력, 욕설과 같은 모욕적인 언어가 다양한 콘텐츠에서 등장한다. 이 논문은 HAP(Hate, Abuse, Profanity) 시작을 표시하는 히트맵을 사용하여 혐오표현이 포함된 다국어 콘텐츠를 식별하는 MUTED 시스템을 제안한다. 추가적인 fine-tuning 없이 transformer기반의 모델을 사용하여 독성 부분을 식별하고, spaCy 라이브러리를 사용하여 attention heatmap으로 예측된 단어의 대상과 주장을 식별한다. 
    
    2. 기존 연구는 주로 문장 수준의 주석을 다루었지만, 최근에는 모욕적인 부분을 식별하기 위해 노력한 연구도 있다. 
    3. 이 논문은 기존 데이터셋에서의 혐오적 표현과 대상 식별에 대한 모델의 성능을 제시하고, 독일어 텍스트에 대한 새로운 주석을 제시한다. 이후 다국어 입력에 대해 제안된 시각화 도구를 시연한다.

###### Gentopia.AI: A Collaborative Platform for Tool-Augmented LLMs (https://aclanthology.org/2023.emnlp-demo.20/)
- Anthology ID: 2023.emnlp-demo.20 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. "Augmented Language Models (ALMs)"은 대화 시 인공지능 기반의 지능적인 에이전트로 사용되기 위한 대형 언어 모델을 가능하게 한다. 하지만, 기존의 ALMs 프레임워크는 유연한 맞춤화, 협력적 민주주의, 모든 면에서의 평가와 같은 중요한 특징들이 부족하다. 
    2. 이 논문에서는 Gentopia라는 가벼우면서도 확장 가능한 ALMs 프레임워크를 제안한다. Gentopia는 간단한 구성을 통해 에이전트를 유연하게 맞춤화할 수 있으며, 다양한 언어 모델, 과제 형식, 프롬프팅 모듈, 플러그인을 통합하여 통일된 패러다임으로 제공한다.
    3. 무료로 제공되는 Gentpool 플랫폼을 통해 사용자 맞춤형 에이전트 등록과 공유가 가능하다. Gentpool에서 등록된 에이전트들은 결합이 가능하므로, 인공지능 민주주의의 진보를 이룰 수 있게 된다. 또한, 고품질의 에이전트를 보장하기 위해 Gentbench가 안전성, 강건성, 효율성 등 다양한 측면에서 사용자 맞춤형 에이전트를 철저히 평가한다.

###### MusicAgent: An AI Agent for Music Understanding and Generation with Large Language Models (https://aclanthology.org/2023.emnlp-demo.21/)
- Anthology ID: 2023.emnlp-demo.21 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. AI-기반 음악 처리는 음향 합성과 음악 분류 등 많은 태스크를 포함하는 다양한 분야이지만, 이러한 태스크를 이해하고 요구사항을 충족시키기 위해서는 음악 데이터의 표현과 모델 적용성 등의 큰 차이를 고려해야 하므로 개발자와 아마추어들에게는 매우 어려운 일이다.
    2. 이 논문에서는 이러한 문제를 해결하기 위해 MusicAgent라는 시스템을 개발하여 다양한 음악 관련 도구들을 통합하고, 사용자 요구사항을 자동으로 분석하여 적절한 도구를 호출하여 요구를 충족시키는 자동화된 워크플로우를 제공한다.
    3. 이를 통해 사용자들은 복잡한 인공지능 음악 도구의 세부 사항에서 해방되고 창의적인 측면에 집중할 수 있으며, 도구들을 자유롭게 결합함으로써 원활하고 풍부한 음악 체험을 제공한다.

###### SentAlign: Accurate and Scalable Sentence Alignment (https://aclanthology.org/2023.emnlp-demo.22/)
- Anthology ID: 2023.emnlp-demo.22 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. SentAlign은 매우 큰 병렬 문서 쌍을 처리하는 정확한 문장 정렬 도구로, 수천 개의 문장을 포함하는 큰 문서에서 가능한 모든 정렬 경로를 평가하고 천 만 개의 문장을 포함하는 문서를 정렬하기 위해 분할 정복 접근법을 사용한다.
    2. SentAlign은 LaBSE 이중 언어 문장 임베딩을 기반으로 하는 점수 함수를 사용하여, 독일어-프랑스어 및 영어-아이슬란드어와 같은 두 가지 차원에서 다른 5개의 문장 정렬 도구보다 우수한 성능을 보인다.
    3. SentAlign은 downstream 기계 번역 작업에서도 평가되었을 때 더 우수한 성능을 보여준다.

###### QACheck: A Demonstration System for Question-Guided Multi-Hop Fact-Checking (https://aclanthology.org/2023.emnlp-demo.23/)
- Anthology ID: 2023.emnlp-demo.23 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 현실 세계의 주장을 사실로 확인하기 위해서는 직접적인 증거가 없어 복잡하고 다단계적인 추론이 필요하다. 이 논문에서는 의사결정 과정을 투명하게 하고 이해하기 쉽도록 설명하는 QACheck 시스템을 제안한다. 
    2. QACheck은 주장을 검증하기 위해 핵심 질문들을 일련의 질문들로 제시하면서 모델의 추론 과정을 안내한다. 
    3. 사용자는 주장을 입력하고, QACheck은 그의 진실성을 예측하고 질문-답변 쌍의 시퀀스에 기반한 추론 과정을 상세히 설명하는 종합적인 보고서를 제공한다.

###### RobustQA: A Framework for Adversarial Text Generation Analysis on Question Answering Systems (https://aclanthology.org/2023.emnlp-demo.24/)
- Anthology ID: 2023.emnlp-demo.24 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 질문응답(QA) 시스템은 사람 수준의 정확도에 도달한 반면, 이러한 시스템은 충분히 강건하지 않고 적대적인 예제에 취약하다. 이 논문에서는 텍스트 분류에서 널리 연구된 공격 알고리즘을 QA 시스템에 적용하기 위해 수정하고, 문자, 단어 및 문장 수준에서 다양한 공격 방법의 영향을 평가하였다.
    2. 또한, RobustQA라는 새로운 프레임워크를 개발하여 QA 시스템에서 텍스트 적대적 공격을 조사하기 위한 첫 번째 오픈 소스 툴킷으로 제안하였다. RobustQA는 Tokenizer, Victim Model, Goals, Metrics, Attacker, Attack Selector 및 Evaluator 등 7개의 모듈로 구성되어 있으며, 현재 6가지 다른 공격 알고리즘을 지원한다.
    3. 이 프레임워크는 QA에서 새로운 공격 알고리즘을 개발하는 것을 간소화한다. RobustQA의 소스 코드와 문서는 https://github.com/mirbostani/RobustQA에서 확인할 수 있다.

###### Kandinsky: An Improved Text-to-Image Synthesis with Image Prior and Latent Diffusion (https://aclanthology.org/2023.emnlp-demo.25/)
- Anthology ID: 2023.emnlp-demo.25 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 텍스트에서 이미지를 생성하는 것은 현대 컴퓨터 비전 분야에서 중요한 영역이며, 생성 모델의 발전을 통해 상당한 향상을 이뤄냈습니다. Kandinsky는 이미지 사전 모델과 latent diffusion 기술의 원리를 결합한 새로운 latent diffusion 아키텍처의 탐구입니다.
    2. Kandinsky는 CLIP 텍스트와 이미지 임베딩을 매핑하기 위해 별도로 훈련된 이미지 사전 모델과 함께 사용됩니다. 또한 제안된 모델의 특징 중 하나는 이미지 오토인코더 구성 요소로 사용되는 수정된 MoVQ 구현입니다.
    3. 실험적 평가 결과, COCO-30K 데이터셋에서 8.03의 FID 점수를 기록하여, 우리의 모델이 측정 가능한 이미지 생성 품질 측면에서 최고의 오픈 소스 결과를 달성한 것으로 나타났습니다.

###### NewsRecLib: A PyTorch-Lightning Library for Neural News Recommendation (https://aclanthology.org/2023.emnlp-demo.26/)
- Anthology ID: 2023.emnlp-demo.26 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. NewsRecLib은 Pytorch-Lightning과 Hydra를 기반으로 한 오픈 소스 라이브러리로, 뉴스 추천 모델의 훈련과 평가에 사용된다.
    2. NewsRecLib은 실험의 재현성과 엄격한 실험 평가를 촉진하기 위해 (i) 포괄적인 실험 연구를 위한 통합 및 높은 환경 설정 가능성을 제공하고 (ii) 다양한 모델 아키텍처 구성 요소와 훈련 방식의 성능 기여를 철저하게 분석할 수 있도록 한다.
    3. NewsRecLib은 모듈화가 잘 되어있고, 하나의 설정 파일에서 실험을 지정할 수 있으며, 뉴스 추천에 대한 표준 평가 기준과 평가 메트릭의 준비된 구현을 제공한다.

###### MiniChain: A Small Library for Coding with Large Language Models (https://aclanthology.org/2023.emnlp-demo.27/)
- Anthology ID: 2023.emnlp-demo.27 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 대규모 언어 모델(Large Language Model)로 프로그래밍하는 방법은 다양한 적용 분야를 열어줄 뿐 아니라 조심스러운 접근이 필요하다. 대체적으로 정확성은 높지만, 기본적인 오류가 발생하는 등 로버스트성(robustness)이 부족하다. 
    2. 우리는 프로그래밍에 대한 가시성 향상을 위해 MiniChain이라는 도구를 소개한다. 이 도구는 프로토타이핑의 용이성, 자동 시각화를 통한 투명성, 그리고 고급 기능의 최소주의적 접근 방식을 디자인 목표로 한다.
    3. MiniChain 라이브러리는 LLM 호출을 위한 기본 요소를 제공하며, 프롬프트 템플릿을 분리하고 프로그램 구조를 포착한다. 이 라이브러리에는 챗봇, 코드 생성, 검색 기반 질의 응답, 복잡한 정보 추출을 위한 주요 응용 논문의 데모 구현이 포함되어 있다.

###### Okapi: Instruction-tuned Large Language Models in Multiple Languages with Reinforcement Learning from Human Feedback (https://aclanthology.org/2023.emnlp-demo.28/)
- Anthology ID: 2023.emnlp-demo.28 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 대규모 언어 모델의 핵심 기술은 사용자의 기대에 따라 모델의 응답을 조율하는 instruction tuning으로, 이를 통해 놀랄만한 학습 능력을 실현할 수 있다. 그러나 기존 오픈 소스 언어 모델은 영어와 몇몇 인기있는 언어만을 대상으로 instruction tuning이 이루어져 다양한 언어에 대한 접근성이 제한되었다.
    2. 본 논문에서는 다양한 언어에 대한 RLHF 기반의 instruction-tuned 언어 모델을 소개한다. 이를 위해 26개의 다양한 언어에 대한 instruction 및 응답 순위 데이터를 도입하여 다국어 LLM 연구의 실험과 개발을 용이하게 한다.
    3. 실험 결과는 다양한 기본 모델과 데이터셋에 대해 RLHF 기반의 다국어 instruction이 SFT보다 우월함을 보여주며, 생성형 LLM의 다양한 언어 평가를 가능하게 하는 벤치마크 데이터셋도 제시한다.

###### SAGEViz: SchemA GEneration and Visualization (https://aclanthology.org/2023.emnlp-demo.29/)
- Anthology ID: 2023.emnlp-demo.29 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 스키마 유도(schema induction)는 시나리오에서 사건의 전개를 그래프로 묘사하는 작업을 말한다. 본 논문에서는 SAGEViz라는 직관적이고 모듈화된 도구를 제안하며, 이를 통해 인간-AI 협업으로 다양한 도메인의 복잡한 스키마 그래프를 효율적으로 생성하고 수정할 수 있다.
    2. SAGEViz 도구는 (1) 플러그앤플레이 이벤트 언어 모델을 이용하여 이벤트 시퀀스를 생성하고 확장하는 커레이션 구성 요소와, 인간 주석가들이 검증하고 풍부하게 만들어 복잡한 계층적 스키마를 구축하는 기능, (2) 다양한 계층 수준에서 스키마를 시각화하는 기능으로 구성되어 있다.
    3. 이 논문은 사용자 연구를 통해 SAGEViz를 사용하여 스키마를 더 나은 품질로 생성하는 데에 더 적은 노력이 필요함을 보여준다. 또한 시스템을 시연한 동영상도 포함되어 있다.

###### Thresh: A Unified, Customizable and Deployable Platform for Fine-Grained Text Evaluation (https://aclanthology.org/2023.emnlp-demo.30/)
- Anthology ID: 2023.emnlp-demo.30 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 최근 텍스트 생성 작업의 세밀한 수준의 인간 평가는 요약, 단순화, 기계 번역, 뉴스 생성과 같은 작업을 평가하기 위한 신뢰할 수 있고 견고한 방법으로 등장하였다. 
    2. 그러나 이러한 평가에 사용되는 기존 도구들은 다양한 도메인이나 언어로 확장하거나 사용자의 요구에 따라 주석 설정을 수정하기에 적합하지 않다.
    3. 본 논문에서는 세부 인간 평가를 위한 Thresh라는 통합 가능하고 사용자 정의 가능하며 배포 가능한 플랫폼을 소개하고 이를 통해 다양한 NLP 작업을 커버하는 인간 평가 도구의 커뮤니티 모음을 제공한다.

###### InsightPilot: An LLM-Empowered Automated Data Exploration System (https://aclanthology.org/2023.emnlp-demo.31/)
- Anthology ID: 2023.emnlp-demo.31 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 데이터 분석에서 데이터를 탐색하는 것은 데이터를 효과적으로 이해하고 해석하는 데 도움이 되기 때문에 중요하다. 그러나 효과적인 데이터 탐색을 위해서는 데이터셋에 대한 깊은 지식, 사용자 의도 및 데이터 분석 기법에 대한 전문지식이 필요하다.
    2. 이 논문에서는 InsightPilot이라는 LLM(Large Language Model) 기반의 자동 데이터 탐색 시스템을 소개한다. InsightPilot은 데이터 탐색 과정을 단순화하기 위해 신중하게 설계된 분석 작업 세트를 제공한다.
    3. InsightPilot은 자연어 질문을 입력으로 받아 LLM과 협력하여 데이터를 탐색하고 인사이트를 생성하는 기능을 가지고 있으며, 사용자 연구 및 사례 연구를 통해 그 효과를 입증하였다.

###### SynJax: Structured Probability Distributions for JAX (https://aclanthology.org/2023.emnlp-demo.32/)
- Anthology ID: 2023.emnlp-demo.32 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 딥 러닝 소프트웨어 라이브러리의 발전은 사용자들이 모델링에 집중할 수 있도록 하면서 현대 하드웨어 가속기에 대한 실행 최적화 작업을 라이브러리에 맡겨 시간과 노력을 절약시켰다. 그러나 구조적 객체를 명시적으로 처리하는 모델들은 벡터화된 계산으로 구현하기 어렵기 때문에, 이러한 모델들은 동일한 혜택을 받지 못했다.
    2. SynJax는 벡터화된 구조 분포에 대한 추론 알고리즘의 효율적인 구현을 제공하여 이 문제를 직접 해결한다. 이는 자동 미분 및 확률적 추론을 위한 알고리즘 간의 연결을 활용함으로써 실현된다.
    3. SynJax를 사용하면 데이터의 구조를 명시적으로 모델링하는 대규모 미분 모델을 구축할 수 있다.

###### RESIN-EDITOR: A Schema-guided Hierarchical Event Graph Visualizer and Editor (https://aclanthology.org/2023.emnlp-demo.33/)
- Anthology ID: 2023.emnlp-demo.33 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 복잡한 이벤트를 분석하기 위해 설계된 대화형 이벤트 그래프 시각화 및 편집기인 RESIN-EDITOR를 제안한다. RESIN-EDITOR 시스템은 멀티미디어와 다중 문서 뉴스 클러스터에서 추출된 계층적 이벤트 그래프를 인간이 편집한 이벤트 스키마의 안내로 렌더링하고 자유롭게 편집할 수 있게 한다.
    2. RESIN-EDITOR의 고유한 기능으로는 계층적 그래프 시각화, 전체적인 소스 추적 및 대화형 사용자 편집이 포함되어 있으며, 이는 정보 추출 (IE) 시각화 도구에서 현재의 모델 분석 및 개선을 크게 능가한다.
    3. RESIN-EDITOR의 평가에서 우리는 복잡한 이벤트 이해와 시스템 성능 향상에 효과적인 도구임을 보여주고 있다. RESIN-EDITOR의 소스 코드, 비디오 데모 및 실시간 웹 사이트는 공개적으로 제공되고 있다.

###### DRGCoder: Explainable Clinical Coding for the Early Prediction of Diagnostic-Related Groups (https://aclanthology.org/2023.emnlp-demo.34/)
- Anthology ID: 2023.emnlp-demo.34 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 의료 클레임 코딩은 의료 기록을 구조화된 코드로 변환하는 과정이다. 이 논문에서는 의료 중증도 DRG(Diagnosis-Related Group) 코드의 조기 예측을 위한 DRGCoder라는 시스템을 제안한다.
    2. DRGCoder 프레임워크는 MS-DRG 예측을 위해 새로운 멀티태스크 Transformer 모델을 도입하고, 퇴원 요약본의 DRG 라벨과 중요한 단어들을 모델링한다.
    3. DRGCoder는 사용자가 입력의 각 단어별 가중치를 시각화하여 추론과정을 검토할 수 있게 하며, 퇴원 요약본에서 질병을 식별하고 여러 요약본을 비교할 수 있도록 함을 제공한다.

###### CAMRA: Copilot for AMR Annotation (https://aclanthology.org/2023.emnlp-demo.35/)
- Anthology ID: 2023.emnlp-demo.35 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. "이 논문에서는 자연어 텍스트로부터 Abstract Meaning Representation (AMR)을 구축하기 위한 최신 웹 기반 도구인 CAMRA를 소개한다. CAMRA는 AMR 주석을 프로그래밍 언어로서의 코딩에 유사한 방식으로 다루며, 프로그래밍 패러다임에 대한 친숙성을 활용한다. CAMRA는 기존의 AMR 편집기의 모든 중요한 기능을 포함하면서도 Propbank roleset 찾기와 같은 기능을 통합하여 사용자의 효율과 정확성을 크게 향상시킨다."
    
    2. "CAMRA는 프로그래밍 패러다임과의 유사성을 활용하여 AMR 편집을 쉽게 할 수 있는 웹 도구로, AMR 주석의 프로그래밍적 특성을 강조한다. CAMRA는 예제 검색 기능을 비롯한 기능을 제공하며, 도구 내에서 자동완성 기능으로 Propbank roleset을 통합한다. 이를 통해 CAMRA는 AMR 주석 작업자의 효율과 정확성을 크게 향상시킨다."
    
    3. "CAMRA는 AMR 주석 작업에 있어 프로그래밍적 관점을 도입한 웹 기반 도구로, 예제 검색과 Propbank roleset 자동완성 기능 등으로 편의성을 제공하며, AMR 파서 모델을 코딩 협업 도우미로 활용하여 AMR 주석 작업자의 효율과 정확성을 크게 향상시킨다."

###### Reaction Miner: An Integrated System for Chemical Reaction Extraction from Textual Data (https://aclanthology.org/2023.emnlp-demo.36/)
- Anthology ID: 2023.emnlp-demo.36 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 화학 반응은 화학 분야에서 중요한 역할을 하며 실험 및 약물 설계에 대한 전반적인 이해에 매우 중요하다. 
    2. 이 논문에서는 Reaction Miner라는 시스템을 소개하는데, 이 시스템은 원시적인 과학 문헌과 상호작용하여 정확하고 더 유익한 화학 반응을 제공한다. 
    3. Reaction Miner는 단순히 추출하는 것을 넘어서 PDF 파일을 입력으로 받고, 전체 화학 반응을 포함하는 세분화된 텍스트로 변환하여 추출의 정확성을 향상시킨다.

###### CHAMP: Efficient Annotation and Consolidation of Cluster Hierarchies (https://aclanthology.org/2023.emnlp-demo.37/)
- Anthology ID: 2023.emnlp-demo.37 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 다양한 NLP 태스크에서는 각 노드가 아이템들의 클러스터로 구성되는 복잡한 계층 구조를 필요로 한다. 이 논문에서는 CHAMP라는 오픈소스 도구를 소개하여, 텍스트 유형에 상관없이 클러스터와 계층 구조를 동시에 점진적으로 구축할 수 있게 한다.
    2. 이 점진적인 접근법은 기존의 쌍별 어노테이션 방식에 비해 어노테이션 시간을 크게 줄여 주며, 클러스터와 계층 수준에서 전이성(transitivity)을 유지하는 것을 보장한다.
    3. 또한 CHAMP는 합의자가 여러 클러스터 계층 어노테이션을 쉽게 비교하고 의견 상이성을 해결할 수 있는 합의 모드를 포함한다.

###### Prompt2Model: Generating Deployable Models from Natural Language Instructions (https://aclanthology.org/2023.emnlp-demo.38/)
- Anthology ID: 2023.emnlp-demo.38 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 대형 언어 모델(Large language models, LLMs)은 몇 가지 예제를 제공하고 자연 언어로 작업 설명만 하면 현재 시스템 빌더들이 경쟁력 있는 NLP 시스템을 만들 수 있게 한다. 그러나 LLMs는 배포를 위해 컴퓨팅 리소스가 많이 필요하며 API를 통해서만 사용 가능하다.
    2. 본 논문에서는 Prompt2Model이라는 범용 방법론을 제안하는데, LLMs에 제공되는 프롬프트와 같은 자연 언어의 작업 설명을 사용하여 배포에 용이한 특수 목적 NLP 모델을 훈련시킨다.
    3. 실험 결과, Prompt2Model을 사용하여 훈련된 모델은 강력한 LLM인 gpt-3.5-turbo의 결과를 20% 이상 능가하면서 최대 700배 작을 수 있다고 보여준다. 또한 이 데이터를 사용하여 모델 성능의 신뢰성을 평가하여 배포 전에 모델 신뢰성을 판단할 수 있다고 보여준다.

###### NewsSense: Reference-free Verification via Cross-document Comparison (https://aclanthology.org/2023.emnlp-demo.39/)
- Anthology ID: 2023.emnlp-demo.39 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. NewsSense는 다양한 소스의 기사에서 정보를 수집하고 통합하기 위해 설계된 새로운 sensemaking 도구 및 독서 인터페이스를 제공한다.
    2. NewsSense는 사용자가 선택한 기사를 중심으로 다른 소스의 관련 기사로 링크를 제공하고, 구체적인 주장이 다른 기사의 정보로부터 어떻게 지원되거나 반박되는지에 대한 인라인 하이라이트를 제공하여 중앙에서 지불된 기사를 보완하는 참조 없는 검증(reference-free verification) 기능을 제공한다.
    3. 우리의 pilot study에서는 NewsSense가 사용자가 핵심 정보를 식별하고 뉴스 기사의 신뢰성을 확인하며 다른 관점을 탐색하고, 어떤 콘텐츠가 지원되었는지, 반박되었는지 또는 누락되었는지를 이해하는 데 도움이 될 수 있는 잠재력을 보여주고 있다.

###### NeMo Guardrails: A Toolkit for Controllable and Safe LLM Applications with Programmable Rails (https://aclanthology.org/2023.emnlp-demo.40/)
- Anthology ID: 2023.emnlp-demo.40 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. "NeMo Guardrails"는 LLM 기반 대화 시스템에 간편하게 프로그래밍 가능한 보호막을 추가할 수 있는 오픈 소스 툴킷입니다.
    2. Guardrails (or rails)는 LLM의 출력을 제어하기 위한 특정 방법입니다. 예를 들어 유해한 주제에 대해 이야기하지 않도록 하거나 미리 정의된 대화 경로를 따르거나 특정 언어 스타일을 사용하는 등의 제어가 가능합니다.
    3. NeMo Guardrails는 대화 관리에서 영감을 받은 실행 환경을 사용하여 개발자가 LLM 애플리케이션에 프로그래밍 가능한 rails을 추가할 수 있는 다른 접근 방식을 제공합니다. 이러한 rails는 사용자 정의되어 LLM에 독립적이며 해석 가능합니다. 초기 결과로는 제안된 방법을 사용하여 여러 LLM 제공 업체와 협력하여 조절 가능하고 안전한 LLM 애플리케이션을 개발할 수 있음을 보여주고 있습니다.

###### LM-Polygraph: Uncertainty Estimation for Language Models (https://aclanthology.org/2023.emnlp-demo.41/)
- Anthology ID: 2023.emnlp-demo.41 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 대용량 언어 모델의 발전은 다양한 분야에서 혁신적인 응용 프로그램을 가능하게 했지만, 이러한 모델은 종종 "환각(hallucination)" 하여 사실이 아닌 내용을 제공한다. 
    2. 이 논문에서는 확신(uncertainty) 추정 및 평가 방법을 소개하는 LM-Polygraph라는 프레임워크를 제안하여, 안전하고 책임감 있는 LLM 사용을 위한 방법을 제공한다. 
    3. LM-Polygraph는 최신 LLM과 호환되며, 연구자들에게 일관된 평가를 가능하게 하는 확신 추정 기법을 위한 벤치마크 및 신뢰도 점수를 포함한 데모 웹 응용 프로그램을 제공한다.

###### Descriptive Knowledge Graph in Biomedical Domain (https://aclanthology.org/2023.emnlp-demo.42/)
- Anthology ID: 2023.emnlp-demo.42 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 의료 관련 말뭉치에서 중요하고 설명적인 문장들을 자동으로 추출하고 생성하는 시스템을 제안한다. 이 시스템은 관련있는 생물학적 엔티티들을 관계형 그래프로 조직화하여 연구자들이 밀접하게 연결된 생물학적 엔티티들을 탐색하거나 간접적으로 연결된 엔티티들을 탐색할 수 있게 한다.
    2. ChatGPT와 fine-tuned 관계 합성 모델을 사용하여 검색된 정보로부터 간결하고 신뢰성 있는 설명적인 문장을 생성한다.
    3. 이 시스템을 COVID-19 연구에 적용하여, 약물 재활용 및 문헌 정리와 같은 분야에서의 유용성을 보여준다.

###### Prompterator: Iterate Efficiently towards More Effective Prompts (https://aclanthology.org/2023.emnlp-demo.43/)
- Anthology ID: 2023.emnlp-demo.43 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. Large Language Models (LLM)을 사용한 문제 해결 과정에서 prompt를 잘 사용하는 것이 중요한데, 이를위한 실험이 필요할 때가 있다. 때문에 이 논문에서는 prompterator라는 도구를 제안하여 사용자가 여러가지 prompt를 시도하고 인간의 피드백을 기반으로 가장 성능이 우수한 prompt를 선택하도록 도와준다.
    2. prompterator는 오픈 소스 패키지로, 다양한 LLM 제공 업체를 지원하며, 확장도 쉽게 가능하도록 설계되었다.
    3. 이 도구를 사용하면 인간의 평가를 기반으로 prompt를 선택하여 LLM의 성능을 향상시킬 수 있다.

###### ZhuJiu: A Multi-dimensional, Multi-faceted Chinese Benchmark for Large Language Models (https://aclanthology.org/2023.emnlp-demo.44/)
- Anthology ID: 2023.emnlp-demo.44 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. LLMs 평가를 위해서는 포괄적이고 체계적인 벤치마크가 필요하다. 이 논문에서는 7가지 역량 차원과 51가지 task를 포함하는 Zhujiu 벤치마크를 제안하였다.
    2. 좀 더 정확하고 평가 결과의 신뢰도를 보장하기 위해 3가지 다른 평가 방법을 사용하여 LLMs를 포괄적으로 평가한다.
    3. 중국어로의 포괄적인 벤치마크인 ZhuJiu는 현재 주요 LLMs 10개를 평가하고 그 결과에 대해 깊이 있는 분석과 토의를 진행하였다. 벤치마크와 리더보드는 공개되어 있으며 동영상 데모도 제공된다.

###### PaperMage: A Unified Toolkit for Processing, Representing, and Manipulating Visually-Rich Scientific Documents (https://aclanthology.org/2023.emnlp-demo.45/)
- Anthology ID: 2023.emnlp-demo.45 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. PaperMage는 시각적으로 다양한 구조를 가진 학술 문서를 분석하고 처리하기 위한 Python 기반의 오픈소스 툴킷으로, PDF 형식과 모델 생태계의 단편성과 불완전함으로 인해 어려움을 겪는 학술 문서를 다루는 데 도움을 준다.
    2. PaperMage는 NLP와 CV 모델을 통합된 프레임워크로 제공하여 학문적인 문서 처리에 필요한 기능을 제공하며, 텍스트와 시각적인 요소를 활용해 문서를 효과적으로 다룰 수 있는 기능을 제공한다.
    3. PaperMage는 Semantic Scholar의 대규모 생산 시스템에서 수백만 개의 PDF를 처리하는 용도로 활용되는 등 학술 문서를 다루는 AI 응용 프로토 타입의 개발에 사용되고 있다.

###### OmniEvent: A Comprehensive, Fair, and Easy-to-Use Toolkit for Event Understanding (https://aclanthology.org/2023.emnlp-demo.46/)
- Anthology ID: 2023.emnlp-demo.46 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 이 논문에서는 텍스트 내의 이벤트의 콘텐츠와 관계를 이해하는 이벤트 이해를 위한 OmniEvent 도구킷을 제안한다. 
    2. 이 도구킷은 이벤트 탐지, 이벤트 아규먼트 추출, 이벤트 관계 추출 등의 복잡한 정보 추출 작업을 지원하며 15개의 영어와 중국어 데이터셋의 처리를 지원한다. 
    3. OmniEvent는 종합적이고 공정하며 사용하기 쉬운 도구로 공개되며, 웹 서비스로 직접 배포할 수 있는 기본 모델을 제공하고 사용자가 새로운 이벤트 이해 모델을 쉽게 구현하고 평가할 수 있도록 도와준다.

###### CocoSciSum: A Scientific Summarization Toolkit with Compositional Controllability (https://aclanthology.org/2023.emnlp-demo.47/)
- Anthology ID: 2023.emnlp-demo.47 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 이 연구에서는 과학 커뮤니티의 특수한 요구를 충족시키기 위해 과학 문서의 조절 가능한 요약을 위한 첨단 도구를 제시한다. 사용자의 선호도에 따라 요약을 생성하며, 길이와 키워드 포함 등의 중요한 속성을 조정할 수 있다.
    2. 핵심적인 특징은 CocoSciSum으로 나타나며, 여러 속성을 동시에 관리하고, 단일 및 다중 속성에 대한 제어 능력과 요약 생성의 품질에서 강력한 성능을 보여준다. 
    3. 또한, CocoSciSum은 사용자 중심의 도구로, 자연어 명령으로 표현된 사용자 선호도를 지원하며, 다양한 입력 문서 형식을 수용한다. CocoSciSum은 GitHub (https://github.com/WING-NUS/SciAssist/tree/CocoSciSum)에서 사용 가능하며, 소개 동영상 (https://youtu.be/YC1YDeEjAbQ)도 제공된다.

###### CoLLiE: Collaborative Training of Large Language Models in an Efficient Way (https://aclanthology.org/2023.emnlp-demo.48/)
- Anthology ID: 2023.emnlp-demo.48 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 대규모 언어 모델(LLM)은 다양한 자연어 처리 작업에서 점점 중요해지고 있다. 그러나 이러한 모델을 효율적으로 학습하기 위해서는 대량의 리소스가 필요하다. 이 논문에서는 3D 병렬 처리, PEFT 메서드, Lion, Adan, Sophia, LOMO와 같은 optimizer 등을 활용하여 대규모 언어 모델들을 효율적으로 학습할 수 있는 CoLLiE 라이브러리를 소개한다.
    2. CoLLiE는 모듈식 설계와 포괄적인 기능을 제공하여 효율성, 사용 편의성, 맞춤 설정 기능을 균형있게 제공한다. CoLLiE는 기존의 사례에 비해 사전 학습 및 fine-tuning 시나리오에서 우수한 학습 효율성을 입증했다. 또한, 다양한 optimization 방법에 따른 모델 크기와 GPU 메모리 소비의 상관 관계 및 처리량을 empirical evaluation 하였다.
    3. 또한, CoLLiE를 사용하여 instruction 튜닝(context) 내에서 다양한 optimizer와 PEFT 방법을 종합적으로 비교했다. CoLLiE는 https://github.com/OpenLMLab/collie 에서 사용할 수 있다.

###### Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding (https://aclanthology.org/2023.emnlp-demo.49/)
- Anthology ID: 2023.emnlp-demo.49 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. Video-LLaMA는 Large Language Models (LLMs)에 시각 및 음향 컨텐츠를 이해할 수 있는 능력을 부여하는 멀티모달 프레임워크이다. 이를 위해 Video-LLaMA는 시각 및 음향 인코더와 LLM을 cross-modal 학습시킨다.
    2. Video-LLaMA는 이미지 엔코더를 사용하여 시각적 변화를 캡처하고, 다중 모달을 정렬하는 ImageBind를 활용하여 음향 엔코더를 학습한다.
    3. Video-LLaMA는 비디오 콘텐츠를 인식하고 이해하며, 비디오에 제시된 시각적 및 음향적 정보에 기반한 의미 있는 응답을 생성하는 능력을 보여준다.

###### SummHelper: Collaborative Human-Computer Summarization (https://aclanthology.org/2023.emnlp-demo.50/)
- Anthology ID: 2023.emnlp-demo.50 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 기존의 텍스트 요약 방법은 주로 자동화되어 있어 인간의 개입 및 작업 과정의 제어 여지가 제한적이다.
    2. 본 논문에서는 SummHelper라는 2단계 요약 어시스턴트를 소개하며, 사용자가 시스템이 추천한 내용을 수락, 수정 또는 추가 선택할 수 있도록 한다.
    3. 작은 규모의 사용자 연구를 통해 우리의 응용 프로그램의 효과성을 입증하였고, 참가자들은 자동 가이드와 개인적인 입력 기회 간의 균형을 특히 감사하게 여겼다.

###### ModelScope-Agent: Building Your Customizable Agent System with Open-source Large Language Models (https://aclanthology.org/2023.emnlp-demo.51/)
- Anthology ID: 2023.emnlp-demo.51 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. 최근 큰 언어 모델들은 인간의 의도를 이해하고 추론에 참여하며 계획과 같은 동작을 디자인하는 놀라운 능력을 보여주고 있으나, 복잡한 작업을 수행하는 데 이들의 능력을 발휘하기 위해 LLM을 도구 사용 능력으로 갖춘 에이전트 프레임워크를 구축하는 추세가 있다.
    2. 본 연구에서는 실제 응용 프로그램에 대한 일반적이고 사용자 정의 가능한 에이전트 프레임워크인 ModelScope-Agent를 소개한다. 이는 오픈 소스 LLM을 컨트롤러로 사용하며, 다양한 오픈 소스 LLM에 대한 모델 훈련을 지원하고 모델 API 및 일반적인 API와의 통합을 통일적으로 가능하게 하는 사용자 친화적인 시스템 라이브러리를 제공한다.
    3. 또한, 도구 사용 능력을 갖춘 LLM을 장착하기 위해 도구 사용 데이터 수집, 도구 검색, 도구 등록, 메모리 제어, 사용자 정의 모델 훈련, 실제 응용 프로그램의 평가 등을 포괄하는 종합적인 프레임워크를 제안하였다.

###### EfficientOCR: An Extensible, Open-Source Package for Efficiently Digitizing World Knowledge (https://aclanthology.org/2023.emnlp-demo.52/)
- Anthology ID: 2023.emnlp-demo.52 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations 
- Summary: 
    1. "공개 문서들 중 상당수는 하드 복사본에 갇혀 있거나 정확한 디지털화가 이루어지지 않은 상태입니다. 이런 텍스트들은 현대의 자연어 처리 방법으로 색인화, 검색, 요약, 계산적 텍스트 분석, 통계 분석의 정보 추출이 불가능하며, 언어 모델 훈련에 사용될 수도 없습니다."
    2. "이 논문에서는 대량의 텍스트를 해방시키기 위해 효율적이고 저렴한 규모의 문자 인식 (OCR) 기술이 필요하며, EffOCR이라는 오픈 소스 OCR 패키지를 제안합니다. EffOCR은 시퀀스-투-시퀀스 아키텍처 대신 문자나 단어 수준의 이미지 검색 문제로 OCR을 모델링하여 훈련에 있어 저렴하고 효율적인 방법을 제공합니다."
    3. "또한, EffOCR은 모바일 폰용으로 설계된 경량 모델을 포함하여 손쉽게 배포될 수 있는데, 개별 라인의 코드로 사용하며, 샘플 효율성 덕분에 단순한 모델 훈련 인터페이스와 최소한의 라벨링 요구 사항을 가지고 쉽고 효율적인 맞춤화를 가능하게 합니다."

## Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track
###### Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track (https://aclanthology.org/2023.emnlp-industry.0/)
- Anthology ID: 2023.emnlp-industry.0 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    요약문을 생성할 수 없습니다.

###### BeautifulPrompt: Towards Automatic Prompt Engineering for Text-to-Image Synthesis (https://aclanthology.org/2023.emnlp-industry.1/)
- Anthology ID: 2023.emnlp-industry.1 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 최근 텍스트-이미지 합성에서 Diffusion 기반 딥 생성 모델 (예 : Stable Diffusion)은 놀라운 결과를 보여주었지만, 현재의 텍스트-이미지 모델은 실제 응용 프로그램에 만족스러운 결과를 얻기 위해 사람들에 의한 여러 번의 문구 작업이 필요하다.
    2. 우리는 간단한 원시 설명에서 고품질 프롬프트를 생성하는 깊은 생성 모델인 BeautifulPrompt를 제안하며, 이를 통해 확산 기반 모델이 더 아름다운 이미지를 생성할 수 있다.
    3. 시각 AI 피드백과 강화 학습을 활용하여 모델을 세밀하게 조정하여 더 아름다운 이미지를 생성할 수 있는 프롬프트를 생성하고, 이를 클라우드 내 AI 플랫폼에 통합하여 더 나은 텍스트-이미지 생성 서비스를 제공하는 것을 보여준다.

###### Enhancing Language Model with Unit Test Techniques for Efficient Regular Expression Generation (https://aclanthology.org/2023.emnlp-industry.2/)
- Anthology ID: 2023.emnlp-industry.2 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 최근 generative language models을 사용하여 시맨틱 기반의 정규 표현식을 생성하는 연구가 진행되었으나, 이러한 접근 방식은 기능적인 정확성에 문제가 있어 실제 적용에서의 한계가 있다.
    2. 이 논문에서는 Unit-Test Driven Reinforcement Learning (UTD-RL)라는 새로운 방법을 제안하는데, 기존 방법과는 다르게 기능적인 정확성을 중요한 측면으로 고려하고 정책 기울기 기술을 사용하여 가중 피드백으로 변환한다.
    3. 실험 결과, 제안된 방법은 정규 표현식 생성에서 효과적이며, 그 결과는 규제 시나리오에서도 적용되어 관련 인원들의 작업 부하를 크게 줄일 수 있다.

###### A Comparative Analysis of Task-Agnostic Distillation Methods for Compressing Transformer Language Models (https://aclanthology.org/2023.emnlp-industry.3/)
- Anthology ID: 2023.emnlp-industry.3 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 최근 NLP에서 상위 성능을 보이는 대형 언어 모델은 실제 개발에서 추론 비용 때문에 비효율적이다. 
    2. 본 연구에서는 Transformer 언어 모델의 과제-비구조(distillation)에 대한 대표적인 방법들을 재생산, 비교 및 분석하였다. 
    3. 결과적으로, MiniLMv2를 기반으로 한 MHA 전이는 일반적으로 가장 효과적이며, HS 전이는 sophisicated한 레이어 매핑 전략 아래에서 경쟁력 있는 베이스라인을 형성하는 것을 보였다.

###### Towards Effective Automatic Debt Collection with Persona Awareness (https://aclanthology.org/2023.emnlp-industry.4/)
- Anthology ID: 2023.emnlp-industry.4 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 채권자의 퍼스널리티를 이해하는 것은 채권자가 채무자와 공감하며 효과적인 수금 전략을 개발하는 데 중요하다.
    2. 본 연구는 채무자의 퍼스널리티의 중요성을 종합적으로 조사하고, 자동 채권 수금 에이전트에 대한 성공적인 상용 실천 사례를 제시한다.
    3. 퍼스널리티에 대한 대화 데이터셋을 구축하여 효과적인 에이전트를 구현한 결과, 수입률이 3.31% 증가하고 약 100,000위안의 추가 수금을 달성했다.

###### Gatekeeper to save COGS and improve efficiency of Text Prediction (https://aclanthology.org/2023.emnlp-industry.5/)
- Anthology ID: 2023.emnlp-industry.5 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 텍스트 예측 작업에서는 사용자가 제안을 수락할 때까지 거의 모든 문자마다 큰 언어 모델을 호출하는데, 이는 모델의 실행 비용을 높이고 정확하지 않은 예측까지 네트워크와 계산 비용을 발생시킨다. 
    2. 따라서 클라이언트 응용 프로그램 수준에서 잘못된 예측을 방지하기 위해 모델 게이트키퍼를 제안한다. 이를 통해 모델 호출 비용을 절약하고 잘못된 예측을 사용자에게 보여주지 않음으로써 사용자 경험을 향상시킬 수 있다.
    3. 모델 게이트키퍼의 사용으로 텍스트 예측 모델의 효율성이 약 73% 향상되고, COGS(임원 지출, 비용, 수익)를 약 46.6% 절약할 수 있었다.

###### Efficient Transformer Knowledge Distillation: A Performance Review (https://aclanthology.org/2023.emnlp-industry.6/)
- Anthology ID: 2023.emnlp-industry.6 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 사전 훈련된 transformer 언어 모델들이 최고 수준의 성능을 보이며, 모델 압축과 효율적인 어텐션 메커니즘에 대한 연구가 이루어졌다. 이 논문에서는 지식 증류를 통한 모델 압축에 대한 평가를 제시하고, 효율적인 어텐션 transformer의 압축에 따른 성능 향상을 연구한다. 
    2. 실험 결과, 훈련된 효율적인 어텐션 transformer는 원래 모델의 성능을 상당 부분 보존할 수 있으며, 추론 시간을 최대 57.8%까지 줄일 수 있다는 것을 발견했다.
    3. 지식 증류는 대부분의 모델과 대부분의 태스크에서 효과적인 방법으로 나타났으며, 저비용으로 높은 성능을 가진 효율적인 어텐션 모델을 얻는데 효과적인 방법으로 나타났다.

###### CDD: A Large Scale Dataset for Legal Intelligence Research (https://aclanthology.org/2023.emnlp-industry.7/)
- Anthology ID: 2023.emnlp-industry.7 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 최근 인공지능의 중요한 응용 분야로 법률 지능이 많은 연구자들의 관심을 끌고 있다. 이 논문에서는 법정 판결 예측을 지원하는 연구를 위한 대규모 법정 토론 데이터셋(총 30,481건의 법정 사건)을 제안한다.
    2. 실제 법정 트라이얼에서 판사, 원고, 피고자들 간의 대화를 포함하는 이 데이터셋은 텍스트 요약, 대화 생성, 텍스트 분류 등 여러 다운스트림 태스크에 적용될 수 있다.
    3. 경험 있는 판사들에게 적절한 레이블을 설계하도록 초대한 후, 법학 학생들에게 정의된 레이블에 따라 주석을 달도록 요청하여 데이터셋을 구축했으며, 이를 통해 법률 지능 분야의 연구가 발전될 수 있다는 점과 그에 따른 성능 벤치마크 결과를 제공한다.

###### MUST&P-SRL: Multi-lingual and Unified Syllabification in Text and Phonetic Domains for Speech Representation Learning (https://aclanthology.org/2023.emnlp-industry.8/)
- Anthology ID: 2023.emnlp-industry.8 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 이 논문에서는 Montreal Forced Aligner (MFA)라는 강제 정렬 도구와 호환될 수 있는 언어적 특징 추출 방법론을 제시한다. 
    2. 텍스트와 음성적 도메인 양쪽에서, 우리의 방법론은 텍스트에서 음성적 문자를 추출하고 강세 기호와 통합된 자동 음절화를 중점적으로 한다.
    3. 우리는 영어, 프랑스어 및 스페인어 등 여러 언어의 단어를 자동 음절화하는 우리의 접근법의 효과를 연구를 통해 입증하였고, 또한 CMU ARCTIC 데이터셋의 전사에 이 기법을 적용하여 스피치 표현 학습, 스피치 유닛 탐색 및 스피치 관련 분야에서의 스피치 요소의 분리에 유용한 주석을 생성하였다.

###### Personalized Dense Retrieval on Global Index for Voice-enabled Conversational Systems (https://aclanthology.org/2023.emnlp-industry.9/)
- Anthology ID: 2023.emnlp-industry.9 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 음성 제어 AI 대화 시스템은 음운 변이와 모호한 개체 해결에 대한 노이즈에 영향을 받는데, 이러한 오류 모드에서 회복하기 위해 개인화된 개체 해결 (ER)과/또는 쿼리 재작성 (QR)이 사용된다. 
    2. 이 논문에서는 개인화된 인덱스에 대한 제약 없이 음성 노이즈와 모호성에 강한 개인화된 개체 검색 시스템을 제안한다. 
    3. 이를 위해 개인의 청취 선호도를 조건화한 상황적 쿼리 임베딩을 사용하여 개체 검색에 사용되며, 기준선에 비해 엔티티 검색 작업에서 91%의 성능 향상을 보였다.

###### Text2Topic: Multi-Label Text Classification System for Efficient Topic Detection in User Generated Content with Zero-Shot Capabilities (https://aclanthology.org/2023.emnlp-industry.10/)
- Anthology ID: 2023.emnlp-industry.10 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. Multi-label 텍스트 분류는 산업에서 매우 중요한 작업인데, 이 논문에서는 Bi-Encoder Transformer 아키텍처를 사용해 높은 분류 성능을 달성하며 zero-shot 예측과 도메인 특화 텍스트 임베딩, 대용량 배치 추론 등 여러 기능을 제공한다.
    2. Text2Topic은 Booking.com의 3개 주요 데이터 소스에서 약 120,000개의 텍스트를 사용하여 약 1.6백만 개의 텍스트-토픽 쌍 주석을 수집하였고, 이를 통해 다른 기법들과 비교했을 때 정확하고 포괄적인 결과를 달성했으며 실제 시스템에 배포되어 사용된다.
    3. 어떠한 모델링 선택지를 했는지, 어떤 테스트와 생산 단계 결정 사항이 있었는지 상세하게 정리되어 있다.

###### Deep Metric Learning to Hierarchically Rank - An Application in Product Retrieval (https://aclanthology.org/2023.emnlp-industry.11/)
- Anthology ID: 2023.emnlp-industry.11 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 대부분의 전자상거래 검색 엔진은 고객 행동 신호를 사용하여 어휘적 일치를 보완하고 검색 관련성을 향상시키는데, 하지만 고객 행동 데이터가 희소한 새로운 상점에서는 문제가 발생한다. 이 논문에서는 상점 간의 중복 및 거의 중복 제품을 식별하는 모델을 개발하였다. 
    2. 제안된 모델은 세계적으로 제품 카탈로그를 유니파이하거나 제품 메타데이터를 개선하거나 검색 관련성을 향상하기 위해 거의 중복 제품을 활용할 수 있다.
    3. 제안된 방법은 다국어로 통합된 검색 및 순위 결합 방법을 통해 제품 유사도 계층 구조를 포착하고 우수한 성과를 보여준다는 점을 실험을 통해 확인하였다.

###### A Pretrained Language Model for Cyber Threat Intelligence (https://aclanthology.org/2023.emnlp-industry.12/)
- Anthology ID: 2023.emnlp-industry.12 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. CTI-BERT는 사이버보안 도메인에서의 CTI 추출 정확도를 개선하여 잠재적인 사이버 위협에 대한 조직의 방어 능력을 향상시킬 수 있는 새로운 BERT 모델을 제안한다.
    2. 이 논문에서는 사이버보안 도메인의 다양한 NLP 과제에 대한 도메인 말뭉치 수집, 훈련 방법 및 효과에 대한 자세한 정보를 제공한다.
    3. 실험 결과, CTI-BERT는 일반 도메인 및 보안 도메인 모델들보다 사이버보안 응용 프로그램에서 우수한 성능을 보이며, 훈련 데이터와 방법론이 모델 성능에 큰 영향을 미친다는 것을 보여준다.

###### SAMP: A Model Inference Toolkit of Post-Training Quantization for Text Processing via Self-Adaptive Mixed-Precision (https://aclanthology.org/2023.emnlp-industry.13/)
- Anthology ID: 2023.emnlp-industry.13 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. FasterTransformer와 TurboTransformers와 같은 최신 산업용 추론 엔진은 반정밀도 부동 소수점 (FP16) 및 8비트 정수 (INT8) 양자화가 모델 추론 속도를 크게 향상시킬 수 있다는 것을 검증하였다. 
    2. 그러나 기존의 INT8 양자화 방법은 너무 복잡하여 부적절한 사용으로 인해 모델 성능에 큰 손상을 유발한다. 
    3. 본 논문에서는 SAMP (Self-Adaptive Mixed-Precision)이라는 기술을 제안하여 혼합 정밀도 아키텍처를 통해 양자화 비율을 자동으로 제어하여 모델 정확성과 효율성을 균형있게 조절할 수 있도록 사용자가 모델을 쉽게 양자화할 수 있는 도구를 개발한다.

###### KD-Boost: Boosting Real-Time Semantic Matching in E-commerce with Knowledge Distillation (https://aclanthology.org/2023.emnlp-industry.14/)
- Anthology ID: 2023.emnlp-industry.14 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 웹 및 제품 검색에서 실시간 의미 일치가 중요한데, Transformer 기반 모델은 쿼리를 임베딩 공간으로 인코딩하여 의미적으로 유사한 엔티티들을 가까운 거리로 표현하는 데 높은 효과를 보여주었다.
    2. 그러나 대규모 Transformer 모델의 계산 복잡성으로 인해 실시간 일치에 제한이 있다. 이 논문에서는 실시간 의미 일치를 위한 새로운 지식 증류 알고리즘인 KD-Boost를 제안한다.
    3. KD-Boost는 선생님 모델로부터의 soft label과 직접적인 감사, 사용자 행동, 분류 기반 데이터로부터 파생된 쌍별 쿼리-제품 및 쿼리-쿼리 신호를 활용하여 낮은 대기 시간의 정확한 학생 모델을 훈련시킨다. KD-Boost를 사용한 모의 온라인 A/B 테스트에서는 6.31%의 쿼리 대 쿼리 일치 증가, 2.76%의 제품 커버리지 증가, 그리고 2.19%의 관련성 개선이 있었다.

###### Multi-teacher Distillation for Multilingual Spelling Correction (https://aclanthology.org/2023.emnlp-industry.15/)
- Anthology ID: 2023.emnlp-industry.15 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 현대의 검색 인터페이스에서 맞춤법 교정은 특히 모바일 기기와 음성 인식 인터페이스 시대에 중요한 단계이다. 전 세계에서 서비스가 배포되는 경우, 모든 언어에서 스펠링 오류를 잡고 수정해야 하는 중요한 과제로 거듭난다.
    2. 이 논문에서는 multi-teacher distillation을 사용하여 이 도전에 대처한다. 방법론은 각 언어/로캘에 대해 단일 언어 선생님 모델을 훈련시키고, 이러한 개별 모델을 모든 언어/로캘을 대상으로 하는 단일 다국어 학생 모델로 축약한다.
    3. 오픈 소스 데이터와 전 세계 검색 서비스의 고객 데이터를 사용한 실험에서, 우리는 효과적인 맞춤법 교정 모델을 얻을 수 있으며, 배포된 서비스의 엄격한 대기 시간 요구 사항을 충족시킬 수 있음을 보여준다.

###### Does Named Entity Recognition Truly Not Scale Up to Real-world Product Attribute Extraction? (https://aclanthology.org/2023.emnlp-industry.16/)
- Anthology ID: 2023.emnlp-industry.16 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 속성-값 추출 작업(AVE)의 주요 과제는 실제 전자 상거래 사이트에서 다양한 속성에 대한 대규모 제품에 확장 가능한 것이다. 최근 연구자들은 대상 속성을 추가로 입력하여 해당 속성의 값을 추출하는 질문-응답(QA) 기반 접근 방식을 도입하여, 전통적인 명명된 개체 인식(NER) 기반 접근 방식과 비교하여 이점을 확인하였다.
    2. 이 연구에서는 QA 기반 접근 방법을 평가하기 위해, BERT 기반 QA 모델을 판단 기준으로 세운 약한 BiLSTM 기반 NER 베이스라인과만 비교하였기 때문에 NER 기반 접근 방식의 확장 가능성을 논한다.
    3. 실제 데이터셋을 사용한 실험 결과, 공정한 설정에서 BERT 기반 NER 모델은 정확성 측면에서 BERT 기반 QA 모델과 어울릴 정도로 동등하며, 같은 제품 텍스트를 여러 번 처리하여 여러 대상 속성을 처리하는 QA 모델에 비해 추론 속도가 빠르다.

###### Investigating Table-to-Text Generation Capabilities of Large Language Models in Real-World Information Seeking Scenarios (https://aclanthology.org/2023.emnlp-industry.17/)
- Anthology ID: 2023.emnlp-industry.17 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 다양한 산업에서 널리 사용되는 표 형식의 데이터는 사용자가 정보를 찾고 조작하는 데 시간과 노력이 많이 필요하다. 
    2. 하지만 대용량 언어 모델 (LLM)의 발전은 사용자의 효율성을 향상시킬 수 있는 엄청난 잠재력을 보여주었으나, 표 정보 탐색에서의 LLM 활용은 아직 탐구되지 않고 있다.
    3. 이 논문에서는 실제 정보 탐색 시나리오에서 다양한 LLM의 표-텍스트 능력을 조사하고, GPT-4를 포함한 다른 LLM과의 성능 차이를 밝히고 있다.

###### TMID: A Comprehensive Real-world Dataset for Trademark Infringement Detection in E-Commerce (https://aclanthology.org/2023.emnlp-industry.18/)
- Anthology ID: 2023.emnlp-industry.18 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 상표권 침해를 탐지하기 위한 새로운 데이터셋인 TMID가 소개되었으며, 이는 Alipay와 같은 세계 최대의 전자상거래와 디지털 결제 플랫폼에서 직접 수집된 실제 데이터이다.
    2. 이 데이터셋은 법적 추론 작업으로, 문맥과 법적 규칙을 이해하는 것을 요구하는데, 법률 전문가들의 주석과 함께 상인 및 상표 관련 문맥 정보의 철저한 수집을 제공한다.
    3. 통계적 분석을 수행하여 데이터 품질을 보장하며, 이 데이터셋을 활용한 실험을 통해 이의 가치와 주요 도전 과제를 강조한다.

###### Joint Dialogue Topic Segmentation and Categorization: A Case Study on Clinical Spoken Conversations (https://aclanthology.org/2023.emnlp-industry.19/)
- Anthology ID: 2023.emnlp-industry.19 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 자연어 처리 기술을 이용하여 임상 대화를 처리하는 것은 의료진과 환자의 건강관리 업무의 효율성을 향상시키는 데 효과적이다.
    2. 일반화된 모델이 도메인 특정 응용 프로그램에 즉시 적용되지 않는다. 이는 분할 세분화와 주제 정의의 다양성, 다양한 주석이 된 코퍼스의 부족으로 인해 발생한다.
    3. 이 논문에서는 대화 분할과 주제 분류를 위해 공통 모델을 도입하고 당뇨병 관리를 위한 의료 후속 전화에 대한 사례 연구를 진행한다. 성능과 견고성에 대한 데이터와 모델 관점에서 통찰력을 제공한다.

###### AdapterDistillation: Non-Destructive Task Composition with Knowledge Distillation (https://aclanthology.org/2023.emnlp-industry.20/)
- Anthology ID: 2023.emnlp-industry.20 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 최근에는 "어댑터"라고 불리는 각 transformer layer에 일부 작업 특정 파라미터들을 추가하여 여러 작업의 지식을 활용하는 것이 큰 관심을 받고 있다. 그러나 지식 합성을 구현하기 위해 추가적인 퓨전 레이어를 추가하는 것은 추론 시간을 증가시키고 일부 응용 프로그램에서는 확장성이 없다. 이런 문제를 피하기 위해 우리는 AdapterDistillation이라고 불리는 두 단계의 지식 전달 알고리즘을 제안한다.
    2. 첫 번째 단계에서는 로컬 데이터를 사용하여 학생 어댑터를 훈련하여 작업별 지식을 추출한다. 두 번째 단계에서는 기존의 교사 어댑터로부터 학생 어댑터로 지식을 전달하여 추론을 도와준다.
    3. 작업 지향적 대화 시스템에서 자주 사용되는 질문 검색 작업에 대한 실험 결과, AdapterDistillation의 효율성이 입증되었다. 정확도, 리소스 소비 및 추론 시간 측면에서 AdapterDistillation이 기존 알고리즘보다 우수한 성능을 보여준다.

###### PROMINET: Prototype-based Multi-View Network for Interpretable Email Response Prediction (https://aclanthology.org/2023.emnlp-industry.21/)
- Anthology ID: 2023.emnlp-industry.21 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. "이메일은 비즈니스 커뮤니케이션에서 널리 사용되는 도구이며, 이메일 마케팅은 기업에게 비용 효과적인 전략으로 부상하고 있다. 그러나 이전 연구들은 이메일 마케팅 성과에 영향을 미치는 요소들을 조사해 왔지만, 이메일 콘텐츠와 메타데이터를 고려한 이메일 반응 행동을 이해하는 데 제한된 연구가 있었다."
    2. 이 연구는 이메일 데이터에서 의미론적 및 구조적 정보를 포함하는 프로토타입 기반 멀티뷰 네트워크 (PROMINET)를 제안한다. PROMINET 모델은 프로토타입 학습을 활용하여 해석 가능한 이메일 응답 예측을 가능하게 한다. 모델은 문서, 문장 또는 구문과 같은 다양한 정밀도 수준에서 학습된 의미론적 및 구조적 인스턴스를 훈련 데이터의 관찰된 샘플과 매핑한다.
    3. 실험 결과 PROMINET 모델은 기준 모델에 비해 F1 점수에서 약 3%의 성능 향상을 보이며, 해석 가능한 모델과 비교 가능한 성능을 유지하면서 다양한 정밀도 수준의 프로토타입을 통해 해석 가능성을 제공한다. 학습된 프로토타입은 이메일 텍스트 편집을 향상시키고 효과적인 이메일 응답 가능성을 향상시키기 위한 제안 생성의 잠재력도 보여준다. 이 연구는 이메일 상호작용에서 발신자-수신자 커뮤니케이션과 고객 참여를 향상시키는 데 기여한다."

###### Retrieval-Enhanced Dual Encoder Training for Product Matching (https://aclanthology.org/2023.emnlp-industry.22/)
- Anthology ID: 2023.emnlp-industry.22 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 판매자가 상품을 올렸을 때 적절한 상품과 매칭하는 것은 전자상거래 플랫폼에게 중요한 과제이며, 대규모 환경에서 효율적으로 실행되어야 한다.
    2. 최근에는 두 개의 인코더를 사용하는 방식이 높은 성능과 계산 효율성으로 인해 상품 매칭에서 일반적인 접근법이 되었다.
    3. 본 논문에서는 두 단계의 훈련을 제안하며, 첫 번째 단계에서는 더 정보가 많은 훈련 데이터를 식별하는 데에 드우며, 두 번째 단계에서는 효과적인 데이터로 학습하여 더 나은 인코더 모델을 만든다.

###### WordArt Designer: User-Driven Artistic Typography Synthesis using Large Language Models (https://aclanthology.org/2023.emnlp-industry.23/)
- Anthology ID: 2023.emnlp-industry.23 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. WordArt Designer는 사용자 중심의 예술적 타이포그래피 합성을 위한 프레임워크이다. Large Language Model (LLM)과 네 가지 핵심 모듈로 구성되어 있다.
    2. LLM 엔진은 사용자 입력을 해석하고 다른 모듈에 대한 작업 가능한 프롬프트를 생성하여 추상적인 개념을 구체적인 디자인으로 변환한다.
    3. SemTypo 모듈은 읽기 가능성과 예술적 변환 사이의 균형을 고려하여 의미적 개념을 활용하여 폰트 디자인을 최적화한다. StyTypo 모듈은 SemTypo 모듈이 제공한 의미적 레이아웃을 기반으로 부드럽고 정제된 이미지를 생성한다. TexTypo 모듈은 텍스처 렌더링을 통해 디자인의 미적인 요소를 강화하여 창의적인 텍스처 폰트를 생성한다.

###### Lattice Path Edit Distance: A Romanization-aware Edit Distance for Extracting Misspelling-Correction Pairs from Japanese Search Query Logs (https://aclanthology.org/2023.emnlp-industry.24/)
- Anthology ID: 2023.emnlp-industry.24 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 검색 쿼리 로그로부터 스펠링 교정 모델의 학습 데이터인 오탈자-정정 짝을 추출하는 데 성공한 것은 편집 거리의 영향이다. 그러나 이는 일본어에 적용하기 어렵다. 
    2. 일본어에서 오탈자는 주로 로마자 기반의 입력 방법 때문에 올바른 스펠링과 다름이 많기 때문이다.
    3. 이 문제를 해결하기 위해 로마자 라티스 경로 편집 거리를 소개하고, 로마자 라티스를 활용하여 입력 문자열의 모든 로마자 형태를 효율적으로 고려한다.

###### Learning Multilingual Sentence Representations with Cross-lingual Consistency Regularization (https://aclanthology.org/2023.emnlp-industry.25/)
- Anthology ID: 2023.emnlp-industry.25 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 다국어 문장 표현은 다국어 신경 기계 번역(NMT) 시스템을 더 많은 언어로 확장하기 위한 중요한 요소이다.
    2. 이 논문에서는 223개 언어를 지원하는 MuSR(Multilingual Sentence Representation) 모델을 소개한다. 수십억 개의 영어 중심 병렬 문장 데이터를 활용하여 transformer encoder와 auxiliary transformer decoder를 훈련시킨다.
    3. 실험 결과는 MuSR이 148개 독립적인 다국어 문장 인코더로 구성된 LASER3보다 우수한 성능을 보여준다.

###### Unveiling Identity Biases in Toxicity Detection : A Game-Focused Dataset and Reactivity Analysis Approach (https://aclanthology.org/2023.emnlp-industry.26/)
- Anthology ID: 2023.emnlp-industry.26 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 주로 성별이나 인종적 편향에 초점을 둔 기존 bias benchmarking 데이터셋은 게임 채팅의 독성 감지를 위해 만들어진 모델에는 적합하지 않은 문제였으며, 이러한 과민한 용어를 강조하기 위한 데이터셋과 방법을 제안한다.
    2. 우리는 reactivity analysis와 모델의 성능을 활용하여 과민한 용어를 강조하는 데이터셋과 방법을 개발하였다.
    3. 우리의 실험 결과, 독성 모델들이 이미 어려움을 겪는 그룹의 존재를 알리지 못하게 하거나 성숙한/정상적인 대화를 할 수 없게 하는 공동체의 정체성과 관련된 용어를 자동으로 독성으로 분류하는 경우가 많다는 것을 발견하였다.

###### ORANGE: Text-video Retrieval via Watch-time-aware Heterogeneous Graph Contrastive Learning (https://aclanthology.org/2023.emnlp-industry.27/)
- Anthology ID: 2023.emnlp-industry.27 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. TikTok과 YouTube와 같은 산업용 비디오 공유 플랫폼에서 짧은 영상 데이터가 폭발적으로 증가함에 따라, 텍스트-비디오 검색 기술은 점점 중요해지고 있다.
    2. 기존의 텍스트-비디오 검색 작업은 질문과 비디오 자체의 내용 정보(질문의 텍스트 정보 및 비디오의 복합 정보)를 활용하는 정보성 표현 및 매칭 메커니즘에 초점을 맞추고 있다. 
    3. 하지만 현실적인 상황에서는 간단하고 모호한 질문과 저화질 비디오가 많아서 내용 기반 검색이 효과적이지 못하다. 이 논문은 이러한 다양한 검색 요구를 수용하고 사용자 만족도를 향상시키기 위해 새로운 텍스트-비디오 검색 방법인 ORANGE를 소개한다.

###### Compute-Efficient Churn Reduction for Conversational Agents (https://aclanthology.org/2023.emnlp-industry.28/)
- Anthology ID: 2023.emnlp-industry.28 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. "모델의 변동(churn)은 같은 데이터와 하이퍼파라미터를 사용하더라도 재학습 시 다른 예측 결과가 나타날 때 발생한다. 이러한 변동을 줄이는 것은 사용자가 동일한 쿼리에 대해 일관된 결과를 기대하는 산업용 대화 시스템에서 중요하다."
    2. "우리는 추가적인 자원을 요구하지 않으면서도 변동을 완화하는 계산 효율적인 방법을 제안한다. 이 방법은 '함수 호출 서명'을 기반으로 의미 파싱을 짝지움으로써 가벼운 데이터 전처리 단계를 수행하고, Jensen-Shannon Divergence를 기반으로 한 추가적인 손실을 통해 유사성을 촉진한다."
    3. "우리는 학술(평균 3.93%의 변동 감소 메트릭 개선), 시뮬레이션된 잡음 데이터(8.09%), 산업(5.28%) 환경에서 우리의 방법의 효과를 검증하였다."

###### Empower Large Language Model to Perform Better on Industrial Domain-Specific Question Answering (https://aclanthology.org/2023.emnlp-industry.29/)
- Anthology ID: 2023.emnlp-industry.29 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 대형 언어 모델 (LLM)은 개방형 도메인 작업에서 높은 성능을 보여주었으나, 실제 산업 분야에서 도메인 특정 지식 부족으로 평균적인 성능을 보인다. 
    2. 이 논문에서는 Microsoft 제품과 고객이 마주치는 IT 기술 문제를 중심으로 한 MSQA라는 벤치마크 QA 데이터셋을 제공한다. 
    3. 이 데이터셋은 일반 LLM에서는 제대로 다루지 않는 산업 클라우드 특정 QA 지식을 포함하고 있어서 LLM의 도메인 특정 능력을 향상시키고자 하는 방법을 평가하는 데 적합하다.
    
    주어진 paper에서는 Microsoft 제품과 IT 기술 문제를 다루는 산업 분야에 대한 벤치마크 데이터셋인 MSQA를 제공하고, 이 데이터셋을 활용하여 LLM의 도메인 특정 능력을 향상시키는 방법을 제안하고 실험 결과를 보여준다.

###### Enhancing Extreme Multi-Label Text Classification: Addressing Challenges in Model, Data, and Evaluation (https://aclanthology.org/2023.emnlp-industry.30/)
- Anthology ID: 2023.emnlp-industry.30 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. Extreme multi-label text classification은 산업에서 흔한 작업이지만, 일반적인 SciBERT 기반 분류 모델의 한계, 데이터 부족 문제, 시간이 소요되는 평가와 같은 기계 학습 측면에서 많은 도전을 겪는다.
    2. 우리는 두 가지 혁신적인 접근 방식을 제시하여 이러한 문제를 완화하고자 한다. 먼저, 대규모 레이블을 효율적으로 처리하고 새로운 레이블을 수용할 수 있는 레이블 순위 모델을 제안한다.
    3. 또한, 분류 시스템의 업데이트 과정에서 새로운 레이블의 데이터 부족 문제를 해결하기 위한 액티브 러닝 기반 파이프라인을 제안하고, ChatGPT를 통해 모델 평가를 보조하는 방식을 소개한다. 실험 결과는 이러한 기술들이 extreme multi-label text classification 작업을 향상시키는 데 효과적임을 보여준다.

###### Query-aware Multi-modal based Ranking Relevance in Video Search (https://aclanthology.org/2023.emnlp-industry.31/)
- Anthology ID: 2023.emnlp-industry.31 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 비디오 검색에서 중요도 순위 시스템은 스트리밍 플랫폼에서 중요한 역할을 한다. 
    2. 이 논문에서는 텍스트 모달리티에 초점을 맞춘 relevance ranking 방법들이 비디오 내에 존재하는 cross-modal 정보를 완전히 활용하지 못한다는 문제점이 있다고 분석하였다. 
    3. 이를 해결하기 위해, 우리는 query 정보를 정렬 타겟으로 활용하는 모델인 QUALITY를 제안하고, 이를 relevance ranking 모델에 통합하여 다중 모달 지식을 활용하고 순위 최적화 방법을 향상시켰다.

###### Coordinated Replay Sample Selection for Continual Federated Learning (https://aclanthology.org/2023.emnlp-industry.32/)
- Anthology ID: 2023.emnlp-industry.32 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 지속적 페더레이티드 학습(CFL)은 페더레이티드 학습(FL)과 계속적 학습(CL)을 결합한 것으로, 여러 클라이언트 장치에서 중앙 모델을 학습하되 데이터를 공유하지 않는 구조를 가진다.
    2. 이 논문에서는 줄줄이 새로운 데이터가 들어올 때 기존 데이터를 잊는 것이 주요 과제로 제시되고 있다.
    3. 지난 연구에서는 단순한 재생 샘플 선택 전략만 CFL에 적용되었으며, 클라이언트 간 협력을 통한 더 나은 샘플 선택은 고려되지 않았다. 이 논문에서는 샘플 선택 목적을 최적화하기 위해 그래디언트 기반의 재생 샘플 선택 방법과 데이터를 공유하지 않으면서 클라이언트 간 그래디언트 기반의 재생 샘플 선택을 조정하는 알고리즘을 제안하고 있다.

###### Building Real-World Meeting Summarization Systems using Large Language Models: A Practical Perspective (https://aclanthology.org/2023.emnlp-industry.33/)
- Anthology ID: 2023.emnlp-industry.33 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 본 논문은 대규모 언어 모델(Large Language Model; LLM)을 사용하여 현실 세계에서 회의 요약 시스템을 효과적으로 구축하는 방법을 연구한다.
    2. 대다수의 상용 LLM은 일반적으로 더 나은 성능을 보이지만, 작은 오픈 소스 모델인 LLaMA-2 (7B 및 13B)는 제로샷 시나리오에서도 대형 상용 모델과 비교 가능한 성능을 달성할 수 있다.
    3. 성능과 연관된 비용 및 개인 정보 보호 문제를 균형있게 고려할 때, LLaMA-2-7B 모델이 산업용으로 더 유망하다. 총론적으로, 이 논문은 실제 비즈니스 회의 요약에 LLM을 사용하는 데 대한 실용적인 통찰력을 제공하며, 성능과 비용 사이의 트레이드오프에 대한 양면의 조명을 한다.

###### Creator Context for Tweet Recommendation (https://aclanthology.org/2023.emnlp-industry.34/)
- Anthology ID: 2023.emnlp-industry.34 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 트윗을 논할 때 사람들은 주로 그 내용에 대한 언급뿐 아니라 트윗의 작성자에 관해서도 언급한다. 다시 말해, 트윗의 해석을 작성자의 맥락에 근거하여 해독하는 것이 트윗의 진짜 의도와 중요성을 파악하는 데 중요한 역할을 한다.
    2. 이 논문에서는 트윗 이해를 발전시키기 위해 작성자의 맥락을 어떻게 사용해야 하는지에 대한 질문에 대답하려고 한다. 특히, 다양한 유형의 작성자 맥락의 유용성을 조사하고 트윗 모델에 작성자 맥락을 통합하기 위한 다양한 모델 구조를 검토한다.
    3. 우리는 트윗 이해 모델을 실용적인 사례인 뉴스 기사에 관련 트윗을 추천하는 데에 적용하여 평가한다. 이 경우는 이미 인기있는 뉴스 앱에 존재하며, 기자들에게 유용한 보조 도구 역할도 할 수 있다. 우리는 작성자 맥락이 트윗 이해에 필수적이며, 응용 프로그램 지표를 크게 개선시킬 수 있다는 것을 발견했다. 그러나 모든 작성자 맥락이 동일하지는 않다는 것도 관찰되었다. 작성자 맥락은 시간에 민감하고 노이즈가 될 수 있다. 신중한 작성자 맥락 선택과 모델 구조 설계는 작성자 맥락의 효과적인 활용에 중요한 역할을 한다.

###### AdaBERT-CTC: Leveraging BERT-CTC for Text-Only Domain Adaptation in ASR (https://aclanthology.org/2023.emnlp-industry.35/)
- Anthology ID: 2023.emnlp-industry.35 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. E2E 자동 음성 인식(ASR) 모델은 가상 어시스턴트, 자막, 딕테이션 시스템 등 상업적 응용분야에서 점점 인기를 끌고 있다. 그러나 E2E 모델은 여전히 명사나 도메인 특정 용어와 같은 도메인 외 단어를 인식하는 데 어려움을 겪고 있다. 
    2. 본 논문에서는 텍스트 데이터만을 활용하는 도메인 적응 기술인 AdaBERT-CTC를 소개한다. 우리의 방법은 사전 학습된 self-supervised 텍스트 인코더 모델을 fine-tuning하여 텍스트만으로 적응을 가능하게 한다. 
    3. 또한, 우리의 방법은 사전 학습 모델에 bottleneck 어댑터를 추가함으로써 파라미터를 효율적으로 관리할 수 있다. 이를 통해 파라미터 증가량이 5% 미만이며 추론 시 최소한의 계산 비용만 발생한다. 여러 도메인 외, 공개 데이터셋을 기반으로 실험 결과, 우리의 접근 방식이 기본 BERT-CTC 모델 대비 14%까지 상대적인 단어 오류율 개선을 얻을 수 있음을 보여주었다.

###### Conversing with databases: Practical Natural Language Querying (https://aclanthology.org/2023.emnlp-industry.36/)
- Anthology ID: 2023.emnlp-industry.36 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 본 논문에서는 DataQue라는 하이브리드 NLQ 시스템을 개발하여 대화식 DB 질의를 수행한다. 이 시스템은 고객의 다양한 실제적인 문제를 해결하기 위해 설계되었으며, 사용자 질문에 포함된 다양한 복잡한 implicit 조건, 용어와 약어, 사용자 정의 계산, SQL이 아닌 연산 등을 처리할 수 있다.
    2. DataQue는 텍스트를 SQL로 번역하기 위해 10-15개의 모델 기반 및 규칙 기반 컴포넌트로 구성된 처리 파이프라인을 사용하여 처리를 정확하게 제어할 수 있다.
    3. 이 시스템은 빠른 시간 내에 파이프라인에 이를 수 있도록 하고, 요구 사항이 높은 사용자에게 확실한 파싱 결과를 제공하는 등 다양한 실제적인 문제를 해결할 수 있는 기능을 제공한다.

###### AART: AI-Assisted Red-Teaming with Diverse Data Generation for New LLM-powered Applications (https://aclanthology.org/2023.emnlp-industry.37/)
- Anthology ID: 2023.emnlp-industry.37 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 대규모 언어 모델에 적용되는 공격적인 테스트는 그들의 안전한 전개를 위해 중요하다. 이 논문은 LLM(대규모 언어 모델)이 새로운 하위 응용 프로그램에서 안전성을 테스트하기 위해 적대적인 평가 데이터셋을 자동으로 생성하는 AI 보조 접근법을 소개한다.
    2. 이 논문에서는 AART (AI 보조 레드팀)라고 불리는 자동 팀테스팅 시스템을 소개하고 있다. 이 시스템은 인간의 노력을 크게 줄이고 적대적인 테스트를 신제품 개발 초기에 통합할 수 있는 재사용 가능하고 맞춤 설정 가능한 데이터 생성 및 증강 파이프라인을 제공한다.
    3. AART는 다양한 문화적 지역과 응용 프로그램 시나리오에 특정한 민감하고 해로운 개념들을 포함하는 평가 데이터셋을 생성하며, AI 보조 레시피를 사용하여 새로운 응용 프로그램 문맥에서 다양성을 정의, 범위화 및 우선순위를 지정한다.

###### Speakerly: A Voice-based Writing Assistant for Text Composition (https://aclanthology.org/2023.emnlp-industry.38/)
- Anthology ID: 2023.emnlp-industry.38 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. Speakerly는 email, 인스턴트 메시지, 노트 등 다양한 사용 사례에서 사용자가 텍스트를 작성하는 데 도움을 주는 새로운 실시간 음성 기반 작성 지원 시스템을 제공한다.
    2. 사용자는 지시나 딕테이션을 통해 시스템과 상호 작용하고, 시스템은 잘 정리되고 일관성 있는 문서를 생성한다.
    3. 작은 task-specific 모델과 미리 학습된 언어 모델을 조합하여 시스템은 빠르고 효과적인 텍스트 작성을 지원하며, 더 나은 사용성을 위해 다양한 입력 모드를 지원한다.

###### Are ChatGPT and GPT-4 General-Purpose Solvers for Financial Text Analytics? A Study on Several Typical Tasks (https://aclanthology.org/2023.emnlp-industry.39/)
- Anthology ID: 2023.emnlp-industry.39 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 최근의 대규모 언어 모델들은 ChatGPT와 GPT-4와 같이 일반화 능력이 뛰어난 모델로서, 적은 수정 없이 다양한 NLP 태스크에서 최고 수준의 성능을 보여주고 있다. 이러한 모델들이 금융 도메인에서 얼마나 효과적인지 알아보는 것은 다양한 금융 텍스트 분석 작업에 중요한 영향을 줄 수 있다.
    2. 본 논문에서는 5개 범주의 태스크에서 비교 실험을 통해 8개 벤치마크 데이터셋을 사용하여 금융 텍스트 분석 문제에서의 성능을 계량한 경험적 연구를 수행한다.
    3. 또한, 저자들은 모델을 최신 fine-tuned 접근법과 최근 출시된 도메인 특정 pretrained 모델들과 비교하여 현재 모델들의 강점과 한계를 보고하며, 이를 통해 기존 모델들의 금융 도메인 역량을 이해하고 더 나은 성능을 도모할 수 있기를 희망한다.

###### CL-QR: Cross-Lingual Enhanced Query Reformulation for Multi-lingual Conversational AI Agents (https://aclanthology.org/2023.emnlp-industry.40/)
- Anthology ID: 2023.emnlp-industry.40 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. Alexa, Google 어시스턴트, Siri와 같은 대화형 AI 에이전트의 인기 증가로 정확한 음성 언어 이해를 필요로 하고 있다. 
    2. 하지만 QR(Query Reformulation)은 언어 리소스 부족으로 non-English 사용자에게 고품질의 QR을 제공하는 것이 여전히 어려운 과제로 남아있다. 
    3. 이 논문에서는 영어의 풍부한 리포매퓰레이션 리소스를 활용하여 non-English QR 성능을 개선하기 위한 클로싱귤 QR(CL-QR) 프레임워크를 제안한다.

###### Improving Contextual Query Rewrite for Conversational AI Agents through User-preference Feedback Learning (https://aclanthology.org/2023.emnlp-industry.41/)
- Anthology ID: 2023.emnlp-industry.41 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. Conversational AI 에이전트에서는 Contextual query rewriting (CQR)이 중요한 구성 요소로 작용하여 이전 사용자-에이전트 대화의 문맥 정보를 활용하여 현재 사용자 의도를 더 잘 이해할 수 있도록 한다.
    2. 기존 CQR 방법은 사용자 피드백을 활용하여 사용자 선호도에 맞춘 쿼리 재작성을 학습할 수 있는 기회를 놓치는 경향이 있다.
    3. 본 논문에서는 Preference Aligned Contextual Query Rewriting (PA-CQR) 프레임워크를 제안하고, 다양한 최신 피드백 학습 알고리즘의 CQR 작업에 대한 효과를 조사하였다. 또한, 대규모 CQR 학습에 Dynamic Direct Preference Optimization (Dynamic DPO) 알고리즘을 적용하도록 개선된 알고리즘을 제안하였다.

###### Scaling Neural ITN for Numbers and Temporal Expressions in Tamil: Findings for an Agglutinative Low-resource Language (https://aclanthology.org/2023.emnlp-industry.42/)
- Anthology ID: 2023.emnlp-industry.42 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. ITN 작업은 방언, 전사 오류 등으로 인해 단어의 철자 변형으로 인해 ITN 항목을 식별하는 데 어려움이 있다.
    2. 타밀어는 음운 형태론적 변형인 Punarchi로 인해 문장에서 인접한 단어 사이의 단어 경계가 모호해진다.
    3. 실험 결과, 부트스트래핑과 데이터 증강을 통해 추가 데이터를 사용하는 s2s 모델이 최적의 성능을 보이며, fully-supervised 설정 대비 20.1%의 향상을 보고한다.

###### EELBERT: Tiny Models through Dynamic Embeddings (https://aclanthology.org/2023.emnlp-industry.43/)
- Anthology ID: 2023.emnlp-industry.43 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. EELBERT는 transformer 기반 모델 (예: BERT)을 압축하는 방법으로, downstream 태스크 정확도에 미치는 영향이 최소화되도록 설계되었다.
    2. 이 방법은 모델 크기를 크게 줄여주기 위해 모델의 입력 임베딩 레이어를 동적인 계산으로 대체하여 성취된다. 
    3. 실험 결과, EELBERT 모델은 전통적인 BERT 모델과 비교하여 미미한 성능 하락만을 보이며, 최소한의 크기로 GLUE 점수를 달성할 수 있는 UNO-EELBERT 모델을 개발하였다.

###### Gold Standard Bangla OCR Dataset: An In-Depth Look at Data Preprocessing and Annotation Processes (https://aclanthology.org/2023.emnlp-industry.44/)
- Anthology ID: 2023.emnlp-industry.44 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 본 연구 논문은 방글라 문자 인식(OCR) 시스템의 개선을 위해 방글라 텍스트 구조의 복잡성, 다양한 필체 스타일 및 종합 데이터셋의 부족에 대한 도전에 대처하기 위한 것이 목적이다. 
    2. 최근 딥러닝과 OCR 기술의 발전을 활용하여, 다양한 종류의 라벨이 달린 방글라 텍스트 이미지 데이터셋을 활용하여 방글라 OCR의 성능을 크게 향상시킬 것으로 기대된다.
    3. 이 연구는 400만 개가 넘는 인간 주석 이미지로 구성된 가장 광범위한 방글라 문자 및 단어 골드 표준 말뭉치를 소개하며, 이 데이터셋을 공개함으로써 방글라 OCR 및 관련 분야의 추가 연구 및 개발을 용이하게 할 것이다.

###### PILLOW: Enhancing Efficient Instruction Fine-tuning via Prompt Matching (https://aclanthology.org/2023.emnlp-industry.45/)
- Anthology ID: 2023.emnlp-industry.45 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 기존의 instruction tuning 기술은 대규모 언어 모델을 다양한 태스크에 적응시키는 데 사용되었지만, 계산 리소스가 많이 필요하여 개인이나 소규모 기관에서 실제로 사용하기 어려웠다.
    2. 최근에는 리소스 부담을 줄인 LoRA (Low-Rank Adaptation)이라는 대안이 등장했지만, LoRA의 성능을 만족시키기는 어려운 문제가 있다.
    3. 이 논문에서는 PILLOW라는 방법을 제안하여 제한된 리소스 환경에서 reinforcement learning을 통해 LLM의 in-context learning 능력을 활용하여 LoRA의 성능을 향상시키는 것을 목표로 한다.

###### Welcome to the Real World: Efficient, Incremental and Scalable Key Point Analysis (https://aclanthology.org/2023.emnlp-industry.46/)
- Anthology ID: 2023.emnlp-industry.46 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. "Key Point Analysis (KPA)는 의견 집합에서 주요 요점을 추출하고 그 보편성을 정량화하는 요약 프레임워크로, 이는 논쟁, 사용자 리뷰, 설문 응답과 같은 다양한 유형의 데이터에 성공적으로 적용되었다."
    2. 그러나 KPA 시스템을 실제로 구현하는데 필요한 실용적인 도전과제에 대한 주목은 아직 그리 높지 않다.
    3. 이 논문은 우리 조직 내의 여러 팀에 정기적으로 서비스되는 KPA 시스템을 발표하며 시스템 구축 중 마주친 주요 도전과제, 아키텍처 및 알고리즘적 개선사항에 대해 논의한다.

###### Automatic Linking of Judgements to UK Supreme Court Hearings (https://aclanthology.org/2023.emnlp-industry.47/)
- Anthology ID: 2023.emnlp-industry.47 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 영국에서 가장 중요한 법적 자료 중 하나는 국가의 최고 법원에서 판결된 사건에 대한 특판과 법정 속기 및 녹화 영상이다.
    2. 이 연구에서는 법적 논의에서 중요한 인용구들에 대한 연구를 위해 텍스트 판결서의 세그먼트를 영상의 시간부분과 연결하는 자동 도구를 구축하는데 초점을 맞췄다. 
    3. 우리는 AI 생성 기술을 사용하여 관련 링크를 검색하고, GPT 텍스트 임베딩을 우리 데이터셋에 맞게 사용하면 링킹 시스템의 최고 정확도를 달성할 수 있다는 것을 보였다.

###### Automatic Marketing Theme and Commodity Construction System for E-commerce (https://aclanthology.org/2023.emnlp-industry.48/)
- Anthology ID: 2023.emnlp-industry.48 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 소비자들의 쇼핑 필요성이 집중될 때 특정 마케팅 테마 아래의 상품 모음에 더 관심이 있다. 따라서 마케팅 테마와 해당 상품 모음을 탐지하면 고객이 쇼핑 비용을 절약하고 추천 시스템의 사용자 클릭 및 구매를 개선할 수 있다.
    2. 기존 시스템은 전문가들이 마케팅 테마를 작성하고 관련 상품을 선택하도록 요구하지만 대량 생산, 신속성 및 저온 표시와 같은 문제가 있다.
    3. 이 논문에서는 우리는 자동 마케팅 테마 및 상품 구축 시스템을 제안하여 마케팅 테마를 자동으로 생성하고 관련 상품을 선택할 수 있으며, 추천 시스템에서 테마의 온라인 효과성을 향상시킬 수 있다는 것을 보여준다.

###### Towards Safer Operations: An Expert-involved Dataset of High-Pressure Gas Incidents for Preventing Future Failures (https://aclanthology.org/2023.emnlp-industry.49/)
- Anthology ID: 2023.emnlp-industry.49 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 본 논문은 safety prevention을 위한 새로운 IncidentAI 데이터셋을 소개한다. 기존 코퍼스와는 달리, 이 데이터셋은 named entity recognition, cause-effect extraction, information retrieval 등 세 가지 작업으로 구성되어 있다.
    2. 이 데이터셋은 실무 경험을 가진 도메인 전문가들에 의해 주석이 달렸으며, 이를 통해 사고 예방 시나리오에서의 유용성을 검증하였다.
    3. 세 가지 작업을 위한 초기 결과는 사고 보고서를 분석하는 NLP 기술이 미래의 실패를 예방하는 데 도움이 된다는 것을 보여주며, 해당 데이터셋은 NLP 및 사고 관리 커뮤니티에서의 미래 연구를 용이하게 한다.

###### An Auxiliary Task Boosted Multi-task Learning Method for Service Account Retrieval with Limited Human Annotation (https://aclanthology.org/2023.emnlp-industry.50/)
- Anthology ID: 2023.emnlp-industry.50 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 공식 계정 및 미니 프로그램을 포함한 서비스 계정은 사용자에게 다양한 편의 서비스를 제공하며 애플리케이션의 중요한 구성 요소가 되었다. 그러나 이 작업은 인간 주석의 한계로 인해 어렵다. 
    2. 이 논문에서는 로그 데이터를 보조로 활용하여 본래 작업인 서비스 계정 검색의 성능을 향상시키는 여러 보조 작업을 도입한 새로운 접근 방식을 제안한다.
    3. 또한 Adaptive Hierarchical Fusion Module (AHF module)을 도입하여 여러 보조 작업의 임베딩을 주 작업에 유연하게 통합함으로써 모델의 효과를 향상시킨다.

###### VKIE: The Application of Key Information Extraction on Video Text (https://aclanthology.org/2023.emnlp-industry.51/)
- Anthology ID: 2023.emnlp-industry.51 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 비디오에서 구조화된 정보를 추출하는 것은 산업에서 많은 하위 응용프로그램에 대해 중요하다. 본 논문에서는 비디오의 시각적 텍스트에서 계층적인 중요 정보를 추출하는 작업을 정의한다.
    2. 이 작업을 수행하기 위해, 논문에서는 4가지 하위 작업으로 분리하여 PipVKIE와 UniVKIE라는 두 가지 구현 솔루션을 소개한다.
    3. PipVKIE는 연속적인 단계에서 4가지 하위 작업을 순차적으로 완료하며, UniVKIE는 모든 하위 작업을 하나의 백본으로 통합하여 개선된다. PipVKIE와 UniVKIE는 비전, 텍스트와 좌표로부터 다중 모달 정보를 활용하여 피쳐 표현을 수행한다. 실험 결과, 우리의 솔루션은 뛰어난 성능과 효율적인 추론 속도를 달성할 수 있다.

###### Investigating the Role and Impact of Disfluency on Summarization (https://aclanthology.org/2023.emnlp-industry.52/)
- Anthology ID: 2023.emnlp-industry.52 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 챗과 음성 통화를 모두 처리하는 컨택센터에서는 대화가 종료되면 요약문을 작성하는 것이 일반적인 관행이다. 음성 통화에서는 반복, 재시작 및 대체 등의 특징으로 불차분한 대화가 나타난다. 이러한 불차분한 요소는 하향식 자연어 이해 (NLU) 작업에서는 잡음으로 여겨진다.
    2. 이 논문에서는 챗과 음성 데이터 채널에 대한 수동 주석을 필요로하지 않으면서 완벽한 데이터로 훈련된 모델이 불차분한 데이터를 효과적으로 처리할 수 있는지 조사하는 것이 중요하다.
    3. 실험 결과, 완벽한 데이터로 훈련된 모델이 불차분한 데이터를 처리할 때 Rouge-L 점수가 최대 6.99점 하락하며 더불어 유창성, 일관성 및 관련성이 감소한다는 것을 확인했다. 이를 완화하기 위해 Fused-Fine Tuning을 조사하여 완벽한 데이터와 불차분한 데이터를 결합하여 모델을 훈련시키면 공개 및 실제 데이터셋에서 성능이 향상된다는 것을 알 수 있다.

###### InsightNet : Structured Insight Mining from Customer Feedback (https://aclanthology.org/2023.emnlp-industry.53/)
- Anthology ID: 2023.emnlp-industry.53 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 고객 리뷰에서 구조화된 Insight를 자동으로 추출하기 위해 InsightNet을 제안한다. 현재의 솔루션의 한계인 식별된 주제에 대한 구조 부재, 비표준적인 측면 이름, 풍부한 훈련 데이터의 부재 등을 극복하기 위해 설계된 이 시스템은 원시 리뷰에서 반지도학습 다중 레벨 분류법을 구축하고 의미 유사성 휴리스틱 접근법을 사용하여 레이블 데이터를 생성하며 LLM을 세밀하게 조정하여 다중 작업 Insight 추출 아키텍처를 적용한다.
    2. InsightNet은 각 주제별로 고객의 감정과 원문을 포함한 구체적인 대응 가능 주제를 식별한다.
    3. 실제 고객 리뷰 데이터에서의 평가 결과, InsightNet은 구조, 계층, 완전성 측면에서 기존 솔루션보다 우수한 성과를 내었다. 또한, InsightNet은 다중 레이블 주제 분류에서 현재 최고 성능을 보여주는 기법들과 비교하여 F1 점수가 0.85로 약 11% 향상되었다. 또한, InsightNet은 새로운 측면을 추론하고 분류하는 데에서 일반화 능력이 우수하다.

###### E2E Spoken Entity Extraction for Virtual Agents (https://aclanthology.org/2023.emnlp-industry.54/)
- Anthology ID: 2023.emnlp-industry.54 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 사람-컴퓨터 대화에서 음성으로부터 이름, 주소, 이메일과 같은 entity를 추출하는 것은 어려운 작업이다.
    2. 이 논문에서는 미세조정 된 사전 훈련된 음성 인코더가 음성을 텍스트 전사 없이 상대방이 이해할 수 있는 형태로 entity를 추출하는 데 미치는 영향을 연구한다.
    3. 1단계 접근법이 대화 내의 발화 entity를 식별하기 위해 먼저 텍스트 전사를 생성한 후 텍스트 기반 entity 추출을 수행하는 전통적인 2단계 접근법보다 우수하다는 것을 보여준다.

###### Generative Models for Product Attribute Extraction (https://aclanthology.org/2023.emnlp-industry.55/)
- Anthology ID: 2023.emnlp-industry.55 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 제품 속성 추출은 지식베이스 구축, 제품 추천 및 고객 경험 향상과 같은 응용 프로그램을 포함하는 정보 추출 및 전자 상거래의 신흥 분야이다. 
    2. 본 논문에서는 제품 속성 추출을 위한 생성 모델의 유용성을 분석하고 하드하고 소프트한 프롬프팅 방법을 사용하여 암시적인 속성값을 생성할 수 있는 능력을 시연한다.
    3. 아마존과 MAVE 데이터셋을 사용한 다양한 실험을 통해 생성 모델이 명시적인 제품 속성 추출에 대해 최신 sequence tagging 모델보다 우수한 성능을 발휘하고, 더 많은 데이터 효율성을 갖으며, 암시적인 제품 속성 추출을 수행할 수 있는 독특한 능력을 가지며, 특정 상황에서는 두 개의 문맥 예제로도 훈련된 모델과 경쟁적인 성능을 발휘하는 것을 보여준다.

###### CarExpert: Leveraging Large Language Models for In-Car Conversational Question Answering (https://aclanthology.org/2023.emnlp-industry.56/)
- Anthology ID: 2023.emnlp-industry.56 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 대형 언어 모델(LLM)은 domain-specific한 태스크와 데이터에 대해 fine-tuning 없이도 자연어 명령을 잘 따라할 수 있지만, domain-specific한 질문에 대한 LLM의 활용은 심각한 한계가 있다.
    2. 이 논문에서 CarExpert라는 자동차에 관련된 대화형 질문-답변 시스템을 소개하며, LLM을 이용하여 input을 제어하고 domain-specific 문서를 추출 및 생성하는 답변 구성요소에 제공하며, 안전하고 domain-specific한 답변을 보장하도록 output을 제어한다.
    3. 포괄적인 실험적 평가 결과, CarExpert가 최첨단 LLM보다 자연스럽고 안전하며 자동차에 특화된 답변을 잘 생성하는 것을 확인할 수 있다.

###### BUSTER: a “BUSiness Transaction Entity Recognition” dataset (https://aclanthology.org/2023.emnlp-industry.57/)
- Anthology ID: 2023.emnlp-industry.57 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 최근 자연어 처리 (NLP) 분야에서 큰 발전이 있었지만, 이러한 발전을 실제 비즈니스 상황에 적용하는 것은 어려울 수 있다. 이는 대중적인 벤치마크와 실제 데이터 간의 격차 때문이다. 
    2. 우리는 BUSTER라는 비즈니스 거래 개체 인식 데이터셋을 소개하여 산업 지향적인 연구를 지원한다. 이 데이터셋은 3779개의 수동으로 주석이 달린 금융 거래 문서로 구성되어 있다. 
    3. 우리는 일반 목적과 도메인 특정 언어 모델을 활용하여 여러 가지 벤치마크를 설정하였고, 가장 성능이 좋은 모델은 BUSTER에 추가적인 실버마감문서로서 6196개의 문서를 자동으로 주석을 달았다.

###### Multi-word Tokenization for Sequence Compression (https://aclanthology.org/2023.emnlp-industry.58/)
- Anthology ID: 2023.emnlp-industry.58 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 대규모 언어 모델의 성능은 다양한 작업에 대해 매우 우수한 결과를 보여주고 있다. 하지만 이는 컴퓨터 자원을 많이 필요로 하기 때문에 산업적으로 보다 널리 사용되기 어렵다. 
    2. 본 논문에서는 Multi-Word Tokenizer (MWT)인 MWT를 제안하여, 빈도가 높은 여러 단어 표현을 단일 토큰으로 표현함으로써 단어 경계를 넘어서는 토큰화를 수행한다. 
    3. 실험 결과, MWT는 시퀀스 길이가 짧을 때에도 더 견고하여 시퀀스를 조기에 줄임으로써 큰 속도 향상을 가능하게 한다.

###### JarviX: A LLM No code Platform for Tabular Data Analysis and Optimization (https://aclanthology.org/2023.emnlp-industry.59/)
- Anthology ID: 2023.emnlp-industry.59 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. JarviX는 고도로 발전된 데이터 분석 프레임워크로, 대용량 언어 모델(LLM)을 활용하여 표 형식의 데이터셋에 대한 자동 가이드와 고정밀 데이터 분석을 수행하는 것을 목표로 한다. 
    2. JarviX는 최신의 LLM을 활용하여 다양한 열 유형의 중요성을 강조하며, 간결한 데이터 인사이트 요약을 생성하고 관련 분석 문의를 제안하며, 데이터를 효과적으로 시각화하고, 포괄적인 결과에 대한 설명을 제공한다. 
    3. 또한, JarviX는 예측 모델링을 위한 자동화된 기계 학습(AutoML) 파이프라인을 통합하여, 기계 구성을 최적화하는 데 특히 유리한 종합적이고 자동화된 최적화 주기를 형성한다.

###### Retrieve and Copy: Scaling ASR Personalization to Large Catalogs (https://aclanthology.org/2023.emnlp-industry.60/)
- Anthology ID: 2023.emnlp-industry.60 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 개별화된 음성인식 모델의 성능을 향상시키기 위해 주로 주의 메커니즘을 사용하는데, 기존 방법들은 효율성에 제한이 있어 실제로 사용하기 힘들다.
    2. 이 논문은 "Retrieve and Copy" 메커니즘을 제안하고, 큰 카탈로그에 확장할 때도 정확성을 유지하며 지연 시간을 개선한다.
    3. 실험 결과, 6% 더 많은 WER 감소 및 F1에서 3.6%의 절대적인 향상을 보여주었으며, 최소 20%의 추론 속도 향상을 달성할 수 있다.

###### STEER: Semantic Turn Extension-Expansion Recognition for Voice Assistants (https://aclanthology.org/2023.emnlp-industry.61/)
- Anthology ID: 2023.emnlp-industry.61 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 음성 어시스턴트 시스템에서 스티어링은 사용자가 이전 턴을 지시하거나 명확히 하기 위해 연속된 명령을 내리는 현상을 말한다. 
    2. 우리는 이전 명령을 조절하려는 사용자의 연속 턴을 예측하는 스티어링 탐지 모델 STEER을 제안한다. 
    3. STEER은 사용자 트랜스크립트만으로도 높은 정확도를 보이며, STEER+는 세마틱 파싱 트리를 활용하여 더 많은 문맥을 제공하고 모델 성능을 향상시킨다.

###### Self-Criticism: Aligning Large Language Models with their Understanding of Helpfulness, Honesty, and Harmlessness (https://aclanthology.org/2023.emnlp-industry.62/)
- Anthology ID: 2023.emnlp-industry.62 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 최근 대화형 스타일의 언어 모델 (LLM)이 인공 일반 지능 (AGI)의 발전에 크게 기여하면서 대규모 언어 모델 (LLMs)의 중요성이 급증하고 있다. 이 논문에서는 RLHF에 비해 저렴하게 LLMs와 함께 일반화된 방식으로 유연하게 정렬하는 방법에 대해 탐구한다.
    2. 이 연구에서는 Self-Criticism라는 새로운 프레임워크를 제안하여 LLMs가 텍스트 코퍼스에서 배운 HHH 정의에 따라 스스로를 정렬할 수 있게 한다. 이 방법은 사전 분류 (IF)와 적은 양의 입력을 통한 인문 학습 (ICL)을 통해 LLMs를 조정하고, 모델이 자체 생성한 응답을 평가하고 자체 판단에 따라 "더 좋은" 응답을 생성하도록 학습한다.
    3. 실험 결과는 Self-Criticism 방법이 RLHF와 거의 동일한 인간 평가 및 다른 LLMs에 의한 평가 성과를 달성한다는 것을 보여준다.

###### InstructPTS: Instruction-Tuning LLMs for Product Title Summarization (https://aclanthology.org/2023.emnlp-industry.63/)
- Anthology ID: 2023.emnlp-industry.63 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 전자상거래 제품 카탈로그는 수십억 개의 항목을 포함하고 있으며, 대부분의 제품은 키워드를 제품 속성과 함께 포함하여 검색 성능을 향상하고 제품의 주요 측면을 강조한다. 이로 인해 소비자들이 사용하는 방식과 다른 불필요한 제목이 생성되는데, 이는 추천, 질의응답, 리뷰 요약과 같은 작업에서 문제가 될 수 있다.
    2. 이 논문은 최근 instruction-tuned LLMs에 영감을 받아 Product Title Summarization (PTS) 작업에 대한 조절 가능한 접근법인 InstructPTS를 제안한다. 새로운 instruction fine-tuning 전략을 사용하여 훈련된 이 접근법은 다양한 기준에 따라 제품 제목을 요약할 수 있다.
    3. 실제 전자상거래 카탈로그에서의 방대한 평가 결과, 단순한 fine-tuning 방법에 비해 제안된 접근법은 더 정확한 제품 이름 요약을 생성할 수 있으며, BLEU와 ROUGE 점수에서 각각 14점과 8점이상의 개선을 보였다.

###### LLM4Vis: Explainable Visualization Recommendation using ChatGPT (https://aclanthology.org/2023.emnlp-industry.64/)
- Anthology ID: 2023.emnlp-industry.64 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. "데이터 시각화는 다양한 도메인에서 통찰력을 탐색하고 전달하기 위한 강력한 도구이다. 시각화 권장은 이러한 데이터셋에 대한 시각화 선택을 자동화하기 위해 제안된 작업이다. 기계 학습 기반 접근법들은 이를 위해 개발되었으나 현재 다양한 예제 데이터와 결과에 대한 자연스러운 설명이 부족하다."
    2. "이 연구에서는 LLM4Vis라는 ChatGPT 기반의 적극적인 접근 방식을 제안하여 매우 적은 실제 예제를 사용하여 시각화 권장 작업을 수행하고 사람과 유사한 설명을 제공한다."
    3. "우리의 접근 방식은 feature description, demonstration example selection, explanation generation, demonstration example construction 및 inference 단계를 포함한다. 평가 결과, LLM4Vis가 Random Forest, Decision Tree 및 MLP와 같은 지도학습 모델에 비해 몇 개의 예제부터 모든 데이터를 사용한 경우에도 우수한 성능을 보였으며, 질적 평가에서도 생성된 설명의 효과성을 확인할 수 있었다."

###### DUBLIN: Visual Document Understanding By Language-Image Network (https://aclanthology.org/2023.emnlp-industry.65/)
- Anthology ID: 2023.emnlp-industry.65 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. OCR에 의존하지 않는 비주얼 문서 이해를 위한 픽셀 기반 모델인 DUBLIN을 제안한다. DUBLIN은 이미지와 텍스트를 픽셀로 처리하고 다양한 문서 유형과 작업을 처리할 수 있다.
    2. DUBLIN은 비주얼과 언어적 능력을 향상시키는 새로운 작업을 포함한 대규모 문서 이미지 코퍼스에서 사전 훈련된다.
    3. 우리는 DUBLIN이 DocVQA, InfoVQA, AI2D, OCR-VQA, RefExp, CORD와 같은 추출 작업에서 우수한 성능을 보이며 VisualMRC 및 텍스트 캡션 작업에서도 강력한 성능을 보인다는 것을 다양한 벤치마크를 통해 평가한다.

###### DocumentNet: Bridging the Data Gap in Document Pre-training (https://aclanthology.org/2023.emnlp-industry.66/)
- Anthology ID: 2023.emnlp-industry.66 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 최근 몇 년간 기업 AI의 다양한 응용 분야에서 중요한 역할을 하는 시각적인 문서 엔터티 검색(VDER)과 같은 문서 이해 작업은 광범위한 관심을 받았으나, 엄격한 개인정보 보호 제한과 높은 주석 비용으로 인해 이러한 작업에 대한 공개 데이터는 부족하다.
    2. 이 논문에서는 웹에서 대량의 약하게 주석이 된 데이터를 수집하여 VDER 모델의 훈련에 활용하는 방법을 제안한다. 
    3. DocumentNet이라는 수집된 데이터셋은 특정 문서 유형이나 엔터티 집합에 의존하지 않으며, 모든 VDER 작업에 적용할 수 있는 범용적인 데이터셋이다.

###### Relevance-assisted Generation for Robust Zero-shot Retrieval (https://aclanthology.org/2023.emnlp-industry.67/)
- Anthology ID: 2023.emnlp-industry.67 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. BEIR 벤치마크와 같은 zero-shot 검색 과제는 고성능 dense retriever의 out-of-domain generalization을 약점으로 보여준다.
    2. 기존의 도메인 적응 방법은 도메인별 유사도를 이용해 pseudo queries(PQ)를 생성하고 fine-tuning하는 것이다. 그러나 PQ 샘플링에 대한 키 바이어스가 있어 일반화에 부정적인 영향을 미칠 수 있다.
    3. 우리는 PQ 생성 과정을 여러 단계로 분리함으로써 그것들을 예방하는 방법을 제안한다. 실험 결과, 우리의 제안은 도메인 변화에 대해 더 강한 내성을 가지는 것으로 나타났다.

###### Too much of product information : Don’t worry, let’s look for evidence! (https://aclanthology.org/2023.emnlp-industry.68/)
- Anthology ID: 2023.emnlp-industry.68 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 제품 질문 답변 (PQA)은 쇼핑 메시지 보드, 소셜 미디어, 브랜드 웹사이트 및 매장에서 고객의 질문에 즉각적으로 응답하는 것을 목표로 한다.
    2. 이 논문에서는 제품 정보를 사용하여 고객 질문에 대답하는 방법론을 제시한다. 
    3. 이를 위해 레이블된 데이터가 쉽게 확보되지 않고, 긴 제품 정보는 질문에 대답하기 위해 다양한 텍스트 부분에 관심을 기울여야 하는 두 가지 주요 과제를 해결한다.

###### Harnessing LLMs for Temporal Data - A Study on Explainable Financial Time Series Forecasting (https://aclanthology.org/2023.emnlp-industry.69/)
- Anthology ID: 2023.emnlp-industry.69 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 금융 시계열에 대한 기계 학습은 시장 통찰력, 리스크 관리, 전략적 의사 결정 및 정책 형성에서 혁신을 가능하게 하는 산업 연구의 활발한 분야입니다. 이 논문은 전통적인 접근 방식에서 볼 수 있는 교차 순서 추론, 다중 모달 데이터 통합 및 결과 해석과 같은 문제들을 해결하기 위해 대규모 언어 모델(Large Language Models, LLMs)을 이용한 설명 가능한 금융 시계열 예측에 대해 탐구합니다.
    2. NASDAQ-100 주식을 중점으로 공개된 역사적 주식 데이터, 회사 메타데이터 및 경제/금융 뉴스를 활용하며, zero-shot/few-shot 추론을 위해 GPT-4 및 instruction-based fine-tuning을 위해 Open LLaMA를 사용합니다.
    3. 실험 결과, LLM 기반 접근 방식이 전통적인 ARMA-GARCH 및 gradient-boosting tree 모델보다 우수한 성능을 보였으며, Open-LLaMA와 같은 공개된 LLMs의 fine-tuning을 통해 합리적이고 설명 가능한 예측을 생성할 수 있음을 보여줍니다. 단, GPT-4와 비교했을 때 성능은 약간 낮습니다.

###### ViGPTQA - State-of-the-Art LLMs for Vietnamese Question Answering: System Overview, Core Models Training, and Evaluations (https://aclanthology.org/2023.emnlp-industry.70/)
- Anthology ID: 2023.emnlp-industry.70 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. training 데이터와 benchmarking 데이터 부족 때문에 저자는 베트남어에 대한 실용적인 질의응답 시스템을 구현할 수 있는 방법을 제안한다. 이를 위해 베트남어에 적합하도록 조정된 instruction-tuned LLM (ViGPT)을 도입하고 평가한다.
    2. ViGPT는 실제 시나리오에서 탁월한 성능을 보여준다. 저자들은 인공지능과 인간이 생성한 데이터를 포함하는 새로운 벤치마크 데이터셋을 제작하여 베트남어 LLM의 포괄적인 평가 프레임워크를 제공한다.
    3. 최종적으로 저자들은 최신 기술을 달성하고 다른 다국어 LLM에 근접한 성과를 이끌어내는 instruction-tuned LLM의 필요성을 강조하며, 개인화 및 개인정보를 보호하는 베트남어 언어 처리 시스템을 지원하는 오픈 소스 모델을 제공한다.

###### An Integrated Search System for Korea Weather Data (https://aclanthology.org/2023.emnlp-industry.71/)
- Anthology ID: 2023.emnlp-industry.71 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. WeatherSearch는 대한기상청에서 배포된 통합 검색 시스템으로, 사용자가 간단한 자연어 질의로 대량의 기상 데이터베이스에서 관련 데이터를 검색할 수 있게 한다.
    2. 우리는 전문가 설문 및 인터뷰를 통해 템플릿을 만들고, 템플릿 채우기와 같은 데이터 증강 기법을 적용하여 400만 개의 데이터를 최소한의 인력으로 수집하였다.
    3. 수집한 데이터를 바탕으로 mT5를 finetune한 결과, 평균 MRR이 0.66, 평균 회수율이 0.82를 달성하였으며, 이를 통해 다른 지역에서 유사한 시스템을 설계하는 데 도움이 되기를 기대한다.

###### Adaptive Hyper-parameter Learning for Deep Semantic Retrieval (https://aclanthology.org/2023.emnlp-industry.72/)
- Anthology ID: 2023.emnlp-industry.72 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 온라인 전자상거래 응용 프로그램에서 깊은 의미적 검색은 놀라운 성과를 거두었습니다. 그러나 대부분의 방법들은 마진 손실이나 소프트맥스 손실을 활용하여 각 쿼리마다 양수 항목과 음수 항목을 구별하려고 합니다.
    2. 최근 몇 가지 방법들은 추천에서 학습 가능한 / 통계적인 메소드를 통해 각 매개 변수를 학습하여 위 문제를 완화하려고 시도했습니다.
    3. 우리는 질의(query)의 독립성과 다양성 때문에 검색 시나리오에 적합하지 않다고 주장하며, 본 논문에서는 검색 성능을 향상시키기 위해 간단하고 범용적인 하이퍼 파라미터 무선학습 방법을 제안합니다.

###### On Sample-Efficient Code Generation (https://aclanthology.org/2023.emnlp-industry.73/)
- Anthology ID: 2023.emnlp-industry.73 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 큰 언어 모델들은 코드 생성 태스크에서 실행 시간 동작을 예측하는 것에 어려움을 겪는다. 그래서 여러 개의 코드 스니펫을 생성한 다음 최적의 것을 선택하기 위해 거부 샘플링(best-of-n)에 의존하고 있다. 
    2. 이 논문에서는 샘플링 비용을 줄이면서도 생성 품질을 유지하는 것이 주요한 차별점이다. 
    3. EFFICODE라는 새로운 프레임워크를 소개하는데, 이는 모델이 해결할 수 있는 테스트 문제에 샘플링을 중점적으로 하는 방법을 제안한다.

###### Batch Prompting: Efficient Inference with Large Language Model APIs (https://aclanthology.org/2023.emnlp-industry.74/)
- Anthology ID: 2023.emnlp-industry.74 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 대규모 언어 모델(Large Language Models, LLMs)에서의 추론은 샘플의 수가 많을수록 계산 및 금전적 비용이 상승하는 문제가 있다. 본 논문에서는 배치 프롬프팅(batch prompting)이라는 간단하고 효과적인 방법을 제안하여 LLM이 한 번에 여러 개의 샘플에 대한 추론을 수행할 수 있도록 한다. 이 방법은 토큰 및 시간 비용을 줄이면서도 다운스트림 성능을 유지한다. 
    2. 테오리적으로 우리는 Few-shot In-Context Learning 설정에서, 배치당 샘플 수에 대한 추론 비용이 거의 역선형적으로 감소함을 보인다.  
    3. Common sense QA, 산술적 추론, NLI/NLU 등 10개의 데이터셋에서 배치 프롬프팅의 효과를 체계적으로 검증하였으며, LLM 추론 토큰 및 시간 비용을 크게 줄이면서도 더 나은 또는 비슷한 성능을 보여준다. 또한, 배치 프롬프팅은 LLM을 사용하는 다양한 추론 방법에 적용할 수 있다.

###### Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust Conversational Understanding (https://aclanthology.org/2023.emnlp-industry.75/)
- Anthology ID: 2023.emnlp-industry.75 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 맞춤화된 질의 재작성 시스템은 개별 사용자의 행동과 선호도를 고려하여 결함이 있는 질의를 최소화하고 강력한 대화 기능을 보장하기 위해 노력한다. 이 논문은 사용자의 역사적 색인에 포함되지 않은 새로운 사용자 상호작용에서 발생하는 결함이 있는 질의를 다루기 위해 다양한 기술을 사용하는데, 그 중 하나는 고객 피드백 상호작용 그래프로부터 유래된 "협력형 사용자 색인"을 구축하여 새로운 상호작용에 적합한 인덱스를 생성하는 것이다.
    2. 이 논문은 그래프 탐색과 Large Language Models (LLMs)를 결합하여 새로운 상호작용에 대한 적합한 인덱스 증가를 실현하는데 효과적이라는 것을 실험을 통해 입증하였다.
    3. 실제 대규모 데이터셋과 온라인 A/B 실험을 통해 우리가 제안한 방법의 효과를 입증하였다.

###### DELPHI: Data for Evaluating LLMs’ Performance in Handling Controversial Issues (https://aclanthology.org/2023.emnlp-industry.76/)
- Anthology ID: 2023.emnlp-industry.76 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 논란은 우리의 시대정신을 반영하며, 모든 토론에 중요한 측면이다. 대화 시스템으로 사용되는 대형 언어 모델이 등장함에 따라 사람들은 다양한 질문에 대한 답변을 위해 이 모델에 크게 의존하고 있다. 이에 따라 현재의 토론과 관련된 질문에 대해 이러한 모델이 어떻게 응답하는지 체계적으로 조사하는 것이 중요하다. 
    2. 하지만 현대적인 토론을 반영하는 사람이 주석을 단 데이터셋은 거의 없다. 이 연구는 Quora Question Pairs Dataset을 확장하여 논란이 있는 질문 데이터셋을 새롭게 구축한다. 
    3. 우리는 이 데이터셋의 일부를 사용하여 다양한 언어 모델을 평가하고, 이들이 논란이 있는 문제를 어떻게 다루고, 어떤 입장을 취하는지에 대해 조명한다. 이 연구는 결국 대형 언어 모델이 논란이 있는 문제와 상호작용하는 방법을 이해하는 데에 기여하며, 복잡한 사회적 토론의 이해력과 처리 능력을 향상시킬 수 있는 발전의 길을 열어준다.

###### Angel: Enterprise Search System for the Non-Profit Industry (https://aclanthology.org/2023.emnlp-industry.77/)
- Anthology ID: 2023.emnlp-industry.77 
- Volume: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track 
- Summary: 
    1. 비영리 산업은 펀드를 찾는 사람 (예: AMERICAN NATIONAL RED CROSS)과 펀드를 제공하는 사람 (예: BILL AND MELINDA GATES FOUNDATION)을 원인 (예: 암)과 대상 수혜 그룹 (예: 어린이)에 맞추어 정확하게 매치시키기 위한 시스템이 필요하다.
    2. 본 연구에서는 비영리 산업을 위한 "ANGEL"이라는 기업 검색 시스템을 만들었다. 이 시스템은 펀드 제공자의 미션 설명을 입력으로 받고 펀드를 찾는 사람들의 순위 목록을 반환한다.
    3. ANGEL은 ColBERT라는 신경 정보 검색 모델을 활용하며, 문법 정보와 다중 헤드 셀프 어텐션을 결합하는 문법 정보 인식 로컬 어텐션 (SLA) 및 간결한 미션 설명의 augmentation을 위한 댄스 가짜 연관 피드백 (DPRF) 기술을 사용한다.

## Findings of the Association for Computational Linguistics: EMNLP 2023
###### Findings of the Association for Computational Linguistics: EMNLP 2023 (https://aclanthology.org/2023.findings-emnlp.0/)
- Anthology ID: 2023.findings-emnlp.0 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Multi Document Summarization Evaluation in the Presence of Damaging Content (https://aclanthology.org/2023.findings-emnlp.1/)
- Anthology ID: 2023.findings-emnlp.1 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Multi-document summarization (MDS) task에서는 여러 개의 문서에 대한 요약을 생성한다. 그런데 일부 문서에는 various reasons로 인해 독자에게 노출되어서는 안 되는 damaging documents가 있다. 
    2. 기존 메트릭들은 요약의 관련성과 일관성을 평가하지만, 우리는 damaging documents를 올바르게 처리하는 MDS 시스템의 능력을 측정하는 두 가지 새로운 평가 메트릭을 제안한다.  
    3. 실험을 통해 우리의 메트릭이 MDS 시스템에서 damaging content를 제거하면서 문서의 요약을 제대로 처리하는 능력을 효과적으로 측정할 수 있음을 보였다.

###### Guiding AMR Parsing with Reverse Graph Linearization (https://aclanthology.org/2023.findings-emnlp.2/)
- Anthology ID: 2023.findings-emnlp.2 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Abstract Meaning Representation (AMR) 파싱은 주어진 문장으로부터 추상적 의미 그래프를 추출하는 것을 목표로 한다. 기존의 시퀀스-투-시퀀스 접근법은 의미 그래프를 노드와 엣지의 시퀀스로 선형화하고 직접 선형화된 그래프를 생성하는 방식으로 좋은 성능을 달성하였다. 
    2. 그러나 이러한 접근법에서는 디코딩 과정에서 구조 손실이 누적되는 현상이 발생하고, 그로 인해 이후에 디코딩된 노드와 엣지의 F1-점수가 이전에 디코딩된 것보다 훨씬 낮게 나타난다.
    3. 이 문제를 해결하기 위해 우리는 새로운 Reverse Graph Linearization (RGL) 향상 프레임워크를 제안한다. RGL은 AMR 그래프의 기본 및 역 선형화 순서를 정의하며, 기본 순서의 뒷부분에 나타나는 대부분의 구조가 역순서의 앞부분에 나타나고 그 반대도 성립한다. RGL은 역순서 선형화를 기존의 AMR 파서에 두 번의 셀프 디스틸레이션 메커니즘을 통해 통합시키고, 모델이 기본 선형화를 생성하는 동안 모델을 가이드한다.

###### Translate the Beauty in Songs: Jointly Learning to Align Melody and Translate Lyrics (https://aclanthology.org/2023.findings-emnlp.3/)
- Anthology ID: 2023.findings-emnlp.3 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 'Song translation'은 가사 번역과 음악적 알맞은 맞춤을 모두 다루어야 하는데,  이는 번역 과정의 어려운 문제로 관심을 받고 있다.
    2. 본 논문에서는 lyric 번역과 가사-멜로디 맞춤을 동시에 모델링하는 Lyrics-Melody Translation with Adaptive Grouping (LTAG)를 제안한다.
    3. 훈련 데이터 부족 문제를 해결하기 위해 back-translation 방법을 사용하였고, 영어-중국어 가사 번역 데이터셋에서 실험한 결과, 모델의 효과성을 확립했다.

###### Aksharantar: Open Indic-language Transliteration datasets and models for the Next Billion Users (https://aclanthology.org/2023.findings-emnlp.4/)
- Anthology ID: 2023.findings-emnlp.4 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다중 스크립트 사용과 로마자 표기법의 인도어 문맥에서 Transliteration은 매우 중요하지만, 훈련 및 평가 세트가 공개적으로 제공되는 경우가 드물다.
    2. 본 논문에서는 모노링글 및 병렬 코퍼스에서 마이닝하고, 의사결정자들로부터 데이터를 수집하여 인도어 언어에 대한 가장 큰 공개적인 Transliteration 데이터셋인 Aksharantar를 소개한다.
    3. Aksharantar는 21개의 인도어 언어로 총 26백만 개의 Transliteration 쌍을 가지고 있으며, 기존 데이터셋의 21배 크기이며 7개 언어와 1개 언어 가족에 대한 최초의 공개 데이터셋이다.

###### Pretraining Without Attention (https://aclanthology.org/2023.findings-emnlp.5/)
- Anthology ID: 2023.findings-emnlp.5 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. NLP에서 pretraining 성공에 Transformers는 필수적인 역할을 한다. 
    2. 하지만 다른 아키텍처를 사용하면 downstream 정확성은 현저히 나빠지거나 GLUE와 같은 표준 벤치마크에는 attention layer가 필요하다. 
    3. 이 연구는 최근 state-space 모델 기반의 순서 라우팅의 진보를 이용하여 attention 없이 pretraining을 탐구한다.

###### Time-Aware Representation Learning for Time-Sensitive Question Answering (https://aclanthology.org/2023.findings-emnlp.6/)
- Anthology ID: 2023.findings-emnlp.6 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 실제 문제 해결에서 시간은 중요한 요소 중 하나이지만, 기존 QA 데이터셋에는 충분한 시간 표현이 없어 언어 모델은 'after'와 'before'와 같은 시간 표시자와 숫자 사이의 관계를 이해하는 데 어려움을 겪는다.
    2. 이 문제를 해결하기 위해, 우리는 시간-문맥 정보를 고려한 질문 응답 (TCQA) 프레임워크를 제안한다.
    3. TCQA로 훈련된 모델이 TimeQA 데이터셋에서 8.5의 F1-점수를 넘어서는 등 베이스라인 모델보다 성능이 우수함을 실험적으로 보여준다.
    
    (Note: It seems like the term "TimeQA" refers to a specific dataset.)

###### EffEval: A Comprehensive Evaluation of Efficiency for MT Evaluation Metrics (https://aclanthology.org/2023.findings-emnlp.7/)
- Anthology ID: 2023.findings-emnlp.7 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 효율성은 LLMs 시대에 인클루저브성을 증진시키고 환경적 비용을 줄이기 위한 중요한 속성이다. 본 연구에서는 MT 평가 메트릭의 효율성에 대한 철저한 평가를 제공한다.
    2. 우리의 접근은 계산 집약적인 transformers를 가벼운 대안으로 대체하고, LLM 표현 위에 정렬 알고리즘에 대한 선형 및 이차 근사를 사용하는 것이다.
    3. 결과적으로 TinyBERT가 품질과 효율성 사이의 최적의 균형을 제공하며, CPU 속도 향상은 GPU보다 훨씬 크다는 것을 보였다.

###### Unsupervised Opinion Summarization Using Approximate Geodesics (https://aclanthology.org/2023.findings-emnlp.8/)
- Anthology ID: 2023.findings-emnlp.8 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 의견 요약은 사용자 리뷰로부터 유명한 의견을 잡아내는 작업이다. 이 논문에서는 데이터에 대한 사전 지식이 필요하지 않는 비지도 추출적 의견 요약 시스템인 GeoSumm을 소개한다. GeoSumm은 인코더-디코더 기반 표현 학습 모델로 구성되어 텍스트의 토픽별 표현을 생성한다.
    2. 이러한 토픽별 표현은 학습 가능한 잠재 단위의 분포로써 텍스트의 맥락을 포착한다. GeoSumm은 디코더의 여러 레이어에서 사전 학습한 텍스트 표현을 기반으로 사전 학습을 수행하여 이러한 토픽별 표현을 생성한다.
    3. 우리는 이러한 토픽별 표현을 사용하여 새로운 근사 Geodesic 거리 기반의 스코어링 메커니즘을 이용하여 리뷰 문장의 중요성을 정량화한다. 이 중요성 점수를 사용하여 일반적인 의견 및 측면별 요약을 작성한다. GeoSumm은 세 가지 의견 요약 데이터셋에서 강력한 성능을 달성하고 있으며, 모델의 작동 방식을 분석하고 다양한 도메인에서 GeoSumm의 일반화 능력을 보여주기 위해 추가 실험을 수행한다.

###### Investigating the Frequency Distortion of Word Embeddings and Its Impact on Bias Metrics (https://aclanthology.org/2023.findings-emnlp.9/)
- Anthology ID: 2023.findings-emnlp.9 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 연구들은 정적인 단어 임베딩이 단어의 빈도를 인코딩할 수 있다고 보여주었으나, 이러한 동작에 대해서는 덜 연구되어 왔다. 
    2. 이 연구에서 우리는 정적인 단어 임베딩에서 빈도와 의미 유사성 사이의 관계가 어떻게 관련되어 있는지 연구하고, 이러한 관계가 임베딩 기반 편향 메트릭에 미치는 영향을 평가한다. 
    3. 우리는 Skip-gram, GloVe, FastText 임베딩이 높은 빈도 단어 사이의 유사성이 다른 빈도 조합 사이의 것보다 높은 경향을 가지도록 한다는 것을 발견하였다.

###### Improving Classifier Robustness through Active Generative Counterfactual Data Augmentation (https://aclanthology.org/2023.findings-emnlp.10/)
- Anthology ID: 2023.findings-emnlp.10 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Counterfactual 데이터 증강(CDA)은 자연어 분류기의 robustness를 향상시키기 위해 일반적으로 사용되는 기술이다. 하지만 meaningful한 counterfactual을 발견하고 효율적으로 라벨링하는 것은 인간의 비용을 최소화하는 문제점이 있는데, 이 논문에서는 counterfactual 생성 모델을 이용하여 더 많은 다양한 counterfactual을 생성하고 학습된 보조 분류기로 자동으로 라벨을 달 수 있는 framework를 제안한다.
    2. 생성된 counterfactual들에 대해 원래의 예시와의 관계를 보간하는 pairwise 분류기를 훈련시킴으로써 보다 정확하게 라벨을 달 수 있다는 통찰력을 제공한다.
    3. 작은 양의 인간-라벨링된 counterfactual 데이터(10%)로 학습된 라벨을 가진 counterfactual 증강 데이터셋을 생성할 수 있으며, 이를 통해 sentiment classification과 question paraphrase 태스크에서 robustness를 18-20% 향상시키고 6개의 도메인 외 데이터셋에서 에러를 14-21% 감소시킬 수 있다는 것을 실험적으로 보여준다.

###### Data Augmentation Techniques for Machine Translation of Code-Switched Texts: A Comparative Study (https://aclanthology.org/2023.findings-emnlp.11/)
- Anthology ID: 2023.findings-emnlp.11 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 데이터 부족 문제를 해결하기 위한 코드 스위칭(CSW) 텍스트 생성이 점점 주목받고 있다. 이 연구에서는 세 가지 인기있는 augmentation 접근 방식인 용어 대체, 언어학 이론, 배후 번역(back-translation)을 이집트 아라비아어-영어 코드 스위칭 문맥에서 비교하였다.
    2. CSW 평행 데이터로 학습된 배후 번역과 CSW 예측 기반 용어 대체가 두 가지 작업에 대해 가장 좋은 성능을 보였다.
    3. 언어학적 이론과 임의의 용어 대체는 CSW 평행 데이터가 없는 경우에 효과적이었으며, 두 가지 접근 방식 모두 유사한 결과를 달성했다.

###### On the Relation between Sensitivity and Accuracy in In-Context Learning (https://aclanthology.org/2023.findings-emnlp.12/)
- Anthology ID: 2023.findings-emnlp.12 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "In-context learning(ICL)은 prompt에 대해 너무 민감해서 실제 상황에서 신뢰성이 떨어진다. 이 연구에서는 ICL의 다양한 변형에 대한 민감도를 조사했다."
    2. "실험 결과, ICL의 민감도와 정확도 사이에 강한 음의 상관관계를 발견했다. 민감한 예측은 정확하지 않을 가능성이 높다."
    3. "이러한 결과를 바탕으로, 우리는 SenSel이라는 few-shot selective prediction 방법을 제안한다. 실험 결과, SenSel은 abstention 결정에서 두 가지 기존 기법을 일관되게 능가한다."

###### Self-distilled Transitive Instance Weighting for Denoised Distantly Supervised Relation Extraction (https://aclanthology.org/2023.findings-emnlp.13/)
- Anthology ID: 2023.findings-emnlp.13 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. distant supervision을 이용한 관계 추출에서 잘못된 레이블이 존재하는 것은 큰 문제로 인식되고 있으며, 기존 연구는 이러한 잡음을 완화하기 위해 bag-level 학습을 하는 경우가 많았다. 
    2. 이 논문에서는 중간 출력의 정보를 활용하여 동적인 인스턴스 가중치를 생성하는 새로운 Transitive Instance Weighting 메커니즘을 제안하여 잘못된 레이블이 있는 경우에도 효과적으로 대응하는 것을 목표로 한다. 
    3. 실험 결과는 우리의 방법이 state-of-the-art 성과를 달성하며, 기준 모델 대비 일관된 성능 향상을 보여준다.

###### MWE as WSD: Solving Multiword Expression Identification with Word Sense Disambiguation (https://aclanthology.org/2023.findings-emnlp.14/)
- Anthology ID: 2023.findings-emnlp.14 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 단어 의미 구분 (WSD) 접근법은 인풋 콘텍스트 외에 의미 설명서의 인코딩을 활용하여 성능을 향상시키고 있다. 본 연구에서는 이러한 접근법을 사용하여 다중단어 표현 (MWE) 식별에 적용할 수 있음을 보여주었다.
    2. 우리의 방법은 규칙 기반 추출 파이프라인에서 생성되는 MWE 후보들을 필터링하는 데에 의미 설명서와 콘텍스트 정보를 사용하는 모델을 훈련시켰다.
    3. 우리의 접근법은 DiMSUM 데이터셋에서 최대 1.9 F1 포인트의 성능 향상을 이끌어내어 MWE 식별에서 최고 성능을 보여주고, PARSEME 1.1 영어 데이터셋에서도 경쟁력 있는 결과를 달성하였다. 또한, 우리의 모델은 WSD 성능의 대부분을 유지하며, 두 가지 작업에 하나의 모델을 사용할 수 있다는 것을 보여준다.

###### Dual Contrastive Learning Framework for Incremental Text Classification (https://aclanthology.org/2023.findings-emnlp.15/)
- Anthology ID: 2023.findings-emnlp.15 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 증분 학습은 온라인 지식 발견의 맥락에서 중요한 역할을 한다. 바다 모델 (Language Model)이 지속적으로 지식을 학습하고 갱신할 수 있도록 도와준다.
    2. 우리는 이 논문에서 다운스트림 시퀀스 태스크로 잘 전달될 수 있는 더욱 일반화된 임베딩 공간을 학습하는 데 초점을 맞추고 있다.
    3. 우리는 Dual Contrastive Learning (DCL) 기반 프레임워크를 제안하여 다른 태스크간에 임베딩의 전이성을 향상시키고, 과적합 현상을 감소시키며, 다양한 텍스트 데이터셋에서 우수한 성능을 달성하고 있다.

###### Reference Free Domain Adaptation for Translation of Noisy Questions with Question Specific Rewards (https://aclanthology.org/2023.findings-emnlp.16/)
- Anthology ID: 2023.findings-emnlp.16 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기술 분야 내의 질문-답변(CQA) 포털은 조직 내 사용자들에게 도움이 되는 가치있는 도구로 작용하지만, 영어를 구사하지 못하는 사용자들에게 접근 가능하게 만드는 것은 여전히 도전과제이다. 
    2. 이 논문에서는 Neural Machine Translation (NMT)을 사용하여 질문을 번역하는 것이 어려운 noisy한 환경에 대응하기 위한 훈련 방법론을 제안한다. 
    3. 기존의 synthetic target data에 의존하는 방법들 보다 더 나은 성능을 보이며, 잡음이 있는 데이터에 대해서도 robust하게 동작하는 것을 입증하였다.

###### Filtered Semi-Markov CRF (https://aclanthology.org/2023.findings-emnlp.17/)
- Anthology ID: 2023.findings-emnlp.17 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 전통적인 Linear Chain CRF 대신, Semi-Markov CRF가 Named Entity Recognition (NER)과 같은 텍스트 분할 작업에 대안으로 제안되었다. 단어 수준 예측이 아닌 Segment를 기본 단위로 취급하기 때문에 더 표현력이 우수하다.
    2. 하지만 Semi-CRF는 두 가지 주요 문제가 있다: (1) 입력 시퀀스의 모든 Span에 대해 동작하기 때문에 시퀀스 길이에 대해 이차 복잡성이 발생한다는 것와 (2) NER과 같은 시퀀스 레이블링 작업에서 CRF보다 성능이 떨어진다는 것.
    3. 본 논문에서는 필터링 단계를 통해 관련 없는 Segment를 제거하여 복잡성과 탐색 공간을 줄이는, Semi-CRF의 변형인 Filtered Semi-Markov CRF를 소개한다. 우리의 접근법은 여러 NER 벤치마크에서 CRF와 Semi-CRF보다 우수한 성능을 발휘함과 동시에 훨씬 빠르다.

###### Data Pruning for Efficient Model Pruning in Neural Machine Translation (https://aclanthology.org/2023.findings-emnlp.18/)
- Anthology ID: 2023.findings-emnlp.18 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 큰 규모의 사전 훈련된 언어 모델의 메모리 요구량과 추론 시간을 줄이기 위해 모델 가지치기 방법을 사용할 수 있는데,이 논문에서는 데이터 가지치기와 이동 가지치기를 결합하여 효율적인 fine-pruning을 가능하게 했다.
    2. 개별 훈련 인스턴스의 Cross-entropy 점수들을 활용하여 데이터셋 가지치기 전략을 설계하였고, 루마니아어-영어 및 터키어-영어 번역 과업에서 데이터셋 가지치기 방법이 다른 방법에 비해 우수한 성능을 보였다.
    3. 데이터 가지치기는 수렴에 필요한 전체 단계와 이동 가지치기의 훈련 시간을 줄이는 것을 실험적으로 보여주었으며, NMT의 상황에서 데이터와 모델 가지치기의 상호작용을 이해하기 위해 새로운 통찰력을 얻었다.

###### Long-Form Speech Translation through Segmentation with Finite-State Decoding Constraints on Large Language Models (https://aclanthology.org/2023.findings-emnlp.19/)
- Anthology ID: 2023.findings-emnlp.19 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 음성 번역에서의 한 가지 어려움은 말하는 내용이 긴 형태일 때, 고품질의 번역을 위해 짧은 단위가 필요하지만 이 불일치를 해결하기 위해 큰 언어 모델 (LLM)을 사용하여 긴 ASR 트랜스크립트를 독립적으로 번역 가능한 세그먼트로 분할한다.
    2. 우리는 디코딩 중 유효하지 않은 출력을 제거하기 위해 유한 상태 제약 조건을 포함하여 LLM의 환각되는 경향을 극복한다.
    3. 우리는 prompt-tuning이나 fine-tuning을 통해 ASR 오류가 포함된 트랜스크립트에 대해서도 LLM이 적응 가능함을 발견하였고, 최고의 LLM은 분할을 향상시킴으로써 9개의 테스트 세트에서 영어-독일어, 영어-스페인어, 영어-아라비아어 TED 강연 번역에서 평균 BLEU를 2.9 포인트 향상시켰다.

###### Re-Temp: Relation-Aware Temporal Representation Learning for Temporal Knowledge Graph Completion (https://aclanthology.org/2023.findings-emnlp.20/)
- Anthology ID: 2023.findings-emnlp.20 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Temporal Knowledge Graph Completion (TKGC)는 미래의 사실을 기반으로 누락된 엔티티를 예측하는데 실제 예측 문제와 더 가까워 실제적인 도전 과제를 제시한다. 
    2. 기존 연구들은 주로 최근 스냅샷에 적용하는 sequential graph neural networks를 사용하여 entity와 relation을 인코딩하지만, 이러한 방식은 쿼리에 나타난 entity와의 관련 관계를 고려하여 관련 없는 스냅샷을 건너뛰는 능력과 명시적인 시간 정보의 중요성을 간과하기 쉽다.
    3. 이를 해결하기 위해 우리는 명시적인 시간 임베딩을 입력으로 사용하고 각 타임스탬프 이후에 스킵 정보 흐름을 통합하여 예측에 불필요한 정보를 건너뛰는 모델인 Re-Temp (Relation-Aware Temporal Representation Learning)을 제안한다. 또한 정보 누출을 막기 위해 두 단계의 전방 전파 방법을 도입한다. 6개의 TKGC (extrapolation) 데이터셋에서 실시한 평가를 통해 우리의 모델이 최근 8개의 state-of-the-art 모델보다 큰 폭으로 우수한 성능을 보여주었다."

###### RethinkingTMSC: An Empirical Study for Target-Oriented Multimodal Sentiment Classification (https://aclanthology.org/2023.findings-emnlp.21/)
- Anthology ID: 2023.findings-emnlp.21 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근, 타겟 지향적 다중 모달 감성 분류(TMSC)가 학계에서 큰 관심을 받고 있으나, 현재의 다중 모달 모델은 성능 한계에 도달했다. 
    2. 이 논문에서는 어떤 모달이 TMSC에 있어서 더 중요한지, 어떤 다중 모달 퓨전 모듈이 더 효과적인지, 기존 데이터셋이 연구를 충분히 지원하는지 등을 연구하고 있다. 
    3. 실험과 분석 결과, 현재의 TMSC 시스템은 최대한 많은 타겟의 감성을 텍스트로만 결정할 수 있기 때문에 텍스트 모달에 주로 의존하고 있다는 것을 보여주었다. 따라서 모델 디자인과 데이터셋 구축을 위해 여러 가지 방향을 제안하고 있다.

###### Lexical Entrainment for Conversational Systems (https://aclanthology.org/2023.findings-emnlp.22/)
- Anthology ID: 2023.findings-emnlp.22 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화 시스템은 인간과 같은 특징을 갖추기를 기대되고 있다. 이 논문은 lexical entrainment (LE)이라는 현상을 다룬다. LE는 대화 상대방의 어휘 선택에 맞게 어휘를 조정하는 현상으로, 대화의 명확성과 모호성 감소를 위해 LE를 대화 시스템에 명시적으로 통합하는 방법을 제안한다.
    2. LE 현상을 대화 시스템에 통합하기 위해, MultiWOZ-ENTR이라는 새 데이터셋과 대화 시스템을 위한 LE 측정 방법을 제안한다.
    3. 또한, LE 추출 작업과 LE 생성 작업을 위한 두 가지 기준선 접근법을 제시한다. LE 추출 작업은 대화 맥락에서 LE 표현을 감지하는 것을 목표로 한다.

###### AutoReply: Detecting Nonsense in Dialogue with Discriminative Replies (https://aclanthology.org/2023.findings-emnlp.23/)
- Anthology ID: 2023.findings-emnlp.23 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문에서는 대화 모델이 자신의 메시지에 오류를 감지할 수 있다고 보여준다. "이해하지 못했다" 라는 대답의 가능성을 계산하여 부적절한 메시지를 감지할 수 있다. 
    2. 미리 정의된 대답들로 이루어진 AutoReply를 사용하여 복잡한 어플리케이션인 Diplomacy에서도 효과적으로 말이 안되는 대화를 감지할 수 있음을 보여준다. 
    3. AutoReply는 소수의 주석이 달린 대화 예시를 기반으로 자동으로 최적의 대답을 탐색하며, 이는 수동으로 만든 대답과 성능이 비슷하다.

###### Follow-on Question Suggestion via Voice Hints for Voice Assistants (https://aclanthology.org/2023.findings-emnlp.24/)
- Anthology ID: 2023.findings-emnlp.24 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Alexa나 Siri와 같은 음성 비서의 사용이 급속히 증가함에 따라 사용자는 음성 검색을 통해 즉시 정보에 접근할 수 있다. 그러나 음성 기반의 상황에서 질의 제안은 단순한 일이 아니다.
    2. 이 논문에서는 사용자가 계속 질문할 수 있도록 간결하고 자연스러운 음성 힌트를 제공하는 새로운 작업인 "질문 제안"에 도전한다.
    3. 우리는 기존의 모델과 sequence-to-sequence Transformer를 사용하여 질문 목록에서 음성 힌트를 생성하기 위한 방법을 제안하고, 새로운 데이터셋을 사용하여 이를 평가한다. 평가 결과, 단순히 질문을 연결하는 것보다 언어학적으로 기반된 사전 훈련 과정을 적용한 접근법이 가장 자연스러운 힌트를 생성하는 데 사람들이 더 선호함을 보였다.

###### Bidirectional Masked Self-attention and N-gram Span Attention for Constituency Parsing (https://aclanthology.org/2023.findings-emnlp.25/)
- Anthology ID: 2023.findings-emnlp.25 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 어텐션 메커니즘은 특히 자연어 처리(NLP) 태스크에서 심층 학습의 중요한 요소가 되었다. 그러나, 어텐션 메커니즘은 문장 범위를 형성하는 데 필요한 방향성 정보를 부족하게 할 수 있다. 
    2. 이 문제를 해결하기 위해, 우리는 Bidirectional masked and N-gram span Attention (BNA) 모델을 제안한다. 이 모델은 어텐션 메커니즘을 수정하여 각 단어 사이의 명확한 종속성을 포착하고 출력 범위 벡터의 표현을 강화한다. 
    3. 제안된 모델은 Penn Treebank와 Chinese Penn Treebank 데이터셋에서 최고의 성능을 달성하며, 각각 96.47과 94.15의 F1 스코어를 기록한다. 축소 연구와 분석은 BNA 모델이 양방향 종속성을 통해 각 단어를 문장에 맥락화하고 범위 표현을 향상시키는 데 효과적임을 보여준다.

###### CR-COPEC: Causal Rationale of Corporate Performance Changes to learn from Financial Reports (https://aclanthology.org/2023.findings-emnlp.26/)
- Anthology ID: 2023.findings-emnlp.26 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "이 논문에서는 CR-COPEC라고 불리는 자율 상업 성능 변화의 인과관계를 갖는(rationale) 기업들의 재무 보고서를 소개한다."
    2. 이 데이터셋은 전문가의 인과분석을 포현하는 방식으로 U.S. 기업들의 10-K 연간보고서로부터 인과관계를 탐지한다. 
    3. CR-COPEC는 기업의 재무 성과에 영향을 미치는 다양한 특성들을 고려하여 다양한 산업에서도 유일한 내러티브를 고려하여 인과 문장을 식별할 수 있다.

###### Plausibility Processing in Transformer Language Models: Focusing on the Role of Attention Heads in GPT (https://aclanthology.org/2023.findings-emnlp.27/)
- Anthology ID: 2023.findings-emnlp.27 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문은 Transformer 언어 모델이 명사-동사 관계의 타당성 처리를 어떻게 수행하는지, 특히 심층적인 지식에 대해서 탐구하는 것이다. 
    2. 실험 결과, GPT2는 다른 Transformer 언어 모델들과 비교했을 때 명사-동사 관계의 타당성 처리에서 사람과 더 비슷한 특성을 보였다. 
    3. 또한, GPT2의 attention heads가 타당성에 대한 지식을 갖고 있으며 이러한 heads가 GPT2의 타당성 처리 능력에 인과적으로 기여한다는 것을 실험 결과를 통해 확인하였다.

###### Automatic Unit Test Data Generation and Actor-Critic Reinforcement Learning for Code Synthesis (https://aclanthology.org/2023.findings-emnlp.28/)
- Anthology ID: 2023.findings-emnlp.28 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 큰 사전 훈련 언어 모델의 등장으로 코드 합성 (Code Synthesis) 분야에서 놀라운 성능을 보이고, Language Modelling (LM) 목적으로 훈련된 자연어 생성(Natural Language Generation)과 유사한 방식으로 Code Generation 문제를 다룬다.
    2. RL 기반 방법은 기존에 정의된 Unit Tests에 기반한 보상 신호에 의존하는데, 이러한 Unit Tests를 정의하는 것은 사전 훈련 데이터셋과 비교해 어렵다. 따라서 이 논문에서는 Code Synthesis 모델의 RL 훈련을 위해 자동으로 함수 시그니처와 관련된 Unit Tests 데이터를 얻는 것을 제안한다.
    3. 또한, 단순하지만 효과적인 Actor-Critic 기반 RL 훈련 방법을 도입하고, 자동 생성 된 훈련 데이터와 함께 사용하면 기존의 code synthesis LM에 비해 최대 9.9%의 성능 향상을 가져오며, 표준 PPO 또는 CodeRL로 훈련된 RL 기반 모델에 비해 최대 4.3%의 성능 향상을 얻을 수 있다.

###### Unlocking the Heterogeneous Landscape of Big Data NLP with DUUI (https://aclanthology.org/2023.findings-emnlp.29/)
- Anthology ID: 2023.findings-emnlp.29 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대용량 코퍼스의 자동 분석은 시간 효율성 관점에서 복잡한 작업이다. 이에 NLP 분야에서 유연하고 확장가능한 텍스트 분석을 위한 적합한 프레임워크가 없다는 문제가 있다. 이 논문은 이러한 문제를 해결하기 위해 Docker Unified UIMA Interface(DUUI)를 제안한다.
    2. DUUI는 대용량 텍스트 코퍼스의 자동 분석을 위한 확장 가능하고 유연하며 가벼운 웹 프레임워크로, Docker를 통해 빅데이터 경험과 가상화 기술을 활용한다. 
    3. DUUI의 통신 접근 방식은 최신 기술과 비교하여 우수한 시간 효율성을 보여주며, 대용량 텍스트 데이터의 분석이 가능하게 한다.

###### Towards Agile Text Classifiers for Everyone (https://aclanthology.org/2023.findings-emnlp.30/)
- Anthology ID: 2023.findings-emnlp.30 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 텍스트 기반 안전 분류기는 콘텐츠 관리에 널리 사용되며 점점 더 디지털 어시스턴트와 챗봇의 안전 기능 조정에 사용되고 있다.
    2. 이 논문에서는 특정 정책을 빠르게 개발할 수 있는 작은 목표 데이터셋을 사용하여 분류기를 훈련시키는 "민첩한 텍스트 분류" 방법을 소개하고 평가한다.
    3. 작은 데이터셋으로도 최첨단 성능을 달성할 수 있으며, 이를 통해 대규모 안전 분류기를 개발하는데 필요한 시간과 자원을 대폭 줄일 수 있다.

###### Beyond Good Intentions: Reporting the Research Landscape of NLP for Social Good (https://aclanthology.org/2023.findings-emnlp.31/)
- Anthology ID: 2023.findings-emnlp.31 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 NLP의 발전과 함께 다양한 분야에서 다양한 NLP 응용 프로그램이 나타나고 있지만, 이러한 연구들이 오늘날의 사회적 문제를 다루고 있는지는 연구자들에게 항상 분명하지 않다. 
    2. 따라서 이 논문에서는 NLP4SGPapers라는 과학적 데이터셋과 관련된 세 가지 작업을 소개하고, NLP4SG 논문을 식별하고 NLP4SG의 경험을 파악할 수 있게 한다. 
    3. 이 논문은 최신 NLP 모델을 사용하여 이러한 작업을 수행하고, ACL Anthology 전체에 적용하여 NLP4SG 분야의 포괄적인 개요를 제공한다.

###### PAXQA: Generating Cross-lingual Question Answering Examples at Training Scale (https://aclanthology.org/2023.findings-emnlp.32/)
- Anthology ID: 2023.findings-emnlp.32 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 질의응답(QA) 시스템들의 성공은 대량의 고품질 훈련 데이터에 기인하고 있다. 하지만 이러한 주석 작업은 비용이 많이 들며, 크로스-언어 환경에서는 어려움이 더욱 증가한다. 이 논문에서는 기존 병렬 말뭉치로부터 간접 감독을 활용한 재원화된 크로스-언어 QA 데이터 생성 방법을 제안한다.
    2. "PAXQA"라고 명명한 이 방법은 크로스-언어 QA를 두 단계로 분해한다. 첫 번째 단계에서는 질문 생성(QG) 모델을 영어 쪽에 적용한다. 두 번째 단계에서는 질문과 답변을 번역하기 위해 주석 투사(annotation projection)를 적용한다.
    3. PAXQA를 적용하여 4개 언어(총 662,000개의 예제)에 대한 크로스-언어 QA 예제를 생성하고 인간 평가를 수행한 결과, 이 데이터셋으로 미세 조정된 모델이 기존의 재원화된 데이터 생성 모델들보다 추출 기반 QA 데이터셋에서 우수한 성능을 보였다. 특히, 영어 이외의 언어로 된 질문과 영어로 된 맥락의 경우 가장 큰 성능 향상이 있었다.

###### Sharing, Teaching and Aligning: Knowledgeable Transfer Learning for Cross-Lingual Machine Reading Comprehension (https://aclanthology.org/2023.findings-emnlp.33/)
- Anthology ID: 2023.findings-emnlp.33 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Cross-lingual machine reading comprehension (MRC)에서는 다른 언어에서의 답 위치의 변동 때문에 크로스-언어적 전송을 향상시키기 위한 깊은 수준의 지원을 제공하기 어렵다."
    2. X-STA는 크로스-언어적 MRC를 위한 새로운 접근법으로, attenive한 '선생님'을 활용하여 소스 언어의 답 위치를 목표 출력 공간으로 subtle하게 전달한다. Gradient-Disentangled Knowledge Sharing 기법을 제안하여 교차 어텐션 블록을 더 개선시켰다.
    3. 실험 결과는 우리의 방법이 최신의 접근법들보다 효과적이며, 3가지의 다국어 MRC 데이터셋에서 우수한 결과를 보여준다.

###### BERT Goes Off-Topic: Investigating the Domain Transfer Challenge using Genre Classification (https://aclanthology.org/2023.findings-emnlp.34/)
- Anthology ID: 2023.findings-emnlp.34 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 사전 훈련 언어 모델(Pretrained Language Model, PLM)의 성능으로 많은 텍스트 분류 작업의 성능이 향상되었지만, 토픽의 분포가 변하는 경우 성능 차이가 여전히 발생한다.
    2. 우리는 대량의 말뭉치와 다양한 주제를 사용하여 이 현상을 실험적으로 확인하고, 도메인 전이가 전혀 계속 어렵다는 것을 확인했다.
    3. 우리는 훈련 코퍼스에 특정 장르와 주제로 동시에 있는 문서가 없어도 원하는 장르와 주제의 텍스트를 생성하는 데이터 증강 방법을 개발했다. 이를 사용하여 훈련 데이터셋을 증강하면 일부 주제에서 F1 점수가 50%까지 향상되며, 다른 주제에서는 거의 향상되지 않는다.

###### Toward Stronger Textual Attack Detectors (https://aclanthology.org/2023.findings-emnlp.35/)
- Anthology ID: 2023.findings-emnlp.35 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 텍스트 적대적 공격의 다양성이 급증함에 따라 딥 NLP 시스템의 무결성에 대한 우려와 심각한 위협이 제기되고 있지만, 이를 방어하기 위한 연구는 아직 많이 이루어지지 않았다.
    2. 이 논문은 텍스트 적대적 공격을 탐지하기 위한 LAROUSSE 프레임워크를 소개하고, STAKEOUT이라는 새로운 벤치마크를 제안한다. 
    3. LAROUSSE는 비지도 학습 기반이며 하이퍼파라미터 없고 미분 가능하지 않기 때문에 기울기 기반 방법에 대해 보호되며, STAKEOUT은 다양한 실험을 통해 LAROUSSE가 이전에 제안된 방법들보다 우수하게 작동하며, 탐지율의 변동에 대한 흥미로운 요인을 확인하는 데 사용될 수 있는 강력한 평가 프레임워크를 제공한다.

###### MEAL: Stable and Active Learning for Few-Shot Prompting (https://aclanthology.org/2023.findings-emnlp.36/)
- Anthology ID: 2023.findings-emnlp.36 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 고정된 데이터셋에서의 few-shot classification은 run to run variability가 높아 비교가 어렵고, 많은 실제 어플리케이션에 대해서 신뢰할 수 없게 만든다. 
    2. 이 논문에서는 run variability를 줄이기 위해 새로운 앙상블 기법을 제안하고, 데이터셋을 선택하기 위한 새로운 active learning 기준을 소개한다.
    3. 실험을 통해 제안된 MEAL (Multiprompt finetuning and prediction Ensembling with Active Learning) 방법이 prompt-based finetuning의 성능을 2.3개 향상시킨다는 것을 보여준다.

###### Structure and Label Constrained Data Augmentation for Cross-domain Few-shot NER (https://aclanthology.org/2023.findings-emnlp.37/)
- Anthology ID: 2023.findings-emnlp.37 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Cross-domain few-shot named entity recognition (NER)은 소스 도메인의 관련 지식을 활용하여 제한된 레이블 데이터로 대상 도메인의 개체를 인식하는 어려운 작업이다. 
    2. 이 논문에서는 entity annotations과 entity structures 두 가지 새로운 관점에서 도메인 차이를 분석하고, 각각 word-to-tag 및 word-to-word 관계를 활용하여 이를 모델링하는 방법을 제안한다.  
    3. 또한, SLC-DA라 불리는 Structure and Label Constrained Data Augmentation에서는 소스 도메인에서 대상 도메인으로의 원활한 전이를 도와주기 위해 레이블 제한된 사전 훈련 작업과 구조 제한된 최적화 목적을 도입하여 도메인 특정 증강 데이터를 생성한다. 여러 표준 데이터셋을 평가한 결과, 우리의 방법은 최고의 기록이나 경쟁력 있는 결과를 달성하여 cross-domain few-shot NER에서의 효과를 입증한다.

###### Weakly-supervised Deep Cognate Detection Framework for Low-Resourced Languages Using Morphological Knowledge of Closely-Related Languages (https://aclanthology.org/2023.findings-emnlp.38/)
- Anthology ID: 2023.findings-emnlp.38 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 적은 데이터를 가진 언어에 대한 transfer learning에서 cognate을 활용하는 것은 자동기계번역, 개체명인식, 정보 검색과 같은 언어이해 태스크에 대한 흥미로운 기회이다.
    2. 기존의 방법은 orthographic, phonetic, 혹은 state-of-the-art contextual language model을 활용한 지도형 cognate 탐지 태스크에 초점을 맞추었으며, 대부분의 적은 데이터를 가진 언어에서 성능이 좋지 않다.
    3. 본 논문에서는 적은 데이터를 가진 언어를 위한 언어견지는 weakly-supervised 기반의 deep cognate 탐지 프레임워크를 제안한다. 더불어, 관련 언어로부터 유래된 형태적 지식을 활용하여 탐지 작업을 수행하며, 사전 정의된 cognate annotation이 필요없으며 다른 언어 가족에 속하는 다양한 언어에 적용될 수 있다.

###### SQLPrompt: In-Context Text-to-SQL with Minimal Labeled Data (https://aclanthology.org/2023.findings-emnlp.39/)
- Anthology ID: 2023.findings-emnlp.39 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 텍스트-투-SQL은 자연어 텍스트로부터 데이터베이스에 대한 SQL 쿼리를 자동으로 생성하기 위한 작업이다. 이 연구에서는 Text-to-SQL의 소수의 데이터셋에 대한 프롬프팅 능력을 향상시키기 위해 "SQLPrompt"라는 방법을 제안한다.
    2. SQLPrompt는 혁신적인 프롬프트 디자인, 일관성을 기반으로 한 실행 디코딩 전략, 그리고 일관성 선택 도중 다양한 프롬프트 디자인과 기초 모델을 사용하여 SQL 제안을 다양화하는 방법("MixPrompt" 및 "MixLLMs")을 포함한다.
    3. 우리는 SQLPrompt가 레이블이 없는 소수 데이터에 대한 인-컨텍스트 학습에서 기존 접근법들보다 훨씬 우수한 성능을 보이며, 수천 개의 레이블 데이터를 사용한 최첨단 fine-tuning과의 격차를 줄였음을 보여준다.

###### Toward Building General Foundation Models for Language, Vision, and Vision-Language Understanding Tasks (https://aclanthology.org/2023.findings-emnlp.40/)
- Anthology ID: 2023.findings-emnlp.40 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 foundation models는 언어, 시각 또는 시각-언어 태스크 중 하나에서만 가장 우수한 성능을 보여주지만, 모든 이해 태스크에 대해 가장 우수한 성능을 보이는 일반 foundation model을 구성할 수 있는지 여전히 미정이다.
    2. 이 논문에서는 일반 foundation model인 X-Foundation Model (X-FM)을 훈련하기 위한 새로운 방법을 제안한다. X-FM은 언어 인코더, 시각 인코더, 퓨전 인코더로 구성되어 있으며, 훈련 방법에는 텍스트, 이미지, 이미지-텍스트 쌍 데이터로부터 X-FM을 학습하기 위한 두 가지 새로운 기술이 포함되어 있다.
    3. 벤치마크 데이터셋에서의 실험 결과, X-FM은 기존의 일반 foundation 모델보다 우수한 성능을 보이고, 언어, 시각 또는 시각-언어 이해를 위해 특정한 foundation 모델들과 비교할 때 더 나은 성능을 보여준다는 것을 보여준다.

###### Trigger Warnings: Bootstrapping a Violence Detector for Fan Fiction (https://aclanthology.org/2023.findings-emnlp.41/)
- Anthology ID: 2023.findings-emnlp.41 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 새로운 task인 트리거 경고 할당에 관한 첫 번째 데이터셋과 평가 결과를 제시한다.
    2. Archive of Our Own (AO3)라는 인기있는 팬픽 사이트에서 추출한 서술적 픽션(corpus)의 라벨링된 말뭉치를 도입하고 영어 이야기에 트리거 경고를 할당할 것인지 여부를 결정하는 문서 수준의 분류 작업을 정의한다.
    3. 우리는 "violence"라는 가장 일반적으로 할당되는 트리거 유형에 초점을 맞추고, AO3 작가들에 의해 제공되는 경고 라벨을 사용하여 SVM, BERT 및 Longformer 모델을 훈련시키고 F1 점수가 0.8에서 0.9 사이라는 결과를 얻어 violence에 대한 트리거 경고 할당이 실현 가능함을 보여준다.

###### Pass-Tuning: Towards Structure-Aware Parameter-Efficient Tuning for Code Representation Learning (https://aclanthology.org/2023.findings-emnlp.42/)
- Anthology ID: 2023.findings-emnlp.42 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 코드 인텔리전스 분야에서 Code Pre-trained Models(CodePTMs)가 다양한 작업에 대해 표준 범주가 되었으나, 많은 작업에 대해 파인튜닝하는 전략이 적용되면 모델 크기가 증가하고 이는 과도한 비용을 초래한다.
    2. 기존의 Parameter-Efficient Learning (PEL) 방법론은 이와 유사한 문제를 완화하기 위해 자연어 처리 모델에 적용되었지만, 이를 코드에 적용하는 것은 코드의 내재 구조적 특성을 포착하지 못한다.
    3. 이 논문에서는 코드의 내재 구조적 특성을 캡처하기 위해 Pass-Tuning이라는 구조 인식적 파라미터 효율적 코드 표현 학습 방법을 제안한다. 이 방법은 튜닝 가능한 Prefix로서 Abstract Syntax Tree (AST)로부터 학습하는 그래프 신경망 모듈을 이용한다. 우리는 총 8개의 프로그래밍 언어를 대상으로 다양한 작업을 평가하였고, 이를 통해 우리의 방법의 효과성, 강건성, 그리고 일반성을 입증하였다.

###### Counterfactual Augmentation for Multimodal Learning Under Presentation Bias (https://aclanthology.org/2023.findings-emnlp.43/)
- Anthology ID: 2023.findings-emnlp.43 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 실제 기계 학습 시스템에서 라벨은 시스템이 원하는 사용자 행동에서 파생되는 경우가 많다. 하지만 사용자와 모델 사이의 피드백 루프로 인해 향후 사용자 행동에 영향을 주는 presentation bias가 발생하며, 이는 새로운 모델을 학습시키는 능력을 저해한다.
    2. 이 논문에서는 counterfactual augmentation이라는 새로운 인과적 방법을 제안하여 생성된 counterfactual 라벨을 사용하여 presentation bias를 보정하는 것을 목표로 한다.
    3. 실험 결과는 counterfactual augmentation이 보정되지 않은 모델 및 기존의 편향 보정 방법보다 더 나은 성능을 보여준다고 보여주며, 모델 분석 결과는 생성된 counterfactual이 오라클 설정에서 실제 counterfactual과 일치한다는 것을 나타낸다.

###### A Table-to-Text Framework with Heterogeneous Multidominance Attention and Self-Evaluated Multi-Pass Deliberation (https://aclanthology.org/2023.findings-emnlp.44/)
- Anthology ID: 2023.findings-emnlp.44 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 행렬-텍스트 변환의 성능은 크게 발전했으나, 계층적 구조와 같은 행렬 구조 신호의 효과적인 활용은 여전히 어려운 문제입니다.
    2. 또한, 생성된 설명을 신중히 검토하는 것이 행렬-텍스트 문제에서 효과적임이 입증되었으나, 여러 번의 후보 중 어떤 결과를 채택해야 할지 결정하는 것은 다른 어려움을 제공합니다.
    3. 이 논문에서는 자체 평가된 다중 패스 생성(Self-evaluated multi-pass Generation) 및 이질성 다중 우세성 어텐션(Heterogenous Multidominance Attention)을 기반으로 한 새로운 행렬-텍스트 접근법인 SG-HMA를 제안합니다. 이로 인해 효율적인 계층 구조의 상호 작용을 포함한 텍스트 생성에 대한 풍부한 신호를 제공합니다.

###### Crossing the Aisle: Unveiling Partisan and Counter-Partisan Events in News Reporting (https://aclanthology.org/2023.findings-emnlp.45/)
- Anthology ID: 2023.findings-emnlp.45 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 언론은 비편향적인 보도를 유지하는 것이 기대되지만, 그들은 여전히 이념적 입장을 지지하거나 반대하는 사건들을 선택적으로 포함하거나 제외함으로써 대중 의견에 영향을 미칠 수 있다. 
    2. 이 논문에서는 언론의 중립성과 사건의 포함 또는 제외를 통해 대중에게 어떤 영향을 미치는지 연구한다. 
    3. 이를 위해, 우리는 언론사에 따라 다른 304개의 뉴스 기사에서 8,511개의 (반대-)이념적 이벤트 주석이 있는 고품질 데이터셋 PAC을 도입한다.

###### Video-Text Retrieval by Supervised Sparse Multi-Grained Learning (https://aclanthology.org/2023.findings-emnlp.46/)
- Anthology ID: 2023.findings-emnlp.46 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 비디오-텍스트 검색에서의 진전은 더 나은 표현 학습에 의해 이루어졌으나, 이 논문에서는 비디오-텍스트 검색을 위한 새로운 다수정보 변형 학습 프레임워크인 S3MA를 제안한다. 
    2. S3MA는 비디오와 텍스트 간에 공유되는 희소 공간을 학습하기 위해 유한 수의 sparse 개념을 초기화하고 제안된 유사성 및 정렬 손실을 사용하여 공유 희소 공간을 지도 방식으로 학습하고 업데이트한다. 
    3. S3MA의 학습된 공유 희소 공간과 다양한 정보 변형 학습 결과, 여러 비디오-텍스트 검색 벤치마크에서 S3MA가 기존 방법들보다 우수한 성능을 보여준다는 것을 확인할 수 있다.

###### Zero-Shot-BERT-Adapters: a Zero-Shot Pipeline for Unknown Intent Detection (https://aclanthology.org/2023.findings-emnlp.47/)
- Anthology ID: 2023.findings-emnlp.47 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자연어 처리에서 의도 발견은 중요한 작업이며 산업 응용 분야에서 점점 더 중요해지고 있다. 사용자 입력에서 새로운, 이전에 보지 못한 의도를 식별하는 것은 이 분야에서 가장 큰 도전 중 하나이다.
    2. 이 연구에서는 Transformer 아키텍처를 기반으로 한 다국어 의도 발견을 위한 Two-stage 방법을 제안한다. 알려진 클래스에 대한 학습 후, 알려지지 않은 의도를 분류하는 Zero-shot setting에서 성능을 평가한다.
    3. 실험 결과, Zero-Shot-BERT-Adapters가 알려진 의도 분류 및 보이지 않는 의도 발견과 같은 Zero-shot setting에서 다양한 기준선을 앞서는 것을 보여준다. 이 접근 방식은 고객 관리에 널리 응용될 수 있는 잠재력을 갖고 있으며, 대형 언어 모델과는 달리 쉽게 배포 및 확장할 수 있는 경량 모델을 통해 자동화된 동적 트리아지를 가능하게 한다.

###### ReFSQL: A Retrieval-Augmentation Framework for Text-to-SQL Generation (https://aclanthology.org/2023.findings-emnlp.48/)
- Anthology ID: 2023.findings-emnlp.48 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Text-to-SQL"은 자연어 질문을 SQL 쿼리로 번역하는 작업이다. 기존 방법들은 자연어와 SQL 언어를 직접 매칭시키고 모든 질문에 대해 하나의 인코더-디코더 기반 모델을 학습시키지만, 이는 SQL의 내재적인 구조적 특성과 구체적인 구조 지식과 일반적인 지식 사이의 간격을 과소평가하여 생성된 SQL에 구조적 에러가 발생한다. 
    2. 저자들은 이러한 문제를 해결하기 위해 ReFSQL이라는 검색-인수(argument) 프레임워크를 제안한다. 이 프레임워크는 구조 강화 검색기와 생성기 두 부분으로 구성되어 있다. 
    3. 실험 결과는 우리의 접근 방식이 Text-to-SQL 생성의 정확성과 견고성을 향상시키는 데 효과적임을 검증하며, 다양한 다른 기저 모델과 결합할 때 (11B flan-T5를 포함한) 개선된 성능을 보이며, fine-tuning 접근 방식을 사용하는 기존 방법과 비교했을 때 최고의 성능을 달성하였다.

###### Approximating Two-Layer Feedforward Networks for Efficient Transformers (https://aclanthology.org/2023.findings-emnlp.49/)
- Anthology ID: 2023.findings-emnlp.49 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 성능을 희생하지 않고 신경망의 계산 및 메모리 요구량을 줄이는 방법은 무엇인가요? 최근의 연구들은 희소한 MoEs를 사용하여 자원 효율적인 대형 언어 모델을 구축한다. 
    2. 이 논문에서는 MoEs에 대한 여러 가지 새로운 관점을 제시하고, *두개 층의 신경망* (예: Transformer의 feedforward block)을 근사화하는 다양한 방법을 *통합*하는 일반적인 프레임워크를 소개한다. 
    3. 계산-동일한 조건이 아닌 매개변수-동일한 조건에서 MoEs를 밀집한 기준모델과 비교하는 이전의 연구와는 달리, 우리의 평가 조건은 매개 변수-동일한 조건으로 설정되며, 이는 LM을 적절하게 평가하는 데 중요하다.

###### Adapter-TST: A Parameter Efficient Method for Multiple-Attribute Text Style Transfer (https://aclanthology.org/2023.findings-emnlp.50/)
- Anthology ID: 2023.findings-emnlp.50 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다중 속성 텍스트 스타일 전환을 위해 대형 언어 모델을 세밀 조정으로 적용하는 것은 특정 다운스트림 작업을 위해 많은 계산 자원과 레이블된 데이터가 필요하여 어려울 수 있다.
    2. 이 논문에서는 Adapter-TST라는 프레임워크를 제안하여 사전 학습 모델의 원래 파라미터를 고정시키고 여러 속성 정보를 모델링하기 위해 다른 신경 어댑터를 사용하는 다중 속성 텍스트 스타일 전환 모델을 개발한다.
    3. 실험 결과, Adapter-TST는 모든 최신 기베으로부터 더 적은 자원을 사용하여 탁월한 성능을 보여주며, 각 어댑터는 특정 스타일 속성을 효과적으로 특징화하고 구성 편집을 수행하기 위해 설정될 수 있다는 것을 실험적으로 입증했다.

###### Solving the Right Problem is Key for Translational NLP: A Case Study in UMLS Vocabulary Insertion (https://aclanthology.org/2023.findings-emnlp.51/)
- Anthology ID: 2023.findings-emnlp.51 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델의 발전으로 인해 NLP 시스템은 실제 세팅에서 우수한 성능을 보여야 하는 요구가 증가하고 있다. 하지만, 실제 문제와 잘 부합하지 않은 경우에는 강력한 모델 만으로는 좋은 결과를 얻기 어렵다. 이 논문에서는 실제 세계의 작업과 일치하는 UMLS 어휘 삽입 작업을 연구하고 이를 반영한 새로운 task와 dataset, 강력한 기준 모델을 제안한다.
    2. UMLS 어휘 삽입 작업을 위해 기존 솔루션을 재활용하여 개발한 강력한 베이스라인을 사용하며, 실제 편집자에게도 질적 개선을 제공하는 효과적인 바이오메디컬 언어 모델을 제안한다.
    3. 문제 수정의 중요성을 강조하기 위해 이 사례 연구가 실제 NLP 솔루션의 성공에 어떤 중요성을 가지는지를 제시한다.

###### Improving Cross-lingual Transfer through Subtree-aware Word Reordering (https://aclanthology.org/2023.findings-emnlp.52/)
- Anthology ID: 2023.findings-emnlp.52 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 다국어 언어 모델(XLM-R 및 mT5 같은)의 능력이 인상적으로 성장했음에도 불구하고, 특히 low-resource 환경에서는 멀리 떨어진 언어를 처리하는 데 여전히 어려움이 있음이 보여져왔다.
    2. 효과적인 교차언어 전이를 위한 장벽 중 하나는 단어 순서 패턴의 변동성이다. 이는 원천 언어나 목표 언어 측면에서의 단어 재배치를 통해 완화될 수 있으며, 다양한 방법이 제안되었다. 
    3. 이 논문에서는 Universal Dependencies를 기반으로 한 새로운 강력한 재배치 방법을 제안하며, 이는 소량의 주석 데이터에 대해 구문적 문맥에 따른 세밀한 단어 순서 패턴을 학습할 수 있으며, 구문 트리의 모든 수준에 적용할 수 있다는 것을 보여주었다.

###### Novel Slot Detection With an Incremental Setting (https://aclanthology.org/2023.findings-emnlp.53/)
- Anthology ID: 2023.findings-emnlp.53 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 현재 대화 시스템은 다양한 사용자 요청과 빠르게 변화하는 도메인에 직면하여, 이전에 보지 못한 슬롯 유형에 빠르게 적응하는 것은 주요 도전과제이다.
    2. 이 논문에서는 새로운 슬롯 탐지 (NSD)를 도입하여 잠재적인 새로운 유형을 발견하는 것을 소개하고, 이를 이후 상호 작용에서 처리할 수 없는 상태로 남겨지기 때문에 NSD를 이용한 대화 시스템은 실용적인 개선을 이끌어내지 못한다.
    3. 그래서 우리는 이 논문에서 NSD를 이용한 대화 시스템을 1) 알려지지 않은 슬롯을 검색하고 2) 새로운 유형을 처리할 수 있는 능력을 갖는 모델을 훈련시키기 위한 두 단계로 분리하는 접근 방법을 제안한다.

###### Self-supervised Post-processing Method to Enrich Pretrained Word Vectors (https://aclanthology.org/2023.findings-emnlp.54/)
- Anthology ID: 2023.findings-emnlp.54 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Retrofitting 기법은 단어 표상 간 의미적 및 관계적 지식의 약점을 보완하기 위해 외부 리소스를 주입하는 방법이었다. 하지만, 이전의 방법은 추가적인 외부 리소스를 필요로하며 Lexicon에 강하게 의존한다. 따라서 우리는 이러한 문제에 대처하기 위해 self-supervised extrofitting이라는 기존 extrofitting의 간단한 확장을 제안한다."
    2. "우리의 방법은 외부 리소스 없이도 모든 단어 유사도 태스크에서 기본 임베딩을 개선시킨다. 게다가 이 방법은 Lexicon이 희소한 언어에도 효과적이다. 우리는 대화 상태 추적 및 텍스트 분류 과제에서 우리의 방법의 장점을 보여주며, 다른 단어 벡터 특수화 방법과 비교하여 더 나은 결과와 일반화된 결과를 보고한다."
    3. (띄어쓰기 체크) "retrofitting 방법인 extrofitting은 외부 리소스를 단어 표상에 주입하여 단어들간의 의미적 및 관계적 지식의 한계를 보완하는 기법이다. 그러나, 이전 방법들은 외부 리소스에 의존하고 Lexicon에 강한 제약이 있다. 이 문제를 해결하기 위해 우리는 extrofitting의 간단한 확장인 self-supervised extrofitting을 제안한다."

###### Automatic Model Selection with Large Language Models for Reasoning (https://aclanthology.org/2023.findings-emnlp.55/)
- Anthology ID: 2023.findings-emnlp.55 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Chain-of-Thought (CoT)와 Program-Aided Language Models (PAL)은 서로 다른 추론 방법으로 각각의 장점을 가지고 있는데, CoT는 자연 언어를 사용하여 유연성과 해석 가능성을 제공하고, PAL은 프로그래밍 언어를 사용하여 구조화되고 엄격한 논리를 제공한다.
    2. 이 논문에서는 큰 언어 모델 (LLM)을 사용하여 동적으로 두 방법을 선택하는 모델 선택 방법을 제안한다. 이 방법의 실현 가능성은 이론적 분석에 의해 강조되었으며, 실험 결과로도 확인되었다.
    3. 우리의 제안된 방법은 Codex, ChatGPT, GPT-4와 함께 여덟 가지 추론 데이터셋에서 상당한 성능 향상을 보여주었으며, self-consistency와 결합하면 성능을 더 향상시키면서 계산 비용을 크게 줄일 수 있다. 또한, GSM8K와 SVAMP에서는 96.8%와 93.7%의 정확도로 새로운 최고 성과를 달성하였다.

###### ARKitSceneRefer: Text-based Localization of Small Objects in Diverse Real-World 3D Indoor Scenes (https://aclanthology.org/2023.findings-emnlp.56/)
- Anthology ID: 2023.findings-emnlp.56 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 3D Refering Expression Comprehension은 3D 장면 내에서 텍스트 표현을 객체로 지정하는 작업으로, 가정용 로봇이나 확장현실 기기에서 사용자 지시에 언급된 객체를 로컬라이즈(localize)하는 데 중요한 작업이다. 
    2. 기존 indoor 3D referring expression comprehension 데이터셋들은 일반적으로 로컬라이즈하기 쉬운 대형 객체 클래스(예: 의자, 테이블, 문)를 다루고 소형 객체(예: 조리 도구나 사무용품)를 자주 무시한다. 
    3. 이 논문은 ARKitScenes의 다양하고 고해상도 3D scene 데이터셋을 기반으로 실제 실내 장면에서 자주 등장하는 소형 일상용품에 초점을 맞춘 ARKitSceneRefer 데이터셋을 구축한다.

###### Improving Question Generation with Multi-level Content Planning (https://aclanthology.org/2023.findings-emnlp.57/)
- Anthology ID: 2023.findings-emnlp.57 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문은 주어진 맥락과 답변으로부터 질문을 생성하는 문제를 해결하기 위해, 특히 맥락 간 다중 점프 추론을 필요로 하는 질문에 초점을 맞추었다.
    2. Key phrase의 선택이 QG에 필수적이라는 이전 연구들의 제안에도 불구하고, 특히 긴 맥락에 대해 이러한 이분 표현된 구문들을 의미있는 질문으로 연결하는 것은 여전히 어렵다.
    3. 이를 해결하기 위해 MultiFactor라는 새로운 QG 프레임워크를 제안하였는데, MultiFactor에는 key phrase 선택과 텍스트 생성을 위한 복합성 적용을 위한 두 개의 구성요소인 FA-Model 및 Q-Model이 포함되어 있다.

###### Is ChatGPT a Financial Expert? Evaluating Language Models on Financial Natural Language Processing (https://aclanthology.org/2023.findings-emnlp.58/)
- Anthology ID: 2023.findings-emnlp.58 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. ChatGPT와 같은 대형 언어 모델 (LLM)의 등장으로 일반적인 자연어 전처리 (NLP) 작업은 혁신되었지만, 금융 도메인에서의 전문성은 포괄적인 평가가 부족하였다.
    2. 금융 NLP 작업에서 LLM의 능력을 평가하기 위해 FinLMEval이라는 Financial Language Model Evaluation 프레임워크를 제시하고, 언어 모델의 성능을 평가하기 위해 설계된 아홉 개의 데이터셋을 제공한다. 
    3. 연구 결과, ChatGPT는 대부분의 금융 작업에서 뛰어난 성능을 보여주지만, 특히 독점 데이터셋을 처리할 때에는 전문가 모델에 비해 성능이 떨어지는 것으로 나타났다. 이 연구는 금융 도메인에서 더 세련된 LLM을 구축하기 위한 지속적인 노력을 위한 평가 기준을 마련하기를 바란다.

###### DelucionQA: Detecting Hallucinations in Domain-specific Question Answering (https://aclanthology.org/2023.findings-emnlp.59/)
- Anthology ID: 2023.findings-emnlp.59 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대량 언어 모델(LLM)로 생성된 텍스트에서 환각 현상은 요약, 질의응답 등 거의 모든 응용 분야에서 발견된다. 신뢰성이 요구되는 응용 분야에서 LLM 생성 텍스트에 환각이 존재할 수 있다면 심각한 문제이지만, 정보 검색을 활용하여 LLM에 관련 배경 정보를 제공함으로써 환각의 양을 줄일 수 있다.
    2. 그러나 여전히 LLM은 맥락의 관련 정보를 포착하지 못하거나 파라메트릭 지식을 우선시함으로써 다양한 이유로 환각을 생성할 수 있다. 자동 방법을 통해 환각을 감지하는 것이 매우 중요하다.
    3. 따라서 이 논문에서는 특정 도메인의 QA 작업을 위해 LLM에서 검색을 보강하여 생성된 환각을 포착하는 정교한 데이터셋 DelucionQA를 도입하고, 환각 감지 방법의 기준을 제안한다. 또한 대상 시나리오에서의 환각 현상에 대한 유용한 통찰력을 공유하기 위해 분석 및 사례 연구를 제공한다.

###### InvGC: Robust Cross-Modal Retrieval by Inverse Graph Convolution (https://aclanthology.org/2023.findings-emnlp.60/)
- Anthology ID: 2023.findings-emnlp.60 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 획기적인 시각 및 언어 모델링으로 인해 크로스 모달 검색의 중요한 진전이 이뤄졌지만, 멀티모달 데이터 표현은 제한적인 볼록 모양에 군집화되어 검색 성능을 저해하는 것으로 조사되었다.
    2. 이 논문에서는 다양한 크로스 모달 벤치마크와 방법들에서 표현의 변질 문제가 존재함을 실험적으로 검증하였다.
    3. InvGC라는 그래프 컨벌루션과 평균 풀링에 영감을 받은 후처리 기술을 소개하여 데이터 포인트들 간의 거리를 늘려 효과적으로 표현들을 분리하는 것을 제안하였다.

###### Dissecting In-Context Learning of Translations in GPT-3 (https://aclanthology.org/2023.findings-emnlp.61/)
- Anthology ID: 2023.findings-emnlp.61 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 언어 모델을 기반으로한 기계 번역에서의 연구는 대부분 few-shot 샘플을 선택하는 데 중점을 두고 있다. 
    2. 이 논문에서는 high-quality, in-domain demonstrations을 변형하여 인접한 문맥에서 번역을 학습하는 데 데모 이력의 역할을 더 잘 이해하려고 한다. 
    3. 본 연구에서는 asymmetric perturbation(비대칭 유사 지배)의 결과가 매우 다른 것을 보이며, 번역의 문맥적 학습에서 가장 중요한 학습 신호는 출력 텍스트 분포이다는 것을 밝혔다.

###### Social Commonsense-Guided Search Query Generation for Open-Domain Knowledge-Powered Conversations (https://aclanthology.org/2023.findings-emnlp.62/)
- Anthology ID: 2023.findings-emnlp.62 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 오픈 도메인 대화에서는 유용한 대화를 위해 관련 지식을 얻을 수 있는 검색 쿼리를 생성하는 것이 도전적일 수 있다. 하지만 사용자가 명확한 요청을 표현하지 않을 때 정보를 검색해야 할지 결정하는 것은 어려울 수 있다. 
    2. 이 논문에서는 사회적 상식에 기반한 검색 쿼리 생성에 초점을 맞춘 새로운 접근 방식을 제시한다. 대화 주제와 관련된 연결을 생성함으로써 검색 쿼리 생성을 지원하는데, 이를 위해 상식 대화 시스템을 활용한다.
    3. 제안된 프레임워크는 주제 추적, 상식적인 응답 생성 및 매개 변수로서의 검색 쿼리 생성을 통해 수동 사용자 상호 작용을 다룬다. 평가 결과, 명시적인 대화 정보에만 의존하는 기존의 쿼리 생성 기법의 한계를 극복하고, 더 관련성이 높고 특정하며 매력적인 검색 쿼리를 생성하여 더욱 흥미로운 응답을 얻을 수 있다.

###### MixTEA: Semi-supervised Entity Alignment with Mixture Teaching (https://aclanthology.org/2023.findings-emnlp.63/)
- Anthology ID: 2023.findings-emnlp.63 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 반지도 학습 entity alignment (EA)은 충분한 라벨링된 매핑 데이터의 부재로 인해 실질적이고 어려운 작업이다.
    2. 이 논문은 MixTEA라는 새로운 반지도 EA 방법을 제안한다. 이 방법은 표준으로 몇 개의 라벨 매핑을 사용하여 학생 모델을 훈련시킨다. 잡음이 있는 가짜 매핑의 부정확성을 평가하기 위해 BDV 기법을 제안하고, MDR 모듈을 통해 잡음이 있는 매핑의 부정적인 영향을 줄인다.
    3. 벤치마크 데이터셋을 통한 결과와 추가적인 분석에서 우리 제안 방법의 우수성과 효과성을 입증하였다.

###### EZ-STANCE: A Large Dataset for Zero-Shot Stance Detection (https://aclanthology.org/2023.findings-emnlp.64/)
- Anthology ID: 2023.findings-emnlp.64 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Zero-shot stance detection (ZSSD)는 훈련 과정에서 보지 못한 대상에 대해 작성자가 찬성, 반대 또는 중립적인지 여부를 결정하는 것을 목표로 한다.
    2. 이 논문에서는 다른 ZSSD 데이터셋인 VAST와는 대조적으로, 다양한 도메인을 커버하는 명사구 대상과 주장 대상을 함께 포함한 대규모 영어 ZSSD 데이터셋인 EZ-STANCE를 제공한다. 
    3. 또한, 명사구 대상에 대해 두 가지 간단하고 효과적인 prompt를 적용하여 ZSSD를 NLI 태스크로 변환하는 방법을 제안하고, 실험적 결과에서 EZ-STANCE가 새로운 도전 과제로서 의미있는 연구 기회를 제공한다는 것을 보여준다.

###### Boot and Switch: Alternating Distillation for Zero-Shot Dense Retrieval (https://aclanthology.org/2023.findings-emnlp.65/)
- Anthology ID: 2023.findings-emnlp.65 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Neural 'dense' retrieval 모델은 많은 데이터셋에서 state-of-the-art 성능을 보이지만, 종종 제한된 도메인 이전 능력을 가진다." 
    2. 기존의 적응 방법들은 명시적인 지도, 복잡한 모델 구조 또는 거대한 외부 모델을 요구하는 등 불편하다. 
    3. 본 논문에서는 간단하지만 효과적인 비지도 학습 방법인 ABEL을 제안하고, 이러한 방법은 unsupervised dense retriever 모델을 향상시키는 reranker의 피드백을 통해 상호 증진을 달성한다.

###### TESTA: Temporal-Spatial Token Aggregation for Long-form Video-Language Understanding (https://aclanthology.org/2023.findings-emnlp.66/)
- Anthology ID: 2023.findings-emnlp.66 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 비디오-언어 사전 훈련은 비디오-언어 이해 태스크를 발전시키는 데 있어 중요한 역할을 하고 있으나, 비디오 인코딩의 엄청난 계산 부담은 특히 장편 비디오의 경우 효율성 저해요소로 작용한다.
    2. 이 논문에서는 비디오의 시공간 관련성을 효율적으로 포착하기 위해 TEmporal-Spatial Token Aggregation (TESTA)라는 방법을 제안한다. TESTA는 비디오 성질에 기인한 대규모 시각 토큰을 적게하여 비디오 인코딩을 가속화한다.
    3. TESTA를 기반으로 한 사전 훈련된 비디오-언어 모델을 소개하며, 이 모델은 각 비디오 인코더 블록에서 분리된 공간-시간 토큰 집계 모듈을 갖추고 있다. TESTA는 이 모델의 계산 효율성을 1.7배 향상시키고, 더 긴 입력 프레임 처리에서 유연성을 통해 중요한 성능 향상을 이룬다.

###### Fusing Temporal Graphs into Transformers for Time-Sensitive Question Answering (https://aclanthology.org/2023.findings-emnlp.67/)
- Anthology ID: 2023.findings-emnlp.67 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 긴 문서로부터 시간에 민감한 질문에 답변하는 것은 문서와 질문에서 시간적 추론이 필요하다. 
    2. 본 연구에서는 기존의 시간 정보 추출 시스템을 활용하여 시간에 대한 그래프를 구성하고, Transformer 모델에 이러한 그래프를 통합하는 다양한 접근 방식을 조사한다.
    3. 실험 결과, 우리가 제안한 시간 그래프를 입력 텍스트에 통합하는 방식은 Transformer 모델의 시간적 추론 능력을 크게 향상시키며, 그래프 컨볼루션 기반 접근 방식보다 우수한 성능을 보여 새로운 최고 성능을 수립한다.

###### The Internal State of an LLM Knows When It’s Lying (https://aclanthology.org/2023.findings-emnlp.68/)
- Anthology ID: 2023.findings-emnlp.68 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델 (LLM)은 다양한 작업에서 뛰어난 성능을 보여주지만, 가장 큰 단점은 확신있는 톤으로 부정확하거나 거짓 정보를 생성한다는 것이다.
    2. 이 논문에서는 LLM의 내부 상태를 사용하여 명제의 진실성을 확인하는 것이 가능하다는 증거를 제공한다.
    3. LLM의 은닉 레이어 활성화를 기반으로 명제가 참인지 거짓인지를 예측하는 분류기를 학습하여, LLM이 명제를 읽거나 생성할 때 이를 판별할 수 있다는 것을 실험을 통해 보여주었다.

###### Factual Relation Discrimination for Factuality-oriented Abstractive Summarization (https://aclanthology.org/2023.findings-emnlp.69/)
- Anthology ID: 2023.findings-emnlp.69 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대부분의 신경망 추상적 요약 모델은 고품질 요약을 생성할 수 있으나, 여전히 사실적 오류가 자주 포함되어 있다. 
    2. 기존 사실성 지향적 추상적 요약 모델은 사실적 정보의 통합만을 고려하고 사실적 오류의 원인을 간과한다. 
    3. 이 논문에서는 사실성지향적 추상적 요약 모델 DASum을 제안하며, 사실성 오류의 원인을 식별할 수 있는 새로운 작업인 factual relation discrimination을 기반으로 한다.

###### Multi-Modal Knowledge Graph Transformer Framework for Multi-Modal Entity Alignment (https://aclanthology.org/2023.findings-emnlp.70/)
- Anthology ID: 2023.findings-emnlp.70 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다중 모달 지식 그래프에서 동등한 entity 쌍을 찾는 MMEA(Multi-Modal Entity Alignment)는 여러 종류의 정보로 인해 어려움을 겪는 중요한 작업이다.
    2. 이 논문에서는 Meaformer라는 새로운 MMEA transformer를 제안하여 neighbor features, multi-modal attributes, entity types를 계층적으로 도입하여 alignment 작업을 강화한다.
    3. Transformer의 hierarchical modifiable self-attention block과 entity-type prefix injection을 이용하여 전역 정보를 제한하고 다양한 정보의 독특한 의미를 보전한다.

###### Is a Prestigious Job the same as a Prestigious Country? A Case Study on Multilingual Sentence Embeddings and European Countries (https://aclanthology.org/2023.findings-emnlp.71/)
- Anthology ID: 2023.findings-emnlp.71 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문은 다국어 문장의 표현이 유럽 국가와 직업을 어떻게 파악하고 이것이 유럽 언어별로 다른지를 연구한다.
    2. 우리는 기계 번역을 통해 12개 유럽 언어로 템플릿 문장을 제시하고 임베딩에서 가장 두드러진 차원을 분석한다.
    3. 분석 결과, 전체적으로 가장 큰 차이는 동유럽과 서유럽의 정치적 차이와 GDP에 따른 국가의 경제적 강도로 나타났으며, 직업 차원은 대부분의 모델에서 국가 차원과는 관련이 없었다.

###### Towards A Holistic Landscape of Situated Theory of Mind in Large Language Models (https://aclanthology.org/2023.findings-emnlp.72/)
- Anthology ID: 2023.findings-emnlp.72 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 연구는 대형 언어 모델들이 Theory of Mind (ToM)에 대한 부족한 성능을 보이고 있으며, 기존의 평가 지표들이 ToM의 여러 측면에 초점을 맞추고 있어 경로 단축이나 데이터 누수에 취약하다는 문제가 있다.
    2. 이 논문에서는 기계의 ToM을 7가지 정신 상태 범주로 지표화하고, 기존의 평가 기준을 분석하여 ToM의 미개척된 측면을 확인한다. 또한 기계를 환경에 물리적으로 위치하고 인간과 상호작용하는 개체로 취급하여 ganzs 다른 평가 방법론을 제안한다.
    3. 맥락을 고려한 평가는 정신 상태를 더 포괄적으로 평가할 수 있으며, 단축 경로와 데이터 누출의 위험을 줄일 수 있다. 그 외에도 그리드 월드(experimental setup)에서의 연구 결과를 제시하여 미래의 ToM과 LLMs(Intuitive means)를 융합하는 연구를 촉진하기를 희망한다.

###### Text Augmented Spatial Aware Zero-shot Referring Image Segmentation (https://aclanthology.org/2023.findings-emnlp.73/)
- Anthology ID: 2023.findings-emnlp.73 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문은 픽셀 수준의 어노테이션을 사용하지 않고 언급된 사진 세그멘테이션을 하기 위한 zero-shot referring image segmentation 문제를 다룬다.
    2. 기존 연구들은 CLIP와 같은 사전 훈련된 cross-modal 모델을 활용하여 언급된 식별 마스크와 관련성을 맞추는 것으로, 이미지-텍스트 간의 전역적인 매칭만을 고려한다.
    3. 이 논문에서는 Training-free하고 다양한 비주얼 인코더에 강건한 Text Augmented Spatial-aware (TAS) zero-shot referring image segmentation 프레임워크를 제안하며, 확장된 실험을 통해 다른 방법들보다 탁월한 성능을 보였다.

###### IRFL: Image Recognition of Figurative Language (https://aclanthology.org/2023.findings-emnlp.74/)
- Anthology ID: 2023.findings-emnlp.74 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 글과 이미지와 같은 다중 모달에서 유사유형(예: 은유, 유사유, 관용구) 같은 말의 의미를 이해하는 것은 AI의 중요한 도전 과제이다.
    2. 이 연구에서는 Image Recognition of Figurative Language (IRFL) 데이터셋을 개발하였고 이에서 두 가지의 새로운 태스크를 제안하였다.
    3. 최신 비전과 언어 모델로 실험한 결과, 최고의 모델 성능은 인간(97%)보다 현저히 낮았고, 이러한 문제를 개선하기 위해 데이터셋과 코드를 공개하였다.

###### Self-supervised Meta-Prompt Learning with Meta-Gradient Regularization for Few-shot Generalization (https://aclanthology.org/2023.findings-emnlp.75/)
- Anthology ID: 2023.findings-emnlp.75 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Prompt tuning"은 parameter-efficient한 방법으로, soft prompts을 학습하고 언어 모델을 특정 downstream task에 맞게 조건을 걸 수 있다. 그러나 few-shot 설정에서는 좋은 초기화에 크게 의존하며, 적은 데이터로는 일반화하기 어렵다. 
    2. 이 논문에서는 Self-supervised meta-learning을 이용하여 적은 수의 unlabeled data만으로 효율적인 적응을 위한 universal prompt 초기화를 학습하고, 과적합 문제를 완화하기 위해 gradient regularization 기법을 함께 사용한다. 
    3. 실험 결과, SUPMER은 다양한 few-shot downstream task에서 더 좋은 성능을 보이며, 도메인 일반화 능력도 우수하다. SUPMER 코드는 https://github.com/beepkh/SUPMER에서 확인할 수 있다.

###### An Adaptive Prompt Generation Framework for Task-oriented Dialogue System (https://aclanthology.org/2023.findings-emnlp.76/)
- Anthology ID: 2023.findings-emnlp.76 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대부분의 대형 언어 모델 (LLM)은 프롬프트를 사용하여 여러 다운스트림 작업을 수행하는 데 있어서 사실상의 방법이지만, 특정 작업에 적합한 프롬프트를 찾는 것은 여전히 어려운 문제입니다.
    2. 이 논문에서는 훈련 가능한 슬롯 생성자(TSG)와 적응형 프롬프트 생성자(APG)를 제안하여, LLM을 통해 실태완비된 TOD 시스템을 위한 잠재력을 최대로 발휘합니다.
    3. MultiWOZ 2.0 데이터셋에서의 실험 결과, 제안한 방법은 기존 방법보다 성능이 우수함을 입증하였으며, 코드와 데이터가 공개될 예정입니다.

###### Temporal Knowledge Graph Reasoning Based on N-tuple Modeling (https://aclanthology.org/2023.findings-emnlp.77/)
- Anthology ID: 2023.findings-emnlp.77 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "시간적 지식 그래프(TKG)를 통한 추론은 다양한 응용 분야에서 미래의 시간적 사실(예: 이벤트)을 예측하기 위해 중요하다. 기존 TKG에 있는 시간적 사실은 본질적 개체(즉, 주요 역할을 하는 개체)만 포함하고 (주체 개체, 술어, 목적 개체, 타임스탬프)라는 네 개의 요소로 구성되어 있다. 이러한 표현은 시간적 사실을 과도하게 단순화하고 불가피하게 정보 손실을 초래한다. 따라서 우리는 temporal fact를 보다 정확하게 n-튜플로 설명하여 TKG를 N-튜플 Temporal Knowledge Graphs (N-TKGs)로 보완하는 것을 제안한다." 
    2. "N-TKG를 통해 추론을 수행하기 위해, 우리는 더 나아가 N-tuple Evolutional Network (NE-Net)을 제안한다. NE-Net은 시간적 사실의 다른 타임스탬프에서 엔티티와 술어의 진화적인 표현을 반복적으로 학습하며, 이러한 엔티티와 술어 간의 관계를 모델링한다. 학습된 표현을 기반으로 미래 타임스탬프에서의 추론 작업을 과업별 디코더를 통해 실현할 수 있다." 
    3. "새로운 두 개의 데이터셋에서의 실험 결과는 N-TKG의 우수성과 NE-Net의 효과를 입증한다."

###### Make Your Decision Convincing! A Unified Two-Stage Framework: Self-Attribution and Decision-Making (https://aclanthology.org/2023.findings-emnlp.78/)
- Anthology ID: 2023.findings-emnlp.78 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 블랙박스 모델 해석 방법은 높은 NLP 성능을 보이며 고품질의 근거를 생성하기는 하지만, 생성된 근거와 모델의 결정 사이에 신뢰성이 부족하다는 문제가 있다.
    2. 따라서 이 논문에서는 Self-Attribution and Decision-Making (SADM)라는 통일된 두 단계 프레임워크를 제안하여 생성된 근거와 모델의 결정 사이의 신뢰성을 높인다.
    3. ERASER 벤치마크에서 수행한 실험으로 우리의 프레임워크가 신뢰성 높은 근거-모델 결정 링크를 확립하면서 NLP 성능과 근거 품질에서 경쟁력 있는 결과를 얻었음을 보였다.

###### Adaptive Structure Induction for Aspect-based Sentiment Analysis with Spectral Perspective (https://aclanthology.org/2023.findings-emnlp.79/)
- Anthology ID: 2023.findings-emnlp.79 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근에는 구조 정보 (예 : 의존 구문 트리)를 포함하는 것이 측면 기반 감성 분석 (ABSA)의 성능을 향상시킬 수 있다고 알려져 있다. 그러나 이 구조 정보는 대개 최적화되지 않고 번거롭게 구해진다. 따라서 자동으로 적응적인 구조를 학습하는 것이 이 문제를 해결하는 데 도움이 된다.
    2. 본 논문에서는 사전 훈련된 언어 모델 (PLM)에서 구조 유도에 집중하며, 언어 표현의 규모 정보가 구조 유도 능력에 미치는 영향을 탐구하기 위해 스펙트럼 관점에서 구조 유도를 시도한다. 우리의 모델은 일반적으로 사용되는 PLM (예 : RoBERTa 등)과 간단하면서 효과적인 그래프 구조 학습 (GSL) 모듈로 구성된다.
    3. ABSA에 대한 세 가지 공개 벤치마크에서 광범위한 실험을 수행하였고, 결과와 추가적인 분석에서 스펙트럼 접근법을 도입함으로써 AsD (Aspects-sentiment Distance)를 줄일 수 있으며 구조 유도에 도움이 됨을 보여주었다. 심지어 이러한 간단한 프레임워크를 기반으로한 결과가 세 데이터셋에서 최고 성능 또는 거의 최고 성능에 달할 수 있다는 것을 발견하였다. 게다가, 우리의 연구는 다른 작업에 일반화되거나 다른 유사한 도메인에 영감을 줄 수 있는 잠재력을 가지고 있다.

###### NovaCOMET: Open Commonsense Foundation Models with Symbolic Knowledge Distillation (https://aclanthology.org/2023.findings-emnlp.80/)
- Anthology ID: 2023.findings-emnlp.80 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. NovaCOMET은 지식 모델과 일반적인 task 모델의 최상의 측면을 결합한 오픈 커먼센스 지식 모델이다.
    2. NovATOMIC에서 기호적으로 정리된 지식 그래프를 만들고, 이를 통해 NovaCOMET을 학습시킨다.
    3. NovaCOMET은 임의의 구조를 입력이나 출력으로 사용할 수 있도록 한 오픈 포맷 훈련 목적으로 구성되어 있다. 그 결과, NovaCOMET은 커먼센스 생성 태스크에서 Flan-T5와 유사한 오픈 태스크 모델을 능가한다.

###### In-Context Demonstration Selection with Cross Entropy Difference (https://aclanthology.org/2023.findings-emnlp.81/)
- Anthology ID: 2023.findings-emnlp.81 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델(Large language model, LLM)은 문맥 내 시연을 활용하여 제로샷(task-agnostic) 태스크 성능을 향상시킬 수 있으나, 가장 적합한 문맥 예제를 선택하는 것은 어렵다. 
    2. 우리는 테스트 예제에 대해 finetuning된 언어 모델의 perplexity와 문맥 시연의 효과가 음의 상관관계를 가진다는 관찰을 기반으로 크로스 엔트로피 차이(CED) 메소드를 제안한다. 
    3. CED를 사용하여 각 테스트 입력마다 문맥 시연을 순위화하고 선택함으로써, CED를 사용한 문맥 시연 선택은 다양한 LLM에 대해 베이스라인 선택 방법보다 성능을 향상시킬 수 있다.

###### The Past, Present, and Future of Typological Databases in NLP (https://aclanthology.org/2023.findings-emnlp.82/)
- Anthology ID: 2023.findings-emnlp.82 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 타입론 database들은 서로와 언어문법과 같은 다른 근원들 사이에서 일관성이 없다. 일부 불일치는 에러나 언어적 변형 때문이지만, 많은 불일치는 database의 이산적인 범주적 특성 때문이다.
    2. 우리는 타입론 database와 자연어처리의 활용과 불일치에 대해 체계적인 조사를 통해 이 문제에 빛을 냈다.
    3. 우리는 이산적인 타입론 database 대신 연속적인 타입론 특성을 사용하는 것이 유익하며, 이는 언어학의 권장사항과도 일치한다고 주장한다. 특히, 저자원 언어 모델링에 큰 잠재력을 가진다고 제안한다.

###### SoulChat: Improving LLMs’ Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations (https://aclanthology.org/2023.findings-emnlp.83/)
- Anthology ID: 2023.findings-emnlp.83 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델은 기억력과 사고 흐름의 능력 때문에 다양한 분야에서 널리 적용되고 있다. 그러나 심리상담 분야에서 이 모델들은 종종 일반적인 조언을 제공하려고 성급하게 움직인다. 
    2. 우리는 심리 지원을 받는 사용자들이 이성적인 조언보다는 공감, 신뢰, 이해, 위안을 필요로 한다는 점을 감안하여 대화 맥락과 감정적인 응답을 대상으로 한 다면 대화 데이터셋을 구축하였다. 
    3. 실험 결과, 심리 상담사의 표현에 가까운 대화 기록과 응답을 사용하여 대형 언어 모델의 공감 능력을 유의미하게 향상시킬 수 있다는 것을 보였다.

###### Can ChatGPT Assess Human Personalities? A General Evaluation Framework (https://aclanthology.org/2023.findings-emnlp.84/)
- Anthology ID: 2023.findings-emnlp.84 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 대형 언어 모델들 (LLM)은 다양한 영역에서 탁월한 결과를 내지만, 그들의 인간과 유사한 심리학적 특성은 아직 크게 연구되어지지 않았다.
    2. 본 논문에서는 LLM을 사용하여 인간의 성격을 분석하는 가능성을 탐구한 일반적인 평가 프레임워크를 제시한다.
    3. 실험 결과, ChatGPT는 인간의 성격을 평가할 수 있으며, 평균 결과는 InstructGPT보다 낮은 견고성에도 불구하고 더 일관되고 공정한 평가를 달성할 수 있음을 보여준다.

###### MoqaGPT : Zero-Shot Multi-modal Open-domain Question Answering with Large Language Model (https://aclanthology.org/2023.findings-emnlp.85/)
- Anthology ID: 2023.findings-emnlp.85 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 멀티모달 오픈 도메인 질문 답변은 이미지, 테이블, 파손 등과 같은 다양한 모달리티 데이터베이스에서 증거 검색을 필요로 하는데, GPT-4와 같은 대형 언어 모델조차 이 작업에 부족함을 보인다. 
    2. 우리는 LLMs가 이 작업을 제로샷 방식으로 수행할 수 있게하기 위해 MoqaGPT라는 간단하고 유연한 프레임워크를 제안한다.
    3. MoqaGPT는 복잡한 멀티모달 순위매기기를 우회하는 divide-and-conquer 전략을 사용하며, 새로운 모달리티를 수용하고 새로운 모델로 순조롭게 전환할 수 있다.

###### Large Language Models Know Your Contextual Search Intent: A Prompting Framework for Conversational Search (https://aclanthology.org/2023.findings-emnlp.86/)
- Anthology ID: 2023.findings-emnlp.86 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화형 검색에서 사용자의 상황에 맞는 검색 의도를 정확히 이해하는 것은 중요한 도전 과제이다. 기존 방법들은 제한된 데이터로 학습되었기 때문에 실제 대화형 검색 시나리오를 처리하는 데에 효과적이고 견고한 성능을 보여주지 못한다.
    2. 이 논문에서는 큰 언어 모델(Large Language Models)을 사용하여 대화형 검색에 도움이 되는 텍스트 기반 검색 의도 해석기로 활용하는 간단하면서도 효과적인 프롬프팅 프레임워크인 LLM4CS를 제안한다.
    3. 실험 결과, 우리의 LLM4CS 프레임워크는 기존 방법 및 심지어 사람에 의한 재작성을 사용한 경우와 비교하여 널리 사용되는 대화형 검색 벤치마크에서 뛰어난 성능을 보여준다. 이는 LLM을 대화형 검색에 더 잘 활용하기 위한 중요한 증거를 제공한다.

###### DocAsRef: An Empirical Study on Repurposing Reference-based Summary Quality Metrics as Reference-free Metrics (https://aclanthology.org/2023.findings-emnlp.87/)
- Anthology ID: 2023.findings-emnlp.87 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자동 요약 품질 평가는 reference-based와 reference-free 두 가지 범주로 나뉜다. 자동 요약을 평가할 때 reference-based 메트릭은 인간이 작성한 참조 정보에 의존하지만, 이 논문에서는 이러한 메트릭을 참조 문서 대신 원본 문서에 대해 평가하는 것으로 적용하여 reference-free 메트릭으로 변환할 수 있다는 가설을 제시한다.
    2. 실험 결과가 이 가설을 지원한다. pretrained DeBERTa-large-MNLI 모델을 사용한 zero-shot BERTScore는 다양한 측면에서 SummEval과 Newsroom 데이터셋에서 원래의 reference-based 버전보다 일관되게 성능이 우수하다. 또한 대부분의 기존 reference-free 메트릭 보다 우수한 결과를 보이며, GPT-3.5를 기반으로 한 zero-shot 요약 평가기와도 견줄만한 성능을 보인다.

###### Toxicity in chatgpt: Analyzing persona-assigned language models (https://aclanthology.org/2023.findings-emnlp.88/)
- Anthology ID: 2023.findings-emnlp.88 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화 기반의 LLM인 ChatGPT에서 특정 인물을 설정하는 것이 생성물의 독성을 크게 증가시키는 것을 발견했다. ChatGPT에 지정된 페르소나, 예를 들어 체급추기꾼 무함마드 알리와 같은,에 따라서 독성이 최대 6배까지 증가할 수 있는데, 이 때 생성물은 잘못된 편견, 유해한 대화, 상처를 주는 의견을 가지게 된다. 
    2. 또한 특정 개체(예: 특정 인종)가 다른 개체에 비해 표적으로 지정되어 논리 페르소나와 상관없이 차별적인 편견을 반영하는 문제가 있다. 
    3. 본 연구 결과는 법규안에서 여러 조항을 위반하고 있음을 보여주며, 폭넓은 AI 커뮤니티가 현재의 안전 매커니즘의 효과를 재고하고 견고하며 안전하며 신뢰성 있는 AI를 개발하기 위한 더 나은 기술을 개발하기를 바란다.

###### Execution-Based Evaluation for Open-Domain Code Generation (https://aclanthology.org/2023.findings-emnlp.89/)
- Anthology ID: 2023.findings-emnlp.89 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 실제적인 설정에서 코딩 쿼리 범위를 확장하기 위해, 우리는 ODEX라는 첫 번째 Open-Domain Execution 기반 Python 코드 생성 데이터셋을 제안한다. 
    2. ODEX에는 79개의 다양한 라이브러리를 포함한 945개의 자연어-코드 쌍과 실행을 위한 1,707개의 사람이 작성한 테스트 케이스가 있다. 
    3. ODEX는 CODEX보다 더 나은 결과를 보이는 반면, CODEGEN은 규모를 확장함에 따라 효과적으로 개선되며 CODEX과 동등한 성능을 보여준다.

###### Syntax-Aware Retrieval Augmented Code Generation (https://aclanthology.org/2023.findings-emnlp.90/)
- Anthology ID: 2023.findings-emnlp.90 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자연어 설명을 바탕으로 코드를 자동으로 생성하는 신경망 코드 생성 모델이 널리 채택되고 있으나, 현재의 방식은 색인 기반 메커니즘이 코드 생성과정에서 추가적인 잡음을 도입해 문법적으로도 잘못된 코드를 생성하는 문제가 있다.
    2. kNN-TRANX는 코드 생성 작업에 대한 맞춤형 작은 데이터 저장소에서의 검색을 가능하게 하여 이러한 문제를 해결한다. 또한 검색노이즈의 영향을 줄이기 위해 구문 제약을 활용한다.
    3. 두 개의 공개 데이터셋에서 kNN-TRANX를 평가한 결과, 우리의 접근 방식의 효과가 입증되었다.

###### Selecting Key Views for Zero-Shot Entity Linking (https://aclanthology.org/2023.findings-emnlp.91/)
- Anthology ID: 2023.findings-emnlp.91 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 엔티티 링킹은 텍스트의 멘션과 지식 베이스의 엔티티를 매칭시키는 것인데, 최근 연구에서는 zero-shot 환경에 초점을 맞추고 있다. 이 논문은 엔티티 설명에서 주요 정보를 선택하여 zero-shot 엔티티 링킹을 위한 KVZEL 프레임워크를 제안한다.
    2. KVZEL은 주석 관련 정보를 강조하고 멘션과 관련된 정보를 캡처하기 위해 unsupervised clustering과 키 뷰 선택 모듈을 사용한다.
    3. 실험 결과 KVZEL은 zero-shot 엔티티 링킹 데이터셋에서 새로운 최고 성능을 달성한다.

###### Is Explanation the Cure? Misinformation Mitigation in the Short Term and Long Term (https://aclanthology.org/2023.findings-emnlp.92/)
- Anthology ID: 2023.findings-emnlp.92 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 NLP 모델의 발전으로 자동 설명 생성이 제안되어 사회적 미디어 플랫폼에서의 잘못된 정보에 대항하는 대안으로 제시되고 있으나, 이러한 설명이 실제로 어떻게 사람들이 가짜 뉴스와 싸울 수 있는 데 도움이 되는지는 더 연구되어야 한다.
    2. 본 연구에서는 경고 레이블과 GPT-4로 생성된 최신 대조적 설명의 효과를 비교하여 가짜 뉴스의 잘못된 정보를 해체하는 데 어떤 것이 더 유용한지를 비교하는 것이다.
    3. 결과적으로, 경고 그룹과 설명 그룹 모두 단기 및 장기적으로 가짜 주장에 대한 참여자의 자체적인 믿음을 유의미하게 감소시키는 것으로 나타났다.

###### Improving the Robustness of Summarization Models by Detecting and Removing Input Noise (https://aclanthology.org/2023.findings-emnlp.93/)
- Anthology ID: 2023.findings-emnlp.93 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 요약 모델의 평가는 일반적으로 학습 데이터와 동일한 분포의 테스트 데이터를 사용한다. 그러나 실제 환경에서는 요약 대상 문서에 텍스트 추출 오류나 데이터 파이프라인 버그로 인해 노이즈가 포함될 수 있다.
    2. 우리는 다양한 유형의 입력 노이즈로 인한 모델 성능의 심각한 저하를 12 개의 ROUGE-1 점까지 측정하는 대규모 실험을 제시한다.
    3. 또한, 우리는 추가적인 학습, 보조 모델 또는 노이즈 유형의 사전 지식을 필요로하지 않고 모델 추론 중에 입력에서 노이즈를 감지하고 제거하는 가벼운 방법을 제안한다. 이를 통해 성능 저하의 상당 부분을 효과적으로 완화할 수 있으며, 때로는 11 개의 ROUGE-1 점 정도 큰 성능 향상을 나타낸다.

###### How Reliable Are AI-Generated-Text Detectors? An Assessment Framework Using Evasive Soft Prompts (https://aclanthology.org/2023.findings-emnlp.94/)
- Anthology ID: 2023.findings-emnlp.94 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 강력한 사전 학습 언어 모델(PLM)의 출시를 주된 원동력으로하여 AI가 생성한 텍스트의 급속한 확산이 있었지만, 이러한 텍스트의 남용 문제를 해결하기 위해 OpenAI detector와 Stanford DetectGPT 등 다양한 성능 우수한 탐지기가 개발되었다.
    2. 본 연구에서는 이러한 탐지기의 신뢰성을 어떻게 평가할 수 있는지를 묻고, 이에 대한 대답으로 PLM이 이러한 우수한 탐지기를 피하기 위해 텍스트를 생성할 수 있는 철저한 접근 방식을 설계한다.
    3. 제안된 접근 방식은 PLM이 탐지기를 속일 수 있는 "인간과 비슷한" 텍스트를 생산하기 위한 새로운 유형의 소프트 프롬프트인 "universal evasive prompt"를 제안하며, 다양한 작성 업무에서 여러 PLM을 활용하여 extensive한 실험을 진행하여 evasive soft prompt의 효과를 평가하였다.

###### Knowledge is a Region in Weight Space for Fine-tuned Language Models (https://aclanthology.org/2023.findings-emnlp.95/)
- Anthology ID: 2023.findings-emnlp.95 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 단일 모델과 단일 데이터셋에 대한 연구가 널리 집중되어 왔으나, 서로 다른 모델들 간의 관계에 대해서는 상대적으로 많이 알려져 있지 않다. 
    2. 본 논문에서는 서로 다른 모델들이 가중치 공간과 손실 함수 landscape에서 어떻게 상호 연결되는지를 연구하고 있다. 
    3. 실험 결과, 비슷한 데이터셋에서 finetuning된 모델들은 가중치 공간에서 군집을 이루며, 이들 모델들 사이를 탐색하면 새로운 모델이 태스크 성능을 유지하거나 개선할 수 있다는 것을 보여준다.

###### Unveiling the Multi-Annotation Process: Examining the Influence of Annotation Quantity and Instance Difficulty on Model Performance (https://aclanthology.org/2023.findings-emnlp.96/)
- Anthology ID: 2023.findings-emnlp.96 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. NLP 커뮤니티에서는 언어 해석, 주관성, 모호함의 뉘앙스를 더 잘 잡기 위해 다중 주석 데이터셋 구축을 주장해왔다. 
    2. 본 논문에서는 단일 주석과 다중 주석으로 데이터셋이 확장될 때 성능 평가 점수가 어떻게 다를 수 있는지 선행 연구를 진행한다. 
    3. 우리는 주석 예산이 동일한 유사한 데이터셋이 성능 향상에도 불구하고 다양한 결과를 야기할 수 있다는 것을 보여준다.

###### On the Risk of Misinformation Pollution with Large Language Models (https://aclanthology.org/2023.findings-emnlp.97/)
- Anthology ID: 2023.findings-emnlp.97 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 Large Language Models (LLMs)의 잠재적 오용이 신뢰할 만한 가짜 정보를 생성하고 이에 따른 정보 중심 애플리케이션, 특히 Open-Domain Question Answering (ODQA) 시스템에 미치는 영향을 조사했습니다.
    2. LLMs가 효과적인 가짜 정보 생성기로 작용할 수 있으며, 이는 ODQA 시스템의 성능에 중대한 저하 (최대 87%)를 일으킵니다.
    3. LLM이 생성한 가짜 정보로 인한 피해를 완화하기 위해, 가짜 정보 탐지, 주의 권유, 독자 앙상블이라는 세 가지 방어 전략을 제안하고 있습니다.

###### Dolphin: A Challenging and Diverse Benchmark for Arabic NLG (https://aclanthology.org/2023.findings-emnlp.98/)
- Anthology ID: 2023.findings-emnlp.98 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Dolphin"은 다양한 아랍어 언어와 다양성에 특화된 자연어 생성(NLG) 평가 프레임워크를 제공한다고 한다. 이 벤치마크는 다이얼로그 생성, 질문 응답, 기계 번역, 요약 등 13개의 다양한 NLG 태스크를 포함하고 있으며, 40개의 다양하고 대표적인 공개 데이터셋으로 구성되어 있다.
    2. Dolphin은 실제 상황과 아랍어의 언어적 풍부함을 반영하기 위해 신중하게 선정된 50개의 테스트 세트를 가지고 있으며, 아랍어 및 다국어 모델의 성능과 일반화 능력을 평가하는 새로운 기준을 제시하고 있다.
    3. Dolphin은 다양성을 강조하고 현재의 아랍어 NLG 연구의 빈곤한 부분을 파악하는 광범위한 분석을 제공하며, 이 벤치마크에서 여러 아랍어 및 다국어 모델을 평가하고 강력한 기준을 제시하여 연구자들이 비교할 수 있도록 한다.

###### Hierarchical Enhancement Framework for Aspect-based Argument Mining (https://aclanthology.org/2023.findings-emnlp.99/)
- Anthology ID: 2023.findings-emnlp.99 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Aspect-Based Argument Mining (ABAM)는 계산적 논증에서 중요한 작업이다. 기존의 방법들은 ABAM을 nested named entity recognition 문제로 다루어 ABAM 작업의 독특한 도전과제를 효과적으로 해결하기 위한 전략의 필요성을 간과하고 있다."
    2. 우리는 Hierarchical Enhancement Framework (HEF)에서 세 개의 새로운 구성 요소를 소개하여 ABAM을 위한 층별 개선 프레임워크를 제안한다. 
    3. 이 프레임워크는 Semantic and Syntactic Fusion (SSF) 구성 요소, Batch-level Heterogeneous Graph Attention Network (BHGAT) 구성 요소, Span Mask Interactive Attention (SMIA) 구성 요소를 통해 동작하여, argument unit과 aspect term 인식에서 도전 과제를 더 잘 다루고 성능과 정확도를 향상시킨다.

###### MenatQA: A New Dataset for Testing the Temporal Comprehension and Reasoning Abilities of Large Language Models (https://aclanthology.org/2023.findings-emnlp.100/)
- Anthology ID: 2023.findings-emnlp.100 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 큰 언어 모델 (LLMs)은 많은 자연어 처리 (NLP) 작업에서 거의 포화 상태의 성능을 보였다. 그 결과, 사람들은 LLMs가 시간 이해와 추론과 같은 능력도 능숙하게 습득했다고 믿는 것이 자연스럽다. 그러나, LLMs의 시간 감수성에 대한 연구는 충분히 강조되지 않았다.
    2. 이 논문에서는 LLMs의 시간 이해와 추론 능력을 평가하는 Multiple Sensitive Factors Time QA (MenatQA)를 구성한다. 이는 세 가지 시간적 요인 (범위 요인, 순서 요인, 반사실적 요인)을 포함하며, 총 2,853개의 샘플로 구성된다.
    3. 실험 결과, 현재 주요 LLMs는 다양한 매개변수 크기 (수십억에서 수천억까지)의 작은 시간 추론 모델에 비해 다른 정도로 시간적 추론에 뒤쳐지는 것으로 나타났다. 특히, LLMs는 시간적 편향에 취약하며 질문에서 제공된 시간적 정보에 크게 의존한다.

###### What Makes Chain-of-Thought Prompting Effective? A Counterfactual Study (https://aclanthology.org/2023.findings-emnlp.101/)
- Anthology ID: 2023.findings-emnlp.101 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 체인오브소울트 프롬프팅(CoT)의 효과는 널리 인정되었지만, 그 성공의 기반 메커니즘, 왜 다양한 태스크에서 잘 동작하는지에 대해서는 여전히 알려지지 않은 문제이다.
    2. 이 논문의 연구에서는 카운터펙처얼 프롬프팅 접근 방법을 사용하여 few-shot 프롬프트에서 사용되는 예제 요소들을 체계적으로 조작하고, 모델 동작에 미치는 영향을 테스트함으로써 이를 조사한다.
    3. 세 가지 서로 다른 대용량 언어 모델로 수행한 실험 결과는 몇 가지 핵심적인 결과를 보여준다.

###### Perceptual Structure in the absence of grounding: the impact of abstractedness and subjectivity in color language for LLMs (https://aclanthology.org/2023.findings-emnlp.102/)
- Anthology ID: 2023.findings-emnlp.102 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 언어 이해에 대한 그라운딩이 활발히 연구되고 있다. 이 연구에서는 인지적 중요성과 색상 모델과 언어 모델 간의 특성 공간의 상당한 일치를 보여주는 색상 인지와 색상 언어를 연구하기 위한 적합한 테스트 베드로 인식된다.
    2. 이 논문에서는 대규모의 색상과 설명을 수집하여 (1) 임베딩 공간과 색상 공간 간의 매핑을 학습한 inter-space 정렬과 (2) 색상 설명 간에 비교하는 intra-space 정렬을 비교하는 경험적 분석을 수행한다. 
    3. 결과는 모노렉스믹이고 실용적인 색상 설명의 경우 색상 공간 정렬이 유지되지만 주관성과 추상성과 같은 실제 언어 사용 요소가 포함된 예에서는 정렬이 상당히 감소하는 것을 보여주므로 그라운딩이 해당 경우에 필요할 수 있다는 것을 시사한다.

###### A Dataset for Investigating the Impact of Context for Offensive Language Detection in Tweets (https://aclanthology.org/2023.findings-emnlp.103/)
- Anthology ID: 2023.findings-emnlp.103 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 온라인 상에서의 욕설 탐지는 자연어처리에서 중요한 주제이다. 이 논문에서는 트위터의 답글 트윗에서 욕설 탐지를 위한 문맥의 중요성을 조사하였다.
    2. 욕설이 흔히 사용되는 트위터에서, 특정 트윗에 작성된 원본 트윗을 답글로 추가함으로써 문맥적 정보를 풍부하게 만든 터키어 트윗 데이터셋을 수집하였다.
    3. 이 데이터셋은 인간의 주석자에 의해 수작업으로 라벨링되어 공개되었으며, 문맥 정보의 유무에 따른 다양한 머신러닝 모델의 성능을 비교하였다. 그 결과, 특정 모델의 macro-averaged F1-score을 약간 향상시키긴 했지만, 일반적으로 문맥 정보는 모델 성능 향상에 크게 기여하지는 않았다.

###### Remember what you did so you know what to do next (https://aclanthology.org/2023.findings-emnlp.104/)
- Anthology ID: 2023.findings-emnlp.104 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 연구에서는 6B parameter GPT-J 언어 모델을 사용하여 초등학교 과학 실험을 위한 텍스트 게임 시뮬레이터인 ScienceWorld에서 30가지 목표를 달성하기 위한 계획을 작성하는 방법을 탐구한다. 
    2. 마르코프 가정을 사용하여 모델은 강화학습에 기반한 최신 방법을 1.4배 능가하는 성능을 보인다. 
    3. 실험 결과를 통해 30가지 작업에 대한 성능이 크게 다르므로 작업 평균화가 중요한 성능 문제를 가려낼 수 있다는 것을 보여준다.

###### An Empirical Study of Multimodal Model Merging (https://aclanthology.org/2023.findings-emnlp.105/)
- Anthology ID: 2023.findings-emnlp.105 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 모델 병합 기술을 통해 여러 가지 다른 작업에서 학습된 다수의 모델을 하나로 결합하여 멀티태스크 솔루션을 생성하는 방법이 주로 유사한 작업과 초기화로 학습된 모델들에 대해 성공적으로 적용되었다. 
    2. 본 논문에서는 이 개념을 모델들이 다른 모달리티에서 학습된 변형기들을 병합하는 다중 모달리티 설정에 적용하고자 한다. 
    3. 실험 결과, 초기화, 병합 메커니즘, 모델 아키텍처 등이 모델 병합 이후의 성능에 영향을 미친다는 것을 확인하였고, 또한 병합될 가중치 사이의 거리를 측정하고 병합 결과를 평가하는 두 가지 메트릭을 제안하였다. 이를 통해 모델 병합을 통해 모달리티-방지 구조의 성능을 매칭하는 효과적인 학습 방법을 발견하였고, VQA에서 3%, COCO 검색에서 7%, NLVR2에서 25%, Flickr30k에서 14%, ADE20k에서 3%의 성능 향상을 보였다.

###### Learning to Abstract with Nonparametric Variational Information Bottleneck (https://aclanthology.org/2023.findings-emnlp.106/)
- Anthology ID: 2023.findings-emnlp.106 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 글자, 서브 단어, 단어, 문장 수준의 학습된 표현은 각각 다른 NLP 작업과 언어 현상 이해에 기여하였지만, 텍스트 임베딩 학습은 토큰화에 특화되어 있고 추상화 수준별로 다른 모델을 훈련해야 하는 비용이 크다.
    2. 우리는 하나의 모델 내에서 서로 다른 계층에서 다른 수준의 추상화를 압축하는 학습 가능한 언어 표현 모델인 Nonparametric Variational Information Bottleneck (NVIB)을 Transformer self-attention 계층에 적용한다.
    3. 우리는 모델 내의 계층이 추상화 수준을 증가시키며, 그 표현이 언어적인 특성을 더 잘 반영한다는 것을 발견하였으며, NVIB 압축은 적대적 왜곡에 대해 더 견고한 모델을 얻을 수 있다고 보여준다.

###### Global Structure Knowledge-Guided Relation Extraction Method for Visually-Rich Document (https://aclanthology.org/2023.findings-emnlp.107/)
- Anthology ID: 2023.findings-emnlp.107 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 시각적 관계 추출(VRE)은 시각적으로 풍부한 문서 내의 entity 간 관계를 발견하는 강력한 수단이다. 
    2. 기존 방법들은 entity feature를 조작하여 pairwise 관계를 찾는 데 초점을 두었으나, 서로 다른 entity 쌍을 연결하는 더 근본적인 구조적 정보를 소홀히 한다. 
    3. GOSE는 초기 단계에서 문서의 스캔 이미지에서 추출된 entity 쌍에 대해 사전적인 관계 예측을 생성한 다음, 반복적인 예측에서 전역 구조적 지식을 포착하고 entity의 표현에 통합하여 모델의 성능을 향상시키는 프레임워크를 제안한다.

###### Learning to Compose Representations of Different Encoder Layers towards Improving Compositional Generalization (https://aclanthology.org/2023.findings-emnlp.108/)
- Anthology ID: 2023.findings-emnlp.108 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 seq2seq 모델들은 compositional generalization (CG)에 어려움을 겪는다는 것이 알려져왔다. 이 논문에서는 CG가 어려운 이유 중 하나가 인코더의 최상위 레이어의 표현이 혼재되어 있다는 점을 제시하고 있다.
    2. 이전에 식별되었던 표현의 혼재 문제만으로는 충분하지 않다고 본다. 또한, 다른 디코더 레이어에 전달되는 소스 키(key)와 값(value)의 표현도 혼재되어 있는 것으로 가정한다.
    3. 이 논문에서는 CompoSition이라는 seq2seq 모델의 확장을 제안하는데, 이 모델은 다른 태스크에 대해 다른 인코더 레이어의 표현을 동적으로 합성하여 특정 키와 값이 다른 디코더 레이어로 전달되도록 한다. 이 제안의 효과를 실험적으로 입증하였다.

###### SelectNoise: Unsupervised Noise Injection to Enable Zero-Shot Machine Translation for Extremely Low-resource Languages (https://aclanthology.org/2023.findings-emnlp.109/)
- Anthology ID: 2023.findings-emnlp.109 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 연구에서는 극히 적은 자원으로 주어진 언어에서 영어로의 기계 번역 작업에 초점을 맞추고 있다. 평행 데이터의 부재와 큰 다국어 사전 훈련 모델에서의 대표성 부족, 한정된 단일 언어 데이터가 ELRL 언어에 대한 MT 시스템 개발을 저해한다. 
    2. 그러나 많은 ELRL 언어는 방언의 변이, 지리적 근접성, 언어 구조와 같은 요인으로 인해 고자원 언어와 어휘적 유사성을 가진다. 이러한 특성을 활용하여 ELRL 언어에 대한 MT 작업을 가능하게 하는데 HRL 언어로부터의 cross-lingual 신호 향상을 위해 새로운 비지도식 접근 방법인 SelectNoise를 제안한다.
    3. 제안된 모델은 FLORES-200 벤치마크의 12개 ELRL 언어에 대해 zero-shot 설정에서 두 언어 패밀리를 거쳐 평가되었으며, 강력한 기준에 비해 더 나은 성능을 보여주었다. 그리고 supervised noise injection 모델과 품질이 비슷하다는 결과를 얻었다.

###### Breaking Boundaries in Retrieval Systems: Unsupervised Domain Adaptation with Denoise-Finetuning (https://aclanthology.org/2023.findings-emnlp.110/)
- Anthology ID: 2023.findings-emnlp.110 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Dense retrieval 모델들은 탁월한 효과를 보여주었지만, 풍부한 레이블 데이터에 의존하고 다른 도메인에 적용할 때 문제점이 있다.
    2. 기존의 도메인 적응 방법들은 가짜 쿼리를 생성하는 생성 모델을 사용하여 dense retrieval 모델의 성능을 향상시키기 위해 가짜 데이터셋을 생성했다. 
    3. 그러나 이러한 접근법은 일반적으로 적응되지 않은 rerank 모델을 사용하므로, 정확하지 않은 레이블을 얻을 수 있다. 이 논문에서는 rerank 모델을 target 도메인에 적응시키는 것의 중요성을 입증하고, 이를 통해 더 정확한 레이블을 얻어 dense retrieval 모델의 전체적인 성능을 향상시키는 방법을 소개한다.

###### Exploring the Cognitive Knowledge Structure of Large Language Models: An Educational Diagnostic Assessment Approach (https://aclanthology.org/2023.findings-emnlp.111/)
- Anthology ID: 2023.findings-emnlp.111 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 연구는 LLMs의 학습 능력을 테스트하고 다양한 도메인에서 뛰어난 능력을 나타내었으나, LLMs의 지식 구조에 대한 인식은 부족하다. 
    2. 이 논문에서는 교육적 진단 평가 방법을 사용하여 LLMs의 지식 구조를 평가하고 인식 능력을 파악한다.
    3. LLMs의 지식을 조명함으로써 연구자들은 더욤 정보화되고 효과적인 LLMs의 개발과 활용을 진전시킬 수 있다.

###### Simpler neural networks prefer subregular languages (https://aclanthology.org/2023.findings-emnlp.112/)
- Anthology ID: 2023.findings-emnlp.112 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. LSTMs는 L0 정규화의 연속적 완화를 적용함으로써 희소성을 유도하는데 이를 통해 LSTMs가 학습하고 표현하기 쉬운 형식 언어의 패턴에 관심이 있다.
    2. 다양한 테스트에서 우리는 희소한 LSTMs가 정반 정규 언어보다 소규칙(subregular) 언어를 선호한다는 것을 발견했으며, LSTMs에서의 이러한 편향은 희소성 압력이 커질수록 강해진다.
    3. 또한, 소규칙 언어로 훈련된 LSTMs는 비-0 매개변수가 더 적다. 이러한 LSTMs의 소규칙 편향은 적절한 설명 언어의 간단함 편향 아래에서 발생하는 인간의 음운학에서의 소규칙 언어 편향과 관련되어 있다고 추측한다.

###### Simple Hardware-Efficient PCFGs with Independent Left and Right Productions (https://aclanthology.org/2023.findings-emnlp.113/)
- Anthology ID: 2023.findings-emnlp.113 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 수천 개의 nonterminal에 대한 밀집 PCFG 스케일링은 규칙 확률 텐서의 저차원 파라미터화를 통해 비슷한 규모의 HMM보다 효과적임이 입증되었으나, 이 방식으로 크기를 확장한 PCFG는 여전히 언어 모델로서 성능이 안 좋고 HMM보다 성능이 나쁘다.
    2. 본 논문에서는 독립적인 좌우 생성 (independent left and right productions) 을 강하게 가정한 SimplePCFG를 소개하며, 저차원 방식보다 확장성이 효과적이라는 것을 발견했다.
    3. 또한 SimplePCFG의 확장성을 향상시키기 위해 FlashInside라는 하드웨어 I/O-aware한 inside algorithm 구현을 도입하였으며, 여러 grammar induction 벤치마크에서 extensive한 실험을 통해 SimplePCFG의 효과를 검증하였다.

###### R3 Prompting: Review, Rephrase and Resolve for Chain-of-Thought Reasoning in Large Language Models under Noisy Context (https://aclanthology.org/2023.findings-emnlp.114/)
- Anthology ID: 2023.findings-emnlp.114 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Chain-of-Thought (CoT) prompting을 통해 Large Language Models (LLMs)은 다양한 추론 태스크에서 놀라운 성능을 달성했지만, 대부분의 태스크는 노이즈가 없는 문맥에서 평가되었고, 노이즈가 있는 문맥에서 LLMs가 부정확한 결과를 생성하는 문제는 완전히 조사되지 않았다.
    2. 기존 연구는 트리거 문장(trigger sentences)을 사용하여 LLMs가 관련 정보에 집중하도록 유도하지만, 트리거는 최종 정답 예측에 제한적인 영향을 미친다.
    3. 이 논문에서는 noise가 있는 문맥에서 CoT 추론을 위한 R3 prompting이라는 새로운 프롬프팅 방법을 제안한다. R3 prompting은 LLMs와 상호작용을 통해 핵심 문장 추출, 변수 선언 및 정답 예측을 수행하며, 이는 검토, 다시 구문화 및 해결 등의 사고과정에 해당한다. R3 prompting은 노이즈가 있는 문맥에서 다섯 가지 추론 태스크에서 기존 CoT prompting 방법보다 큰 성능 향상을 보였다.

###### Quality Estimation-Assisted Automatic Post-Editing (https://aclanthology.org/2023.findings-emnlp.115/)
- Anthology ID: 2023.findings-emnlp.115 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자동 텍스트 수정(APE) 시스템은 기계 번역(MT) 출력물의 과다 수정 문제가 있다. 단어 수준의 품질 평가(QE) 시스템은 과다 수정을 방지하는 방법을 제공할 수 있지만, 기존의 APE와 QE 조합 전략을 사용하여 상당한 성능 향상이 관측되지 않았다.
    2. 이 논문에서는 APE를 개선하기 위해 APE와 QE 작업에 대한 모델의 공동 훈련을 제안한다. 제안된 접근 방식은 다중 작업 학습(MTL) 방법론을 활용하며, 훈련 중 양쪽 작업을 '협상 게임'으로 다루면서 상당한 향상을 보여준다.
    3. 또한, 다양한 기존 조합 전략을 조사하고, 제안된 접근 방식이 '먼' 언어 쌍인 영어-마라티어에 대해 최첨단 성능을 달성하는 것을 보여준다. QE 비지도 APE 시스템에 대해 영어-마라티어에서 1.09 TER 및 1.37 BLEU 포인트 개선을 관찰하고, 영어-독일어에서는 0.46 TER 및 0.62 BLEU 포인트를 관찰한다.

###### Adapter Pruning using Tropical Characterization (https://aclanthology.org/2023.findings-emnlp.116/)
- Anthology ID: 2023.findings-emnlp.116 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 어댑터는 사전 훈련된 언어 모델의 레이어 사이에 학습 가능한 모듈을 삽입하는 파라미터 효율적인 전이 학습 접근법이다. 그러나 어댑터 파라미터의 최적 개수를 분석하는 연구가 부족하다. 
    2. 따라서, 우리는 훈련 가능한 모듈의 tropical 특성을 연구하여 어댑터 가중치를 자르는 접근법을 제안한다.
    3. 실험 결과는 tropical geometry가 magnitude-based 기준과 비교했을 때 더 관련성이 높은 파라미터를 자를 수 있음을 보여주며, 합친 방법이 다양한 작업에서 가장 잘 작동한다.

###### Self-Supervised Rule Learning to Link Text Segments to Relational Elements of Structured Knowledge (https://aclanthology.org/2023.findings-emnlp.117/)
- Anthology ID: 2023.findings-emnlp.117 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 우리는 지식 베이스 질문 응답 시스템에서 관계 연결을 수행하기 위해 해석 가능한 규칙인 지식을 자기학습하는 신경 기호적 접근 방식을 제안한다.
    2. 학습 중에 학습된 가중치는 관계 연결을 수행하는 데 필요한 매핑 역할을 효과적으로 수행한다.
    3. 마스킹 된 훈련 전략을 사용하여 규칙을 자기학습하는 데 있어 이 작업의 차별화된 측면은 문장의 논리 형태에 적용된다. 이는 구조화된 지식 원본에서 확장된 문맥 정보를 추출하고 이를 기반으로 견고하고 인간이 읽을 수 있는 규칙을 구축하는 기회를 제공한다.

###### TaTA: A Multilingual Table-to-Text Dataset for African Languages (https://aclanthology.org/2023.findings-emnlp.118/)
- Anthology ID: 2023.findings-emnlp.118 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 data-to-text generation 데이터셋은 대부분 영어로 제한되어 있다. 이 연구에서는 이러한 데이터 부족 문제를 해결하기 위해 아프리카어에 초점을 맞춘 첫 번째 대규모 다국어 table-to-text 데이터셋인 TaTA를 생성하였다.
    2. TaTA는 계통학적 및 보건 조사 프로그램에 의한 이중언어 보고서의 테이블과 관련 텍스트를 전문 번역을 통해 9개 언어로 병렬화하여 구축되었다.
    3. 인간 평가를 통해 TaTA는 현재의 모델에 대해 어렵고, mT5-XXL 기반 모델에 의한 출력 중 이해 가능하고 소스 데이터에 귀속되는 결과는 절반에 불과함을 보여주었다. 이 결과는 가) 평가 메트릭의 검증 필요성과 나) 도메인 특정 메트릭의 중요성을 강조한다.

###### Explain-then-translate: an analysis on improving program translation with self-generated explanations (https://aclanthology.org/2023.findings-emnlp.119/)
- Anthology ID: 2023.findings-emnlp.119 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 연구는 언어 모델을 사용하여 코드 간 변환을 위한 중간 단계로 자체 생성된 자연어 설명의 사용을 탐색한다. MultiPL-E 데이터셋에서 생성된 3가지 유형의 설명과 19개 프로그래밍 언어를 대상으로 실험한 결과, 설명은 제로샷 경우에 특히 효과적이며, 성능을 평균 12% 향상시킨다. 자연어 설명은 어려운 프로그램에서 특히 두드러진 효과를 보였다.
    2. 자연어 설명을 사용한 실험 결과, 제로샷 경우에 특히 수행 성능이 향상되었으며, 설명이 어려운 프로그램에 특히 도움이 된다는 것을 확인하였다.
    3. 19개 언어로 된 데이터셋, 코드 및 기준 솔루션을 공개한다.

###### Can Brain Signals Reveal Inner Alignment with Human Languages? (https://aclanthology.org/2023.findings-emnlp.120/)
- Anthology ID: 2023.findings-emnlp.120 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "뇌 신호 (예: 뇌파)와 인간 언어는 다양한 하향 작업에 독립적으로 널리 연구되었지만, 그들 간의 관계 와 의존성을 잘 알려진 바가 없다." 
    2. "우리는 MTAM이라는 다중 모달 트랜스포머 (Multimodal Transformer Alignment Model)을 소개하여 이 두 매체 간의 조정된 표현을 관찰하는 것을 목표로 한다."
    3. "우리의 방법은 감성 분석 및 관계 감지와 같은 하향 응용 프로그램에서 ZuCo 및 K-EmoCon 두 데이터 세트에 대해 새로운 최첨단 결과를 달성했다. 또한, 우리는 그 결과의 해석과 함께 코드를 공개적으로 제공한다."

###### DemoSG: Demonstration-enhanced Schema-guided Generation for Low-resource Event Extraction (https://aclanthology.org/2023.findings-emnlp.121/)
- Anthology ID: 2023.findings-emnlp.121 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 현재의 이벤트 추출 (EE) 방법들은 대규모의 주석이 달린 데이터가 필요한 높은 리소스 시나리오에 초점을 맞추고 있어서, 저자금 도메인에는 적용하기 어렵다. 이러한 제한된 리소스로 EE를 더 효과적으로 다루기 위해, 저작 리서스를 활용한 스키마 가이드 생성 (DemoSG) 모델을 제안한다.
    2. 우리는 EE를 설명에 기반한 학습 패러다임으로 제안하여 주석이 달린 데이터를 활용하여 추출 프로세스를 설명하고, 모델의 효과적인 학습을 돕도록 한다.
    3. 또한, 우리는 스키마 기반 프롬프트에 따라 자연어 생성 작업으로 EE를 정의하여, 저자원 시나리오에서 라벨 의미론을 활용하고 지식 전이를 촉진한다. 우리는 세 개의 데이터셋에서 도메인 내 및 도메인 적응 저자원 시나리오에서의 확장적인 실험을 수행하고, DemoSG의 강건성을 연구한다. 결과는 DemoSG가 저자원 시나리오에서 현재 방법들보다 큰 성능 향상을 보인다.

###### GLGR: Question-aware Global-to-Local Graph Reasoning for Multi-party Dialogue Reading Comprehension (https://aclanthology.org/2023.findings-emnlp.122/)
- Anthology ID: 2023.findings-emnlp.122 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다자간 대화 읽기 이해(MDRC)에서 그래프 추론은 다양한 정보(clue)를 통합하는데 기여한다. 하지만 기존의 접근 방식은 질문을 그래프 추론에 적용하지 않고, 발화문의 지역적 의미 구조를 무시한다.
    2. 이 논문에서는 질문을 고려한 전역부터지역 그래프 추론 방법을 제안한다. 전통적인 상대말-발화문 그래프에 질문 노드를 추가하여 종합적인 전역 그래프 추론을 가능하게 한다. 또한, 각 발화문에 대해 의미 역할 그래프를 구성하여 의미적 관계에 의거한 지역 그래프 추론을 수행한다.
    3. 실험 결과, 제안된 방법은 BERT와 ELECTRA 기준에 비해 매우 큰 개선을 보여주며, 모울웨니와 FriendsQA에서 각각 73.6%와 77.2%의 F1 점수를 얻어 다른 사전 훈련 언어 모델을 백본으로 사용하는 최신 기법들을 능가한다.

###### Towards Mitigating LLM Hallucination via Self Reflection (https://aclanthology.org/2023.findings-emnlp.123/)
- Anthology ID: 2023.findings-emnlp.123 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 대형 언어 모델(LLMs)은 질의응답(QA)과 같은 생성 및 지식 집약적 작업에 대한 가능성을 보였으나, 모델이 사실과 일치하지 않거나 의미없는 정보를 생성하는 "환각(hallucination)" 문제가 여전히 해결되지 않고 있다.
    2. 본 논문에서는 의학 분야에서 널리 사용되는 LLM과 데이터셋을 사용하여 환각 현상을 분석하였는데, 목표는 일반적으로 문제가 되는 답변들을 식별하고 이해하는 것이다.
    3. 이를 해결하기 위해, 우리는 지식 습득과 답변 생성을 접목한 대화식 자기 반성 방법론을 제안한다. 이를 통해 우리의 접근 방식은 점진적으로 사실성, 일관성 및 함의를 향상시키며, 점점 더 정확하고 정확한 답변을 생성한다는 것을 실험 결과로 입증하였다.

###### Making Body Movement in Sign Language Corpus Accessible for Linguists and Machines with Three-Dimensional Normalization of MediaPipe (https://aclanthology.org/2023.findings-emnlp.124/)
- Anthology ID: 2023.findings-emnlp.124 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 수화 동영상 자료에서 movement를 확인하는 데에는, 수동 주석이나 컴퓨터 기반 방법이 사용된다. 하지만 전자는 feature의 사전 정의에 의존하고, 후자는 기술적인 지식을 요한다.
    2. 이 논문에서는 2차원 이미지에서 한정적인 depth 좌표 근사치로 body pose를 감지하는 MediaPipe 및 OpenPose와 같은 방법을 제안한다.
    3. 논문에서 제안하는 새로운 3차원 정규화 방법을 사용하여 2차원 자세 데이터의 잠재적인 한계를 해결하였고, 이를 통해 deep learning 기반 접근법에서 좋은 성능을 보여주었다.

###### XTREME-UP: A User-Centric Scarce-Data Benchmark for Under-Represented Languages (https://aclanthology.org/2023.findings-emnlp.125/)
- Anthology ID: 2023.findings-emnlp.125 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 데이터 부족은 다국어 NLP 시스템 개발에 있어 중요한 문제입니다. 그러나 NLP 연구가 특히 사용자 요구를 충족시키지 못하는 언어들에 대해서는 소량의 데이터를 주석으로 붙이는 것이 가능합니다.
    2. 이 논문에서는 XTREME-UP라는 벤치마크를 제안하며 일반적으로 유용한 작업인 사용자 중심(task-centric) 작업에 초점을 맞추고 있습니다. XTREME-UP은 OCR, 자동 완성, 의미 분석, 음성 인식, 기계 번역 등 9가지 주요한 사용자 중심 기술 부문에 걸쳐 88개의 언더 리프레젠티드 언어들을 평가합니다.
    3. 이를 위해 XTREME-UP은 텍스트만을 고려한 모델링 시나리오, 멀티모달(비전, 오디오, 텍스트) 모델링 시나리오, 지도 학습 매개변수 조정, 문맥 학습 등 여러 가지 모델링 시나리오를 평가하는 방법론을 제공하고 있습니다.

###### DiffuVST: Narrating Fictional Scenes with Global-History-Guided Denoising Models (https://aclanthology.org/2023.findings-emnlp.126/)
- Anthology ID: 2023.findings-emnlp.126 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 AI 기반 이미지 합성의 진보로 인해, 추상성과 다양성을 갖춘 시각적인 장면들이 많이 생성되었으며, 이에 따라 시각적인 스토리텔링(VST)은 더욱 도전적인 작업이 되었고, 실제 장면 이상으로 요구되고 있다.
    2. 기존 VST 기술은 보통 자가회귀 디코더를 사용하는데, 많은 progress를 보이지만 추적 속도가 낮고 가상 장면에는 적합하지 않다.
    3. 이 논문에서는 시각적 설명의 생성을 단일 조건부 노이즈 제거 과정으로 모델링하는 획기적인 확산 기반 시스템인 DiffuVST를 제안한다. 추론 시에 확률적이고 비자기 회귀적인 특성을 가진 DiffuVST는 더 효율적으로 다양한 내러티브를 생성할 수 있다.

###### DiFair: A Benchmark for Disentangled Assessment of Gender Knowledge and Bias (https://aclanthology.org/2023.findings-emnlp.127/)
- Anthology ID: 2023.findings-emnlp.127 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사전 학습 언어 모델의 성별 편향을 완화하기 위해 많은 균형 조정 기술이 제안되었지만, 이는 모델의 예측에서 성별 중립성을 얼마나 검증하는지를 평가하는 기존 데이터셋에 의존한다. 이 논문에서는 이러한 평가 프로토콜이 유용한 성별 지식에 대한 부작용을 고려하지 못한다고 지적하고, 유용한 성별 지식이 유지되는지를 확인할 수 있는 통합 메트릭인 "gender invariance score"를 도입한다.
    2. "DiFair"라는 수동으로 제작된 데이터셋을 기반으로, 사전 학습 언어 모델과 균형 조정 기술에 대한 벤치마크로 사용된다. 실험 결과는 기존의 성별 편향 문제를 확인하면서도, 균형 조정 기술이 성별 편향 문제를 개선하지만 이로 인해 모델의 유용한 성별 지식이 감소하는 경향을 보여준다.
    3. 따라서 이 논문은 성별 편향을 해결하는 한편, 모델의 유용한 성별 지식을 유지할 수 있는 방법을 제시한다.

###### Transformer-Based Language Model Surprisal Predicts Human Reading Times Best with About Two Billion Training Tokens (https://aclanthology.org/2023.findings-emnlp.128/)
- Anthology ID: 2023.findings-emnlp.128 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 심리언어학적 연구들은 언어 모델의 품질과 예상치의 능력 사이에 모순된 결론을 내놓았다. 이 논문은 역사적으로 높은 양의 훈련 데이터와 모델 용량의 큰 격차 때문에 이러한 다양성이 생기는 것이라고 제안한다.
    2. 이 연구에서는 훈련 데이터와 모델 용량이 체계적으로 다른 Transformer 기반 언어 모델별로 예상치 측정치가 인간의 읽기 시간을 예측하는 능력을 평가하여 이러한 결과들을 통합한다.
    3. 결과적으로, 현대적인 모델 용량을 가진 대부분의 변형체들은 약 20억 개의 훈련 토큰을 본 후에 가장 적합한 예측치를 제공하며, 그 이후에는 인간의 기대치와 일치하지 않게 되는 것으로 나타났다. 또한, 새롭게 훈련된 작은 모델 변형체들은 수렴시 '포인트'로 반영되며, 언어 모델의 내재적인 크기가 인간의 읽기 시간과 일치하는데 필요한 요소임을 보여준다.

###### ExplainCPE: A Free-text Explanation Benchmark of Chinese Pharmacist Examination (https://aclanthology.org/2023.findings-emnlp.129/)
- Anthology ID: 2023.findings-emnlp.129 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 연구들은 언어모델의 유용성을 탐구하고 있지만, 중요한 문제는 이 모델들의 해석 가능성이다. 기존 설명 데이터셋은 영어와 일반적인 도메인에 한정되어 있어 언어 다양성의 부족과 의료와 같은 특수 도메인의 부족으로 인해 한계가 있다. 이를 해결하기 위해 "ExplainCPE"라는 의학 분야에 특화된 도전적인 데이터셋을 제안한다.
    2. 중국에서 의약사 시험에 대한 7K개 이상의 문제로 구성된 ExplainCPE는 언어모델이 생성하는 설명을 평가하는 목적으로 만들어졌다.
    3. 전체 결과를 보면, GPT-4만이 약사 시험을 75.7%의 정확도로 통과하고, ChatGPT와 같은 다른 모델들은 실패한다. 더 상세한 분석 결과, 언어모델이 생성한 설명의 한계와 의료 텍스트의 이해와 계산적 추론에 대한 한계가 드러난다. 따라서 ExplainCPE는 의료 분야에서 언어모델의 해석 가능성을 개선하고 평가하는 방향으로 한 발 더 나아간다.

###### CLASS: A Design Framework for Building Intelligent Tutoring Systems Based on Learning Science principles (https://aclanthology.org/2023.findings-emnlp.130/)
- Anthology ID: 2023.findings-emnlp.130 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. CLASS 프레임워크는 고성능의 Large Language Model (LLM)을 통해 고급 지능형 학습 시스템 (ITS)을 구축하는 데 사용하는 설계 도구이다. 이 프레임워크는 학습자에게 튜터처럼 단계별 가이드를 제공하고 학습자와 자연어 상호작용을 도와주는 두 가지 주요 기능을 제공한다.
    2. CLASS 프레임워크를 사용하여 개발된 SPOCK은 대학 수준의 생물학 컨텐츠에 중점을 둔 ITS로, 학습자에게 질문을 관리 가능한 하위 문제로 나누고 학습자에게 격려하는 답변을 제공하는 능력을 강조하여 전문가로부터 긍정적인 평가를 받았다.
    3. CLASS 프레임워크는 연속된 수정 및 개선을 가능하게 하며 사용자 피드백을 통합할 수 있어 ITS의 내부 의사 결정 과정에 대한 통찰력을 제공한다.

###### Normal-Abnormal Decoupling Memory for Medical Report Generation (https://aclanthology.org/2023.findings-emnlp.131/)
- Anthology ID: 2023.findings-emnlp.131 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 의료 보고서의 자동 생성은 임상 자동화에서 중요한 역할을 한다. 라디올로지 이미지는 자연 이미지와 달리 높은 유사성을 보이는 동시에 의료 데이터는 데이터 편향과 복잡한 노이즈에 취약하므로, 기존 방법들이 미세한 시각적 정보를 포착하는 데 어려움을 겪는다.
    2. 이 논문에서는 비정상적인 패턴 메모리를 활용하는 새로운 정상/비정상 의미 해체 네트워크를 소개하여 시각적 추출을 최적화한다. 정상/비정상 의미를 독립적으로 학습하여 시각적 네트워크의 최적화에 영향을 미치지 않도록 한다.
    3. 이 방법은 잡음이 있는 정상 의미와 보고서의 영향을 완화하며, 비정상 패턴 메모리를 위한 새로운 인코더를 개발하여 이미지의 비정상 패턴을 포착하고 내장하는 네트워크의 능력을 개선한다. 이 접근법은 MIMIC-CXR 벤치마크에서 우수한 성능을 나타내며 현재의 최고 성능 방법을 능가한다.

###### mmT5: Modular Multilingual Pre-Training Solves Source Language Hallucinations (https://aclanthology.org/2023.findings-emnlp.132/)
- Anthology ID: 2023.findings-emnlp.132 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다국어 sequence-to-sequence 모델은 언어 처리 범위가 넓어질수록 성능이 저하되며, few-shot 설정에서 올바른 목표 언어의 텍스트를 일관되게 생성하지 못한다. 
    2. 이 논문에서는 mmT5라는 모듈식 다국어 sequence-to-sequence 모델을 제안한다. 
    3. mmT5는 pre-training 중 언어별 모듈을 사용하여 언어-일반 정보를 분리하며, fine-tuning 과정에서 발생하는 representation drift를 완화시키기 위한 전략을 개발하여 40개 이상의 언어에서 대표적인 자연어 이해와 생성 과제에서 mT5과 비교했을 때 월등한 성능 향상을 보인다.

###### ImageNetVC: Zero- and Few-Shot Visual Commonsense Evaluation on 1000 ImageNet Categories (https://aclanthology.org/2023.findings-emnlp.133/)
- Anthology ID: 2023.findings-emnlp.133 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근, 대형 언어 모델 (LLM)은 일반적인 인터페이스로 사용되고 있는데, 이는 포괄적인 시각적 지식에 대한 중요한 요구 사항을 발생시킨다.
    2. 이 연구에서는 시각적 commonsense 지식을 제대로 활용할 수 있는 현재의 LLM과 그의 시각적 augmented 상대방 (VaLM)의 실력이 어느 정도인지 조사한다.
    3. ImageNetVC를 활용하여 1,000개의 ImageNet 카테고리를 대상으로 zero- 및 few-shot 시각적 commonsense 평가를 위한 인간 주석 데이터셋을 구축한다.

###### MultiCoNER v2: a Large Multilingual dataset for Fine-grained and Noisy Named Entity Recognition (https://aclanthology.org/2023.findings-emnlp.134/)
- Anthology ID: 2023.findings-emnlp.134 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. MULTICONER V2는 12개 언어에서 33개 entity 클래스를 다루는 fine-grained Named Entity Recognition(NER) 데이터셋으로, movie titles과 같은 복잡한 entity를 포함하는 fine-grained 클래스를 효과적으로 처리하고, typing mistakes나 OCR 오류로 인한 노이즈로 인한 성능 하락을 대비한다.
    2. MULTICONER V2의 특징으로는 fine-grained taxonomy의 어려움과 entity 오염이 성능에 미치는 영향이 크다는 점이 있다. entity 오염으로 인해 비엔티티 오염에 비해 성능이 9% 하락하는 것을 확인할 수 있다.
    3. MULTICONER V2 데이터셋은 Wikipedia와 Wikidata 같은 오픈 리소스를 사용하여 공개되어 있으며, XLM-RoBERTa 기준 평가 결과는 이 데이터셋의 독특한 어려움을 강조하고 있다.

###### A Query-Parallel Machine Reading Comprehension Framework for Low-resource NER (https://aclanthology.org/2023.findings-emnlp.135/)
- Anthology ID: 2023.findings-emnlp.135 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 명명된 개체 인식(NER)은 자연어 처리에서 중요한 작업이다. 현재의 MRC(Machine Reading Comprehension)-기반 NER 기술은 한 번에 하나의 유형의 개체만 추출할 수 있으며 주로 resource-rich한 상황에 적용된다. 이로 인해 추론 단계에서 효율적이지 못하며, low-resource한 상황에서의 활용 가능성도 제한된다.
    2. 우리는 여러 개의 유형의 개체를 동시에 추출할 수 있는 query-parallel MRC 기반 접근법을 제안한다. 이는 resource-rich와 resource-limited 상황 모두에 적용 가능하다.
    3. 우리는 query-parallel encoder를 제안하며, 이는 query-segmented attention 메커니즘을 사용하여 query의 의미를 독립적으로 분리하고, 쿼리-컨텍스트 상호작용을 단방향 흐름으로 모델링한다. 이는 새로운 개체 유형에 대한 일반화나 새로운 도메인으로의 전이를 보다 쉽게 가능하게 한다.

###### BiSPN: Generating Entity Set and Relation Set Coherently in One Pass (https://aclanthology.org/2023.findings-emnlp.136/)
- Anthology ID: 2023.findings-emnlp.136 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Set Prediction Networks (SPNs)는 인스턴스간 상호작용을 모델링하여 named entity recognition과 관계 트리플 추출 작업에서 최고의 성능을 달성했다. 그러나 SPNs를 통해 entity와 relation triple을 동시에 추출하는 방법은 아직 연구되지 않은 문제이다. 이 논문에서는 Bipartite Set Prediction Network (BiSPN)을 제안하여 병렬로 entity set과 relation set을 효율적으로 생성할 수 있는 새로운 모델을 소개한다.
    2. BiSPN은 coherence 유지를 위한 새로운 bipartite consistency loss와 entity-relation linking loss를 훈련 중에 적용하여 도전적인 과제를 극복한다.
    3. 바이오의학/임상 데이터셋과 일반 도메인 데이터셋에서의 실험 결과, BiSPN은 지식 중심 scene에서 새로운 state-of-the-art 성능을 달성하며, 일반 도메인에서도 경쟁력 있는 성능을 보여준다. 이때, 두 단계의 joint extraction 방법보다 효율적이다.

###### MEEP: Is this Engaging? Prompting Large Language Models for Dialogue Evaluation in Multilingual Settings (https://aclanthology.org/2023.findings-emnlp.137/)
- Anthology ID: 2023.findings-emnlp.137 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다양한 언어에서 대화 시 평가를 위해 대화 기록을 사용한 실시간 평가 기준이 필요한데, 기존의 자동화된 평가 메트릭은 대화 기록을 고려하지 않거나 특정 데이터셋에 한정돼 있으며 사람의 평가와 상관성이 제한적이었다.
    2. 저자들은 대규모 언어 모델(Large Language Models, LLMs)을 활용하여 멋있는(engaging) 대화의 평가를 위한 프롬프트 시스템을 제안한다.
    3. 저자들은 선별된 프롬프트 요소와 LLMs를 사용함으로써 다국어 대화에서 engagingness 평가에서 기존 방법들보다 뛰어난 성능을 보였다.

###### Exploring the Impact of Corpus Diversity on Financial Pretrained Language Models (https://aclanthology.org/2023.findings-emnlp.138/)
- Anthology ID: 2023.findings-emnlp.138 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근에는 다양한 도메인 특화 사전 훈련 언어 모델(PLMs)이 제안되었으며, 생물의학, 과학 및 임상 분야와 같은 특수 영역에서 범용 PLM보다 우수한 성능을 보였다.
    2. 하지만 금융 데이터 분석의 경제적 영향이 크기 때문에 금융 PLMs에 대한 연구가 진행 중이며, 금융 PLMs는 충분히 다양한 금융 데이터로 사전 훈련되지 않았다는 문제점을 발견하였다. 
    3. 이 문제를 해결하기 위해 우리는 다양한 금융 말뭉치를 수집하고 이러한 다양한 데이터셋으로 Financial Language Model (FiLM)을 훈련시켰다. 실험 결과에서 FiLM은 기존 금융 PLMs뿐만 아니라 일반적인 도메인 PLMs보다 우수한 성능을 보인다는 것을 확인하였으며, 이 개선은 본문에서 제시한 방법을 통해 본문 그룹에 대해서도 달성될 수 있음을 입증하였다.

###### LLMDet: A Third Party Large Language Models Generated Text Detection Tool (https://aclanthology.org/2023.findings-emnlp.139/)
- Anthology ID: 2023.findings-emnlp.139 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 대형 언어 모델 (LLMs) 에서 생성된 텍스트는 고품질 인간 작성 텍스트에 근접하여, 거짓 정보 전파 및 학문적 부도에 잘못 사용될 수 있는 우려가 있습니다. 따라서 주어진 텍스트의 출처를 정확하게 식별할 수 있는 매우 실용적인 감지 도구가 긴급히 필요합니다. 
    2. 기존의 감지 도구들은 일반적으로 LLMs에 대한 액세스에 의존하며, 기계 생성 텍스트와 인간 작성 텍스트만 감지할 수 있으며, 미세한 추적, 중개 판단 및 신속한 감지의 요구 사항을 충족하지 못합니다. 
    3. 따라서 우리는 특정 LLMs (예: GPT-2, OPT, LLaMA 등) 을 통해 텍스트 출처를 파악할 수 있는 모델별, 안전하고 효율적이며 확장 가능한 감지 도구인 LLMDet을 제안합니다. LLMDet은 주요한 n-gram의 다음 토큰 확률을 기록하여 각 LLM의 Proxy Perplexity를 계산하는 기능을 가지고 있습니다. LLM의 Proxy Perplexities를 공동으로 분석함으로써 생성된 텍스트의 출처를 판단할 수 있습니다. 실험 결과, LLMDet은 높은 탐지 성능을 보여주며, 속도와 보안을 보장하며 인간 작성 텍스트를 인식하는 데 약 5배 빠르게 동작합니다. 추가로, LLMDet은 손쉽게 새로운 오픈 소스 모델에 대한 감지 기능을 확장할 수 있습니다. (https://github.com/TrustedLLM/LLMDet에서 오픈 소스 도구를 제공할 예정입니다.)

###### RECAP: Towards Precise Radiology Report Generation via Dynamic Disease Progression Reasoning (https://aclanthology.org/2023.findings-emnlp.140/)
- Anthology ID: 2023.findings-emnlp.140 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 방사선학 보고서 생성의 자동화는 방사선과사의 작업 부담을 크게 줄일 수 있다. 이전 연구는 예전부터 주로 문제점을 정확하게 파악하는 것에 중점을 두었으나, 환자의 현재 상태를 평가하는데 중요한 시간 정보를 무시하고 있다.
    2. 이 논문에서는, 두 개의 연속 방사선 사진을 기반으로 관찰과 진행 상황 (공간-시간 정보) 을 예측한 다음, 이를 토대로 보고서를 생성하는 RECAP을 제안한다.
    3. RECAP은 질병 진행 그래프와 동적 진행 추론 메커니즘을 고안하여 관찰과 진행의 속성을 정확하게 선택하는 방사선 보고서를 생성한다.

###### Causal Intervention for Abstractive Related Work Generation (https://aclanthology.org/2023.findings-emnlp.141/)
- Anthology ID: 2023.findings-emnlp.141 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Abstractive related work generation"은 독자들이 현재 연구를 이해하는 데 도움이 되는 일관성 있는 관련 작업을 생성하는 데에 관심이 증가하고 있다. 그러나 대부분의 기존 모델은 관련 작업 생성 중에 내재적인 인과 관계를 무시하여 잘못된 상관관계를 유발하고 이로 인해 모델의 생성 품질과 일반성이 저하된다.
    2. 이 연구에서는 인과적 개입이 이러한 한계를 해결하고 생성된 관련 작업의 품질과 일관성을 개선할 수 있다고 주장한다. 이를 위해 우리는 효과적으로 생성 과정에서 원인-결과 사이의 관계를 포착하기 위한 새로운 Causal Intervention Module for Related Work Generation (CaM)을 제안한다.
    3. CaM을 Transformer와 융합하여 end-to-end 관련 작업 생성 프레임워크를 얻을 수 있으며, 두 개의 실제 데이터셋에서 수행한 실험 결과, CaM은 효과적으로 모델이 인과 관계를 학습하고 더 높은 품질과 일관성의 관련 작업을 생성할 수 있도록한다.

###### G-SPEED: General SParse Efficient Editing MoDel (https://aclanthology.org/2023.findings-emnlp.142/)
- Anthology ID: 2023.findings-emnlp.142 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델은 인간의 지시를 이해하고 기대한 내용을 출력하여 작업 효율성을 크게 향상시킬 수 있다. 
    2. 본 논문에서는 General SParse Efficient Editing MoDel (G-SPEED)을 제안하여 최소한의 계산 비용으로 다양한 편집 요구를 충족시킬 수 있다. 
    3. 실험 결과는 G-SPEED가 175B 개의 파라미터를 갖는 대형 모델보다 우수한 성능을 보인다는 것을 보여준다.

###### Attack Prompt Generation for Red Teaming and Defending Large Language Models (https://aclanthology.org/2023.findings-emnlp.143/)
- Anthology ID: 2023.findings-emnlp.143 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델은 유해한 콘텐츠를 생성할 수 있는 red teaming 공격에 취약한데, 이전 연구는 수작업이나 자동 방법을 통해 공격 prompt를 구성하는 데 제한이 있다. 
    2. 이 논문에서는 지속가능한 공격 prompt를 경제적으로 생성하기 위해 수작업 방법과 자동 방법을 결합한 통합 접근법을 제안한다.
    3. 새롭게 제안된 공격 프레임워크와 방어 프레임워크를 통해 LLM의 안전성을 향상시키고, SAP라는 다양한 크기의 공격 prompt 데이터셋을 제공하여 더 많은 LLM의 안전성 평가와 개선을 용이하게 한다.

###### Smart “Chef”: Verifying the Effect of Role-based Paraphrasing for Aspect Term Extraction (https://aclanthology.org/2023.findings-emnlp.144/)
- Anthology ID: 2023.findings-emnlp.144 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "우리는 문장으로부터 Aspect Term을 자동으로 추출하는 ATE(Apsect Term Extraction) 작업에 접근한다. PLN 기반 추출기들이 많은 향상을 이루었다. 하지만 ATE corpora에는 많은 비정보적이고 낮은 품질의 문맥들이 포함되어 있다."
    2. "우리는 문맥 지향적인 품질 향상 방법을 탐구한다. 특히, 우리는 가상 전문가들의 관점에서 문장을 자동으로 다시 작성하는 방법을 제안한다. 이를 기반으로 우리는 훈련된 추출기를 사용하여 테스트 중에 paraphrased된 문장 위에서 ATE를 수행한다."
    3. "실험 결과, 우리의 접근 방식은 "al di la"와 같은 눈에 띄지 않는 aspect term들을 효과적으로 재호출할 수 있었으며, 이는 정확도를 떨어뜨리기는 하지만 기존 문장에서 얻은 예측을 확장하는 데 사용될 수 있다는 것이 입증되었다."

###### Multi-Defendant Legal Judgment Prediction via Hierarchical Reasoning (https://aclanthology.org/2023.findings-emnlp.145/)
- Anthology ID: 2023.findings-emnlp.145 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "다수의 피고인을 포함하는 형사 사실 설명은 일반적으로 복잡한 상호작용을 나타내며, 단일 피고인 사건에 대한 판례 예측 (LJP) 방법이 이를 제대로 처리하기 어렵다." 
    2. "이 문제를 해결하기 위해, 우리는 다수의 피고인 LJP 작업을 제안하며, 이 작업은 다수의 피고인 사건의 판결 결과 (예 : 법조, 혐의, 형벌 조건)를 자동으로 예측하는 것을 목표로 한다." 
    3. "Hierarchical Reasoning Network (HRN)이라는 다수의 피고인 LJP 방법을 도입하여 각 피고인의 범죄 관계, 판결 환경, 법조, 혐의, 형벌 조건을 결정하기 위해 계층적 추론 체인을 따르는 HRN 방법을 소개한다."

###### Interpreting Indirect Answers to Yes-No Questions in Multiple Languages (https://aclanthology.org/2023.findings-emnlp.146/)
- Anthology ID: 2023.findings-emnlp.146 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Yes-no 질문은 "예" 또는 "아니오"로 대답을 기대하지만, 사람들은 종종 극단적인 키워드를 건너뛰고 긴 설명으로 대답한다. 이 논문에서는 이 문제에 초점을 맞추고 8개 언어의 새로운 벤치마크를 발표한다.
    2. 우리는 훈련 데이터를 수집하기 위해 distant supervision 접근법을 제시하고, 극단적인 키워드를 포함하는 직접적인 대답이 간접적인 대답을 해석하는 모델 훈련에 유용하다는 것을 보여준다.
    3. 우리는 단일 언어의 fine-tuning이 관심 언어에 대해 distant supervision을 통해 훈련 데이터를 얻을 수 있는 경우에 유용하다는 것을 보여주며, cross-lingual fine-tuning은 항상 유익하다는 것을 보여준다.

###### Generalizing Few-Shot Named Entity Recognizers to Unseen Domains with Type-Related Features (https://aclanthology.org/2023.findings-emnlp.147/)
- Anthology ID: 2023.findings-emnlp.147 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 적은 데이터로 인식하는 NER 방법들은 낮은 자원 도메인에서 entity를 식별하는 데에 큰 진전을 보였으나, Out-of-Domain (OOD) 예제에는 여전히 어려움을 겪는다. 
    2. 이 논문에서는 OOD 예제에 대한 모델의 일반화를 위해 데이터 증강 기법을 사용하며, 도메인 간 지식 전이를 강화하는 프레임워크인 PLTR을 제안한다. 
    3. PLTR은 상호 정보 기준으로 entity type 관련 feature (TRF)를 추출하고, 각 OOD 예제에 대해 해당 TRF를 선택하여 고유한 프롬프트를 생성하여 모델의 능력을 향상시킨다.

###### Intervention-Based Alignment of Code Search with Execution Feedback (https://aclanthology.org/2023.findings-emnlp.148/)
- Anthology ID: 2023.findings-emnlp.148 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 코드 검색에서의 기본적인 목표 중 하나는 주어진 자연어 질의에 대해 기능적으로 정확한 코드를 검색하는 것입니다. 그러나 기존의 코드 검색 훈련 데이터는 정확성을 주장하기 위해 테스트 케이스를 실행하는 것이 필요하며, 이러한 실행 피드백을 긍정적인 것으로 인식합니다. 그러나 이 정규화는 모델의 검색 결정을 실제 정확성과 일치시키지 못할 수 있습니다.
    2. 이러한 제한을 해결하기 위해, 우리는 CIRL(Code Intervention-based Reinforcement Learning)을 제안합니다. 이는 훈련 코드를 개입시켜 모델의 결정을 왜곡시키고, 그 후 강화 학습을 통해 실행 피드백으로 이를 수정합니다. CIRL의 첫 번째 기술적 기여는 실제 실행 없이 개입으로부터 실행 피드백을 유발하는 것입니다.
    3. 두 번째로, CIRL은 단순한 어휘적 변경을 넘어 추상 구문 트리를 사용하여 구조적 개입을 도입합니다. 다양한 데이터셋에서의 실험적 결과는 CIRL이 기존 방법과 비교하여 효과적임을 보여줍니다.

###### Enhancing Neural Machine Translation with Semantic Units (https://aclanthology.org/2023.findings-emnlp.149/)
- Anthology ID: 2023.findings-emnlp.149 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 NMT 모델은 기본적으로 서브워드와 단어를 모델의 입력과 이해에 사용하지만, 실제 의미를 표현하는 데 필수적인 완전한 단어와 구문은 종종 의미 단위로 사용된다. 
    2. 이 논문에서는 문장 내의 의미 단위의 총 의미를 모델링하고, 이를 활용하여 문장을 이해하기 위한 새로운 관점을 제공하는 Semantic Units for Machine Translation (SU4MT) 방법을 제안한다. 
    3. 실험 결과에서는 우리의 방법이 의미 단위 수준의 정보를 효과적으로 모델링하고, 강력한 기준 모델보다 성능이 우수함을 보여준다.

###### DRAFT: Dense Retrieval Augmented Few-shot Topic classifier Framework (https://aclanthology.org/2023.findings-emnlp.150/)
- Anthology ID: 2023.findings-emnlp.150 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다양한 정보의 증가로 인해 임의의 주제를 분류하는 수요가 점점 중요해지고 있다. DRAFT는 몇 개의 예시를 사용하여 특정 주제의 분류기를 훈련시키기 위해 설계된 간단한 프레임워크이다.
    2. DRAFT는 특정 주제와 관련된 여러 개의 질문을 효과적으로 처리하는 Multi-query retrieval (MQR) 알고리즘을 사용하여 Customized 데이터셋을 구축한다.
    3. DRAFT는 InstructGPT 175B와 같은 in-context learning을 사용하는 베이스라인과 비교했을 때, 177배 더 적은 파라미터를 가지면서도 few-shot 주제 분류 작업에서 경쟁력 있는 또는 우수한 성능을 보여주며 그 효과를 입증한다.

###### A Framework for Exploring Player Perceptions of LLM-Generated Dialogue in Commercial Video Games (https://aclanthology.org/2023.findings-emnlp.151/)
- Anthology ID: 2023.findings-emnlp.151 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화 시스템에 사용되는 LLM으로 생성된 대화를 포함한 비디오 게임의 플레이어 경험을 평가하는 것은 여전히 큰 도전이다. 이 논문에서는 역할극 비디오 게임에서 자주 사용되는 task-oriented 대화를 제어하는 대화 관리 시스템에 대한 동적 평가 프레임워크를 제안한다.
    2. *Disco Elysium: The Final Cut*이라는 역할 극 게임에서 대화를 추출하여 이를 데이터셋으로 사용하고, GPT-4를 사용하여 게임 상태를 표현하는 코드로 기반된 대화를 생성한다.
    3. 플레이어들에게 선호도 판단 및 자유양식 피드백을 통해 LLM 생성 결과를 게임 디자이너의 글과 비교 평가하였고, 전반적으로 게임 디자이너의 글이 더 선호되었다고 밝혔다.

###### Generative Calibration for In-context Learning (https://aclanthology.org/2023.findings-emnlp.152/)
- Anthology ID: 2023.findings-emnlp.152 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델(Large Language Model, LLM)의 한 가지 흥미로운 특징인 in-context learning은 몇 가지 학습 예제만으로도 과연솔버를 속속들이 제작할 수 있게 해줍니다. 그러나 이는 다양한 프롬프트 설정에 민감하며 학습 예제의 선택이나 순서와 같은 설정에 따라 성능이 다릅니다.
    2. 저자들은 이 겂체의 모순이 LLM의 종속 변수 분포를 데이터 분포로 이동시키는 일종의 label shift 때문이라고 처음으로 이론적으로 및 경험적으로 밝혀냅니다. 이해를 통해 Monte-Carlo 샘플링을 통해 추정된 프롬프트 생성을 통해 라벨의 마진을 조정하여 예측 분포를 보정할 수 있게 됩니다.
    3. 저자들의 제안은 generative calibration이라는 방법으로, 12가지 텍스트 분류 작업과 774M에서 33B로 스케일이 조정된 12개의 LLM에서 철저한 실험을 수행하여 제안된 방법이 일반적으로 ICL 및 최첨단 보정 방법보다 약 27%까지 macro-F1에서 향상되었다고 보여줍니다. 또한, 제안된 방법은 다양한 프롬프트 설정에 대해서도 안정적입니다.

###### Chain of Thought with Explicit Evidence Reasoning for Few-shot Relation Extraction (https://aclanthology.org/2023.findings-emnlp.153/)
- Anthology ID: 2023.findings-emnlp.153 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 희소 학습 데이터로 관계 추출 문제를 해결하기 위해 CoT-ER (chain-of-thought with explicit evidence reasoning) 알고리즘을 제안한다. 
    2. CoT-ER은 대규모 언어 모델을 사용하여 task-specific하고 concept-level한 지식으로 증거를 생성하고 관계 추출에 명시적으로 사용한다. 
    3. 실험 결과, CoT-ER은 훈련 데이터 0%인 상황에서 Fully-Supervised (훈련 데이터 100%)로 비교했을 때 FewRel1.0과 FewRel2.0 데이터셋에서 경쟁력 있는 성능을 보여준다.

###### AdaTranS: Adapting with Boundary-based Shrinking for End-to-End Speech Translation (https://aclanthology.org/2023.findings-emnlp.154/)
- Anthology ID: 2023.findings-emnlp.154 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. End-to-end 음성 번역에서 데이터 부족 문제를 완화하기 위해 음성인식과 기계 번역 데이터에 대한 사전 훈련이 중요한 기술로 간주되고 있다. 그러나 음성과 텍스트 사이의 모달리티 갭으로 인해 사전 훈련 모델로부터 효율적으로 지식을 상속하는 것이 어렵다. 
    2. 이 논문에서는 end-to-end ST를 위한 AdaTranS를 제안한다. 이 모델은 단어 경계를 예측하여 음성과 텍스트 피처 간의 길이 불일치 문제를 완화하기 위해 새로운 shrinking 메커니즘을 사용하여 음성 피처를 적응시킨다. 
    3. MUST-C 데이터셋에서의 실험 결과, AdaTranS가 다른 shrinking 기반 방법보다 더 나은 성능, 더 빠른 추론 속도 및 더 낮은 메모리 사용량을 보였다. 추가적인 정렬 손실을 적용하면 성능을 더욱 개선할 수 있다는 실험 결과도 제시되었다.

###### No offence, Bert - I insult only humans! Multilingual sentence-level attack on toxicity detection networks (https://aclanthology.org/2023.findings-emnlp.155/)
- Anthology ID: 2023.findings-emnlp.155 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 연구에서는 black-box toxicity detector 모델에 대한 간단하면서도 효과적인 문장 수준 공격을 소개한다. 혐오 메시지 뒤에 몇 개의 긍정적인 단어나 문장을 추가하여 신경망의 예측을 변경하고 독성 감지 시스템의 체크를 통과할 수 있다.
    2. 이 접근 방식은 세 가지 다른 언어 군으로부터 일곱 개의 언어에서 작동함을 보여준다.
    3. 또한, 위에서 언급한 공격에 대한 방어 메커니즘을 설명하고 그 제한점에 대해 논의한다.

###### Manipulating the Perceived Personality Traits of Language Models (https://aclanthology.org/2023.findings-emnlp.156/)
- Anthology ID: 2023.findings-emnlp.156 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 연구에서는 대규모 언어 모델로부터 생성된 텍스트가 "Big Five"라는 성격 특성에 일관된지 여부를 조사한다. 예를 들어, GPT2와 같은 언어 모델은 파티에 가라고 하면 일관된 방식으로 응답할 것인가? 
    2. 우리는 또한 BERT와 GPT2와 같은 언어 모델이 다른 유형의 맥락(성격 설명이나 성격 특성에 대한 진단 질문에 대한 답변)에 노출되었을 때, 해당 맥락에서 성격 특징을 일관되게 인식하고 반영한다는 것을 보여준다.
    3. 이러한 행동은 일관적으로 특정 방식으로 조작될 수 있는 능력(의도한 성격 특성 변경과 실현된 변경 사이의 상관관계가 0.84까지 나타남)을 보여주며, 대화 시스템과 같은 응용 프로그램에서 페르소나(personas)를 제어하는 도구로 사용될 수 있다.

###### WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia (https://aclanthology.org/2023.findings-emnlp.157/)
- Anthology ID: 2023.findings-emnlp.157 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문은 반복 및 지연시간이 적은 대화능과 conversationality를 갖춘 거의 존스회할 일이 없는 최초의 few-shot LLM 기반 챗봇을 제시한다. 
    2. WikiChat은 영어 위키피디아에 기반을 둔데, LLM에서 응답을 생성하고, 기존에 있는 grounded facts만 보존하며, 긍정적이고 사실적인 응답을 형성하기 위해 전체 말뭉치에서 추가적인 정보를 검색한다. 
    3. LLM은 7B-parameter LLaMA 모델로 변환되며, 다양한 면에서 향상된 대화 시간, 비용, 개인정보 보호, 연구 및 배포가 가능하도록 한다.

###### Automated Few-Shot Classification with Instruction-Finetuned Language Models (https://aclanthology.org/2023.findings-emnlp.158/)
- Anthology ID: 2023.findings-emnlp.158 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최신 few-shot learning 접근법 중 하나인 로드맵(complement data samples)을 사용하는 언어 모델은 성공적이지만, 각 작업마다 로드맵을 수작업으로 설계하기 위해서는 도메인 지식과 상당한 추측이 필요하다.
    2. 이 논문에서는 AuT-Few라는 새로운 방법을 제안하여 수작업으로 만든 로드맵을 필요로하지 않게 한다. AuT-Few는 로드맵 검색 모듈과 교차 검증을 통한 두 가지 다른 의미를 가진 클래스 설명 생성 및 선택 메커니즘으로 구성되어 있다.
    3. 12개 데이터셋과 8개의 분류 작업에서 실험을 진행한 결과, AuT-Few가 현재 최첨단 few-shot learning 방법을 능가하는 성과를 보였고, 또한 RAFT few-shot benchmark에서 가장 우수한 순위를 달성하였다. 이러한 결과는 수작업으로 만든 로드맵을 사용하지 않은 새로운 작업에 대해서도 유효하다.

###### Meta-Learning of Prompt Generation for Lightweight Prompt Engineering on Language-Model-as-a-Service (https://aclanthology.org/2023.findings-emnlp.159/)
- Anthology ID: 2023.findings-emnlp.159 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 다양한 회사들이 Language-Model-as-a-Service (LMaaS)로 대형 언어 모델의 기능을 제공하고 있다. 하지만 자동 프롬프트 엔지니어링 기법이 고비용 연산이 필요한 이유때문에 이러한 기능을 제공하지 않는다.
    2. 이 논문에서는 LMaaS를 위한 경량 자동 프롬프트 생성 방법인 MetaL-Prompt을 제안한다. 이는 메타-러닝 접근 방식을 사용하여 특정 작업에 대한 추가적인 훈련 없이 언어 모델이 보다 강력한 학습을 할 수 있도록 한다. 또한, 기존 방법에 비해 계산 비용을 크게 절감시킨다.
    3. MetaL-Prompt을 QA 데이터셋에 대해 평가한 결과, 최첨단 기법인 P-tuning과 비교하여 평균 F1 점수 기준으로 최대 19.4%의 성능 향상을 보였으며, 계산 비용도 크게 줄일 수 있다.

###### Beneath Surface Similarity: Large Language Models Make Reasonable Scientific Analogies after Structure Abduction (https://aclanthology.org/2023.findings-emnlp.160/)
- Anthology ID: 2023.findings-emnlp.160 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사전 연구들은 단어 유추에 주목했지만, 본 연구는 대형 언어 모델이 이 유추의 기반인 구조를 간과하는 경향이 있다고 제안하며, 인간의 유추적 사고와 유사한 능력을 측정하는 대비 유추 (analogy structure abduction) 작업을 소개한다.
    2. SCAR라는 벤치마크를 통해 대비 유추를 평가하는데 사용되는 13개의 다양한 분야에서 400개의 과학적 대비를 포함시키고, 이 작업을 지원한다.
    3. ChatGPT와 GPT-4와 같은 대형 언어 모델들이 이 작업에서 여전히 도전을 겪고 있으며, 그 능력을 향상시키기 위한 미래 탐구의 필요성을 강조한다.

###### HiCL: Hierarchical Contrastive Learning of Unsupervised Sentence Embeddings (https://aclanthology.org/2023.findings-emnlp.161/)
- Anthology ID: 2023.findings-emnlp.161 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문에서는 지역 세그먼트-level과 전체 sequence-level 관계를 고려한 계층적 대조 학습 프레임워크인 HiCL을 제안한다. 기존의 방법들은 전체 시퀀스를 대조하기 위해 전체를 인코딩하므로 지역 표현 학습을 소홀히하고 짧은 텍스트에 대한 일반화에 어려움이 있었다. 
    2. HiCL은 시퀀스를 여러 세그먼트로 나누고 지역 및 전역 대조 학습을 활용하여 세그먼트 수준과 시퀀스 수준의 관계를 모델링하여 효과를 향상시킨다. 
    3. 또한, HiCL은 transformers의 입력 토큰에 대한 이차 시간 복잡도를 고려하여 먼저 짧은 세그먼트를 인코딩하고 이를 집계하여 시퀀스 표현을 얻는 방식으로 훈련 효율성을 향상시킨다. 실험 결과, HiCL은 STS 태스크에서 이전에 최고 성능을 보인 SNCSE 모델을 향상시키며, BERTlarge에서 평균적으로 +0.2%의 상승과 RoBERTalarge에서 +0.44%의 상승을 관찰하였다.

###### Density-Aware Prototypical Network for Few-Shot Relation Classification (https://aclanthology.org/2023.findings-emnlp.162/)
- Anthology ID: 2023.findings-emnlp.162 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근들어, few-shot relation classification은 많은 연구 관심을 불러일으켰지만, 훨씬 어려운 NOTA(none-of-the-above) 문제에 대해서는 더욱 탐구가 필요하다.
    2. 기존 연구들은 NOTA를 추가 클래스로 취급하고 이미 알려진 관계와 동일하게 처리하였으나, 이 방법은 NOTA 인스턴스들이 알려진 인스턴스와는 달리 이상치로 분포되어 있음을 고려하지 않는다.
    3. 이 논문에서는 unique training objectives를 설계하여 알려진 인스턴스와 NOTA 인스턴스를 분리하고 이상치로 취급함으로써 이상적인 인스턴스 분포를 달성하는 density-aware prototypical network (D-Proto)를 제안한다.

###### Improved Training of Deep Text Clustering (https://aclanthology.org/2023.findings-emnlp.163/)
- Anthology ID: 2023.findings-emnlp.163 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 전통적인 깊은 클러스터링 최적화 방법은 클러스터링 센터, 상호 정보, 거리 메트릭과 같은 정보를 활용하여 암묵적인 일반화 레이블을 구성하여 딥 모델을 최적화한다. 그러나, 클러스터링 정확성의 한계로 인해 생성된 일반화 레이블은 클러스터링 과정에서 다양한 정도의 오류를 가지며, 클러스터링 과정에 큰 간섭을 일으킨다.
    2. 이 논문에서는 샘플 간의 상관관계를 사용하여 경험적 위험 최소화의 관점에서 일반적인 딥 클러스터링 최적화 방법을 제안한다.
    3. 두 가지 전통적인 딥 클러스터링 방법에 대한 실험은 이 방법의 필요성과 효과를 입증한다.

###### RegaVAE: A Retrieval-Augmented Gaussian Mixture Variational Auto-Encoder for Language Modeling (https://aclanthology.org/2023.findings-emnlp.164/)
- Anthology ID: 2023.findings-emnlp.164 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 업데이트되지 않은 정보와 환각(hallucination)과 같은 언어 모델의 문제를 해결하기 위해, retrieval-augmented 언어 모델이 유망한 성과를 보이지만, 현재의 연구에서는 두 가지 주요 문제점이 있다.
    2. 우리는 유용한 검색된 정보는 현재의 소스 텍스트뿐만 아니라 미래의 타겟 텍스트까지 고려해야 한다고 주장합니다. 또한, 우리는 문맥 길이에 제한을 받고 노이즈에 영향을 받기 쉬운 명시적인 원시 텍스트 대신, 압축된 잠재 공간에서 유도된 잠재 변수를 사용하는 방법이 더 효율적이라고 제안합니다.
    3. RegaVAE는 VAE(변이형 오토 인코더)를 기반으로 구성된 retrieval-augmented 언어 모델로, 텍스트 말뭉치를 잠재 공간에 인코딩하며, 소스 텍스트와 타겟 텍스트에서 현재와 미래의 정보를 포착합니다. 또한, 우리는 VAE를 사용하여 잠재 공간을 초기화하고, 가우시안 사전 분포를 가우시안 혼합 분포로 확장하여 확률적인 검색 생성 패러다임을 채택합니다. 이론적 분석은 RegaVAE의 최적화 가능한 상한을 제공하며, 다양한 데이터셋에서의 실험 결과는 텍스트 생성 품질과 환각 제거에서 상당한 개선을 보여줍니다.

###### RefGPT: Dialogue Generation of GPT, by GPT, and for GPT (https://aclanthology.org/2023.findings-emnlp.165/)
- Anthology ID: 2023.findings-emnlp.165 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델 (LLM)은 높은 품질의 지시 데이터를 세밀 조정하여 다양한 NLP 작업을 수행할 수 있는 능력을 갖추었다. 그러나 고품질의 인간이 작성한 대화 데이터, 특히 다중 턴 대화의 수집은 대부분의 사람들에게는 비용이 많이 들고 어렵다. 
    2. 이 논문에서는 모델 환시 (model hallucination)로 인한 사실적 오류를 걱정하지 않고 거대하고 진실하고 맞춤형 대화를 생성하기 위한 RefGPT라는 방법을 제안한다. 
    3. RefGPT는 LLM을 이용한 대화 생성에서 모델 환시 문제를 해결하기 위해 모델이 자체 지식이 아닌 주어진 참고 자료를 활용하도록 제한하고, 이전 연구에서 무시된 각 발언에 대한 상세한 제어기능을 추가한다.

###### INA: An Integrative Approach for Enhancing Negotiation Strategies with Reward-Based Dialogue Agent (https://aclanthology.org/2023.findings-emnlp.166/)
- Anthology ID: 2023.findings-emnlp.166 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문에서는 온라인 마켓플레이스를 위해 디자인된 새로운 협상 에이전트를 제안한다. 
    2. 이 에이전트는 가격뿐만 아니라 거래 번들에서 아이템의 추가나 제거와 같은 다른 요소들에 대해서도 협상할 수 있는 능력을 가지고 있다. 
    3. 제안된 방법은 협상 능력을 크게 향상시키며, 인수 또는 배제 등 거래 번들을 동적으로 조정할 수 있는 능력을 보여준다.

###### Large Language Models are Better Reasoners with Self-Verification (https://aclanthology.org/2023.findings-emnlp.167/)
- Anthology ID: 2023.findings-emnlp.167 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근에는 문장 사슬 (CoT) 프롬프팅을 통해 GPT-3와 같은 대규모 언어 모델이 산술, 상식, 논리 추론과 같은 여러 NLP 태스크에서 강력한 추론 능력을 보여주고 있다.
    2. 그러나, CoT를 사용한 언어 모델은 다단계 프롬프팅과 다중 토큰 예측이 필요하여 개인 실수에 민감하고 오류가 누적될 수 있다.
    3. 따라서 이 논문에서는 셀프-검증(self-verification) 기술을 제안하여 언어 모델이 스스로 답을 검증하고 가장 높은 점수의 후보 답을 선택할 수 있도록 한다. 실험 결과는 이 방법이 산술, 상식, 논리 추론 데이터셋에서 추론 성능을 향상시킬 수 있다는 것을 보여준다.

###### Multi-Granularity Information Interaction Framework for Incomplete Utterance Rewriting (https://aclanthology.org/2023.findings-emnlp.168/)
- Anthology ID: 2023.findings-emnlp.168 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 Incomplete Utterance Rewriting (IUR) 접근법은 불완전한 발화를 수정하는데 필요한 단어들의 출처를 파악하지 못하고, 관련 없는 발화에서 단어들을 도입한다.
    2. 우리는 multi-granularity의 의미 정보를 포착하기 위해 context selection, edit matrix construction, relevance merging을 포함한 새로운 효과적인 multi-task 정보 상호작용 프레임워크를 제안한다.
    3. 우리의 접근법은 관련 있는 발화를 가져오고 중요한 단어를 파악하는 이점을 갖고 있어 기존의 최첨단 모델들을 이 분야에서 능가한다.

###### Accuracy is not enough: Evaluating Personalization in Summarizers (https://aclanthology.org/2023.findings-emnlp.169/)
- Anthology ID: 2023.findings-emnlp.169 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 텍스트 요약 모델은 ROUGE, BLEU, METEOR, BERTScore, PYRAMID, readability 등 다양한 지표를 사용해 정확도와 품질을 평가한다. 그러나 독자의 취향에 따라 요약의 중요성은 주관적이므로 주어진 문서에 대한 "적합한" 요약은 존재하지 않을 수 있다.
    2. 따라서 많은 경우 요약 모델이 사용자 프로필에 맞게 개인화되어야 하는데, 현재로서는 요약 모델의 개인화 정도를 평가하는 방법이 없다.
    3. 이 논문에서는 기존의 정확도 측정 방법이 어떤 요약 모델의 개인화 정도를 평가할 수 없음을 증명하고, 개인화 정도를 자동으로 측정하기 위한 새로운 측정 지표인 EGISES를 제안한다. 이를 Microsoft Research에서 공개한 PENS 데이터셋을 사용해 실험하고, 개인화를 명시적으로 학습한 모델과 개인화를 구현한 모델을 포함한 총 10개의 최신 요약 모델의 개인화 정도를 분석한다. 마지막으로 개인화를 고려하는 새로운 정확도 측정 방법인 P-Accuracy를 제안하고, 메타평가를 통해 이 측정 방법의 강건성과 신뢰성을 검증한다.

###### For Generated Text, Is NLI-Neutral Text the Best Text? (https://aclanthology.org/2023.findings-emnlp.170/)
- Anthology ID: 2023.findings-emnlp.170 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자연어 추론(NLI)을 텍스트 생성 파이프라인에 통합하는 방법을 탐구한다. 그들은 사전 훈련된 NLI 모델을 사용하여 생성된 문장이 prompt와 이전 텍스트와 동등하거나 모순되거나 중립인지를 판단하는 데 사용한다.
    2. 이 논문은 GPT-3가 만드는 오류들의 예측에 NLI 작업이 도움이 된다는 것을 보여준다. 이 결과를 사용하여 GPT-J에 대한 NLI 기반 생성 절차를 개발한다.
    3. 실험 결과, Laugaveglur (nucleus sampling randomness parameter) 값이 높을 때는 NLI를 entailment (동등성)을 최대화하는 전략을 사용하는 것이 텍스트 생성을 개선시키는 반면, 낮을 때는 contradiction (모순성)을 최대화하는 전략이 효과적이라는 것을 보여준다. 하지만, 매개변수 값에 관계없이 neutral (중립) 클래스를 최대화하는 NLI 전략이 가장 높은 품질의 생성된 텍스트를 제공한다. (vanilla generations 보다 유의미하게 우수)

###### Combining Counting Processes and Classification Improves a Stopping Rule for Technology Assisted Review (https://aclanthology.org/2023.findings-emnlp.171/)
- Anthology ID: 2023.findings-emnlp.171 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 Technology Assisted Review (TAR) stopping rule은 수작업으로 문서의 관련성을 평가하는 비용을 줄이기 위해 검토해야 할 문서의 수를 최소화하기 위해 개발되었다. 
    2. 이 연구에서는 추가적인 주석 없이 훈련할 수 있는 텍스트 분류기로부터 유도된 정보를 사용하여 효과적인 stopping rule을 확장하였다. 
    3. 다양한 데이터셋 (CLEF e-Health, TREC Total Recall, TREC Legal and RCV1)에서 시행한 실험 결과, 제안된 접근 방식이 성능을 일관되게 향상시키고 다른 대안적인 방법보다 우수한 결과를 보여주었다.

###### Complexity-Guided Curriculum Learning for Text Graphs (https://aclanthology.org/2023.findings-emnlp.172/)
- Anthology ID: 2023.findings-emnlp.172 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 커리큘럼 학습은 훈련 과정을 점진적으로 세분화하여 다양한 예시에 노출함으로써 일반화 능력을 향상시키는 체계적인 학습 방법을 제공한다. 본 논문에서는 텍스트 그래프 데이터와 함께 학습하기 위해 텍스트 및 그래프 복잡성 형식에 대한 기존 지식을 기반으로 하는 커리큘럼 학습 방법을 소개한다.
    2. 제안된 모델은 더 많은 데이터를 이용하고, 더 적은 데이터를 사용한다. 훈련 과정에서 일관적으로 텍스트를 그래프 복잡성 지수보다 선호하며, 텍스트와 그래프 복잡성 지수에서 나온 최적의 커리큘럼은 동일한 효과를 가져온다. 이 모델은 GNN 모델과 데이터셋에 걸쳐 전송 가능한 커리큘럼을 학습한다.
    3. 또한, 노드 수준(지역)과 그래프 수준(전역) 복잡성 지수뿐만 아니라 얕은 및 전통적인 텍스트 복잡성 지수가 효과적인 커리큘럼 학습에 중요한 역할을 한다는 것을 발견하였다.

###### CoVariance-based Causal Debiasing for Entity and Relation Extraction (https://aclanthology.org/2023.findings-emnlp.173/)
- Anthology ID: 2023.findings-emnlp.173 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. entity 및 relation 추출 과제는 명명된 entity를 인식하고 동시에 relation을 추출하는 것을 목표로 한다. 그러나 데이터 선택 편향 및 분포 편향과 같은 다양한 데이터 편향의 문제로 전이성, 견고성 및 일반화에 대한 모델의 위험이 증가하고 있다.
    2. 우리는 인과 관점에서 위의 문제들을 해결하는 것을 목표로 한다. 우리는 feature representations를 최적화하고 일반적인 debiasing을 수행하기 위해  ̲covariance and  ̲variance  ̲optimization (OVO)이라는 새로운 인과적 프레임워크를 제안한다.
    3. OVO를 entity 및 relation 추출 작업에 적용한 결과, 두 개의 널리 사용되는 데이터셋에서 세 가지 강력한 기준에 효과적이며 일반화할 수 있음을 보여준다. 또한 미세한 분석 결과, OVO가 long-tail 분포의 영향을 완화하는 능력을 갖고 있다는 것을 보여준다.

###### Multi-label and Multi-target Sampling of Machine Annotation for Computational Stance Detection (https://aclanthology.org/2023.findings-emnlp.174/)
- Anthology ID: 2023.findings-emnlp.174 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 수동 레이블링을 통한 데이터 수집은 데이터 기반 방법의 도메인 특화된 지도를 제공하며, 합리적인 성능을 얻기 위해서는 잘 주석이 된 자원들의 상당량이 필요하다.
    2. 이 논문에서는 대용량 언어 모델을 활용하여 자동 주석 작업에 대한 유효성을 조사하였다. 
    3. 우리의 방법을 채택한 실험 결과들은 성능과 학습 효과를 크게 향상시킬 수 있음을 보여주었다.

###### In What Languages are Generative Language Models the Most Formal? Analyzing Formality Distribution across Languages (https://aclanthology.org/2023.findings-emnlp.175/)
- Anthology ID: 2023.findings-emnlp.175 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다국어 생성 언어 모델 (LM)은 여러 언어에서 많은 숙련도를 보여주고 있다. 그러나 이러한 모델의 예측에는 어떤 문화적 편향이 생기는지는 여전히 알려지지 않았다.
    2. 이 논문에서는 문화적인 영향을 받는 언어 속성 중 하나인 "정형성(formality)"을 분석한다.
    3. 다양한 모델과 언어들 간에 다양한 행동을 관찰하며, 생성된 텍스트의 정형성에 대한 다국어 LMs의 영향을 측정한다.

###### MaXM: Towards Multilingual Visual Question Answering (https://aclanthology.org/2023.findings-emnlp.176/)
- Anthology ID: 2023.findings-emnlp.176 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 Visual Question Answering (VQA)은 영어로 주로 연구되었으며, 다른 언어로의 mVQA에는 많은 자원이 필요하다. 본 논문에서는 데이터 및 모델링 측면에서 mVQA의 scalable 한 솔루션을 제안한다.
    2. 기존 방식인 질문-답변 수집에 필요한 인력을 줄이기 위해 번역 기반의 프레임워크를 mVQA 데이터 생성에 제안하였다.
    3. Crossmodal-3600 데이터셋의 다국어 캡션을 활용하여 효율적인 주석 프로토콜을 개발하고, MaXM이라는 7개 언어의 VQA 벤치마크를 생성하였다.

###### Efficient Latent Variable Modeling for Knowledge-Grounded Dialogue Generation (https://aclanthology.org/2023.findings-emnlp.177/)
- Anthology ID: 2023.findings-emnlp.177 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "지식 기반 대화 생성은 대화적 맥락을 기반으로 적절한 외부 지식을 검색하고 이를 기반으로 대답을 생성하는 것을 요구한다. 기존의 방법은 지식 검색 모듈과 응답 생성 모듈을 따로 훈련시켜왔으나, 특히 개방형 대화에서는 중간 라벨을 얻는 것이 비용이 많이 든다. 이 논문에서는 중간 변수 모델링을 통해 이러한 라벨 필요성을 줄이는 효율적인 알고리즘을 제안한다."
    2. "우리의 알고리즘은 복잡한 검색 모델을 직접 학습시키는 대신, 일반적인 모델을 사용하여 질의 생성 모델을 적용하며, 질의 생성 모델과 응답 생성 모델을 동시에 학습한다. 또한, 적절한 훈련 목적 함수와 수정된 증거의 하한을 사용하여 학습을 안정적으로 수행한다."
    3. "다양한 지식 기반 대화 데이터셋에서의 실험 결과, 우리의 방법은 주석된 지식을 사용하지 않고도 지식 기반 대화 작업에서 지도 학습 알고리즘보다 훨씬 성능이 우수하며 효율적이고 확장 가능함을 보였다."

###### Ask To The Point: Open-Domain Entity-Centric Question Generation (https://aclanthology.org/2023.findings-emnlp.178/)
- Anthology ID: 2023.findings-emnlp.178 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "엔티티 중심의 질문 생성" (ECQG) 이라는 새로운 작업을 소개한다. 이 작업은 주제별 학습, 도움을 받은독서, 사실 검증과 같은 실제 응용 프로그램에서 동기를 얻었다. 이 작업은 엔티티의 관점에서 질문을 생성하는 것을 목표로 한다. 
    2. 이 작업을 해결하기 위해 요약된 PLM 기반 프레임워크 GenCONE을 제시하며, 이 프레임워크는 두 개의 새로운 모듈인 콘텐츠 초점화 기능과 질문 검증을 제공한다. 
    3. 우리는 또한 SQuAD에서 대규모의 오픈 도메인 데이터셋을 구축하여 이 작업을 지원한다. 우리의 um이우는 GenCONE이 다양한 기준선보다 유의미하고 일관되게 우수한 결과를 보여주며, 두 모듈은 높은 품질의 질문을 생성하는 데 효과적이고 보완적임을 보여준다.

###### Self-prompted Chain-of-Thought on Large Language Models for Open-domain Multi-hop Reasoning (https://aclanthology.org/2023.findings-emnlp.179/)
- Anthology ID: 2023.findings-emnlp.179 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 개방 도메인 질의응답 (ODQA)에서는 대부분의 질문이 상식에 따른 단일 점프 추론(single-hop reasoning)을 필요로 한다. 이 논문에서는 더 확장된 개방 도메인 다중 점프 추론 (ODMR)을 소개하고, 개방 도메인에서 명시적인 추론 과정을 거친 다중 점프 질문에 대한 답을 찾는 과제를 제시한다.
    2. 이 논문에서는 Self-prompted Chain-of-Thought (SP-CoT)라는 자동화된 프레임워크를 제안하는데, 이는 LLMs (large language models)의 고성능 CoT 생성을 위해 사용되는 LLMs에 의해 만들어진다. SP-CoT은 고품질 ODMR 데이터셋의 자동 생성 파이프라인, 문맥 내 CoT 선택을 위한 적응형 샘플러, 그리고 문맥 학습을 통한 자기 프롬프팅 추론을 도입한다.
    3. 실험 결과, SP-CoT는 4개의 다중 점프 질의응답 벤치마크에서 SOTA 방법들을 대폭 초월하며, 큰 규모의 LLMs에서는 거의 2배의 zero-shot 성능 향상을 보인다. 추가적인 분석에서는 SP-CoT이 MuSiQue-Ans 데이터셋에서는 중간 답변의 약 50%를 회상하여 직접적이고 간결한 중간 추론 단계를 도출하는 뛰어난 능력을 보인다.

###### CASE: Commonsense-Augmented Score with an Expanded Answer Space (https://aclanthology.org/2023.findings-emnlp.180/)
- Anthology ID: 2023.findings-emnlp.180 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. LLM은 학습 과정에서 얻은 지식 덕분에 NLP 태스크에서 인상적인 zero-shot 성능을 보여주었다. 하지만 multiple-choice QA 태스크에서 사용되는 LM 확률은 각 선택지의 타당성을 나타내는 불완전한 지표로 사용되는데, 이 기본 점수의 주요한 한계는 모든 단어를 동등하게 다룬다는 것이다.
    2. 이 논문에서는 단어의 중요도 가중치를 부여하여 개별 단어가 입력 내의 다른 단어와의 의미적 관계에 기반하여 중요도를 결정하는 CASE라는 설명 추가 점수를 제안한다.
    3. 또한 선택지와 개념적으로 유사한 다양한 응답을 생성함으로써 응답 공간을 확장하고, 이를 기존 방법과 결합하면 5가지 공통 감각 기준에서 강력한 기준 모델을 능가하는 결과를 얻을 수 있음을 실험을 통해 보여주었다.

###### GRENADE: Graph-Centric Language Model for Self-Supervised Representation Learning on Text-Attributed Graphs (https://aclanthology.org/2023.findings-emnlp.181/)
- Anthology ID: 2023.findings-emnlp.181 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근에는 downstream tasks를 위해 표현 학습을 위한 self-supervised 방법이 많은 연구 주목을 받고 있습니다. 그러나, 기존 방법들은 구조적 컨텍스트 정보의 완전한 범위를 포착하기 어렵거나 과제별 훈련 레이블에 의존하는 등 실제 상황에서의 효과성과 일반성을 크게 저해합니다. 
    2. 우리는 텍스트 속성 그래프에서의 self-supervised 표현 학습 문제를 해결하기 위해 새로운 GRENADE (Graph-Centric Language model)를 개발했습니다. 
    3. GRENADE는 사전 훈련된 언어 모델과 그래프 신경망의 시너지를 활용하여 그래프 중심의 비교 및 지식 조정을 통해 정보성 텍스트 의미론과 구조적 컨텍스트 정보를 효과적으로 포착합니다. 실험 결과, GRENADE는 최첨단 방법들에 비해 우수성을 보여주었습니다.

###### Sources of Hallucination by Large Language Models on Inference Tasks (https://aclanthology.org/2023.findings-emnlp.182/)
- Anthology ID: 2023.findings-emnlp.182 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델 (LLM)은 질문 답변 및 요약과 같은 응용 작업에 필요한 자연어 추론 (NLI)의 능력을 가질 수 있는 것으로 주장되며, 우리는 이들을 향한 통제된 실험을 통해 그들의 행동을 조사한 설명과 함께 시범을 제시한다.
    2. 우리는 사전 훈련에서 비롯된 두 가지 편향성을 확립하고, 이것들이 생성형 LLMs의 환각의 주요 원인임을 보여준다. 첫째, 문장 수준에서의 암기: 우리는 모델이 훈련 데이터에서 가설 이행을 표시할 때, 무관하게 전제가 무엇이든 잘못된 NLI 테스트 샘플을 잘못된 것으로 분류함을 보여준다. 둘째, 말뭉치 수준에서 학습된 통계적 패턴: 훈련 데이터에서 전제 술어가 가설 술어보다 덜 빈번한 경우에도 유사한 효과가 나타나며, 이는 이전 연구에서 유추되는 편향이다.
    3. 우리는 이러한 편향에 부합하지 않는 NLI 테스트 샘플에서 LLMs의 성능이 부적합한 것으로 안 내고, 이들을 미래 LLM 평가에 유용한 검증 자료로 제시한다.

###### Efficient Long-Range Transformers: You Need to Attend More, but Not Necessarily at Every Layer (https://aclanthology.org/2023.findings-emnlp.183/)
- Anthology ID: 2023.findings-emnlp.183 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사전 학습된 transformer 모델들은 다양한 자연어 처리 태스크에서 놀라운 성능을 보여주고 있으나, full attention 메커니즘은 계산 비용이 높기 때문에 긴 시퀀스를 다루는 작업에는 적합하지 않다.
    2. 본 논문에서는 MASFormer라는 transformer variant를 제안하여 full attention을 몇 개의 레이어에서만 사용하고 나머지 레이어에서는 sparse attention을 사용하여 계산 비용을 줄이면서도 복잡한 dependency를 캡처할 수 있다.
    3. 실험 결과, 1.3B parameter로 이루어진 MASFormer 모델은 full attention을 사용하는 vanilla transformer와 비교하여 연산 비용을 현저히 줄이면서 경쟁력 있는 성능을 보이고, 긴 시퀀스 데이터를 이용한 계속적인 training의 효과와 시퀀스 길이가 downstream generation 성능에 어떤 영향을 미치는지도 조사하였다.

###### Prompting ChatGPT in MNER: Enhanced Multimodal Named Entity Recognition with Auxiliary Refined Knowledge (https://aclanthology.org/2023.findings-emnlp.184/)
- Anthology ID: 2023.findings-emnlp.184 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 소셜 미디어에서의 다중모달 Named Entity Recognition (MNER)은 이미지 기반 단서를 포함하여 텍스트 엔티티 예측을 향상하는 것을 목표로 한다. 기존 연구들은 적절한 이미지 정보의 활용을 극대화하거나 명시적인 지식 베이스에서 외부 지식을 통합하는 데 주로 초점을 맞추고 있다. 
    2. 그러나 이러한 방법들은 모델에 외부 지식 제공의 필요성을 간과하거나 검색된 지식에서 과도한 중복 문제에 부딪힌다. 
    3. 본 논문에서는 ChatGPT를 암묵적인 지식 베이스로 활용하고, 보조적인 효율적인 엔티티 예측을 위해 직관적으로 보조 지식을 생성할 수 있도록 하는 PGIM - 2단계 프레임워크를 제시한다.

###### Understanding HTML with Large Language Models (https://aclanthology.org/2023.findings-emnlp.185/)
- Anthology ID: 2023.findings-emnlp.185 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델(Large language models, LLMs)은 다양한 자연어 처리 작업에서 뛰어난 성능을 보여주었지만, HTML 이해 능력인 웹페이지의 원시 HTML 구문 분석, 웹 기반 작업 자동화, 크롤링 및 브라우저 지원 검색과 같은 응용 분야는 아직 완전히 탐구되지 않았다.
    2. 본 논문은 HTML 이해를 위한 모델과 세 가지 작업에 대한 심층 분석을 제시한다: (i) HTML 요소의 의미론적 분류, (ii) HTML 입력에 대한 설명 생성 및 (iii) HTML 페이지의 자동 웹 탐색.
    3. 기존 연구들은 HTML 이해를 위해 전용 아키텍처와 학습 절차를 개발해왔지만, 우리는 표준 자연어 말뭉치로 사전 학습된 LLMs가 HTML 이해 작업에 대하여 놀라울 정도로 전이 학습이 잘 되는 것을 보여준다.

###### The PEACE-Reviews dataset: Modeling Cognitive Appraisals in Emotion Text Analysis (https://aclanthology.org/2023.findings-emnlp.186/)
- Anthology ID: 2023.findings-emnlp.186 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 인식 평가는 감정을 해석하는데 중요한 역할을 한다. 이 연구는 다양한 형태의 인식 평가와 기쁨, 분노와 같은 특정 감정과의 상호작용을 고객 상황에서 알아보는 영역이다.
    2. PEACE-Reviews 데이터셋은 고객의 개인적인 제품이나 서비스와의 상호작용 중 인식 경험과 감정을 다룬 주관적인 기록들의 독특한 컴필레이션으로, 구매에 대한 평가와 결과적인 감정에 대한 참가자들의 심리적 특성과 평가적 피드백을 깊이 분석한다.
    3. PEACE-Reviews 데이터셋은 감정, 인식, 개인 특성 및 인구 통계 데이터를 포함하며, 자서전적 이야기를 기반으로 특정 기능을 예측하는 초기 모델을 소개한다.

###### UReader: Universal OCR-free Visually-situated Language Understanding with Multimodal Large Language Model (https://aclanthology.org/2023.findings-emnlp.187/)
- Anthology ID: 2023.findings-emnlp.187 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 문서, 웹사이트, 사진 등에서 중요한 정보를 전달하는 텍스트는 우리의 시각적 세계에서 널리 사용된다. 본 논문에서는 Multimodal Large Language Model (MLMM)을 기반으로 한 OCR-free 시각적 언어 이해 모델인 UReader를 제안한다. 
    2. MLLM의 얕은 텍스트 인식 능력을 활용하여 이전의 작업들에 비해 파라미터의 1.2%만을 finetuning하며 훈련 비용이 훨씬 낮다. 
    3. 업데이트되지 않은 단일 모델로 10가지 시각적 언어 이해 작업 중 8가지에서 최첨단 성능을 달성하였다.

###### Loose lips sink ships: Mitigating Length Bias in Reinforcement Learning from Human Feedback (https://aclanthology.org/2023.findings-emnlp.188/)
- Anthology ID: 2023.findings-emnlp.188 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "사람의 피드백으로부터의 강화 학습은 대규모 언어 모델을 인간과 사회적 가치와 조화롭게 만들기 위한 중요한 다리 역할을 한다." 
    2. "그러나 우리는 보상 모델이 종종 그 의도된 목적을 우회하기 위한 단축키를 찾는다는 것을 발견했다. 이로 인해 모델이 더 긴 출력을 선호하는 경향이 생기는데, 이는 이러한 출력 내에서 유용한 정보의 증가를 의미하지 않는다."
    3. "이 논문에서는 sequence length의 영향으로부터 보상 모델링을 분리하기 위해 Product-of-Experts (PoE) 기법을 적용하는 혁신적인 해결책을 제안한다. 실험 결과는 우리의 접근 방식의 효과를 검증하며, sequence length와 관계없이 언어 모델의 성능이 향상되는 것을 보여준다."

###### Filling the Image Information Gap for VQA: Prompting Large Language Models to Proactively Ask Questions (https://aclanthology.org/2023.findings-emnlp.189/)
- Anthology ID: 2023.findings-emnlp.189 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델은 자연어 태스크와 함께 open-domain knowledge-based 시각 질의 응답(OK-VQA)과 같은 몇 개의 시각-언어 태스크에서도 인상적인 추론 능력과 세계 지식을 유지한다. 
    2. 그러나 이미지는 LLM에게 표시되지 않으므로 연구자들은 이미지를 텍스트로 변환하여 LLM을 시각적 질문 추론 과정에 참여시킨다.
    3. 이 논문에서는 LLM이 더 많은 세부사항을 드러내기 위해 관련 질문을 주도적으로 제기하고 생성된 정보를 정제하는 필터를 포함한 프레임워크를 설계한다.

###### Take a Closer Look at Multilinguality! Improve Multilingual Pre-Training Using Monolingual Corpora Only (https://aclanthology.org/2023.findings-emnlp.190/)
- Anthology ID: 2023.findings-emnlp.190 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 연구에서는 병렬 코퍼스를 사용하지 않고 사전 훈련된 다국어 사전 훈련 언어 모델(mPLMs)의 현저한 언어간 능력이 밝혀졌지만, 공간 임베딩의 유사성이 그런 능력의 이유일 것으로 추측되었지만, 이는 미개척된 분야이다.
    2. 이 논문에서는 단어 기준의 정렬 특성을 조사하고, 공간 임베딩의 유사성과 일치함을 발견했다. 그러나, cross-lingual 상호작용이 부족하므로 mono-mPLMs는 높은 레이어에서 공간 임베딩의 유사성을 파괴할 가능성이 높아지며, cross-lingual 전이 능력이 제한된다.
    3. 이 문제를 해결하기 위해 병렬 문장에 의존하지 않고 mono-mPLMs의 레이어 간 cross-lingual 상호작용을 명시적으로 향상시키기 위해 토큰 수준과 의미 수준의 코드 스위치 마스크 언어 모델링을 도입한다. 이 방법을 다양한 자연어 이해 작업과 비지도 기계 번역 작업에서 평가했고, 결과는 강력한 기준 모델을 능가하며, 병렬 코퍼스로 훈련된 mPLMs와 비슷한 성능을 달성하였다.

###### LogiCoT: Logical Chain-of-Thought Instruction Tuning (https://aclanthology.org/2023.findings-emnlp.191/)
- Anthology ID: 2023.findings-emnlp.191 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Generative Pre-trained Transformer 4 (GPT-4)는 뛰어난 연속적인 추론 능력을 가지고 있다. 그러나 이전의 self-instruction tuning 기술들은 일반적인 작업에 탁월한 성능을 보였지만, 복잡한 추론 작업에 한계가 있다. 이 논문에서는 GPT-4와 함께 논리적 연속적인 추론을 가르치기 위한 LogiCoT라는 새로운 instruction-tuning 데이터셋을 소개한다."
    2. "LogiCoT는 GPT-4 모델에게 논리적인 추론을 유도하기 위한 instruction 집합이다. 이 데이터셋은 모델에게 일반적인 추론 능력을 가르치고자 하는 목적으로 수집되었으며, 복잡한 추론 작업을 처리하는 데 도움을 준다."
    3. "논문에서는 GPT-4가 연속적인 추론을 생성하기 위한 instruction을 수집하는 과정을 상세히 설명하고 있다."

###### Hiding in Plain Sight: Tweets with Hate Speech Masked by Homoglyphs (https://aclanthology.org/2023.findings-emnlp.192/)
- Anthology ID: 2023.findings-emnlp.192 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 혐오 발언에 대한 모니터링 애플리케이션을 우회하기 위해, 혐오 발언의 생산자들은 종종 문제와 비슷한 유니코드 문자인 'homoglyph'로 비속어의 한 개 이상의 글자를 대체한다. 
    2. 본 연구에서는 homoglyph가 포함된 실제 혐오 발언을 수집하는 것이 어렵기 때문에, 문자 대체 스크래핑 방법을 개발하여 Offensive Tweets with Homoglyphs (OTH) 데이터셋 (N = 90,788)을 구축하였다.
    3. 다양한 transformer 기반 혐오 발언 탐지 모델의 성능을 평가해본 결과, zero-shot 환경에서의 성능이 낮았지만 데이터 정규화를 통해 탐지 성능을 크게 향상시킬 수 있다는 것을 보여준다. 부가적으로 주석이 달린 데이터로 모델을 훈련시키면 성능이 더욱 향상되며, homoglyph를 알고 있거나 스크래핑 스크립트에서 모르는 homoglyph를 포함하는 데이터셋을 수집하고, 신경망 모델을 훈련하여 난장이된 실제 혐오 발언을 인식하는 데 사용될 수 있다.

###### Reducing Spurious Correlations in Aspect-based Sentiment Analysis with Explanation from Large Language Models (https://aclanthology.org/2023.findings-emnlp.193/)
- Anthology ID: 2023.findings-emnlp.193 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근에는 Aspect-Based Sentiment Analysis (ABSA) 모델이 매우 유망한 결과를 보여주고 있다. 그러나 이 모델은 특정 단어와 출력 레이블 사이의 표면적인 상관관계를 학습하므로, 이 컨텍스트에서는 spurious correlation (가짜 상관관계) 문제가 발생할 수 있다. 
    2. 이 문제를 해결하기 위해, 우리는 큰 언어 모델(Large Language Models, LLMs)로부터 각 aspect의 sentiment 극성에 대한 설명을 활용하여 ABSA에서 spurious correlation을 줄이는 방법을 제안한다. 
    3. 다양한 데이터셋과 몇 가지 대표적인 ABSA 모델을 통합한 방법을 실험한 결과, 우리의 방법은 성능 향상을 이끌어내며 ABSA 모델의 성능과 일반화 능력을 향상시킬 수 있다.

###### High-quality argumentative information in low resources approaches improve counter-narrative generation (https://aclanthology.org/2023.findings-emnlp.194/)
- Anthology ID: 2023.findings-emnlp.194 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 작은 규모의 fine-tuning에도 언어 모델의 성능을 크게 향상시킬 수 있다는 것이 보여지고 있는데, 이 논문에서는 작은 학습 크기에도 hate speech 반언 생성(task)에 매우 효과적인 highly targeted fine-tuning이 어떻게 작용하는지 보여준다. 
    2. 이 작업에서는 단일 논쟁 전략에 집중하며, 해당 전략과 관련된 논쟁 분석을 함께 제공하여 소량의 예제 세트를 제공하면 전체 반언 세트를 제공하는 것과 동등한 수준의 반언을 생성해낸다. 
    3. 또한 fine-tuning에 긍정적인 영향을 미치기 위해서는 좋은 기본 모델이 필요한 것으로 나타났는데, 특히 스페인어의 경우 fine-tuning 없이 얻은 반언 대부분이 받아들일 수 없을 정도로 낮은 품질이었으며, fine-tuning으로 전체적인 품질이 개선되기는 하였지만 여전히 비만족스러운 수준이었다.

###### A Reference-free Segmentation Quality Index (SegReFree) (https://aclanthology.org/2023.findings-emnlp.195/)
- Anthology ID: 2023.findings-emnlp.195 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자연어 처리(NLP)에서의 주제 분할은 문맥의 의미 변화시 문장들을 분할하고 구분하는 것을 의미한다. 현재 이 분할의 품질을 평가하기 위해서는 사람이나 알고리즘에 의한 분할을 실제 분할과 비교하여 평가해야 한다. 이 논문은 사람 평가자 없이도 분할 품질을 측정하기 위해 참조 없는 분할 품질 지표(SegReFree)를 제안한다. 
    2. 제안된 메트릭은 문장의 의미적 임베딩을 사용하여 변형된 군집 유효성 메트릭을 적용하여 분할 품질을 결정한다. 
    3. 기존의 참조 기반 분할 메트릭과의 비교를 통해 제안된 메트릭은 강력한 상관관계를 보이며, 해당 메트릭을 구현한 파이썬 라이브러리가 공개되었다.

###### In-context Learning for Few-shot Multimodal Named Entity Recognition (https://aclanthology.org/2023.findings-emnlp.196/)
- Anthology ID: 2023.findings-emnlp.196 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존 연구들은 몇몇 entity category에 대한 다량의 주석이 담긴 자료가 있기 때문에 multimodal named entity recognition(MNER)에서 우수한 성능을 달성하였으나, 실제 상황에서는 사전에 모든 entity category를 나열하는 것은 불가능하다. 
    2. 본 논문에서는 소량의 labeled 예제만을 사용하여 텍스트-이미지 쌍 내의 named entity를 효과적으로 탐지하고 식별하는 FewMNER 과제를 제안한다. 
    3. 이미지 모달리티를 텍스트로 변환하여 대규모 언어 모델이 시각적 모달리티로부터 정보를 흡수하도록 하고, 텍스트와 이미지 모달리티의 유사도 순위 합의 랭킹을 사용하여 유용한 예제를 선택하여 task demonstration 환경을 구성하며, 각 entity 카테고리의 의미와 MNER 정의를 효과적인 지시사로 활용하는 프레임워크가 기준 모델들보다 우수한 성능을 보인다는 실험 결과를 제시한다.

###### On Uncertainty Calibration and Selective Generation in Probabilistic Neural Summarization: A Benchmark Study (https://aclanthology.org/2023.findings-emnlp.197/)
- Anthology ID: 2023.findings-emnlp.197 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 요약을 위한 딥 모델은 인상적인 성능을 달성하지만, 예측적 불확실성을 잘못하여 신뢰성과 신뢰성이 저하되는 현실 응용 분야에서 높은 확신을 낮은 품질의 예측에 할당한다. 
    2. 이 논문에서는 복잡한 자기회귀 요약 작업에서 다양한 최신 확률적 방법의 효과를 철저히 조사하고 평가 프로토콜을 통해 불확실성 품질을 개선한다. 
    3. 확률적 방법은 모델의 생성 및 불확실성 품질을 일관되게 향상시키며, 낮은 품질의 요약을 피하는 것에 대한 우수한 성능을 실증적으로 입증하고 있다.

###### Handshape-Aware Sign Language Recognition: Extended Datasets and Exploration of Handshape-Inclusive Methods (https://aclanthology.org/2023.findings-emnlp.198/)
- Anthology ID: 2023.findings-emnlp.198 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 수화인식 연구는 수어의 음운론적 특성을 명확히 고려하지 않고 수화 비디오를 인코딩한다. 하지만 수어에서는 손 모양이 중요한 매개변수이기 때문에, 손 모양을 고려한 수화인식에 대한 가능성을 탐구한다.
    2. PHOENIX14T 데이터셋을 손 모양 레이블로 확장하여 PHOENIX14T-HS 데이터셋을 생성한다.
    3. 단일 인코더 네트워크와 듀얼 인코더 네트워크를 활용한 손 모양 포함 수화인식의 새로운 방법론을 제안하고, CTC 손실과 프레임 수준의 크로스 엔트로피 손실을 동시에 최적화하는 학습 전략을 사용한다. 이러한 방법은 기존의 성능을 일관되게 개선한다.

###### SimCKP: Simple Contrastive Learning of Keyphrase Representations (https://aclanthology.org/2023.findings-emnlp.199/)
- Anthology ID: 2023.findings-emnlp.199 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 키워드 생성(KG)은 소스 문서가 주어졌을 때 요약하는 단어나 구를 생성하는 것을 목표로하며, 키워드 추출(KE)은 텍스트에서 이를 식별하는 것을 목표로합니다. 현재의 통합 접근 방식은 주로 토큰 수준에서 작동하는 순차 레이블링 및 최대화 기반 생성을 채택하여 전체적인 키워드를 관찰하고 점수를 매기는 데 실패합니다.
    2.  이 논문에서는 SimCKP라는 간단한 대조 학습 프레임 워크를 제안하며, 이는 두 단계로 구성됩니다. 첫 번째는 어떤 문서에도 나타나지 않는 키워드도 생성하면서 대조적인 방식으로 문맥을 고려하는 구문 수준 표현을 학습하여 키워드를 추출하는 추출기-생성기입니다. 두 번째는 생성 된 각 구문과 해당 문서의 표현을 정렬하여 점수를 조정하는 재순위 모델입니다.
    3. 다중 벤치마크 데이터셋에서의 실험 결과는 우리가 제안하는 방법의 효과를 입증하며, 최신 모델을 상당히 능가합니다.

###### LEXTREME: A Multi-Lingual and Multi-Task Benchmark for the Legal Domain (https://aclanthology.org/2023.findings-emnlp.200/)
- Anthology ID: 2023.findings-emnlp.200 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 transformer 아키텍처의 현저한 발전에 힘입어, 법적인 NLP 분야가 급속히 성장하고 있다. 이러한 발전을 측정하기 위해서는 정성적이고 도전적인 벤치마크가 필수적이다. 그러나 과거의 노력들은 주로 뉴스나 위키백과와 같은 일반적인 NLP 모델을 위한 벤치마크를 제작해왔는데, 법률 영역처럼 독특한 어휘와 복잡한 문장 구조가 있는 특정 도메인에는 적합하지 않을 수 있다.
    2. 우리는 법적인 NLP 문헌을 조사하고 24개 언어를 포함하는 11 개의 데이터셋을 선택하여 LEXTREME을 만들었다. 모델을 공정하게 비교하기 위해 데이터셋 통합 점수와 언어 통합 점수 두 개의 점수를 제안했다. 최상의 베이스라인도 수준 높은 결과를 달성하지 못하며, ChatGPT도 많은 과제에서 어려움을 겪는다는 결과를 보여준다.
    3. 연구원들과 실무자들이 쉽게 사용할 수 있도록, 우리는 LEXTREME을 huggingface에서 공개하고 모델을 평가하기 위한 필요한 코드와 함께 공개 리더보드를 제공한다. 또한 모든 실험 결과를 위한 public Weights and Biases 프로젝트도 제공한다.

###### Three Questions Concerning the Use of Large Language Models to Facilitate Mathematics Learning (https://aclanthology.org/2023.findings-emnlp.201/)
- Anthology ID: 2023.findings-emnlp.201 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델(LLM)의 탁월한 언어 이해 및 생성 능력을 통해 교육 응용 분야에서 활용이 탐구되었지만, 수학 학습을 돕기 위한 LLM의 교육적 능력에 대한 연구는 거의 이루어지지 않았다.
    2. 이 포지션 논문에서는 적응형 피드백을 통해 학생의 수학 문제 해결 능력을 향상시키기 위해 LLM을 활용하는 과제와 관련된 도전 과제에 대해 논의한다.
    3. LLM은 잘못된 이유 구조를 생성할 수 있을 뿐만 아니라, 질문의 의미를 오해하고 학생의 답을 고치려고 할 때 주어진 질문의 이유를 이해하는데 어려움을 겪을 수 있다. 이를 고려하여 세 개의 연구 질문을 제시한다.

###### Simultaneous Machine Translation with Tailored Reference (https://aclanthology.org/2023.findings-emnlp.202/)
- Anthology ID: 2023.findings-emnlp.202 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Simultaneous machine translation (SiMT)은 전체 소스 문장을 읽으며 번역을 생성합니다. 그러나 기존의 SiMT 모델은 일정 지연 시간에서 사용 가능한 소스 정보의 다양성을 고려하지 않고 동일한 참조(reference)로 학습됩니다."
    2. "저희는 저희가 제안하는 새로운 방법을 통해 학습 시간에 따라 다른 참조(reference)를 제공하여 다양한 Latency에서 학습된 SiMT 모델에 맞춤형 참조를 제공하는 것을 제안합니다."
    3. "저희의 방법은 새로운 참조를 도입하고, tailor라는 reinforcement learning에 의해 유도된 참조를 통해 ground-truth를 수정하여 학습하는 것을 포함하고 있습니다. 실험 결과 무엇보다도 저희의 방법은 현재 SiMT 접근법의 다양한 문제에서 최고 수준의 성능을 달성합니다."

###### Dynamic Voting for Efficient Reasoning in Large Language Models (https://aclanthology.org/2023.findings-emnlp.203/)
- Anthology ID: 2023.findings-emnlp.203 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Self-consistency와 같은 다중 경로 투표 방법은 사실적인 오류와 시각적 생성에 의한 reasoning 오류를 완화하는데 사용되었지만, 각 문제에 대해 많은 reasoning 경로를 생성하기 때문에 많은 계산 자원이 필요합니다.
    2. 이 논문에서는 Dynamic Voting이라는 새로운 다중 경로 투표 기술을 제안하여, 대형 언어 모델이 확신을 가지고 풀 수 있는 문제에 대해 이른 퇴장 (early exiting)을 적용하여 이성적인 경로 수를 효과적으로 줄이고 정확성을 유지합니다.
    3. Dynamic Voting은 산술, 상식, 기호적 추론 작업에서의 실험적 평가 결과, 적은 양의 reasoning 경로를 사용하여 비슷한 정확성을 달성하는 것을 보여줍니다. 또한, 임계값 선택에서 강한 강건성을 보여주며, 다른 투표 기술, 다양한 모델, 다양한 프롬프트와 결합할 때 우수한 일반화 능력을 보입니다.

###### On Surgical Fine-tuning for Language Encoders (https://aclanthology.org/2023.findings-emnlp.204/)
- Anthology ID: 2023.findings-emnlp.204 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존 방식으로 pre-trained 언어 인코더 모형을 새로운 태스크에 적용하는 경우, 전체 레이어를 fine-tuning 하는 것이 일반적이나, 우리는 일부 레이어만 fine-tuning 해도 비슷하거나 더 나은 성능을 얻을 수 있는 것을 보여준다.
    2. 바로 이를 위해, 우리는 고효율적인 메트릭로서 Fisher 정보 행렬의 대각 성분을 사용하여 selective fine-tuning을 위한 후보 레이어를 선택하는 방법을 제안한다.
    3. GLUE와 SuperGLUE의 실험 결과를 통해, 우리는 이 메트릭이 강력한 downstream 성능을 얻기 위한 레이어 선택에 유용하게 사용될 수 있음을 보여준다. 또한, FIM 점수의 강건성을 보여 줌으로써 최적화 과정 동안 일관되게 레이어를 순위 지정할 수 있다는 것을 확인한다.

###### AutoPlan: Automatic Planning of Interactive Decision-Making Tasks With Large Language Models (https://aclanthology.org/2023.findings-emnlp.205/)
- Anthology ID: 2023.findings-emnlp.205 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 대형 언어 모델은 매우 유망하며 구체화된 환경에서의 의사결정에 사용될 수 있다. 하지만, 이러한 모델들은 실제 환경에서의 규칙과 사전 훈련된 지식 사이의 오류로 인해 복잡한 의사결정 과제에서 종종 실패한다.
    2. 기존 방법들은 보통 비용이 많이 드는 기울기 계산이나 시간이 많이 걸리는 문맥 내 예시를 요구한다. 하지만, 이 논문에서는 AutoPlan이라는 방법을 제안하여 LLM 기반 에이전트가 상호작용적인 의사결정 과제를 수행하는 데 도움을 줄 수 있다.
    3. AutoPlan은 경험 수집과 반영을 통해 LLM 프롬프트에 작업 해결 계획을 추가하고 최적화한다. 실험 결과, AutoPlan은 인간이 작성한 예시를 사용하지 않음에도 불구하고 ALFWorld에서의 성공률은 베이스라인과 비슷하게 유지하며 HotpotQA에서는 8% 더 좋은 결과를 보였다.

###### Measuring Faithful and Plausible Visual Grounding in VQA (https://aclanthology.org/2023.findings-emnlp.206/)
- Anthology ID: 2023.findings-emnlp.206 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Visual Question Answering (VQA) 시스템에서 시각적 링크 (VG)에 대한 메트릭은 시스템이 주어진 질문에 대한 답을 추론할 때 관련 이미지 부분에 얼마나 의존하는지를 측정하는 것을 목표로 한다. VG의 부족은 최신 VQA 시스템에 공통적인 문제이며 그 결과로 무관한 이미지 부분에 과도하게 의존하거나 시각적 모달리티를 무시하는 경우가 발생할 수 있다."
    2. "우리는 시스템의 VG 특성을 양적으로 평가하지 않은 대부분의 시스템에서 VG 메트릭을 측정하여 이러한 결점을 보완하고 모델 평가 및 분석에 또 다른 가치 있는 차원을 추가하는 것이 도움이 될 것이라고 생각합니다."
    3. "우리는 질문과 관련된 객체를 식별하고 관련 객체에 포함된 정보를 사용하여 답을 생성하는지 여부를 캡처하는 새로운 VG 메트릭을 제안합니다. 이 메트릭은 "신뢰성 (faithful)"과 "합리성 (plausible)" 모두를 고려한 시각적 링크의 적합성을 쉽게 판단할 수 있으며, 대부분의 VQA 모델 설계에 대해 선명하게 설명하고 다양한 VQA 아키텍처에 대한 여러 참조 시스템을 평가합니다."

###### Improving Zero-shot Reader by Reducing Distractions from Irrelevant Documents in Open-Domain Question Answering (https://aclanthology.org/2023.findings-emnlp.207/)
- Anthology ID: 2023.findings-emnlp.207 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 대형 언어 모델 (LLM)은 오픈 도메인 질문 응답 (ODQA)에서 제로샷 접근 방식을 가능하게 했지만, 리트리버와 비교했을 때 리더는 제한적인 발전을 보여주고 있다.
    2. 이 연구는 계산 비용과 레이블이 달린 데이터의 필요성 등에 대응할 수 있는 제로샷 리더의 타당성을 조사한다.
    3. 우리는 LLM이 검색된 문서 중에서 관련 없는 문서로 인해 주의가 산만해지고, 제로샷 리더로 사용되었을 때 생성된 답변의 자신감 때문에 문제가 발생함을 발견했다. 이 문제를 해결하기 위해 부정에 기반한 지시와 적절한 답변 선택을 위한 점수 조정을 통해 이러한 문서의 영향을 완화시켰다. 실험 결과는 우리의 접근 방법이 다양한 시나리오에서 산만함을 처리하고 제로샷 리더의 성능을 향상시키는 것을 성공적으로 보여준다. 또한, 훈련 없이도 보편적인 전이 가능성을 보여주는 지도 리더에 비해 제로샷 리더는 보완적인 전이성을 보여주고 있다.

###### Can you Summarize my learnings? Towards Perspective-based Educational Dialogue Summarization (https://aclanthology.org/2023.findings-emnlp.208/)
- Anthology ID: 2023.findings-emnlp.208 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 가상 교사(VT)의 활용이 증가함에 따라 효율적이고 맞춤형으로 상호작용하는 AI 기반 학습 경험이 가능해졌다. 그러나 VT와 학생 간 대화를 요약하는 접근은 관점에 따라 다양화되어야 한다.
    2. 이 논문에서는 교사와 학생, 일반적 관점 세 가지로 교육 대화를 요약하는 Multi-modal Perspective based Dialogue Summarization (MM-PerSumm) 작업과 데이터셋 CIMA-Summ을 소개한다. 또한, IP-Summ 모델을 제안하여 이미지와 관점 기반 인코더를 활용하여 다양한 관점에서 대화를 요약한다.
    3. 마지막으로, IP-Summ 모델의 성능을 자세히 분석하여 최적의 모델링을 위한 측면을 강조한다.

###### Adaptive Textual Label Noise Learning based on Pre-trained Models (https://aclanthology.org/2023.findings-emnlp.209/)
- Anthology ID: 2023.findings-emnlp.209 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 현실 세계에서의 레이블 오차는 예측할 수 없으며 다양한 종류의 오차의 혼합일 수 있다. 
    2. 이에 대응하기 위해 사전 훈련된 모델을 기반으로 한 적응적 텍스트 레이블 오차 학습 프레임워크를 개발하였다. 
    3. 여러 가지 일반화 전략을 통합하여, 잘못 레이블이 지정된 인스턴스들을 점진적으로 수정하여 노이즈를 잘 활용할 수 있도록 하는 방법을 제안한다.

###### Towards Informative Open-ended Text Generation with Dynamic Knowledge Triples (https://aclanthology.org/2023.findings-emnlp.210/)
- Anthology ID: 2023.findings-emnlp.210 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사전 훈련된 언어 모델은 텍스트 생성에서 놀랄만한 능력을 보여주지만, 생성된 텍스트가 주어진 프롬프트에 과도하게 집중되어 인간처럼 충분한 배경과 세부 정보를 제공하지 못하는 문제가 있다.
    2. 이 논문에서는 지식 그래프를 활용하여 모델이 더 맥락에 맞는 엔티티와 세부 사실을 생성하도록 하는 동적 지식 안내형 정보성 텍스트 생성 접근 방식을 제안한다.
    3. 실험 결과, 제안된 접근 방식이 기준 모델보다 더 정보성 있는 텍스트를 생성할 수 있다는 것을 보여주고 있다.

###### Novel Relation Detection: Discovering Unknown Relation Types via Multi-Strategy Self-Supervised Learning (https://aclanthology.org/2023.findings-emnlp.211/)
- Anthology ID: 2023.findings-emnlp.211 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 관계 추출 방법은 미리 정의된 관계 유형만 인식할 수 있어, 새로운 관계 유형이나 범위를 벗어난 유형들이 모델에 계속적으로 도전하는 현실 세계에서는 제한적이다.
    2. 본 논문에서는 이러한 도전적인 문제를 Novel Relation Detection (NRD)으로 정의하고, 알려진 관계의 학습 샘플을 기반으로 잠재적인 새로운 관계 유형을 발견하는 것을 목표로 한다.
    3. 실험 결과는 우리의 방법이 두 데이터셋에서 이전 최신 기법을 크게 능가하는 효과적인 NRD 방법임을 보여준다.

###### Ask Language Model to Clean Your Noisy Translation Data (https://aclanthology.org/2023.findings-emnlp.212/)
- Anthology ID: 2023.findings-emnlp.212 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 신경 기계 번역(NMT)에서 TTransformer 모델들은 높은 성능을 보여주고 있으나, 소음이 섞인 입력에 대한 취약성이 있어 실제 구현에서 깨끗한 출력을 생성하는 것은 중요한 도전 과제이다. 
    2. 우리는 MTNT 데이터셋의 대상 문장에서 노이즈를 제거하여 소음 평가에 더 적합한 벤치마크로 만들기 위해 힘들게 검토하였다. 
    3. 우리의 실험은 언어 모델의 기능을 활용하여 노이즈 제거에 그들의 놀라운 능력을 관찰하였으며, 이를 통해 NMT 모델의 견고성 평가에 효과적인 C-MTNT 데이터셋을 구축하였고, LLM이 이 작업에 효과적으로 수행된다는 결론을 도출하였다.

###### Multi-User MultiWOZ: Task-Oriented Dialogues among Multiple Users (https://aclanthology.org/2023.findings-emnlp.213/)
- Anthology ID: 2023.findings-emnlp.213 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화 시스템은 이제 더 많은 사용자들과 동시에 협력적으로 결정을 내리는 대화를 수행하는 것이 기대된다. 이를 위해, 저자들은 두 명의 사용자와 한 명의 에이전트 간의 대화를 포함하는 Multi-User MultiWOZ 데이터셋을 공개하였다.
    2. 이 데이터셋은 여러 사용자가 공동으로 작업을 진행하는 상황에서의 대화 동역학을 반영하고 있다.
    3. 이 데이터를 기반으로 저자들은 multi-user 대화에서 prediction된 쿼리를 사용하여 대화 상태 추적을 효과적으로 개선하는 방법을 제안하였다. 이 방법은 기존의 single-user 대화에 훈련된 대화 시스템을 수정하지 않고도 적용 가능하며, 새로운 도메인에도 일반화될 수 있다.

###### Extractive Summarization via ChatGPT for Faithful Summary Generation (https://aclanthology.org/2023.findings-emnlp.214/)
- Anthology ID: 2023.findings-emnlp.214 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 요약 추출은 긴 문서를 직접 문장을 추출하여 짧은 버전으로 요약하는 자연어 처리의 중요한 과제이다. 이 논문은 ChatGPT의 요약 추출 성능을 보다 폭넓은 benchmark 데이터셋에서 전통적인 fine-tuning 방법과 비교하여 평가하였다. 실험 결과, ChatGPT는 ROUGE 점수 측면에서 기존의 지도학습 시스템에 비해 성능이 떨어지는 반면, LLM 기반 평가 메트릭을 기반으로 한 높은 성능을 보였다고 밝혔다.
    2. 또한, in-context learning과 chain-of-thought reasoning의 효과를 조사하여 성능을 향상시키는 방법을 탐구하였다. 이에 따라, ChatGPT를 extract-then-generate 파이프라인에 적용하는 것은 요약의 충실성 측면에서 abstractive 기준에 비해 상당한 성능 향상을 이끌어 냈다.
    3. 이러한 관찰결과는 두 단계 접근법을 사용하여 ChatGPT의 신뢰성 있는 요약 능력을 향상시키는 잠재적인 방향을 제시하였다.

###### MAPO: Boosting Large Language Model Performance with Model-Adaptive Prompt Optimization (https://aclanthology.org/2023.findings-emnlp.215/)
- Anthology ID: 2023.findings-emnlp.215 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Prompt engineering"은 대규모 언어 모델 (LLM) 을 활용하는 효과적인 방법이지만, 기존 연구들은 특정 LLM보다는 특정 작업에 적합한 prompt의 중요성을 강조한다.
    2. 본 연구에서는 서로 다른 LLM에 대한 다른 prompt의 사용이 NLP의 다양한 하위 작업에서 능력을 강화하는데 중요하다는 사실을 정량적으로 보였다. 
    3. 제안된 MAPO (model-adaptive prompt optimizer) 방법은 각 특정 LLM의 하위 작업에 대해 원래의 prompt를 최적화하는데 효과적이며, 다양한 하위 작업에서 큰 향상을 이끌었다.

###### PsyCoT: Psychological Questionnaire as Powerful Chain-of-Thought for Personality Detection (https://aclanthology.org/2023.findings-emnlp.216/)
- Anthology ID: 2023.findings-emnlp.216 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 대형 언어 모델 (LLMs)의 발전은 ChatGPT와 같은 다양한 NLP 작업에서 놀라운 zero-shot 성능을 나타내었다. 그러나 글로 작성된 텍스트에서 개인의 성격을 식별하는 인식 작업에서의 LLM의 잠재력은 아직 충분히 탐구되지 않았다.
    2. 우리는 심리 질문지에서 영감을 받아 심리학자들에 의해 개별 성격 특성을 평가하기 위해 신중하게 설계된 질문 항목들을 체인 오브 스로트 (CoT, 사고의 연결) 프로세스의 집합으로 간주 할 수 있다고 주장한다.
    3. 이에 대응하여 우리는 PsyCoT라는 새로운 성격 인식 방법을 제안하며, 이는 다중 턴 형식의 대화 방식으로 심리 질문지를 완료하는 개인의 방법을 모방한다. 우리는 텍스트 분석을 전문으로 하는 AI 어시스턴트로서 LLM을 사용한다. 우리는 어시스턴트에게 각 턴마다 개별 항목을 평가하도록 하고, 평가 결과를 이용하여 결론적인 성격 선호도를 도출한다.

###### Harnessing the power of LLMs: Evaluating human-AI text co-creation through the lens of news headline generation (https://aclanthology.org/2023.findings-emnlp.217/)
- Anthology ID: 2023.findings-emnlp.217 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. LLM 기술을 활용하여 텍스트 작성에 인간이 어떻게 최상의 결과를 얻고, 이 모델과 상호작용하는 것이 글 작성 과정에 소유감과 신뢰감에 어떤 영향을 미치는지 알아보기 위해, LLM 보조 뉴스 제목 생성을 통해 일반적인 인간-인공지능 상호작용 방식을 비교해보았다.
    2. LLM 자체만으로도 만족스러운 뉴스 제목을 생성할 수 있지만, 잘못된 모델 출력을 수정하기 위해서는 평균적으로 인간의 개입이 필요했다.
    3. 인터랙션 방법 중에서도, 모델 출력을 안내하고 선택하는 것이 시간과 노력에 비해 가장 많은 이점을 제공했다. 또한, AI 협력은 자유롭게 편집하는 것과 비교하여 참가자들의 통제감에 해를 끼치지 않았다.

###### NERetrieve: Dataset for Next Generation Named Entity Recognition and Retrieval (https://aclanthology.org/2023.findings-emnlp.218/)
- Anthology ID: 2023.findings-emnlp.218 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 텍스트에서 entity를 인식하는 것은 정보 탐색 시나리오에서 중요한 필요로 여겨지며, Named Entity Recognition (NER)은 널리 채택된 NLP 태스크와 해당 기술의 가장 성공적인 예라고 볼 수 있다. 
    2. 큰 언어 모델의 최근 발전은 전용 모델로 처리되던 NER 작업에도 효과적인 솔루션을 제공하며, 전용 모델의 능력을 맞추거나 능가하는 경우도 많다. 그러나 NER은 여전히 해결된 문제로 보기에는 이르지 않다.
    3. 이 논문에서는 NER 작업의 세 가지 변형을 제시하고, 이를 지원하는 데이터셋을 제공한다. 더 세분화되고 서로교차하는 entity 유형으로 나아가는 것, entity 유형 레이블을 기반으로 미리 학습되지 않은 유형의 인식 및 추출을 하는 것, 검색 설정에서 인식 설정으로 전환하는 것이다. 이러한 모든 변형은 아직 해결되지 않은 문제들이다.

###### SWEET - Weakly Supervised Person Name Extraction for Fighting Human Trafficking (https://aclanthology.org/2023.findings-emnlp.219/)
- Anthology ID: 2023.findings-emnlp.219 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 본 연구에서는 SWEET(Supervise Weakly for Entity Extraction to fight Trafficking)이라는 엔터티 추출을 위한 약한 감독 파이프라인을 제안한다.
    2. SWEET은 노이즈가 있는 에스코트 광고에서 사람 이름을 추출하기 위해 규칙 일치와 대규모 언어 모델을 결합한 방법이다.
    3. SWEET은 라벨링 함수를 통해 다중 약한 라벨을 얻고 효과적으로 집계하여 이전의 감독형 성능 지표를 9% F1 점수로 능가하며 벤치마크 데이터에 더 잘 일반화된다.

###### Watermarking LLMs with Weight Quantization (https://aclanthology.org/2023.findings-emnlp.220/)
- Anthology ID: 2023.findings-emnlp.220 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델의 남용은 언어 모델을 빠르게 배포하면서 높은 위험을 드러내고 있다. 이 논문은 대화스러운 양자화 과정에서 워터마크를 추가하는 새로운 전산수법을 제안한다.
    2. 이 워터마크는 모델이 fp32 모드에서 사용될 때 동작하고, int8로 양자화될 때는 숨겨져 있는다. 이를 통해 사용자들은 모델을 그 자체로 추론할 수 있지만, 모델의 추가 지도학습 없이는 워터마크를 삭제할 수 없다.
    3. GPT-Neo와 LLaMA를 포함한 오픈소스 대규모 언어 모델에 워터마크를 성공적으로 심었다. 이 방법이 대규모 언어 모델 응용 분야에서 모델 가중치 보호를 위한 잠재적인 방향을 제공할 수 있기를 희망한다.

###### Disentangling Extraction and Reasoning in Multi-hop Spatial Reasoning (https://aclanthology.org/2023.findings-emnlp.221/)
- Anthology ID: 2023.findings-emnlp.221 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 텍스트를 통한 공간 추론은 직접적인 공간 정보를 추출하는 데에 그치는 것이 아니라 해당 정보에 대한 추론과 암묵적인 공간 관계를 유추하는 것도 필요하기 때문에 어려운 문제이다.
    2. 본 논문에서는 이러한 도전을 극복하기 위해 정보 추출과 추론을 분리(disentangle)하는 다양한 모델을 설계하고, 해당 모델들을 명시적으로 디자인하지 않은 최신기술(SOTA) 베이스라인과 비교한다.
    3. 실험 결과는 분리(disentangling)의 유효성을 일관되게 입증하여, 실제 데이터 도메인 내에서 모델의 일반화 능력을 향상시킬 수 있는지 보여주었다.

###### PsyAttention: Psychological Attention Model for Personality Detection (https://aclanthology.org/2023.findings-emnlp.222/)
- Anthology ID: 2023.findings-emnlp.222 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 개성 탐지 작업은 BigFive 및 MBTI와 같은 다양한 개성 모델의 심리학적 특징을 포함하려고 했다. 그러나 이러한 특징들을 결합해서 사용할 때, 서로 다른 계산 표준을 갖고 있는 기능들 사이의 간섭이 발생할 수 있어 노이즈를 도입하고 성능을 저하시킬 수 있다.
    2. 이 논문에서는 PsyAttention을 제안하여 다른 심리학적 모델을 개성 탐지에 적용하고, 이를 효과적으로 인코딩하여 특징의 수를 85% 줄일 수 있다.
    3. BigFive와 MBTI 모델에 대한 실험에서, PsyAttention은 각각 65.66%와 86.30%의 평균 정확도를 달성하여 최신 기법보다 우수한 성능을 보여주었다.

###### RoAST: Robustifying Language Models via Adversarial Perturbation with Selective Training (https://aclanthology.org/2023.findings-emnlp.223/)
- Anthology ID: 2023.findings-emnlp.223 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사전 훈련된 언어 모델(LM)을 fine-tuning 하는 것은 많은 NLP 태스크에서 표준이 되었지만, 여전히 adversarial robustness와 모델 calibration과 같은 robustness 문제에 취약하다.
    2. 본 논문에서는 adversarial perturbation을 fine-tuning 도중에 도입하고, 불필요한 편차를 최소화하기 위해 모델 파라미터를 상대적 중요성에 따라 선택적으로 업데이트하여, LMs의 다양한 관점에서의 robustness를 향상시키는 간단하면서도 효과적인 fine-tuning 기술인 RoAST를 제안한다.
    3. RoAST는 모델 robustness에 대한 네 가지 대표적인 관점을 통합하여 fine-tuned LMs를 평가하고, 여섯 가지 다른 유형의 LMs에서 최신 fine-tuning 방법과 비교해서 그 효과성을 입증하였으며, 실제 응용에서의 유용성을 시사한다.

###### The Law and NLP: Bridging Disciplinary Disconnects (https://aclanthology.org/2023.findings-emnlp.224/)
- Anthology ID: 2023.findings-emnlp.224 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 법적 실무는 언어의 구조에 근본이 있지만 법적 실무자들과 학자들은 자연어 처리(NLP) 도구를 도입하는 데서 느림이 있다. 동시에, 법체계가 접근성에 따른 위기를 겪고 있는데, NLP를 통해 이 부분을 일부 완화할 수 있다. 이 논문에서는 법적 실무 중 NLP의 필요성과 NLP 연구자의 초점 사이의 괴리가 NLP의 천천히 채용되는 데 영향을 미친다고 주장한다. 
    2. 법적 실무에서 가장 인기 있는 NLP 태스크 중 일부는 법적 실무자의 요구사항을 충족시키지 못하는 것으로 나타났다. 
    3. 법률 NLP 연구의 최근 동향을 검토한 결과, 법률 NLP 커뮤니티와 법률 학계 간에는 제한적인 중첩이 있으며, 연구를 할 수 있는 여러 가지 법적 NLP 작업을 소개하여 이러한 괴리를 벌릴 수 있는 흥미로운 연구 분야를 강조하고 있다.

###### Symbolization, Prompt, and Classification: A Framework for Implicit Speaker Identification in Novels (https://aclanthology.org/2023.findings-emnlp.225/)
- Anthology ID: 2023.findings-emnlp.225 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 새로운 대화에서 발화자 식별은 다중 발화자 오디오북 생성 및 소설을 대본으로 변환하는 등 다양한 하위 작업에 적용될 수 있는데, 기존 최첨단 방법은 "Tom said, '...'"과 같은 명시적인 이야기 패턴에만 제한되어 있어서 장거리 맥락을 완전히 이해하고 복잡한 경우를 처리할 수 없다.
    2. 이를 위해 우리는 SPC라는 프레임워크를 제안하는데, 이는 상징화(symbolization), 프롬프트(prompt), 분류(classification)를 통해 장르에서 은암적인 발화자를 식별한다.
    3. 실험 결과, SPC는 웹 소설 모음에서 4.8% 정확도의 큰 향상을 보여 이전 방법들보다 발화자 식별 오류를 47% 줄일 수 있으며, 새로운 ChatGPT보다 뛰어나다. 또한 SPC는 장거리 맥락 의미 이해가 필요한 은암적 발화자 식별의 경우에 더 정확하다.

###### Open-Ended Instructable Embodied Agents with Memory-Augmented Large Language Models (https://aclanthology.org/2023.findings-emnlp.226/)
- Anthology ID: 2023.findings-emnlp.226 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 고정된 prompt로는 open-domain 자연어를 처리하고 사용자의 특이한 절차에 적응하는 것이 어렵습니다. 이 논문에서는 HELPER라는 화면이 있는 에이전트를 소개합니다. HELPER는 대화의 문맥에 맞는 prompt 예제를 사용하여 뉴메모리 기반 언어 모델(Language Model)에 질의합니다.
    2. HELPER는 사용자의 언어와 행동 계획을 기록하여 향후 추론을 지원하고 사용자의 언어와 루틴에 맞춤화합니다. HELPER는 TEACh 벤치마크에서 Execution from Dialog History (EDH) 및 Trajectory from Dialogue (TfD)에서 새로운 최고 성능을 달성하였고 이전에 기록된 최고 기록에 비해 1.7배 성능 향상을 이끌어냈습니다.
    3. 개발된 모델, 코드 및 비디오 결과는 https://helper-agent-llm.github.io에서 확인할 수 있습니다.

###### ACT-SQL: In-Context Learning for Text-to-SQL with Automatically-Generated Chain-of-Thought (https://aclanthology.org/2023.findings-emnlp.227/)
- Anthology ID: 2023.findings-emnlp.227 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근에는 대형 언어 모델(LLM)이 다양한 도메인과 태스크에서 강력한 능력을 갖추었다. 이 연구에서는 텍스트-SQL 태스크에서 프롬프트 설계 문제를 연구하고, LLM의 추론 능력을 개선한다. 
    2. 우리는 스키마 링크와 비슷한 방법으로 연결된 상태습관 (chain-of-thought) 프롬프트를 설계하고, ACT-SQL이라는 방법을 제안하여 자동으로 상태습관을 생성한다. 이로써 수작업 레이블링이 필요하지 않아 비용 절감효과를 얻을 수 있다. 
    3. 실험 결과, 우리의 ACT-SQL 접근 방식은 LLM의 성능을 향상시키고, 기존의 상황인식 학습 접근 방식 중에서도 Spider dev 세트에서 최고 성능을 달성하였다.

###### Manifold-Preserving Transformers are Effective for Short-Long Range Encoding (https://aclanthology.org/2023.findings-emnlp.228/)
- Anthology ID: 2023.findings-emnlp.228 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다양한 학습 작업에서 Multi-head self-attention 기반 Transformer 모델은 매우 유망하게 나타났으나, 이 모델들은 계층별 문맥 정보를 보존하지 못한다. TransJect는 이 문제를 해결하기 위해 layer 간 토큰 간 거리 보존의 이론적 한계를 보장하면서 토큰 표현을 다른 manifold로 변환하여 Euclidean 거리를 보존한다.
    2. 다양한 벤치마크 짧은 및 긴 시퀀스 분류 작업에서 TransJect는 Transformers의 변형들보다 각각 최대 6.8%와 5.9%의 성능 향상을 보여준다. 또한 TransJect는 언어 모델링 작업에서 Transformer보다 79% 우수한 성능을 보인다.
    3. TransJect는 다양한 attention head들이 무작위하고 비정렬적으로 학습하는 문제를 해결하기 위해 전문가들의 조합을 이용하여 규제할 수 있으며, 이러한 전문가들은 입력 시퀀스로부터 다른 희소 표현을 학습한다. TransJect는 엔트로피가 매우 낮고 깊이를 더욱 효율적으로 확장할 수 있다.

###### ASPIRO: Any-shot Structured Parsing-error-Induced ReprOmpting for Consistent Data-to-Text Generation (https://aclanthology.org/2023.findings-emnlp.229/)
- Anthology ID: 2023.findings-emnlp.229 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. ASPIRO는 구조화된 데이터를 zero to few-shot 환경에서 짧은 템플릿 문장으로 변환하는 기법을 제안한다. 이전 방법과 다르게, ASPIRO는 큰 언어 모델에게 엔티티에 대해 고려하지 않는 템플릿을 직접 생성하도록 유도한다.
    2. ASPIRO는 알고리즘적 파싱 체크와 LLM 재프롬프팅을 활용하여 실시간으로 템플릿 생성 문제를 해결하는 방법을 제시한다.
    3. ASPIRO는 DART 데이터셋에서 RDF 트리플의 문장화 과정에서 파싱 오류를 평균 66% 줄이며, Rel2Text 데이터셋에서 BLEU 50.62, METEOR 45.16, BLEURT 0.82, NUBIA 0.87, PARENT 0.8962의 성능을 보이며 최신 사전 훈련 언어 모델과 경쟁한다.

###### Detecting Syntactic Change with Pre-trained Transformer Models (https://aclanthology.org/2023.findings-emnlp.230/)
- Anthology ID: 2023.findings-emnlp.230 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 연구에서는 Transformer 기반 언어 모델이 19세기 초과 20세기 후반의 영어 사이의 구문적 차이를 찾을 수 있는 능력을 조사한다. 이를 위해 BERT 모델을 fine-tuning하여 문맥 정보를 가린 뒤, 구문 정보만을 사용하여 이 두 시기의 텍스트를 구분할 수 있다는 것을 보여준다. 
    2. 또한, fine-tuned BERT 모델을 사용하여 구체적인 구문 변화 및 새로운 품사가 도입된 단어를 식별하는 방법을 제안한다. 이를 위해 자동적인 품사 태거와 BERT의 사전학습된 표현을 활용하여 특정 말뭉치에 대한 품사 태거를 학습시킨다. 
    3. 최종적으로, 이 방법을 사용하여 구문적 변화의 역사적인 발전인 진행형 문법의 등장을 확인하는데 사용한다.

###### A Word Sense Distribution-based approach for Semantic Change Prediction (https://aclanthology.org/2023.findings-emnlp.231/)
- Anthology ID: 2023.findings-emnlp.231 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 단어의 의미 변화를 예측하는 것은 시간에 민감한 NLP 애플리케이션에서 중요한 작업이다. 각 맥락에 따라 모호한 단어들의 의미를 구분하는 WSD 방법과 의미 변화 감지 사이에 관계가 있는데, 우리는 두 개의 시간 단위로 수집된 코퍼스에서 대상 단어의 의미가 변화했는지를 예측할 수 있는지 조사한다.
    2. 사전 훈련된 정적 sense embedding을 사용하여 대상 단어의 각 인스턴스에 sense id를 자동으로 부여한다.
    3. 다른 발산 또는 거리 측정 기법을 사용하여 주어진 두 코퍼스 간 대상 단어의 의미 변화를 양적으로 측정한다. 실험 결과, 단어의 의미 변화를 정확하게 예측하는 데에 단어 sense 분포를 사용할 수 있다는 것을 확인하였다.

###### Gold: A Global and Local-aware Denoising Framework for Commonsense Knowledge Graph Noise Detection (https://aclanthology.org/2023.findings-emnlp.232/)
- Anthology ID: 2023.findings-emnlp.232 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 일반 상식 그래프(Commonsense Knowledge Graphs)를 사람의 주석을 통해 구축하는 것은 비용이 많이 들 수 있다. 그 결과, 더 많은 의미적인 범위를 가진 CSKG를 구축하기 위해 여러 자동 방법이 제안되고 있다.
    2. 이 논문에서는 CSKG의 노이즈를 감지하기 위해 Entity Semantic Information, Global Rules, Local Structural Information을 활용하는 Noise detection framework인 Gold를 제안한다.
    3. 실험 결과, Gold는 합성된 노이즈가 있는 CSKG 벤치마크에서 모든 기준 성능을 능가하며, CSKG의 노이즈를 제거하는 것이 Zero-shot commonsense question answering task에도 효과적임을 보여준다.

###### Improving Conversational Recommendation Systems via Bias Analysis and Language-Model-Enhanced Data Augmentation (https://aclanthology.org/2023.findings-emnlp.233/)
- Anthology ID: 2023.findings-emnlp.233 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화형 추천 시스템은 언어 모델링 기술의 발전에 따라 주목을 받으면서 빠르게 성장하는 연구 분야이다. 그러나 현재의 대화형 추천은 상대적으로 새로운 분야이며 제한된 기여로 인해 여러 가지 도전에 직면하고 있다. 
    2. 본 연구에서는 CRS 모델 개발을 위한 벤치마크 데이터셋을 탐구하고, 다중 턴 상호작용에서 나타나는 피드백 루프로 인해 발생하는 선택 편향과 다양한 인기 편향 변형 등의 잠재적인 편향 문제를 다룬다. 
    3. 언어 모델과 데이터 확장 기법을 사용하는 데이터 증강 접근 방식을 제안하고, ReDial 및 TG-ReDial 벤치마크 데이터셋에서의 실험을 통해 CRS 기술의 성능을 향상시키고 새롭게 정의된 다양한 편향 문제를 해결하는 데 도움이 되는 결과를 제시한다.

###### Exploring Graph Pre-training for Aspect-based Sentiment Analysis (https://aclanthology.org/2023.findings-emnlp.234/)
- Anthology ID: 2023.findings-emnlp.234 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존 연구들은 감성 요소를 생성적으로 추출하여 복잡한 모델링을 피하기 위해 해왔는데, 이러한 방식은 감성 요소간의 관계를 고려하지 않아서 중요한 문제를 놓치고 있다. 
    2. 따라서, 이 논문에서는 그래프 기반 pre-training을 활용하여 감성 요소 간의 관계를 더 잘 파악할 수 있는 모델을 개발하였다.
    3. 실험 결과는 우리의 방법이 뛰어나며, 우리의 동기에 대한 올바른 이해를 검증한다.

###### DemaFormer: Damped Exponential Moving Average Transformer with Energy-Based Modeling for Temporal Language Grounding (https://aclanthology.org/2023.findings-emnlp.235/)
- Anthology ID: 2023.findings-emnlp.235 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 시간 언어 지원은 비디오 순간을 자연어 질의와 의미적으로 대응시키는 것을 목표로 한다. 최근 연구들은 어텐션 메커니즘을 사용하여 비디오 순간과 텍스트 질의 사이의 관계를 학습한다. 그러나 단순한 어텐션은 이러한 관계를 적절하게 파악하지 못하여 목표 비디오 순간을 다른 순간들과 구분하기 어려운 분포를 생성할 수 있다.
    2. 이 문제를 해결하기 위해, 우리는 에너지 기반 모델 프레임워크를 제안하여 순간-질의 분포를 명시적으로 학습한다.
    3. 또한, 우리는 exponential moving average와 학습 가능한 감쇠 인자를 사용하는 새로운 Transformer 기반 아키텍처인 DemaFormer를 제안하여 순간-질의 입력을 효과적으로 인코딩한다. 4개의 공개 데이터셋에서 수행한 포괄적 실험을 통해 우리의 방법이 최신 기준선에 비해 우수함을 보였다.

###### Test-time Augmentation for Factual Probing (https://aclanthology.org/2023.findings-emnlp.236/)
- Anthology ID: 2023.findings-emnlp.236 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사실적 파악은 언어 모델이 특정 세계 지식 사실을 "알고 있는지" 테스트하는 방법으로, prompt의 작은 변경이 모델 출력에 큰 변화를 일으키는 문제가 있다. 
    2. 기존 연구는 텍스트 마이닝이나 세밀한 조정을 통해 이 문제를 완화시키려고 했으나, 이런 접근 방식은 관련성에 특화되어 있고 본연의 종족을 보이지 않아 새로운 관계 유형에는 일반화하지 못한다. 
    3. 본 논문은 시험 시간 증강 (TTA)을 사용하여 prompt 변동에 대한 민감도를 줄이는 관계 비의 방법으로 제안한다. 실험 결과, TTA를 사용하면 모델 신뢰도가 예측 정확성을 더 잘 반영하는 개선이 보여진다. 몇몇 모델에서는 예측 정확도가 향상되지만, 다른 모델에서는 TTA가 저하를 일으킨다. TTA에 대한 해석 분석은 높은 품질의 prompt 변이 생성의 어려움을 주요 도전 요소로 확인했다.

###### Methodological Insights in Detecting Subtle Semantic Shifts with Contextualized and Static Language Models (https://aclanthology.org/2023.findings-emnlp.237/)
- Anthology ID: 2023.findings-emnlp.237 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문에서는 네덜란드어와 영어의 다른 정치적 신념을 가진 사회 공동체 사이의 미묘한 의미 변화를 자동으로 탐지하는 연구를 수행한다.
    2. 우리는 정적 모델과 문맥화된 언어 모델을 사용하는 방법을 비교하는 방법론적 연구를 수행한다. 
    3. 우리의 결과는 정적 모델을 사용하는 방법과 우리의 마스크 토큰 예측 방법은 정치적으로 부담스러운 용어의 함의 차이를 감지할 수 있으며, 문맥화된 표현의 거리를 측정하는 방법은 심지어 극단적인 변화의 합성 시나리오에서도 명확한 신호를 제공하지 않는다는 것을 보여준다.

###### Disfluent Cues for Enhanced Speech Understanding in Large Language Models (https://aclanthology.org/2023.findings-emnlp.238/)
- Anthology ID: 2023.findings-emnlp.238 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자연스러운 대화에서 입다듬지 않는(disfluent) 내용을 제거하는 것이 보통의 방법이지만, 이 논문에서는 이러한 disfluencies가 단순한 노이즈 이상의 정보적인 표식 역할을 할 수 있다고 가정한다.
    2. 이 연구에서는 다양한 유형의 대화 수정 (speech repairs)이 포함된 disfluent 질의를 포함하여 읽기 이해 작업에 대해 사전 학습된 모델을 사용한다.
    3. 연구 결과, 특정 disfluencies는 모델 성능을 향상시킬 수 있는데, 특히 문맥 기반의 조절으로 인한 disfluencies가 그렇다는 것을 보여준다. 그러나 대규모 언어 모델은 의사 결정을 포함한 수정이나 어휘 또는 구문 오류의 수정에 어려움이 있어 발전 가능성이 있는 중요한 영역이라고 제안한다.

###### Watermarking PLMs on Classification Tasks by Combining Contrastive Learning with Weight Perturbation (https://aclanthology.org/2023.findings-emnlp.239/)
- Anthology ID: 2023.findings-emnlp.239 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "대규모 사전 훈련 언어 모델(PLM)은 비용이 많이 드는 훈련으로 인해 저작권보호에 대한 중요성이 있는 가치 있는 지적 재산이 되었다. 이에따라, 지적 재산을 보호하기 위해 개발된 PLM 워터마킹 방법이 중요하지만 미개발된 기술이다." 
    2. "이 연구에서는 특정 입력에 의해 트리거 될 수 있는 백도어를 포함하여 PLM 워터마킹의 실현 가능성을 조사한다. 워터마킹 단계에서 대조 학습을 사용하여 특정 입력의 표현을 다른 입력에서 분리하고, 후속 학습 후에 특정 레이블과 연결시킬 수 있게 한다." 
    3. "다양한 데이터셋에서 수행된 광범위한 실험 결과 워터마크를 다운스트림 작업에 대한 어떠한 지식 없이도 견고하게 추출할 수 있으며, 성공률이 높다는 것을 보여준다."

###### BanLemma: A Word Formation Dependent Rule and Dictionary Based Bangla Lemmatizer (https://aclanthology.org/2023.findings-emnlp.240/)
- Anthology ID: 2023.findings-emnlp.240 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 레마타이제이션은 자연어처리와 언어학에서 중요하며, 데이터 밀도를 줄이고 문맥적 의미를 이해하는 데 도움이 된다. 그러나 방글라 텍스트의 인플렉션과 형태론적인 풍부함으로 인해 레마타이제이션은 복잡한 도전 과제가 된다.
    2. 우리는 방글라에 대한 레마타이저를 설계하기 위해 언어학적 규칙을 제안하고 규칙과 사전을 이용한다. 이 시스템은 주어진 문장 내에서 단어의 품사 클래스에 기반하여 단어를 레마타이즈하는 것을 목표로 한다. 
    3. 우리의 룰은 인플렉션된 단어의 단어 형성을 관찰하기 위해 다양한 도메인, 원본 및 시간대의 방글라 텍스트 크러포스를 분석한다. 이를 통해 우리의 레마타이저는 훈련된 언어학자들이 수작업으로 주석을 단 테스트 데이터셋에서 96.36%의 정확도를 달성하고 이전에 발표된 세 개의 방글라 레마타이제이션 데이터셋에서 경쟁력 있는 성능을 보여준다.

###### Exploring the Sensitivity of LLMs’ Decision-Making Capabilities: Insights from Prompt Variations and Hyperparameters (https://aclanthology.org/2023.findings-emnlp.241/)
- Anthology ID: 2023.findings-emnlp.241 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. LLM의 의사결정 능력은 하이퍼파라미터와 prompt의 변화에 민감하다는 점을 고려하지 않은 이전 연구들이 있다. 
    2. 이 논문에서는 세 가지 다른 성능을 갖는 OpenAI 언어 모델을 사용하여 prompt와 온도 설정에 따른 LLM의 의사결정 능력 변동을 분석하였다. 
    3. 단순한 prompt 조정에 따라 언어 모델은 사람과 유사한 탐사와 활용의 균형을 나타낸다는 점을 발견하였다.

###### Search Augmented Instruction Learning (https://aclanthology.org/2023.findings-emnlp.242/)
- Anthology ID: 2023.findings-emnlp.242 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델들은 instruction fine-tuning을 통해 크게 발전해왔으나, 여전히 투명성과 최신 지식과 정보 활용 능력이 부족하다. 
    2. 본 논문에서는 in-house와 외부 검색 엔진들이 생성한 복잡한 검색 결과에 기반하여 언어 생성과 지시 따르기 능력을 더 높이는 search-augmented instruction learning (SAIL)을 제안한다. 
    3. 실험 결과, fine-tuned SAIL-7B 모델은 강력한 지시 따르기 능력을 가지며, 개방형 질문 답변과 사실 확인처럼 투명성이 중요한 작업에서 유의미한 개선을 보인다.

###### “Kelly is a Warm Person, Joseph is a Role Model”: Gender Biases in LLM-Generated Reference Letters (https://aclanthology.org/2023.findings-emnlp.243/)
- Anthology ID: 2023.findings-emnlp.243 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 대형 언어 모델은 권장서와 같은 전문 문서를 작성하는 데 도움이되는 효과적인 도구로 등장했습니다. 그러나 이 응용 프로그램은 편의성을 제공하는 한편 이전에 없던 공정성 문제를 도입합니다. 모델 생성된 추천서에 잠재된 편견이 있다면, 정성적인 검토 없이 사용하면 여성 지원자의 합격률을 감소시키는 등 사회적인 문제를 초래할 수 있습니다.
    2. 우리는 이 긴급한 문제를 감안하여 실세계 사용 사례에서의 공정성 문제와 관련된 피해를 포괄적으로 연구하는 것이 절실하고 필요하다고 생각합니다.
    3. 이 논문에서는 LLM이 생성한 추천서에서 성별 편견을 비판적으로 조사합니다. 우리는 사회과학 연구 결과로부터 영감을 받아 언어 스타일의 편견과 어휘 내용의 편견 이라는 2가지 차원을 통해 편견을 명백히 보이는 평가 방법을 설계합니다. 또한, 편식 편견(hallucination bias)을 분석하여 편견의 전파 정도를 조사하고, ChatGPT와 Alpaca라는 두 가지 인기 있는 LLM에서 평가를 수행하여 LLM이 생성한 추천서에서 심각한 성별 편견을 발견합니다. 이 연구 결과는 검토 없이 LLM을 이용하는 것에 대한 경고뿐만 아니라 LLM이 생성한 전문 문서에서의 숨겨진 편견과 피해를 철저히 연구하는 중요성을 명확히 합니다.

###### TextMixer: Mixing Multiple Inputs for Privacy-Preserving Inference (https://aclanthology.org/2023.findings-emnlp.244/)
- Anthology ID: 2023.findings-emnlp.244 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사전 훈련된 언어 모델(PLM)은 클라우드 서비스로 배포되어 사용자가 텍스트 데이터를 업로드하고 원격으로 추론을 수행할 수 있게 한다. 그러나 사용자의 개인 텍스트는 민감한 정보를 포함하고 있으며, 이를 서비스 제공자와 직접 공유하면 심각한 개인정보 유출에 이어질 수 있다. 본 연구에서는 추론 단계에서 평문 유출을 방지하는 혁신적인 개인 정보 보호 추론 프레임워크인 MixPi를 소개한다.
    2. MixPi는 사용자의 개인 입력을 여러 다른 입력과 혼합하여 의미적 연결을 혼란시켜 잠재적인 개인 정보 공격자를 방지하는 것을 목표로 한다. 이를 위해 우리의 접근 방식은 (1) 혼합, 표현 및 위치와 같은 세 가지 다른 차원에서 입력을 암호화하는 혁신적인 암호화 모듈인 Privacy Mixer를 제안한다. (2) 혼합된 표현을 처리하고 여러 예측을 얻기 위해 사전 훈련된 다중 입력 다중 출력 네트워크를 채택한다. (3) 사용자만이 여러 예측 중에서 실제 출력을 해독할 수 있도록 Privacy Demixer를 사용한다.
    3. 또한, 혼합에 필요한 합성 입력을 자동으로 생성하는 다양한 방법을 탐색한다. 토큰 및 문장 분류 작업에 대한 실험 결과는 MixPi가 성능과 개인 정보 보호 측면에서 기존의 비공개 방법을 크게 능가한다는 것을 보여준다.

###### FinePrompt: Unveiling the Role of Finetuned Inductive Bias on Compositional Reasoning in GPT-4 (https://aclanthology.org/2023.findings-emnlp.245/)
- Anthology ID: 2023.findings-emnlp.245 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자연어 처리에서 텍스트 간의 구성적 추론은 오랫동안 과제였는데, GPT-4와 같은 큰 언어 모델이 등장하면서 chain-of-thought (CoT)와 같은 프롬프팅 기법이 제안되었다. 그러나 이러한 프롬프팅은 발견하고 검증하는 데 상당한 인력이 필요하다.
    2. 우리의 연구는 GPT-4의 구성적 추론 능력을 향상시키는 방법으로 사후조정된 모델로부터 작업별 귀납적 편향을 프롬프트로 전달하는 것을 제안한다.
    3. 다중 점프 질문 응답과 텍스트에서의 수치 추론에 대한 실험 결과, 우리의 프롬프트 방식은 복잡한 추론 작업에 대해 기존의 프롬프트와 경쟁력 있는 제로샷 및 퓨샷 성능을 보여주며, 이전 패러다임의 검증된 편향을 채택하는 것의 중요성을 강조한다.

###### Teacher Perception of Automatically Extracted Grammar Concepts for L2 Language Learning (https://aclanthology.org/2023.findings-emnlp.246/)
- Anthology ID: 2023.findings-emnlp.246 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 언어 교육에서의 한 도전은 구문, 의미, 또는 음운론에 관한 규칙을 의미 있는 방식으로 조직하는 것이다. 이 논문에서는 교육자가 규칙을 생성하는 데 도움을 주기 위해 문법 설명을 자동으로 추출하고 시각화하는 방법을 제안한다.
    2. 인도의 칸나다어와 마라티어라는 두 개의 언어를 가르치기 위해 이 방법을 적용하고, 영어와 달리 잘 개발된 학습 자료가 없는 이 언어들에 대한 매우 의미 있는 자료를 자동으로 추출할 수 있다는 것을 보여준다.
    3. 북미의 언어 교육자들에게 수동 평가를 받아서 추출된 자료의 유용성을 평가한 결과, 이 자료는 수업 준비와 학습자 평가에 사용될 수 있는 잠재력을 가지고 있다고 평가받았다.

###### Allies: Prompting Large Language Model with Beam Search (https://aclanthology.org/2023.findings-emnlp.247/)
- Anthology ID: 2023.findings-emnlp.247 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델(LLM)의 발전으로 인해, LLM 응용 분야의 연구는 점점 인기를 끌고, LLM API 호출을 쌓아 복잡한 작업을 수행하는 파이프라인을 구축하는 아이디어가 실현되었다.
    2. 그러나 이러한 방법은 정보 범위가 제한되고 잘못 대처하는 한계가 있다. 본 논문에서는 ALLIES라는 참신한 방법을 제안한다. 
    3. ALLIES는 입력 쿼리를 기반으로 LLM을 사용하여 원본 쿼리와 관련된 새로운 쿼리를 반복적으로 생성하여 반복적인 추론 과정을 가능하게 한다.
    
    ***code: https://github.com/microsoft/SimXNS/tree/main/ALLIES***

###### Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning (https://aclanthology.org/2023.findings-emnlp.248/)
- Anthology ID: 2023.findings-emnlp.248 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델 (LLMs)은 인간과 유사한 추론 능력을 보이지만 복잡한 논리적 문제에 여전히 어려움을 겪습니다. 이 논문에서는 LLM과 심볼릭 풀러 (symbolic solver)를 통합하는 새로운 Logic-LM 프레임워크를 소개합니다. 
    2. 우리의 방법은 먼저 LLM을 사용하여 자연어 문제를 심볼릭한 수식으로 변환합니다. 그런 다음 심볼릭 풀러가 변환된 문제에 대한 추론을 수행합니다. 
    3. 우리는 논리 지식을 활용하는 Logic-LM이 LLM만 사용하는 것보다 평균적으로 39.2%의 성능 향상을 보이며,  chain-of-thought prompting을 사용하는 LLM보다도 18.4%의 성능 향상을 보인다는 실험 결과를 보여줍니다.

###### SiMFy: A Simple Yet Effective Approach for Temporal Knowledge Graph Reasoning (https://aclanthology.org/2023.findings-emnlp.249/)
- Anthology ID: 2023.findings-emnlp.249 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 Temporal Knowledge Graph (TKG) reasoning 작업은 그래프 신경망과 순환 신경망을 사용하여 지식 그래프의 구조적 정보와 시간적 정보를 모델링하였으나, 훈련 효율성이 낮고 일반화 능력이 부족한 문제가 있다.
    2. 이 논문은 이러한 복잡한 모델 구조의 필요성을 고찰하고, multilayer perceptron (MLP)과 고정 빈도 전략을 사용하여 간단하고 효과적인 접근법인 SiMFy를 제안한다.
    3. 실험 결과에서 SiMFy는 빠른 수렴 속도와 더 좋은 일반화 능력, 훈련 과정에서의 시간 소비 감소, 그리고 KG의 구조적 의존성을 더 잘 포착하는 능력을 보여주었다. 이러한 결과는 복잡한 모델을 간단한 대칭 모델로 대체하는 것도 실현 가능한 전략임을 보여준다.

###### Understanding Translationese in Cross-Lingual Summarization (https://aclanthology.org/2023.findings-emnlp.250/)
- Anthology ID: 2023.findings-emnlp.250 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Cross-lingual 요약에서 번역어가 학습 및 성능에 영향을 끼친다는 것을 확인하고, 기존 데이터셋 구축 방법에 따라 번역어 정도가 다르게 나타남을 밝혀냈다.
    2. 번역어가 테스트 세트의 문서나 요약에 영향을 미쳐 인간의 판단과 자동 평가 간의 차이를 야기할 수 있음을 발견했다.
    3. 트레이닝 세트에 번역어가 포함되면 실제 응용 프로그램에서 모델 성능에 해로울 수 있음을 확인했으며, 특정한 학습 전략 아래에서 저자원 언어에 대한 CLS 시스템 구축에 매우 유용한 기계 번역 문서임을 밝혔다.

###### The Truth, The Whole Truth, and Nothing but the Truth: A New Benchmark Dataset for Hebrew Text Credibility Assessment (https://aclanthology.org/2023.findings-emnlp.251/)
- Anthology ID: 2023.findings-emnlp.251 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 정보 과잉의 시대에서는 사실과 허구를 구별하는 것이 이전보다 더 중요하다. 이 논문에서는 이스라엘 공공 인물과 정치인들의 발언의 신뢰성을 평가하기 위한 새로운 공개 데이터셋 HeTrue를 소개한다.
    2. 우리는 이 데이터셋을 활용하여 텍스트만을 기반으로 발언의 신뢰성을 예측할 수 있는지 검증한 결과, 발언 텍스트만 사용하는 방법과 메타데이터, 맥락, 증거와 같은 추가 데이터를 사용하는 방법을 비교하였다.
    3. 실험 결과, 발언과 맥락을 통합하는 모델이 단순히 발언 텍스트만을 기반으로 하는 모델보다 성능이 향상되었으며, 증거도 통합한 최고 모델은 48.3의 F1 Score를 달성하여 HeTrue가 어려운 벤치마크임을 보여주었다.

###### IndiSocialFT: Multilingual Word Representation for Indian languages in code-mixed environment (https://aclanthology.org/2023.findings-emnlp.252/)
- Anthology ID: 2023.findings-emnlp.252 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 인도어 사용자들의 수가 증가함에 따라, 인도어 기술을 개발하는 것이 필요하다고 한다.
    2. 이 논문은 원어, 음역, 다국어, 코드 혼용 및 소셜 미디어 관련 특성을 포함한 다양한 텍스트 특징에 대한 일반화된 표현 벡터를 제안한다.
    3. 제안된 임베딩은 대부분의 경우와 언어에서 기준선을 뛰어넘어 다양한 NLP 응용에 적합함을 보여주었다.

###### Adaptive Hinge Balance Loss for Document-Level Relation Extraction (https://aclanthology.org/2023.findings-emnlp.253/)
- Anthology ID: 2023.findings-emnlp.253 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다중 문장에서 개체 간 관계를 예측하는 문서 수준 관계 추출은 개체 쌍 간의 관계 여부를 결정하기 위해 multi-label 분류 임계값을 선택하는 것이 일반적이다. 하지만 문서 수준 작업에서는 대부분의 개체 쌍이 어떤 관계도 표현하지 않아 양성 및 음성 클래스 간에 매우 불균형한 분포가 발생한다.
    2. 본 논문에서는 관계의 예측 점수와 분류 임계값 간의 거리를 활용하여 쉬운 음성 데이터를 가중치를 줄이는 방법을 제안한다. 즉, 소수의 양성 관계인 어려운/잘못된 분류 관계에 더욱 집중하여 그들의 난이도를 측정하는 새로운 Adaptive Hinge Balance Loss를 제안하고 있다.
    3. Re-DocRED에서의 실험 결과를 통해 우리의 접근법이 다른 균형 조절 방법보다 우수함을 보였다고 한다.
    
    논문 링크: https://github.com/Jize-W/HingeABL

###### Answer-state Recurrent Relational Network (AsRRN) for Constructed Response Assessment and Feedback Grouping (https://aclanthology.org/2023.findings-emnlp.254/)
- Anthology ID: 2023.findings-emnlp.254 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. NLP에서 새로운 유형인 constructed response (CR) 질문에 대응하는 Answer-state Recurrent Relational Network (AsRRN)를 개발하여, college STEM에서 일반적인 multiple questions per context 구조를 다루었다.
    2. AsRRN은 계산 그래프에서 특정 종속성을 위한 relation 벡터를 학습하며, contrastive loss를 통해 더 좋은 표현 학습과 학생 피드백을 지원한다.
    3. AsRRN은 LLMs 기반의 분류기, CR 질문을 위한 이전 relational network, 그리고 GPT-3.5를 이용한 few-shot learning을 능가하는 성능을 보였다.

###### Low-Resource Comparative Opinion Quintuple Extraction by Data Augmentation with Prompting (https://aclanthology.org/2023.findings-emnlp.255/)
- Anthology ID: 2023.findings-emnlp.255 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Comparative Opinion Quintuple Extraction (COQE)는 비교 문장에서 주체, 대상, 공유 가능한 측면, 비교 의견, 선호도를 예측하는 것을 목표로 한다. 기존의 COQE 방법은 오류 전파 문제로 실패한다.
    2. 이 논문에서는 데이터 증강 기법에 기반한 저자원 비교 의견 퀸텀 추출 방법인 DAP(Dataset Augmentation with Prompting)을 소개한다.
    3. Camera, Car, Ele의 세 가지 데이터셋을 사용한 실험 결과 우리의 접근법이 대폭 개선되며 최고 성능을 달성한다는 것을 보여준다.

###### A New Benchmark and Reverse Validation Method for Passage-level Hallucination Detection (https://aclanthology.org/2023.findings-emnlp.256/)
- Anthology ID: 2023.findings-emnlp.256 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델은 현실 세계에서 사람들과 효과적으로 협업할 수 있지만, 잘못된 텍스트나 검증되지 않은 정보를 만들어 내는 오류가 발생할 수 있다.
    2. 본 논문에서는 제로 리소스 방식으로 사실적인 오류를 자동으로 감지하기 위해 역 검증을 기반으로 한 자가 점검 방법을 제안한다.
    3. 실험 결과는 제안된 방법이 베이스 라인보다 우수한 성능을 보이며, 토큰과 시간이 적게 든다는 것을 보여준다. 또한, LLM이 포착하지 못한 몇 가지 오류 케이스를 수동으로 분석하여 제로 리소스 방법의 공통적인 한계를 밝힌다.

###### Speculative Decoding: Exploiting Speculative Execution for Accelerating Seq2seq Generation (https://aclanthology.org/2023.findings-emnlp.257/)
- Anthology ID: 2023.findings-emnlp.257 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Speculative Decoding (SpecDec)를 제안하여 예상 실행의 개념을 활용하여 autoregressive (AR) decoding을 가속화하는 방법을 공식적으로 연구하였습니다. 
    2. SpecDec는 Spec-Drafter와 Spec-Verification이라는 두 가지 혁신을 가지고 있으며, 이를 통해 Transformer 아키텍처에서 약 5배의 속도 향상을 달성할 수 있습니다. 
    3. 뿐만 아니라 SpecDec의 추가적인 장점들을 보여주며, 실제 응용 프로그램에서 생성 모델의 가속화를 위한 실용적인 가치를 확인할 수 있습니다.

###### APP: Adaptive Prototypical Pseudo-Labeling for Few-shot OOD Detection (https://aclanthology.org/2023.findings-emnlp.258/)
- Anthology ID: 2023.findings-emnlp.258 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "사용자 쿼리에서 out-of-domain (OOD) 의도를 감지하는 것은 task-oriented 대화 시스템에 있어서 필수적이다. 이 논문에서는 대부분의 라벨링된 in-domain (IND) 의도가 있는 가정이 아닌, 실제로 IND 데이터가 적고 IND와 OOD에 속할 수 있는 대량의 라벨 되지 않은 혼합 데이터가 있는 few-shot OOD 설정에 초점을 맞춘다."
    2. "우리는 한정된 IND 데이터를 사용하여 구별력 높은 표현을 학습하고, 라벨 되지 않은 혼합 데이터를 활용하는 few-shot OOD 감지를 위한 adaptive prototypical pseudo-labeling (APP) 메소드를 제안한다. 이 방법은 한정된 IND 데이터를 사용하고 IND 데이터를 이용한 low-resource OOD 감지를 돕는 prototypical OOD 감지 프레임워크(ProtoOOD)와 고품질의 pseudo OOD와 IND 라벨을 생성하기 위한 adaptive pseudo-labeling 방법을 포함한다."
    3. "영구 실험과 분석을 통해 우리의 방법이 few-shot OOD 감지에 효과적임을 입증하였다."

###### 2INER: Instructive and In-Context Learning on Few-Shot Named Entity Recognition (https://aclanthology.org/2023.findings-emnlp.259/)
- Anthology ID: 2023.findings-emnlp.259 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Pre-training 지식을 활용하여 down-stream few-shot task에서 강력한 기법인 Prompt-based learning이 등장했으나, NER 태스크를 위한 새로운 text-to-text 프레임워크 2INER를 제안한다.
    2. 우리의 접근 방식은 InstructionNER를 기반으로 instruction finetuning을 사용하여 모델이 과제별 지침을 효과적으로 이해하고 처리할 수 있게 한다. 
    3. 우리는 Type Extracting이라는 새로운 보조 작업을 소개하여 문장의 전체 의미적 맥락에서 entity 유형을 모델이 더 잘 이해하도록 한다. 결과적으로 우리의 방법은 존재하는 Few-Shot NER 방법을 능가하며 최첨단 표준 NER 알고리즘과 경쟁력을 유지한다.

###### Generative Emotion Cause Triplet Extraction in Conversations with Commonsense Knowledge (https://aclanthology.org/2023.findings-emnlp.260/)
- Anthology ID: 2023.findings-emnlp.260 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. ECTEC (Emotion Cause Triplet Extraction in Conversations)는 대화에서 감정 발화, 감정 범주 및 원인 발화를 동시에 추출하는 것을 목표로 한다. 
    2. 기존 연구들은 ECTEC 작업을 여러 하위 작업으로 분해하고 이를 파이프라인 방식으로 해결한다.
    3. 이 논문에서는 SHARK라는 commonSense knowledge-enHanced generAtive fRameworK를 제안하였다. 이는 ECTEC 작업을 인덱스 생성 문제로 정의하고 시퀀스 투 시퀀스 모델을 사용하여 감정-원인-범주 세트를 자동으로 생성한다.

###### Proto-lm: A Prototypical Network-Based Framework for Built-in Interpretability in Large Language Models (https://aclanthology.org/2023.findings-emnlp.261/)
- Anthology ID: 2023.findings-emnlp.261 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델 (LLMs)은 자연어 처리 (NLP) 분야를 크게 발전시켰으나, 해석 가능성의 부족은 주요한 문제점이다. 
    2. 기존 방법들은 추론 시간 이후에 적용되는 후처리(post hoc) 방식으로 저수준 피처에 초점을 맞추고 상위 수준의 텍스트 단위의 설명 가능성을 갖지 못한다.
    3. 이 연구에서는 proto-lm이라는 프로토타입 네트워크 기반의 화이트 박스 프레임워크를 소개하는데, 이는 경쟁력 있는 성능을 유지하면서 fine-tuning 단계에서 바로 해석 가능한 임베딩을 학습할 수 있게 한다.

###### GROVE: A Retrieval-augmented Complex Story Generation Framework with A Forest of Evidence (https://aclanthology.org/2023.findings-emnlp.262/)
- Anthology ID: 2023.findings-emnlp.262 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 조건부 이야기 생성은 복잡한 플롯을 가진 이야기를 만드는 사람-기계 상호작용에서 중요하며, 기존 방법은 세부적인 프롬프트에 의존하여 창의적인 플롯을 억제한다. 
    2. 이 논문에서는 인간이 작성한 예시 이야기에서 정보를 활용하여 다양한 플롯을 생성하는 "GROVE"라는 프레임워크를 제안한다.
    3. 이 프레임워크는 타깃 조건에 대한 검색 저장소를 구축하여 LLMs를 자극하는데 활용하며, "asking-why" 프롬프팅 체계를 설계하여 이야기의 배경에 대한 정보를 공급한다.

###### KAPALM: Knowledge grAPh enhAnced Language Models for Fake News Detection (https://aclanthology.org/2023.findings-emnlp.263/)
- Anthology ID: 2023.findings-emnlp.263 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 소셜 미디어에서의 뉴스 소비가 증가함에 따라 가짜 뉴스의 전파 또한 늘어났는데, 기존의 가짜 뉴스 탐지 방법은 외부 entity(knowledge) 정보를 활용한다.
    2. 이 논문에서는 뉴스 entity 정보 뿐만 아니라 뉴스 entity 간의 구조화된 지식까지 고려하는 방법을 제안한다.
    3. 실험 결과는 우리의 방법이 저자들의 실험 기준에 비해 더 나은 성능을 보여준다는 것을 보여준다. 또한, few-shot 시나리오에서도 경쟁력을 가지고 있다.

###### Comparing the Evaluation and Production of Loophole Behavior in Humans and Large Language Models (https://aclanthology.org/2023.findings-emnlp.264/)
- Anthology ID: 2023.findings-emnlp.264 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "법, 전통, 일상생활에서 loopholes는 흔하게 일어난다. 파고드는 이들은 다른 사람의 의도된 의미나 목표를 이해하나, 다른 해석을 택한다. AI 연구는 지금까지 artificial intelligence가 loopholes를 활용하는 것처럼 보였으나, 이는 아마 인간화일 가능성이 높다. 현재 모델들, 특히 큰 Language 모델들이 loopholes를 이해하는 데 필요한 실용적 이해를 얼마나 잘 포착하는지는 여전히 불분명하다."
    2. "우리는 두 가지 loophole 행동 연구를 위해 개발된 평가 지표인 LLMs의 성능을 조사했다: 평가 (문제, 불쾌함, 유머의 평가)와 생성 (주어진 맥락에서 새로운 loopholes 찾기). 우리는 최신 LLMs와 인간들을 세밀하게 비교하고, 대다수의 모델들이 loophole 행동을 통한 결과물이 완벽한 비준수보다 문제와 불쾌함이 적다고 평가했으며 (성인들과 일치), 그러나 인간들처럼 loophole을 창의적으로 활용한 유머를 인식하는 데 어려움이 있다는 것을 발견했다."
    3. "게다가, GPT 3과 3.5 두 모델만이 자체 loophole을 생성할 수 있으며, 그 중 GPT3.5가 인간의 기준에 가장 가깝게 수행하는 것으로 나타났다."

###### InstructExcel: A Benchmark for Natural Language Instruction in Excel (https://aclanthology.org/2023.findings-emnlp.265/)
- Anthology ID: 2023.findings-emnlp.265 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델(Large Language Models, LLMs)의 발전으로 우리는 스프레드시트를 포함한 다양한 도메인에서 복잡한 NLP 태스크를 해결할 수 있게 되었습니다. 이 연구는 LLMs가 자연어 사용자 명령을 통해 스프레드시트 특정 작업을 해결하는 코드(Excel OfficeScripts)를 생성할 수 있는지를 조사합니다.
    2. 이를 위해 우리는 Excel의 '자동화' 기능을 활용하여 사용자의 동작으로부터 OfficeScripts를 자동으로 생성하는 InstructExcel이라는 대규모 벤치마크를 소개합니다.
    3. GPT-4와 같은 최신 모델을 기준으로한 다양한 제로샷 및 퓨샷 설정에서의 실험 결과, InstructExcel이 GPT-4와 같은 최신 모델에게 어려운 벤치마크라는 것을 관찰하며, (1) GPT-4 대 GPT-3.5 사용, (2) 보다 많은 문맥 예제 제공, (3) 동적 프롬프팅은 이 벤치마크에서의 성능을 향상시키는 데 도움이 될 수 있다는 것을 알 수 있었습니다.

###### Hallucination Detection for Grounded Instruction Generation (https://aclanthology.org/2023.findings-emnlp.266/)
- Anthology ID: 2023.findings-emnlp.266 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 본 연구에서는 실내 환경에서 사람을 안내하기 위한 지침 생성 문제를 조사한다. 현재 모델의 주요 문제는 환각이다: 모델은 사람이 따라갈 때 실행되거나 마주칠 수 없는 동작이나 물체에 대한 참조를 생성한다.
    2. 우리는 이러한 환각된 참조를 탐지하기 위해 큰 양의 이미지 - 텍스트 쌍으로 사전 훈련된 모델을 채택하고, 합성된 환각을 포함한 지침과 올바른 지침을 구분하는 대조 손실에 대해 세부 튜닝을 한다.
    3. 우리의 최종 모델은 지시어 생성 모델에 의한 단어 확률을 사용하는 기준선 및 LSTM 및 Transformer를 기반으로 한 지도 모델을 포함하여 여러 가지 기준모델을 능가한다.

###### Definitions Matter: Guiding GPT for Multi-label Classification (https://aclanthology.org/2023.findings-emnlp.267/)
- Anthology ID: 2023.findings-emnlp.267 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델은 미세 조정(fine-tuning) 없이도 많은 자연어 태스크를 수행하는 능력으로 최근 인기를 끌고 있다. 
    2. 이 연구에서는 (1) 예시에서 정의를 생성하고 제로샷 분류에 사용하며, (2) LLM이 그 정의를 활용하는 방법을 조사하는 두 가지 새로운 아이디어에 초점을 맞추고 있다.
    3. GPT-3 모델을 사용하여 트윗의 세부적인 다중 레이블 음모론 분류에 대해 제로샷 레이블링을 통해 성능을 분석하고, 레이블의 정의형식의 최소한이면서도 의미 있는 컨텍스트를 제공하여 레이블링을 개선하는 방법을 평가한다.

###### ECHo: A Visio-Linguistic Dataset for Event Causality Inference via Human-Centric Reasoning (https://aclanthology.org/2023.findings-emnlp.268/)
- Anthology ID: 2023.findings-emnlp.268 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. ECHo는 비디오-언어적 소셜 시나리오에 기반한 사건 인과 추론을 위한 진단 데이터셋으로, 인간 중심의 연역적 정보를 활용한다. 
    2. ECHo는 비디오-언어적 추론에 대한 ToM 능력을 요구하여, 현재 AI 시스템의 추론 능력을 평가하는 CoT 프레임워크를 제안한다.
    3. ECHo는 InstructGPT와 MiniGPT-4와 같은 최근의 대형 foundation model들을 사람 중심의 진단 태스크에서 검증하는 데 사용되며, 이를 통해 추론의 불완전성과 일관성의 문제를 드러내는 어려운 데이터셋임을 보여준다.
    
    (ECHo: Event Causality Inference via Human-Centric Reasoning, ToM: Theory-of-Mind, CoT: Chain-of-Thought)

###### An Empirical Study of Instruction-tuning Large Language Models in Chinese (https://aclanthology.org/2023.findings-emnlp.269/)
- Anthology ID: 2023.findings-emnlp.269 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. ChatGPT의 성공은 대형 언어 모델의 인공 일반지능 (AGI)에 대한 잠재력을 입증한다. 다음으로, 대형 언어 모델 공개로 인해 커뮤니티에서는 ChatGPT 복제 프로세스를 가속화하기 위해 'instruction-tuning'에 대한 관심이 높아졌다.
    2. 그러나 세계에서 가장 많이 사용되는 중국어에서 instruction-tuning 대한 연구는 아직 초기 단계에 있다. 따라서 이 논문은 중국어에서 instruction-tuning 대한 철저한 경험적 연구를 수행하였으며, 이는 중국어 지침에 더 효과적으로 대응할 수 있는 LLMs를 사용자 정의하는 데 유용한 결과를 제공하는 쿡북 역할을 할 수 있다.
    3.특히, LLM 기반, 매개변수 효율적인 방법, instruction 데이터 유형 등, instruction-tuning에 가장 중요한 세 가지 요소의 영향을 체계적으로 탐색했다. 또한, chain-of-thought 데이터와 인간의 가치 정렬과 같은 다른 요소들의 영향을 연구하기 위한 실험도 수행되었다.

###### Debiasing Multimodal Models via Causal Information Minimization (https://aclanthology.org/2023.findings-emnlp.270/)
- Anthology ID: 2023.findings-emnlp.270 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 다중모달 모델에 대한 편향 보정 방법은 근사적인 휴리스틱을 사용하여 편향을 나타내는데, 이러한 휴리스틱은 훈련 초기의 얕은 특징 또는 VQA와 같은 다중모달 태스크의 단일모달 특징들을 사용하는 것이 일반적이다.
    2. 이 논문에서는 다중모달 데이터에 대한 인과 그래프에서 발생하는 편향을 연구하고, 인과론적 정보 최소화를 활용하여 편향 제거를 위한 새로운 접근 방식을 제안한다. 
    3. 제안된 방법들은 데이터셋의 편향을 포착하고, 편향 제거 방법은 분포 범위를 벗어난 데이터에 대한 성능을 향상시키면서도 분포 내의 성능은 유지할 수 있다는 것을 실험 결과를 통해 확인하였다.

###### Evaluating Emotion Arcs Across Languages: Bridging the Global Divide in Sentiment Analysis (https://aclanthology.org/2023.findings-emnlp.271/)
- Anthology ID: 2023.findings-emnlp.271 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Emotion arcs는 개인 또는 인구의 시간에 따른 감정 변화를 나타내는데 널리 사용되지만, 이를 자동으로 생성하는 것에 대한 평가에는 여전히 연구가 부족하다. 이 연구에서는 자동으로 생성된 감정 변화를 첫 번째로 체계적이고 정량적으로 평가하며, 머신러닝 모델과 Lexicon-Only 방법 두 가지 일반적인 감정 변화 생성 방법을 비교한다.
    2. 인스턴스 수백 개에서 정보를 종합하는 데 있어서는 Lexicon-Only 방법이 감정 분류에서는 좋지 않지만, 감정 변화를 생성하는 데에는 매우 정확하다는 것을 18개의 다양한 데이터셋과 9개의 언어에서 실험을 통해 보여준다.
    3. 또한 영어 감정 어휘의 자동 번역이 자원이 적은 언어에서도 높은 품질의 감정 변화를 생성하는 데 사용될 수 있다는 것을 여섯 가지 아프리카 원주민 언어, 아랍어, 스페인어 실험을 통해 보여준다.

###### Multi-step Jailbreaking Privacy Attacks on ChatGPT (https://aclanthology.org/2023.findings-emnlp.272/)
- Anthology ID: 2023.findings-emnlp.272 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델(Large Language Models, LLMs)의 빠른 발전으로 적절한 입력 프롬프트가 주어질 경우, 다양한 NLP 태스크를 잘 해결할 수 있다. 그러나 LLM에서 유해한 콘텐츠 생성을 피하기 위한 작업에도 불구하고, 인공지능 생성 콘텐츠(AIGC)를 인간의 이익을 위해 조절하는 것은 여전히 어려운 과제이다. 
    2. 강력한 LLMs이 다양한 도메인의 기존 텍스트 데이터를 처리하고 있는데 (예: GPT-3는 45TB의 텍스트로 훈련함), 이 훈련 데이터에 개인 정보가 포함되어 있는지 그리고 이러한 LLMs과 그들의 downstream 어플리케이션은 어떤 개인정보 위협을 가져올 수 있는지 의심스러울 수 있다.
    3. 이 논문에서는 OpenAI의 ChatGPT와 ChatGPT 기반으로 개선된 New Bing으로부터의 개인정보 위협을 연구하고, 어플리케이션에 통합된 LLMs가 새로운 개인정보 위협을 일으킬 수 있음을 보여준다. 이를 위해 우리는 광범위한 실험을 수행하여 주장을 뒷받침하고, LLMs의 개인정보 영향에 대해 논의한다.

###### Chain-of-Thought Embeddings for Stance Detection on Social Media (https://aclanthology.org/2023.findings-emnlp.273/)
- Anthology ID: 2023.findings-emnlp.273 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 소셜 미디어에서의 stance detection은 대형 언어 모델(LLM)에게 도전적이며, 임의 표현과 비형식적인 언어로 인해 암묵적인 stance 레이블이 포함되어 있다. COT(prompt) 기법은 stance detection 성능을 향상시키는 것으로 알려져 있으나 여전히 암묵적 stance 인식에 어려움을 겪고 있다. 
    2. 이 논문에서는 COT(reasoning chain) 임베딩을 도입하여 전통적인 RoBERTa 기반의 stance detection 파이프라인에 통합함으로써 COT의 성능을 향상시켰다. 
    3. 실험 결과, COT(reasoning chain)은 text encoder가 COT 레이블을 왜곡시킬 수 있는 미세한 오류나 착각을 통해 학습할 수 있으며, 도메인 특정 패턴에 의존하는 경우 잘못된 COT reasoning을 간과할 수 있다는 것을 보여주었다.

###### Using LLM for Improving Key Event Discovery: Temporal-Guided News Stream Clustering with Event Summaries (https://aclanthology.org/2023.findings-emnlp.274/)
- Anthology ID: 2023.findings-emnlp.274 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 정치적 담론을 분석하기 위해서는 뉴스 스트림에서 핵심 사건과 그에 연관된 뉴스 기사를 식별하는 것이 중요하다. 
    2. 우리는 뉴스 스트림 클러스터링을 위한 일반적인 프레임워크를 제안하고, 이를 통해 중요한 뉴스 이벤트와 그에 대한 뉴스 아티클을 자동으로 추출한다.
    3. 우리의 간단하고 효과적인 프레임워크는 더 일관된 이벤트 중점 클러스터를 생성하며, 이를 통해 KeyEvents라는 11개 주제의 611개 핵심 이벤트를 가진 40,000개 문서의 데이터셋을 구축한다.

###### Descriptive Prompt Paraphrasing for Target-Oriented Multimodal Sentiment Classification (https://aclanthology.org/2023.findings-emnlp.275/)
- Anthology ID: 2023.findings-emnlp.275 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Target-Oriented Multimodal Sentiment Classification (TMSC)"은 텍스트, 이미지 및 기타 다양한 모달리티를 포함하여 대상의 감성 극성을 함께 분류하는 작업이다. 
    2. 기존 연구들은 대상의 타입에 따라 분산 방식으로 작업을 수행하는데, 이는 대상의 감성 극성이 타입이 아니라 문맥에 의해 결정된다는 점을 고려하지 않았다.
    3. 이 논문에서는 UnifiedTMSC라는 통합 모델을 제안하여 이 문제를 해결하였고, 실제 실험결과에서도 그 효과를 입증하였다.

###### Joint Semantic and Strategy Matching for Persuasive Dialogue (https://aclanthology.org/2023.findings-emnlp.276/)
- Anthology ID: 2023.findings-emnlp.276 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 설득 대화는 대화를 통해 사용자를 설득하여 목표를 달성하는 것을 목표로 한다. 기존의 설득 모델은 주로 문장의 의미 일치에 기반하지만, 대화 전략과 같은 중요한 측면을 무시하는 경향이 있다.
    2. 대화 전략은 문장 의미에 비해 고수준 개념이며, 효과적인 설득을 위해 정보를 제공하고 보완하는 역할을 할 수 있다.
    3. 본 논문에서는 대화 의미와 전략을 함께 모델링하여 설득 모델을 구축하는 것을 제안한다. 실험 결과, 우리의 접근법은 Recall@1 측면에서 작은 데이터셋에서 5%와 큰 데이터셋에서 37%까지 최신 기준 모델에 비해 성능을 크게 개선했다. 상세 분석 결과, 자동 회귀 예측기가 최종 성능에 가장 큰 기여를 한다는 것을 보여준다.

###### Non-Autoregressive Sentence Ordering (https://aclanthology.org/2023.findings-emnlp.277/)
- Anthology ID: 2023.findings-emnlp.277 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 문장 순서 결정 방법은 순서에 맞게 문장을 예측하기 위해 반복적으로 엔코더-디코더 프레임워크를 사용한다. 그러나 이러한 방식은 디코딩 중에 단방향 종속성만을 활용하며 문장 간의 의미적 종속성을 완전히 탐구할 수 없다는 한계가 있다.
    2. 이 논문에서는 문장 간의 양방향 종속성을 탐구하고 각 위치에 대한 문장을 병렬로 예측하는 새로운 비자기 회귀적 순서 결정 네트워크인 NAON을 제안한다. 문장의 길이가 결정적이며 문장과 위치가 서로 매치되어야 하는 문장 순서 결정 과제에 비자기 회귀적 방식이 특히 적합하다고 주장한다.
    3. 실험 결과를 통해 제안한 모델의 효과를 확인하고, 기존의 자기 회귀적 접근 방식보다 우수한 성능을 나타내며 최신 기법과 경쟁력 있는 성능을 달성한다는 것을 보여준다.

###### Large Language Models are Not Yet Human-Level Evaluators for Abstractive Summarization (https://aclanthology.org/2023.findings-emnlp.278/)
- Anthology ID: 2023.findings-emnlp.278 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 언어 모델(ChatGPT, GPT-4 등)의 추론 능력이 크게 발전함에 따라, 다양한 작업에 언어 모델을 활용하는 추세가 있다. 그 중 한 분야는 복잡한 생성 작업의 대체 평가 메트릭으로 언어 모델을 사용하는 것이다.
    2. 본 논문에서는 ChatGPT와 GPT-4가 기존 자동 평가 메트릭을 능가하지만, 일관성과 신뢰성 측면에서 아직은 인간 대체 수준에 이르지 못하는 것으로 밝혀졌다. 또한, 언어 모델은 후보 시스템을 일관되게 평가하지 못하며, 차원에 따라 평가 결과가 달라진다.
    3. 언어 모델은 성능이 비슷한 후보들을 비교하는 데 어려움을 겪으며, 높은 품질의 요약문일수록 인간 평가와의 상관관계가 낮아져 신뢰성이 떨어진다. 따라서, 발전하는 요약 시스템을 평가할 때 언어 모델을 사용하면 오해를 불러일으킬 수 있다.

###### Women Wearing Lipstick: Measuring the Bias Between an Object and Its Related Gender (https://aclanthology.org/2023.findings-emnlp.279/)
- Anthology ID: 2023.findings-emnlp.279 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문에서는 이미지 캡션 시스템에서 객체가 성별 편향에 미치는 영향을 조사하였다. 그 결과, 성별 특정 객체만이 성별 편향을 강하게 가지고 있음을 보였다.
    2. 또한, 우리는 시각적 의미 기반 성별 점수를 제안하였는데, 이 점수는 편향 정도를 측정하고 어떤 이미지 캡션 시스템에도 적용될 수 있는 플러그인 역할을 할 수 있다.
    3. 실험 결과 우리는 성별 점수가 유용하게 사용될 수 있는데, 캡션과 관련된 성별 편향을 측정할 수 있기 때문에 기존의 Object Gender Co-Occ 접근법에 추가적인 메트릭으로 사용될 수 있다.

###### FREDSum: A Dialogue Summarization Corpus for French Political Debates (https://aclanthology.org/2023.findings-emnlp.280/)
- Anthology ID: 2023.findings-emnlp.280 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 인코더-디코더 아키텍처의 발전으로 문서에 대한 추상적 요약 시스템의 성능이 크게 향상되었다. 그러나 최근 몇 년간 대화와 다자간 대화의 요약에 대한 관심이 증가하고 있다.
    2. 이 논문은 프랑스 정치 토론에 대한 데이터셋을 제안하여 다국어 대화 요약 연구에 필요한 리소스를 개선하는 목적으로 한다.
    3. 고품질의 전사 및 주석이 정확하고 효과적인 대화 요약 모델을 훈련하는 데 중요하며, 비영어 언어에서의 대화 요약을 지원하기 위해 다국어 리소스가 필요하다고 강조한다. 또한 최신 기법을 사용한 베이스라인 실험을 제공하고, 대화 요약 분야의 연구를 촉진할 것을 권장하며, 데이터셋을 연구 커뮤니티에 공개하여 다국어 대화 요약의 추가적인 발전을 가능하게 할 것이다.

###### Towards Zero-shot Relation Extraction in Web Mining: A Multimodal Approach with Relative XML Path (https://aclanthology.org/2023.findings-emnlp.281/)
- Anthology ID: 2023.findings-emnlp.281 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 웹 페이지의 급증과 그 구조의 복잡성이 웹 마이닝 모델에 도전을 제기한다. 현재의 방법들은 텍스트 노드들 사이의 관계를 고려하지 못하고, 이에 대한 문제를 해결하기 위해 새로운 방법인 ReXMiner를 제안한다. ReXMiner는 웹 페이지의 Document Object Model (DOM) 트리에서 가장 짧은 상대 경로를 인코딩하여 웹 페이지 내에서 key-value 쌍 추출에 더 정확하고 효율적인 신호를 제공한다.
    2. 또한 ReXMiner는 각 텍스트 노드의 인기도를 고려하여 다른 웹 페이지에서 동일한 텍스트 노드의 발생 빈도를 계산한다. 
    3. 공개적인 벤치마크 실험 결과로써, ReXMiner는 웹 마이닝의 zero-shot 관계 추출 과제에서 최신 기준선보다 우수한 성능을 보여준다.

###### Narrative Style and the Spread of Health Misinformation on Twitter (https://aclanthology.org/2023.findings-emnlp.282/)
- Anthology ID: 2023.findings-emnlp.282 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 서술적 스타일은 소셜미디어에서의 건강 정보 전달에 효과적인 방법이지만, 잘못된 정보가 온라인으로 퍼지고 그것의 부정적인 영향이 커지는 상황에서 서술적 의사소통 스타일과 건강 정보의 불규칙성이 소셜미디어에서의 사용자 참여에 어떤 영향을 미치는지 조사하는 것이 필요하다.
    2. 본 연구에서는 Twitter 컨텍스트에서의 이를 탐구하기 위해, 이전에 어노테이트된 건강 정보의 잘못된 트윗 (약 15,000개)을 사용하고 서술적 스타일의 존재 유무를 어노테이션을 통해 확인하였다. 이후 이러한 레이블을 사용하여 텍스트 분류기를 훈련시키고, 자동 서술 감지를 위해 지도 학습과 인텍스트 학습을 실험했다.
    3. 최고 모형을 사용하여 데이터 집합의 남은 부분을 레이블링 한 뒤, 서술적 스타일, 잘못된 정보 및 사용자 수준 특징과 참여 사이의 관계를 통계적으로 분석하였으며, 서술의 일반적인 언어 범주 및 건강 정보에 대한 잘못된 정보의 범주를 분석하였다.

###### HadSkip: Homotopic and Adaptive Layer Skipping of Pre-trained Language Models for Efficient Inference (https://aclanthology.org/2023.findings-emnlp.283/)
- Anthology ID: 2023.findings-emnlp.283 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사전 훈련된 언어 모델(LMs)은 많은 NLP 작업에서 놀라운 성능을 보여주었지만, 투입되는 자원과 추론에 필요한 높은 계산 비용 때문에 실시간 시스템에 적용하기 어렵다. 
    2. 우리는 기존의 조기 종료 방법들과 달리, 선택된 종료층 이전의 모든 층을 순차적으로 통과해야 하는 제약을 없애고 유연성을 높여 성능을 향상시키기 위해 HadSkip이라는 새로운 레이어 스킵 방법을 제안한다. 
    3. GLUE 벤치마크에서의 실험 결과, 제안된 HadSkip이 모든 최신 기베라인에 비해 우수한 성능을 보여주었다.

###### Empowering Psychotherapy with Large Language Models: Cognitive Distortion Detection through Diagnosis of Thought Prompting (https://aclanthology.org/2023.findings-emnlp.284/)
- Anthology ID: 2023.findings-emnlp.284 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 정신 질환은 전문가의 부족과 접근성 제한으로 인해 현재 가장 중요한 공중 보건 문제 중 하나입니다. 표현력이 뛰어나고 복잡한 추론과 분석을 수행하는 고급 전문성이 필요합니다. 
    2. 우리는 대규모 언어 모델 시대에 인공지능을 통한 심리치료 지원을 개발하기에 적절한 시기라고 생각합니다. 우리는 인식 왜곡(cognitive distortion) 검출 작업을 연구하고, DoT (Diagnosis of Thought) prompting을 제안합니다.
    3. DoT은 환자의 언어를 세 단계로 진단하여 주제 평가, 대조적 추론, 기질 분석을 수행합니다. 이를 통해 전문가들의 지원을 위한 진단 이유를 생성합니다. 실험 결과, DoT은 ChatGPT에 비해 인지 왜곡 감지에서 큰 향상을 보여주며, 인간 전문가가 승인한 고품질 이유를 생성합니다.

###### Measuring the Knowledge Acquisition-Utilization Gap in Pretrained Language Models (https://aclanthology.org/2023.findings-emnlp.285/)
- Anthology ID: 2023.findings-emnlp.285 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사전 훈련된 언어 모델(PLM)이 많은 지식을 습득하는 것을 보여주었으나, 이 파라미터 기반 지식 중 얼마나 실제로 다운스트림 태스크 수행에 활용될 수 있는지는 여전히 불분명하다.
    2. 우리는 PLM에서 파라미터의 지식을 추출하고, 이 추출된 지식을 기반으로 다운스트림 태스크를 구성하는 체계적인 프레임워크를 제안한다.
    3. 우리의 연구 결과는 PLMs의 습득된 지식과 활용된 지식 사이에 차이가 있음을 보여주며, 분포 변화에서의 지식 활용에서 제한된 강건성을 보여주고, 큰 모델일수록 확보된 지식의 차이를 줄이지만 활용된 지식의 차이는 여전하다.

###### Non-compositional Expression Generation Based on Curriculum Learning and Continual Learning (https://aclanthology.org/2023.findings-emnlp.286/)
- Anthology ID: 2023.findings-emnlp.286 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "비구성 표현은 NLP 시스템에 있어서 한계가 있는데, 현재의 신경망 모델, 특히 대규모 사전 훈련 언어 모델에서도 어렵다."
    2. 이 논문은 비구성 표현 생성 과제에서 동적 커리큘럼 학습 프레임워크를 제안하고, 잊혀짐 문제를 완화하기 위해 지속적 학습 방법을 적용한다.
    3. 이러한 방법을 통해 비구성 표현 생성 작업에서 모델의 성능을 점진적으로 개선할 수 있으며, 관용구 생성 및 은유 생성에 대한 실험에서도 유효성을 확인하였다.

###### Information Extraction from Legal Wills: How Well Does GPT-4 Do? (https://aclanthology.org/2023.findings-emnlp.287/)
- Anthology ID: 2023.findings-emnlp.287 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문은 법적 유언에서의 정보 추출 (IE)를 위한 수동으로 주석이 달린 데이터셋을 제시하고, 데이터셋에서 진행된 관련 "in-context learning" 실험을 소개한다. 
    2. 이 데이터셋은 entity, entity 간의 이진 관계, n-ary events (e.g., bequest) 등을 포함하며, 이는 미국의 두 주에서 추출된 45개의 법적 유언으로 구성되어 있다. 
    3. 이 데이터셋은 법률 도메인에서의 하향식 작업에 기반이 될 수 있으며, 대형 언어 모델 (LLMs)의 이 IE 작업에 대한 성능을 평가하는 데에도 활용될 수 있다.

###### Transparency at the Source: Evaluating and Interpreting Language Models With Access to the True Distribution (https://aclanthology.org/2023.findings-emnlp.288/)
- Anthology ID: 2023.findings-emnlp.288 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 인공적인 언어와 비슷한 데이터를 사용하여 신경 언어 모델을 훈련하고 평가하고 해석하기 위한 세팅을 제안한다.
    2. 많은 자연어 코퍼스에서 파생된 상당한 확률적 문법을 사용해서 데이터를 생성하고 이를 통해 훈련과정을 완전히 제어할 수 있다.
    3. 우리의 결과는 신경 언어 모델의 아키텍처와 훈련 목표가 perplexity의 하한에 대해 얼마나 잘 근사할 수 있는지에 대한 놀라운 차이를 보여준다.

###### Continual Generalized Intent Discovery: Marching Towards Dynamic and Open-world Intent Recognition (https://aclanthology.org/2023.findings-emnlp.289/)
- Anthology ID: 2023.findings-emnlp.289 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 일반적인 대화 시스템에서 사용자는 주제 외의 쿼리를 입력할 수 있다. GID 작업은 OOD(Out-of-Domain) 쿼리에서 OOD intents를 발견하고 이를 IND(In-Domain) 분류기에 확장하는 것을 목표로 한다. 
    2. 하지만 GID는 OOD 학습의 일부분만 고려하며, 이전 단계의 데이터를 모두 사용하여 공동 학습해야 하기 때문에 실제 응용에 제한이 있다.
    3. 이 논문에서는 Continuous Generalized Intent Discovery (CGID)라는 새로운 과제를 소개하고, 동적인 OOD 데이터 스트림에서 OOD intents를 지속적으로 발견하고 거의 이전 데이터 없이 분류기에 점진적으로 추가하는 것을 목표로 한다.

###### Frugal Prompting for Dialog Models (https://aclanthology.org/2023.findings-emnlp.290/)
- Anthology ID: 2023.findings-emnlp.290 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델(Large Language Model, LLM)을 자연어처리 태스크에 사용하는 경우가 많아지고 있으며, 이로 인해 연구자들은 문제에 접근하는 방식을 바꿔가고 있다. 이 연구는 LLM을 사용하여 대화 시스템을 구축하는 다양한 접근 방식과 대화 기록의 효율적인 표현에 대해 분석하여 LLM의 상호작용 능력을 이해하는 데 기여한다.
    2. 연구에서는 지침, 예시, 현재 질의, 추가적인 맥락 등의 다양한 prompt 요소를 고려하여 다른 대화 시스템을 구축하는 방법을 실험하였다. 또한, 대화 기록의 표현을 분석하여 유용한 정보 밀도가 최적인 방법을 찾았다.
    3. 연구 결과를 기반으로, 대화 기록 정보를 보다 간결하게 제공하면서 성능을 유지하고 모델의 추론-API 비용을 줄일 수 있는 방법을 제안하였다. 이 연구는 LLM을 효과적으로 대화 시스템 구축에 활용하는 데 도움이 되는 내용을 제시한다.

###### The Interpreter Understands Your Meaning: End-to-end Spoken Language Understanding Aided by Speech Translation (https://aclanthology.org/2023.findings-emnlp.291/)
- Anthology ID: 2023.findings-emnlp.291 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 현재의 대형 사전 훈련 언어 모델을 사용하여도, 다양한 언어의 경우에도 엔드 투 엔드 음성 언어 이해 (SLU)를 실현하는 것은 여전히 어렵다. 음성 모델에는 낮은 수준의 음향 프레임에서 작동하는 것이 원하는 상위 의미와 다른 언어 간의 연결을 포착할 수 있도록 하므로 기계 번역은 문자 기반으로 강력한 사전 훈련 목표로서 확립되어 있다.
    2. 우리는 특히 다국어 SLU 작업에서 음성 번역 (ST) 작업을 통해 엔드 투 엔드 SLU를 사전 훈련할 수 있는 좋은 방법임을 보여준다. ST를 도입함으로써 우리의 모델은 SLURP, MINDS-14, NMSQA 벤치마크를 사용한 단일 및 다국어 의도 분류 및 음성 질문 답변에서 기준 모델보다 더 좋은 성능을 달성한다.
    3. 우리의 방법의 효과를 검증하기 위해, 우리는 음성 요약 및 영어에서 프랑스어 또는 스페인어로의 저자원/제로샷 전이를 위한 합성 및 실제 원본에서 새로운 벤치마크 데이터셋을 생성하였으며, 더 나은 후속 성능을 위해 ST 사전 훈련 작업에 대한 지식을 보존하는 가치를 보여주고자 한다.

###### MacLaSa: Multi-Aspect Controllable Text Generation via Efficient Sampling from Compact Latent Space (https://aclanthology.org/2023.findings-emnlp.292/)
- Anthology ID: 2023.findings-emnlp.292 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 multi-aspect controllable text generation 방법들은 디코딩 단계에서 비싼 반복과 탐색을 요구했거나, 각각의 속성을 위해 별도의 컨트롤러를 훈련시키는 문제점이 있어서 다양한 속성 간의 불일치로 인해 텍스트의 품질이 저하된다.
    2. 이 논문에서는 MacLaSa라는 새로운 multi-aspect 제어 방식을 제안하는데, 이 방식은 여러 속성에 대한 압축된 잠재 공간을 추정하고 빠른 샘플러를 사용하여 효율적인 샘플링을 수행한다.
    3. 실험 결과로는 MacLaSa가 속성의 관련성과 텍스트의 품질 모두에서 강력한 기준을 능가하면서도 높은 추론 속도를 유지한다는 것을 보여준다.

###### HPE: Answering Complex Questions over Text by Hybrid Question Parsing and Execution (https://aclanthology.org/2023.findings-emnlp.293/)
- Anthology ID: 2023.findings-emnlp.293 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "텍스트 기반 질문 응답 시스템의 우세한 패러다임은 자연어 질문에 능숙하게 대응하지만 복잡한 질문에는 한계가 있다. 이에 대조적으로, 구조화된 데이터 소스 (ex. 관계형 데이터베이스, 지식 그래프) 상에서 의미 파싱 접근방식의 널리 사용으로 자연어 질문을 논리적 형태로 변환하고 질의 엔진으로 실행하는 것이 이루어진다."
    2. "우리는 신경망 모델과 심볼릭 방법의 간다한 점을 결합하기 위해 텍스트 기반 질문 파싱 및 실행 프레임워크를 제안한다."
    3. "제안된 프레임워크는 질문 파싱과 하이브리드 실행으로 구성되어 있으며, 해석 가능성을 높이고 심볼릭 연산의 이점을 유지하면서 기본 구성 요소를 해결하기 위해 신경망 판독기를 사용한다."

###### Length-Adaptive Distillation: Customizing Small Language Model for Dynamic Token Pruning (https://aclanthology.org/2023.findings-emnlp.294/)
- Anthology ID: 2023.findings-emnlp.294 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사전 훈련된 언어 모델의 성능을 향상시키기 위해 모델 압축과 동적 계산 방법이 연구되었으나, 이 두 가지 방법은 따로 개발되어 동적 계산에 최적화된 모델을 만들기 어렵다. 
    2. 길이 적응적 지식 증류 (Length-Adaptive Distillation)라는 이름의 새로운 방법을 제안하여 동적 토큰 가지치기에 적합한 작은 언어 모델을 만드는데 집중한다. 
    3. 실험적 결과는 우리의 방법이 동적 토큰 가지치기에 최적화된 작은 언어 모델을 만들고 속도 및 성능의 균형을 향상시킬 수 있음을 보여준다.

###### Toxicity, Morality, and Speech Act Guided Stance Detection (https://aclanthology.org/2023.findings-emnlp.295/)
- Anthology ID: 2023.findings-emnlp.295 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 본 논문은 소셜 미디어 플랫폼에서 논의되는 다양한 사회 문제에 대한 대중의 태도를 판단하는 작업에 초점을 맞추고 있다. 그러나 트위터와 같은 플랫폼은 종종 극단적인 견해로 오인정보나 가짜 뉴스를 퍼뜨리는 데 사용되며, 톡실한 대화는 부정적인 영향을 퍼뜨려 사회 문제 해결을 지연시킨다.
    2. 이전 연구들은 대개의 경우 트윗의 태도를 캡처하는 데 도움이 될 수 있는 톡실성, 도덕성, 이사회 특징을 무시하거나, 대상에 걸친 태도를 감지할 수 있는 효율적인 아키텍처를 잊고 있는 것으로 나타났다.
    3. 따라서 우리의 연구에서는 톡실성, 도덕성, 이사회 특징을 공유하는 공유 피쳐를 사용하여 트윗의 태도를 정확하게 감지하기 위해 감정, 도덕성, 톡실성과 같은 보조 작업을 활용하는 다중 작업 모델 TWISTED를 제안한다.

###### Reasoning about Ambiguous Definite Descriptions (https://aclanthology.org/2023.findings-emnlp.296/)
- Anthology ID: 2023.findings-emnlp.296 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자연어 추론은 언어모델의 복잡한 언어이해 과제를 해결하는 데에 점점 더 중요한 역할을 하고 있으며, 추론 기능을 통해 문맥 의존적인 모호함을 해결하는 것이 흥미로운 사례로 등장하고 있다.
    2. 우리는 문맥을 이해하기 위해 명시적 추론을 얼마나 잘 활용할 수 있는지 평가하기 위해 모호한 정확한 표현을 사용하는 것을 제안하고 이를 위한 첫 번째 벤치마크 데이터셋을 제작하고 공개한다.
    3. 우리의 방법은 문제의 모호함을 해결하는 데 필요한 모든 정보를 포함하고 있으므로 모델은 추론 외에 다른 것을 요구하지 않아도 성능이 잘 나온다. 최근의 언어 모델에 대해서도 이는 도전적인 과제임을 확인했다.

###### A Framework for Bidirectional Decoding: Case Study in Morphological Inflection (https://aclanthology.org/2023.findings-emnlp.297/)
- Anthology ID: 2023.findings-emnlp.297 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 텍스트 시퀀스에 대한 sequence-to-sequence 작업에서, 기존의 좌에서 우로 생성하는 Transformer 기반 모델 대신 외부에서 내부로 시퀀스를 생성하는 디코딩 프레임워크를 제안한다. 
    2. 이러한 방식은 이전의 양방향 디코더보다 더 원칙적이라고 주장하며, 모델 아키텍처를 지원하고, 잠재적인 순서 변수를 고려하는 동적 프로그래밍 알고리즘과 같은 여러 훈련 방법을 포함한다.
    3. 제안된 모델은 최신의 SOTA 성능을 보여주며, 특히 긴 시퀀스에 대해서 우수한 성능을 보이고, 어간과 접사로 이루어진 단어의 분리점을 암묵적으로 학습하며, 고유한 레마가 적은 데이터셋에서 기준선에 비해 더 나은 성능을 보인다.

###### Text-guided 3D Human Generation from 2D Collections (https://aclanthology.org/2023.findings-emnlp.298/)
- Anthology ID: 2023.findings-emnlp.298 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 3D 인간 모델링은 게임, 영화, 애니메이션에서 적극적인 상호작용을 위해 폭넓게 사용되고 있다. 이 논문에서는 텍스트에 의해 동작하는 3D 인간 생성 모델을 제안한다. 
    2. 이 모델은 두 가지 목표가 있다. 3D 인간의 처리가 정확해야 하며, 의상은 주어진 텍스트로 제어되어야 한다. 
    3. Cross-modal attention을 사용하는 CCH 모델을 도입하여 3D 인간의 렌더링과 패션 의미를 결합하여 모델링하였으며, 실험 결과는 우수한 성능을 보인다.

###### Statistically Profiling Biases in Natural Language Reasoning Datasets and Models (https://aclanthology.org/2023.findings-emnlp.299/)
- Anthology ID: 2023.findings-emnlp.299 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 연구에서는 많은 자연어 이해 및 추론 데이터셋이 NLP 모델에 의해 활용되는 통계적 단서를 가지고 있으며, 이로 인해 그들의 능력이 과대평가되고 있다는 것을 보여준다. 
    2. 기존 방법들은 이러한 편향을 식별하고 모델의 약점을 평가하는 데 제한이 있다. 
    3. 이 논문에서는 추가 테스트 케이스를 필요로하지 않으면서도 다중 선택 NLU 데이터셋에서 잠재적인 편향을 자동으로 식별할 수 있는 경량, 일반적인 통계 프로파일링 프레임워크(ICQ)를 소개한다.

###### Verb Conjugation in Transformers Is Determined by Linear Encodings of Subject Number (https://aclanthology.org/2023.findings-emnlp.300/)
- Anthology ID: 2023.findings-emnlp.300 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Transformer와 같은 딥 아키텍처는 해석하기 어려운 "black-box" 표현으로 비판받을 때가 있다. 
    2. 우리는 인과적 개입 분석을 사용하여 언어적 특징이 일부 선형적이고 해석 가능한 형식으로 표현된다는 것을 보여준다. 
    3. 특히, 우리는 BERT의 동사 활용 능력이 주어의 수에 대한 선형 인코딩에 의존하며, 이는 동사 위치에서 마지막 레이어에서, 특히 주어의 수에 대한 여러 신호가 있는 경우 중간 레이어에서 위치별로 분산된다는 것을 보여준다.

###### MUX-PLMs: Data Multiplexing for High-throughput Language Models (https://aclanthology.org/2023.findings-emnlp.301/)
- Anthology ID: 2023.findings-emnlp.301 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. ChatGPT와 Bard와 같은 대규모 언어 모델의 널리 퍼짐은 이러한 기술에 대한 전례 없는 수요를 불러왔다. 하지만 점점 커지는 모델 크기에 따라 증가하는 추론 비용과 하드웨어 부족은 접근성을 제한하고, 고효율을 위한 효율 접근 방식이 절실하게 필요하다. 
    2. 여러 개의 입력 및 출력 (MIMO) 알고리즘은 데이터 다중화와 같은 방법을 통해 신속한 처리량의 수행을 통해 한 입력의 비용으로 여러 개의 입력에 대한 추론이 가능한 해결책을 제공한다. 그러나 현재 이러한 방법은 현대적 시스템에 배포하기에 충분히 효율적이지 않다. 
    3. 우리는 MUX-PLMs라는 클래스의 고처리량 사전 훈련 언어 모델 (PLMs)을 개발하여 원하는 하위 작업에 대해 고처리량 및 고성능을 제공하기 위해 데이터 다중화와 함께 훈련할 수 있다. 우리의 신규 다중화 및 복구 모듈은 입력을 효과적으로 혼합하고 분리하여 vanilla PLMs와 경쟁력이 있으면서도 1-4 %의 성능 하락만으로도 추론 속도를 2배/5배 향상시킬 수 있는 MUX-PLMs를 제공한다.

###### That was the last straw, we need more: Are Translation Systems Sensitive to Disambiguating Context? (https://aclanthology.org/2023.findings-emnlp.302/)
- Anthology ID: 2023.findings-emnlp.302 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 모호한 텍스트의 번역은 번역 시스템에 동떨어진 문맥을 가능한 한 명확하게 하는 도전적인 과제이다.
    2. 이전 연구들은 언어 특징에 따른 문법적 모호성에 주목해 왔으나, 이 논문에서는 영어 원문 자체에서 나타나는 의미적 모호성에 초점을 맞춘다.
    3. 기존 MT 모델들은 문맥이 비유적 해석을 시사하는 경우에도 영어 관용구를 일관되게 독자적으로 번역하나, LMs는 문맥에 대해 훨씬 더 인식하며 대상 언어에 따라 성능 격차가 남아있다는 결론을 얻었다. LMs은 context-aware translation을 위한 강력한 기반이 될 수 있다.

###### MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic (https://aclanthology.org/2023.findings-emnlp.303/)
- Anthology ID: 2023.findings-emnlp.303 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. '이해의 이론'은 지능의 중요한 구성 요소이지만, 그 평가는 아직 많은 논란의 대상이다.
    2. 이전 연구에서는 인공지능 모델에 인간 창의/Perspective of intelligence (ToM)을 적용하기 위해 인간이 만든 표준화된 테스트나 규칙 기반의 템플릿을 사용했다.
    3. 이 논문에서는 ToM의 특정 구성 요소를 분리하기 위해 동적 지식 로직을 활용하고, 이러한 문제를 영어로 표현하기 위해 새로운 언어 표현 기법을 소개한다.

###### LATENTLOGIC: Learning Logic Rules in Latent Space over Knowledge Graphs (https://aclanthology.org/2023.findings-emnlp.304/)
- Anthology ID: 2023.findings-emnlp.304 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 지식 그래프 추론을 위한 논리 규칙 학습은 해석 가능한 설명과 다양한 도메인에 일반화가 가능하다는 장점이 있지만, 기존 방법들은 거대한 탐색 공간에서 검색하는 것이 어렵고, 비효율적인 최적화 기법이 사용된다는 어려움이 있다.
    2. 이 논문에서는 LatentLogic이라는 새로운 프레임워크를 제안하여 잠재 공간에서 규칙을 생성함으로써 논리 규칙을 효율적으로 발견하는 방법을 소개한다.
    3. 벤치마크 데이터셋에 대한 실험 결과, 제안한 방법의 효과와 효율성을 입증하였다.

###### RobustEmbed: Robust Sentence Embeddings Using Self-Supervised Contrastive Pre-Training (https://aclanthology.org/2023.findings-emnlp.305/)
- Anthology ID: 2023.findings-emnlp.305 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사전 훈련된 언어 모델(PLM)은 다양한 자연어 처리 태스크에서 우수한 성능을 보여주었지만, 새로운 샘플에 대해 일반화가 잘 되지 않고 적대적인 시나리오에서의 견고성이 부족하다. 
    2. 이 논문에서는 RobustEmbed라는 자기 지도 학습 문장 임베딩 프레임워크를 제안하여 다양한 텍스트 표현 과제에서의 일반화와 적대적 공격에 대한 견고성을 강화한다.
    3. 실험 결과는 RobustEmbed가 적대적 상황에서 이전 최고 성능 모델보다 우수한 성능을 보인다는 것을 확인하였으며, 의미적 텍스트 유사성(STS) 태스크와 전이 태스크에서도 상대적인 개선을 나타냈다.

###### More than Votes? Voting and Language based Partisanship in the US Supreme Court (https://aclanthology.org/2023.findings-emnlp.306/)
- Anthology ID: 2023.findings-emnlp.306 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 미국 대법원에서 공정성에 대한 정당성과 이념의 유통성과 역학을 이해하는 것은 법관구역 연구를 위해 중요하다. 
    2. 이 논문에서는 대법원 변론에서 법관들의 언어 분석을 통해 정당 선호도를 연구하고, 이를 투표 패턴과의 일치와 비교한다. 
    3. 결과적으로, 법관들의 언어적 정당성과 투표 이념 사이에 강한 상관관계가 있다는 것을 보였다.

###### Automatic Evaluation of Attribution by Large Language Models (https://aclanthology.org/2023.findings-emnlp.307/)
- Anthology ID: 2023.findings-emnlp.307 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 대형 언어 모델 (LLM) 개발은 외부 참조를 통해 생성된 문장의 근거를 생성하고 지원하는 것에 초점을 맞추고 있다. 하지만 생성된 문장이 인용된 참조에 완전히 의해 지지되는지를 검증하는 attribution 평가는 여전히 미해결된 문제이다.
    2. 이 논문에서는 LLM이 제공한 attribution을 자동 평가하는 두 가지 접근 방법을 탐구한다. 첫째, LLM을 prompt시켜서 평가하는 방법과, 둘째, 작은 크기의 LLM을 fine-tuning시켜서 평가하는 방법을 사용한다.
    3. 우리는 generative search engine인 New Bing의 12개 도메인으로 구성된 테스트 샘플을 수동으로 준비하여, 이러한 중요한 문제에 대한 미래 연구의 기반을 마련하기 위한 문제 정의, 테스트 베드 및 결과를 제공한다.

###### Modeling Highlighting of Metaphors in Multitask Contrastive Learning Paradigms (https://aclanthology.org/2023.findings-emnlp.308/)
- Anthology ID: 2023.findings-emnlp.308 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "시간을 함께 보내다"와 같은 은유적인 언어는 의미를 돈(source domain)에서 시간(target domain)으로 옮기며, 이를 통해 시간 투자의 노력과 같은 특정 측면을 강조한다. 이 논문에서는 은유적인 문장에서 강조된 주요 측면을 식별하는 작업을 소개하고, 강조된 측면과 소스 도메인을 함께 예측하는 다중 작업 접근 방식을 제안한다.
    2. 소스 도메인과 강조된 측면 간의 상호작용을 고려하여, 사전 훈련된 대조 학습 모델을 기반으로 한 공동 학습 접근 방식과 지속적 학습 접근 방식을 제안한다.
    3. 실험 결과는 소스 도메인에 대한 정보가 강조된 측면을 예측하는 데 더 나은 성능을 발휘하며, 그 반대의 경우도 마찬가지라고 보여주었다.

###### LDM2: A Large Decision Model Imitating Human Cognition with Dynamic Memory Enhancement (https://aclanthology.org/2023.findings-emnlp.309/)
- Anthology ID: 2023.findings-emnlp.309 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델 (LLM)의 빠른 발전에 따라 인공 일반 지능을 가능하게 하기 위해 LLM을 사용하여 결정을 내릴 수 있는 요구가 높아졌다. 여러 기존 방법들은 사람의 결정 과정을 모방하도록 LLM을 촉발시키기 위해 수동으로 제작된 예제를 활용한다. 
    2. 그러나 최적의 프롬프트를 설계하는 것은 어렵고 패턴화된 프롬프트는 더 복잡한 환경에 일반화되기 어렵다. 
    3. 본 논문에서는 LDM2라는 새로운 모델을 제안한다. 이 모델은 동적 메모리 메커니즘을 활용하여 동적 프롬프트를 구성하고, 현재 상태에 따라 LLM을 적절한 결정을 내리도록 안내한다. 두 단계로 구성된 LDM2는 인간의 행동을 LLM의 강력한 요약 능력을 활용하여 상태-액션 튜플로 분해하여 메모리에 저장하고, 현재 상태를 기반으로 가장 관련있는 일부 튜플을 검색할 수 있도록 LLM에 의해 생성된 인덱스로 이루어진 메모리를 사용한다. 이후, LDM2은 더 적합한 결정 과정을 발견하고 가치 있는 상태-액션 튜플을 추가하여 메모리를 보강하기 위해 트리 탐색을 사용한다. 탐색과 메모리 강화의 동적 순환은 LDM2가 전역 환경을 더 잘 이해할 수 있게 한다.

###### ZARA: Improving Few-Shot Self-Rationalization for Small Language Models (https://aclanthology.org/2023.findings-emnlp.310/)
- Anthology ID: 2023.findings-emnlp.310 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. end-task 답변과 자유로운 텍스트 설명을 동시에 생성하는 언어 모델 (LM)을 self-rationalization 모델이라고 하는데, 최근의 연구에서는 rationale이 포함된 예시로 few-shot prompting LMs를 사용하여 self-rationalization의 큰 성능 향상을 보였다.
    2. 그러나 이러한 설명을 활용하는 능력은 대규모 LMs에만 나타나며, 접근성이 낮은 것으로 알려져 있다.
    3. 이 논문에서는 작은 LMs에 대한 설명 활용을 탐구하며, plausibility judgment 문제를 자연 언어 추론으로 감소시킴으로써 자가 교육을 위한 pseudo-parallel 데이터를 자동으로 구성하는 ZARA라는 새로운 접근 방식을 제안한다.

###### ToxicChat: Unveiling Hidden Challenges of Toxicity Detection in Real-World User-AI Conversation (https://aclanthology.org/2023.findings-emnlp.311/)
- Anthology ID: 2023.findings-emnlp.311 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화형 AI 모델들은 최근 많은 발전을 보였지만, 비독성 사용자-인공지능 상호작용 환경 유지는 점점 중요해지고 있다. 그러나 이전 연구들은 대부분 소셜미디어 콘텐츠에서 파생된 벤치마크에 기반해 왔으며, 실제 사용자-인공지능 상호작용에서의 독특한 도전들은 충분히 탐구되지 않아왔다.
    2. 본 연구에서는 오픈소스 챗봇의 실제 사용자 질문을 기반으로 한 새로운 벤치마크인 ToxicChat을 소개한다. 이 벤치마크는 현재 독성 감지 모델에게 어려움을 줄 수 있는 다양하고 미묘한 현상을 포함하고 있으며, 소셜미디어 콘텐츠와 비교할 때 상당한 도메인 차이를 보여준다.
    3. 기존 독성 데이터셋으로 학습된 모델들을 ToxicChat에 적용한 결과, 그들의 한계점이 드러났다. 이 연구는 실제 사용자-인공지능 대화에서 독성 감지의 잠재적으로 간과되는 도전들을 밝혀주며, ToxicChat은 사용자-인공지능 상호작용에 안전하고 건전한 환경을 구축하기 위한 추가적인 발전을 이끌기 위한 가치 있는 자원이 될 수 있다.

###### Mind the Gap: Automated Corpus Creation for Enthymeme Detection and Reconstruction in Learner Arguments (https://aclanthology.org/2023.findings-emnlp.312/)
- Anthology ID: 2023.findings-emnlp.312 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 강한 주장을 작성하는 것은 학습자에게 어려울 수 있으며, 학습자들은 논증을 이해하기 어려울 수 있다. 이 논문에서는 학습자의 주장에 빠진 ADU(Argumentative Discourse Unit)가 있는지 감지하고 채우는 두 가지 새로운 작업을 소개한다.
    2. 확립하지 않은 ADU의 부재는 논리적 흐름을 이해하지 못하게 만들 수 있다. 학습자의 인수의 질을 향상시키기 위해 이러한 작업들을 연구한다.
    3. ICLEv3 corpus에서 ADU를 삭제하여 감소시키는 방식으로 인수의 부재를 감지하고 복원하는 작업을 자동으로 수행하는 방식을 제시하였으며, 이를 통해 다양한 baseline 접근 방식을 검토하였다.

###### Dior-CVAE: Pre-trained Language Models and Diffusion Priors for Variational Dialog Generation (https://aclanthology.org/2023.findings-emnlp.313/)
- Anthology ID: 2023.findings-emnlp.313 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 변분 대화 모델은 사전 훈련된 언어 모델을 사용하여 가능도 및 사후 분포를 파라미터화하였다. 그러나 사전 분포에 대한 가우시안 가정은 이러한 분포와 호환되지 않으므로 생성된 응답의 다양성을 제한한다.
    2. 이 논문에서는 이러한 도전에 대처하기 위해 확산 사전을 사용하는 계층적 조건부 변분 오토인코더(CVAE)인 Dior-CVAE를 제안한다. 우리는 확산 모델을 사용하여 사전 분포의 복잡성을 증가시키고, PLM에 의해 생성된 분포와의 호환성을 확보한다.
    3. 또한, 우리는 응답 생성을 위해 latent 변수의 사용을 적극적으로 장려하기 위해 cross-attention 메커니즘에 메모리 드롭아웃을 제안한다. 실험 결과, 대화 사전 훈련 없이도 더 다양한 응답을 생성할 수 있는 것을 보여주었다.

###### Retrieving Multimodal Information for Augmented Generation: A Survey (https://aclanthology.org/2023.findings-emnlp.314/)
- Anthology ID: 2023.findings-emnlp.314 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델(Large Language Model, LLM)이 인기를 얻으면서, 다양한 형태의 지식을 활용하여 LLM의 생성 능력을 향상시키는 것이 중요한 동향이 되었지만, 어떤 단계에서 어떻게 다양한 형태의 모달리티를 통합해야 하는지에 대한 통일된 인식이 부족하다.
    2. 이 논문에서는 이미지, 코드, 테이블, 그래프, 오디오와 같은 형태의 다중모달 지식을 검색하여 생성 모델을 보조하고 향상시키는 방법을 조사한다. 이러한 방법들은 사실성, 추론, 해석 가능성, 강건성과 같은 중요한 문제에 대한 유망한 해결책을 제공한다.
    3. 이 조사를 통해 기존 기법을 LLM 분야에 적용하기 위해 스칼라들에게 깊은 이해를 제공하고 그 응용 방법에 대한 이해를 높여줄 것으로 기대된다.

###### Improving Contrastive Learning of Sentence Embeddings with Focal InfoNCE (https://aclanthology.org/2023.findings-emnlp.315/)
- Anthology ID: 2023.findings-emnlp.315 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. SimCSE의 원래 공식은 contrastive learning에서 hard negative 샘플의 잠재력을 충분히 활용하지 못한다. 
    2. 이 연구는 SimCSE와 hard negative mining을 결합한 비지도형 contrastive learning 프레임워크를 소개하여 문장 임베딩의 품질을 향상시키고자 한다. 
    3. 다양한 STS 벤치마크에서의 실험결과, 우리의 방법은 Spearman 상관관계 및 표현 정렬 및 일관성의 관점에서 문장 임베딩을 개선시킨다.

###### The Vault: A Comprehensive Multilingual Dataset for Advancing Code Understanding and Generation (https://aclanthology.org/2023.findings-emnlp.316/)
- Anthology ID: 2023.findings-emnlp.316 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "The Vault"은 여러 프로그래밍 언어로 된 고품질 코드-텍스트 쌍의 오픈소스 데이터셋으로, 대용량 언어 모델이 코드를 이해하고 생성하는 데 사용된다. 
    2. 이 논문에서는 규칙과 딥러닝을 사용하여 고품질의 코드-텍스트 쌍을 추출하는 방법을 제안하고, 결과적으로 4300만 개의 고품질 코드-텍스트 쌍 데이터셋을 구축했다. 
    3. 이 데이터셋을 사용하여 다양한 코드 언어 모델을 학습시킬 때 다른 데이터셋보다 우수한 성능을 보이며, 코드 생성, 코드 요약, 코드 검색과 같은 일반적인 코딩 작업에 활용될 수 있다.

###### SDOH-NLI: a Dataset for Inferring Social Determinants of Health from Clinical Notes (https://aclanthology.org/2023.findings-emnlp.317/)
- Anthology ID: 2023.findings-emnlp.317 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "건강결과에 영향을 주는 사회적 및 행동적 결정인자(SDOH)는 건강관리자가 적절한 치료 기회를 식별하고 격차를 해소하기 위해 체계적으로 식별할 수 있도록 돕는 첫 번째 단계이다. 그러나 진전은 실제 환자 정보의 개인정보 및 규제 제약으로 인해 공개적으로 사용 가능한 고품질 레이블 데이터 부족으로 지체되고 있다. 본 논문에서는 공개적으로 사용 가능한 기록을 기반으로하는 새로운 데이터 세트인 SDOH-NLI를 소개하고 공개한다."
    2. "우리는 SDOH 추출을 자연어 추론(natural language inference) 작업으로 정의하고, 사회적인 이력 스니펫과 SDOH 요소의 교차 제품을 가정으로하는 바이너리 텍스트 함의 레이블을 인간 평가자에서 얻었다."
    3. "우리는 "off-the-shelf" 함의 모델뿐만 아니라 우리의 데이터로 fine-tuning한 모델을 평가하고, 우리의 데이터 세트가 일반적으로 사용되는 NLI 데이터 세트보다 어려운 점을 강조한다."

###### On the Zero-Shot Generalization of Machine-Generated Text Detectors (https://aclanthology.org/2023.findings-emnlp.318/)
- Anthology ID: 2023.findings-emnlp.318 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 인간이 쓴 텍스트와 구별하기 힘든 정도로 자연스러운 큰 언어 모델들의 만연 현상은 기계 생성 텍스트의 탐지를 전례 없이 중요하게 한다.
    2. 이 논문은 중요한 연구 질문으로 진행되며, 기계 생성자가 훈련되지 않은 새로운 생성자 출력에서 기계 생성 텍스트 탐지기의 성능이 어떻게 나올지 알아보고 있다.
    3. 실험 결과로는 모든 탐지기가 일반화되지는 않지만, 중간 크기 모델의 데이터로 훈련된 탐지기가 큰 버전에 대해 제로샷(zero-shot) 일반화가 가능하다는 일관된 흥미로운 패턴을 관찰할 수 있었다.

###### Complex Event Schema Induction with Knowledge-Enriched Diffusion Model (https://aclanthology.org/2023.findings-emnlp.319/)
- Anthology ID: 2023.findings-emnlp.319 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 복잡한 이벤트 스키마의 개념은 이벤트와 그들의 다차원적인 관계를 나타내는 그래프 구조를 가리키며, 그러나 이전의 이벤트 스키마 인덕션 연구는 오류 전파와 데이터 품질 문제로 인해 어려움을 겪었습니다.
    2. 이러한 도전에 대응하기 위해, 우리는 지식-풍부한 이산확산 모델을 제안합니다. 우리는 대용량 언어 모델(Large Language Models, LLMs)의 풍부한 이벤트 시나리오 지식을 파이썬 스타일의 prompt를 통해 추출하여 훈련 데이터에 통합시킵니다. 
    3. 또한, 오류 전파 문제를 해결하기 위해 자기회귀적이지 않은 방식으로 이산확산 과정을 사용하여 동시에 모든 노드와 링크를 생성하고, 이벤트 아규먼트 간의 entity relationship 예측 모듈을 개발합니다. 실험 결과, 우리의 접근 방식은 다양한 평가 메트릭에서 뛰어난 성능을 달성합니다.

###### Exploiting Emotion-Semantic Correlations for Empathetic Response Generation (https://aclanthology.org/2023.findings-emnlp.320/)
- Anthology ID: 2023.findings-emnlp.320 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "공감 대화 생성은 대화의 언어에서 발화자의 감정을 이해하여 공감적인 응답을 생성하는 것을 목표로 한다. 하지만 최근 연구들은 감정 단어들을 정적인 벡터로만 취급하여 세밀한 감정을 파악하기 어렵게 한다. 그래서 우리는 감정 단어들이 문법 의미론적인 다른 역할과 상관관계를 가지고 있다고 보고, 문맥과 감정의 상호작용을 통해 동적인 감정-의미 벡터를 생성하는 모델을 제안한다."
    2. "우리의 모델은 문맥과 감정의 상호작용을 반영하기 위해 의존성 트리를 도입하고, 동적인 감정-의미 벡터와 의존성 트리를 기반으로 다이내믹한 상관 그래프 합성곱 신경망을 제안한다."
    3. "실험 결과, 우리의 모델은 문맥과 감정을 더 정확하게 이해하고 유창하고 정보가 풍부한 공감적인 응답을 생성한다. 또한, 분석 결과는 감정과 의미 사이의 상관관계가 대화에서 자주 사용되며, 공감적 지각과 표현에 큰 의미가 있다는 것을 보여준다."

###### Long-Range Language Modeling with Selective Cache (https://aclanthology.org/2023.findings-emnlp.321/)
- Anthology ID: 2023.findings-emnlp.321 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 트랜스포머 기반 언어 모델은 시퀀스 길이에 따라 계산 비용이 제곱으로 증가한다. 그러므로 이 연구에서는 이전 문맥으로부터 선택적으로 중요한 key-value 쌍을 저장하는 셀렉티브 캐시를 도입하였다. 이 캐시를 잘 활용함으로써 한정된 캐시 크기 내에서 더 긴 문맥 이력을 저장할 수 있게 되었다.
    2. 사람의 언어 처리 실험을 통해 fixated token에 대응하는 key-value 쌍을 선택하여 셀렉션하는 첫 번째 방법을 설계하였다. 또한, 이러한 인지적인 선택 프로세스를 훈련 가능한 과정으로 언어 모델에 통합하여 성능을 개선했다.
    3. 제안된 셀렉티브 캐시는 다양한 데이터셋에서 언어 모델링 성능을 향상시키는 것을 입증하였다. 동일한 저장된 key-value 쌍(캐시 크기)으로 비교했을 때, 셀렉티브 캐시는 XL 캐시와 압축 캐시보다 상당한 차이로 우수한 결과를 보였다.

###### Medical Text Simplification: Optimizing for Readability with Unlikelihood Training and Reranked Beam Search Decoding (https://aclanthology.org/2023.findings-emnlp.322/)
- Anthology ID: 2023.findings-emnlp.322 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 의학 분야에서의 텍스트 간소화는 기술 용어와 복잡한 구조로 인해 의사소통을 개선하는 데 더욱 유용한 AI 응용 프로그램으로 등장했으나, 의학 간소화 방법은 생성된 텍스트의 품질과 다양성이 낮을 수 있다.
    2. 이 연구에서는 의료 분야에서 텍스트 간소화의 읽기 가능성을 더욱 향상시키기 위한 방법을 탐색한다.
    3. 우리는 (1) 간소한 용어 생성을 장려하는 새로운 비실제손실, (2) 단순성을 최적화하는 재순위 빔 서치 디코딩 방법을 제안하였으며, 세 개의 데이터셋에서 가독성 측정 지표에서 더 좋은 성능을 달성한다.

###### FaLA: Fast Linear Adaptation for Replacing Backbone Models on Edge Devices (https://aclanthology.org/2023.findings-emnlp.323/)
- Anthology ID: 2023.findings-emnlp.323 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문에서는 비정상적인 On-device 시나리오에서 개인화된 다운스트림 작업을 위한 언어 모델 백본 교체 문제를 연구한다.
    2. 기존의 전체 모델 튜닝이나 전이 학습은 로컬 디바이스의 훈련 비용을 상당히 소모하고, 심층 변환기 레이어 내에서 광범위한 역전파를 요구한다. 
    3. 이 문제를 해결하기 위해 우리는 백본 교체 후 개인화된 NLP 분류 작업을 위한 경량화된 튜닝 방법을 제안한다. 이 방법은 사용자의 이전 및 새로운 백본에 해당하는 문서에서 계산된 개인화된 행렬을 활용하여 상위 레이어 매개변수 튜닝을 수행하고, 역전파 계산을 크게 줄인다.

###### Intuitive Multilingual Audio-Visual Speech Recognition with a Single-Trained Model (https://aclanthology.org/2023.findings-emnlp.324/)
- Anthology ID: 2023.findings-emnlp.324 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다국어 음성-시각 인식 작업에 대한 신규 접근법을 제시하여, 멀티리근 데이터셋에서 단일 모델을 소개한다. 인간의 인지 체계에서 사람들은 어떠한 의식적인 노력이나 안내 없이도 다른 언어를 직관적으로 구별할 수 있는데, 이런 특성을 반영하여 언어들 사이의 내재적인 유사성과 차이를 구별하는 모델을 제안한다. 
    2. 우리는 대부분 사전 훈련된 음성-시각 표현 모델에 prompt fine-tuning 기술을 도입하여 네트워크가 언어 분류와 해당 언어로 된 음성을 인식할 수 있도록 한다.
    3. 우리의 연구는 강건하고 효율적인 다국어 음성-시각 인식 시스템을 개발하는 데 기여하며, 언어별 모델의 필요성을 줄인다.

###### Controllable Chest X-Ray Report Generation from Longitudinal Representations (https://aclanthology.org/2023.findings-emnlp.325/)
- Anthology ID: 2023.findings-emnlp.325 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "방사선학 보고서는 의료 검사 결과의 세부 텍스트 설명이다. 각 보고서는 관련 임상 소견의 존재/부재와 위치를 기술하며, 보통 같은 환자의 이전 검사와 비교하여 진화하는 과정을 설명한다. 자동 보고 시스템을 통합하여 보고 속도를 높이는 전략 중 하나는 있으나, 임상 적합성을 위해서는 높은 정확성과 해석 가능성이 필요하다."
    2. "기존의 방사선학 자동 보고 접근 방식은 대체로 이전 검사를 입력으로 제공하지 않아 일부 유형의 검사에서 필요한 비교를 할 수 없으며, 해석 가능성에 불신불명의 방법만 제공한다."
    3. "이 논문에서는 기존의 해부학 토큰을 이용한 시각적 입력 형식을 활용하여 (1) 종단적인 표현 학습 - 이전 검사를 추가 입력으로 활용하여 현재와 이전의 시각적 정보를 합쳐서 보고서 생성 모델에 제공하는 방법을 제안하고, (2) 문장-해부학 dropout - 원본 보고서의 문장 중 입력으로 제공된 해부학 영역에 해당하는 문장만을 예측하도록 모델을 훈련시키는 훈련 전략을 소개한다. MIMIC-CXR 데이터셋을 활용한 실험을 통해 제안된 접근 방식이 최고 수준의 결과를 달성하면서 해부학별 제어 가능한 보고서 생성을 가능케 한다."

###### Is ChatGPT a Good Multi-Party Conversation Solver? (https://aclanthology.org/2023.findings-emnlp.326/)
- Anthology ID: 2023.findings-emnlp.326 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 대형 언어 모델(LLMs)은 자연어 처리 분야에서 영향력 있는 도구로 등장했지만, 복잡한 정보 교환을 포함하는 다자간 대화(MPCs)를 처리하는 능력은 아직 알려지지 않았다.
    2. 본 논문에서는 ChatGPT와 GPT-4와 같은 생성형 LLMs의 MPC에서의 잠재력을 탐구하고, 세 가지 MPC 데이터셋에서 다섯 가지 대표적인 작업을 기반으로 평가하여 제로샷 학습 능력을 분석한 연구를 수행한다.
    3. 연구 결과, ChatGPT는 여러 MPC 작업에서 성능이 좋지 않았지만 GPT-4의 결과는 향후 유망한 미래를 보여준다. 또한, 발화자와 수신자 아키텍처를 포함한 MPC 구조를 도입하여 성능을 향상시켰다. 이 연구는 생성형 LLMs를 MPC에 적용하는 평가와 분석을 제공하며, 효과적이고 강건한 MPC 에이전트의 개발과 창조에 빛을 비추고 있다.

###### Improving End-to-End Speech Processing by Efficient Text Data Utilization with Latent Synthesis (https://aclanthology.org/2023.findings-emnlp.327/)
- Anthology ID: 2023.findings-emnlp.327 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 레이블이 달린 음성 데이터는 텍스트 데이터에 비해 적고 비용이 많이 들기 때문에, 우리는 E2E 음성 처리 모델을 위한 효율적인 텍스트 데이터 활용 프레임워크인 Latent Synthesis (LaSyn)을 제안한다.
    2. LaSyn은 텍스트 데이터를 사전 훈련된 음성 모델의 중간 잠재 표현인 음성 표현으로 변환하기 위해 잠재 합성기를 훈련시키고, 이를 통해 텍스트 데이터를 음향 데이터로 보강하여 모델을 훈련한다.
    3. 실험 결과, LaSyn은 저자원 자동음성인식 (ASR) 및 구술언어이해 (SLU) 작업에서 종래와 비교하여 음성 모델의 성능을 크게 향상시킬 수 있다는 것을 보여준다.

###### Bipartite Graph Pre-training for Unsupervised Extractive Summarization with Graph Convolutional Auto-Encoders (https://aclanthology.org/2023.findings-emnlp.328/)
- Anthology ID: 2023.findings-emnlp.328 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사전 훈련된 문장 표현은 비지도 문서 추출 요약에서 중요한 문장을 식별하는 데 중요하다. 그러나 사전 훈련 및 문장 순위 매기기의 전통적인 두 단계 패러다임은 서로 다른 최적화 목표 때문에 격차가 발생한다.
    2. 따라서 우리는 정보를 최적화하고 구별할 수 있는 문장 표현을 얻기 위해 specifically designed to optimize informative and distinctive sentence representations를 사용하는 것이 중요하다고 주장한다.
    3. 우리의 방법은 사전 훈련된 그래프 오토 인코더를 제안하여 문장-단어 일대다 그래프를 통해 문장의 내부적인 특징과 문장 간의 일관된 특징을 명시적으로 모델링하여 문장 임베딩을 얻는다. 이러한 세부 조정된 문장 임베딩은 비지도 요약을 위한 그래프 기반 순위 알고리즘에서 사용된다.

###### Bayesian Multi-Task Transfer Learning for Soft Prompt Tuning (https://aclanthology.org/2023.findings-emnlp.329/)
- Anthology ID: 2023.findings-emnlp.329 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Prompt 튜닝은 대규모 사전 훈련 언어 모델을 하위 작업에 적용하기 위해 프롬프트를 최적화하는 방식이며, 특히 다중 작업 전이 학습 환경에서 효과적으로 작동한다. 
    2. 그러나 이 방법은 일부 원본 작업들이 서로 부정적이거나 긍정적인 영향을 미칠 수 있다는 사실을 중요하게 간과하고 있다.
    3. 따라서 우리는 소스 태스크로부터 지식을 추출할 때 소스 태스크 사이의 상관 관계를 고려하여 목표 태스크로의 전이를 개선하는 베이지안 접근법을 제안한다.

###### CCIM: Cross-modal Cross-lingual Interactive Image Translation (https://aclanthology.org/2023.findings-emnlp.330/)
- Anthology ID: 2023.findings-emnlp.330 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 급부 상황으로 “Text image machine translation (TIMT)”은 원본 언어 텍스트 이미지를 대상 언어 텍스트로 변환하는 작업에 큰 주목을 받는다. 
    2. 기존 모델들은 호환성 저하로 인해 원본 언어 정보를 부여하기 어렵기 때문에 번역 성능이 저하되었으며, 이를 해결하기 위해 우리는 Cross-modal Cross-lingual Interactive Model (CCIM)을 제안한다. 
    3. 다양한 실험 결과를 통해, CCIM이 기존 모델보다 성능이 향상되었고, 작은 모델 크기로 빠른 디코딩 속도를 가진 것을 확인할 수 있었다.

###### TRAMS: Training-free Memory Selection for Long-range Language Modeling (https://aclanthology.org/2023.findings-emnlp.331/)
- Anthology ID: 2023.findings-emnlp.331 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Transformer 아키텍처는 여러 AI 모델에 필수적이지만, 특히 long-range 언어 모델링에서는 여전히 도전을 겪고 있다.
    2. 이 연구에서는 TRAining-free Memory Selection (TRAMS)라는 전략을 소개하는데, 이는 attention 계산에 참여하는 토큰을 간단한 메트릭을 기반으로 선택한다.
    3. TRAMS 전략을 테스트한 결과, 추가적인 학습이나 파라미터 추가 없이도 성능이 향상된다는 것을 보여주었다.

###### A Critical Analysis of Document Out-of-Distribution Detection (https://aclanthology.org/2023.findings-emnlp.332/)
- Anthology ID: 2023.findings-emnlp.332 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 사전 훈련은 최근 문서 이해 작업에서 많이 사용되지만, 배포 과정에서는 OOD (out-of-distribution) 샘플을 만나면 보수적인 fallback 정책을 활성화해야 한다고 기대된다. 
    2. 이 논문에서는 문서는 다중 모달로 구성되어 있지만, 기존의 OOD 탐지 방법은 이미지나 텍스트와 같은 단일 모달 입력에만 초점을 맞추고 있다. 
    3. 그렇기 때문에 우리는 문서 OOD 탐지를 위해 공간 정보를 활용하는 spatial-aware adapter를 제안하고, 실험 결과 이를 사용하면 경쟁적인 기준에 비해 우수한 성능을 달성할 수 있다는 것을 보여주었다.

###### Improving Neural Machine Translation by Multi-Knowledge Integration with Prompting (https://aclanthology.org/2023.findings-emnlp.333/)
- Anthology ID: 2023.findings-emnlp.333 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 prompt을 활용한 신경기반 기계 번역(NMT) 시스템의 성능 개선에 큰 진전이 이루어졌는데, 해당 논문은 다양한 종류의 지식(Multi-knowledge)들을 NMT 모델에 효과적으로 통합하여 번역 성능을 향상시키는 방법에 초점을 맞춘다.
    2. 우리는 문장, 용어/구, 번역 템플릿과 같은 다양한 종류의 지식을 NMT 모델에 통합하는 통합 프레임워크를 제안한다.
    3. 실험 결과, 우리의 접근법은 강력한 기준선을 크게 능가하여 고품질 번역과 용어 일치 정확성을 달성하는 것을 보여주었다.

###### Active Learning Principles for In-Context Learning with Large Language Models (https://aclanthology.org/2023.findings-emnlp.334/)
- Anthology ID: 2023.findings-emnlp.334 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 대형 언어 모델(LLM)은 소수의 라벨링된 예제(데모)만 사용하여 in-context 학습을 통해 주어진 작업을 효과적으로 수행할 수 있다. 그러나 최적의 성능을 위해 데모를 선택하는 과정은 이전 연구에서 제한적으로 다루어졌다.
    2. 이 논문에서는 약간의 주어진 데이터로 가장 효과적인 데모를 식별하기 위해 pool-based Active Learning(AL) 문제로 접근한다. 이를 위해 불확실성, 다양성 및 유사성을 기반으로 한 표준 AL 알고리즘을 비교하고, 유사성 기반 알고리즘이 더 우수한 성능을 보인다는 일관된 결과를 얻는다.
    3. 다양한 GPT 및 OPT 모델을 사용한 24개 분류 및 다중선택 태스크에 대한 광범위한 실험 결과와 철저한 분석을 통해 테스트 예제와 의미적으로 유사한 데모를 사용하는 것의 중요성을 명확히 보여준다. 실제로, GPT-2 (124M)로 "유사한" 데모를 사용할 경우 GPT-Neox (20B)의 무작위 데모보다 높은 평균 분류 성능을 보여준다.

###### InteMATs: Integrating Granularity-Specific Multilingual Adapters for Cross-Lingual Transfer (https://aclanthology.org/2023.findings-emnlp.335/)
- Anthology ID: 2023.findings-emnlp.335 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다국어 언어 모델(MLLMs)들은 다양한 cross-lingual transfer task에서 매우 성공적인 성과를 보여왔으나, 특히 긴 문맥을 다룰 때 zero-shot low-resource 언어에서 성능이 낮다. 
    2. 기존 연구들은 MLLMs의 cross-lingual alignment을 증진시키기 위해 대규모 병렬 데이터셋에서 전체 모델을 fine-tuning하는 방식을 주로 사용하였고, 이는 계산 리소스를 많이 필요로 한다.
    3. 이 논문에서는 다양한 granuality 레벨의 텍스트를 이용하여 pre-train된 다국어 adapter를 통합하는 InteMATs라는 새로운 접근 방법을 제안한다. InteMATs의 효과는 광범위한 실험을 통해 입증되었다.

###### PlugMed: Improving Specificity in Patient-Centered Medical Dialogue Generation using In-Context Learning (https://aclanthology.org/2023.findings-emnlp.336/)
- Anthology ID: 2023.findings-emnlp.336 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 환자 중심의 의료 대화 시스템은 환자에게 특정한 응답을 제공하는 것을 강조함으로써 의료 지식을 덜 알고 있는 사용자에게 진단 해석 서비스를 제공하려고 한다. 
    2. 큰 언어 모델 (LLM)들은 의료 분야에서 일부 업무에서도 높은 성능을 보이지만 응답의 특수성을 보장하는 것은 어렵다. 
    3. 우리는 PlugMed라는 새로운 시스템을 제안하고, 이는 큰 언어 모델에게 실제 대화를 제시함으로써 특정 대화 전략을 강화하고, 적합한 응답을 선택할 수 있도록 한다. 또한 응답의 특수성을 효과적으로 평가하기 위해 새로운 평가 방법을 소개한다.

###### CodeTransOcean: A Comprehensive Multilingual Benchmark for Code Translation (https://aclanthology.org/2023.findings-emnlp.337/)
- Anthology ID: 2023.findings-emnlp.337 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 코드 번역 데이터셋은 한 쌍의 인기있는 프로그래밍 언어에만 초점을 맞추고 있어 실제 응용 프로그램의 다양한 요구 사항을 충족시키지 못합니다. 본 연구에서는 최대한 다양한 프로그래밍 언어를 지원하는 대규모 벤치마크인 CodeTransOcean을 구축하였습니다. 
    2. CodeTransOcean은 다중 유명 프로그래밍 언어 간의 번역을 지원하는 MultilingualTrans, 출처언어 언어와 인기있는 프로그래밍 언어 간의 번역을 지원하는 NicheTrans, 대용량 언어 모델로 번역된 코드의 실행 가능성을 평가하는 LLMTrans 등 세 가지 독창적인 다국어 데이터셋으로 구성되어 있습니다. 
    3. 또한 CodeTransOcean은 딥러닝 코드를 다른 프레임워크로 번역하는 교차 프레임워크 데이터셋인 DLTrans와 함께, 코드 번역을 위한 다국어 모델링 접근 방법을 개발하여 낮은 리소스 언어 쌍과 높은 리소스 언어 쌍의 번역 품질을 향상시키고 훈련 효율성을 향상시킬 수 있는 가능성을 보였습니다.

###### impact of sample selection on in-context learning for entity extraction from scientific writing (https://aclanthology.org/2023.findings-emnlp.338/)
- Anthology ID: 2023.findings-emnlp.338 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델 (LLM)의 프롬프트 기반 사용은 많은 자연어 문제를 해결하는데 점점 더 인기있는 방법이다. 
    2. 이 논문에서는 GPT-3.5를 사용하여 과학 문서로부터 entity 추출을 위한 in-context 샘플 선택 방법에 대한 포괄적인 분석을 제공한다. 
    3. 도메인 종속적인 방법의 효과는 상당히 다르지만, entity 타입이 많은 문제에서 더 유의미한 향상이 있다고 결과에서 나타났다.

###### Goodtriever: Adaptive Toxicity Mitigation with Retrieval-augmented Models (https://aclanthology.org/2023.findings-emnlp.339/)
- Anthology ID: 2023.findings-emnlp.339 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 독성을 완화하는 데 많은 노력을 기울였지만, 기존 방법들은 모델 파라미터의 극단적인 수정이나 계산량이 많은 보조 모델의 사용을 필요로 한다. 
    2. 이전의 접근 방식들은 언어의 변화하는 특성을 무시하는 경향이 있었다.
    3. 이 연구에서는 독성 완화의 현재 상태를 고려하는 포괄적인 관점을 제시하며, Goodtriever라는 유연한 방법론을 소개한다. Goodtriever는 인코딩 시에 검색 기반 접근 방식을 도입하여 독성 제어된 텍스트 생성을 가능하게 한다.

###### Robustness Tests for Automatic Machine Translation Metrics with Adversarial Attacks (https://aclanthology.org/2023.findings-emnlp.340/)
- Anthology ID: 2023.findings-emnlp.340 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 전략적으로 만들어진 텍스트에 대한 기계 번역 평가 메트릭의 성능을 조사하여 메트릭의 강인성을 밝힌다. BERTScore, BLEURT, COMET 세 가지 인기있는 기계 번역 평가 메트릭에 대한 단어-문자 수준의 공격을 시도하였다.
    2. 우리의 인간 실험은 자동 평가 메트릭이 전략적으로 훼손된 번역을 지나치게 저하시키는 경향을 검증한다.
    3. 우리는 BERTScore 평가에서 일관성 없음을 발견하였는데, 원문과 전략적으로 훼손된 문장을 유사하게 판단하면서 레퍼런스에 비해 훼손된 번역을 원본보다 훨씬 나쁘게 평가한다. 이러한 취약성 패턴을 확인하여 더 견고한 메트릭 개발에 동기부여한다.

###### Time-Considerable Dialogue Models via Reranking by Time Dependency (https://aclanthology.org/2023.findings-emnlp.341/)
- Anthology ID: 2023.findings-emnlp.341 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 generative dialogue model은 뛰어난 성능을 보이며 다양한 응용 분야에 사용되고 있지만, 기존의 대화 모델들은 사람들이 지속적으로 인식하는 시간 정보를 고려하지 않는다.
    2. 이 논문에서는 시간 정보를 적극적으로 활용하는 시간을 고려할 수 있는 대화 모델을 구축하는 것을 목표로 한다. 
    3. 제안된 메트릭을 사용하여 응답을 다양한 시간에 대한 자연스러움으로 분류하고, 이를 활용하여 기존 대화 모델을 시간을 고려하는 모델로 개선하는 reranking 방법을 제안하고, 인간에 의해 주관적으로 평가한 성능을 평가한다.

###### Non-Compositionality in Sentiment: New Data and Analyses (https://aclanthology.org/2023.findings-emnlp.342/)
- Anthology ID: 2023.findings-emnlp.342 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자연어 구문이 결합될 때 그 의미는 종종 부품들의 합 이상이다. 그렇다면 감성 분석 같은 NLP 작업에서도 그렇다. 그러나 그런 NLP 연구들은 대부분의 경우 감성을 계산함에 있어서는 구성적이다라고 주장한다.
    2. 그 대신, 우리는 구문의 감성에 따른 비구성성 평가를 얻기 위해 노력했다.
    3. 우리의 기여는 다음과 같다: a) 이러한 비구성성 평가를 얻기 위한 방법론, b) NonCompSST라는 259개의 구문에 대한 평가 자원과 그 자원의 분석, c) 이 새로운 자원을 사용하여 감성 분석에 대한 컴퓨터 모델의 평가.

###### MPrompt: Exploring Multi-level Prompt Tuning for Machine Reading Comprehension (https://aclanthology.org/2023.findings-emnlp.343/)
- Anthology ID: 2023.findings-emnlp.343 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델은 다양한 자연어 태스크에서 우수한 성능을 보여주었지만, 새로운 데이터셋에 대해 fine-tuning을 하는 데 많은 자원이 필요하다는 단점이 있다. 
    2. 본 논문에서는 multi-level prompt tuning (MPrompt) 방법을 제안하여 컨텍스트 및 태스크에 관련된 정보를 고려하여 fine-tuning을 수행한다. 도메인별 prompt에 대한 독립성 제약도 소개되었고, prompt 생성을 위해 문맥 관련 지식을 활용하는 prompt generator도 제안되었다. 
    3. 실험 결과, QA 형식의 12개 벤치마크에서 평균적으로 최신 기법 대비 1.94%의 성능 개선을 달성하였다.

###### DocTrack: A Visually-Rich Document Dataset Really Aligned with Human Eye Movement for Machine Reading (https://aclanthology.org/2023.findings-emnlp.344/)
- Anthology ID: 2023.findings-emnlp.344 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 시각적으로 풍부한 문서를 읽고 이해할 수 있는 Document AI 모델의 필요성은 기술적, 언어적, 인지적 장벽을 극복하는 것을 요구한다. 그러나 적합한 데이터셋의 부재가 이 분야의 발전을 방해하고 있다.
    2. 이 문제에 대응하기 위해 우리는 인간의 시선 추적 기술을 사용하여 시각적으로 풍부한 문서와 정렬된 휴먼 아이포인트 정보를 포함하는 DocTrack 데이터셋을 소개한다.
    3. 우리의 연구 결과는 Document AI 모델이 큰 진전을 이루었지만, 인간처럼 정확하고 지속적이며 유연하게 시각적으로 풍부한 문서를 읽을 수 있는 정도에는 아직 멀었다는 것을 시사한다. 이러한 결과는 문서 인텔리전스의 미래적인 연구와 개발에 잠재적인 함의가 있다.

###### Adaptation with Self-Evaluation to Improve Selective Prediction in LLMs (https://aclanthology.org/2023.findings-emnlp.345/)
- Anthology ID: 2023.findings-emnlp.345 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 LLMs는 자연어 이해 및 생성을 포함한 다양한 작업에서 큰 발전을 보였지만, 오류 가능성 때문에 고위험 결정 상황에서의 사용은 아직 제한적이다. 
    2. selective prediction은 LLMs의 신뢰성을 향상시키기 위해 쓰이는 기술로, 대답을 확신할 수 없는 경우 예측을 하지 않고 기권할 수 있게 한다.
    3. 이 논문에서는 특정 작업에 LLM을 적응시키는 동시에 자가 평가 능력을 향상시키기 위해 매개 변수 효율적 튜닝을 사용하는 새로운 프레임워크를 제안하고, 이를 통해 다양한 질문-응답 데이터셋에서 제일 성능이 좋은 selective prediction 방법보다 우월한 결과를 보였다.

###### Bi-Drop: Enhancing Fine-tuning Generalization via Synchronous sub-net Estimation and Optimization (https://aclanthology.org/2023.findings-emnlp.346/)
- Anthology ID: 2023.findings-emnlp.346 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기훈련된 언어 모델을 한정된 학습 데이터로 세밀 조정할 경우 과적합되어 성능이 감소하는 문제가 있다. 이 논문에서는 Bi-Drop이라는 세밀 조정 전략을 제시한다. 이는 드롭아웃에서 동적으로 생성된 다양한 서브넷의 기울기를 사용하여 모델 파라미터를 선택적으로 업데이트한다.
    2. Bi-Drop은 배치 내에서 서브넷을 추정하므로 비동기적 서브넷 추정을 수행하는 이전 방법의 위상유지 문제를 극복한다. 또한, Bi-Drop은 서브넷 추정을 위해 한 번의 미니배치만 필요로 하기 때문에 학습 데이터의 유틸리티가 높다.
    3. GLUE 벤치마크 실험 결과, Bi-Drop은 이전 세밀 조정 방법보다 일관되게 우수한 성능을 보여준다. 또한, 실험 결과는 Bi-Drop이 도메인 전이, 데이터 불균형, 저자원 시나리오에서 우수한 일반화 능력과 강건성을 가지고 있는 것을 보여준다.

###### ClozEx: A Task toward Generation of English Cloze Explanation (https://aclanthology.org/2023.findings-emnlp.347/)
- Anthology ID: 2023.findings-emnlp.347 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Cloze questions의 설명을 생성하는 새로운 task인 ClozEx를 소개한다. 이 task는 특히 제2언어로 영어를 배우는 학습자들을 위해 만들어졌으며, 적절한 설명과 함께 cloze questions을 생성하는 것이 목표이다.
    2. 우리는 cloze questions과 해당 설명으로 이루어진 dataset을 소개한다. 이 dataset은 언어 능력을 평가하고 유익하고 정확한 설명을 제공하여 언어 학습을 돕는 것을 목표로 한다.
    3. 우리는 fine-tuned된 다양한 기본 모델과 encoder-decoder 및 decoder-only 아키텍처로 task에 대처했다. 또한 large language models (LLMs)가 사전 정의된 prompt만을 사용하여 좋은 설명을 생성할 수 있는지도 탐구하였다. 평가 결과는 encoder-decoder 모델이 우리의 dataset으로 학습될 때 유창하고 유효한 설명을 제공할 수 있는 잠재력을 가지고 있음을 보여준다.

###### Is Probing All You Need? Indicator Tasks as an Alternative to Probing Embedding Spaces (https://aclanthology.org/2023.findings-emnlp.348/)
- Anthology ID: 2023.findings-emnlp.348 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 단어 벡터 표현에 인코딩된 언어 정보를 식별하고 제어하는 능력은 설명 가능성과 편향 제거 등 다양한 용도로 활용될 수 있다. 이를 위해 사용되는 "프로브(probes)"라고 불리는 단순한 분류 작업을 통해 embedding 공간에서 인코딩된 정보를 평가한다. 그러나 훈련 가능한 분류기의 사용은 프로브 결과와 분류기의 특성을 얽어 매우 복잡하게 만든다.
    2. 이 논문에서는 보조 모델의 훈련 없이 embedding 공간을 조회하여 특정 속성의 존재 여부를 확인하기 위해 사용되는 "인디케이터(indicator) 작업"에 대해 소개하고, 이러한 작업이 프로브와는 반대 방향을 가리킬 수 있고, 이 모순이 embedding 공간 내에서 특성의 존재 여부를 결정하기를 복잡하게 만든다고 주장한다. 
    3. 이러한 주장을 두 가지 테스트 케이스를 통해 실험적으로 검증하였는데, 하나는 성별 편향 제거와 관련된 것이며, 다른 하나는 embedding 공간에서 형태론적 정보를 삭제하는 것과 관련되었다. 이를 통해 적절한 인디케이터의 적용이 프로브 대비 더 정확한 정보를 제공한다는 것을 보였고, embedded 표현으로부터 정보를 추출할 때 인디케이터 작업을 고려해야 한다는 결론을 내렸다.

###### The Cost of Compression: Investigating the Impact of Compression on Parametric Knowledge in Language Models (https://aclanthology.org/2023.findings-emnlp.349/)
- Anthology ID: 2023.findings-emnlp.349 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델 압축은 빠른 추론, 작은 메모리 풋프린트 및 로컬 배포를 가능하게 해주지만, 일반적으로 파악되는 평가 지표 외에도 박제된 지식을 측정하는 세부적인 평가 지표에 대한 연구는 아직 충분히 이루어지지 않았으며, 이 연구를 충족시키기 위해 LAMA 및 LM-Harness 벤치마크를 사용하여 일반적으로 사용되는 압축 기법이 모델 성능에 미치는 영향을 체계적으로 분석한다고 주장한다.
    2. LLM 압축 기술의 주된 trade-off은 압축 정도와 압축된 모델의 품질에 대한 영향 사이에서 이루어지고 있으며, 기존의 연구들은 주로 퍼플렉서티(perplexity)나 다운스트림 태스크 정확도와 같은 일반적인 지표에 초점을 맞추고 있다.
    3. 본 연구는 대규모 언어 모델에서 일반적으로 사용되는 압축 기법의 영향을 체계적으로 분석하여 실제적인 통찰력을 제공함으로써 실무자들이 압축에 대한 결정을 내릴 수 있게 하는 것을 목표로 한다.

###### CoEdIT: Text Editing by Task-Specific Instruction Tuning (https://aclanthology.org/2023.findings-emnlp.350/)
- Anthology ID: 2023.findings-emnlp.350 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. CoEdIT은 텍스트 편집을 위한 최신 텍스트 편집 시스템으로, 사용자의 지시에 따라 원하는 텍스트의 속성을 지정하고 수정된 텍스트를 출력한다. 
    2. 우리는 다양한 텍스트 편집 벤치마크에서 최고 성능을 달성하며, 공개적으로 사용 가능한 가장 큰 크기의 LLM보다 약 60배 작으면서 경쟁력을 가지고 있다. 
    3. 뿐만 아니라, 이 모델은 이전에 보지 못한 편집 지침의 일반화를 할 수 있으며, 편집 동작의 다른 조합을 포함하는 복합 지침에 일반화할 수 있는 능력을 보인다.

###### Exploring Large Language Models for Multi-Modal Out-of-Distribution Detection (https://aclanthology.org/2023.findings-emnlp.351/)
- Anthology ID: 2023.findings-emnlp.351 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 신뢰할 수 있는 기계 학습을 위해 out-of-distribution(OOD) 탐지는 필수적이다. 이 논문에서는 큰 언어 모델을 활용하여 OOD 탐지의 성능을 향상시키기 위해 월드 지식을 적용하는 방법을 제안한다. 
    2. 제안하는 방법은 consistency-based uncertainty calibration을 이용하여 각 생성물의 신뢰도를 추정하는 것이다. 이미지에서 시각적 객체를 추출하여 월드 지식을 활용하는 것도 추가로 도입된다.
    3. 실험 결과, 제안하는 방법은 기존 기법보다 일관성 있게 더 좋은 성능을 보였다.

###### Better Together: Enhancing Generative Knowledge Graph Completion with Language Models and Neighborhood Information (https://aclanthology.org/2023.findings-emnlp.352/)
- Anthology ID: 2023.findings-emnlp.352 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 실제 지식 그래프(KG)는 종종 불완전함으로, 잠재력을 제한한다. 이를 해결하기 위해 Knowledge Graph Completion (KGC) 기법이 사용된다. 
    2. 그러나 기존의 KGC 방법은 연산량이 많아 대규모 KG에는 적합하지 않다. 
    3. 이 논문에서는 이웃 노드를 추가 정보로 사용하여 언어 모델 기반의 KGC 방법을 개선하는 방법을 제안하고, 실제로 KGT5와 전통적인 KGC 방법들보다 더 우수한 성능을 보인다는 것을 실험을 통해 보여준다.

###### DeltaScore: Fine-Grained Story Evaluation with Perturbations (https://aclanthology.org/2023.findings-emnlp.353/)
- Anthology ID: 2023.findings-emnlp.353 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자연어 생성 작업에 대한 다양한 평가 메트릭이 개발되었지만, 이러한 메트릭은 흥미로움과 유창성과 같은 서술의 복잡한 측면을 평가하는 데 제한적이다.
    2. 이 논문에서는 미세한 서술 측면의 평가를 위해 편작 기법을 사용하는 새로운 방법인 DeltaScore를 소개한다.
    3. DeltaScore는 사전 학습된 언어 모델을 사용하여 사전-후처리 상태의 가능성 차이를 계산하여 각 측면의 품질을 측정하며, 플루언시, 일관성, 관련성, 논리성, 흥미로움에 대해 강력한 성능을 보인다.

###### MuG: A Multimodal Classification Benchmark on Game Data with Tabular, Textual, and Visual Fields (https://aclanthology.org/2023.findings-emnlp.354/)
- Anthology ID: 2023.findings-emnlp.354 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존 연구에서는 다중 소스로부터 수집한 데이터를 통합하는 것이 전통적으로 단일 모달 데이터보다 장점이 있는 것이 증명되어, 다양한 신규 다중 모달 응용 프로그램들이 등장하였다.
    2. 우리는 MuG라는 다중 모달 분류 벤치마크를 제안하여 연구자들이 자신들의 모델을 평가하고 개선할 수 있는 환경을 제공한다.
    3. MuG는 타블로, 텍스트, 비주얼 모달을 포괄한 4가지 다양한 게임 장르에서 수집된 8개의 데이터셋으로 구성되어 있으며, 이를 통해 다중 모달 분류기의 어려운 특징과 다양한 종속성을 시험할 수 있다.

###### Don’t waste a single annotation: improving single-label classifiers through soft labels (https://aclanthology.org/2023.findings-emnlp.355/)
- Anthology ID: 2023.findings-emnlp.355 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 보통 객관식 단일 라벨 분류 작업에서 데이터 주석 및 훈련 방법의 한계를 다룬다. 
    2. 기존 방법은 주석 달 때 매번 한 샘플에 대해 하나의 라벨을 선택하도록 요구하는데, 이는 모호성과 맥락 부재로 인해 적절한 라벨을 결정하기 어려울 수 있다. 
    3. 따라서 이 논문에서는 모호한 주석의 정보를 활용하여 훈련시키는 소프트 라벨 방법을 제안하고, 이를 사용하면 성능과 보정(calibration)이 향상된다고 밝혔다.

###### Black-Box Tuning of Vision-Language Models with Effective Gradient Approximation (https://aclanthology.org/2023.findings-emnlp.356/)
- Anthology ID: 2023.findings-emnlp.356 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Parameter-efficient fine-tuning (PEFT) 방법은 대규모 vision-language 모델을 특정 과제나 시나리오에 적응시키는 효과적인 방법을 제공하고 있다. 그러나 대규모 모델은 남용 방지나 상업적인 이유로 인해 종종 오픈소스가 아니기 때문에, 흰 상자 PEFT 방법의 적용에는 장벽이 있다.
    
    2. 이 논문에서는 모델 접근성에 대한 의존성을 완화하기 위해, 검정 상자 모델에 대한 텍스트 프롬프트 최적화와 출력 특징 적응을 위한 협력적 검은 상자 튜닝 (CBBT)를 소개한다.
    
    3. 제안된 CBBT는 열 한 가지의 하류 벤치마크에서 괄목할 만한 개선을 이루며, 기존의 검은 상자 VL 적응 방법과 비교했을 때 높은 수준의 성능을 달성한다.

###### How to Determine the Most Powerful Pre-trained Language Model without Brute Force Fine-tuning? An Empirical Survey (https://aclanthology.org/2023.findings-emnlp.357/)
- Anthology ID: 2023.findings-emnlp.357 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 컴퓨터 비전 분야에서 전이능력 추정 (transferability estimation)은 매우 중요한 관심사로 여겨져왔다.
    2. 이 논문에서는 전이능력 추정 방법을 철저히 조사하고 가장 적합한 모델을 찾기 위해 GLUE 벤치마크에 기반한 상세한 실험을 실시한다.
    3. 이미 존재하는 방법들의 강점과 약점을 보여주며, H-Score가 효과적이고 효율적인 성능을 갖는다는 것을 보여준다.

###### Licon: A Diverse, Controllable and Challenging Linguistic Concept Learning Benchmark (https://aclanthology.org/2023.findings-emnlp.358/)
- Anthology ID: 2023.findings-emnlp.358 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 개념 학습은 이미지로부터 개념을 학습하는 데 중점을 둔 기존 방법 대부분이 있지만, 시각적 정보는 추상적인 개념을 완전히 표현하지 못하기 때문에 기존 개념과 관련된 새로운 개념을 도입하는 데 어려움이 있다. 
    2. 본 연구에서는 인간이 언어적 설명을 통해 대부분의 개념을 학습하는 사실을 바탕으로, Linguistic Concept Learning benchmark (Licon)을 소개한다. 다양한 형태 (예: 일반 속성, 이미지, 텍스트)의 개념이 언어적 설명으로 정의된다. 
    3. 또한, EnC라는 entailment 기반 개념 학습 방법을 설계하여 개념들 간의 관계를 모델링한다고 한다. 다양하고 조절 가능한 개념은 개념 분류, 속성 예측, 개념 관계 인식 등의 도전적인 평가 과제를 지원한다.

###### InterroLang: Exploring NLP Models and Datasets through Dialogue-based Explanations (https://aclanthology.org/2023.findings-emnlp.359/)
- Anthology ID: 2023.findings-emnlp.359 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 개발된 NLP explainability 방법들은 우리에게 다양한 방식으로 '블랙박스'를 열어주지만, 대화 인터페이스를 제공하는 인터랙티브 도구가 부족하다.
    2. 우리는 TalkToModel 프레임워크를 NLP 도메인에 적용하고, 자유 텍스트 인지를 포함하는 NLP 특정 작업에 대한 일반적인 적용 가능성을 보여준다. 
    3. 모델 동작을 설명하기 위해 우리는 합리화(rationalization)와 특징 속성(feature attribution)이 도움이 된다는 것을 밝혀냈고, 설명 대화를 기반으로 모델 결과를 신뢰할 수 있게 예측할 수 있다는 것을 보였다.

###### INVITE: a Testbed of Automatically Generated Invalid Questions to Evaluate Large Language Models for Hallucinations (https://aclanthology.org/2023.findings-emnlp.360/)
- Anthology ID: 2023.findings-emnlp.360 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 대형 언어 모델들은 여러 번의 대화를 통해 자유로운 대화를 처리할 수 있게 되었으나, 그들은 주장의 근거가 없거나 잘못된 진술을 할 수 있는 경향이 있다 (hallucinations). 
    2. 기존 평가 방법들은 TruthfulQA와 같은 QA 테스트 세트에서 LLMs를 테스트하는 것이지만, LLMs는 점점 더 큰 텍스트 코퍼스에서 사전훈련을 받기 때문에 훈련 중에 이러한 테스트 세트에 노출되어 테스트 세트의 모델 성능을 과소평가하게 만든다. 
    3. 이 논문에서는 이러한 리스크를 대응하기 위해 LLMs가 잘못된 질문에 대해 강력하게 대응할 수 있도록 돕기 위한 INVITE라는 프레임워크를 제안한다. 이 프레임워크는 유사한 entity로 대체된 주제나 객체로 유효한 사실을 왜곡하여 새로운 일괄적인 무효 질문을 생성하는데 사용된다.

###### Multimodal Automated Fact-Checking: A Survey (https://aclanthology.org/2023.findings-emnlp.361/)
- Anthology ID: 2023.findings-emnlp.361 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 잘못된 정보는 종종 잘못 된 캡션을 가진 이미지와 같은 다양한 매체에서 전달된다. 라기에는는 멀티 모달 잘못된 정보가 사람들에게 더 신뢰도 높은 것으로 인식되며 텍스트만 있는 것보다 더 빠르게 확산된다. 
    2. 이 논문에서는 텍스트, 이미지, 오디오 및 비디오와 같은 실제 팩트 체킹에 흔한 네 가지 다양한 매체에 초점을 맞추고, 멀티모달 잘못된 정보에 대한 특수한 하위 작업을 포함하는 AFC (자동 팩트 체크)를 위한 프레임 워크를 개념화한다.
    3. 또한 우리는 다른 커뮤니티에서 사용되는 관련 용어들을 논의하고 우리의 프레임 워크에 매핑한다.

###### PROTEGE: Prompt-based Diverse Question Generation from Web Articles (https://aclanthology.org/2023.findings-emnlp.362/)
- Anthology ID: 2023.findings-emnlp.362 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. StackOverflow, Quora와 같은 온라인 지식 공유 커뮤니티 및 대화형 어시스턴트(chatbot)와 같은 응용 프로그램에게 풍부하고 다양한 지식 베이스(KB: knowledge base)가 필수적이다. 
    2. 이 논문은 도메인 특정한 긴 형태의 텍스트 내용(웹 기사 등)에서 Q&A 기반 지식 베이스의 자동 생성 문제에 초점을 맞춘다.
    3. PROTEGE라는 다양한 질문 생성 프레임워크를 제안하여, 다양성과 충실성을 모두 달성한다고 실험 결과를 통해 보여준다.

###### GPT-4 as an Effective Zero-Shot Evaluator for Scientific Figure Captions (https://aclanthology.org/2023.findings-emnlp.363/)
- Anthology ID: 2023.findings-emnlp.363 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근에는 자연어처리(NLP) 태스크에서 최고 수준의 정확성을 보이는 딥 모델들에게서도 spurious 패턴에 의존하는 것으로 알려져 있어서, robustness가 제한된다는 것이 보고되고 있다.
    2. 유사한 counterfactual이 이미 데이터셋에 있는지 자동으로 찾는 기계나 사람이 데이터셋에 counterfactual을 추가하는 방법은 spurious correlation이 여전히 문제가 된다.
    3. 이 논문은 "여러 개의" counterfactual을 합성하고, 이 집합에서 예측 분포에 대한 집단적인 결정을 내리면서 각 용어의 인과관계를 강력하게 지도하는 방법을 제안한다.

###### Mulan: A Multi-Level Alignment Model for Video Question Answering (https://aclanthology.org/2023.findings-emnlp.364/)
- Anthology ID: 2023.findings-emnlp.364 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 비디오에 대한 질문에 답하는 것을 목표로 하는 VideoQA에서는 비디오와 텍스트 간의 세밀한 시맨틱 상호작용에 관심이 부족한 것이 현재 주된 문제이다.
    2. 그러므로 이 논문에서는 객체 수준, 프레임 수준 및 비디오 수준에서 비주얼과 텍스트 간의 alignment를 수립하는 Multi-Level Alignment Model for Video Question Answering인 Mulan을 제안한다.
    3. 실험 결과, 우리의 방법은 최소한의 비주얼-언어 사전학습 데이터 및 줄어든 학습 가능한 매개변수 수를 활용할 때에도 최신 기법들보다 뛰어난 성능을 보인다.

###### HARE: Explainable Hate Speech Detection with Step-by-Step Reasoning (https://aclanthology.org/2023.findings-emnlp.365/)
- Anthology ID: 2023.findings-emnlp.365 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 소셜 미디어의 확대로 인해 혐오 발언의 정확한 탐지는 온라인 안전을 보장하기 위해 중요해졌다. 이 논문에서는 큰 언어 모델들의 추론 능력을 활용하여 혐오 발언에 대한 설명의 비어있는 부분을 채우는 hate speech detection 프레임워크 'HARE'를 소개한다. 
    2. 기존 주석 체계에서의 추론 갭을 해결하기 위해 모델이 생성한 데이터를 활용한 접근법이 사용되었으며, 이를 통해 훈련된 모델의 설명의 질을 향상시키고 보지 못한 데이터셋에 대한 일반화 성능을 크게 향상시킬 수 있었다.
    3. 실험 결과는 기존의 인간 주석을 사용한 베이스라인들보다 모델이 생성한 데이터를 사용한 접근법이 일관되게 우월한 성능을 발휘하며, 훈련된 모델의 설명의 질을 향상시키고 보이지 않는 데이터에 대한 일반화를 개선시켜줌을 보여준다.

###### ReLM: Leveraging Language Models for Enhanced Chemical Reaction Prediction (https://aclanthology.org/2023.findings-emnlp.366/)
- Anthology ID: 2023.findings-emnlp.366 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 화학적 지식을 활용하여 실제 화학 반응 예측의 정확성을 향상시키는 새로운 프레임워크인 ReLM을 제안하였다.
    2. Graph Neural Networks (GNNs)을 사용하는 기존 기술은 텍스트 정보를 활용할 수 없고, 충분한 훈련 데이터가 없어 실제 응용에 적용하기에 한계가 있다.
    3. ReLM은 GNNs에 언어 모델의 화학적 지식을 활용하여 신뢰성을 자가 평가하고 예측 성능을 향상시킨다. 실험 결과, ReLM은 다양한 화학 반응 데이터셋에서 최신 GNN 기반 방법보다 뛰어난 성능을 보여준다.

###### Decomposing Complex Queries for Tip-of-the-tongue Retrieval (https://aclanthology.org/2023.findings-emnlp.367/)
- Anthology ID: 2023.findings-emnlp.367 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 아이템을 다시 찾을 때, 사용자들은 잊어버리거나 식별할 수 없는 세부 정보에 대해 창의적인 전략을 사용하는데, 이는 문서 텍스트를 벗어난 정보 (예: 책 표지의 설명)나 개인적인 문맥 (예: 언제 책을 읽었는지), 콘텐츠 요소 (예: 책의 캐릭터나 사건)를 설명하는 복잡한 질의 형태일 수 있다. 
    2. 이 논문에서는 이러한 복잡한 질의를 처리하기 위해 LLM을 사용하여 질의를 힌트로 분해하고 이를 특화된 검색기에 서브질의로 라우팅한 다음 결과를 앙상블하는 간단하면서도 효과적인 프레임워크를 제안한다.
    3. 이 접근 방식은 off-the-shelf 검색기 (예: 책 표지 이미지를 검색하기 위한 CLIP)를 활용하거나 검색기 별 논리 (예: 날짜 제한)를 통합할 수 있다는 것을 보여주며, 새로운 데이터셋에서 Recall@5에 대해 골드 책 검출을 최대 6% 향상시킬 수 있다.

###### Values, Ethics, Morals? On the Use of Moral Concepts in NLP Research (https://aclanthology.org/2023.findings-emnlp.368/)
- Anthology ID: 2023.findings-emnlp.368 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 NLP의 윤리적 측면을 연구한 많은 논문들이 있으나, 이들 논문들에는 기초적인 용어와 이론에 대한 논의가 거의 이루어지지 않았다.
    2. 이 논문에서는 철학적인 윤리 개념과 이미 존재하는 도덕적인 NLP 연구를 체계적으로 조사하여 이들의 철학적 기반과 용어, 데이터 기반에 대해 분석한다. 
    3. 이를 통해 논문 작성자는 NLP 분야에서의 도덕적인 논의에 대한 정보 제공과 함께 향후 연구에 대한 세 가지 권고사항을 제시한다.

###### Self-Supervised Behavior Cloned Transformers are Path Crawlers for Text Games (https://aclanthology.org/2023.findings-emnlp.369/)
- Anthology ID: 2023.findings-emnlp.369 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 연구에서는 텍스트 게임에 대한 self-supervised behavior cloning transformer를 소개한다. 이는 가상 환경에서의 다단계 추론에 대한 어려운 벤치마크로, 기존의 Behavior Cloning Transformers는 이와 같은 작업에서 뛰어나지만 지도 학습 데이터에 의존한다. 
    2. 우리의 방법은 게임에서 보상을 얻을 수 있는 공통된 매크로 동작 순서로 정의된 트라젝터리를 탐색하면서 학습 데이터를 자동으로 생성한다. 빠른 모델 훈련을 통해 이러한 트라젝터리의 일반성과 유효성을 결정하고, 본 연구에서는 본문에서 제시된 벤치마크 텍스트 게임 세 가지에 대해 지도 학습 시스템의 약 90% 성능을 달성함을 보여주었다.

###### Adapting Pretrained Text-to-Text Models for Long Text Sequences (https://aclanthology.org/2023.findings-emnlp.370/)
- Anthology ID: 2023.findings-emnlp.370 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이미 존재하는 짧은 문맥 모델로부터 긴 문맥 모델을 구축하는 효과적인 방법을 제안한다. 
    2. transformer에서 full attention을 pooling-augmented blockwise attention으로 대체하고, 다양한 길이의 span을 가진 masked-span prediction task로 모델을 pretrain하는 방법을 제안한다. 
    3. 또한, 대용량 오픈 도메인 코퍼스에서 랜덤하게 연결된 짧은 문서를 사용하는 것이 기존의 긴 문서 코퍼스를 사용하는 것보다 성능이 우수함을 확인하고 이를 통해 긴 텍스트 QA 작업에서 경쟁력 있는 성능을 달성하였다.

###### xDial-Eval: A Multilingual Open-Domain Dialogue Evaluation Benchmark (https://aclanthology.org/2023.findings-emnlp.371/)
- Anthology ID: 2023.findings-emnlp.371 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 오픈 도메인 대화 평가를 위한 레퍼런스-프리 학습 메트릭은 미리 학습된 언어 모델과 고품질의 인간 주석을 통해 발전하고 있다. 하지만 현재의 연구는 주로 영어 대화에 초점을 맞추고 있으며, 다른 언어로의 일반화 여부는 충분히 검토되지 않았다.
    2. 이 논문에서는 오픈 소스 영어 대화 평가 데이터셋을 기반으로 한 xDial-Eval을 소개한다. xDial-Eval은 12개의 턴 수준 데이터와 6개의 대화 수준 데이터를 포함하며, 영어 대화 데이터는 상용 기계 번역 시스템을 이용하여 다른 언어로 확장되었다.
    3. xDial-Eval을 통해 이전에 제안된 BERT 기반 메트릭과 최근 등장한 대형 언어 모델들을 포괄적으로 분석하고, 강력한 자기 지도 및 다국어 기준선을 수립했다.

###### MathDial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems (https://aclanthology.org/2023.findings-emnlp.372/)
- Anthology ID: 2023.findings-emnlp.372 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자동 대화 튜터는 교육을 개인화하고 접근성을 높이는데 큰 잠재력을 가지고 있지만, 충분히 크고 고품질의 데이터셋이 부족하여 연구가 지연되고 있다.
    2. 이 논문에서는 인간 교사와 Large Language Model (LLM)을 결합하여 이러한 대화를 생성하기 위한 프레임워크를 제안한다.
    3. 이를 통해 알고리즘 풀이에 능한 모델들을 튜터로 사용할 수 있으며, MathDial 데이터셋을 통해 더 효과적인 튜터로 모델을 fine-tuning할 수 있다고 입증하였다.

###### Towards Making the Most of ChatGPT for Machine Translation (https://aclanthology.org/2023.findings-emnlp.373/)
- Anthology ID: 2023.findings-emnlp.373 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. ChatGPT는 높은 resource를 갖는 언어에 대해서는 상업용 시스템과 비교 가능한 결과를 보이지만, 낮은 resource나 먼 언어 쌍의 번역 같은 복잡한 작업에서는 성능이 뒤처지는 것으로 알려져 있다. 이 연구에서는 ChatGPT의 번역 능력을 더 발전시키기 위해 temperature, task 정보, domain 정보 등을 고려하여 두 개의 (단순하지만 효과적인) 프롬프트를 제안한다.
    2. ChatGPT의 성능은 크게 temperature에 따라 달라지며, 낮은 temperature일수록 더 좋은 성능을 달성할 수 있다.
    3. 태스크 정보를 강조함으로써 ChatGPT의 성능을 더 향상시킬 수 있으며, 특히 복잡한 MT 작업에서 도움이 된다. 또한 domain 정보를 도입함으로써 ChatGPT의 일반화 능력을 활성화시키고 특정 도메인에서의 성능을 향상시킬 수 있다.

###### Enhancing Reasoning Capabilities by Instruction Learning and Chain-of-Thoughts for Implicit Discourse Relation Recognition (https://aclanthology.org/2023.findings-emnlp.374/)
- Anthology ID: 2023.findings-emnlp.374 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 암시적 담화 관계 인식은 두 가지 주장 사이의 관련성을 이해하는 것을 목표로 한다. 본 논문에서는 생성 모델을 기반으로한 분류 방법을 제안한다.
    2. 우리의 접근법은 명령어 템플릿과 컨텍스트 내 학습을 결합하여 생성 모델을 개선시키는데 활용되며, 이렇게 함으로써 암시적 담화 관계 인식 작업에 효과적으로 대응한다.
    3. 실험 결과, PDTB 2.0, PDTB 3.0 및 CoNLL16 공유 작업 데이터셋에서 평가한 결과, 기존 최고 성능 모델과 비교하여 우수한 성능을 보였다.

###### Large-Scale and Multi-Perspective Opinion Summarization with Diverse Review Subsets (https://aclanthology.org/2023.findings-emnlp.375/)
- Anthology ID: 2023.findings-emnlp.375 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 의견 요약 솔루션은 정보 선택을 위한 디자인 부재로 인해 대규모의 리뷰를 요약하고 다양한 관점에서 의견 요약을 제공하는 데에 있어서 부족하다.
    2. 그래서, 우리는 대규모 다각도 의견 요약을 위한 감독 학습 요약 프레임워크 SubSumm을 제안한다. SubSumm은 리뷰 샘플링 전략 세트와 두 단계의 훈련 방법으로 구성되어 있다.
    3. SubSumm은 여러 관점과 질 수준의 리뷰 하위집합을 선택하기 위해 감성 방향과 대비 정보 가치를 고려하는 샘플링 전략을 사용하며, 이를 통해 수많은 입력을 활용하여 요약 생성 모델을 훈련시킬 수 있다는 것을 실험 결과로 보여준다.

###### Topic-Informed Dialogue Summarization using Topic Distribution and Prompt-based Modeling (https://aclanthology.org/2023.findings-emnlp.376/)
- Anthology ID: 2023.findings-emnlp.376 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화 요약에서 다중 주제를 다루는 것은 문서와 달리 주제 이동에 취약하므로 중요한 문제로 고려되어야 합니다.
    2. 우리는 대화 주제 분포를 반영하는 새로운 대화 요약 모델을 제안합니다. 대화 주제 분포를 추정하는 효과적인 주제 발견 모델을 사용하여 대화 인코더 및 디코더 벡터의 출력에 주제 정보를 전달합니다.
    3. 실험 결과로는 우리 모델이 ROUGE 점수에서 최신 기법보다 우수한 성능을 보이며, 인간 평가 결과로는 우리의 프레임워크가 포괄적인 요약을 잘 생성한다는 것을 보여줍니다.

###### Disentangling Structure and Style: Political Bias Detection in News by Inducing Document Hierarchy (https://aclanthology.org/2023.findings-emnlp.377/)
- Anthology ID: 2023.findings-emnlp.377 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 언론 신문 기사에서 정치적 편견을 식별하는 방법은 각 신문 매체의 글쓰기 스타일에 영향을 받아 overfitting과 일반화 능력의 한계가 있다. 
    2. 우리는 문장 수준의 의미와 문서 수준의 retorical structure을 고려하여 정치적 편견을 식별하는 더 견고하고 스타일에 구애받지 않는 방법을 제안한다. 
    3. 우리는 다양한 어텐션 헤드의 앙상블을 통해 긴 문서의 구조를 효과적으로 인코딩하는 새로운 다중 헤드 계층적 어텐션 모델을 소개하고, 이는 도메인 종속성을 극복하며 이전 방법보다 더 견고하고 정확한 결과를 보여준다.

###### Measuring and Narrowing the Compositionality Gap in Language Models (https://aclanthology.org/2023.findings-emnlp.378/)
- Anthology ID: 2023.findings-emnlp.378 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 본 연구에서는 어휘 모델들이 서브 문제들의 답을 올바르게 합성함으로써 전체적인 해결책을 찾는 구성적 추론 작업의 능력을 조사했다.
    2. 우리는 서브 문제들의 답을 모델들이 올바르게 대답하지만 전체적인 해결책을 생성하지 못하는 비율을 측정하는데 이를 구성성 갭(compositionality gap)이라고 명명하였다.
    3. 우리는 GPT-3 모델들에서 모델 크기가 커짐에 따라 단일-홉의 질문-답변 작업 성능이 더 빠르게 개선되는 반면, 다중-홉 작업 성능은 그렇지 않아서 구성성 갭이 줄어들지 않는다는 것을 보였다.

###### Unsupervised Candidate Answer Extraction through Differentiable Masker-Reconstructor Model (https://aclanthology.org/2023.findings-emnlp.379/)
- Anthology ID: 2023.findings-emnlp.379 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 질문 생성은 광범위한 응용 분야에서 사용되는 데이터 증강 접근 방법이지만, 기존의 후보 답안 추출 방법은 언어적 규칙이나 주석이 달린 데이터에 의존하여 부분적 주석 문제와 일반화 도전에 직면한다.
    2. 이 연구에서는 문맥 단락의 내재적 구조를 활용하여 자가 일관성을 강화하는 Differentiable Masker-Reconstructor (DMR) 모델을 통해 감지력 있는 정보 토큰을 추출하는 비지도 후보 답안 추출 방법을 제안한다.
    3. DMR 모델의 효과를 입증하기 위해 전수 조사된 답안을 가진 두 개의 데이터셋을 구성하고, 감독 없는 방법 중에서도 성능이 우수하며 감독 방법과 동등한 성능을 보여준다.

###### HoneyBee: Progressive Instruction Finetuning of Large Language Models for Materials Science (https://aclanthology.org/2023.findings-emnlp.380/)
- Anthology ID: 2023.findings-emnlp.380 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 저자들은 재료 과학 (materials science)에 특화된 천억 개의 파라미터를 가진 언어 모델인 HoneyBee를 만들기 위해 신뢰할 수 있는 데이터 정제 과정인 MatSci-Instruct를 제안한다. 
    2. MatSci-Instruct는 상업적으로 사용 가능한 대형 언어 모델에게 나열 모듈 (예: Chat-GPT)을 사용하여 생성을 하고 독립적인 확인자 모듈 (예: Claude)에서 확인함으로써 생성된 데이터의 신뢰성을 향상시킨다.
    3. MatSci-Instruct를 사용하여 다양한 척도를 통해 생성된 데이터의 품질을 측정하고, HoneyBee 모델의 성능을 점진적으로 개선하는 반복적인 과정을 거친 결과를 평가하여 재료 과학 작업에서 기존 언어 모델보다 뛰어난 성과를 보였다.

###### Prompt-Based Editing for Text Style Transfer (https://aclanthology.org/2023.findings-emnlp.381/)
- Anthology ID: 2023.findings-emnlp.381 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근에는 텍스트 스타일 전환에서 텍스트 쿼리를 사용하여 사전 훈련된 언어 모델(PLM)을 쿼리하는 "Prompting 접근법"이 탐구되었지만, 이러한 생성 과정은 덜 제어 가능하며 초기 예측 오류가 후속 단어 예측에 영향을 줄 수 있다.
    2. 이 논문에서는 텍스트 스타일 전환을 위한 프롬프트 기반 편집 접근법을 제안한다. 특히, 스타일 분류를 위해 PLM에 프롬프트를 제공하고, 분류 확률을 사용하여 스타일 점수를 계산한다. 그런 다음, 문장 수준 변환 작업을 위한 포괄적인 점수 함수를 최대화하기 위해 단어 수준 편집과 이산적 탐색을 수행한다.
    3. 실험에서는 세 가지 스타일 전환 벤치마크 데이터셋에서 자동 및 인간 평가를 수행하고, 매개변수가 20배 더 많은 기존 시스템보다 우수한 성능을 보이는 것을 보여준다. 추가적인 실험 결과 분석은 우리의 방법의 효과를 더욱 명확히 보여준다.

###### Representativeness as a Forgotten Lesson for Multilingual and Code-switched Data Collection and Preparation (https://aclanthology.org/2023.findings-emnlp.382/)
- Anthology ID: 2023.findings-emnlp.382 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 세계적으로 다양한 언어를 사용하며 code-switching (CSW)은 다른 언어들이 섞이는 일반적인 현상이다. 하지만 최근의 대규모 다국어 언어 모델(MMLM)의 발전에도 불구하고, 성공적인 CSW 시스템을 구축하는 데는 아직 큰 진전이 없다. 
    2. 이 논문은 CSW 데이터셋에 대한 수집과 준비 (예: 전사 및 주석) 단계에서의 이슈들을 검토하여 이러한 문제의 원인을 조사한다. 
    3. 분석 결과, 대부분의 CSW 데이터가 영어에만 집중되어 다른 언어 쌍/튜플이 무시되고, 위치, 사회-인구학적 및 등록 상의 변동성을 무시하여 데이터 수집과 준비 과정에서 대표성에 결함이 있다는 사실을 밝혀냈다. 또한, CSW 데이터셋의 대표성에 대한 명확한 데이터 선택 및 필터링 과정이 부족하다는 문제도 있다.

###### NERvous About My Health: Constructing a Bengali Medical Named Entity Recognition Dataset (https://aclanthology.org/2023.findings-emnlp.383/)
- Anthology ID: 2023.findings-emnlp.383 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이름 있는 entity를 인식하는 능력인 Named Entity Recognition (NER)은 생명 과학 분야의 여러 다운스트림 작업에서 유용하다. 특히 NER은 환자들이 일상적으로 사용하는 비공식 언어로 이루어진 Consumer Health Questions (CHQs)를 다룰 때 어렵다. 
    2. 이 논문에서는 Bengali 언어의 문장 구조의 유연성과 지역 방언의 차이로 인해 이러한 어려움이 더욱 커진다고 언급한다. 
    3. 이러한 데이터의 부족으로 인해, 이 논문에서는 Bengali 언어의 건강 관련 텍스트에서 named entities를 인식하는 종합적인 데이터셋인 'Bangla-HealthNER'를 제공한다.

###### Sparse Black-Box Multimodal Attack for Vision-Language Adversary Generation (https://aclanthology.org/2023.findings-emnlp.384/)
- Anthology ID: 2023.findings-emnlp.384 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 딥러닝 모델은 실제 상황에서 다양한 플랫폼의 안전한 관리를 위해 상품 제한, 혐오 발언 모니터링 등 다양한 분야에서 널리 사용되고 있다. 하지만 불법적인 판매자들은 금지된 제품에 대해 대규모로 왜곡을 추가하여 감지 모델을 속일 수 있으므로, 이러한 왜곡에 대한 모델의 취약성을 시뮬레이션하고 평가하는 것은 도전적이다.
    2. 이 논문에서는 Sparse Multimodal Attack (SparseMA)라는 새로운 블랙박스 다중모달 공격을 제안한다. SparseMA는 희소한 왜곡을 이용하여 불법적인 판매자들의 공격 행동을 블랙박스 상황에서 시뮬레이션한다. 또한, SparseMA는 이미지 패치와 텍스트 단어를 이산 공간에서 동등하게 처리하여 이미지와 텍스트 간의 간극을 좁힌다.
    3. 실험 결과 SparseMA는 다른 모달성에 대한 모델의 취약성을 식별하는 데에 탁월한 성능을 보이며, 기존의 다중모달 공격과 단일모달 공격을 능가한다. SparseMA는 우리가 알기로는 처음으로 제안된 블랙박스 다중모달 공격 방법으로, 다중모달 모델의 강건성을 평가하는 데에 효과적인 도구로 사용될 수 있다.

###### Towards a Unified Framework for Reference Retrieval and Related Work Generation (https://aclanthology.org/2023.findings-emnlp.385/)
- Anthology ID: 2023.findings-emnlp.385 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 관련 작업 생성 과제는 사람들에게 시간과 노력을 절약하기 위해 자동으로 관련 연구 주제에 대한 통합적인 설문 조사를 생성하는 것을 목표로 한다. 기존 방법은 대규모 과학적 말뭉치에서 사람이 주석을 단 참고 문헌을 정보원으로 사용함으로써 이 작업을 단순화했지만 시간과 비용이 많이 든다.
    2. 본 논문에서는 대규모 언어 모델(LLM)을 기반으로 참고 문헌 검색과 관련 작업 생성 프로세스를 통합된 프레임워크로 결합하는 통합 참고문헌 검색 및 관련 작업 생성 모델(UR3WG)을 제안한다. UR3WG는 먼저 LLM의 세계 지식을 활용하여 초록을 확장하고 후속 검색 단계를 위한 쿼리를 생성한다. 그런 다음 중요성을 고려한 렉시콘 개선형 밀집 검색이 제안되어 관련 참고 문헌을 검색한다. 또한 리트리버를 최적화하기 위해 다중 층위 대조 학습을 제안한다.
    3. 이 작업은 단순히 참고 문헌의 주요 포인트를 요약하는 것이 아니므로 복잡한 관계를 분석하고 논리적으로 제시해야 한다. 또한 LLM을 활용하여 관련 작업을 생성하기 위해 인스트럭션 튜닝 방법을 제안한다. 널리 적용된 두 개의 데이터셋에서의 실험 결과는 우리 모델이 생성 및 검색 메트릭에서 최신 기법을 능가한다는 것을 보여준다.

###### Visual Storytelling with Question-Answer Plans (https://aclanthology.org/2023.findings-emnlp.386/)
- Anthology ID: 2023.findings-emnlp.386 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이미지 시퀀스로부터 흥미로운 내러티브를 생성하는 시각적 스토리텔링은 기존 모델들이 주로 외부 지식 소스나 고급 그래프 구조와 같은 이미지 시퀀스의 표현을 향상시키는 데 초점을 맞추었다. 
    2. 그러나 최근 연구들에서는 이러한 이야기들이 자주 반복되거나 논리적으로 알맞지 않으며 세부 정보가 부족하다는 문제점이 있다. 
    3. 이 논문에서는 이미지 시퀀스를 시각적 접두사로 변환하여 언어 모델이 해석할 수 있는 연속적인 임베딩의 시퀀스로 표현한 후, 질문-답변 쌍의 시퀀스를 기반으로 강조할 시각적 개념을 선택하고 이를 내러티브로 결합하는 계획을 수립하는 새로운 프레임워크를 제안한다.

###### Investigating Online Community Engagement through Stancetaking (https://aclanthology.org/2023.findings-emnlp.387/)
- Anthology ID: 2023.findings-emnlp.387 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문은 Reddit 커뮤니티에서 stance markers가 사용되는 문맥의 stance-relevant properties를 고려하지 않은 채로 커뮤니티 간의 유사성을 탐구한 대규모 컴퓨팅 작업에 대해 다룬다.
    2. 우리는 1798개의 Reddit 커뮤니티를 위한 stance context 표현을 제안하고, 이 표현이 텍스트나 marker 유사도 측정치와는 다른 커뮤니티 아이덴티티 패턴을 포착한다는 것을 보여준다.
    3. 또한, 우리는 stance context 표현을 cross-community posting patterns과 커뮤니티의 소셜 네트워크 특성과 연결해 보다 포괄적인 커뮤니티 간 및 커뮤니티 내 참여 패턴을 관찰한다. 우리의 연구 결과는 stance의 풍부한 특성을 이용하여 온라인 다중 커뮤니티 공간에서 커뮤니티 아이덴티티와 참여 패턴을 드러내는 데의 강점을 강조한다.

###### ASSERT: Automated Safety Scenario Red Teaming for Evaluating the Robustness of Large Language Models (https://aclanthology.org/2023.findings-emnlp.388/)
- Anthology ID: 2023.findings-emnlp.388 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델이 사회에 통합됨에 따라, 다양한 환경에서 신뢰성을 유지하기 위해 다양한 프롬프트에 대한 강건함 평가가 점점 중요해지고 있다. 
    2. 이 논문에서는 자동화된 안전 시나리오 레드팀인 ASSERT를 제안하며, semantic alignment augmentation, target bootstrapping, adversarial knowledge injection 등 세 가지 방법을 소개한다. 
    3. 이를 통해 AI 안전 분야에서 강건성 설정을 포괄적으로 커버하는 테스트 스위트를 알고리즘적으로 생성하고 모델 성능에 미치는 도메인 효과를 분석한다.

###### Learning to Correct Noisy Labels for Fine-Grained Entity Typing via Co-Prediction Prompt Tuning (https://aclanthology.org/2023.findings-emnlp.389/)
- Anthology ID: 2023.findings-emnlp.389 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 세부적인 entity typing (FET) 작업은 텍스트에서 entity에 의미적인 유형을 할당하는 것을 목표로 하는데, 이 작업에서는 labeling noise 문제가 있어 현재의 방법들은 노이즈 분포를 추정하여 잘못된 라벨을 식별하지만 다양한 노이즈 분포 편차로 혼란스러워한다.
    2. 우리는 FET에서 noise 수정을 위해 Co-Prediction Prompt Tuning을 소개하는데, 이는 여러 예측 결과를 활용하여 잘못된 라벨을 식별하고 수정한다.
    3. 실험 결과, 우리의 노이즈 수정 접근법은 먼 감독, ChatGPT, 크라우드소싱을 이용하여 주석을 단 다양한 유형의 훈련 샘플의 품질을 signficantly 향상시키는 것을 보여준다.

###### Co2PT: Mitigating Bias in Pre-trained Language Models through Counterfactual Contrastive Prompt Tuning (https://aclanthology.org/2023.findings-emnlp.390/)
- Anthology ID: 2023.findings-emnlp.390 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사회적 편향을 제거하기 위한 효과적이고 효율적인 debias-while-prompt tuning 방법인 Co2PT를 제안한다. 
    2. Co2PT는 downstream task에서 counterfactual contrastive prompt tuning을 통해 편향을 완화하는데 효과적이며, 기존 upstream debiased language model에 적용 가능한 적응성을 보여준다.
    3. 3가지의 extrinsic bias 벤치마크 실험을 통해 Co2PT의 bias 완화 역량을 입증하였으며, downstream task에서의 편향 완화를 위한 발전 가능성을 제공한다.

###### A Hierarchical Encoding-Decoding Scheme for Abstractive Multi-document Summarization (https://aclanthology.org/2023.findings-emnlp.391/)
- Anthology ID: 2023.findings-emnlp.391 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사전 학습 언어 모델 (PLM)은 추상적 단일 문서 요약 (SDS)에서 뛰어난 성과를 거두었다. 그러나 이러한 이점은 다중 문서 요약 (MDS)에 충분히 적용되지 않을 수 있다. 
    2. 이전 연구들은 새로운 MDS 아키텍처를 설계하거나 단순한 SDS 태스크로 PLM을 적용하는 방식을 사용했다. 그러나 전자는 이전 사전 학습의 노력을 활용하지 못하며, 후자는 MDS 태스크에 특유한 복잡한 문서 간 관계에 충분히 주의를 기울이지 못할 수 있다. 
    3. 대신에 우리는 PLM을 활용하여 MDS 작업을 위해 다중 문서 상호 작용을 더 잘 이용하기 위해 인코더와 디코더에 계층 구조를 강제로 적용한다. 다양한 도메인의 10개의 MDS 벤치마크에서 우리의 방법은 기존의 최고 모델보다 우수한 성능을 보여주었다.

###### Universal Domain Adaptation for Robust Handling of Distributional Shifts in NLP (https://aclanthology.org/2023.findings-emnlp.392/)
- Anthology ID: 2023.findings-emnlp.392 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 실제 환경에 기계 학습 시스템을 배포할 때, 사용자가 알 수 없는 도메인에서 사전 지식을 효과적으로 활용하면서도 이상한 입력에 경고를 내놓는 것이 매우 바람직하다. 
    2. 컴퓨터 비전에서 지식 전이를 포함하는 UniDA(Universal Domain Adaptation) 기법은 주어진 도메인으로의 적응능력과 이상 값 검출능력을 동시에 달성하기 위해 연구되었다.
    3. 이 논문에서는 UniDA 기법을 자연어 입력에 적용해보고, 다양한 난이도와 특성을 가진 여러 데이터셋을 포함하는 종합적인 Natural Language benchmark를 제안한다.

###### Aligning Language Models to User Opinions (https://aclanthology.org/2023.findings-emnlp.393/)
- Anthology ID: 2023.findings-emnlp.393 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 인간과 상호작용하는 LLM을 개발하는 중요한 측면은 모델의 행동을 사용자에게 일치시키는 것이다. 
    2. 우리는 PEW 조사를 통해 사용자의 의견, 인구통계학적 특성, 이념과 상관관계가 서로 독립적임을 발견하였고, 이 통찰력을 활용하여 LLM을 사용자의 의견과 인구통계학적 특성, 이념으로 일치시키는 방법을 제안한다. 
    3. 우리의 연구는 사용자 의견을 언어 모델과 일치시키는 데 중요한 요소로 생각할 수 있는 연구 방향을 열어준다.

###### CCSRD: Content-Centric Speech Representation Disentanglement Learning for End-to-End Speech Translation (https://aclanthology.org/2023.findings-emnlp.394/)
- Anthology ID: 2023.findings-emnlp.394 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 심층 신경망은 음성 입력에서 특징을 추출하는 데에 성공했지만, 이러한 특징은 음성의 의미와 직접적으로 관련이 없는 음색과 화자 식별과 같은 비언어적인 요소를 포함할 수 있다.
    2. 이 논문에서는 음성 통역을 위해 음성 표현을 콘텐츠 중심의 구조로 분리하는 CCSRD라는 프레임워크를 제안한다. 이를 위해 음성의 콘텐츠 정보를 인코딩하는 콘텐츠 인코더, 비언어적 특징을 모델링하는 비콘텐츠 인코더, 그리고 순환 복원자, 특징 복원자, 화자 분류기로 구성된 구분 모듈을 활용하여 분리된 표현을 학습한다.
    3. MuST-C 벤치마크 데이터셋을 통한 실험 결과, CCSRD는 기준선 대비 두 가지 설정에서 다섯 가지 번역 방향에 걸쳐 평균 +0.9 BLEU의 성능 향상을 보여주며, 최첨단 엔드 투 엔드 음성 통역 모델과 단계별 모델을 능가한다.

###### Miracle: Towards Personalized Dialogue Generation with Latent-Space Multiple Personal Attribute Control (https://aclanthology.org/2023.findings-emnlp.395/)
- Anthology ID: 2023.findings-emnlp.395 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 개인화된 대화 시스템은 챗봇 에이전트가 인간과 유사한 상호작용을 할 수 있도록 하는 것을 목표로 한다. 그러나 기존 접근 방식은 문장 설명을 사용하여 사용자 프로필 모델링, 사용자 임베딩의 암묵적 유도, 또는 ChatGPT와 같은 모델에 대한 수작업 프롬프트를 사용하고 있다.
    2. 이 논문에서는 복잡한 개인화된 대화 생성 작업을 수행하기 위해 Miracle 이라는 새로운 방법론을 제안한다. 이 방법은 복잡한 성격을 여러 가지 다양한 속성으로 분리하고, 조건부 변분 오토인코더를 사용하여 잠재적인 속성 공간 내의 밀집 개인화된 응답과 조화를 이룬다.
    3. 실험 결과, Miracle은 성격의 조절 가능성과 응답 생성 품질 측면에서 몇 가지 강력한 기준선을 능가한다.

###### Towards Multilingual Interlinear Morphological Glossing (https://aclanthology.org/2023.findings-emnlp.396/)
- Anthology ID: 2023.findings-emnlp.396 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 인터리니어 형태 밝힘 (Interlinear Morphological Glosses)은 언어 문서화 작업에서 만들어진 주석이다. 이 논문에서는 이러한 주석을 자동으로 생성하는 작업을 연구하고 있다.
    2. 형태 밝힘 생성을 위해 Conditional Random Field (CRF)를 사용하며, 이를 통해 L1 모포(morphs)를 레이블링하고 동시에 L2 단어에 매치시키고 있다.
    3. 저자들은 이러한 접근법이 몇 가지 저리어 데이터에서 효과적이며 데이터 효율성도 높아지며, 알려지지 않은 모포(morphs)에 주석을 달기 어려운 문제도 해결할 수 있음을 실험적으로 보여주고 있다.

###### Transformer Working Memory Enables Regular Language Reasoning And Natural Language Length Extrapolation (https://aclanthology.org/2023.findings-emnlp.397/)
- Anthology ID: 2023.findings-emnlp.397 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 RNN 모델과 달리, Transformer는 완벽히 정규 언어(regular languages)를 모델링할 수 없다고 알려져 있으나, 이 논문에서는 RegularGPT라는 새로운 Transformer 변형 모델을 제안한다.
    2. RegularGPT는 Weight-Sharing, Adaptive-Depth, Sliding-Dilated-Attention이라는 새로운 기법을 결합하여 규칙 언어 (PARITY와 같은)를 효과적으로 모델링할 수 있는 작업 메모리 (working memory)를 구축한다.
    3. 또한 RegularGPT를 자연어 길이 외삽(natural language length extrapolation) 작업에 적용하여, 이전 연구에서 길이 외삽에 필요하다고 여겨져 오던 로컬 윈도우어 어텐션 효과를 재발견하는 것으로 나타냈다.

###### Enhancing Conversational Search: Large Language Model-Aided Informative Query Rewriting (https://aclanthology.org/2023.findings-emnlp.398/)
- Anthology ID: 2023.findings-emnlp.398 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화 검색을 향상시키기 위해 질문 재작성은 맥락-의존 사용자 질문을 독립적인 형태로 변환하는 데 중요한 역할을 한다. 
    2. 기존 방법은 사람이 재작성한 질문을 사용하여 모델을 훈련시키지만, 이러한 인간 재작성은 최적의 검색 성능을 위한 충분한 정보를 갖지 못할 수 있다. 
    3. 이 논문에서는 큰 언어 모델을 쿼리 재작성 도구로 사용하여 잘 설계된 지시사항을 통해 정보성 있는 쿼리 재작성을 생성하는 방법을 제안한다. 게다가 초기 쿼리 재작성이 있는 경우에는 LLM의 수정 편집자 역할을 도입하여 "재작성 후 편집" 프로세스를 형성한다.

###### Distilling ChatGPT for Explainable Automated Student Answer Assessment (https://aclanthology.org/2023.findings-emnlp.399/)
- Anthology ID: 2023.findings-emnlp.399 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자동화된 학생 답안 평가를 위해 명시적이고 정확한 피드백을 제공하는 것은 매우 중요하다.
    2. 이 논문에서는 ChatGPT, 즉 최첨단 대형 언어 모델을 사용하여 학생 답안 점수화와 근거 생성을 동시에 수행하는 새로운 프레임워크를 소개한다.
    3. 실험 결과 및 인간 평가를 통해 우리의 방법이 ChatGPT의 근거 생성 결과와 비교 가능하다는 것을 보여준다. 우리의 접근 방식은 교육에서 설명 가능한 자동 평가를 구현하기 위한 실질적인 해결책을 제공한다.

###### Grammatical Error Correction via Mixed-Grained Weighted Training (https://aclanthology.org/2023.findings-emnlp.400/)
- Anthology ID: 2023.findings-emnlp.400 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 문법 오류 수정(GEC)의 작업은 자연 텍스트에서 문법적인 오류를 자동으로 수정하는 것을 목표로 한다. 이전 연구들은 주석이 달린 훈련 데이터를 동등하게 처리하지만, 데이터의 내재적인 불일치를 무시한다.
    2. 따라서 우리는 MainGEC를 제안하는데, 이는 내재적인 불일치를 고려하여 토큰 수준과 문장 수준의 훈련 가중치를 설계하고, 혼합된 정도의 가중치 훈련을 수행하여 GEC의 훈련 효과를 향상시킨다.
    3. 실험 결과, Seq2Seq 또는 Seq2Edit 방식에서도 MainGEC는 두 가지 벤치마크 데이터셋에서 일관된 성능 향상을 이끌어 내며, 설계된 가중치의 효과를 검증하기 위한 추가 실험도 효과적임을 보여준다.

###### A Unified Framework for Synaesthesia Analysis (https://aclanthology.org/2023.findings-emnlp.401/)
- Anthology ID: 2023.findings-emnlp.401 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Synaesthesia"은 감각 운동을 다른 감각으로 표현하는 현상으로, 이는 언어적 현상 뿐만 아니라 인간의 사고와 행동을 구성하는 인지 현상으로 이해하기 어렵다. 
    2. 이 논문은 모든 종류의 Synaesthesia 요소를 주석으로 달고 그들 사이의 관계를 완전히 탐구하기 위한 통합 프레임워크를 제안한다. 
    3. 특히, 우리는 감각 운동뿐만 아니라 그들의 힌트와 자극을 포함한 새로운 주석 체계를 도입하여 Synaesthetic 정보를 효과적으로 이해할 수 있도록 한다.

###### Domain Private Transformers for Multi-Domain Dialog Systems (https://aclanthology.org/2023.findings-emnlp.402/)
- Anthology ID: 2023.findings-emnlp.402 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 일반적인 큰 규모의 언어 모델은 다양한 대화 도메인에서 인상적인 성능을 보이고 있다. 그러나 다양한 도메인에 대한 출력을 보장할 수 없으므로 도메인 따른 개인 정보 보호 방법인 "도메인 프라이버시"를 제안한다.
    2. 토큰 수준의 도메인 분류를 기반으로 정책 함수를 개발하고 훈련된 모델의 도메인 프라이버시를 개선하기 위한 효율적인 미세 조정 방법을 제안한다.
    3. 멤버쉽 추론 공격에 대한 실험에서 우리의 제안된 방법이 최근에 다루었던 동적 사생활 언어 모델에서 적용된 방법과 유사한 저항력을 가짐을 보여준다.

###### Visual Elements Mining as Prompts for Instruction Learning for Target-Oriented Multimodal Sentiment Classification (https://aclanthology.org/2023.findings-emnlp.403/)
- Anthology ID: 2023.findings-emnlp.403 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Target-oriented Multimodal Sentiment Classification (TMSC)는 문장 내 특정 대상에 대한 감성 극성을 식별하기 위해 시각적 모달리티와 텍스트 모달리티를 결합하는 것을 목표로 한다."
    2. "VEMP(VIsual Elements Mining as Prompts) 방법을 제안하여 시각적 요소의 의미 정보를 텍스트 심볼로 내장된 이미지(TSEI), 대상을 고려한 형용사-명사 쌍(TANPs) 및 이미지 장면 설명으로 기술하고 이를 모델 Tk-Instruct의 인스트럭션 학습을 위한 프롬프트로 변환한다."
    3. "실험 결과, 우리의 방법이 두 개의 벤치마크 데이터셋에서 최고의 성능을 달성하며, 추가적인 분석에서 우리의 방법의 각 구성 요소의 효과를 입증한다."

###### NASH: A Simple Unified Framework of Structured Pruning for Accelerating Encoder-Decoder Language Models (https://aclanthology.org/2023.findings-emnlp.404/)
- Anthology ID: 2023.findings-emnlp.404 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Structured pruning 방법은 Transformer와 같은 다양한 네트워크 구조에서 모델 크기를 줄이고 추론 속도를 빠르게 하는 데 효과적으로 사용된다.
    2. 하지만 encoder-decoder 모델에서 structured pruning 방법은 encoder-only 모델에 비해 상대적으로 조금 연구되었다.
    3. 이 연구에서는 encoder와 decoder 구성 요소를 분리된 방식으로 structured pruning하는 encoder-decoder 모델의 동작을 조사하였고, 그 결과를 통해 encoder 레이어의 수가 추론 속도에 지배적인 요소이며, pruned encoder 네트워크의 낮은 희소도가 생성 품질을 향상시킨다는 두 가지 인사이트를 제시하였다.

###### GBT: Generative Boosting Training Approach for Paraphrase Identification (https://aclanthology.org/2023.findings-emnlp.405/)
- Anthology ID: 2023.findings-emnlp.405 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 문장의 쌍이 동일한 의미를 나타내는지 판별하는 Paraphrase Identification (PI) 작업은 정보 검색과 질문 응답에서 널리 사용되는데, 데이터 확장 (DA)은 PI 작업에 효과적이라 증명되었습니다. 그러나 대부분의 DA 방법은 비효율성과 낮은 품질의 한계를 가지고 있습니다.
    2. 이 연구에서는 PI를 위해 Generative Boosting Training (GBT) 접근 방식을 제안합니다. GBT는 인간 학습 과정을 기반으로 단일 모델에 대한 부스팅 학습 방법을 설계하며, 주기적으로 misclassified 인스턴스에 대한 seq2seq 모델을 사용하여 DA를 수행합니다.
    3. 실험 결과, GBT의 부스팅을 통해 단일 BERT 모델은 효율적이고 효과적인 성능을 보여주며, Pre-trained Language Model (PLM) 기반 기준 모델보다 우수한 성능을 보입니다.

###### DeCrisisMB: Debiased Semi-Supervised Learning for Crisis Tweet Classification via Memory Bank (https://aclanthology.org/2023.findings-emnlp.406/)
- Anthology ID: 2023.findings-emnlp.406 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 위기 상황에서 사람들은 주로 Twitter와 같은 소셜 미디어 플랫폼을 사용하여 상황에 대한 정보, 경고, 조언 및 지원을 전파한다. 이 논문에서는 위기 사태 분석을 위해 사회적 미디어에서 얻은 정보를 활용하는데, 최신 디바이어싱 방법을 연구하고 새로운 디바이어싱 방법을 제안한다.
    2. 완전 감독 학습은 방대한 양의 데이터를 주석으로 달아야 하므로 제한된 응답 시간 때문에 실용적이지 않다. 반면, 반감독 모델은 일부 클래스에는 중간 결과를 얻지만 다른 클래스에는 극히 부정확하게 수행되어 재난 모니터링과 구조에 심각한 영향을 줄 수 있다.
    3. 이 논문에서는 반감독 위기 트윗 분류에서 최근의 두 디바이어싱 방법을 연구하고, 각 훈련 반복마다 각 클래스의 생성된 가짜 레이블로부터 동일한 샘플링을 수행하는 메모리백(Memory Bank)을 활용한 간단하면서도 효과적인 디바이어싱 방법인 DeCrisisMB를 제안한다.

###### Probing LLMs for hate speech detection: strengths and vulnerabilities (https://aclanthology.org/2023.findings-emnlp.407/)
- Anthology ID: 2023.findings-emnlp.407 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 소셜 미디어 플랫폼과 연구자들은 최근 대형 언어 모델을 사용하여 혐오 또는 유해한 언어를 탐지하려는 노력을 기울이고 있다. 그러나 이러한 연구들에서는 설명, 추가적인 맥락, 피해자 정보를 탐지과정에 활용하지 않는다.
    2. 본 연구에서는 다양한 prompt 변형, 입력 정보를 활용하고, 인과관계를 추가하지 않은 상황에서 대형 언어 모델의 성능을 평가한다. 이를 통해 모델 성능을 개선하기 위해 목표 정보를 파이프라인에 포함시키는 것이 효과적임을 확인한다.
    3. 또한, 모델이 올바르게 분류하거나 그 이유를 설명하지 못하는 오류 사례들의 유형을 제시하고, 이러한 취약점들은 모델에 대한 'jailbreak' prompt로 작용할 수 있으며, 이를 대비하기 위한 산업용 안전장치 기술의 개발이 필요하다.

###### From Simple to Complex: A Progressive Framework for Document-level Informative Argument Extraction (https://aclanthology.org/2023.findings-emnlp.408/)
- Anthology ID: 2023.findings-emnlp.408 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Document-level Event Argument Extraction (EAE)는 단일 문서에서 여러 이벤트의 인자(argument)를 추출하는 모델에 더 의존하기 때문에 이러한 이벤트들 사이의 종속성(dependencies)을 고려해야 한다. 
    2. 기존 방법들은 문서에서 이벤트들이 나타나는 순서에 따라 추출하지만, 첫 번째 문장에 나타나는 이벤트가 가장 추출하기 쉬운 것은 아니다. 
    3. 이 논문에서 제안하는 simple-to-complex 접근법은 이벤트의 난이도를 계산한 다음, 추출을 단순한 것부터 복잡한 순서로 수행하여 더 확실한 결과를 메모리에 저장하고, 모델은 이 신뢰할 수 있는 정보를 사용하여 더 어려운 이벤트를 예측한다.

###### MultiCMET: A Novel Chinese Benchmark for Understanding Multimodal Metaphor (https://aclanthology.org/2023.findings-emnlp.409/)
- Anthology ID: 2023.findings-emnlp.409 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 메타포는 인간의 의사소통에서 보편적인 측면이며, 대중 매체의 발전과 함께 다중 모드 형태로의 존재가 더욱 두드러지게 되었다. 그러나 다중 언어적 메타포 자원에 대한 연구는 제한적이며, 기존의 자연어 처리 작업은 메타포의 소스와 타겟 도메인을 분류하는 탐색을 다루지 않고 있다. 
    2. 이 연구에서는 다중 모달 중국 메타포 데이터셋인 MultiCMET을 소개하고, 광고의 텍스트-이미지 쌍 13,820개에 대한 메타포, 도메인 카테고리, 그리고 메타포가 전달하는 감성에 대해 수동으로 주석을 달았다.
    3. 또한, 도메인 특정 어휘 기능을 소개함으로써 메타포를 감지하기 위한 Cascading Domain Knowledge Integration (CDKI) 벤치마크를 구축했으며, 실험 결과 CDKI의 효과를 입증하였다. 데이터셋과 코드는 공개되어 있다.

###### GlotLID: Language Identification for Low-Resource Languages (https://aclanthology.org/2023.findings-emnlp.410/)
- Anthology ID: 2023.findings-emnlp.410 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 많은 논문들이 300개 정도의 고자원 및 중간자원 언어에 대한 언어 식별(LID)에 대한 좋은 솔루션을 발표했지만, 저자원 언어, 신뢰성, 효율성, 사용 용이성에 대한 특징( desiderata)을 만족하는 LID 모델이 없다.
    2. 이 논문에서는 GlotLID-M이라는 LID 모델을 발표하며 저자원 언어에 대해 넓은 범위의 커버리지, 신뢰성 및 효율성 조건을 만족시키는 것을 보여준다.
    3. GlotLID-M은 1665개 언어를 식별하며, 이전 작업에 비해 커버리지가 크게 증가한다. 실험 결과, F1과 false positive rate (FPR)를 가중치로 잡을 때 GlotLID-M은 네 개의 베이스라인(CL, FT176, OpenLID, NLLB)을 능가한다.

###### Finding Support Examples for In-Context Learning (https://aclanthology.org/2023.findings-emnlp.411/)
- Anthology ID: 2023.findings-emnlp.411 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "In-context learning"은 언어 모델이 몇 가지 예시를 관찰하고 테스트 입력에 대한 예측을 직접 출력하는 새로운 학습 패러다임이다. 그러나 기존 방법들은 제공된 예시에 민감하며 무작위로 샘플링된 예시는 성능이 낮을 수 있다. 
    2. 이 논문에서는 in-context learning에 최적인 "support examples"를 찾기 위한 방법을 제안한다. 이를 위해 언어 모델의 피드백을 기반으로 예시의 in-context 정보성을 평가하는 새로운 메트릭을 제안하고, 이를 이용하여 예시를 선별하는 과정을 진행한다. 
    3. 실험 결과, 이 알고리즘은 다양한 기준모델보다 우월한 성능을 보이며, 각 구성요소가 성능 향상에 중요한 역할을 하는 것으로 나타났다. 이를 통해 supporting examples와 in-context learning의 원리에 대한 통찰을 얻을 수 있다.

###### Uncovering the Root of Hate Speech: A Dataset for Identifying Hate Instigating Speech (https://aclanthology.org/2023.findings-emnlp.412/)
- Anthology ID: 2023.findings-emnlp.412 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존 hate speech 탐지와 중재 방법에는 주로 기계학습 등의 컴퓨터적 접근이 사용되어왔지만, hate speech의 근본 원인을 찾는 작업은 미비한 상태였다. 
    2. 이 연구에서는 hate instigating speech라는 개념을 소개하며, 이는 다른 사람들이 hate speech에 동참하도록 유도하거나 자극하는 특정 유형의 온라인 텍스트 게시물을 말한다. 
    3. hate instigating speech의 식별은 효과적인 hate speech 중재에 상당한 영향력을 가지며, hate speech의 뿌리인 hate instigating speech에 초점을 맞추면 중재 검토가 필요한 콘텐츠의 양을 크게 줄일 수 있다.
    
    abstract: A difficulty of creating high-quality Multiple Choice Questions (MCQs) for educational purposes lies in the lack of good metrics for evaluating their quality. We propose using Knowledge Dependent Answerability (KDA) as a novel evaluation metric to measure the MCQ's ability to assess the student's knowledge of the corresponding target fact. This metric takes into account the answerability of the MCQ given knowledge of the target fact, unlike existing metrics that only evaluate the similarity of the generated MCQ to a gold sample in the dataset. Through human studies, we demonstrate the strong correlation of KDA_disc and KDA_cont with the usability and effectiveness of MCQs in an actual classroom setting, as labeled by experts.
    
    1. MCQ의 품질을 평가하는 좋은 메트릭스의 부재로 인해 교육 목적으로 높은 품질의 MCQ를 만드는 데 어려움이 있다. 
    2. 이 논문에서는 MCQ가 대응하는 학생의 지식을 평가하는 능력을 측정하기 위해 Knowledge Dependent Answerability (KDA)를 새로운 평가 메트릭으로 제안한다. 
    3. 기존 메트릭과 달리 KDA는 MCQ의 대상 사실에 대한 지식을 고려하여 평가하며, 인간 연구를 통해 KDA_disc와 KDA_cont가 실제 강의실에서의 사용성과 효과에 강한 상관관계를 가짐을 보였다.

###### Responsible AI Considerations in Text Summarization Research: A Review of Current Practices (https://aclanthology.org/2023.findings-emnlp.413/)
- Anthology ID: 2023.findings-emnlp.413 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. AI 및 NLP 연구에는 주로 윤리적 고려 사항, 부정적 영향 및 다른 책임 있는 AI 문제에 대해 생각하도록 요구한다. 하지만, 텍스트 요약과 같은 특정 NLP 작업에서 이러한 문제가 얼마나 흔한지 또는 언제, 그리고 왜 이러한 문제가 발생할 가능성이 있는지에 대한 이해는 여전히 제한적이다.
    2. 이 논문에서는 화자인 AI 커뮤니티에서 주로 간과되는 텍스트 요약과 같은 주요 NLP 작업에서 연구 및 보고 관행을 조사한다.
    3. 연구 방법을 기반으로 매우 제한적인 논문에서 잠재적인 부정적 영향이나 다른 책임 있는 AI 문제를 고려하는 것이 제한되고 있음을 발견하였다. 이를 바탕으로 구체적인 연구 방향과 실천 사례에 대한 권고사항을 제시한다.

###### Improving Speech Translation by Fusing Speech and Text (https://aclanthology.org/2023.findings-emnlp.414/)
- Anthology ID: 2023.findings-emnlp.414 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 연구에서는 언어 번역을 개선하기 위해 음성과 텍스트의 상호 보완적인 특성을 활용한다.
    2. 하지만 음성과 텍스트는 다른 특성을 가지고 있어 통합이 어려운데, 이러한 특성 차이를 해결하기 위해 FuseST라는 모델을 제안한다.
    3. FuseST는 음성, 텍스트, 그리고 통합된 음성-텍스트 세 가지 입력 형태를 지원하며, MuST-C, GigaST, newstest benchmark에서 우수한 성능을 보인다.

###### Narrative Order Aware Story Generation via Bidirectional Pretraining Model with Optimal Transport Reward (https://aclanthology.org/2023.findings-emnlp.415/)
- Anthology ID: 2023.findings-emnlp.415 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 매력적인 이야기를 만들기 위해 작가는 종종 논리적으로 일관된 사건의 연속을 계획하고 서사적 순서를 요령 있게 조작하여 플래시백을 생성한다. 그러나 기존의 이야기 생성 시스템은 사건 간 상관관계를 충분히 이해하지 못하고 사건의 시간적 순서에 대한 인식도 부족하여, 이야기의 논리와 서사적 순서를 균형있게 잡는 고품질 사건을 생성하는 것이 어렵다.
    2. 본 논문에서는 이야기 생성을 위한 narrative order 인식 프레임워크 BPOT를 제안한다. 이 프레임워크는 이벤트 간 상관관계와 이벤트 간 순서를 양방향으로 사전 훈련(pretraining)하는 모델을 제시한다. 또한, 심층 강화학습 알고리즘과 새로운 optimal transport reward를 설계하여 세부 튜닝 단계에서 생성된 사건의 품질을 더욱 개선한다.
    3. 자동 및 수동 평가 결과 모두, 우리의 프레임워크가 논리적으로 일관된 플래시백을 가진 이야기를 생성하는 데 우수함을 보여주고 있다.

###### Explainable Claim Verification via Knowledge-Grounded Reasoning with Large Language Models (https://aclanthology.org/2023.findings-emnlp.416/)
- Anthology ID: 2023.findings-emnlp.416 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Claim verification의 문제에서는 인간이 주석을 단 데이터의 사용 없이 claim을 검증하는 방법을 이해하는 것이 중요하다."
    2. 시험 데이터가 없이도 Comprehensive한 설명을 제공할 수 있는 모델을 제안한다.
    3. FOLK는 claim을 FOL (First-Order-Logic)로 번역하여 검증해주며, 이 프로세스는 사람이 읽을 수 있는 형태로 이해 과정을 설명한다.

###### Strong and Efficient Baselines for Open Domain Conversational Question Answering (https://aclanthology.org/2023.findings-emnlp.417/)
- Anthology ID: 2023.findings-emnlp.417 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존 연구들은 대화형 (ODConvQA) 도메인에 대한 baseline 성능 평가에 제한적인 관심을 보이고 있다. 
    2. 이 논문에서는 SotA(DPR retriever 및 FiD reader pipeline)가 ODConvQA 태스크에 적용될 때 여러 제한으로 인해 성능이 크게 저하됨을 보여준다. 
    3. 우리는 retriever와 reader 사이에 빠른 reranking 구성 요소를 도입하고, 대상 finetuning 단계를 수행함으로써 강력하면서도 단순하고 효율적인 baseline을 제안하고 평가한다. 이를 통해 SotA 결과를 향상시키고 reader의 지연 시간을 60% 감소시키는 것을 실험을 통해 보여준다.

###### Efficient Continue Training of Temporal Language Model with Structural Information (https://aclanthology.org/2023.findings-emnlp.418/)
- Anthology ID: 2023.findings-emnlp.418 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 현재 언어 모델은 특정 시점에서 수집된 데이터로 주로 훈련되며, 시간에 따라 일반화하고 언어 변화를 모델링하기 어려워진다. 
    2. 기존의 temporal language model(TempoBERT)은 훈련 과정에 타임스탬프를 직접 포함시켜 시간 변수를 모델링했다. 
    3. 이 논문에서는 토큰들과 함께 중요한 구문적 변화를 가지는 단어들과 시간 접두어 간의 내재적 관계를 기반으로 언어 변화를 학습하는 Syntax-Guided Temporal Language Model(SG-TLM)을 제안한다.

###### Retrieval-Augmented Parsing for Complex Graphs by Exploiting Structure and Uncertainty (https://aclanthology.org/2023.findings-emnlp.419/)
- Anthology ID: 2023.findings-emnlp.419 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 retrieval 방법은 복잡한 그래프 파싱 문제에서 정확한 예시를 식별하지 못해 부적절한 검색을 하고 제한된 검색 예산 하에서 유추된 결과를 얻기 때문에, 복잡한 그래프 문제에서 retrieval augmented 모델을 개선하기 위해 structural similarity와 model uncertainty 두 가지 독특한 정보를 활용하였다.
    2. 모델의 불확실성을 그래프 예측의 양자화하기 위해 SUGAR를 제안하였다. 가장 불확실한 서브그래프를 식별하고 이를 기준으로 예시를 검색한다.
    3. 복잡한 그래프 구조를 가진 실제 파싱 벤치마크에서, SUGAR는 구조나 모델의 불확실성을 고려하지 않는 전통적인 방법에 비해 강력한 성능을 보였다.

###### When it Rains, it Pours: Modeling Media Storms and the News Ecosystem (https://aclanthology.org/2023.findings-emnlp.420/)
- Anthology ID: 2023.findings-emnlp.420 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대부분의 사건들은 뉴스 매체에서 짧은 보도만 받지만, 가끔은 하나의 사건이 뉴스를 뒤집어 놓고 몇 주 동안 지속되는 대량의 보도가 나온다. 
    2. 이 연구에서는 두 개의 기사 유사도 모델을 개발함으로써 지역 및 국가 온라인 뉴스를 커버하고 대략 2년 동안의 매체 폭풍을 포함하는 포괄적인 말뭉치를 만들었다. 
    3. 이를 통해 우리는 매체 폭풍의 진화와 주제 분포에 대한 확인하고 이를 통해 매체 보도와 매체 간의 어제타설 순서에 대한 이전 가설에 대한 증거를 제공할 수 있었다.

###### Intra-Event and Inter-Event Dependency-Aware Graph Network for Event Argument Extraction (https://aclanthology.org/2023.findings-emnlp.421/)
- Anthology ID: 2023.findings-emnlp.421 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "이벤트 인자 추출은 구조화된 정보를 제공하기 위해 다양한 자연어 처리 작업에 있어서 중요하다. 기존의 방식은 일일히 이벤트 인자를 추출하고 이벤트 구조의 관점에서 인자 역할 간의 의존성 정보를 구축하는 것을 주로 소홀히 한다."
    2. "이 논문에서는 다른 역할 간의 의존성을 적절하게 모델링하여 성능을 높이는 방법에 대해 연구한다."
    3. "우리는 이벤트 구조를 기반으로 하는 intra-event와 inter-event 의존성을 고려한 그래프 네트워크를 제안하고, 의존성 정보와 이벤트 표현을 최적화하기 위해 의존성 상호작용 모듈과 보조 과업을 소개한다. 실험 결과는 우리가 제안한 방법의 큰 장점을 보여준다."

###### From Relevance to Utility: Evidence Retrieval with Feedback for Fact Verification (https://aclanthology.org/2023.findings-emnlp.422/)
- Anthology ID: 2023.findings-emnlp.422 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 검증 증명 (FV)에서 검색 강화 방법은 주요 접근법이 되었으며, 명제의 정당성을 검증하기 위해 여러 검색된 증거에 대한 추론이 필요하다. 
    2. 기존의 작업은 자주 사용되는 검색 모델을 사용하여 증거를 검색하며, 확률 순위 원칙에 기반한 모델을 사용한다. 하지만, FV에서는 관련성 대신 검증기가 전달된 증거에서 어떤 유틸리티를 얻는지에 집중해야 한다. 
    3. 우리는 claim verifier의 피드백을 통합하여 증거 검색 프로세스를 최적화하는 feedback-based evidence retriever (FER)를 소개한다. 실험 결과, FER가 기존의 기준에 비해 우월함을 입증하였다.

###### How to Train Your Dragon: Diverse Augmentation Towards Generalizable Dense Retrieval (https://aclanthology.org/2023.findings-emnlp.423/)
- Anthology ID: 2023.findings-emnlp.423 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 들어 DR(dense retrieval)를 개선하기 위해 비감독 대조 학습과 pseudo-query 생성과 같은 다양한 기술들이 개발되었지만, 기존 DR들은 supervises와 zero-shot retrieval 간의 효율성 절충을 겪는 경우가 많다.
    2. 본 논문에서는 DR의 contrastive learning에 대해 DA(data augmentation) 프레임워크 아래에서 체계적으로 연구하였다. 또한, 기존 DA의 일부 문제를 지적하고, 새로운 DA 접근법을 제안하여 일반화 가능한 DR을 훈련시켰다.
    3. DRAGON이라는 BERT-base 사이즈의 DR은 supervised와 zero-shot 평가에서 최고의 효과성을 달성하여, 더 복잡한 late interaction을 사용하는 모델들과도 경쟁할 수 있게 되었다.

###### Discovering Highly Influential Shortcut Reasoning: An Automated Template-Free Approach (https://aclanthology.org/2023.findings-emnlp.424/)
- Anthology ID: 2023.findings-emnlp.424 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Shortcut reasoning"은 NLP 모델의 robustness를 손상시키는 비합리적인 추론 과정이다. 이전 연구들은 shortcut reasoning을 식별하는 것에 대한 많은 노력이 있었지만, 발견된 shortcut reasoning의 심각성을 정량화하는 방법은 제시되지 않았고, 특정 유형의 shortcut reasoning이 누락될 수 있다는 두 가지 주요한 한계가 있다.
    2. 이러한 문제를 해결하기 위해, 우리는 shortcut reasoning을 식별하기 위한 새로운 방법을 제안한다. 제안된 방법은 out-of-distribution 데이터를 활용하여 shortcut reasoning의 심각성을 정량화하고, shortcut reasoning을 유발하는 토큰 유형에 대한 가정을 하지 않는다.
    3. Natural Language Inference와 Sentiment Analysis에서의 실험 결과는 우리의 프레임워크가 이전 연구에서 알려진 shortcut reasoning 뿐만 아니라 알려지지 않은 shortcut reasoning도 성공적으로 발견한다는 것을 보여준다.

###### Schema-adaptable Knowledge Graph Construction (https://aclanthology.org/2023.findings-emnlp.425/)
- Anthology ID: 2023.findings-emnlp.425 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 지식 그래프 구축 방식은 정적인 정보 추출 방식으로, 사전에 정의된 스키마로 제한되어 있다. 이는 동적인 상황이나 도메인에서 새로운 지식이 등장할 때 제대로 작동하지 못한다.
    2. 이에 따라 우리는 스키마 자동적으로 변화시키는 KGC를 위한 새로운 태스크를 제안한다. 이 태스크는 재학습 없이 동적으로 변화하는 스키마 그래프에 기반하여 entity, relation, event를 추출하는 것을 목표로 한다.
    3. 우리는 여러 가지 유명한 접근 방식들의 스키마 변화 대응 능력을 조사하고, AdaKGC라고 불리는 간단하지만 효과적인 베이스라인을 제안한다. 실험 결과, AdaKGC가 다른 방법들보다 우수한 성능을 보이지만, 아직 개선의 여지가 있다는 것을 보여준다.

###### Evaluating the Knowledge Base Completion Potential of GPT (https://aclanthology.org/2023.findings-emnlp.426/)
- Anthology ID: 2023.findings-emnlp.426 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 구조화된 지식 베이스(KB)는 검색 엔진 및 기타 응용 프로그램에 필수적이지만, 그들은 불완전할 수 있다. 
    2. 최근의 연구들은 대중적인 주제들에 대해 평가하거나 이미 존재하는 사실들을 샘플링하는 한계가 있다. 
    3. 본 연구에서는 GPT-3, ChatGPT 및 GPT-4와 같은 모델이 Wikidata와 같은 대형 KB를 완성하는 데 있어 완전히 설득력 있는 결과를 달성하지 못한다는 것을 발견했지만, 보다 작은 LMs에 비해 실질적인 개선을 보여준다.

###### Conic10K: A Challenging Math Problem Understanding and Reasoning Dataset (https://aclanthology.org/2023.findings-emnlp.427/)
- Anthology ID: 2023.findings-emnlp.427 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 인공지능의 능력을 평가하는 데 수학적 이해와 추론은 중요한 작업이다. 그러나 기존 벤치마크는 추론의 몇 단계만 요구하거나 특정 주제의 적은 양의 데이터만 포함하므로 다양한 문제를 세부적으로 분석하기 어렵다.
    2. 본 논문에서는 중국의 고교 교육에서의 Conic10K라는 도전적인 수학 문제 데이터셋을 제안한다. 이 데이터셋은 다양한 수리적 추론을 포함하고 있으며, 콘익 섹션에 대한 지식만 요구한다.
    3. 실험 결과, 기존의 대형 언어 모델 (GPT-4 포함)은 복잡한 추론에서 성능이 떨어진다. 이 연구는 더 정확한 자연어 이해와 추론 기술에 대한 발전을 위한 영감을 줄 것으로 기대된다.

###### DepWiGNN: A Depth-wise Graph Neural Network for Multi-hop Spatial Reasoning in Text (https://aclanthology.org/2023.findings-emnlp.428/)
- Anthology ID: 2023.findings-emnlp.428 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 공간적 추론은 다양한 실생활 응용에서 중요한 역할을 한다. 기존의 공간적 추론 접근법은 순수한 텍스트에서 공간적 관계를 추론하지만, 자연어와 심볼 구조 간의 차이를 간과한다.
    2. 이 논문에서는 그래프 신경망(GNN)을 활용하여 심볼 구조를 합성하고 집계하는 능력을 갖춘 새로운 방법을 제안한다. 
    3. 실험 결과로는 DepWiGNN이 기존의 공간적 추론 방법들보다 우수한 성능으로 장기 의존성을 포착하는 능력을 갖추고 있음을 보여준다.

###### TK-KNN: A Balanced Distance-Based Pseudo Labeling Approach for Semi-Supervised Intent Classification (https://aclanthology.org/2023.findings-emnlp.429/)
- Anthology ID: 2023.findings-emnlp.429 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화 시스템에서 의도 감지의 능력은 현대 기술에서 점점 더 중요해지고 있다. 그러나 이러한 시스템은 보통 레이블이 없는 많은 데이터를 생성하며, 이 데이터에 수작업으로 레이블을 붙이는 것은 상당한 인력이 필요하다. 
    2. 반지도 학습 방법은 일부 레이블이 달린 레이블을 훈련한 모델을 사용하고 모델 예측 확신이 특정 임계값보다 높은 일부 레이블이 달려있지 않은 레이블에 가짜 레이블(pseudo-label)을 지정하여 이 비용을 해결하려고 시도한다. 
    3. 본 논문에서는 임베딩 공간에서의 거리를 기반으로 한 더 견고한 가짜 레이블링 접근 방식을 사용하는 Top-K 최근접 이웃(TK-KNN)을 소개한다. 이는 랭킹 기반 접근 방식을 통해 클래스 간에 균형 잡힌 가짜 레이블이 달린 예제 세트를 유지하는 것을 목표로 한다.

###### Late Fusion of Transformers for Sentiment Analysis of Code-Switched Data (https://aclanthology.org/2023.findings-emnlp.430/)
- Anthology ID: 2023.findings-emnlp.430 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 코드 스위칭은 다중 언어를 사용하는 지역 사회에서 흔한 현상이지만, 코드 스위칭 데이터의 감성 분석은 도전적이면서도 소중한 연구 분야입니다.
    2. 논문에서는 두 개의 트랜스포머를 결합하여 (logits, 추정치) 생성한 후 신경망으로 입력하여 코드 스위칭 데이터에 대한 감성 분석 시스템을 개발합니다.
    3. 실험 결과, 우리의 접근 방식은 GLUECoS 벤치마크 데이터셋에서 최고 성능을 보여줌으로써 En-Es에서 73.66%, En-Hi에서는 61.24%의 F1 점수를 달성했습니다.

###### Inductive Relation Inference of Knowledge Graph Enhanced by Ontology Information (https://aclanthology.org/2023.findings-emnlp.431/)
- Anthology ID: 2023.findings-emnlp.431 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 지식 그래프의 추론은 그래프 내의 새로운 미지의 개체들 간의 잠재적인 관계를 완성하는 것을 목표로 한다. 기존 방법들은 그래프 구조 정보나 관계 정보와 같은 entity-independent feature들을 기반으로 추론을 한다.
    2. 하지만 새로운 개체들의 이웃은 종종 충분한 정보를 제공하지 못하여 이 feature들을 효과적으로 구성하는 데 어려움을 겪는다.
    3. 본 논문에서는 온톨로지 정보를 융합하는 지식 그래프 추론 방법을 제안한다. 초점이 되는 서브그래프를 기반으로 개념에 해당하는 feature embeddings를 가져와 온톨로지 내에 내재된 시맨틱 정보를 학습하며, 개체들과 개념들 사이의 시맨틱 관계를 명시적으로 모델링하기 위해 타입 제약 regular loss를 구축하여 개체의 누락된 개념들을 포착한다.

###### Dynamic Stance: Modeling Discussions by Labeling the Interactions (https://aclanthology.org/2023.findings-emnlp.432/)
- Anthology ID: 2023.findings-emnlp.432 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Stance detection은 주어진 주제에 대한 텍스트의 표현된 태도를 할당하여 일반화 능력이 떨어지고 주제에 강하게 의존하는 정적인 작업으로 주로 모델링되었다. 
    2. 이 논문에서는 메시지와 그에 대한 응답 간의 상호작용에 초점을 맞춘 동적인 작업으로 stance를 모델링하는 것을 제안한다.
    3. DySC라는 새로운 데이터셋을 만들고, 여러 언어에서 토픽과 언어 간의 이식성을 보여주기 위해 일련의 단일 언어 및 다국어 모델을 DySC에 대해 세밀하게 조정하였다.

###### Harnessing the Power of Large Language Models for Empathetic Response Generation: Empirical Investigations and Improvements (https://aclanthology.org/2023.findings-emnlp.433/)
- Anthology ID: 2023.findings-emnlp.433 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 공감 대화는 조화로운 사회적 관계 구축에 필수적인 부분이며, 도움이 되는 AI 개발에 기여한다. 이전 접근 방식은 주로 작은 규모의 언어 모델을 사용하였으나, ChatGPT의 등장으로 대형 언어 모델의 응용 효과가 큰 관심을 받고 있다.
    2. 본 연구는 대규모 언어 모델(Large Language Models)을 사용한 공감적인 대답 생성의 성능을 실험적으로 조사하고, 의미론적으로 비슷한 문맥 학습, 두 단계의 상호작용 생성과 지식 베이스와의 결합과 같은 세 가지 개선 방법을 제안한다.
    3. 광범위한 실험 결과, 대형 언어 모델은 우리가 제안한 방법을 통해 상당한 성과 향상을 이룰 수 있으며, 자동 및 인간 평가에서 최고의 성능을 달성할 수 있는 것으로 나타났다. 또한, GPT-4가 인간 평가자를 시뮬레이션하는 가능성도 탐색하였다.

###### GPT Deciphering Fedspeak: Quantifying Dissent Among Hawks and Doves (https://aclanthology.org/2023.findings-emnlp.434/)
- Anthology ID: 2023.findings-emnlp.434 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 세계의 시장과 정책 결정자들은 Federal Open Market Committee (FOMC)의 중대한 통화정책 결정에 많은 관심을 갖고 있다. 회의 기록에는 위원들의 경제에 대한 태도가 담겨있으며, 이들로부터 인플레이션에 대한 연구와 차별을 분석한다.
    2. 작은 차이점들이 공개적인 발언에서는 누락되기 때문에, 회의 기록과 소식통은 위원들의 다양한 의견을 보다 잘 반영하고 있다.
    3. 따라서, FOMC의 의견을 예측할 때는 진영 간의 의견 충돌을 충분히 반영하지 않는다면 정확하지 않을 수 있음을 주장한다.

###### DialogQAE: N-to-N Question Answer Pair Extraction from Customer Service Chatlog (https://aclanthology.org/2023.findings-emnlp.435/)
- Anthology ID: 2023.findings-emnlp.435 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 고객 서비스의 대화 기록에서 질문-답변 (QA) 쌍을 추출하여 차가운 시작 또는 지속적 통합 시나리오에서 고객 서비스 챗봇의 지식 베이스를 풍부하게 하는 것은 효율적인 방법이다.
    2. 기존 연구들은 성장하는 고객 서비스 챗봇의 대화 기록에서 1대1 QA 쌍을 얻으려고 시도하였으나, 대화 문맥에서 불완전한 발화를 통합하는 데 실패하였다.
    3. 이 논문에서는 N-to-N QA 추출 작업을 제안하며, 파생된 질문과 해당하는 답변이 서로 다른 발화에서 나뉠 수 있는 작업을 다룬다.

###### Inverse Reinforcement Learning for Text Summarization (https://aclanthology.org/2023.findings-emnlp.436/)
- Anthology ID: 2023.findings-emnlp.436 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 우리는 역 강화 학습(IRL)을 요약 모델 훈련에 적용하여 사람의 요약 행동을 모방하는 효과적인 패러다임으로 소개한다.
    2. 우리의 IRL 모델은 요약을 위한 여러 중요한 부 서브 리워드 (sub-reward)를 이용하여 보상 함수를 추정하고, 동시에 정책 네트워크를 최적화한다.
    3. CNN/DailyMail와 WikiHow와 같은 다양한 도메인의 데이터셋과 BART-base 및 BART-large와 같은 다양한 모델 크기에서의 실험 결과는 MLE 및 RL 베이스라인 대비 우리의 제안된 IRL 모델의 우위성을 보여준다.

###### MM-Reasoner: A Multi-Modal Knowledge-Aware Framework for Knowledge-Based Visual Question Answering (https://aclanthology.org/2023.findings-emnlp.437/)
- Anthology ID: 2023.findings-emnlp.437 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델의 강력한 추론 능력을 활용한 최근 지식 기반 시각 질의 응답 (KVQA) 접근 방식은 입력 이미지의 전역 캡션을 사용하여 질문에 답을 제공한다. 그러나 이러한 방식은 캡션에 포착되지 않은 중요한 시각적 정보를 놓칠 수 있다. 또한 질문에 답하기 위해 필요한 시각적 정보를 완전히 활용할 수 없다.
    2. 우리는 이러한 문제를 해결하기 위해 KVQA를 위한 새로운 프레임워크인 MM-Reasoner를 소개한다. MM-Reasoner는 먼저 밀집 캡셔너, 객체 탐지기, OCR과 같은 비전 API 세트를 사용하여 텍스트 형식으로 이미지에서 상세한 정보를 추출한다. 그런 다음, 추출된 텍스트 정보에서 LLM에게 질문에 특정된 지식을 추출하도록 요청하여 추론에 필요한 외부 지식, 상식, 명시적인 지지 사실 및 근거가 포함된 풍부한 표현을 제공한다.
    3. 마지막으로, 지식, 질문 및 시각적 입력을 사용하여 비전-언어 모델 (VLM)을 세밀하게 조정하는 데 사용된다. 테스트 시에 MM-Reasoner는 VLM이 예측한 잠재적인 답변을 사용하여 프롬프트를 반복적으로 갱신 및 최적화하여 답변을 미세조정한다. 실험적 연구는 MM-Reasoner가 여러 KVQA 데이터셋에서 최고 성능을 달성함을 보여준다.

###### Toward Joint Language Modeling for Speech Units and Text (https://aclanthology.org/2023.findings-emnlp.438/)
- Anthology ID: 2023.findings-emnlp.438 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 음성과 텍스트는 인간 언어의 두 가지 주요 형태이다. 하지만 언어 모델링 분야에서는 이들을 공동으로 모델링하는 데 거의 노력이 기울여지지 않았다.
    2. 본 논문에서는 연속된 음성 신호를 이산 단위로 변환하기 위해 다양한 음성 토크나이저를 비교하며 혼합된 음성-텍스트 데이터를 구성하는 다양한 방법을 사용한다. 그리고 음성과 텍스트를 얼마나 잘 혼합하는지를 평가하기 위해 자동화된 메트릭을 소개한다.
    3. 또한, 공동 언어 모델을 다양한 형태(음성 또는 텍스트)의 하위 의미 이해(SLU) 작업에 Fine-tuning하고, 공유 표현 학습을 평가하기 위해 성능을 테스트한다. 결과적으로 제안된 혼합 기술로 음성 단위와 텍스트를 섞는 것은 SLU 작업에서 음성만을 고려한 기준 모델에 비해 향상되며, 제로샷 크로스모달 전이성을 보인다.

###### From Chaos to Clarity: Claim Normalization to Empower Fact-Checking (https://aclanthology.org/2023.findings-emnlp.439/)
- Anthology ID: 2023.findings-emnlp.439 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 소셜 미디어 플랫폼의 확산과 함께 소셜 미디어 포스트를 통해 사실과 다른 주장이 포함 된 게시물에 노출되게 된다. 하지만 이러한 포스트의 잡음은 검증이 필요한 정확하고 중요한 주장을 식별하는 것에 어려움을 제공한다. 이 논문에서는 ClaimNorm이라고 불리는 새로운 작업을 소개하며, 복잡하고 잡음이 많은 소셜 미디어 포스트를 더 직관적이고 이해하기 쉬운 정규화된 주장으로 분해하고자 한다. 
    2. 우리는 CACN이라는 전처리 방법을 제안하며, chain-of-thought와 claim check-worthiness estimation을 활용하여 인간의 추론과정을 모방하여 복잡한 주장을 이해한다. 
    3. 우리는 CLAN이라는 6,000개 이상의 실제 소셜 미디어 포스트와 해당 정규화된 주장으로 구성된 포괄적인 데이터셋을 만들어 실험을 진행하였고, 이를 통해 CACN이 다양한 평가 척도에서 여러 베이스라인 알고리즘을 능가함을 보였다.

###### Mitigating Biases in Hate Speech Detection from A Causal Perspective (https://aclanthology.org/2023.findings-emnlp.440/)
- Anthology ID: 2023.findings-emnlp.440 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 현재 많은 혐오 발언 탐지기들이 자동으로 혐오 문구를 감지하는 데 사용되고 있지만, 그들의 훈련 데이터셋은 때때로 특정 고정 관념 (예: 인종 또는 종교와 관련된)으로 치우쳐있어서 예측을 위한 편법에 의존하기 쉽다.
    2. 이 논문에서는 grammar induction을 사용하여 혐오 발언의 문법 패턴을 찾아 원인 관점에서 이 현상을 분석한다. spuriousness와 모델 예측에 미치는 영향을 기반으로 다양한 편견을 분류하고 검증한다.
    3. 그런 다음, 이러한 confounder를 기반으로 Multi-Task Intervention 및 Data-Specific Intervention과 같은 두 가지 완화 접근 방식을 제안한다. 9개의 혐오 문구 데이터셋에서 수행한 실험은 우리의 접근법의 효과를 입증한다.

###### Unmasking the Hidden Meaning: Bridging Implicit and Explicit Hate Speech Embedding Representations (https://aclanthology.org/2023.findings-emnlp.441/)
- Anthology ID: 2023.findings-emnlp.441 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자동 혐오 발언(HS) 감지에 대한 연구는 주로 사용자 생성 콘텐츠에서 명백한 혐오 표현을 식별하는 데 초점을 맞추었다. 하지만 최근에는 보다 묵시적이고 미묘한 학대적 콘텐츠를 다룰 수 있는 방법에 대한 연구도 진행되고 있다.
    2. 그러나 이러한 노력에도 불구하고, 자동화된 시스템은 여전히 묵시적이고 더 은폐된 혐오 발언을 정확하게 인식하는 데 어려움을 겪고 있다.
    3. 이 연구에서는 트랜스포머 모델에 기반한 다양한 모델들을 비교 분석하며, 묵시적인 HS 메시지를 포함한 다섯 가지 데이터셋에서의 성능을 평가하였다.

###### PerturbScore: Connecting Discrete and Continuous Perturbations in NLP (https://aclanthology.org/2023.findings-emnlp.442/)
- Anthology ID: 2023.findings-emnlp.442 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 NLP에서의 신경망 응용의 빠른 발전으로 인해 모델의 robustness 문제에 대한 관심이 증가하고 있다. 
    2. 컴퓨터 비전과 달리 텍스트의 이산적인 특성은 NLP에서의 robustness를 탐구하는 것이 더 도전적이다. 
    3. 본 연구에서는 이산성(specificity)와 연속성(continuity) 사이의 상관관계를 연결하고 측정하는 방법을 제안하여 NLP 모델에서 이산적인 변동을 이해하는 데 도움을 주려고한다.

###### InstructoR: Instructing Unsupervised Conversational Dense Retrieval with Large Language Models (https://aclanthology.org/2023.findings-emnlp.443/)
- Anthology ID: 2023.findings-emnlp.443 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존 방법들은 제한된 지도학습 데이터로 사전 훈련된 ad-hoc 재검색기를 단순히 세밀 조정하는 것에 그치기 때문에, 다중 턴 대화를 처리하고 사용자의 실제 질의 의도를 이해하는 것이 어렵다. 
    2. 이 논문에서는 대화형 재검색 과제에 대해, 큰 언어 모델 (LLM)이 복잡한 대화 맥락에서 사용자의 질의 의도를 정확하게 파악하고, 지도 신호를 통해 무지도 방식으로 재검색기를 가르칠 수 있다는 것을 발견했다.
    3. 우리는 InstructoR라는 독창적인 방법을 제안하여, LLM을 사용하여 세션-패시지 일치도 점수를 추정하고, 이를 소프트 라벨로 사용하여 재검색기의 훈련을 안내하는 무지도 훈련 프레임워크를 설계했다. 우리의 방법은 낮은 자원 및 제로샷 설정에서도 효과적임을 실험적으로 검증하였다.

###### The Iron(ic) Melting Pot: Reviewing Human Evaluation in Humour, Irony and Sarcasm Generation (https://aclanthology.org/2023.findings-emnlp.444/)
- Anthology ID: 2023.findings-emnlp.444 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "자연어 생성 시스템을 평가하기 위해 인간 평가가 가장 효과적인 방법이라고 알려져 있지만, 그 실행의 질은 자주 의심 받는다."
    2. "특히 유머, 반어적 표현 등과 같은 특이한 언어 형태의 생성은 선택된 평가자들의 특성이 매우 중요한 하위 도메인으로, 투명성과 재현성을 위해 가능한 한 평가자들의 인구 특성을 보고하는 노력이 필요하다고 주장한다."
    3. "이 논문에서는 각 언어 형태의 개요와 다른 참가자 변수에 의해 어떻게 해석이 영향을 받는지에 대한 예시를 분석하여 이러한 주장을 뒷받침하였고, NLG에서 평가 절차가 어떻게 보고되는지에 대한 비판적인 조사를 수행하여 평가자 인구 특성의 공개적인 보고 부족과 크라우드소싱 플랫폼에 대한 의존성이 심각하다는 점을 확인하였다."

###### INGENIOUS: Using Informative Data Subsets for Efficient Pre-Training of Language Models (https://aclanthology.org/2023.findings-emnlp.445/)
- Anthology ID: 2023.findings-emnlp.445 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사전 학습 언어 모델(PTLM)은 모델 용량과 학습 데이터셋 크기가 증가함에 따라 일반화 및 새로운 기능에서 높은 성능을 보이는데, 이로 인해 대단한 모델의 개발이 진행되고 있다. 
    2. 그러나 훈련 시간이 길어지고 컴퓨팅 비용이 많이 들며, 환경에도 해로울 수 있으므로, 훈련 데이터의 유효성을 최적화하는 것이 중요하다.
    3. 우리는 정보를 많이 담은 하위 집합을 선택하는 서브모듈러 최적화를 활용하여 효율적으로 PTLM(BERT, BioBERT, GPT-2)을 훈련시킬 수 있으며, 완전히 훈련된 모델의 성능의 약 99%를 달성할 수 있다는 것을 검증하였다.

###### Towards General Error Diagnosis via Behavioral Testing in Machine Translation (https://aclanthology.org/2023.findings-emnlp.446/)
- Anthology ID: 2023.findings-emnlp.446 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기계 번역(MT) 시스템에 대한 행동 테스트는 언어 오류를 진단하고 NLP 모델의 능력을 평가하는 중요한 수단이다. 하지만 MT 시스템의 행동 테스트는 일반적으로 새로운 테스트 케이스에 대한 번역 품질을 평가하기 위해 사람의 노력이 필요하다. 이 논문은 MT 시스템의 행동 테스트를 수행하기 위해 새로운 BTPGBT (Bilingual Translation Pair Generation based Behavior Testing) 프레임워크를 제안한다. 
    2. BTPGBT의 핵심 아이디어는 고품질의 테스트 케이스와 유사 기준을 자동화하는 새로운 이중 번역 쌍 생성(BTPG) 접근 방식을 사용하는 것이다.
    3. 다양한 MT 시스템에 대한 실험 결과는 BTPGBT가 일반적인 오류 진단을 위한 포괄적이고 정확한 행동 테스트 결과를 제공할 수 있으며, 이로부터 몇 가지 유익한 결과를 얻을 수 있다는 것을 보여준다.

###### Retrieval-Augmented Few-shot Text Classification (https://aclanthology.org/2023.findings-emnlp.447/)
- Anthology ID: 2023.findings-emnlp.447 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 retrieval-augmented 방법은 retrieval 공간이 충분한 표준 시나리오에서 잘 작동하지만, 제한된 retrieval 공간을 가진 피실험자 시나리오에서는 실제로 실현하기 어렵다는 것을 이 논문은 보여준다. 
    2. 기본적인 metric을 사용하여 의미론적으로 유사한 예시를 검색하는 것은 불가능하며, task-specific retrieval metric을 학습하는 것이 중요하다. 
    3. 앵커에 기반한 loss를 최소화하여 학습하는 것은 약한 감독 신호와 경사 소실 문제 때문에 어렵다는 것을 심층적인 분석을 통해 보여주었고, 이를 해결하기 위해 EM 알고리즘과 랭크 기반 loss를 활용하는 두 가지 훈련 목표를 도입하였다.

###### Temporal Extrapolation and Knowledge Transfer for Lifelong Temporal Knowledge Graph Reasoning (https://aclanthology.org/2023.findings-emnlp.448/)
- Anthology ID: 2023.findings-emnlp.448 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 실제 시간적인 지식 그래프(TKG)는 시간이 흐름에 따라 계속해서 새로운 개체와 사실이 나타나므로 미래 타임스탬프에 대해 예측하고 새로운 구성 요소에 대한 지식을 전송할 수 있는 모델이 필요하다.
    2. 우리는 '평생 TKG 추론'이라는 실제 문제를 수행하기 위해 시간 경로 기반 강화 학습(RL) 프레임워크를 제안한다.
    3. 실험 결과는 우리의 모델이 모든 기준 모델들보다 더 나은 성능을 보여준다.

###### Comparing Prompt-Based and Standard Fine-Tuning for Urdu Text Classification (https://aclanthology.org/2023.findings-emnlp.449/)
- Anthology ID: 2023.findings-emnlp.449 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 자연어 처리의 발전은 prompt 기반의 미세 조정(fine-tuning)의 효과를 보여준다. prompt 기반 미세 조정은 특정 언어와 태스크에 맞춘 prompt로 몇 개의 라벨링된 예제(few shot)와 함께 가이드를 제공한다.
    2. 저자들은 prompt 기반과 표준 미세 조정을 우르두어와 로마 우르두어 텍스트 분류 작업에서 비교하였다. 다섯 가지 데이터셋과 다국어 변환기를 사용하여 실험을 수행한 결과, prompt 기반 미세 조정은 표준 방식보다 최대 13%의 정확도 향상이 있었다.
    3. 이는 prompt 기반 미세 조정이 제한된 라벨 데이터를 가진 저자의 저-자원 언어에 대한 유망한 대안이 될 수 있다는 가능성을 시사한다.

###### Explore the Way: Exploring Reasoning Path by Bridging Entities for Effective Cross-Document Relation Extraction (https://aclanthology.org/2023.findings-emnlp.450/)
- Anthology ID: 2023.findings-emnlp.450 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Cross-document relation extraction (CodRED)은 different documents에서 언급된 두 entity 간의 관계를 추론하는 작업으로, 기존 연구들은 주로 implicit한 관계만을 포착했다. 그러나 사람들은 일반적으로 하이퍼링크나 추가적인 검색을 통해 explicit한 정보 체인을 활용하여 두 entity 간의 관계를 찾는다. 이에 영감을 받아 우리는 PILOT를 제안하여 문서 내부의 explicit한 단서 정보를 탐색하여 개선된 추론 경로를 제공한다."
    2. "PILOT는 entity 간 경로를 직접적으로 안내하는 bridging entity를 찾고 이를 원하는 경로를 탐색하는 데 사용한다. 우리는 PILOT로 구성된 모델이 CodRED 작업에서 기준 모델들을 능가한다는 것을 보여준다."
    3. "또한 PILOT을 통해 구축된 추론 경로의 타당성을 검증하기 위해 ChatGPT와 같은 대형 언어 모델을 사용한 평가 등 다양한 분석을 제공한다."

###### The student becomes the master: Outperforming GPT3 on Scientific Factual Error Correction (https://aclanthology.org/2023.findings-emnlp.451/)
- Anthology ID: 2023.findings-emnlp.451 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 오류 수정 데이터셋을 생성하는 비용이 매우 높기 때문에 대부분의 사실적 주장 수정 방법은 강력한 검증 모델이 수정 프로세스를 안내하게 되어 있다. 이는 좋은 검증 모델이 항상 존재하지 않는 Scientific Claim Correction과 같은 도메인에서는 성능이 크게 하락하게 된다.
    2. 본 논문에서는 SciFix라는 검증기가 필요하지 않지만 기존 방법들보다 높은 성능을 내는 주장 수정 시스템을 소개한다. Fully supervised training과 regularization에 사용될 수 있는 풍부한 주석이 달린 데이터셋을 생성하기 위해 훈련 중 LLMs와 함께 prompting의 힘을 활용한다.
    3. 또한 주장 인식 디코딩 절차를 사용하여 수정된 주장의 품질을 개선한다. 우리의 방법은 주석이 달린 데이터셋을 생성하는 데 사용된 LLM인 GPT3.5 FewShot Prompting보다 성능이 우수하다. 이 모델은 우리의 모델보다 거의 800배 많은 파라미터를 사용했음에도 불구하고 향상된 수정 정확도(58%, 61% 및 64%)를 보여준다.

###### Leveraging Structured Information for Explainable Multi-hop Question Answering and Reasoning (https://aclanthology.org/2023.findings-emnlp.452/)
- Anthology ID: 2023.findings-emnlp.452 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델 (LLM)을 포함한 신경망 모델은 다중 홉 문제 해결에서 우수한 성능을 보이지만, 불명확한 추론, 환영증, 해석 가능성의 부족 등의 여러 가지 문제가 여전히 남아있다. 
    2. 그 대안으로 정보 추출 (IE)는 문자에 근거한 entity, relation, event 등을 식별한다. 추출된 구조적 정보는 사람과 기계에 의해 쉽게 해석될 수 있으며, 이를 활용하여 다중 홉 질문 답변에서 구성 및 활용할 수 있다. 
    3. 실험 결과와 인간 평가를 통해 논문의 프레임워크가 더 정확한 추론 체인을 생성하고 두 개의 벤치마크 데이터셋에서 QA 성능을 크게 향상시킨다는 것을 보였으며, 추출된 구조 자체만으로도 생성된 추론 체인 및 중요도 기반 설명보다 인간에게 더 선호되는 근거화된 설명을 제공한다.

###### Hierarchical Catalogue Generation for Literature Review: A Benchmark (https://aclanthology.org/2023.findings-emnlp.453/)
- Anthology ID: 2023.findings-emnlp.453 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 과학적인 논문 리뷰 생성은 다량의 참고 논문에서 중요한 정보를 추출하고 정리하여 해당 리뷰를 생성하는 것을 목표로 한다. 하지만 명확하고 논리적인 계층이 부족한 상태에서 이를 수행하기 어렵다. 우리는 고품질의 카탈로그를 활용한 리뷰 생성 과정이 이 문제를 효과적으로 완화시킬 수 있다고 관찰했다. 
    2. 따라서, 우리는 리뷰 생성을 위한 첫 단계로 "Hierarchical Catalogue Generation for Literature Review"라는 어려운 작업을 소개한다. 이 작업은 다양한 참고 자료를 가지고 리뷰 논문의 계층적 카탈로그를 생성하는 것을 목표로 한다. 
    3. 우리는 7.6k개의 리뷰 카탈로그와 389k개의 참고 논문을 포함한 새로운 영어 리뷰 카탈로그 데이터셋을 구축했다. 또한, 이 작업을 정확히 평가하기 위해 의미론과 구조에서의 정보성과 ground truth와의 유사성을 평가하기 위한 두 가지 평가 메트릭을 설계했다. 우리의 광범위한 분석은 데이터셋의 고품질과 평가 메트릭의 효과적인 성능을 입증하고 있다.

###### MCC-KD: Multi-CoT Consistent Knowledge Distillation (https://aclanthology.org/2023.findings-emnlp.454/)
- Anthology ID: 2023.findings-emnlp.454 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 큰 언어 모델들은 chain-of-thought(prompting)을 통해 복잡한 추론 능력을 보여주고 있다. 이 논문에서는 이러한 추론 능력을 작은 모델로 전달하는 데에 초점을 맞춰 다양성과 일관성을 강화하는 Multi-CoT Consistent Knowledge Distillation (MCC-KD)를 제안한다.
    2. MCC-KD에서는 각 질문에 대해 여러 개의 추론을 생성하고, 답변 분포 간의 양방향 KL-divergence를 최소화함으로써 추론의 일관성을 강제한다.
    3. 실험 결과, MCC-KD는 다양한 모델 아키텍처(LLaMA/FlanT5)와 다양한 모델 크기(3B/7B/11B/13B)에서 수학적 추론과 상식적 추론 벤치마크에서 뛰어난 성능을 보이며, 일반화 능력도 강하다.

###### An Empirical Study of Frame Selection for Text-to-Video Retrieval (https://aclanthology.org/2023.findings-emnlp.455/)
- Anthology ID: 2023.findings-emnlp.455 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Text-to-video retrieval (TVR)는 쿼리 텍스트가 주어졌을 때 큰 비디오 갤러리에서 가장 관련 있는 비디오를 찾는 것을 목표로 한다. 
    2. 기존 방법들은 일련의 비디오 콘텍스트를 처리하기 위해 비디오 내 프레임의 부분집합을 선택하는데, 이 선택 방법은 비디오의 의미 정보를 보존하면서 시간적으로 중복되는 프레임을 제거하여 검색 효율성을 향상시키는 데 중요하다.
    3. 이 논문에서는 TVR을 위한 프레임 선택의 첫 번째 경험적 연구를 수행하였으며, 프레임 선택 방법을 효과와 효율성 측면에서 체계적으로 분석하였다. 제안된 프레임 선택 기법은 검색 효율성을 향상시키면서 검색 성능을 희생하지 않을 수 있다는 것을 실험적으로 확인하였다.

###### Conditional Natural Language Inference (https://aclanthology.org/2023.findings-emnlp.456/)
- Anthology ID: 2023.findings-emnlp.456 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 서로 다른 조건에 대해 상반되는 정보를 제공하는 문장 쌍을 올바르게 설명하기 위해, 조건부 자연어 추론 (Cond-NLI) 작업을 소개하고 문장 쌍에서 상반되는 측면과 해당 조건을 자동으로 추출하는 것에 초점을 맞추고 있다.
    2. Cond-NLI는 특정 조건을 다루는 각자 다른 답변을 가진 다중 답변 질문이나 다른 조건에 대한 서로 다른 의견을 가진 리뷰와 같은 다양한 정보를 제공하는 데 도움이 될 수 있다.
    3. 우리는 일반적으로 사용되는 특징-기여 설명 모델이 특히 문장이 길고 독립적으로 작성될 때 조건을 찾는 데 적합하지 않음을 보여준다. 우리는 토큰 수준 주석을 필요로하지 않으면서 조건을 성공적으로 추출할 수있는 간단하고 효과적인 모델을 제안한다.

###### Contrastive Distant Supervision for Debiased and Denoised Machine Reading Comprehension (https://aclanthology.org/2023.findings-emnlp.457/)
- Anthology ID: 2023.findings-emnlp.457 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "원격 감독 (Distant Supervision)은 쉽게 얻을 수 있는 질문-답변 쌍을 활용한 MRC(Machine Reading Comprehension)에 대한 유망한 학습 방법이다. 그러나 휴리스틱하게 주석을 단 데이터셋은 불가피하게 잘못된 라벨링을 초래하여 답변 편향과 맥락 잡음 문제를 야기한다."
    2. "이 논문에서는 CDS (Contrastive Distant Supervision)라는 알고리즘을 제안하는데, 신뢰도를 고려한 대조 학습을 통해 혼돈과 잡음이 섞인 인스턴스를 구분하는 방법을 학습한다."
    3. "실험 결과는 CDS가 효과적이며, 수동 주석 없이도 지도 학습된 MRC 모델을 능가할 수 있다는 것을 보여준다."

###### KEPLET: Knowledge-Enhanced Pretrained Language Model with Topic Entity Awareness (https://aclanthology.org/2023.findings-emnlp.458/)
- Anthology ID: 2023.findings-emnlp.458 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근엔 PLM(Pre-trained Language Models)들이 효율성을 보이는데, KE(지식 증강) PLM들은 Wikipedia 같은 entity-rich한 텍스트 자료에서 토큰 간 및 언급된 entity들과 상호작용을 고려하여 pre-training한다. 
    2. 하지만 기존의 KEPLM들은 Wikipedia의 특별한 레이아웃을 간과하여 entity 상호작용이 충분치 않고 biased한 (relation) word semantics을 가지게 된다. 
    3. 따라서 이 논문에서는 topic entity를 고려한 KEPLET를 제안하며, Wikipedia 문장에서 topic entity 정보를 어디에 추가해야 하는지 식별하고, 해당 정보를 token과 entity의 표현에 통합시켜줌으로써 전체 네트워크 학습에 topic entity를 고려시키는 방법을 제시한다.

###### Revisiting Large Language Models as Zero-shot Relation Extractors (https://aclanthology.org/2023.findings-emnlp.459/)
- Anthology ID: 2023.findings-emnlp.459 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 관계 추출 (RE)은 레이블이나 레이블이 없는 데이터를 일정한 정도로 필요로 하는데, 최근의 연구에서는 대규모 언어 모델 (LLM)이 자연어 프롬프트를 통해 즉시 새로운 작업으로 전이될 수 있음을 보여주었다. 이 논문에서는 ChatGPT와 같은 LLM을 zero-shot 관계 추출기로 탐구한다.
    2. 논문에서는 기존의 관계 추출 프롬프트의 단점을 분석하고, chain-of-thought (CoT)와 같은 최근 프롬프트 기술을 채용하여 zero-shot 관계 추출을 개선하려고 시도한다. 이를 위해 QA 형식의 효과적인 질문으로 RE 입력을 재귀적으로 변환하는 SumAsk 프롬프트를 제안한다.
    3. 다양한 벤치마크와 설정에서 종합적인 실험을 수행한 결과, SumAsk는 다양한 모델 크기, 벤치마크 및 설정에서 LLM의 성능을 일관되고 유의미하게 향상시키며, ChatGPT의 zero-shot 프롬프트는 zero-shot과 완전 지도 방법과 경쟁력 있는 또는 우수한 결과를 달성한다. 또한, LLM은 중첩 관계를 추출하는 데 유망한 성능을 보이며, 서로 다른 관계에 따라 성능이 크게 다르다.

###### Multi-Stage Pre-training Enhanced by ChatGPT for Multi-Scenario Multi-Domain Dialogue Summarization (https://aclanthology.org/2023.findings-emnlp.460/)
- Anthology ID: 2023.findings-emnlp.460 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 대화 요약 방법들은 특정 시나리오나 도메인에만 적용되는 한계가 있다.
    2. 이 연구에서는 다중 시나리오 다중 도메인 대화 요약을 위한 새로운 사전 훈련 모델을 제안한다.
    3. 실험 결과, 우리의 사전 훈련 모델은 전체 fine-tuning, zero-shot, few-shot 설정에서 이전의 최첨단 모델들보다 크게 우수한 성능을 보였다.

###### Towards large language model-based personal agents in the enterprise: Current trends and open problems (https://aclanthology.org/2023.findings-emnlp.461/)
- Anthology ID: 2023.findings-emnlp.461 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 대형 언어 모델(LLMs)을 사용하여 복잡한 목표에 대해 추론하고 목표를 달성하기 위해 일련의 도구나 API를 조율하는 경향이 있다. 그러나 이러한 기능은 미션 크리티컬한 기업 환경에서 사용하기에는 아직 준비되지 않았다.
    2. 이 논문은 LLM 기반의 자율 에이전트 및 도구 합성에 대한 예시를 제시하고 실패하는 경우를 강조하며, 최근 노력들을 조사하고 이러한 솔루션을 기업에 적합하게 만들기 위한 연구 과제를 제시한다.
    3. NLP 연구에서는 신뢰성과 설명 가능성, 일관성과 재현성, 가드레일 및 정책 준수, 합성 도구 설계를 위한 모범 사례, 새로운 메트릭 및 벤치마크 등 여러 개의 개방된 문제들이 있다.

###### CREATOR: Tool Creation for Disentangling Abstract and Concrete Reasoning of Large Language Models (https://aclanthology.org/2023.findings-emnlp.462/)
- Anthology ID: 2023.findings-emnlp.462 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델(Large Language Models, LLMs)은 API의 한계와 암묵적 추론의 불안정성으로 인해 한계가 있다고 알려져 있다. 이 논문에서는 CREATOR라는 새로운 프레임워크를 제안하여 LLMs가 문서와 코드 실현을 통해 자체 도구를 만들 수 있게 한다.
    2. CREATOR를 MATH와 TabMWP 벤치마크에서 평가한 결과, 기존의 사고 과정, 프로그램 과정 등과 비교해 성능이 우수하다는 것을 보였다. 또한, 창조적 도전(Dataset, Creation Challenge)을 소개하여 LLMs의 도구 창조 능력의 필요성과 이점을 강조한다.
    3. 추가적인 연구에서는 LLMs를 도구 생성자로 활용함으로써 지식 전달을 용이하게 하고, LLMs는 다양한 상황에 적응할 수 있는 도구 창조의 능력을 가지고 있음이 확인되며, 문제 해결 시 paradigm을 혁신시킨다는 것을 보여준다.

###### Query-based Image Captioning from Multi-context 360cdegree Images (https://aclanthology.org/2023.findings-emnlp.463/)
- Anthology ID: 2023.findings-emnlp.463 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 360도 이미지는 한 장의 캡션으로 모든 문맥을 설명하기 어렵기 때문에, 이를 해결하기 위해 Query-based Image Captioning (QuIC)이라는 새로운 작업을 제안한다. 이 작업은 360도 이미지에 대한 미세한 장면 이해를 요구하여 사용자 의도에 맞는 내용을 선택하는 데 어려움이 있다.
    2. 우리는 이 작업을 위한 데이터셋을 구축하였고, 실험 결과 이 데이터셋을 기반으로 이미지 캡션 모델을 fine-tuning하면 360도 이미지의 다양하고 제어 가능한 캡션을 생성할 수 있다.
    3. 기존의 이미지 캡션 작업과 비교하여 이 작업은 더 도전적이며, 사용자의 의도에 맞는 다양한 문맥에서의 캡션을 생성하는 능력이 필요하다.

###### Auto Search Indexer for End-to-End Document Retrieval (https://aclanthology.org/2023.findings-emnlp.464/)
- Anthology ID: 2023.findings-emnlp.464 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 연구에서는 모든 문서를 모델에 인코딩하고 직접 검색된 문서를 생성하는 generative retrieval이라는 새로운 고급 패러다임에 대한 관심이 증가하고 있으나, 이 방법은 아직 "전처리된" 문서 식별자 (docids)에 많이 의존하므로, 검색 성능과 새로운 문서 검색 능력에 제한이 있다.
    2. 본 논문에서는 새로운 완전한 end-to-end 검색 패러다임을 제안한다. 이는 의미적 색인 모듈을 통해 기존 및 새로운 문서의 최적의 docids를 자동으로 학습하고, encoder-decoder 기반 generative model인 Auto Search Indexer (ASI)를 통해 end-to-end 문서 검색을 수행할 수 있다.
    3. 또한, 위의 두 모듈을 결합하기 위해 리파라미터화 메커니즘을 설계하여 공동 최적화 프레임워크로 만든다. 실험 결과는 우리의 모델이 공개 및 산업용 데이터셋에서 선진적인 기준 모델에 비해 우수함을 보여주며, 새로운 문서 처리 능력을 검증한다.

###### ‘Person’ == Light-skinned, Western Man, and Sexualization of Women of Color: Stereotypes in Stable Diffusion (https://aclanthology.org/2023.findings-emnlp.465/)
- Anthology ID: 2023.findings-emnlp.465 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 우리는 Stable Diffusion이 성별 및 국적/대륙 식별에 관련된 편견을 어떻게 내포하고 있는지 조사하였다. 그 결과 Stable Diffusion은 별도의 정보 없이 '사람' 또는 '아시아 출신 사람'에 대해 어떤 성별과 국적/대륙 식별을 부여하는지 알 수 있다. Stable Diffusion은 '사람'에 대한 결과로 가장 가깝게 남성의 이미지(평균 유사도 0.64)와 가장 거리가 먼 비이진 성별의 사람의 이미지(평균 유사도 0.41)와, 유럽/북미 (각각 평균 유사도 0.71과 0.68)에 대한 이미지와, 아프리카/아시아 (각각 평균 유사도 0.43과 0.41)에 대한 이미지와 가장 일치하는 것으로 나타났다. 이 결과는 Stable Diffusion이 사람을 유럽/북미 남성으로 표현하는 경향을 나타낸다.
    2. 또한, 대륙적 편견과 그로 인한 피해를 보여준다. 예를 들어, 오세아니아 출신 사람은 팬더(예)로 간주되며 평균 유사도는 파푸아뉴기니인의 경우 0.31에 비해 오스트레일리안/뉴질랜드인의 경우 0.77과 0.74로 높게 나타났다. 이는 오세아니아 원주민들의 지워짐을 나타내며, 실제로 파푸아뉴기니와 오세아니아 전체에서 식민지 정착민의 후손보다 원주민들이 더 많다는 사실을 고려하지 않고 있다.
    3. 마지막으로, 라틴 아메리카, 멕시코, 인도, 이집트 여성들의 성적 대상화 패턴을 뜻하는 의외로 여성들의 성적 대상화 문제를 확인하였다. 이는 NSFW 검출기를 통해 확인되었으며 수동 검토로 확인되었다. 이는 Stable Diffusion이 매체에서 유색 여성을 사물화하여 서양의 페티쉬화를 지속시키고 있다는 것을 보여준다. 이러한 편견적인 표현은 점검되지 않으면 심화될 것이다.

###### Task-Attentive Transformer Architecture for Continual Learning of Vision-and-Language Tasks Using Knowledge Distillation (https://aclanthology.org/2023.findings-emnlp.466/)
- Anthology ID: 2023.findings-emnlp.466 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 사전 훈련된 신경망의 크기와 계산 부하는 많은 응용에서 기계학습 도입의 두 가지 주요 장애물이 되고 있다. 이 논문에서는 sequential task들 간 지식 전달을 가능하게 하는 Continual Learning(CL)을 통해 이 문제를 해결하는데, 기존 CL 알고리즘들은 주로 단일 시각 또는 언어 태스크를 고려한다.
    2. 우리는 동적으로 학습 가능한 매개변수의 수를 증가시키고 지식 증류(knowledge distillation)를 사용하여 비모달 시각-언어 태스크를 학습하기 위한 transformer 기반 CL 아키텍처를 개발한다. 추가 매개변수는 각 태스크에 대해 네트워크를 특화시키는 데 사용된다.
    3. 우리의 접근 방식은 치명적인 Forgetting(catastrophic forgetting)의 도전을 해결하면서 태스크간의 정보 공유를 가능하게 한다. 우리의 모델은 적은 메모리와 시간 오버헤드를 필요로 하기 때문에 다수의 태스크에 대한 확장성 있는 학습을 가능하게 한다. 또한, 우리의 모델은 어려운 시각-언어 태스크에서 최고 성능에 도달한다.

###### Evaluating Verifiability in Generative Search Engines (https://aclanthology.org/2023.findings-emnlp.467/)
- Anthology ID: 2023.findings-emnlp.467 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 신뢰할 수 있는 생성 검색 엔진은 높은 사실 인용률과 정확도를 가지는 것이 필수적이다. 지금까지의 생성 검색 엔진들은 정보성과 유창성은 있으나, 지지되지 않은 문장과 부정확한 인용을 자주 포함한다. 이러한 결과는 정보를 찾는 사용자에게 불신과 불신을 주는 결괏값이며, 이에 대응하기 위해 신뢰할 수 있는 생성 검색 엔진의 개발을 촉진하고 기존 상업적 시스템의 부족점을 명확히하기 위해 기여하길 바란다.
    
    2. 인용률과 정확도가 높은 생성 검색 엔진은 사용자가 정보를 확인하는 데 중요한 역할을 하는데, 기존의 생성 검색 엔진들은 지원되지 않은 문장과 부정확한 인용을 자주 함께 포함한다. 
    3. 따라서 이 논문에서는 네 가지 인기 있는 생성 검색 엔진에 대한 사람에 의한 심사를 실시하여, 그들의 결괏값이 정보를 찾는 사용자에게 신뢰성을 제공하는 역할을 적절히 수행할 수 있는지 확인하였다.

###### Enhancing Abstractiveness of Summarization Models through Calibrated Distillation (https://aclanthology.org/2023.findings-emnlp.468/)
- Anthology ID: 2023.findings-emnlp.468 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. DisCal은 생성된 요약문의 정보성을 희생하지 않고 요약문의 추상적 수준을 높이기 위한 혁신적인 접근 방식이다. 
    2. DisCal은 두 가지 감독을 통해 다양한 가짜 요약문을 만들고, 가장 추상적이고 정보성이 높은 가짜 요약문을 찾아 sequence-level distillation에 사용한다. 
    3. 실험결과, DisCal은 요약문의 추상성과 정보성에서 이전 방법들보다 우수한 성능을 보여준다.

###### Visually Grounded Continual Language Learning with Selective Specialization (https://aclanthology.org/2023.findings-emnlp.469/)
- Anthology ID: 2023.findings-emnlp.469 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 시각적인 세계에서 작동하는 인공 에이전트의 바람직한 특성은 각각의 작업에 충분히 전문화하면서 전이 가능한 일반화된 지식을 구축하며 언어로 정보화된 작업의 연속적인 학습을 지속적으로 할 수 있는 것이다.
    2. 선택적 전문화는 각 작업에 대해 모델 구성 요소를 신중하게 선택하여 이러한 트레이드오프에 대한 통제를 제공하는 전략이다.
    3. 이 논문은 시각적으로 기반을 둔 지속적인 언어 학습을 위한 선택 전략의 철저한 모델 분석을 제공하고, 이를 통해 공통된 지속적인 학습 기준선을 능가하는 개념적으로 간단한 접근 방식을 개발하여 실험했다. 이들의 결과는 개별 모델 부분의 학습 특성에 더 잘 부합하는 지속적인 학습 알고리즘을 위해 더 많은 노력이 필요함을 보여준다.

###### RoMQA: A Benchmark for Robust, Multi-evidence, Multi-answer Question Answering (https://aclanthology.org/2023.findings-emnlp.470/)
- Anthology ID: 2023.findings-emnlp.470 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. RoMQA는 위키데이터 지식 그래프에서 추출한 관련 제약 조건을 기반으로 생성된 강건하고 다중 증거를 포함한 질문 응답(QA)에 대한 첫 번째 벤치마크입니다.
    2. RoMQA는 이전 QA 데이터셋과 비교하여 더 많은 증거 텍스트에 대한 추론과 평균적으로 많은 정답을 요구하는 사람이 만든 질문을 포함하고 있습니다.
    3. RoMQA를 사용하여 수행된 실험 결과, 현재 모델은 질문 제약 조건의 변화에 견고하지 않지만 관련 질문의 클러스터를 튜닝함으로써 더 견고하게 만들 수 있다는 것을 보여줍니다.

###### Leveraging Multiple Teachers for Test-Time Adaptation of Language-Guided Classifiers (https://aclanthology.org/2023.findings-emnlp.471/)
- Anthology ID: 2023.findings-emnlp.471 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 연구들은 langauge-guided classifier에 의해 task-specific한 자연어 설명이 주어질 때 새로운 태스크의 예제를 분류하는 방법을 탐구하였으나, 이들의 성능은 언어 설명에 따라 예측할 수 없는 방식으로 많이 다르다고 보고되고 있다.
    2. 이 논문에서는 TALC라는 프레임워크를 소개하는데, 이는 여러 가르치는 선생님들의 설명과 라벨이 없는 테스트 예제들을 활용하여 새로운 태스크에 language-guided classifier를 적응시킨다.
    3. 실험 결과에서 TALC가 이전 연구에 비해 상대적으로 9.3% 좋은 성능을 보이며, 수질과 수량이 다른 설명에도 강건하다는 것을 보여주고 있다.

###### Summarizing Multiple Documents with Conversational Structure for Meta-Review Generation (https://aclanthology.org/2023.findings-emnlp.472/)
- Anthology ID: 2023.findings-emnlp.472 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. PeerSum은 학술논문의 meta-reviews를 생성하기 위한 새로운 데이터셋으로, 논문 요약, 리뷰, 다중 대화의 성격을 가진다. 이러한 정보들은 전문가들에 의해 평가된 메타데이터와 함께 풍부한 관계를 가진다.
    2. 우리는 hierarchical한 대화 구조와 희소 어텐션을 활용하는 모델인 RAMMER를 제안하였으며, 이 모델은 메타데이터 특징을 예측하는 다중 태스크 훈련 목적으로 학습된다.
    3. 실험 결과, RAMMER는 기존의 강력한 기준 모델들보다 자동 평가 메트릭에서 우수한 성능을 보이지만, 충돌하는 정보를 처리하는 데 어려움을 겪는다는 한계가 있어서 meta-review 생성은 어려운 과제이며 더 많은 연구가 필요하다는 것을 알 수 있다.

###### VIPHY: Probing “Visible” Physical Commonsense Knowledge (https://aclanthology.org/2023.findings-emnlp.473/)
- Anthology ID: 2023.findings-emnlp.473 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Vision-language models (VLMs)는 시각적 추론 작업에서 놀라운 성능을 보이며, 이러한 작업은 시각적 사례를 기반으로 그 사례를 해석하고 추론하는 데 필요한 지식을 측정한다. 그러나 VLM의 지식을 보존하고 일반화하는 능력은 평가되지 않았다.
    2. 본 연구에서는 VLM의 "보이는" 물리적 지식 - 정지된 장면의 이미지로부터 쉽게 얻을 수 있는 정보 (객체의 색상, 크기, 공간 등) - 을 평가한다.
    3. 우리는 자동 파이프라인을 구축하여 VLM의 성능을 평가하고, 모델과 인간의 성능 사이에 심각한 격차가 있음을 보여준다. 또한, 언어에 기반한 사전 훈련 모델이 크기와 공간 작업에서 VLM보다 훨씬 우수한 성능을 보여줌으로써, VLM이 이러한 지식을 보존하는 데 어려움을 겪는다는 사실을 강조한다.

###### Two Directions for Clinical Data Generation with Large Language Models: Data-to-Label and Label-to-Data (https://aclanthology.org/2023.findings-emnlp.474/)
- Anthology ID: 2023.findings-emnlp.474 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. LLMs (Large Language Models)는 희귀하고 민감하며 불균형한 의료 데이터가 있는 임상 텍스트 마이닝 분야에 대한 잠재력이 미개척되어 있다. 
    2. 우리는 AD(알츠하이머 병)-관련 증상 감지를 위한 LLM의 임상 데이터 보강 가능성을 조사한다.
    3. 우리의 연구에서, 전문가의 지식을 통해 AD 증상 진행에 대한 실용적인 분류법과 3개의 데이터셋을 생성하여 진행하였다.
    
    1. 기존 금 데이터셋만 사용한 시스템과 비교하여, 실버와 브론즈 데이터셋은 시스템 성능을 향상시키는 것이 확인되었다.
    2. 이는 LLMs가 전문가 지식을 통합하여 복잡한 과제에 대한 합성 임상 데이터를 생성할 수 있다는 것을 보여준다.
    3. 또한 우리의 라벨-투-데이터 방법은 민감한 정보 없이 적절한 품질을 유지하는 데이터셋을 생성할 수 있다.
    
    (Note: The translation for "label-to-data method" is customized to fit the context better)

###### Stylized Dialogue Generation with Feature-Guided Knowledge Augmentation (https://aclanthology.org/2023.findings-emnlp.475/)
- Anthology ID: 2023.findings-emnlp.475 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 스타일화된 대화 생성 시스템은 원하는 스타일을 효과적으로 재현하면서 일관성있고 문맥에 맞는 대화를 생성하는 것을 목표로 한다. 
    2. 이 논문에서는 특징 기반 스타일 지식 선택 모듈을 포함한 지식증강된 스타일화된 대화 생성 모델을 제안한다.
    3. 실험 결과, 우리의 방법은 두 가지 공개된 스타일화된 대화 벤치마크에서 자동화 및 인간평가 모두에서 만족스러운 성능을 보여준다.

###### Probing LLMs for Joint Encoding of Linguistic Categories (https://aclanthology.org/2023.findings-emnlp.476/)
- Anthology ID: 2023.findings-emnlp.476 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델 (LLMs)은 사전 훈련 과정에서 얻은 일반적인 언어 지식으로 인해 NLP 과제에서 인상적인 성능을 발휘합니다. 그러나 LLM 계층에서는 언어적 계층 구조가 형성되고, 하위 계층에서는 구문 작업에 더 적합하고 상위 계층에서는 의미 처리에 사용된다는 것을 알 수 있습니다. 하지만 다른 언어 현상의 인코딩이 모델 내에서 어떻게 상호 작용하며 얼마나 많이 언어 관련 범주의 처리가 동일한 모델 표현에 의존하는지에 대해서는 잘 알려져 있지 않습니다. 
    2. 이 논문에서는 LLMs에서 언어 범주의 공동 인코딩을 테스트하는 프레임워크를 제안합니다. 구문에 초점을 맞추어, 우리는 동일한 언어적 계층의 일부 (관련된 품사 (POS) 클래스) 및 서로 다른 언어적 계층의 일부 (품사 클래스 및 관련 구문 종속성 관계)에서 공동 인코딩의 증거를 찾을 수 있었습니다.
    3. 우리의 다국어 실험은 다국어 LLM에서 동일한 패턴이 나타남을 보여줍니다.

###### On Robustness of Finetuned Transformer-based NLP Models (https://aclanthology.org/2023.findings-emnlp.477/)
- Anthology ID: 2023.findings-emnlp.477 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. BERT, GPT-2, T5 같은 transformer-based pre-trained model들은 많은 NLP 태스크에 대해 fine-tuning 되었고, 매우 효과적임이 알려져 있다. 그러나, fine-tuning 과정에서 이러한 모델들의 layer 별 변화는 연구되지 않았다. 
    2. 이 논문에서는 두가지 metric인 CKA와 STIR을 사용하여 pre-trained와 fine-tuned 언어 모델의 표현 사이의 변화를 특성화하였다. 더 나아가, 여덟 가지 다른 텍스트 변형에 대해 BERT, GPT-2, T5 세 가지 언어 모델의 견고성을 연구하였다.
    3. GPT-2의 표현은 BERT와 T5에 비해 여러 유형의 입력 변형에 대해 더 견고했다. 전반적으로 모델은 큰 변형에도 견고하게 작동하지만, 명사를 제거하거나 동사를 변경하는 것이 가장 영향력이 크다. 이 연구는 인풋 데이터를 전달할 때 고려해야 하는 transformer-based 모델들의 특정 취약점에 대한 유용한 통찰력을 제공한다.

###### Measuring and Mitigating Constraint Violations of In-Context Learning for Utterance-to-API Semantic Parsing (https://aclanthology.org/2023.findings-emnlp.478/)
- Anthology ID: 2023.findings-emnlp.478 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 실행 가능한 과제 중심의 의미 파싱에서, 시스템은 사용자의 자연어 발화를 머신이 해석할 수 있는 프로그램(API 호출)으로 번역하는데 목적이 있다. LLMs의 인컨텍스트 학습은 데이터 제한적인 상황에서 강력한 기준으로 작용하며, 이와 관련된 과제에서도 강력한 기준을 제공함을 보여준다. 하지만 LLMs은 환각(hallucinate)하는 경향이 있어서 생성된 내용을 제한하는 것에 대한 도전 과제를 제기한다.
    2. 이 연구에서는 API-CD(API-aware Constrained Decoding) 및 SRD(Semantic-Retrieval of Demonstrations)라는 두 가지 방법을 조사하여 사전 정의된 API의 구조 및 과제에 대한 제약을 적극 활용하는데 대한 효과를 측정하고 분석한다.
    3. 실험 결과, 이러한 전략이 제약 사항 위반을 줄이고 생성된 API 호출의 품질을 개선하는 데 효과적이지만, 구현 복잡성과 대기 시간을 고려해야 한다는 것을 알 수 있다.

###### Entity Disambiguation on a Tight Labeling Budget (https://aclanthology.org/2023.findings-emnlp.479/)
- Anthology ID: 2023.findings-emnlp.479 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 실제 NLP 애플리케이션에서는 작은 라벨링 예산으로 특정 도메인의 entity disambiguation 모델을 훈련하는 어려움이 있다. 따라서 이 논문에서는 특징 다양성과 낮은 rank 방법을 결합한 해결책을 제안한다.
    2. 텐서 모델의 맥락에서 제안한 샘플링 전략은 특징 다양성과 낮은 rank 보정을 조합한 것이다.
    3. 실험 결과, 제안한 접근법은 주어진 성능을 달성하기 위해 필요한 라벨링된 데이터 양을 크게 줄일 수 있다.

###### Topic-DPR: Topic-based Prompts for Dense Passage Retrieval (https://aclanthology.org/2023.findings-emnlp.480/)
- Anthology ID: 2023.findings-emnlp.480 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이전 연구들은 단일 벡터로 연속적인 prompt를 최적화하여 사전 훈련된 언어 모델의 의미 이해력을 향상시키는 것에 주로 초점을 맞추었으나, 이러한 방식은 의미 공간의 붕괴를 유발한다. 그 결과, 동일한 의미 정보가 모든 표현들에 스며들어 그 분포가 제한된 영역에서 수렴하게 되어 밀집 검색 도중에 관련성 없는 패스와 관련성 있는 패스를 구분하기 어렵게 한다.
    2. 이러한 문제에 대응하기 위해 우리는 Topic-DPR이라고 불리는 밀집 패스 검색 모델을 제안한다. 단일한 prompt 방법과 달리, 다중 주제 기반 prompt가 확률적 simplex 상에 구성되고, 대조 학습을 통해 동시에 최적화된다. 이러한 방식은 표현들이 주제의 분포와 일치하도록 유도하여 공간의 균일성을 향상시킨다.
    3. 더 나아가, 우리는 반구조적 데이터를 활용한 새로운 양성 및 음성 샘플링 전략을 도입하여 밀집 검색 효율을 향상시킨다. 두 개의 데이터셋에서의 실험 결과는 우리의 방법이 이전의 최첨단 밀집 검색 기법을 능가한다는 것을 확인한다.

###### Quantifying the Dialect Gap and its Correlates Across Languages (https://aclanthology.org/2023.findings-emnlp.481/)
- Anthology ID: 2023.findings-emnlp.481 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. NLP 도구를 소수 언어 변형 (예: 푸에르토리코 스페인어 또는 스위스 독일어)에 적용할 때 품질이 감소하는 경향이 있지만, 이와 관련된 연구는 일부 언어에만 국한되어 있다. 
    2. 이 논문에서는 대표적인 large language models (LLMs)를 통해 수많은 고/저 정보 리소스 언어의 지역 방언에서의 기능을 평가하고, 경제, 사회, 언어적 요인과의 연관성을 분석한다. 
    3. 훈련 데이터의 영향은 모델이나 언어에 따라 일관되지 않으므로, 방언 간 격차를 해소하기 위해 일반적인 접근 방식이 적용될 수 없다는 것을 보여준다. 이 연구는 명심하며 데이터 수집을 통해 불균형을 해소하기 위한 가능한 방법들을 찾아낼 수 있는 방언 NLP 분야의 기반을 마련한다.

###### RECAL: Sample-Relation Guided Confidence Calibration over Tabular Data (https://aclanthology.org/2023.findings-emnlp.482/)
- Anthology ID: 2023.findings-emnlp.482 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 가장 최근의 기계 학습 방법들은 신용 모델링이나 금융 사기 탐지와 같이 높은 위험성을 가진 애플리케이션에 필요한 정확한 신뢰도 측정을 제공하지 못하고 있다.
    2. 이 논문은 실제 세계의 탭형 데이터셋은 일반적으로 암시적인 샘플 관계를 포함하고 있으며, 이는 더 정확한 추정을 얻는데 도움이 될 수 있다는 것을 발견하였다.
    3. 이를 위해, 우리는 RECAL이라는 일반적인 사후 훈련 신뢰도 보정 프레임워크를 소개하고, 그래프 신경망을 사용하여 다른 샘플들 사이의 관계를 모델링하여 현재 기계 학습 모델의 예측 신뢰도를 교정한다.

###### Parameter-Efficient Cross-lingual Transfer of Vision and Language Models via Translation-based Alignment (https://aclanthology.org/2023.findings-emnlp.483/)
- Anthology ID: 2023.findings-emnlp.483 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 Pre-trained vision and language models이 다른 언어를 지원하기 위한 연구들은 모델의 성능에 불균형이 생길 수 있는 리소스의 문제로 인해 불완전했다. 
    2. 따라서, 저희는 번역 기반의 정렬 방법을 활용하여 여러 언어 간의 불균형을 완화시키고, 파라미터 효율적인 fine-tuning 방법을 탐구하는 새로운 작은 자원을 사용하는 크로스-언어 전이 학습 프레임워크를 제안한다. 
    3. XTD와 Multi30K 데이터셋에서 수행한 실험 결과, 우리의 프레임워크는 다양한 언어 간의 불균형을 크게 줄이고, 저자원 시나리오에서 특히 크로스-언어 전이 결과를 향상시킬 수 있음이 입증되었다.

###### Lexical Repetitions Lead to Rote Learning: Unveiling the Impact of Lexical Overlap in Train and Test Reference Summaries (https://aclanthology.org/2023.findings-emnlp.484/)
- Anthology ID: 2023.findings-emnlp.484 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이상적인 요약 모델은 참조 훈련 요약을 외우는 대신 새로운 요약 가능한 콘텐츠에 일반화되어야 한다. 이 논문에서는 훈련 요약과 테스트 요약 간의 어휘적 유사성에 따라 테스트 세트를 분할하여 성능을 평가하는 세분화된 평가 프로토콜을 제안한다.
    2. 이 논문에서는 훈련 반복이 모델이 외워지거나 사실적인 오류와 같은 데이터 아티팩트를 재생하도록 만드는 문제를 지적하고, 새로운 테스트 케이스에서의 성능을 향상시키기 위해 훈련 요약에서 어휘 반복을 제한하는 방법을 제안한다.
    3. 새로운 테스트 하위집합과 최근 뉴스 기사에 대한 자동 및 인간 평가 결과, 훈련 요약에서 어휘 반복을 제한함으로써 외우기 공부를 방지하고 일반화를 향상시킬 수 있다는 것을 보여준다.

###### Pseudointelligence: A Unifying Lens on Language Model Evaluation (https://aclanthology.org/2023.findings-emnlp.485/)
- Anthology ID: 2023.findings-emnlp.485 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 대형 언어 모델들이 많은 벤치마크에서 인간의 성능을 뛰어넘는 반면, 우리는 모델 능력의 타겟화된 평가를 위해 원칙적인 접근 방식을 취해야 한다.
    2. 우리는 의사난수성에 영감을 받아 "의사지성"을 제안하며, "(인지된) 지성은 평가자의 시각에 달려있다"는 원칙을 포착한다.
    3. 우리는 모델과 학습된 평가자 간의 동적 상호작용으로 구성된 복잡성 이론적인 모델 평가 프레임워크를 제안하며, 이 프레임워크가 언어 모델 평가의 두 가지 사례를 추론하고 기존 평가 방법을 분석하는 데 사용될 수 있음을 보여준다.

###### GDA: Grammar-based Data Augmentation for Text Classification using Slot Information (https://aclanthology.org/2023.findings-emnlp.486/)
- Anthology ID: 2023.findings-emnlp.486 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 연구들은 자연어 처리 과제에서의 저자원 문제를 해결하기 위해 다양한 데이터 증강 방법을 제안하고 있다. 그러나 이들 방법들은 문장 구조의 다양성으로 인해 의미적인 오류를 야기할 수 있고, 의미적으로 노이즈가 있는 데이터를 생산할 수 있다. 이 논문에서는 문맥 정보를 활용하여 의미적인 오류를 방지하기 위한 데이터 증강 전략인 GDA를 제안한다.
    2. GDA는 문맥 정보를 이용하여 문법의 rule들을 구성하고 조작하는 알고리즘을 사용하여 데이터셋을 증강시킨다. 이를 통해 GDA는 인간의 개입 없이 설명 가능하고 신뢰할 수 있는 데이터 증강 방법이 된다. 
    3. GDA는 사전 훈련된 언어 모델을 사용하는 다른 데이터 증강 기법들을 포함하여 평가되었고, 결과적으로 GDA는 다른 모든 데이터 증강 방법들을 19.38% 상회하는 성능을 보여주었다. GDA는 보다 정확하고 다양한 데이터를 위해 단어의 의미를 통합하는 효과적인 데이터 증강 전략이다.

###### Implicit Sense-labeled Connective Recognition as Text Generation (https://aclanthology.org/2023.findings-emnlp.487/)
- Anthology ID: 2023.findings-emnlp.487 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "문맥 사이의 은연결조사를 인식하는 작업(IDRR)은 인접한 텍스트 단락 사이의 은연결조사의 의미 레이블을 식별하는 작업입니다. 기존에는 이를 분류 작업으로 접근하지만, 몇 가지 하위 작업에서는 의미 레이블뿐만 아니라 구체적인 연결조사까지 필요합니다. 해당 논문은 Implicit Sense-labeled Connective Recognition (ISCR)을 제안하여 인접한 텍스트 단락 사이의 은연결조사와 그 의미 레이블을 식별합니다."
    2. "ISCR은 분류 작업으로 처리될 수 있지만, 많은 레이블과 그들 사이의 불균형한 데이터 분포로 인해 어렵습니다. 따라서 본 논문에서는 텍스트 생성 작업으로 다루며, 인코더-디코더 모델을 사용하여 연결조사와 그 의미 레이블을 모두 생성합니다."
    3. "PDTB-3.0의 평가 결과로부터, 기존의 분류 기반 방법보다 우수한 성능을 보였습니다."

###### VISTA: Visual-Textual Knowledge Graph Representation Learning (https://aclanthology.org/2023.findings-emnlp.488/)
- Anthology ID: 2023.findings-emnlp.488 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문에서는 이미지나 텍스트 설명을 사용하여 개체와 관계의 지식 그래프를 표현하는 visual-textual knowledge graphs (VTKGs)를 제안한다. 
    2. VTKGs는 이미지로 개체와 관계를 해석하고, 개체와 관계의 의미를 텍스트로 설명할 수 있는 새로운 벤치마크 데이터셋을 구축한다.
    3. VTKGs에 대한 knowledge graph 표현 학습 방법인 VISTA를 제안하고, 실험 결과 VISTA가 실제 VTKGs에서 최신 knowledge graph completion 방법보다 성능이 뛰어나다는 것을 보여준다.

###### Dynamic Stashing Quantization for Efficient Transformer Training (https://aclanthology.org/2023.findings-emnlp.489/)
- Anthology ID: 2023.findings-emnlp.489 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델 (LLM)은 다양한 자연어 처리 (NLP) 작업에서 탁월한 성능을 보여주었지만, 이러한 모델의 훈련은 많은 계산 및 메모리 액세스를 필요로 하기 때문에 하드웨어 비용을 크게 증가시키며, 장치 내 학습과 같은 사용 사례에서 배포하기 어렵다.
    2. 따라서 이 논문에서는 LLM 훈련이 주 메모리에 종속되어 있다는 관찰을 바탕으로, 메모리 작업을 감소시키는 동적 양자화 전략인 DSQ (Dynamic Stashing Quantization)를 제안한다.
    3. 실험 결과, DSQ는 일반적으로 장치 내 학습에 널리 사용되는 16비트 고정소수점과 비교하여 IWSLT17에서 산술 연산량을 20.95배, DRAM 연산량을 2.55배 감소시키는 효과를 보였다.

###### A Comprehensive Evaluation of Large Language Models on Legal Judgment Prediction (https://aclanthology.org/2023.findings-emnlp.490/)
- Anthology ID: 2023.findings-emnlp.490 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대용량 언어 모델 (LLMs)은 법률 분야와 같은 도메인 특화 응용 프로그램에서 큰 잠재력을 보였으나, GPT-4의 법적 평가에 대한 최근 분쟁은 실제 법률 과제에서의 성능에 대한 의문을 제기한다. 
    2. 따라서 우리는 법적 판단 예측 과제에서 LLMs를 기반으로 한 실용적인 기준 솔루션을 설계하고 테스트하여 법률에 대한 능력을 체계적으로 조사한다. LLMs는 유사한 사례들이나 간소화된 객관식 질문들을 통해 도메인 지식을 학습하거나 유사한 사례들로부터 배울 수 있는 정보 검색 (IR) 시스템과 협력할 수 있다는 것을 보여준다.
    3. 우리는 프롬프트에 포함된 유사한 사례들과 다중 선택 옵션, 즉 레이블 후보들이 LLMs가 전문적인 법률 추론에 필수적인 도메인 지식을 회상하는 데 도움이 될 수 있다는 것을 보여준다. 게다가, 강력한 IR 시스템으로부터 약한 LLMs가 얻는 이익이 제한되기 때문에 IR 시스템이 LLM+IR의 성능을 능가하는 흥미로운 역설적인 상황도 제시된다. 이러한 경우에는 LLMs의 역할이 중복이 된다.

###### A Lightweight Method to Generate Unanswerable Questions in English (https://aclanthology.org/2023.findings-emnlp.491/)
- Anthology ID: 2023.findings-emnlp.491 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 질문에 사용 가능한 정보가 없다면, QA 시스템은 대답하지 않아야 한다. 이 논문에서는 존재하지 않는 질문을 생성하는 다른 학습 데이터를 사용하여 QA 모델을 구축하는 방법을 제안하고 있다.
    2. 기존 자동 방법에 비해 우리가 제안하는 학습 무료(lightweight) 전략으로 생성된 데이터는 더 좋은 모델을 만들어주고, 관련성과 가독성도 더 높다.
    3. 우리의 방법은 간단하지만 강력한 베이스라인이 되며, SQuAD 2.0 데이터 (BERT-large에서 +1.6 F1 점)와 TydiQA-MinSpan 데이터 (BERT-large에서 +9.3 F1 점)에서 상당한 성능 향상을 보여준다.

###### Automatic Evaluate Dialogue Appropriateness by Using Dialogue Act (https://aclanthology.org/2023.findings-emnlp.492/)
- Anthology ID: 2023.findings-emnlp.492 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화 시스템 평가에서 적절성은 의사소통 언어 능력의 핵심 요소로서 중요하다. 그러나 현재의 평가는 인간의 판단에 많이 의존하며, 시간과 노력이 많이 소요되며, 편향되기 쉽고 객관성이 부족하다.
    2. 본 논문에서는 다이얼로그 행위 전이의 양상을 이용하여 챗봇의 응답 적절성을 평가하는 DAA라는 새로운 방법을 제안한다.
    3. DAA는 인간-인간 대화 체인을 통해 전이 패턴을 학습하고, 챗봇의 전이 패턴과 유사성을 측정하여 적절성을 평가한다는 것을 실험적으로 검증하였다.

###### TabPrompt: Graph-based Pre-training and Prompting for Few-shot Table Understanding (https://aclanthology.org/2023.findings-emnlp.493/)
- Anthology ID: 2023.findings-emnlp.493 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 표 이해(Table Understanding, TU)는 기계가 표 데이터의 의미를 이해할 수 있게 하는 정보 추출의 필수적인 요소이다. 그러나 기존 TU 방법은 레이블이 지정된 표 데이터의 부족에 대처할 수 없다. 또한, 이러한 방법은 주로 표 내의 텍스트 내용에 초점을 맞추고 표의 고유한 위상 정보를 무시하여 표 의미를 잘못 이해할 수 있다.
    2. 이 논문에서는 위의 문제를 해결하기 위해 TabPrompt라는 새로운 프레임워크를 제안한다. 적은 양의 데이터로도 뛰어난 성능을 보이는 프롬프트 기반 학습을 사용하여 적은 양의 TU를 처리한다.
    3. 또한, 그래프 대비 학습(Graph Contrastive Learning, Graph CL)은 위상 정보를 캡처하는 뛰어난 능력을 보여주어 그래프 신경망이 표를 인코딩하는 이상적인 방법이다. 따라서, 표에 맞춤화된 새로운 Graph CL 방법을 개발한다. 이 방법은 사전훈련 단계에서 사전텍스트 작업으로 사용되어 표의 위상 정보를 포함하는 벡터 표현을 생성한다. 강력한 기준선을 능가하는 실험 결과는 우리의 방법의 적은 양의 표 이해 작업에서의 강점을 보여준다.

###### Towards Formality-Aware Neural Machine Translation by Leveraging Context Information (https://aclanthology.org/2023.findings-emnlp.494/)
- Anthology ID: 2023.findings-emnlp.494 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 번역의 자연스러움을 결정하는 중요한 언어적 성질 중 하나인 엄격성(formality)은 대상 언어 환경에 엄격성과 관련된 토큰이 있음에도 불구하고 희소성(sparsity) 때문에 context-aware한 NMT 모델이 이를 제대로 구별하기 어렵습니다. 
    2. 본 논문에서는 새로운 학습 방법을 소개하여 포멀리티 분류기를 사용하여 NMT 모델에 가장 정보를 제공하는 토큰을 강조하여 명시적으로 알립니다. 대상 언어 환경에서 해당 토큰에 집중하도록 모델을 이끕니다. 
    3. 실험 결과는 우리의 방법이 전체적인 번역 품질을 향상시키는 데 도움이 되는데 더불어 대상 언어 환경으로부터 적절한 엄격성을 반영한다는 것을 보여줍니다.

###### Improving Seq2Seq Grammatical Error Correction via Decoding Interventions (https://aclanthology.org/2023.findings-emnlp.495/)
- Anthology ID: 2023.findings-emnlp.495 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 많이 쓰이고 있는 Seq2Seq 접근법은 문법 오류 수정(GEC)에서 유망한 성능을 보이지만 두 가지 문제점이 있다. 
    2. 첫째, Seq2Seq GEC 모델은 병렬 데이터로만 훈련될 수 있고, GEC 작업에서는 노이즈가 많고 양도 제한적인 경우가 많다. 둘째, Seq2Seq GEC 모델의 디코더는 생성 중인 토큰의 정확성을 명시적으로 알 수 없다.
    3. 본 논문에서는 외부 비평가(critic)를 사용하여 토큰의 적절성을 점진적으로 평가하고, 다음 토큰의 선택에 동적으로 영향을 주는 통합 디코딩 개입 프레임워크를 제안한다.

###### Exploring the Potential of Large Language Models in Generating Code-Tracing Questions for Introductory Programming Courses (https://aclanthology.org/2023.findings-emnlp.496/)
- Anthology ID: 2023.findings-emnlp.496 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문에서는 초급 프로그래밍 강좌에서 큰 언어 모델 (LLM)을 사용하여 코드 추적 질문을 생성하는 응용에 대해 탐구한다.
    2. 우리는 GPT4를 대상으로 코드 조각과 설명을 기반으로 코드 추적 질문을 생성할 수 있도록 유도하는 대상 프롬프트를 설계했다.
    3. 우리는 인간 전문가가 작성한 질문과 모델이 생성한 질문을 비교하여 모델이 생성한 질문의 품질을 평가하기 위한 인간 평가 메트릭을 도출했으며, LLM이 다양한 코드 추적 질문을 생성하는 능력과 잠재력에 대한 통찰력을 제공한다.

###### Learning Easily Updated General Purpose Text Representations with Adaptable Task-Specific Prefix (https://aclanthology.org/2023.findings-emnlp.497/)
- Anthology ID: 2023.findings-emnlp.497 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 실제 응용 프로그램에서는 동일한 텍스트로부터 여러 가지 예측을 만들어야 하는 경우가 많다. 각 downstream task마다 큰 사전 훈련된 언어 모델을 fine-tuning하는 것은 몇 번의 forward passes 때문에 추론 시간에서 계산적 부담을 초래한다. 따라서, 계산 비용을 분산시키기 위해 언어 모델을 고정시키고 고정된 텍스트 표현을 기반으로 downstream task를 위한 경량 모델을 구축하는 것이 일반적인 해결책이다.
    2. 그러나, 어떻게 보면 더 일반적인 텍스트 표현을 학습하여 이를 새로운 downstream task에 잘 일반화할 수 있는지는 난제가 된다.
    3. 해당 논문에서는 소스 태스크로부터 고정된 텍스트 표현을 학습하기 위한 프리픽스 기반의 방법을 제안하며 실험 결과, 프리픽스 기반 훈련이 멀티태스킹 훈련보다 더 좋은 성능을 보이며, 멀티태스킹 훈련보다 계산 비용이 적은 업데이트를 수행할 수 있다는 것을 보여준다.

###### Good Meta-tasks Make A Better Cross-lingual Meta-transfer Learning for Low-resource Languages (https://aclanthology.org/2023.findings-emnlp.498/)
- Anthology ID: 2023.findings-emnlp.498 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 모델-에이노테그닉 메타-러닝은 저자원 상황에서 적은 양의 다국어 전이 학습을 향상시키기 위한 유망한 기법으로 주목받고 있으나, 이 크로스-린귈 메타-전이 방법에서 데이터 선택 전략의 영향에 대한 관심은 적었다. 이 논문에서는 사후적인 레벨에서 크로스-린귈 메타-트레이닝 데이터(즉, 메타-태스크)를 선택하여 언어 간 격차를 줄이기 위한 다양한 데이터 선택 전략을 구성하는 "MeTaCo-XMT"라는 메타-태스크 수집기 기반의 크로스-린귈 메타-전이 프레임워크를 제안한다.
    2. 통사적 차이는 전이 성능에 영향을 미치므로, 우리는 통사적 유사성 샘플링 전략을 고려하고, 사전 학습 모델을 기반으로 한 구문 인코더 블록과 Word Move's Distance (WMD)를 사용하는 거리 측정 블록을 갖춘 통사적 거리 측정 모델을 제안한다.
    3. Wikiann 및 TydiQA라는 두 개의 다국어 NLP 데이터셋에서의 실험 결과는 기존 강력한 기준과 비교하여 우리의 접근 방식의 유의한 우위를 보여준다.

###### Reasoning Makes Good Annotators : An Automatic Task-specific Rules Distilling Framework for Low-resource Relation Extraction (https://aclanthology.org/2023.findings-emnlp.499/)
- Anthology ID: 2023.findings-emnlp.499 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 relation extraction은 부족한 레이블 데이터로 인해 어려움이 있다. 이 논문에서는 ARIA라는 자동 task-specific 규칙 추출 프레임워크를 제안하여 사람이 규칙을 매뉴얼하게 작성하지 않고도 고품질 규칙을 생성할 수 있도록 한다.
    2. ARIA는 사전 훈련된 언어 모델을 사용하여 규칙을 추론하고 강력한 결합 규칙을 구성하는 방법을 안내한다. 또한 신뢰할 수 있는 모델-레이블 데이터를 발견하여 식별 가능한 규칙 생성을 위해 규칙 세트를 지속적으로 향상시킬 수 있다.
    3. 논문에서 진행한 실험은 저자들이 제안한 ARIA가 낮은 리소스 상황에서 효과적으로 작동함을 보여준다.

###### Co-training and Co-distillation for Quality Improvement and Compression of Language Models (https://aclanthology.org/2023.findings-emnlp.500/)
- Anthology ID: 2023.findings-emnlp.500 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 지식 전달 기법인 Knowledge Distillation(KD)의 성능을 향상시키기 위해 Co-Training and Co-Distillation(CTCD)이라는 새로운 프레임워크를 제안한다. 
    2. CTCD 프레임워크는 두 개의 모델을 동시에 학습시키고 상호적으로 지식을 전달함으로써 성능과 추론 속도를 모두 향상시킨다.
    3. CTCD는 기존 방법들과 결합하여 성능을 더욱 향상시킬 수 있으며, GLUE 벤치마크에서 CTCD로 훈련된 작은 모델이 원래의 큰 모델보다 더 우수한 성능을 보여준다는 결과를 보여준다.

###### ReadPrompt: A Readable Prompting Method for Reliable Knowledge Probing (https://aclanthology.org/2023.findings-emnlp.501/)
- Anthology ID: 2023.findings-emnlp.501 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Pre-trained language models (PLMs)를 통해 지식을 파악하는 task에서 기존 방법들은 prompt의 가독성을 희생시키는 문제가 있었다. 이 논문에서는 ReadPrompt라는 새로운 방법을 제안하여 의미 있는 문장을 prompt로 선택함으로써 가독성을 개선하였다.
    2. ReadPrompt는 현재 지식 파악 벤치마크에서 최고 수준의 성능을 얻을 수 있었다. 또한, 가독성이 높아져 prompt와 실제 지식에 대한 불일치를 발견할 수 있었으며 이는 공격 실험을 통해 기존 접근법의 불신성을 보여준다.
    3. 따라서, 현재의 prompting 방법으로 얻은 지식 파악 결과는 PLMs에 포함된 지식을 과대평가한다고 주장한다.

###### Coherent Entity Disambiguation via Modeling Topic and Categorical Dependency (https://aclanthology.org/2023.findings-emnlp.502/)
- Anthology ID: 2023.findings-emnlp.502 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존 entity disambiguation (ED) 방법은 mention context와 후보 entity 간의 일치도에 기반한 판별적 패러다임을 채택하지만, 명확한 문맥 수준의 의존성을 포착하는 데 어려움을 겪어 추상적인 수준에서 일관성 없는 예측 결과를 보인다. 
    2. 우리는 CoherentED라는 ED 시스템을 제안하여 엔티티 예측의 일관성을 향상하는 새로운 디자인을 도입한다. 
    3. 우리는 먼저 무감독적인 variational autoencoder(VAE)를 도입하여 문맥 문장의 latent topic vector를 추출하고, 익숙하지 않은 멘션에 대한 관련 카테고리를 검색할 수 있는 외부 카테고리 memory를 통합한다. 이러한 디자인은 엔티티간 상호작용을 모델링하고 카테고리 수준에서 최대한의 일관성을 유지하도록 도움을 준다.

###### How Predictable Are Large Language Model Capabilities? A Case Study on BIG-bench (https://aclanthology.org/2023.findings-emnlp.503/)
- Anthology ID: 2023.findings-emnlp.503 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다양한 실험 구성에서 대형 언어 모델(Large Language Model; LLM)의 성능을 정확하게 예측할 수 있는가? 이 질문의 답은 LLM 사용자, 개발자 및 연구 커뮤니티에 실용적인 영향을 미친다. 
    2. 연구에서는 BIG-bench 실험 기록을 사용하여 성능 예측 문제를 연구하였으며, MLP 기반 예측기를 사용하여 학습 가능한 패턴의 존재를 확인했다. 
    3. 또한, "small-bench"라고 불리는 작은 부분집합을 찾아 LLM 성능을 최대로 복원할 수 있는데, 이를 위해 MLP 기반 예측기를 통해 학습된 작업 표현을 군집화하고 클러스터 중심에 가까운 작업들을 선정하여 경쟁력 있는 부분집합을 찾아냈다.

###### POSQA: Probe the World Models of LLMs with Size Comparisons (https://aclanthology.org/2023.findings-emnlp.504/)
- Anthology ID: 2023.findings-emnlp.504 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "음체된 언어 이해는 단순히 뇌의 정신적 처리가 아니라 물리적 및 사회적 환경과의 상호작용도 포함된다는 것을 강조한다. 이 논문에서는 최신 대형 언어 모델의 현실 세계 이해력을 확인하기 위해 단순한 크기 비교 질문을 다룬 Physical Object Size Question Answering 데이터셋인 POSQA를 제안한다."
    2. "최신 대형 언어 모델들은 제로샷 설정에서 실망스런 성과를 보인다. 따라서 우리는 고급 프롬프팅 기법과 외부 지식 보완을 통해 그 한계를 넓히려고 한다."
    3. "또한, 문맥 정보와 내부 가중치 중 어느 쪽이 현실 세계 이해력에 주로 기여하는지, 프롬프트 형식의 영향 및 다른 객체의 보고 편향을 분석하였다. 결과적으로 표면 형태의 프롬프트로 인해 LLM 대형 언어 모델들의 현실 세계 이해력이 속임수와 혼란에 취약하며, 이는 인간 행동과 덜 일치한다는 것을 확인하였다."

###### Hierarchical Fusion for Online Multimodal Dialog Act Classification (https://aclanthology.org/2023.findings-emnlp.505/)
- Anthology ID: 2023.findings-emnlp.505 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 음성과 ASR로 생성된 텍스트를 기반으로하는 온라인 다중 모달 대화 행위 (DA) 분류를위한 프레임 워크를 제안한다. 기존의 다중 모달 DA 분류 접근법은 효과적인 오디오 모델링과 늦은 단계 퓨전에 의해 제한되고 있다.
    2. 우리는 모달리티를 더 세분화하여 통합하고, 오디오 특성 추출을 위해 최근의 대형 언어 및 오디오 모델의 발전을 포함하여 다중 모달 DA 분류에서 상당한 개선을 보여준다.
    3. 우리는 DA 분류를 위해 발화와 대화를 모델링하기위한 self-attention 및 cross-attention 메커니즘의 효과도 조사한다. MRDA와 EMOTyDA라는 두 가지 유명한 DA 분류 데이터셋에서 현재의 최첨단 모델과 비교하여 F1 스코어가 3 퍼센트 포인트 증가한다.

###### STEER: Unified Style Transfer with Expert Reinforcement (https://aclanthology.org/2023.findings-emnlp.506/)
- Anthology ID: 2023.findings-emnlp.506 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 텍스트 스타일 전환은 자연어 처리에서 다양한 응용 분야가 있지만, 단일 소스 스타일에서의 전환은 실제 세계에서는 현실적이지 않은 가정이다.
    2. STEER는 제한된 병렬 데이터에 대한 도전을 극복하기 위해 개발된 통합 프레임워크로, 임의의, 알려지지 않은 스타일에서 목표 스타일로 텍스트를 다시 작성하는 임무에 초점을 맞추고 있다.
    3. STEER는 단일 소스 스타일로부터 다양한 목표 스타일로 전환이 가능하며, 실험 결과는 다양한 스타일의 도전적인 데이터셋에서 경쟁력 있는 기준과 비교했을 때 최고 수준의 결과를 보여준다.

###### Enhancing Argument Structure Extraction with Efficient Leverage of Contextual Information (https://aclanthology.org/2023.findings-emnlp.507/)
- Anthology ID: 2023.findings-emnlp.507 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Argument structure extraction (ASE)은 문서 내에서 인식된 논쟁 구조를 식별하는 것을 목표로 한다. 이전 연구에서는 문맥 정보가 효과적인 ASE 모델을 개발하는 데 중요하다는 것을 보였다.
    2. 그러나 우리는 단순히 문맥 창에 있는 문장을 연결하는 것만으로는 문맥 정보를 충분히 활용하지 못하고 때로는 덜 정보성 있는 문장에 과도한 집중을 할 수 있다는 것을 관찰하였다.
    3. 우리는 이 도전을 해결하기 위해, 모델링 능력을 향상시키고 훈련 데이터를 증강시킴으로써 완전히 문맥 정보를 활용하는 효율적인 ECASE 모델을 제안한다. 또한 우리는 훈련 데이터를 특정 단어나 덜 정보성 있는 문장에 의존하지 않도록 논평 표지점과 문장을 무작위로 마스킹하여 데이터를 증강시킨다. 다양한 도메인의 다섯 개 데이터셋에서의 실험은 우리 모델이 최고의 성능을 달성하는 것을 보여준다. 또한, 부분 제거 연구는 우리 모델의 각 모듈의 효과를 확인한다.

###### Examining Inter-Consistency of Large Language Models Collaboration: An In-depth Analysis via Debate (https://aclanthology.org/2023.findings-emnlp.508/)
- Anthology ID: 2023.findings-emnlp.508 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델(Large Language Model)들은 다양한 응용분야에서 놀라운 성능을 보이고 있지만, 여전히 불일치 문제에 직면한다. 우리는 기존 연구들이 LLM 내부의 불일치 문제에 초점을 맞추었다면, 우리는 여러 개의 LLM들 간의 상호적일관성에 주목하여 협업을 탐구한다.
    2. 우리는 LLM들이 공통 목표를 위해 효과적으로 협업하여 합의를 도출할 수 있는지 검토하기 위해 상식적 추론에 초점을 맞추고 형식적 토론(FORD) 프레임워크를 소개한다.
    3. 우리의 실험결과는 LLM들이 상호적 불일치에도 불구하고 합의에 도달하기 위해 효과적으로 협업할 수 있다는 것을 보여주지만, 능력의 균형이 불균형해서 뛰어난 LLM에게 지배될 수 있다. GPT-4와 같은 더욱 발전된 LLM을 권위적인 판단자로 활용하면 협업 성능을 향상시킬 수 있다.

###### Culturally Aware Natural Language Inference (https://aclanthology.org/2023.findings-emnlp.509/)
- Anthology ID: 2023.findings-emnlp.509 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사람들은 특정 문화적 맥락에서 언어를 생산하고 소비한다. 이러한 문화적 맥락의 인식은 의사소통에 있어서 매우 중요하다.
    2. 현재의 연구는 텍스트의 문화적 해석에 어떤 인과관계가 있는지 연구하지 않고 문화적 지식 베이스를 구축하는 데에 초점을 맞추고 있다.
    3. 이 연구에서는 문화적 변이를 자연어 이해(NLI) 작업을 통해 구체화하고, 미국과 인도에 위치한 두 가지 문화 그룹의 주장-가설 쌍을 포함한 첫 번째 문화적 자연어 추론(CALI) 데이터셋을 소개한다.

###### End-to-End Autoregressive Retrieval via Bootstrapping for Smart Reply Systems (https://aclanthology.org/2023.findings-emnlp.510/)
- Anthology ID: 2023.findings-emnlp.510 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화 시스템에서 댓글 제안 시스템은 매우 중요한 부분이지만, 기존의 검색 아키텍처는 개별 메시지-댓글 유사성만 고려하기 때문에 이러한 작업에 적합하지 않다. 결과적으로 이러한 시스템은 다양한 출력을 얻기 위해 추가적인 후처리 모듈에 의존하게 된다. 하지만 이러한 접근 방식은 초기 검색 모델의 성능에 의해 제약받으며, 다운스트림 다양화 모듈에 충분히 다양한 옵션을 제시하지 못하여 사용자에게 적합하지 않은 제안을 제공하게 된다. 이 논문에서는 텍스트-텍스트 추론 모델인 자동 회귀형 토크 수집 모델을 사용하여 이러한 문제를 극복한다.
    2. 이 논문에서는 자동 회귀형 토크 수집 모델을 사용하여 데이터셋에서 스마트 리플라이 작업을 end-to-end로 학습하는 새로운 접근 방식을 제안한다.
    3. 실험 결과, 이 방법은 성능이 우수한 베이스라인 방법과 비교하여 관련성에서 5.1%-17.9% 향상, 다양성에서 0.5%-63.1% 향상을 보여주었다. 이 코드는 공개적으로 이용 가능하다.

###### Evaluating Dependencies in Fact Editing for Language Models: Specificity and Implication Awareness (https://aclanthology.org/2023.findings-emnlp.511/)
- Anthology ID: 2023.findings-emnlp.511 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델(Large Language Model, LLM)을 지식 기반(Knowledge Base, KB)으로 사용하는 잠재력이 큰 관심을 불러일으켰다. LLM에서 습득한 지식을 유지하기 위해서는 학습된 사실의 편집이 내부적인 논리적 제약조건을 준수해야 하는데, 이는 지식의 의존성(dependency of knowledge)로 알려져 있다. 
    2. 기존 연구에서는 사실의 편집이 관련 없는 것들을 방해하지 않으면서 그것의 단어 변형에 적용되어야 한다는 의존성 문제를 부분적으로 해결하였지만, 사실과 그 논리적 함축사이의 의존성을 간과하고 있다. 
    3. 이 논문에서는 의존성 개념을 고려한 편집 과정을 포괄적으로 평가하기 위한 StandUp이라는 질문-답변 데이터셋과 평가 프로토콜을 제안한다. StandUp에서는 판단규칙을 기반으로 편집된 사실의 영향과 논리적 함축사이의 관계를 감시하는 통제된 환경을 구축한다. StandUp 기반의 실험 결과, 기존의 지식 편집 방법은 지식의 표면 형태에 민감하며, 편집된 사실의 함축사를 추론하는 능력이 제한적임을 보여준다.

###### Effects of Human Adversarial and Affable Samples on BERT Generalization (https://aclanthology.org/2023.findings-emnlp.512/)
- Anthology ID: 2023.findings-emnlp.512 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. BERT 기반 모델들은 리더보드에서 성능이 우수하지만, 일반화를 필요로 하는 실제 환경에서는 성능이 떨어진다. 이 논문에서는 일반화를 위해 학습 데이터의 양보다는 품질에 초점을 맞춘다. 
    2. 그들은 훈련 데이터의 두 가지 특성인 h-adversarial (서로 다른 ground-truth 레이블을 가지지만 보이지 않는 차이가 있는 샘플 pair)와 h-affable (같은 ground-truth 레이블을 가지지만 작은 차이가 있는 샘플 pair)에 대한 영향을 조사하였다. 
    3. 실험 결과, 학습 샘플의 수가 일정한 경우, 10-30%의 h-adversarial이 있다면 텍스트 분류와 관계 추출 작업에서 F1 점수를 최대 20 포인트 향상시킬 수 있다는 것을 발견하였다. 그러나 이 범위를 넘어서면 성능이 정체되거나 저하될 수 있다. 반면에, h-affables은 일반화 성능에 기여하지 않을 뿐만 아니라 일반화 성능을 저하시킬 수도 있다.

###### Logic Unveils Truth, While Disguise Obscures It: Transition Logic Augmented Response Selection for Multi-Turn Dialogue (https://aclanthology.org/2023.findings-emnlp.513/)
- Anthology ID: 2023.findings-emnlp.513 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다중 턴 응답 선택은 후보 풀에서 대화 맥락에 대한 응답을 검색하는 작업이다. 하지만 이전 방법들에서는 오픈 도메인 대화에서의 one-to-many 속성으로 인해 false negative가 발생하여 최적화 과정에 영향을 미친다.
    2. 이 논문에서는 순차적 변분 계단 자동인코더를 제안하여 오픈 도메인 대화의 다양한 특성의 one-to-many 전이 패턴을 포착한다. 이를 통해 학습된 전이 논리는 변장한 잠재적인 양성 예시를 식별하는 데 도움을 준다.
    3. 또한, 우리는 TRIGGER 프레임워크를 제안하여 모델 용량에 따라 false negative의 범위를 동적으로 업데이트하여 훈련 과정에서 부정적인 샘플링을 조정한다. 두 가지 벤치마크에서 수행된 실험은 우리의 방법의 효과를 검증한다.

###### Are Language Models Worse than Humans at Following Prompts? It’s Complicated (https://aclanthology.org/2023.findings-emnlp.514/)
- Anthology ID: 2023.findings-emnlp.514 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 연구에서는 일부러 무의미하거나 오도하는 prompt를 주어진 경우에도 모델이 놀랍도록 잘 수행할 수 있다는 것을 발견하였다. 이러한 결과는 모델의 행동이 "인간처럼"이 아님을 증거로 볼 수 있다. 
    2. 본 연구에서는 이러한 연구의 가설 중 하나를 도전하며, 인간들이 병적인 지시사항을 주어진 경우에도 잘 수행할 수 있다는 사실을 발견하였다.
    3. 따라서, 무의미한 prompt로 높은 성능을 얻는 것은 모델의 지시 이해에 반하는 것이 아니라고 주장하지만, 모델이 오도하는 지시를 따르지 않는 것은 우려를 증가시킨다고 강조한다.

###### A Sequence-to-Structure Approach to Document-level Targeted Sentiment Analysis (https://aclanthology.org/2023.findings-emnlp.515/)
- Anthology ID: 2023.findings-emnlp.515 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 연구에서는 document-level의 targeted sentiment analysis task를 다루었으며, review 문서에서 다중 수준 entity로 이루어진 opinion targets를 추출하고 그들의 sentiment를 예측하는 것을 목표로 한다.
    2. 우리는 Seq2Struct 방법론을 제안하는데, 이 방법론은 다중 opinion targets 간의 계층 구조를 명시적으로 모델링하고 문장 간의 관련된 entity 간의 장거리 종속성을 포착할 수 있다.
    3. 실험 결과, 우리의 Seq2Struct 방법은 다양한 사전 훈련 모델과 비교하여 우수한 성능을 보여주며, opinion targets의 다중 수준 target-sentiment pairs를 명시적으로 나타낼 수 있는 장점이 있다.

###### Generating Extractive Answers: Gated Recurrent Memory Reader for Conversational Question Answering (https://aclanthology.org/2023.findings-emnlp.516/)
- Anthology ID: 2023.findings-emnlp.516 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화형 질의응답(CQA)은 전통적인 단일 턴 기계 독해(MRC)보다 복잡한 작업이다. CQA 모델은 대화 기록에 따라 주어진 컨텐츠에서 답변을 추출하여 후속 질문에 대답해야 한다.
    2. GRMR은 기존 추출형 MRC 모델을 일반화된 시퀀스-투-시퀀스 프레임워크에 통합하는 새로운 아키텍처이다. 이 모델은 이전 질문과 답변을 단순히 연결하는 대신, 적은 저장 공간을 사용하고 과거 기억을 깊게 선택적으로 고려할 수 있다.
    3. CoQA 데이터셋에서의 실험 결과, 우리 모델은 가장 적은 공간을 차지하면서 대부분의 모델과 비슷한 결과를 달성한다.

###### Text2Tree: Aligning Text Representation to the Label Tree Hierarchy for Imbalanced Medical Classification (https://aclanthology.org/2023.findings-emnlp.517/)
- Anthology ID: 2023.findings-emnlp.517 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 의료 텍스트 분류에서 Deep learning 기법들은 많은 text 태스크에서 유망한 성능을 보이지만, 심하게 불균형하고 부족한 샘플로 인해 여전히 어려움을 겪고 있다.
    2. 기존 방법들이 외부 의료 정보와 함께 보조 의미를 중점으로 하게 되는 반면, 본 논문은 의료 텍스트의 데이터 문제를 다시 생각하고, 내부 레이블 계층을 deep learning 모델 학습에서만 활용하는 Text2Tree라는 새로운 framework agnostic 알고리즘을 제안한다.
    3. 실험 결과, 공식적인 공개 데이터셋과 실제 의료 기록에서 우리의 접근 방식이 고전적인 imbalance classification 방법보다 우수한 성능을 일관되게 보였다.

###### Impact of Co-occurrence on Factual Knowledge of Large Language Models (https://aclanthology.org/2023.findings-emnlp.518/)
- Anthology ID: 2023.findings-emnlp.518 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 대형 언어 모델들은 다양한 응용 분야에서 성공을 거두었지만, 사실적인 오답을 많이 내놓는 경향이 있다. 우리는 사전 훈련 데이터의 간단한 동시 발생 통계에 지나치게 의존하는 것이 오류 발생의 주된 요인 중 하나라는 가설을 세우고 있다.
    2. 우리의 결과는 자주 동시 발생하는 단어들을 올바른 대답보다 선호한다는 co-occurrence bias에 취약하다는 것을 보여준다. 따라서 LLM은 사전 훈련 데이터에서 주어와 목적어가 드물게 동시 발생하는 사실을 기억하기 어렵다.
    3. 우리는 바이어스가 낮은 데이터셋에서 재조정(finetuning)하여 바이어스를 완화시키는 것을 제안한다. 또한, 훈련 중보지 않은 드문 사실을 재조정 후에 기억하기 위해서는 추가적인 연구가 필요하다.

###### CTQScorer: Combining Multiple Features for In-context Example Selection for Machine Translation (https://aclanthology.org/2023.findings-emnlp.519/)
- Anthology ID: 2023.findings-emnlp.519 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 몇 가지 예시로 입력된 경우에 대형 언어 모델은 기계 번역을 수행할 수 있음을 보였다. 그러나 번역 품질은 예시의 품질과 관련성과 같은 다양한 특성에 따라 다르며, 기존 연구는 주로 개별 특성에 중점을 두었다.
    2. 이 논문에서는 예시 선택에 영향을 미치는 다양한 특성을 결합하는 일반적인 프레임워크를 제안한다.
    3. 실험 결과, CTQ Scorer는 무작위 선택과 문헌에서 보고된 강력한 단일 요인 베이스라인보다 훨씬 우수한 성능을 보여준다. 또한 강력한 BM25 검색 기반 베이스라인과 비교하여 평균적으로 2.5 COMET 점수 향상을 확인할 수 있다.

###### Swap and Predict – Predicting the Semantic Changes in Words across Corpora by Context Swapping (https://aclanthology.org/2023.findings-emnlp.520/)
- Anthology ID: 2023.findings-emnlp.520 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 단어의 의미는 시간과 도메인에 따라 변할 수 있고, 단어의 의미변화를 감지하는 것은 시간에 민감한 NLP 애플리케이션에서 중요한 작업이다.
    2. 두 개의 텍스트 corpus에서 주어진 대상 단어가 의미를 변화시키는지 예측하는 문제를 고려하고, 매스킹된 언어 모델의 컨텍스트화된 단어 임베딩의 분포를 살펴봄으로써 단어 의미의 변화를 예측할 수 있다.
    3. 사전 훈련된 언어 모델을 사용하여 실제로 fine-tuning을 하지 않고도 제안한 컨텍스트 교환 방법은 네 개의 언어(영어, 독일어, 스웨덴어, 라틴어)와 다른 시간 범위(50년 이상, 약 5년)에서 단어 의미 변화를 정확하게 예측할 수 있다.

###### Beyond Layout Embedding: Layout Attention with Gaussian Biases for Structured Document Understanding (https://aclanthology.org/2023.findings-emnlp.521/)
- Anthology ID: 2023.findings-emnlp.521 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 구조화된 문서 이해에서 layout 정보를 효과적으로 인코딩하는 것은 중요한 문제이다. 하지만, 기존 방법들은 수백만 개의 학습 가능한 parameter를 필요로 하고 있는데, 이를 반드시 필요한 것인지 의문이 남아있다.
    2. 이 논문에서는 극좌표가 카르테시안 좌표에 비해 상대적인 위치를 더 효과적으로 측정할 수 있기 때문에 더 나은 선택임을 알아냈다. 또한, 거리와 각도를 2D 가우시안 커널에 입력하여 layout 편향을 모델링하여 텍스트의 주변에 더 집중할 수 있도록 하는 방법을 제안한다.
    3. LAGaBi는 transformer 기반 모델에 적용 가능하며, BERT 및 LayoutLM과 같은 다양한 모델에 대해 수행되는 실험 결과에서 수백만 개의 layout parameter를 48개로 줄인 LAGaBi가 경쟁력 있는 성능을 달성한다.

###### ESPVR: Entity Spans Position Visual Regions for Multimodal Named Entity Recognition (https://aclanthology.org/2023.findings-emnlp.522/)
- Anthology ID: 2023.findings-emnlp.522 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Multimodal Named Entity Recognition (MNER)은 텍스트-only Named Entity Recognition (NER)의 성능을 향상시키기 위해 시각적 정보를 활용한다. 그러나 기존의 로컬 시각 정보 확보 방법은 다음과 같은 한계가 있다."
    2. "이 논문에서는 Entity Spans Position Visual Regions (ESPVR) 모듈을 제안하여 텍스트에 해당하는 가장 관련성 높은 시각적인 지역을 확보할 수 있다. 실험 결과, 제안된 방법은 Twitter-2017에서 최고 성능을 달성하고, Twitter-2015에서 경쟁력 있는 결과를 보여준다."
    3. "(ESPVR 모듈은) 시각적인 기존 방법들과 달리 문장 내 entity와 관련된 시각적인 영역을 정확히 확보할 수 있다."

###### Flatness-Aware Prompt Selection Improves Accuracy and Sample Efficiency (https://aclanthology.org/2023.findings-emnlp.523/)
- Anthology ID: 2023.findings-emnlp.523 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델의 능력이 증가함에 따라, 언어 프롬프트(prompt)를 사용하는 것이 점점 주류화되고 있다. 따라서 효과적인 언어 프롬프트를 자동으로 선택하는 전략들이 개발되고 있다.
    2. 이 논문에서는 언어 프롬프트의 기대 효용을 측정하기 위해 새로운 평가 지표인 pFlat을 소개한다. 이 메트릭은 통계 학습에서 모델의 매개 변수 변동에 대한 강건성을 측정하는 flatness 정규화에서 영감을 받았다.
    3. 실험적으로, pFlat을 기존 메트릭과 결합하면 성능과 샘플 효율성이 모두 개선됨을 보여준다. 6개의 분류 벤치마크에서 10%의 피어슨 상관 관계 평균 증가 및 기존 메트릭 대비 5% 더 높은 정확도를 가진다.

###### Detecting Erroneously Recognized Handwritten Byzantine Text (https://aclanthology.org/2023.findings-emnlp.524/)
- Anthology ID: 2023.findings-emnlp.524 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 손글씨 텍스트 인식(HTR)은 인쇄된 텍스트인 OCRed 텍스트와 비교하여 오류가 훨씬 많이 발생한다. 본 연구에서는 비잔틴 그리스어에서 이러한 문제점을 조사하고 오류 감지를 학습하는 텍스트 분류 시스템을 실험한다.
    2. 현대 그리스어로 사전 훈련한 대규모 마스킹된 언어 모델이 평균 정밀도 점수 95%를 달성한다고 보고한다.
    3. 문서 분석 결과, 고대 그리스어로 사전 훈련한 모델이 오래된 세기의 텍스트에 대해 분류기에서 유리한 결과를 나타낸다. 이 분류기를 손글씨 텍스트 후처리기 앞에 적용하면 후처리 오류를 크게 줄일 수 있다.

###### Improving Factual Consistency for Knowledge-Grounded Dialogue Systems via Knowledge Enhancement and Alignment (https://aclanthology.org/2023.findings-emnlp.525/)
- Anthology ID: 2023.findings-emnlp.525 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사전 훈련된 언어 모델 (PLMs) 기반의 지식 주도형 대화 시스템은 지식 소스와 일치하지 않는 응답을 생성하기 쉽다. 이 연구는 Transformers 내의 FFNs (feedforward networks)가 사실적인 지식 표현에 책임이 있다는 이전 연구를 바탕으로, FFN의 사실적인 표현 능력을 향상시키기 위한 두 가지 방법을 조사한다.
    2. 첫 번째로, 특정한 지식-주도 대화 입력 패턴에 따라 사실적인 지식 표현을 강화하기 위해 Transformers 내에 확장된 FFNs를 도입하는 K-Dial을 제안한다.
    3. RLFC (reinforcement learning for factual consistency) 방법을 적용하여 응답에서 FFN의 표현을 직접적으로 실제 지식에 일치시키고, 지식의 일관성 선호도에 맞게 조정한다. WoW와 CMU_DoG 데이터셋에서의 실험 결과는 우리의 방법이 FFN 모듈의 지식 전달 능력을 효과적으로 향상시키는 것을 보여주며, 지식 주도형 대화 시스템의 사실적인 일관성을 향상시키는 효과를 검증한다.

###### TRIP: Accelerating Document-level Multilingual Pre-training via Triangular Document-level Pre-training on Parallel Data Triplets (https://aclanthology.org/2023.findings-emnlp.526/)
- Anthology ID: 2023.findings-emnlp.526 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 현재의 다국어 시퀀스 투 시퀀스 사전 학습 방법은 문서 수준의 단일 언어 말뭉치와 문장 수준의 양방향 말뭉치, 때로는 합성 문서 수준 양방향 말뭉치를 사용하는 경우가 많은데, 이는 문서 수준의 번역과 같은 크로스-언어 문서 수준 태스크에서의 성능 향상을 저해한다.
    2. 우리는 문서 수준 삼중 언어 병렬 말뭉치를 찾아 활용하여 시퀀스 투 시퀀스 다국어 사전 학습을 개선하는 방법을 제안한다.
    3. 실험 결과, 우리의 방법은 다국어 문서 수준 기계 번역 벤치마크와 교차 언어 요약 벤치마크에서 강력한 최고 수준 점수를 달성하며, 최대 3.11 d-BLEU 포인트와 8.9 ROUGE-L 포인트의 개선을 보여준다.

###### Frequency Balanced Datasets Lead to Better Language Models (https://aclanthology.org/2023.findings-emnlp.527/)
- Anthology ID: 2023.findings-emnlp.527 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. attention 기반 transformer 언어 모델을 훈련하기 위해 필요한 데이터 양의 역할을 이해하기 위해 실험을 수행한 결과를 보고한다.
    2. 매우 높은 빈도로 등장하는 토큰이 학습에 부정적인 영향을 미칠 수 있다는 이전 연구들의 지적을 고려하여, pre-training 데이터에서 높은 빈도의 토큰을 줄이기 위한 샘플링 전략의 영향을 조사했다.
    3. 결과적으로, 균형 잡힌, 언어적으로 올바른 데이터셋으로 pre-training 하는 것이 pre-training 데이터 양을 최대 3배 줄일 수 있었음을 실험 결과를 통해 보였다.

###### Uncertainty-aware Parameter-Efficient Self-training for Semi-supervised Language Understanding (https://aclanthology.org/2023.findings-emnlp.528/)
- Anthology ID: 2023.findings-emnlp.528 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 사전 학습 언어 모델(PLMs)의 최근 성공은 주로 대량의 라벨이 달린 데이터에 의존하는데, 이는 보통 저자원 상황에서는 성능이 떨어지는 문제점을 가지고 있다.
    2. 이 논문에서는 UPET라는 새로운 Unsertainty-aware Parameter-Efficient self-Training 프레임워크를 제안하여 라벨이 달린 데이터 부족 문제를 효과적으로 해결하는데, Monte Carlo 드롭아웃을 활용하여 신뢰도가 높은 가짜 라벨을 선택한다.
    3. 실험 결과, UPET은 효율성과 성능 면에서 상당한 개선을 보여주었다. (GitHub: https: //github.com/wjn1996/UPET)

###### TR-Rules: Rule-based Model for Link Forecasting on Temporal Knowledge Graph Considering Temporal Redundancy (https://aclanthology.org/2023.findings-emnlp.529/)
- Anthology ID: 2023.findings-emnlp.529 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 시간적 지식 그래프(TKG)는 실제 세계의 동적 사실을 모델링하는 데 효과적인 방법으로 증명되었습니다. 본 논문에서는 TKG에서 미래 이벤트(외삽)를 예측하는 데 많은 노력이 기울여졌습니다.
    2. 기존의 임베딩 기반 방법보다 해석 가능성이 높다고 여겨지는 rule 기반 지식 그래프 외삽 방법도 최근에는 TKG에 전이되었습니다. 그러나 rule 기반 모델은 동적인 설정에서 사용될 때 시간적 중복으로 인해 정확하지 않은 rule 신뢰도 계산을 초래합니다.
    3. 본 논문에서는 시간적 중복 문제를 해결하는 간단하고 효과적인 전략을 제시하고, 순환적인 rule 외에도 non-cyclic rule을 적절하게 탐지하고 활용하여 더 많은 정보를 모델링하는 방법을 제안합니다. 실험 결과, TR-Rules은 세 가지 기준에 대해 최상의 성능을 달성하였습니다.

###### On the Transferability of Visually Grounded PCFGs (https://aclanthology.org/2023.findings-emnlp.530/)
- Anthology ID: 2023.findings-emnlp.530 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 시각적으로 기반된 문법 유도에 대한 관심이 크게 증가했으나, 이 작업에 사용된 모델들은 훈련 도메인과 다른 텍스트 도메인에서의 성능을 평가받지 못했기 때문에 시각적 기반의 개선이 얼마나 전이 가능한지 알 수 없다.
    2. 이 연구는 시각적 기반의 개선이 얼마나 전이 가능한지를 평가하기 위해 VC-PCFG 모델을 타겟 도메인에 직접 적용하는 zero-shot 전이 학습 설정에서 실험을 진행했다. 
    3. 실험 결과, 시각적 기반의 이점은 훈련 도메인과 유사한 도메인의 텍스트에 전이되지만, 원격 도메인에는 전이되지 않는 것으로 나타났다. 또한, 도메인 간의 렉서스 오버랩이 VC-PCFG의 전이 가능성에 가장 중요한 요소임을 발견하였다.

###### Analysis of Style-Shifting on Social Media: Using Neural Language Model Conditioned by Social Meanings (https://aclanthology.org/2023.findings-emnlp.531/)
- Anthology ID: 2023.findings-emnlp.531 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문에서는 소셜미디어 대화의 스타일 변화를 평가하기 위한 새로운 프레임워크를 제안한다. 
    2. 개인화된 신경망 언어 모델을 통해 각 개인의 대화 스타일의 변화를 예측한 놀라움 (surprisals)에 기반한 스타일 새로운 프레임워크를 제안한다.
    3. 지식 그래프와 미리 학습된 언어 모델을 활용하여 개인화된 언어 모델을 구축하고, 이 모델은 테스트 세트에서 개인의 언어를 예측하는 우수한 성능을 보여주었다.

###### Linguistic Compression in Single-Sentence Human-Written Summaries (https://aclanthology.org/2023.findings-emnlp.532/)
- Anthology ID: 2023.findings-emnlp.532 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 텍스트 요약은 정보를 압축하는 데 많은 인지적 노력이 필요하다. 이 논문에서는 인간이 작성한 요약에서 언어적 패턴을 분석하는 대규모 공부를 제시한다.
    2. 어휘 확장, 어휘 다양성의 증가, 특정 단어들의 위치 배치와 같은 언어적 압축 패턴을 분석해봤을 때, 그 유형에 관계없이 요약은 일반적으로 원본과 비교하여 작성되며, 작성자와 독자 간에는 어휘 다양성과 단어의 특이성에 대한 선호도가 일치하지 않는다는 것을 발견하였다.
    3. 이러한 언어학적 변화가 독자의 품질 판단에 어떤 영향을 미치는지에 대한 인간 연구를 통해, 요약 작성자와 독자 간에는 문법과 문법적 변화의 사용이 독자의 선호와 일치한다는 결과를 얻었다.

###### MCLF: A Multi-grained Contrastive Learning Framework for ASR-robust Spoken Language Understanding (https://aclanthology.org/2023.findings-emnlp.533/)
- Anthology ID: 2023.findings-emnlp.533 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. ASR 오류에 대한 강인성을 향상시키는 것은 SLU에서 매우 중요하다. 
    2. 이 논문에서는 MCLF라고 불리는 이중 단계 다중 granular 대조 학습 프레임워크를 제안한다. 
    3. 실험 결과와 상세한 분석을 통해 우리의 방법이 효과적임을 보여준다.

###### Beyond Candidates : Adaptive Dialogue Agent Utilizing Persona and Knowledge (https://aclanthology.org/2023.findings-emnlp.534/)
- Anthology ID: 2023.findings-emnlp.534 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이전 연구는 개인화와 지식을 둘 다 기반으로 하는 대화 에이전트를 구축하기 위한 것을 제안해왔지만 실제 대화에 직접 적용하는 것은 아직 한계가 있다.
    2. 이 논문은 주어진 데이터셋에서 전체 문장 형태의 개인화와 지식 후보 세트가 필요한 경우가 많기 때문에, 미리 정의된 후보 문장들 대신 사람들이 그들 마음의 의미적 개념을 활용하는 방법을 따르도록 제안한다.
    3. 본 논문에서는 전체 문장 기반의 후보 문장을 사용한 개인화와 지식을 활용하는 기존 기준선을 능가하는 모델을 제안하고, 인간 평가와 각 구성요소의 효과를 입증하기 위해 핵심 내용을 제시한다.

###### SmartSpanNER: Making SpanNER Robust in Low Resource Scenarios (https://aclanthology.org/2023.findings-emnlp.535/)
- Anthology ID: 2023.findings-emnlp.535 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Named Entity Recognition (NER)은 자연어 처리에서 가장 기본적인 작업 중 하나이다. 
    2. SpanNER 방법은 SeqLab에 비해 nested NER에 더 적합하지만, 실험 결과 SpanNER 방법은 학습 데이터 양에 매우 민감하다. 
    3. 따라서, 저자들은 SmartSpanNER이라고 불리는 새로운 SpanNER 방법을 제안하여 low resource scenario에서 SpanNER의 견고성을 향상시켰다.

###### ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding (https://aclanthology.org/2023.findings-emnlp.536/)
- Anthology ID: 2023.findings-emnlp.536 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. ZeroSCROLLS는 훈련 데이터 없이 테스트 및 소규모 검증 데이터셋만으로 구성된 Zero-shot 벤치마크로, 장문 텍스트에 대한 자연어 이해 능력을 평가한다. 
    2. ZeroSCROLLS를 사용하여 클로드(Claude)가 ChatGPT보다 우수한 성능을 보여주고, GPT-4가 가장 높은 평균 점수를 달성하는 것을 발견하였다. 그러나 ZeroSCROLLS에서 여러 개의 도전과제 중에는 모델이 기본 성능을 넘기기 어려운 집계 작업과 같은 부분에서 개선의 여지가 남아있다.
    3. 현재 기술 수준은 계속 변화하고 있기 때문에 ZeroSCROLLS 리더보드에서 사용자들이 자신의 아이디어를 평가하도록 연구자들에게 초대장을 내린다.

###### Data Selection Curriculum for Abstractive Text Summarization (https://aclanthology.org/2023.findings-emnlp.537/)
- Anthology ID: 2023.findings-emnlp.537 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존에는 임의로 섞은 대규모 데이터를 사용해 학습하지만, ATS 모델의 데이터 선택과 데이터 순서에 대한 영향은 아직 체계적으로 연구되지 않은 분야이다. 
    2. 이 연구는 학습 인스턴스의 학습 난이도를 정확하게 평가하는 것이 어려운 과제로 출발하여, 개선의 난이도와 예상 성능을 종합적으로 고려하는 데이터 선택 커리큘럼 (DSC) 점수 시스템을 제안한다.
    3. 실험 결과, CNN/DailyMail 데이터셋에서 우리의 접근 방식은 강력한 기준 모델들을 능가하며, 사용 가능한 인스턴스의 20%만을 사용하여 성능을 개선할 수 있다.

###### Romanization-based Large-scale Adaptation of Multilingual Language Models (https://aclanthology.org/2023.findings-emnlp.538/)
- Anthology ID: 2023.findings-emnlp.538 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 다국어 사전 훈련 언어 모델(mPLMs)은 NLP의 다국어 전이에서 사실상 최고 수준의 성능을 보여주고 있지만, 일부 언어 모델에 대한 vocabulary 크기 증가 및 파라미터 제약으로 인해 저자원 언어에 대한 적용에 어려움이 있다.
    2. 이 논문에서는 UROMAN이라는 대량의 복제를 통해 transliteration 기술을 활용하여 mPLMs의 저자원 및 미확인 언어 처리 능력을 향상시키는 가능성을 탐구한다.
    3. UROMAN 기반의 변환은 많은 언어에서 강력한 성능을 제공하며, 특히 본문스크립트가 없거나 훈련 데이터가 제한된 언어의 경우 특히 높은 성과를 보여준다는 연구 결과를 보여준다.

###### Measuring bias in Instruction-Following models with P-AT (https://aclanthology.org/2023.findings-emnlp.539/)
- Anthology ID: 2023.findings-emnlp.539 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Instruction-Following Language Models (IFLMs)는 많은 하위 정보 탐색 작업을 해결하기 위한 유망하고 다용도 도구이다. 그러나 기존 및 새로운 IFLMs가 편향된 언어 상호작용에 취약한지 여부를 판단하기 위한 공유 자원이 절박하게 필요합니다."
    2. 우리는 P-AT (Prompt Association Test)를 제안하여 IFLMs의 사회적 편향 존재를 테스트하는 새로운 자원을 개발했습니다.
    3. 우리의 자원은 2310개의 프롬프트로 구성되어 있으며, 여러 가족의 IFLM에서 성별 및 인종 편향을 발견하였습니다.

###### Open-ended Commonsense Reasoning with Unrestricted Answer Candidates (https://aclanthology.org/2023.findings-emnlp.540/)
- Anthology ID: 2023.findings-emnlp.540 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. '묵시적 다단계 추론'을 필요로 하는 'Open-ended Commonsense Reasoning' 문제에 대한 새로운 방법을 제안한다.
    2. 사전 정의된 정한 후보 답안이나 정해진 정답 범위 없이 평소의 상식으로 문제를 해결하는 것을 목표로 한다.
    3. 사전 학습된 언어 모델을 활용하여 외부 지식 베이스에서 추론 경로를 반복적으로 탐색하고, 이를 통해 공통감각 질문에 가장 정확한 답을 찾는다. 이 방법은 다른 접근법에 비해 정량적, 정성적으로 좋은 성능을 보여준다.

###### Speaking Style Conversion in the Waveform Domain Using Discrete Self-Supervised Units (https://aclanthology.org/2023.findings-emnlp.541/)
- Anthology ID: 2023.findings-emnlp.541 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. DISSC는 녹음의 리듬, 음고와 음색을 텍스트 없이도 대상 화자로 변환하는 경량 방법이다. 
    2. 기존 음성 변환 방법들은 주로 음색에만 초점을 두고 개인의 고유한 말투(프로소디)을 무시한다. 
    3. DISSC는 사전 훈련된 자기 감독 모델을 사용하여 음성을 이산 유닛으로 인코딩함으로써 간단하고 효과적이며 빠르게 훈련될 수 있으며, 기존 방법들보다 우수한 성능을 보여준다.

###### Knowledge-Selective Pretraining for Attribute Value Extraction (https://aclanthology.org/2023.findings-emnlp.542/)
- Anthology ID: 2023.findings-emnlp.542 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Attribute Value Extraction (AVE)은 제품 프로필에서 속성 값을 검색하는 작업이다. 
    2. 기존 방법들은 소수의 속성에 대한 성능이 만족스럽지 않으며, 일반화 능력이 부족해 이를 대처하기 어렵다. 
    3. 이 논문에서는 사전학습과 전이학습을 활용하여 성능을 향상시키는 방법을 제안하고, 지식 선택 프레임워크 (KSelF)를 사용하여 성능을 더욱 향상시킨다.

###### New Datasets and Controllable Iterative Data Augmentation Method for Code-switching ASR Error Correction (https://aclanthology.org/2023.findings-emnlp.543/)
- Anthology ID: 2023.findings-emnlp.543 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자동 음성 인식 (ASR) 시스템의 널리 사용으로 인해, ASR 오류 수정 작업을 통해 인식 결과의 품질을 개선하기 위해 더 많은 관심이 기울여지고 있다. 특히, 양/다양한 언어로 이뤄진 code-switching ASR에서는 더 큰 도전과 연구 가치가 있다.
    2. 이 논문에서는 실제 ASR 시스템과 자동 주석 달기 도구로부터 얻은 code-switching ASR 수정 데이터셋을 제시한다. 이 데이터셋은 싱가포르, 말레이시아, 홍콩의 이중 언어 사용자들의 중국어-영어 혼용 대화를 포함하고 있다. 
    3. 이 작업을 기반으로 기존 ASR 오류 수정 시스템의 성능을 향상시키기 위해 조절 가능한 반복 (CI) 데이터 증강 방법을 제안하였다. 소량의 훈련 데이터로, 우리의 제안하는 방법은 중국어-영어 코드-스위칭 ASR 수정을 위해 단일 언어 말뭉치로부터 반복적으로 풍부한 가짜 병렬 데이터를 생성할 수 있다. 실험 결과, 우리의 방법은 rule-based, back-translation-based 데이터 증강 방법 및 대규모 언어 모델 ChatGPT와 비교했을 때 가장 좋은 성능을 보였다.

###### Efficient k-NN Search with Cross-Encoders using Adaptive Multi-Round CUR Decomposition (https://aclanthology.org/2023.findings-emnlp.544/)
- Anthology ID: 2023.findings-emnlp.544 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Cross-encoder 모델은 쿼리-아이템 쌍을 함께 인코딩하고 점수를 매기는 데에는 많은 비용이 들어가고, 따라서 직접적인 k-NN 검색에는 사용하기 힘들다. 
    2. 이 논문에서는 ANNCUR와 같은 기존 방법들보다 효과적으로 상위 k개 이웃 항목의 근사 오차를 최소화하는 ADACUR이라는 방법을 제안한다. 
    3. 다른 데이터셋에서도 ADACUR은 이전의 전통적인 방법 및 최신 방법인 ANNCUR, dual-encoder 기반의 retrieve-and-rerank와 비교하여 리콜 에러를 일관되게 감소시키며, 경쟁 제품들보다 더 많은 계산 자원을 사용하지 않는다.

###### Isotropic Representation Can Improve Zero-Shot Cross-Lingual Transfer on Multilingual Language Models (https://aclanthology.org/2023.findings-emnlp.545/)
- Anthology ID: 2023.findings-emnlp.545 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다국어 사전학습 언어 모델 (mPLM)의 발전과 함께 zero-shot cross-lingual transfer는 큰 가능성을 보여주고 있다. 그러나 국지적인 문맥 표현 분포로 인해 발생하는 misalignment 문제는 형태학적 차이에 의해서만 발생하는 것으로 생각되었던 것과는 달리, 우리는 이 논문에서 이러한 문제를 완화하기 위해 향상된 등방성(isotropy)과 제약 조건이 있는 코드 스위칭(constrained code-switching)을 제안한다.
    2. 우리의 방법은 이러한 등방성 표현의 misalignment 문제를 완화하고 구문 구조적인 지식을 유지하는데 도움을 주며, 강력한 mPLM 백본에 비해 상당한 성능 향상을 보인다.
    3. 세 가지 zero-shot cross-lingual transfer task에 대한 실험을 통해 우리의 방법이 강력한 mPLM 백본에 대해 혁신적인 개선을 이루었고 최고 수준의 방법들을 더욱 향상시킨다는 것을 보여준다.

###### Blackbird language matrices (BLM), a new task for rule-like generalization in neural networks: Can Large Language Models pass the test? (https://aclanthology.org/2023.findings-emnlp.546/)
- Anthology ID: 2023.findings-emnlp.546 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델의 일반화 능력을 평가하고 그들의 지능적 행동의 측면과 한계를 알아내는 방법은 무엇인가?
    2. 이 논문에서는 LLM의 문제해결 능력을 평가하기 위해 RAVEN IQ 테스트와 유사한 BLM task를 제안한다.
    3. 현재 ChatGPT와 같은 최신 생성 모델은 BLM task를 이해하고 해결하는 능력이 있으나, 전반적으로 정확한 답을 찾지 못하고 있다.

###### DistillCSE: Distilled Contrastive Learning for Sentence Embeddings (https://aclanthology.org/2023.findings-emnlp.547/)
- Anthology ID: 2023.findings-emnlp.547 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "본 논문은 지식 증류 기법과 자기 학습 패러다임 하에서 대조적 학습을 수행하는 DistillCSE 프레임워크를 제안한다."
    2. "DistillCSE의 장점은 기본 모델이 추가적인 지도 신호를 제공하여 지식 증류를 통해 더 강력한 모델을 학습할 수 있는 자가 강화 특성이다."
    3. "기존 지식 증류 방식의 구현에서는 상대적으로 큰 분산을 가진 교사 모델의 logits로 인해 문제가 발생하는데, 이 문제를 완화하기 위해 본 논문에서는 두 가지 간단하면서도 효과적인 지식 증류 솔루션을 제안한다."

###### GSAP-NER: A Novel Task, Corpus, and Baseline for Scholarly Entity Extraction Focused on Machine Learning Models and Datasets (https://aclanthology.org/2023.findings-emnlp.548/)
- Anthology ID: 2023.findings-emnlp.548 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. NER 모델은 정보 추출 및 텍스트 이해와 같은 다양한 NLP 작업에서 중요한 역할을 한다. 하지만 기존의 NER 데이터셋은 ML 모델과 모델 구조와 같은 미세한 타입을 별도의 entity 타입으로 다루지 않아 기본 모델이 이를 인식하지 못한다.
    2. 본 논문에서는 100개의 수동으로 주석이 달린 전문과 ML 모델 및 데이터셋 주변의 10개 entity 타입을 위한 첫 번째 baseline 모델을 공개한다.
    3. 우리의 데이터셋은 "our BERT-based model" 또는 "an image CNN"과 같은 비공식적인 언급뿐만 아니라 ML 모델과 데이터셋이 어떻게 언급되고 활용되는지에 대한 세부적인 이해를 제공한다.

###### Open Domain Multi-document Summarization: A Comprehensive Study of Model Brittleness under Retrieval (https://aclanthology.org/2023.findings-emnlp.549/)
- Anthology ID: 2023.findings-emnlp.549 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "다중 문서 요약(MDS)은 주제와 관련된 문서 집합을 입력으로 가정한다. 하지만 실제로 이러한 문서 집합이 항상 사용 가능한 것은 아니고, 정보 필요에 따라 검색해야 하는 경우도 있다. 이를 "open-domain MDS"라고 부르며, 이 더 어려운 상황에서의 과제를 형식화하고, 기존 데이터셋, 검색기, 요약기를 사용하여 적용한다.
    2. 우리는 다양한 자동 평가와 인간 평가를 통해, 1. 현재의 요약기들은 open-domain MDS에 적용할 때 성능이 크게 저하되는 것을 확인하였고, 2. open-domain 환경에서의 추가 학습은 불완전한 검색에 대한 민감도를 낮출 수 있다는 것을 확인하였으며, 3. 요약기는 중복 문서의 검색이나 검색 문서의 순서에는 민감하지 않지만, 관련 없는 문서의 검색과 같은 다른 오류에는 민감하다는 것을 밝혀냈다.
    3. 우리의 결과에 기반하여 open-domain MDS에 대한 미래 연구를 위한 실용적인 가이드라인을 제시하며, 예를 들어 몇 개의 검색된 문서를 선택하여 요약할지 선택하는 방법 등을 제안한다. 우리의 결과는 open-domain 환경에서의 further progress를 위해 새로운 검색과 요약 방법, 학습 및 평가를 위한 주석이 필요하다는 것을 시사한다."

###### Few-shot Unified Question Answering: Tuning Models or Prompts? (https://aclanthology.org/2023.findings-emnlp.550/)
- Anthology ID: 2023.findings-emnlp.550 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. QA 태스크는 특정한 질문 유형, 지식 도메인 또는 추론 기술을 다루기 때문에 특정한 카테고리의 QA 태스크에 대한 모델 개발이 필요하다. 
    2. 본 논문은 저자들이 모델 튜닝과 힌트(tuning, model, and prompts) 이라는 두 가지 패러다임을 제시하여 리소스가 제한된 상황에서 통합된 QA 모델을 개발한다. 
    3. 실험 결과 prompt tuning이 model tuning만큼 성능을 내며, parameter-sharing이 성능을 향상시키는 것을 확인했다. 또한, pre-training을 통한 prompt 초기화가 효과적이며, prompt tuning은 저자의 말로 보면 low-resource 상황에서 효과적이다.

###### Finding Common Ground: Annotating and Predicting Common Ground in Spoken Conversations (https://aclanthology.org/2023.findings-emnlp.551/)
- Anthology ID: 2023.findings-emnlp.551 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사람들과 의사소통할 때 우리는 단순히 단어들의 시퀀스를 생성하는 것이 아니다. 대신에 우리는 인식상태와 청자의 인식상태 모델을 사용하여 청자의 의도된 방식으로 의식상태를 좌지우지하는 어구들을 만든다.
    2. 인식상태의 중요한 부분은 공통 지식(common ground)이며, 이는 화자가 믿고, 청자도 믿고 그런식으로 계속해서 이어가는 내용이다. 
    3. 본 논문에서는 공통 지식을 파악하기 위한 새로운 어노테이션 및 말뭉치를 도입하였고, 이후 시작적인 실험을 통해 대화에서 명제를 추출하고, 각 화자의 관점에서 공통 지식의 상태를 추적하는 방법을 설명한다.

###### Getting MoRE out of Mixture of Language Model Reasoning Experts (https://aclanthology.org/2023.findings-emnlp.552/)
- Anthology ID: 2023.findings-emnlp.552 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 대형 언어 모델(Large Language Models, LLMs)은 다양한 질의응답(Question Answering, QA) 데이터셋에서 더 뛰어난 성과를 보이지만, 단일 모델로는 다양한 추론 능력을 필요로하는 질문 유형에 대해 일반화하는 것이 여전히 어렵다.
    2. 본 논문에서는 다양한 특화된 언어 모델을 앙상블하는 Mixture-of-Reasoning-Experts (MORE) 프레임워크를 제안하여 이러한 문제를 해결한다.
    3. 실험 결과, MORE은 12개의 QA 데이터셋에서 네 가지 추론 유형에서 단일 특화된 모델보다 더 높은 정확성을 보여주며, 해석 가능한 디자인은 다른 기준선과 비교하여 선별적인 질문 응답 결과를 개선한다는 것을 보여준다.

###### “You Are An Expert Linguistic Annotator”: Limits of LLMs as Analyzers of Abstract Meaning Representation (https://aclanthology.org/2023.findings-emnlp.553/)
- Anthology ID: 2023.findings-emnlp.553 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델들은 언어 사용에 있어서 놀라운 능력을 보여주지만, 실제 문장 구조에 대한 정확한 의미 분석 능력에는 제약이 있다.
    2. 이 연구에서는 GPT-3, ChatGPT, GPT-4 모델들의 Abstract Meaning Representation (AMR) 파싱 능력을 조사하였다.
    3. 모델들은 일부 핵심적인 의미 구조를 재현할 수 있지만, 자주 발생하는 오차와 fully accurate한 파싱 결과를 도출하는 능력의 제한이 여전히 존재함을 발견하였다.

###### Zero-Shot Data Maps. Efficient Dataset Cartography Without Model Training (https://aclanthology.org/2023.findings-emnlp.554/)
- Anthology ID: 2023.findings-emnlp.554 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 데이터 맵은 컴퓨터 모델이 데이터에 적합한지를 진단하는데 유용한 도구로 알려져 있다. 이 논문에서는 제로샷 모델을 사용하여 데이터 맵을 더 빠르게 생성하는 방법을 제안한다.
    2. 제로샷 모델을 사용하여 각 데이터 포인트에 대한 신뢰도와 변동성을 계산한다. 이러한 방법은 기존의 방법과 비교하여 약 14배 빠르게 데이터 맵을 생성할 수 있다.
    3. 실험 결과 제로샷 데이터 맵이 기존의 방법과 일치함을 확인하였고, 또한 코드를 공개하였다. (링크 첨부된다.)

###### Isotropy-Enhanced Conditional Masked Language Models (https://aclanthology.org/2023.findings-emnlp.555/)
- Anthology ID: 2023.findings-emnlp.555 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자동 생성 모델은 추론 과정을 가속화하기 위해 자주 사용되지만 생성 품질은 어느 정도 희생됩니다. 우리는 추론 속도를 높이고 생성 품질을 균형있게 유지하기 위해 CMLM과 Disco와 같은 반복적인 NAR 모델을 제안합니다.
    2. 우리는 반복적인 NAR 모델에서 표시되는 다른 예측 대상 토큰들의 표현이 유사하고 구별되지 않는 anisotropic 문제에 대해 더 깊이 있는 분석을 제시합니다.
    3. 우리의 연구는 대조 학습 방법의 효과를 분석하고 훈련 과정에서 토큰 표현 학습을 강화하기 위해 Look Neighbors 전략을 제안합니다. 실험 결과는 우리의 방법이 조건부 마스크 언어 모델의 성능을 일관되게 향상시키고 anisotropic 문제를 완화하는 것을 보여줍니다.

###### Scaling Law for Document Neural Machine Translation (https://aclanthology.org/2023.findings-emnlp.556/)
- Anthology ID: 2023.findings-emnlp.556 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 규모 변화 법칙이 큰 언어 모델의 발전에 중요한 역할을 한다. 이 논문에서는 문서 번역 분야에서 규모 변화 법칙을 체계적으로 조사한다.
    2. 모델 규모, 데이터 규모, 시퀀스 길이라는 세 가지 요소의 번역 품질에 미치는 영향을 깊이 분석한다.
    3. 연구 결과, 모델 규모가 제한된 경우 시퀀스 길이를 늘릴 때 모델 성능을 효과적으로 향상시킬 수 있으며, 그러나 시퀀스 길이는 무한정으로 확장될 수 없으며 모델 규모와 말뭉치 크기와 적절하게 조화를 이루어야 한다. 또한 적절한 문맥을 제공하는 것이 문서의 초기 부분의 번역 품질을 효과적으로 향상시킬 수 있는데, 그러나 뒷부분에서의 번역 품질 개선을 방해하는 주된 요인은 exposure bias이다.

###### Automatic Pronunciation Assessment - A Review (https://aclanthology.org/2023.findings-emnlp.557/)
- Anthology ID: 2023.findings-emnlp.557 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 몇 년 동안 언어 처리와 딥러닝이 급격히 성장함에 따라 발음 평가 및 컴퓨터 지원 발음 훈련엔 높은 진척이 있었다. 
    2. 이 논문에서는 음운 및 운율의 발음 평가에 사용되는 방법들을 검토하고, 주요 연구 동향에서 관찰된 주요 도전과제들을 분류하며, 기존의 한계와 사용 가능한 자원들을 강조한다.
    3. 그 후, 남아있는 도전과제들과 향후 연구 방향에 대해 논의한다.

###### Segmented Recurrent Transformer: An Efficient Sequence-to-Sequence Model (https://aclanthology.org/2023.findings-emnlp.558/)
- Anthology ID: 2023.findings-emnlp.558 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 언어 및 비전과 같은 다양한 분야에서 Transformer는 우수한 성능을 보여주었지만, sequence 길이에 따라 계산 비용이 2차적으로 증가하여 자원이 제한된 애플리케이션에는 사용하기 어렵다. 
    2. 우리의 접근 방식은 전체 sequence를 segment로 나누고 개별 segment에 attention을 적용하는 것이다.
    3. segmented attention과 가벼운 RAF neurons을 결합하여 제안된 transformer는 계산 및 메모리 비용이 낮으면서 순차적 처리 능력을 갖는 모델을 구현한다.

###### PUNR: Pre-training with User Behavior Modeling for News Recommendation (https://aclanthology.org/2023.findings-emnlp.559/)
- Anthology ID: 2023.findings-emnlp.559 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 뉴스 추천은 사용자의 행동을 기반으로 클릭 동작을 예측하는 것을 목표로 한다. 사용자 표현을 효과적으로 모델링하는 것이 선호하는 뉴스를 추천하는 핵심이다.
    2. 기존 연구들은 대부분 감독 학습 fine-tuning 단계에서의 개선에 집중되어 있다. 그러나 사용자 표현에 최적화된 PLM 기반의 비지도 사전학습 방법이 여전히 부족하다.
    3. 이 연구에서는 사용자 행동에 대한 마스킹과 생성이라는 두 가지 작업으로 구성된 비지도 사전학습 패러다임을 제안한다. 이를 통해 훨씬 강력하고 포괄적인 사용자 뉴스 패턴을 모델링할 수 있다.

###### Monte Carlo Thought Search: Large Language Model Querying for Complex Scientific Reasoning in Catalyst Design (https://aclanthology.org/2023.findings-emnlp.560/)
- Anthology ID: 2023.findings-emnlp.560 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 새로운 촉매 발견을 위해서는 여러 화학적 성질과 트레이드 오프를 포함한 복잡한 추론이 필요하며, 이는 경우의 수 증가로 이어진다. 이 논문에서는 Monte Carlo Tree Search(MCTS) 기반의 방법론을 제안하여 이러한 화학적 추론을 개선하고 화학적 변환과정에 대한 새로운 인사이트를 찾는다.
    2. 큰 언어 모델 (LLM) 을 사용하여 경계를 넘어 간단한 인자의 지시사항 추론이 가능해졌으나, LLM 을 사용한 목표지향적인 조합 탐색은 세밀하게 연구되지 않았다.
    3. MCTS 기반의 새로운 방법론을 도입하여 이전 방법보다 25.8% 성능을 향상시키고, 과학자들의 추론과 발견 과정을 혁신적인 통찰력으로 보완할 수 있는 가능성을 제시한다.

###### Measure Children’s Mindreading Ability with Machine Reading (https://aclanthology.org/2023.findings-emnlp.561/)
- Anthology ID: 2023.findings-emnlp.561 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 심리학 연구에서 기계 학습 기술의 발전으로 많은 이득을 보았다. 
    2. 이전 연구들은 아이들의 마음 읽기에 대한 자동 점수 모델을 구축할 수 있다는 것을 보여주었지만, 점수를 매기는 동안 이야기나 비디오 클립의 특징을 고려하지 않았기 때문에 정확성이 저하되었다.
    3. 우리 연구에서는 어린이의 마음 읽기 평가 중에 질문과 관련된 이야기와 비디오에서 추출한 특징을 활용하기 위해 멀티모달 학습 프레임워크를 제안한다. 실험 결과, 제안된 모델이 인간 전문가가 평가한 점수와 일치함을 보여주며, 실용적인 자동 어린이 마음 읽기 점수 시스템에 대한 잠재력을 강조한다.

###### Crosslingual Transfer Learning for Low-Resource Languages Based on Multilingual Colexification Graphs (https://aclanthology.org/2023.findings-emnlp.562/)
- Anthology ID: 2023.findings-emnlp.562 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 언어학에서, colexification은 하나의 어휘 형태가 두 개 이상의 다른 의미를 전달하는 현상을 의미한다. 이전 연구들은 주석이 달린 단어 목록에 의존하므로 확장성과 NLP에서의 유용성이 제한된다. 
    2. 이 논문에서는 주석이 달리지 않은 병렬 말뭉치에서 직접 1,335개의 언어로 2,000여 개 개념의 colexification 패턴을 식별한다. 그리고 이 colexification 패턴을 기반으로 multilingual 그래프를 구축하기 위한 두 가지 간단하고 효과적인 방법을 제안한다.
    3. 제안하는 방법을 이용하여 훈련한 고품질 multilingual 임베딩은 transfer learning에 적합하며, roundtrip 번역, 문장 검색 및 문장 분류 작업에서 여러 transfer learning 기준을 능가하는 결과를 보인다. 이는 multilingual NLP에서 colexification을 정보 출처로 사용하는 이점을 보여준다.

###### Injecting structural hints: Using language models to study inductive biases in language learning (https://aclanthology.org/2023.findings-emnlp.563/)
- Anthology ID: 2023.findings-emnlp.563 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사람들과 transformer 언어 모델은 구조적인 지도 없이 언어를 학습할 수 있다. 이 논문에서는 학습에 영향을 주는 인지적 기대에 대해 조사한다.
    2. 학습을 위해 구조적인 바이어스를 사용하여 인공 학습자의 학습에 영향을 준다. 이를 세 가지 타입의 인지적 기대로 조사한다.
    3. 연구를 통해 토큰 간의 복잡한 상호 작용이 가장 효과적인 인지적 기대라는 것을 보여준다.

###### Machine Reading Comprehension using Case-based Reasoning (https://aclanthology.org/2023.findings-emnlp.564/)
- Anthology ID: 2023.findings-emnlp.564 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기계 독해 분석에서 정답 추출을 위한 CBR(Case-Based Reasoning)을 기반으로 하는 정확하고 해석 가능한 방법을 제안한다. 
    2. CBR-MRC 방법은 유사한 질문에 대한 맥락화된 답변들이 서로 의미적으로 유사하다는 가설을 기반으로 한다. 
    3. CBR-MRC는 큰 리더 모델과 비교할 만큼 높은 정확도를 제공하며, 신뢰성이 높고 디버깅 가능한 QA 시스템 구축에 유용한 선택이 될 수 있다.

###### Unleashing the Power of Language Models in Text-Attributed Graph (https://aclanthology.org/2023.findings-emnlp.565/)
- Anthology ID: 2023.findings-emnlp.565 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 그래프 기반의 텍스트 표현 학습은 실제 문제를 해결하는 데 강력한 도구로 입증되었다. 기존의 방법들은 언어 모델이나 그래프 신경망을 활용하여 이러한 데이터에서 지식을 추출할 수 있도록 했으나, 노드나 단어들 간의 관계 활용이 부족하거나 메모리 비용이 너무 큰 문제가 있다.
    2. 이 논문에서는 텍스트와 그래프를 동시에 모델링하는 Node Representation Update Pre-training Architecture (NRUP)을 제안한다. NRUP에서는 원래 노드와 단어 노드를 모두 포함한 계층적인 텍스트-속성 그래프를 구성한다.
    3. 또한, 생성된 그래프의 다른 수준에 대해 네 가지 자기 지도 학습 작업을 적용하며, 학습 epoch 동안 노드의 특징을 업데이트하는 사전 학습 프레임워크를 설계한다. 실험 결과, 우리의 방법은 벤치마크 데이터셋에서 기준선들과 비교해서 우수한 성능을 보여주며, 그 유효성과 일반성을 증명한다.

###### Locally Differentially Private Document Generation Using Zero Shot Prompting (https://aclanthology.org/2023.findings-emnlp.566/)
- Anthology ID: 2023.findings-emnlp.566 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델로 인한 개인정보 위험에 대한 많은 연구가 있었지만, 이 연구는 사전 훈련된 대규모 언어 모델이 개인 정보 보호에 효과적으로 기여할 수 있다는 독특한 시각을 제시합니다.
    2. 우리는 DP-Prompt라는 로컬로 차이 동질적 개인 정보 보호 기법을 제안하며, 사전 훈련된 대규모 언어 모델의 성능에 기여하고 동시에 다운스트림 유용성에 미치는 영향을 최소화합니다.
    3. DP-Prompt (with ChatGPT)는 기존 방법보다 훨씬 우수한 결과를 보여주며, IMDB 데이터셋의 경우 정적 공격자에 대해 저자 식별 F1 점수를 46% 감소시키고 적응적 공격자에 대해 26% 감소시키면서 깨끗한 감성 F1 점수를 완벽하게 복구합니다.

###### Contrastive Deterministic Autoencoders For Language Modeling (https://aclanthology.org/2023.findings-emnlp.567/)
- Anthology ID: 2023.findings-emnlp.567 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Variational autoencoder (VAE) 모델의 훈련은 후단붕괴(posterior collapse) 문제 때문에 표현 퀄리티 손실이 발생하는데, 특히 텍스트에 적용할 때 이러한 문제가 발생한다. 이 논문에서는 이미지에 대해 설계된 deterministic 모델을 텍스트에 적용하는 방법을 소개한다.
    2. 이 논문에서는 양질의 언어 모델링을 위한 벤치마크인 Batch-normed VAEs (BN-VAEs)를 대체하기 위해 결정론적 모델을 사용하는 것으로 VAE 모델의 리파라미터화(reparametrization) 단계를 건너뛰고 후방 배추(collapse)를 회피하면서 텍스트 생성 및 표현과 관련된 다양한 작업에서 더 나은 성능을 보임을 보여준다.
    3. LSTM 및 Transformer 기반 VAE 아키텍처에 대해 일관된 성능 향상을 보여주며, BERT/GPT-2와의 적절한 비교를 수행한다. 또한, 모델의 양적인 면을 보완하기 위해 보간을 통해 latent space를 질적으로 검토한다.

###### CHiLL: Zero-shot Custom Interpretable Feature Extraction from Clinical Notes with Large Language Models (https://aclanthology.org/2023.findings-emnlp.568/)
- Anthology ID: 2023.findings-emnlp.568 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. CHiLL (Crafting High-Level Latents)은 선형 모델을 위한 기능의 자연어 명세를 위한 접근 방식으로, 전문가가 작성한 질의를 통해 LLMs에게 가이드를 제공하여 건강 기록에서 해석 가능한 기능을 생성한다.
    2. 생성된 노이즈 라벨은 간단한 선형 분류기를 훈련시키는 데 사용된다. LLM에게 질의를 기반으로 기능을 생성하는 것은 의사들이 다운스트림 태스크에 대해 임상적으로 의미 있는 기능을 수동으로 추출하지 않고도 도메인 전문성을 활용하여 기능을 개발할 수 있게 한다.
    3. 우리는 실제 위험 예측 태스크에 영감을 받았지만, 재현 가능한 대리 데이터인 MIMIC-III와 MIMIC-CXR 데이터를 사용하여 이 접근 방식을 평가한다. 자동으로 추출된 기능을 사용하는 선형 모델이 참조 기능을 사용하는 모델에 비해 성능이 비슷하며 "Bag-of-Words" 기능을 사용하는 모델보다 해석 가능성이 더 높다는 것을 확인한다. 또한 학습된 기능 가중치가 임상적인 예상과 일치함을 검증한다.

###### Guiding LLM to Fool Itself: Automatically Manipulating Machine Reading Comprehension Shortcut Triggers (https://aclanthology.org/2023.findings-emnlp.569/)
- Anthology ID: 2023.findings-emnlp.569 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근에 LLMs (Language Models)을 사용한 MRC(Machine Reading Comprehension) 시스템이 인상적인 결과를 보이고 있으나, 신뢰성에 대한 위협으로 spurious correlation과 관련된 shortcut 사용이 나타났다.
    2. 우리는 LLMs을 편집자로 보고, LLMs를 속이기 위해 텍스트를 수정하도록 가이드하는 프레임워크를 소개한다.
    3. 우리는 ShortcutQA라는 데이터셋을 공개하며, LLMs의 shortcut 조작에 대한 내재적 취약점을 강조한다.

###### Large Language Models Meet Harry Potter: A Dataset for Aligning Dialogue Agents with Characters (https://aclanthology.org/2023.findings-emnlp.570/)
- Anthology ID: 2023.findings-emnlp.570 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 대화형 큰 언어 모델들은 오픈 도메인 대화 에이전트를 만드는 데에 많은 잠재력을 보이고 있다. 그러나 특정 캐릭터나 인물과 대화형 에이전트를 조율하는 것은 캐릭터 표현의 복잡성과 포괄적인 주석의 부재로 인해 아직 큰 도전이다.
    2. 이 논문에서는 대화 에이전트와 캐릭터 조율의 연구를 발전시키기 위한 Harry Potter Dialogue (HPD) 데이터셋을 소개한다. HPD 데이터셋은 Harry Potter 시리즈의 영어와 중국어 대화 세션을 모두 담고 있으며, 대화 장면, 발화자, 캐릭터 관계 및 속성 등의 중요한 배경 정보로 주석이 되어 있다.
    3. 이 모델들을 특정 캐릭터와 조율하는 능력을 평가하기 위해 HPD를 사용하는 벤치마크를 수행하여 모델들의 성능을 평가하였고, 제안된 데이터셋은 캐릭터와 정렬된 응답에 더 잘 부합하는 모델을 가리키는 소중한 가이드로 작용할 수 있다는 사실을 확인하였다.

###### Quick Back-Translation for Unsupervised Machine Translation (https://aclanthology.org/2023.findings-emnlp.571/)
- Anthology ID: 2023.findings-emnlp.571 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 비지도 기계 번역에서 Transformer와 back-translation 알고리즘의 결합은 많은 발전을 이루었다. 
    2. 하지만 Transformer는 back-translation 동안 자동회귀 추론의 런타임에 어려움을 겪으며, back-translation은 합성 데이터의 효율 부족으로 제한된다.
    3. 우리는 Quick Back-translation (QBT)라는 Transformer back-translation의 성능 향상 기술을 제안한다. QBT는 인코더를 생성 모델로 재사용하고, 인코더로부터 생성된 시퀀스를 사용하여 디코더를 학습시키는 방법으로, 데이터 처리량과 활용도를 향상시킨다.

###### SIR-ABSC: Incorporating Syntax into RoBERTa-based Sentiment Analysis Models with a Special Aggregator Token (https://aclanthology.org/2023.findings-emnlp.572/)
- Anthology ID: 2023.findings-emnlp.572 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 우리는 특정 입력 토큰에 따라 원하는 출력이 달라지는 Aspect-Based Sentiment Classification (ABSC)과 같은 작업에 대해, 구문 의존성 정보를 transformer 기반 언어 모델 (예: RoBERTa)에 직접 통합하는 간단하지만 효과적인 방법을 제안합니다.
    2. 우리의 모델인 SIR-ABSC (Syntax-Integrated RoBERTa for ABSC)는 이전의 ABSC 접근 방식과는 다르게 의존성 트리 상의 언어 모델과 그래프 신경망을 결합하여 구문을 포착하는 대신, 새로운 어그리게이터 토큰을 사용하여 구문을 언어 모델에 직접 통합합니다.
    3. 그 결과, SIR-ABSC는 이러한 더 복잡한 모델들보다 우수한 성능을 보여주며, ABSC에서 새로운 state-of-the-art 결과를 얻을 수 있습니다.

###### Citance-Contextualized Summarization of Scientific Papers (https://aclanthology.org/2023.findings-emnlp.573/)
- Anthology ID: 2023.findings-emnlp.573 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 과학논문의 요약은 원문과 해당 원문에 인용된 참고자료간의 관계를 나타내지 못하는 현재의 접근 방식으로 이루어진다. 
    2. 우리는 "citance"라고 불리는 참고문의 인용문이 존재하는 문장을 기반으로 정보를 포함한 요약을 생성할 수 있는 문맥화 요약 방법을 제안한다. 
    3. 따라서 우리는 논문의 citances을 추출하고 모델링하며, 인용된 논문에서 관련된 부분을 검색한 후 각각의 citance에 적합한 필사적 요약을 생성하는 방법을 제안한다.

###### SegAugment: Maximizing the Utility of Speech Translation Data with Segmentation-based Augmentations (https://aclanthology.org/2023.findings-emnlp.574/)
- Anthology ID: 2023.findings-emnlp.574 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 말-번역 end-to-end 시스템은 데이터 부족으로 인해 제약을 겪었다. 이 논문은 문장 수준의 다이나믹한 데이터를 생성하고자, SegAugment라는 새로운 데이터 증강 전략을 제안하였다.
    2. SegAugment는 각 문서의 음성을 다른 길이 제한으로 재분할하여 대상 텍스트를 얻는 방식을 사용한다. 실험 결과, MuST-C 데이터셋의 여덟 개 언어 쌍에서 2.5 BLEU 점의 평균 증가 및 mTEDx의 저자원 시나리오에서 최대 5 BLEU 점의 증가를 보였다.
    3. 또한, 강력한 시스템과 결합하면 MuST-C에서 state-of-the-art 결과를 얻을 수 있었고, 제안된 방법은 문장 수준 데이터도 성공적으로 증강시킬 수 있으며, 추론 시점에서 수동 및 자동 분할 사이의 차이를 줄일 수 있었다.

###### Intersectional Stereotypes in Large Language Models: Dataset and Analysis (https://aclanthology.org/2023.findings-emnlp.575/)
- Anthology ID: 2023.findings-emnlp.575 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델(LLM) 내 교차된 인구 그룹을 대상으로 한 편견에 대한 선행 연구들은 주로 개인적인 범주에 중점을 두고 있으며, 이를 보완하기 위해 이 연구는 ChatGPT 모델과 수동으로 검증한 교차된 편견 데이터셋을 소개한다.
    2. 또한, 이 논문은 이 데이터셋을 활용하여 세 가지 최신 LLM에서 교차된 편견 전파를 종합적으로 분석한다. 
    3. 연구 결과는 LLM에서 편견의 확산을 줄이기 위한 지속적인 노력에서 교차된 편견에 중점을 두는 것의 긴요성을 강조한다.

###### Dataset Bias Mitigation in Multiple-Choice Visual Question Answering and Beyond (https://aclanthology.org/2023.findings-emnlp.576/)
- Anthology ID: 2023.findings-emnlp.576 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Vision-language (VL) understanding tasks에서 모델들은 올바른 이해 없이도 다양한 VL 태스크를 올바르게 해결하기 위해 dataset bias를 활용할 수 있다. 이 논문에서는 dataset biases를 해결하기 위해 Adversarial Data Synthesis (ADS)와 Intra-sample Counterfactual Training (ICT)를 제안한다.
    2. ADS는 합성 훈련 데이터와 합성 평가 데이터를 생성하는 것이다. ICT는 특히 counterfactual 데이터를 집중하여 모델이 합성 훈련 데이터를 활용하도록 돕는 것이다.
    3. 실험 결과, ADS와 ICT는 서로 다른 벤치마크에서 모델의 성능을 일관되게 향상시키는데 효과적이었다. 또한 도메인이 다른 경우에도 성능 향상이 있었다.

###### The Intended Uses of Automated Fact-Checking Artefacts: Why, How and Who (https://aclanthology.org/2023.findings-emnlp.577/)
- Anthology ID: 2023.findings-emnlp.577 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자동 사실 확인은 잘못된 정보를 대항하는 교정자, 소셜 미디어 사용자 및 기타 이해 관계자가 사용할 수 있는 인식 도구로 제시된다. 그럼에도 불구하고, 이와 관련된 논문들은 필요한 방법, 목표 및 이해 관계자에 대해 충분히 논의하지 않고 있다. 
    2. 이 논문은 서술된 사실 확인 기술의 목표와 수단 사이에 일관성이 없거나 현실성이 부족하며, 이에 대한 비판과 이해 관계자의 피드백이 제한되어 있다는 문제점에 대해 분석하여 문제를 제기한다.
    3. 따라서, 사실 확인 자산의 사용에 대해 생각하고 쓰기 위해 몇 가지 권고사항을 제시한다.

###### Retrieval-based Knowledge Transfer: An Effective Approach for Extreme Large Language Model Compression (https://aclanthology.org/2023.findings-emnlp.578/)
- Anthology ID: 2023.findings-emnlp.578 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 사전 훈련된 언어모델(Large-scale pre-trained language models)은 다양한 자연어 처리(NLP) 태스크에서 탁월한 성능을 보여주었으나, 모델의 대규모 크기는 실제 응용에서 배치하는 것에 엄청난 도전을 제기한다.
    2. 우리는 극도의 모델 압축을 위해 LLM의 지식을 극소 규모 모델에 전달하는 새로운 압축 패러다임인 Retrieval-based Knowledge Transfer (RetriKT)을 소개한다.
    3. 우리의 접근 방식은 LLM에서 지식을 추출하여 지식 저장소를 구축하고, 극소 규모 모델이 관련 정보를 검색하고 효과적인 추론을 위해 그것을 활용하도록 한다.

###### COUNT: COntrastive UNlikelihood Text Style Transfer for Text Detoxification (https://aclanthology.org/2023.findings-emnlp.579/)
- Anthology ID: 2023.findings-emnlp.579 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 소셜 미디어 플랫폼에서의 혐오 및 독성 텍스트는 온라인 커뮤니티 내의 극단화와 분열을 야기시키고 건설적인 대화를 방해하는 요소이다. 이 논문에서는 텍스트 톡스화 (text detoxification)를 통해 안전하고 비-독성적인 텍스트를 생성하는 방법을 소개한다.
    2. 기존의 방법들은 supervised training에서 encoder-decoder 모델을 사용하여 표준 likelihood-based objective를 가진 골드 표준 출력을 생성하지만, 이러한 모델들은 사전에 학습된 auto-encoder identity mapping에서 벗어나기 어려워 한다.
    3. 이 논문에서는 새로운 contrastive unlikelihood objective (COUNT)를 소개하여 톡스적인 스타일 전이에 초점을 맞춰 톡식이 아닌 스타일 전이 학습에 집중하도록 한다. COUNT를 ParaDetox와 APPDIA 두 가지 데이터셋에서 벤치마킹한 결과, 순조로운 플루언시, 콘텐츠 보존, 그리고 톡스화 (highest "J" score)에서 상당한 개선을 보였다.

###### KICGPT: Large Language Model with Knowledge in Context for Knowledge Graph Completion (https://aclanthology.org/2023.findings-emnlp.580/)
- Anthology ID: 2023.findings-emnlp.580 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 지식 그래프 완성(KGC)은 지식 그래프의 불완전함을 해결하고 하위 응용 프로그램을 지원하는 데 중요하다. KGC는 triple-based와 test-based 방법으로 분류될 수 있는데, 이 중 triple-based 방법은 제한된 구조적 정보와 개체들의 불균형한 분포로 인해 long-tail 개체들에 대해 어려움을 겪는다. 이 논문에서는 훈련 오버헤드를 증가시키지 않으면서 long-tail 문제를 완화하기 위해 대규모 언어 모델과 triple-based KGC 검색기를 통합하는 KICGPT 프레임워크를 제안한다. 
    2. KICGPT 모델에서는 지식의 구조적 지식을 LLM에 안내하기 위해 Knowledge Prompt라는 in-context 학습 전략을 제안한다. 
    3. 벤치마크 데이터셋에서의 실험 결과는 KICGPT 모델이 더 가볍고 훈련 오버헤드 없이 더 효과적임을 보여준다.

###### Show, Write, and Retrieve: Entity-aware Article Generation and Retrieval (https://aclanthology.org/2023.findings-emnlp.581/)
- Anthology ID: 2023.findings-emnlp.581 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기사 이해는 자연어 처리에서 중요한 도전 과제로, 기사 생성이나 이미지-기사 검색 등 다양한 응용분야에 사용된다. 기존 연구는 사전학습 언어 모델을 사용하여 기사의 모든 토큰을 균일하게 인코딩했으나, 실제 기사는 실제 세계의 사건에 기반하고, 정확한 NER(Named Entity Recognition)가 어려운 많은 네임드 엔티티(Named Entities)를 참조할 수 있다.
    2. 본 논문에서는 ENGINE 프레임워크를 제안하여 네임드 엔티티를 언어 모델에 명시적으로 포함시키는 방법을 제시한다. 이 방법은 네임드 엔티티 추출 모듈과 모델의 엔티티 인식 및 예측 기능을 향상시킬 수 있는 엔티티 인식 기능을 포함한다.
    3. 실험 결과, ENGINE 모델은 GoodNews, VisualNews, WikiText와 같은 세 가지 공개 데이터셋에서 기사 생성 및 기사 검색 성능을 향상시킬 수 있으며, 기사 생성에서는 perplexity가 4-5 개 향상되었고, 기사 검색에서는 recall@1이 3-4% 향상되었다.

###### A Language Model with Limited Memory Capacity Captures Interference in Human Sentence Processing (https://aclanthology.org/2023.findings-emnlp.582/)
- Anthology ID: 2023.findings-emnlp.582 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사람들의 문장 처리 난이도에 영향을 미치는 두 가지 주된 요소는 기대치와 작업 메모리에서의 검색이다.
    2. 기존의 unified 모델들은 Transformer 언어 모델의 self-attention 메커니즘과 인간의 문장 처리에서의 cue-based retrieval 이론 사이의 유사점에 기반하여 작성되었으나, 이들은 구문에 특화된 attention head를 식별하는 것을 요구하고 수백 개의 메모리 검색이 병렬적으로 이루어진다는 인지적으로 불가능한 암묵적 가정을 사용한다.
    3. 본 논문에서는 인지 이론에서 가정되는 메모리 시스템과 더 가까운 단일 self-attention head를 가진 반복 신경 언어 모델을 개발하여, 우리의 모델의 단일 attention head가 인간의 실험에서 관찰되는 의미론적 및 구문론적 중간 개입 효과를 포착할 수 있다는 것을 보여준다.

###### Annotations Are Not All You Need: A Cross-modal Knowledge Transfer Network for Unsupervised Temporal Sentence Grounding (https://aclanthology.org/2023.findings-emnlp.583/)
- Anthology ID: 2023.findings-emnlp.583 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. TSG (Temporal Sentence Grounding)의 문제를 다루는 이 논문은 필수적인 작업에서 상당한 성과를 거두었지만, 실제 응용 프로그램에서는 상당한 인력이 필요한 비디오-쿼리 짝 지은 주석에 심하게 의존한다.
    2. 이를 위해 저자는 데이터가 부족한 상황에서 cross-modal task에서 얻은 지식을 이용하여 실제 시나리오에 적용하여, video-frame에 적용된다. 
    3. 실험 결과, 이러한 방법을 통해 unsupervised task에서도 supervised 작업보다 좋은 성과를 내는 것을 확인하였다.

###### Parameter Efficient Multi-task Fine-tuning by Learning to Transfer Token-wise Prompts (https://aclanthology.org/2023.findings-emnlp.584/)
- Anthology ID: 2023.findings-emnlp.584 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 작은 trainable 파라미터를 사용하여 pre-trained language model (PLM)을 고정시키면서 prompt tuning을 이용한 다양한 작업에서 성공적인 결과를 얻었지만, 각 개별 예제에 대해 더 적합한 prompt를 생성하는 방법과 cross-task feature를 활용하여 multi-task learning 시나리오에 prompt tuning을 확장하는 방법은 아직 논의되지 않았다.
    2. 이 논문에서는 token-wise prompt tuning (TPT)를 제안하여 메모리 네트워크를 사용하여 multi-task learning을 위한 더 세분화된 soft prompt tokens을 구축한다. 이 토큰들은 입력 예제와 대조되는 방식으로 bank에서 검색되어 인스턴스별 prompt로 조합된다.
    3. 14개의 데이터셋에 대한 실험 결과는 TPT로 향상된 모델이 전체 파라미터로 fine-tuning된 모델보다 훨씬 좋은 성능을 발휘하며, 0.035%의 파라미터만 조정하여 최고 수준의 결과를 달성했다.

###### A Rewriting Approach for Gender Inclusivity in Portuguese (https://aclanthology.org/2023.findings-emnlp.585/)
- Anthology ID: 2023.findings-emnlp.585 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근에는 성별 포함 및 성별 중립 언어를 자연 언어 처리 모델에 통합하는 연구에 대한 관심이 높아졌다. 그 중 일반성 중립적인 문장을 성별 언어로 변경하는 gender-neutral rewriting이 주목을 받았는데, 이는 작은 자원을 가진 언어(예: 포르투갈어)에는 대용량 데이터셋을 사용하기 어렵다는 한계가 있다. 
    2. 이 논문에서는 법칙 기반과 신경 기반 모델을 사용하여 포르투갈어에 대한 gender-neutral rewriting을 수행하는 툴을 제안한다. 신경 기반 접근 방식은 법칙 기반 모델이 생성한 예제를 사용하여 대규모 다국어 기계 번역 모델을 fine-tuning하는 것에 기반한다. 
    3. 다양한 소스와 맥락의 텍스트를 기반으로 두 모델을 평가하였으며, future work의 평가를 위해 성별 중립 언어와 새로운 대명사를 명시적으로 포함한 포르투갈어 데이터셋과 500개의 문장에 대한 수동으로 주석이 달린 골든 콜렉션을 제공한다.

###### EARA: Improving Biomedical Semantic Textual Similarity with Entity-Aligned Attention and Retrieval Augmentation (https://aclanthology.org/2023.findings-emnlp.586/)
- Anthology ID: 2023.findings-emnlp.586 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 생물의학 텍스트 처리에서 의미론적 텍스트 유사성을 측정하는 것은 기본적인 작업이지만, 생물의학 분야의 STS 데이터셋은 일반적인 분야에 비해 상대적으로 작지만 의미론적으로 더 복잡하여 overfitting 문제와 잘 정의된 텍스트 표현이 어렵다. 
    2. 본 논문에서 이러한 문제를 해결하기 위해 entity-aligned, attention-based, retrieval-augmented PLMs라는 제안을 하였다. 
    3. 실험 결과 EARA는 도메인 내 및 도메인 외 데이터셋에서 최고의 성능을 보여주며, 소스 코드도 제공된다.

###### Neuro-Symbolic Sentiment Analysis with Dynamic Word Sense Disambiguation (https://aclanthology.org/2023.findings-emnlp.587/)
- Anthology ID: 2023.findings-emnlp.587 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 감성 분석은 단어의 의미 이해에 크게 의존하는 태스크이다. 기존의 신경망 모델은 인간에게 해석하기 어려운 벡터로 단어의 의미를 표현한다.
    2. 이 논문은 WSD (Word Sense Disambiguation) 시스템을 적용하는 데에 어려움이 있는데, 그 중에서도 i) 어떤 단어들을 disambiguate해야 하는지와 ii) downstream 모델에 명확하게 이해가능한 단어 의미를 어떻게 모델링할지에 대한 문제를 해결한다.
    3. Neurosymbolic 프레임워크를 제안하여 모호한 단어를 식별하고 어떤 의미론적으로 명확한 단어로 paraphrase함으로써 감성 예측의 정확성을 향상시키는 것을 목표로 한다. 이 프레임워크를 사용하면 어떤 단어가 어떤 의미론적으로 명확한 단어로 paraphrase되었는지 이해할 수 있다.

###### Role of Context in Unsupervised Sentence Representation Learning: the Case of Dialog Act Modeling (https://aclanthology.org/2023.findings-emnlp.588/)
- Anthology ID: 2023.findings-emnlp.588 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 단어 형태와 단어 의미는 크게 연결되어 있지 않다는 관찰에 근거하여, 단어 표현의 비지도학습은 단어 발생 주변의 문맥 정보를 포착하는 작업을 수반한다.
    2. 그러나 문장에서도 동일한 패턴이 유효할지는 의문이다. 이 논문에서는 문장 표현 추론에서 문맥의 역할을 무시하지 않고 고려한 대화 행위 태그 프로빙 태스크를 제안한다.
    3. 결과는 문맥 기반의 문장 표현이 콘텐츠 기반의 문장 표현보다 명확한 이점이 없으나, 거의 모든 접근 방식에서 문장 벡터의 차원을 증가시키는 것이 매우 명확한 이점을 가진다는 것을 보여준다.

###### CLMSM: A Multi-Task Learning Framework for Pre-training on Procedural Text (https://aclanthology.org/2023.findings-emnlp.589/)
- Anthology ID: 2023.findings-emnlp.589 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문에서는 절차적 레시피에서 학습하는 도메인 특화 인공지능 모델인 ***CLMSM***을 제안한다. 이 모델은 Multi-Task Learning Framework를 사용하여 레시피의 개체 간 미묘한 차이를 학습하는 Contrastive Learning과 절차의 단계별 문맥을 학습하는 새로운 Mask-Step Modelling 목적을 최적화한다.
    2. 우리는 ***CLMSM***을 세 가지 데이터셋에서 개체 추적 및 절차 간 작업 조정과 같은 여러 후속 태스크에서 성능을 테스트하였는데, 그 중 하나는 사전 학습 데이터셋과 맞지 않는 open-domain 데이터셋이었다. 
    3. 우리는 ***CLMSM***이 레시피 (in-domain)에서 베이스라인을 능가할 뿐만 아니라 open-domain 절차적 NLP 태스크에도 일반화할 수 있는 능력을 보여준다.

###### Open-source Large Language Models are Strong Zero-shot Query Likelihood Models for Document Ranking (https://aclanthology.org/2023.findings-emnlp.590/)
- Anthology ID: 2023.findings-emnlp.590 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 정보 검색 분야에서 Query Likelihood Models (QLMs)은 문서의 내용에 대한 쿼리 생성 확률을 기반으로 문서 순위를 매긴다. 
    2. 최근에는 미세 조정이 없이 구조화되지 않은 텍스트 데이터에만 사전 훈련된 LLMs이 QLMs로서 유망한 순위 매기기 능력을 보여준다.
    3. 그러나, 추가적인 지시어 미세 조정이 존재하지 않는 한 그런 LLMs의 순위 매기기 효과는 방해받을 수 있음을 밝힌다.

###### On General Language Understanding (https://aclanthology.org/2023.findings-emnlp.591/)
- Anthology ID: 2023.findings-emnlp.591 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "자연어 처리는 경험 중심적이며, 의미와 측정에 관한 본질적인 논쟁에 빠지고 있다."
    2. "이 논문에서는 현재 모델 품질의 측정 방법의 적절성을 물을 수 있는 이해 모델의 개요를 제시한다."
    3. "언어 이해는 다양한 현상으로 구성되며, 이해 지표의 선택이 벤치마킹의 한계를 표시하고 NLP 사용의 윤리를 고려하는 시작이 된다."

###### USB: A Unified Summarization Benchmark Across Tasks and Domains (https://aclanthology.org/2023.findings-emnlp.592/)
- Anthology ID: 2023.findings-emnlp.592 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. NLP 커뮤니티에서는 요약 벤치마크를 많이 만들었지만, 제어와 신뢰성과 관련된 여러 문제를 동시에 해결하기 위해 필요한 풍부한 주석을 제공하는 것은 없다. 
    2. 저자들은 위키피디아에서 파생된 벤치마크를 소개하고, 크라우드소싱된 풍부한 주석을 추가하여 8가지 관련된 작업을 지원한다.
    3. 이 논문에서는 이 벤치마크에서 다양한 방법을 비교하고, 보통 큰 규모의 퓨샷 모델보다 중간 규모의 파인튜닝 모델이 여러 작업에서 일관되게 우월한 성능을 내는 것을 발견한다.

###### tagE: Enabling an Embodied Agent to Understand Human Instructions (https://aclanthology.org/2023.findings-emnlp.593/)
- Anthology ID: 2023.findings-emnlp.593 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 지능적 에이전트가 인간과 상호작용할 때 자연어가 주요한 의사소통 방식으로 사용되는데, 이에 대한 연구는 NLU(natural language understanding)과 관련하여 감정 분석, 의도 예측, 질문 응답, 요약 등으로 집중되어 있다. 
    2. 그러나 몸을 가진 에이전트가 필요로 하는 상황에서 NLU에 초점을 맞춘 연구는 아직 한정적이다. 이 논문에서는 복잡한 작업 지시문에서 일련의 작업을 추출하는 진보적인 신경망 모델을 제안한다. 
    3. 제안된 모델은 인코더-디코더 프레임워크와 중첩 디코딩을 결합하여 복잡한 지시문에서 작업과 해당 인수를 효과적으로 추출한다. 실험 결과는 제안한 방법이 강력한 기준 모델보다 우수함을 보여준다.

###### Instances and Labels: Hierarchy-aware Joint Supervised Contrastive Learning for Hierarchical Multi-Label Text Classification (https://aclanthology.org/2023.findings-emnlp.594/)
- Anthology ID: 2023.findings-emnlp.594 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Hierarchical multi-label text classification (HMTC)은 계층구조를 활용하여 다중 라벨 분류를 수행한다. 
    2. 기존 방법들은 샘플 생성을 위해 대조 학습을 사용하지만 같은 배치 내의 유사한 샘플들 사이의 상관관계를 무시하여 노이즈를 도입하는 경향이 있다. 
    3. 이 논문에서는 supervised contrastive learning과 HMTC 간의 간극을 메우기 위해 HJCL( Hierarchy-aware Joint Supervised Contrastive Learning) 방법을 제안하고 효과를 입증하였다.

###### Uncovering Limitations in Text-to-Image Generation: A Contrastive Approach with Structured Semantic Alignment (https://aclanthology.org/2023.findings-emnlp.595/)
- Anthology ID: 2023.findings-emnlp.595 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 텍스트에서 이미지를 생성하는 모델들은 복잡하거나 상세한 이미지를 생성하는 데에 여전히 어려움을 겪고 있다. 
    2. 우리는 텍스트-이미지 생성 모델의 성능을 평가하기 위해 구조적 의미 일치 (SSA) 방법을 제안한다. 
    3. SSA는 구조적 의미 임베딩을 학습하고 다양한 모달리티에서 일치시키는데 초점을 맞추며, 이를 통해 텍스트-이미지 세대 모델의 의미 일관성을 향상시킨다.

###### An Intent-based and Annotation-free Method for Duplicate Question Detection in CQA Forums (https://aclanthology.org/2023.findings-emnlp.596/)
- Anthology ID: 2023.findings-emnlp.596 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델 (LLM)의 등장으로 Community Question Answering (CQA) 포럼은 교육 튜닝의 용도로 활용 가능한 훌륭한 질문과 답변을 제공하며, 이에 대한 instruction tuning을 위해 LLM을 학습하는 데 효과적으로 사용할 수 있다. 
    2. 그러나 CQA의 콘텐츠 양이 계속해서 증가함에 따라 중복 질문의 문제가 발생하며, 이로 인해 콘텐츠의 품질에 위협이 될 수 있다. 
    3. 이 논문에서는 Intent-DQD라는 새로운 의도 기반 중복 탐지기를 제안하여 CQA에서 중복 질문을 탐지하는 문제를 해결한다. Intent-DQD는 CQA 포럼의 특성을 활용하고, 질문의 의도를 인식하고 매칭하기 위해 훈련 레이블을 추출한다. Intent-DQD는 의도 수준 관계를 효과적으로 종합하고 질문 수준의 관계를 구축하여 의도 인식 중복 탐지를 가능하게 한다.

###### Accelerating Multiple Intent Detection and Slot Filling via Targeted Knowledge Distillation (https://aclanthology.org/2023.findings-emnlp.597/)
- Anthology ID: 2023.findings-emnlp.597 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 비자기회귀(Spoken Language Understanding) 모델들은 추론 속도가 빠르기 때문에 주목을 받고 있지만, 대부분의 기존 방법은 추론 중 참조에 대한 사전 지식이 거의 없기 때문에 다중 모달성(multi-modality) 문제가 발생한다.
    2. 복잡한 프레임워크가 한계로 인해 희망하는 추론 속도를 달성하지 못하는 문제가 있다.
    3. 따라서 저자들은 지식 증류(knowledge distillation) 방법을 활용하여 다중 의도(Multi-intent) SLU를 위한 목표 지식 증류 프레임워크(TKDF)를 제안한다. 이 방법은 선생 모델로부터 지식을 전달하여 학습 속도를 높이고 성능을 개선한다.

###### Type-Aware Decomposed Framework for Few-Shot Named Entity Recognition (https://aclanthology.org/2023.findings-emnlp.598/)
- Anthology ID: 2023.findings-emnlp.598 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 몇몇 two-stage prototypical network 기반 few-shot named entity recognition (NER) 작업의 성공에도 불구하고, span detection 단계에서의 false spans와 type classification 단계에서의 부정확하고 불안정한 prototypes 문제는 여전히 도전적인 문제로 남아있다.
    2. 이 논문에서는 이러한 문제를 해결하기 위해 Type-Aware Decomposed framework인 TadNER를 제안한다. 세가지 성분으로 이루어진 이 프레임워크는, type-aware span filtering 전략과 type-aware contrastive learning 전략을 도입하여 문제를 해결한다.
    3. 다양한 벤치마크 실험을 통해 제안된 TadNER 프레임워크가 새로운 state-of-the-art 성능을 얻는 것을 입증하였다.

###### A Closer Look into Using Large Language Models for Automatic Evaluation (https://aclanthology.org/2023.findings-emnlp.599/)
- Anthology ID: 2023.findings-emnlp.599 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근에서는 큰 언어 모델 (Large Language Models, LLMs)을 텍스트 품질 평가에 사용하는 것이 인기를 끌고 있다.
    2. 이 논문에서는 *LLM 평가*와 *G-Eval*에 대해 분석하고, 평가 과정의 세부 사항이 얼마나 잘 LLM의 평가와 인간의 평가 점수가 일치하게 하는지에 대해 논의한다.
    3. 우리는 G-Eval에서 사용된 자동 Chain-of-Thought (CoT)이 항상 인간의 점수와 일치하게 만들지 못한다는 사실을 발견했다. 또한, G-Eval과 같이 LLM이 숫자 평가만 출력하도록 강제하는 것은 최적화되지 않는다는 것을 보여준다. 마지막으로, LLM에게 자신의 평가를 설명하도록 요청하면 ChatGPT와 인간의 평가 사이의 상관 관계를 일정하게 향상시키고, 두 메타 평가 데이터셋에서 최신 기술 (SoTA) 상관 관계도 향상시킨다.

###### Connecting the Dots: What Graph-Based Text Representations Work Best for Text Classification using Graph Neural Networks? (https://aclanthology.org/2023.findings-emnlp.600/)
- Anthology ID: 2023.findings-emnlp.600 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 구조 정보를 고려한 기계 학습인 GNN의 성공에도 불구하고, 많은 연구들은 특정 도메인에 대해서만 텍스트 분류에 GNN을 사용하였으며, 데이터의 특성에 제한이 있다. 
    2. 이 연구는 다양한 GNN 아키텍처와 설정을 사용하여 다섯 가지 데이터셋에서 다양한 그래프 구성 방법을 비교하고, 각각의 장단점과 개방적인 도전 과제를 밝힌다. 
    3. 실험 결과, 텍스트 입력 특징과 도메인에 따라 그래프의 효과가 다르며, 간단한 그래프 구성 방법이 문서가 길수록 더 좋은 성능을 보여주고, 긴 문서에 대해서는 Transformer-based 모델보다 그래프 표현 방법이 효과적이며, 텍스트 분류 작업에 그래프 기법이 특히 효율적이다.

###### Natural Language Annotations for Reasoning about Program Semantics (https://aclanthology.org/2023.findings-emnlp.601/)
- Anthology ID: 2023.findings-emnlp.601 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 연구자들은 프로그래밍 조수를 만들기 위해 자연어 추론을 코드와 결합하고, 코드에서 추론을 도출하여 그들의 작업을 설명하고, 교육 가능한 프로그래밍 조수를 만들고, 그들의 추론에 있는 틈새를 찾으려고 한다.
    2. 우리는 정적 분석 없이 구문과 일반적인 주석만으로 프로그램의 흥미로운 속성을 자동으로 추론할 수 있을까? 프로그램의 논리와 행동은 얼마나 많이 자연어로 표현될 수 있을까?
    3. 이 논문에서는 이러한 질문에 대답하기 위해 HTL 데이터셋과 프로토콜을 제안한다. 이 데이터셋은 코드 주석에 의존하지 않고, 내부 컴파일러 표현을 사용하지 않고, 코드에 자연어 술어를 더 세분화된 수준으로 주석으로 추가하는 것이 가능하도록 구성되어 있다.

###### Pre-trained Speech Processing Models Contain Human-Like Biases that Propagate to Speech Emotion Recognition (https://aclanthology.org/2023.findings-emnlp.602/)
- Anthology ID: 2023.findings-emnlp.602 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 성별, 인종 등과 같은 인간의 편견에 모델이 영향을 받는 것은 알려져 왔으나, 어떻게 이러한 편견이 생기는지는 아직 파악되지 않았다. 
    2. 이 논문에서는 사전 훈련된 모델에서 편견을 감지하기 위한 메소드인 SpEAT를 제안하고, 이를 사용하여 다양한 영어 음성 모델에서 여섯 가지 유형의 편견을 확인하였다.
    3. 사전 훈련된 음성 모델에서 발견된 편견은 실제 세계에서도 영향을 미칠 수 있으며, SER 작업에 적용된 모델에서도 이러한 편견이 전파될 수 있다는 것을 보여주었다.

###### Text Classification via Large Language Models (https://aclanthology.org/2023.findings-emnlp.603/)
- Anthology ID: 2023.findings-emnlp.603 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. GPT-3와 같은 대규모 언어 모델은 텍스트 분류 작업에서 성능이 좋지 않은데, 이는 복잡한 언어 현상에 대한 추론 능력의 부족과 in-context learning에서 허용되는 토큰 수의 제한 때문이다.
    2. 이 논문에서는 Clue And Reasoning Prompting(CARP)을 소개하는데, 이는 텍스트 분류에서 복잡한 언어 현상에 대응하기 위해 고안된 점진적 추론 전략을 사용한다. CARP은 LLM에게 표면적인 단서를 찾도록 유도하고, 이를 기반으로 최종 결정을 위한 진단 추론 과정을 수행한다. 또한, 제한된 토큰 문제를 해결하기 위해 CARP은 in-context learning에서 kNN demonstration search를 사용한다.
    3. CARP은 4개의 텍스트 분류 벤치마크에서 새로운 SOTA 성능을 보여주며, 저자들은 CARP가 낮은 자원과 도메인 적응에서 인상적인 능력을 발휘한다고 밝혔다. 또한, CARP는 클래스당 16개의 예제를 사용하여 1,024개의 예제를 사용한 지도 학습 모델과 비슷한 성능을 달성한다.

###### On Task-personalized Multimodal Few-shot Learning for Visually-rich Document Entity Retrieval (https://aclanthology.org/2023.findings-emnlp.604/)
- Anthology ID: 2023.findings-emnlp.604 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 비주얼리 리치한 문서 엔티티 검색(VDER)은 송장과 영수증과 같은 문서 이미지에서 주요 정보(예: 날짜, 주소)를 추출하는 것이 중요한 산업용 NLP 응용 프로그램이 되었다. 그러나 새로운 문서 유형이 지속적으로 등장하면서 각각 고유한 엔티티 유형을 포함하기 때문에 다양한 도전 과제가 발생한다. 
    2. 이 연구에서는 새로운 개체 수준의 퓨 샷 VDER 작업을 연구하는데, 이는 각 작업별로 고유한 레이블 공간과 OOD 콘텐츠의 복잡성이 증가하는 독특한 시나리오에서 이루어진다. 
    3. 실험 결과, 우리의 접근 방식은 인기있는 메타 학습 베이스 라인의 견고성을 크게 향상시킴을 보여준다.

###### Semi-Structured Object Sequence Encoders (https://aclanthology.org/2023.findings-emnlp.605/)
- Anthology ID: 2023.findings-emnlp.605 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문에서는 반정형 객체 시퀀스 모델링에 대한 과제를 탐구하며, 특히 이러한 시퀀스에 대한 구조를 고려한 입력 표현 개발에 초점을 맞춘다.
    2. 기존 방법들과 비교하여 우리의 접근법은 hierarchical encoding과 record-centric 표현, flattened 표현을 포함한 다른 방법들을 능가하며, 실제 데이터를 사용한 여러 예측 과제에서 우수한 성능을 보여준다.
    3. 특히, two-part 접근법과 shared-attention-head 아키텍처 및 독특한 훈련 스케줄을 제안하여 기존 방법보다 더 긴 객체 시퀀스에 대해 처리할 수 있다.

###### DeTiME: Diffusion-Enhanced Topic Modeling using Encoder-decoder based LLM (https://aclanthology.org/2023.findings-emnlp.606/)
- Anthology ID: 2023.findings-emnlp.606 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자연어 처리 분야에서 Neural Topic Models (NTMs)와 Large Language Models (LLMs)는 중요한 연구 관심을 받는 분야로 등장하였다. 그러나 NTMs는 주로 LLMs에서 가져온 문맥 임베딩을 사용하는데, 이는 클러스터링에 최적화되지 않거나 토픽 생성에 용이하지 않다.
    2. 본 연구는 Diffusion-Enhanced Topic Modeling using Encoder-Decoder-based LLMs (DeTiME)라는 새로운 프레임워크를 도입하여 이러한 공백을 해결한다. DeTiME은 Encoder-Decoder 기반 LLMs를 활용하여 클러스터링 가능한 임베딩을 생성하고, 기존 방법과 비교하여 우수한 클러스터링 능력과 향상된 의미적 일관성을 가지는 토픽을 생성할 수 있다.
    3. 또한, 확산의 힘을 이용함으로써 DeTiME은 식별된 토픽과 관련 콘텐츠를 생성할 수 있는 능력을 제공한다. 이 중복 기능을 통해 사용자는 효율적으로 고도로 군집화된 토픽과 관련 콘텐츠를 동시에 생성할 수 있다. DeTiME은 임베딩을 생성하는 데에도 적합하며, 학습이 효율적이고 높은 적응성을 가지며 다양한 응용 분야에 잠재력을 보여준다.

###### Energy and Carbon Considerations of Fine-Tuning BERT (https://aclanthology.org/2023.findings-emnlp.607/)
- Anthology ID: 2023.findings-emnlp.607 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. NLP 연구에서 널리 사용되는 미세 조정 (fine-tuning) 접근 방식의 에너지 비용과 탄소 배출량을 정량화하는 작업이 선행되어왔으나, 이 작업은 주로 언어 모델에 집중되어 왔다.
    2. 하나의 사전 훈련 (pre-training) 단계가 낮은 훈련 단계보다 훨씬 더 많은 에너지를 소모하지만, 미세 조정은 더 자주 수행되며 많은 수의 개별 작업자에 의해 수행되므로 NLP의 에너지와 탄소 발자국을 고려할 때 반드시 고려해야 한다.
    3. 본 논문에서는 작업, 데이터셋, 하드웨어 인프라 및 측정 모드에서 미세 조정의 계산 비용에 대한 신중한 실험적 연구를 수행하고, 사전 훈련 및 추론과 비교하여 미세 조정의 에너지 및 탄소 비용을 이해하고 미세 조정의 에너지 효율성을 향상시키기를 원하는 NLP 연구자와 실무자들에게 가이드라인을 제공한다.

###### Democratizing LLMs: An Exploration of Cost-Performance Trade-offs in Self-Refined Open-Source Models (https://aclanthology.org/2023.findings-emnlp.608/)
- Anthology ID: 2023.findings-emnlp.608 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 소위 비공개 LLM의 지배로 인해 접근이 제한되고 정보 개인정보 보안에 대한 우려가 제기되고 있다. 
    2. SoTA(open-source) 대안은 정보 민감한 고용량의 어플리케이션에 중요하지만 성능에서는 부족한 경우가 많다. 
    3. 이 논문에서는 어떤 고려 사항에 따라 태스크에 최적인 모델을 찾기 위해 PeRFICS라는 새로운 랭킹 메트릭과 외부 영향이 없는 반복적인 자가 비판과 자가 재정립 메커니즘을 제안한다.

###### Chinese Metaphorical Relation Extraction: Dataset and Models (https://aclanthology.org/2023.findings-emnlp.609/)
- Anthology ID: 2023.findings-emnlp.609 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 메타포 식별은 일반적으로 sequence labeling이나 구문적으로 관련된 단어 쌍의 분류 문제로 구성된다. 이 논문에서 우리는 메타포 식별을 관계 추출 문제로 새롭게 정의한다. 우리는 타겟 범위와 소스 관련 범위라는 두 가지 범위 사이의 링크인 메타포 관계를 도입한다.
    2. 우리는 타겟과 소스의 특성을 파악하기 위해 단어 이상의 유연하고 정확한 텍스트 단위를 사용할 수 있는데, 이는 단어 단위로는 어려운 메타포의 특성을 잡아낼 수 있다.
    3. 우리는 중국어 메타포 관계 추출을 위한 데이터셋을 만들고, 타겟/소스 관련 범위와 세부적인 범위 유형과 함께 4,200개 이상의 문장을 메타포 관계로 주석을 달았다. 우리는 메타포 관계 추출을 위한 범위 기반의 end-to-end 모델을 개발하고 이의 효과성을 입증했다.

###### Example-based Hypernetworks for Multi-source Adaptation to Unseen Domains (https://aclanthology.org/2023.findings-emnlp.610/)
- Anthology ID: 2023.findings-emnlp.610 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. NLP 알고리즘의 발전에도 불구하고, 도메인 외 일반화는 여전히 큰 도전이다. 이 논문에서는 다양한 소스 도메인으로부터 레이블된 데이터를 활용하여 훈련 중에 알려지지 않은 대상 도메인에 일반화하는 문제를 다룬다. 
    2. 우리는 하이퍼네트워크 적응으로 예시 기반 메타-러닝을 사용하여 새로운 시그니처를 생성하고, 이를 하이퍼네트워크를 통해 과제 분류기의 가중치를 생성하는 혁신적인 프레임워크를 제안한다.
    3. 이 방법을 감성 분류와 자연어 추론 두 가지 작업에서 29개의 적응 시나리오에서 평가하였고, 기존 알고리즘보다 성능이 우수한 것을 확인하였다. 또한 세부 적인 사례에 대한 효과성을 입증하기 위해 few-shot GPT-3와 우리의 학습 모델을 비교하였다. 이 논문은 알려지지 않은 도메인에 대한 하이퍼네트워크 적응의 첫 번째 적용 사례로 전해진다.

###### Beneath the Surface: Unveiling Harmful Memes with Multimodal Reasoning Distilled from Large Language Models (https://aclanthology.org/2023.findings-emnlp.611/)
- Anthology ID: 2023.findings-emnlp.611 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사회적 미디어 시대에는 진부한 "밈"이 넘쳐나고 있는데, 이 밈들의 의미를 탐지하고 파악하는 것은 텍스트나 이미지로는 명시적으로 전달되지 않는 때문에 중요한 도전 과제이다.
    2. 기존의 해로운 밈 탐지 방법들은 표면적으로 해로울 특징을 분류하는 방식만을 사용하고 있지만, 밈의 텍스트와 이미지에 대한 깊은 인식을 무시하고 있다.
    3. 본 논문에서는 밈의 다중 모달 정보를 교차작용을 통해 뛰어난 추론을 기반으로 해로운 밈을 탐지하려고 한다. 많은 양의 텍스트를 다루는 대형 언어 모델에 영감을 받아, 본 연구에서는 추론 연산을 수행하고 그 결과를 이용하여 다중 모달 융합과 가볍게 튜닝하는 새로운 생성적 프레임워크를 제안한다. 이러한 아이디어를 바탕으로 한 실험 결과는 기존 방법과 비교하여 우수한 성능을 보여준다.

###### Domain Adaptation for Conversational Query Production with the RAG Model Feedback (https://aclanthology.org/2023.findings-emnlp.612/)
- Anthology ID: 2023.findings-emnlp.612 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "대화형 쿼리 생성은 대화 시스템을 위한 신흥 기본 작업으로, 검색 엔진에서 방대하고 지속적으로 업데이트되는 지식을 탐색하기 위해 검색 쿼리를 생성한다. "
    2. "이 연구 분야를 가속화하기 위해 이전 연구에서는 여러 가지 도메인의 대화를 커버하지 못하는 제한적인 주석이 달린 데이터셋을 공개해왔으나, 이 과제를 해결하기 위해 우리는 신규 도메인 적응 프레임워크를 제안한다. "
    3. "이 프레임워크는 이전 작업에서 개선된 약간 지도 학습 알고리즘을 바탕으로 하고, RAG 모델 피드백에 따라 방향을 제시하여 더욱 견고하고 강력한 결과를 보여준다."

###### LEGO: A Multi-agent Collaborative Framework with Role-playing and Iterative Feedback for Causality Explanation Generation (https://aclanthology.org/2023.findings-emnlp.613/)
- Anthology ID: 2023.findings-emnlp.613 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 인과성 설명 생성은 초기 원인-결과 쌍이 주어지면 자연어로 설명을 생성하는 것을 말한다. 이 과제는 명시적이고 철저한 근거를 요구하며, 일반 상식 지식을 습득하기 위해 메모리에 쉽게 기억되지 않는 것으로 알려져 있기 때문에 대형 언어 모델에 대한 도전과제이다. 
    2. 이 논문은 LEGO라는 다중 에이전트 협업 프레임워크를 소개하는데, 이는 역할 할당 및 반복적 피드백을 통해 LLM을 자유롭게 변형 가능한 레고 블록으로 취급한다. 먼저 세밀한 세계 지식 통합 모듈을 사용하여 표준 인과 관련성 현상을 완화하기 위해 과제에 대한 정보를 보완한다. 그런 다음 다면적 피드백과 개선 모듈을 이용하여 생성된 설명을 개선한다. 
    3. WIKIWHY와 e-CARE 데이터셋에서의 실험 결과, 우리의 다중 에이전트 프레임워크가 원인과 결과 사이의 인과관계를 추론하는 면에서 우수성을 보였다.

###### Ranking LLM-Generated Loop Invariants for Program Verification (https://aclanthology.org/2023.findings-emnlp.614/)
- Anthology ID: 2023.findings-emnlp.614 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 공리화된 루프 불변수의 합성은 프로그램 검증을 자동화하는 데에 기본적이다. 이 연구에서는 GPT-3.5 또는 GPT-4와 같은 대형 언어 모델은 0-shot 설정에서 특정 프로그램의 루프 불변수를 합성하는 능력을 갖추고 있지만, 올바른 불변수를 생성하기 위해 여러 개의 샘플이 필요하다. 이는 불변수를 확립하기 위해 프로그램 검증기에 대규모 호출을 유발할 수 있다. 이 문제를 해결하기 위해 우리는 LLMs의 생성 결과에 대한 재랭킹 접근법을 제안한다. 우리는 문제 정의를 기반으로 올바른 불변수와 잘못된 시도를 구별할 수 있는 랭커를 설계했다. 이 랭커는 대조 랭커로 최적화되었다. 실험 결과는 이 재랭킹 메커니즘이 생성된 후보들 중 올바른 불변수의 순위를 크게 향상시키며, 검증기에 대한 호출 수를 현저히 줄일 수 있음을 보여준다.
    
    2. 대형 언어 모델인 GPT-3.5나 GPT-4는 특정 프로그램의 루프 불변수를 0-shot 설정에서 합성하는 능력을 갖추고 있지만, 올바른 불변수를 생성하기 위해서는 여러 개의 샘플이 필요하다. 이로 인해 불변수를 검증기에 확립하기 위한 호출 수가 많아질 수 있다.
    3. 이를 해결하기 위해 우리는 생성된 결과에 대한 재랭킹 접근법을 제안하며, 문제 정의를 기반으로 올바른 불변수와 잘못된 시도를 구별하는 랭커를 설계했다. 실험 결과는 이러한 재랭킹 메커니즘이 올바른 불변수의 순위를 크게 향상시키고 검증기에 대한 호출 수를 현저히 줄일 수 있음을 보여준다.

###### WordNet Is All You Need: A Surprisingly Effective Unsupervised Method for Graded Lexical Entailment (https://aclanthology.org/2023.findings-emnlp.615/)
- Anthology ID: 2023.findings-emnlp.615 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 우리는 WordNet을 사용하여 영어에서 등급화된 어휘 의미 연관성 (GLE)을 예측하는 간단한 비지도 학습 방법을 제안한다.
    2. 우리의 방법은 WordNet의 계층적인 synset 구조를 활용하여 대칭적 의미 유사도 점수와 비대칭적 특수성 손실 점수의 합으로 GLE를 모델링한다.
    3. 우리의 방법은 HyperLex (Vulic et al., 2017)라는 가장 큰 GLE 데이터셋에서 상태-of-the-art 성능을 달성하며, WordNet을 약한 지도로 사용하는 전문화된 단어 임베딩 방법을 포함한 모든 이전 방법을 능가한다.

###### Knowledge Corpus Error in Question Answering (https://aclanthology.org/2023.findings-emnlp.616/)
- Anthology ID: 2023.findings-emnlp.616 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 오픈 도메인 질의 응답(QA) 작업에서는 기존의 검색 단계 대신에 큰 언어 모델(LLM)에서 context passages를 생성하는 방식을 적용해왔다. 하지만 생성된 passages가 검색된 것보다 효과적일 수 있는 이유는 잘 알려져 있지 않다.
    2. 이 연구에서는 QA의 전통적인 접근 방식을 재검토하고, knowledge corpus error라는 개념을 도입한다. 이 오류는 검색에 사용된 지식 corpus가 전체 string space의 하위 집합일 때 발생하며, corpus 밖에 있는 더 도움이 되는 passages를 제외할 수 있다.
    3. LLM들은 더 큰 공간에서 passages를 생성함으로써 이러한 한계를 완화할 수 있으며, LLM을 사용하여 인간 주석이 달린 gold context를 다른 방식으로 해석하는 실험을 제안하고, 세 가지 QA 벤치마크에서의 결과는 paraphrased passage를 사용할 때 성능이 향상되었으며, 이는 knowledge corpus error의 존재를 나타낸다.

###### Epsilon Sampling Rocks: Investigating Sampling Strategies for Minimum Bayes Risk Decoding for Machine Translation (https://aclanthology.org/2023.findings-emnlp.617/)
- Anthology ID: 2023.findings-emnlp.617 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 기계 번역에서는 최소 베이즈 위험(MBR) 디코딩이 beam search 디코딩 대안으로 효과적일 수 있다는 것이 밝혀진 바 있다. 그러나 MBR 디코딩은 어떻게 및 얼마나 많은 후보를 모델에서 샘플링하는지에 크게 의존하며, 이 논문에서는 MBR 디코딩을 위한 후보 목록 생성 방법이 성능에 어떤 영향을 미치는지 탐구한다.
    2. 우리는 선조 법칙, nucleus 샘플링, 상위 k 샘플링과 같은 인기있는 샘플링 방법을 평가한다.
    3. 인간 평가를 통해 우리는 epsilon-sampling 기반 MBR 디코딩이 beam search 디코딩뿐만 아니라 다른 모든 샘플링 방법과 비교하여 네 개의 언어 쌍에서 유의미한 성능 향상을 보인다는 것을 입증하였다.

###### The language of prompting: What linguistic properties make a prompt successful? (https://aclanthology.org/2023.findings-emnlp.618/)
- Anthology ID: 2023.findings-emnlp.618 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최신 LLMs(Large Language Models)는 zero-shot이나 few-shot에서 놀라운 성능을 보이는데, 이때 prompt의 선택에 따라 성능이 크게 달라지므로 prompt 최적화에 대한 연구들이 많이 진행되고 있다. 그러나 prompt의 언어적 특성이 작업 성능과 어떻게 관련되는지에 대한 체계적인 이해가 부족하다. 
    2. 이 연구에서는 LLM의 크기, 사전훈련된 정도에 따라 다른 LLM들이 의미적으로 동일하지만 언어 구조가 다른 prompt에서의 성능을 비교한다. 저자들의 발견은 사전훈련이나 지시 튜닝 데이터에서의 언어 사용을 반영하는 prompt에서 최적 성능을 얻을 수 있다는 일반적인 가정과는 다르게, prompts은 데이터셋이나 모델 간에 잘 전이되지 않고, 성능은 보통 perplexity, 단어 빈도, 단어 의미 모호성 또는 prompt의 길이로 설명할 수 없다는 것이다. 
    3. 이 결과를 바탕으로 저자들은 prompting 연구에 대한 더 견고하고 포괄적인 평가 기준의 제안을 제시한다.

###### When and Why Does Bias Mitigation Work? (https://aclanthology.org/2023.findings-emnlp.619/)
- Anthology ID: 2023.findings-emnlp.619 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 신경망 모델은 얕은 표면적인 특징을 활용하여 언어 이해 작업을 수행하는 것으로 나타났으며, 이는 실무자가 원하는 보다 깊은 언어 이해 및 추론 기술을 배우는 것과는 다릅니다. 
    2. 이전 연구에서는 모델을 편견 있는 특징이나 데이터셋의 결함에서 멀리하도록 하는 Debiasing 기술을 개발했지만, 이러한 Debiasing으로 인해 모델은 숨겨진 편견에 더 의존함으로써 테스크를 해결하는 데 도움이 되는 견고한 특징을 학습하지 못할 수 있다는 것을 보여주고 있습니다. 
    3. 그 결과로 우리는 기존의 모델을 Debiasing 하는 것만으로는 많은 언어 이해 작업에는 충분하지 않을 수 있으며, 상식적 추론과 추론과 같은 복잡한 과제를 해결하기 위해 새로운 학습 패러다임을 고려해야 할 것을 제안합니다.

###### Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy (https://aclanthology.org/2023.findings-emnlp.620/)
- Anthology ID: 2023.findings-emnlp.620 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "검색 보강 생성은 오래되어 고정된 지식과 환각과 같은 거대한 언어 모델의 한계를 극복할 수 있는 아주 유망한 분야로써 많은 관심을 받아왔다. 그러나 특히 복잡한 정보 요구를 가진 쿼리의 경우, 검색 시 관련성을 파악하기 어렵다. 최근 연구에서는 대형 언어 모델을 검색에 적극적으로 참여시켜 관련성 모델링을 개선하는 방안을 제안해왔다."
    2. "우리는 이 논문에서 Iter-RetGen이라고 부르는 방법으로 검색과 생성을 반복적으로 통합함으로써 강력한 성능을 얻을 수 있다는 것을 보여준다. 모델의 작업 입력에 대한 응답은 작업을 완료하기 위한 필요한 내용을 보여주며, 따라서 다른 반복에서 더 관련 있는 지식을 검색하고 이를 통해 더 나은 응답을 생성하는 데 도움이 된다."
    3. "우리는 다중 홉 질문응답, 사실 검증, 상식적 추론 등에서 Iter-RetGen을 평가하고, 파라미터 기반 지식과 비파라미터 기반 지식을 유연하게 활용할 수 있으며, 검색과 생성의 추가적인 부담이 적으면서 최첨단 검색 보강 기베스랑 경쟁력이나 우위를 갖는다. 생성 보강 검색 적응을 통해 성능을 더욱 향상시킬 수 있다."

###### Dynamic Low-rank Estimation for Transformer-based Language Models (https://aclanthology.org/2023.findings-emnlp.621/)
- Anthology ID: 2023.findings-emnlp.621 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 행렬 분해 방법 (SVD와 그의 variant들)은 Transformer 기반 언어 모델의 압축에 널리 사용되지만, 기존 방법들은 결국 변화하는 중요도 분포 가정을 하고 파인튜닝 후에 추가적인 조정을 요구하는 문제가 있다.
    2. 이 논문에서는 트레이닝 과정에서 다른 레이어의 행렬에 동적 rank 자원을 할당하는 RankDyna라는 행렬 분해 방법을 제안한다.
    3. 다양한 파라미터 예산 수준에서 RankDyna가 다른 SOTA 방법들보다 우수한 성능을 보이며, 더 높은 압축률에서 RankDyna의 이점이 더욱 부각되는 것을 확인할 수 있다.

###### Non-parallel Accent Transfer based on Fine-grained Controllable Accent Modelling (https://aclanthology.org/2023.findings-emnlp.622/)
- Anthology ID: 2023.findings-emnlp.622 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 강세 전이 연구는 병렬 데이터나 음성인식 모델에 의존하였으나, 이 논문은 비병렬 데이터를 사용하여 강세 전이의 실제 응용을 위해 연구하였다.
    2. 이 연구에서는 강세 전이 모델링의 어려움과 음성 표현의 분리에 집중하였다.
    3. 연구에서 제안한 방법들은 음조와 리듬을 고려하여 강세를 세밀하게 모델링하고, 상호 정보 학습을 이용하여 생성된 음성의 강세를 제어하는 방법으로 이러한 문제들을 해결하였다. 실험 결과는 제안된 프레임워크가 기준 모델과 비교하여 강인함과 오디오 품질 측면에서 우수한 성능을 보였다.

###### Compositional Generalization for Data-to-Text Generation (https://aclanthology.org/2023.findings-emnlp.623/)
- Anthology ID: 2023.findings-emnlp.623 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 데이터-텍스트 생성은 구조화된 데이터를 일관된 텍스트로 변환하는 과정인데, 새로운 형태의 구조화된 데이터를 처리할 때 여전히 문제가 발생하여 (위조나 생략과 같은) 텍스트의 충실성에 영향을 준다. 
    2. 이 문제를 "composition generalisation"이라 칭하며, 이를 해결하기 위해 다른 접근 방식의 성능을 평가하는 벤치마크를 만들기로 하였다. 
    3. 또한, 우리는 군집화를 통해 이러한 문제를 해결하는 새로운 모델을 제안한다. 이 모델은 문장 단위로 텍스트를 생성하며, 한 번에 하나의 군집된 Predicate를 사용한다. 이러한 접근 방식은 모든 평가 메트릭에서 T5에 비해 큰 개선을 보인다. 특히, 입력과의 충실성을 유지하는 메트릭에서 T5보다 31%의 향상을 이루었다.

###### In-Context Learning Creates Task Vectors (https://aclanthology.org/2023.findings-emnlp.624/)
- Anthology ID: 2023.findings-emnlp.624 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최신 언어 모델의 이기능 (ICL)은 강력한 학습 패러다임이지만 여전히 그 밑단 메커니즘을 잘 이해하지 못하고 있다.
    2. 이 논문에서는 ICL에서 학습된 함수가 매우 간단한 구조를 가지고 있다는 것을 보여줌으로써 기존의 기계 학습 프레임워크와의 관계를 설명한다.
    3. 실험을 통해 위의 주장을 지원하며 다양한 모델과 태스크에 걸친 결과를 보여준다.

###### TalkUp: Paving the Way for Understanding Empowering Language (https://aclanthology.org/2023.findings-emnlp.625/)
- Anthology ID: 2023.findings-emnlp.625 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 언어 기술은 교육, 직장 업무, 의료 등 여러 실제 상황에서 중요하며, 하지만 NLP에서 강조되는 "empowering language"은 연구와 구체화하기 어렵다.
    2. 이 논문에서는 언어학과 사회심리학 문헌에 기반하여 empowering language을 탐색하며, 이를 위해 Reddit 게시물 데이터셋을 구축하였다.
    3. 이 데이터셋은 TalkUp이라고 불리며, empowering 및 disempowering language를 포착하는 언어 모델을 훈련시키는 데 사용될 수 있다. 또한 상황에 따른 함의, 전제, 사회적 맥락이 언어의 의미에 어떻게 영향을 미치는지 조사할 수 있는 방향성을 제공한다.

###### Unifying Text, Tables, and Images for Multimodal Question Answering (https://aclanthology.org/2023.findings-emnlp.626/)
- Anthology ID: 2023.findings-emnlp.626 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 멀티모달 질문 답변 (MMQA)은 여러 지식 모달리티 (예: 텍스트, 테이블, 이미지)에서 답을 도출하는 것을 목표로 하는데, 이는 다양한 응용 분야에 대한 주목을 받고 있다. 
    2. 현재의 MMQA 접근 방식은 단일 모달이나 이중 모달 QA 모델에 의존하는 경우가 많은데, 이는 모든 모달리티 간의 정보를 효과적으로 통합하고 사전 훈련된 언어 모델의 능력을 활용하는 데 제한이 있다. 
    3. 이 논문에서는 테이블 선형화와 이미지 캡셔닝 기술을 활용하여 세 가지 다른 입력 모달리티를 텍스트-텍스트 형식으로 통합하는 UniMMQA라는 새로운 프레임워크를 제안하고, 텍스트-텍스트 생성 과정에 다중모달 합리성 생성기를 도입하여 크로스모달 추론을 향상시켰다. 실험 결과는 UniMMQA의 지도 및 비지도 설정에서의 우수성을 보여준다.

###### Unsupervised Lexical Simplification with Context Augmentation (https://aclanthology.org/2023.findings-emnlp.627/)
- Anthology ID: 2023.findings-emnlp.627 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 본 논문은 감독되지 않은 데이터와 사전 훈련된 언어 모델만을 사용하는 새로운 자동 단어 간소화 방법을 제안한다. 
    2. 주어진 대상 단어와 그 문맥에 기반하여, 우리의 방법은 대상 문맥과 동일한 문맥뿐만 아니라 단어력 데이터에서 샘플링한 추가 문맥을 사용하여 대체어를 생성한다.
    3. 영어, 포르투갈어, 스페인어로 TSAR-2022 공유 과제에서 실험을 진행한 결과, 우리의 모델이 모든 언어에서 다른 감독 없는 시스템보다 큰 성능향상을 보여주며, GPT-3.5와 앙상블하면 새로운 최고 성능을 달성함을 보여주었다.

###### mLongT5: A Multilingual and Efficient Text-To-Text Transformer for Longer Sequences (https://aclanthology.org/2023.findings-emnlp.628/)
- Anthology ID: 2023.findings-emnlp.628 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 긴 입력을 처리하는데 적합한 multilingual한 텍스트를 텍스트로 변환하는 transformer 모델인 mLongT5를 개발했다.
    2. mLongT5 모델은 LongT5의 아키텍처를 기반으로하며, mT5의 multilingual 데이터셋과 UL2의 pretrained task를 활용한다.
    3. 다양한 multilingual summarization 및 question-answering 태스크에서 평가를 진행한 결과, mLongT5는 mBART나 M-BERT와 비교했을 때 더 강력한 성능을 보였다.

###### Multilingual Lottery Tickets to Pretrain Language Models (https://aclanthology.org/2023.findings-emnlp.629/)
- Anthology ID: 2023.findings-emnlp.629 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다국어 사전학습 언어 모델(mPLMs)을 훈련할 때 발생하는 다국어로 인한 제약은 용량이 제한되었을 때 특히 심하게 나타난다. 이 논문은 이러한 문제를 해결하기 위해 개별 언어의 용량을 유지하면서 부정적인 간섭을 줄이는 방식을 제안한다.
    2. 먼저 모델의 규모를 줄여 간섭을 감소시키고, 그런 다음 전체 모델과 비슷한 성능을 가진 개별 언어의 하위 네트워크나 "복권티켓"을 찾는다.
    3. 이를 통해 추론 비용을 줄이고 성능을 향상시키는데 성공하며, 탐색 비용 또한 무시할 수 있으며 언어적 유사성을 qualitatively 보존한다.

###### Target-Aware Spatio-Temporal Reasoning via Answering Questions in Dynamic Audio-Visual Scenarios (https://aclanthology.org/2023.findings-emnlp.630/)
- Anthology ID: 2023.findings-emnlp.630 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 오디오-시각적 문의-답변 (AVQA)은 다중 단계 시공간 추론을 포함하여 다중 모달 맥락에서 복잡한 작업이다. 
    2. 이 논문에서는 AVQA를 위한 새로운 목표지향적 시공간 고정 네트워크를 제안하였다. 
    3. 실험 결과는 우리의 방법이 기존 기법들보다 효과적이라는 것을 확인하였다.

###### KG-GPT: A General Framework for Reasoning on Knowledge Graphs Using Large Language Models (https://aclanthology.org/2023.findings-emnlp.631/)
- Anthology ID: 2023.findings-emnlp.631 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델(LLM)은 비구조적인 텍스트 이해와 생성에 큰 발전을 이루고 있지만, 정형 데이터에 대한 응용은 아직 충분히 탐구되지 않았다. 특히, LLM을 지식 그래프(KG)의 복잡한 추론 작업에 사용하는 것은 거의 이루어지지 않았다. 
    2. 이 논문에서는 KG를 활용하는 작업에 LLM을 활용하기 위해 KG-GPT라는 LLM의 다목적 프레임워크를 제안한다. 
    3. KG 기반 사실 검증 및 KGQA 벤치마크를 사용하여 KG-GPT를 평가하였고, 해당 모델은 경쟁력있고 견고한 성능을 보여주었으며, 몇몇 fully-supervised 모델보다 우수한 성능을 보였다.

###### Breaking the Language Barrier: Improving Cross-Lingual Reasoning with Structured Self-Attention (https://aclanthology.org/2023.findings-emnlp.632/)
- Anthology ID: 2023.findings-emnlp.632 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 연구에서는 다국어 언어 모델(MultiLM)이 다른 언어에 대한 논리 추론 능력을 전이할 수 있는지 조사한다. 
    2. 새로운 언어에서 추론이 여전히 동일한 언어로 이루어지지만 모델은 학습한 추론 능력을 다국어로 전이시켜야하는 단일 언어 추론, 그리고 맥락과 질문의 언어가 다른 코드 스위치 추론 두 가지 방식에서 MultiLM의 다국어 추론 능력을 평가한다. 
    3. RuleTaker 및 LeapOfThought 두 가지 논리 추론 데이터셋에서 우리는 MultiLM이 단일 언어 설정에서는 추론 능력을 다국어로 전이시킬 수 있지만 코드 스위치 설정에서는 추론 능력을 전이하기 어려움을 보여준다. 이 관찰을 바탕으로, 우리는 코드 스위치 시퀀스에서 전문적인 효율성을 향상시키기 위해 특별한 매개 변수 세트를 사용하는 새로운 어텐션 메커니즘을 제안한다. 이는 RuleTaker 및 LeapOfThought 데이터셋에서 각각 14% 및 4%까지 추론 성능을 향상시킨다.

###### CITB: A Benchmark for Continual Instruction Tuning (https://aclanthology.org/2023.findings-emnlp.633/)
- Anthology ID: 2023.findings-emnlp.633 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Continual Learning (CL)은 지속적으로 새로운 지식을 학습하고 그것을 새로운 과제에 전달하는 사람의 학습 능력을 재현하기 위한 패러다임이다. 이 논문에서는 Continual Instruction Tuning (CIT)이라는 새로운 문제를 제안하고, 지식을 이전하는 데 도움이 되는 Instruction Tuning (IT)과 CL의 관계를 연구한다.
    2. 실험 결과, 기존의 CL 방법들이 자연어 지침을 효과적으로 활용하지 못하며, 순차적으로 Instruction Tuned 모델을 fine-tuning 하는 것이 비슷하거나 더 좋은 결과를 낼 수 있다고 보여주었다.
    3. 이 논문에서는 CIT에 영향을 미칠 수 있는 다양한 측면을 탐구하며, 이를 통해 이 분야에서의 더 많은 연구를 촉진할 수 있는 CIT 벤치마크를 제시한다.

###### Mixture-of-Linguistic-Experts Adapters for Improving and Interpreting Pre-trained Language Models (https://aclanthology.org/2023.findings-emnlp.634/)
- Anthology ID: 2023.findings-emnlp.634 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 연구에서는 언어 모델에 언어 구조를 주입하는 방식을 제안하여 경제적인 파라미터 조정 (PEFT) 설정에서 성능을 향상시킨다.
    2. 우리의 접근 방식에서는 다양한 언어 구조를 인코딩하는 병렬 어댑터 모듈을 사용하여, Gumbel-Softmax 게이트를 사용하여 각 레이어에서 이러한 모듈의 중요성을 결정한다.
    3. 실험 결과는 우리의 방법이 최첨단 PEFT 방법보다 많은 파라미터를 사용하지 않고 우수한 성능을 발휘할 수 있음을 보여준다. 또한, 각 레이어에서 각 모델이 선택한 전문가들을 분석하여 향후 연구에 대한 통찰력을 제시한다.

###### Towards Better Representations for Multi-Label Text Classification with Multi-granularity Information (https://aclanthology.org/2023.findings-emnlp.635/)
- Anthology ID: 2023.findings-emnlp.635 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문은 Pre-trained Language Model (PLM)을 사용하여 다중 라벨 텍스트 분류 (MLTC)를 위한 텍스트 표현 학습과 라벨 상관관계 모델링에 초점을 맞추었으나, PLM이 단어 빈도 중심의 텍스트 표현을 생성하여 서로 다른 라벨을 가진 텍스트가 가깝게 분포되는 문제가 있다.
    2. 이를 해결하기 위해, CL-MIL(Contrastive Learning-Multi-granularity Information Learning)이라는 새로운 프레임워크를 제안하여 텍스트 표현을 개선한다. 첫째로, 대조적 학습을 사용하여 균일한 초기 텍스트 표현을 생성하고 라벨 빈도를 암묵적으로 통합한다. 둘째로, 다양한 텍스트-라벨 상관관계, 라벨-라벨 관계 및 라벨 빈도와 같은 다중 그래뉴러티 정보를 텍스트 표현에 통합하고 구별력을 향상시킨다.
    3. 실험 결과에서는 CL-MIL의 모듈들이 보완적인 성능을 발휘하며, 텍스트 표현의 품질을 개선하고 MLTC에서 안정적이고 경쟁력 있는 성능 향상을 이끌어냄을 보여준다.

###### PCMID: Multi-Intent Detection through Supervised Prototypical Contrastive Learning (https://aclanthology.org/2023.findings-emnlp.636/)
- Anthology ID: 2023.findings-emnlp.636 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 의도 감지는 자연어 이해(NLU)에서 주요한 작업으로, 사용자의 발화를 기반으로 사용자의 의도를 해석하는 대화 시스템의 구성 요소이다. 이 논문에서는 PCMID라는 새로운 Multi-Intent Detection 프레임워크를 제안한다. PCMID 모델은 최적화된 의미 공간에서 주어진 사용자 발화의 여러 의도 레이블에 대한 다중 의미 표현을 학습할 수 있다.
    2. 기존의 단일 의도 가정에 의한 의도 감지 시스템에 비해 PCMID는 실제 상황에서 각 사용자 발화가 매우 복잡하고 여러 의도를 표현할 수 있는 경우에 더 도전적인 작업이다.
    3. 실험 결과, PCMID는 다중 공개 벤치마크 데이터셋과 실제 세계 데이터셋에서 현재 최고의 성능을 달성한다.

###### Is GPT-4 a Good Data Analyst? (https://aclanthology.org/2023.findings-emnlp.637/)
- Anthology ID: 2023.findings-emnlp.637 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델 (LLM)은 맥락 이해, 코드 생성, 언어 생성, 데이터 스토리텔링 등 다양한 도메인과 작업에서 강력한 성능을 보여주면서 많은 데이터 분석가들이 인공지능에 의해 대체될까 우려하고 있다. 우리는 이 논란의 소재를 다루며 "GPT-4가 좋은 데이터 분석가인가?"라는 연구 질문을 제기하고 대조 연구를 통해 답하려고 한다.
    2. 우리는 GPT-4를 데이터 분석가로 간주하여 다양한 도메인의 데이터베이스를 사용하여 end-to-end 데이터 분석을 수행하도록 하였다. 우리는 GPT-4에 대한 prompt를 신중히 설계하여 실험을 진행하기 위한 프레임워크를 제안하였다.
    3. 실험 결과, GPT-4는 인간과 비교 가능한 성능을 달성할 수 있음을 보였다. 또한 GPT-4가 데이터 분석가를 대체할 수 있는 결론을 내리기 전에 추가 연구에 대한 조명을 제공한다.

###### DiffusionRet: Diffusion-Enhanced Generative Retriever using Constrained Decoding (https://aclanthology.org/2023.findings-emnlp.638/)
- Anthology ID: 2023.findings-emnlp.638 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Generative retrieval"은 쿼리를 관련 문서 ID로 매핑하는 새로운 정보 검색(IR) 패러다임으로 최근에 등장하였지만, 중간 추론 단계의 부족과 인공적인 문서 ID 기호 사용으로 인한 선훈단계와의 불일치 문제로 고통받고 있다.
    2. 이러한 한계를 극복하기 위해 우리는 검색 전에 쿼리로부터 문서 생성을 사용하는 중간 단계로서의 접근 방식을 제안한다.
    3. 실험 결과, 우리가 제안한 DiffusionRet은 기존의 generative retrieval 방법보다 우수한 성능을 보이며, 매우 작은 매개 변수 개수로 최신의 성능을 달성한다.

###### Estimating Large Language Model Capabilities without Labeled Test Data (https://aclanthology.org/2023.findings-emnlp.639/)
- Anthology ID: 2023.findings-emnlp.639 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델 (Large Language Models, LLMs)은 몇 가지 예시만으로도 문맥 학습 (In-Context Learning, ICL)을 효과적으로 수행할 수 있는 능력을 갖추었습니다. 그러나 ICL의 성공은 과제에 따라 다양하게 달라집니다. 따라서 새로운 과제에 대해 ICL을 적용할 수 있는지를 빠르게 판단하는 것은 중요합니다. 그러나 ICL 정확도를 직접 평가하는 것은 주로 비용이 많이 드는 상황에서는 비효율적입니다.
    
    2. 이 논문에서는 ICL 정확도 추정이라는 작업을 제안합니다. 이 작업에서는 새로운 과제에 대해 레이블이 없는 테스트 데이터만으로 LLM의 정확도를 예측합니다. ICL 정확도 추정을 수행하기 위해, LLM의 확신 점수를 특성으로 사용하여 메타모델을 훈련하는 방법을 제안합니다.
    
    3. 우리의 방법을 4개의 LLM과 3개의 과제 컬렉션을 포함한 새로운 벤치마크에서 여러 강력한 정확도 추정 기준과 비교하였고, 12개의 설정 중 7개에서 기존 기준에 비해 성능을 향상시켰습니다. 또한, 40개의 레이블이 있는 테스트 예제 당 직접 평가하는 것과 동일한 추정 성능을 달성하였습니다. 동시에 기존의 접근 방식은 모든 설정에서 정확하고 신뢰할 수 있는 ICL 정확도 추정을 제공하지 않아 LLM 예측의 불확실성을 측정하는 더 좋은 방법에 대한 필요성을 강조하고 있습니다.

###### A Novel Contrastive Learning Method for Clickbait Detection on RoCliCo: A Romanian Clickbait Corpus of News Articles (https://aclanthology.org/2023.findings-emnlp.640/)
- Anthology ID: 2023.findings-emnlp.640 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 수익 증대를 위해 뉴스 웹사이트는 종종 유혹적인 뉴스 제목을 사용하여 사용자들이 제목을 클릭하고 전문을 읽도록 한다. 이 연구에서는 이러한 클릭베이트를 자동으로 탐지하는 작업을 Romanian 언어로 수행하는 새로운 Romanian Clickbait Corpus (RoCliCo)를 소개한다. 
    2. RoCliCo는 8,313개의 뉴스 샘플로 구성되어 있으며, 클릭베이트와 클릭베이트가 아닌 레이블로 수동으로 주석이 달려있다. 
    3. 기계학습 방법과 함께 가중 투표 앙상블을 사용하여 여러 베이스라인을 구축하고, BERT 기반 대조 학습 모델을 제안하여 클릭베이트 및 클릭베이트가 아닌 뉴스의 제목과 내용을 깊은 표현 공간에 인코딩하는 방법을 제시한다.

###### Large Language Models as Source Planner for Personalized Knowledge-grounded Dialogues (https://aclanthology.org/2023.findings-emnlp.641/)
- Anthology ID: 2023.findings-emnlp.641 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 오픈 도메인 대화 시스템은 보다 정보성과 근거 있는 응답을 생성하기 위해 다양한 지식 원천을 필요로 한다. 
    2. 그러나 기존 지식-중심 대화 시스템은 단일 지식 원천에 초점을 맞추거나 여러 지식 원천 간의 의존성을 간과하여 일관성 없는 또는 패러독스적인 응답을 생성할 수 있다.
    3. 본 논문에서는 SAFARI라는 새로운 프레임워크를 제안하여 다중 지식 원천과 그 사이의 의존성을 효과적으로 결합하는 방법을 소개하고 실험 결과를 통해 SAFARI 프레임워크가 페르소나 일관성과 지식 강화된 응답을 효과적으로 생성할 수 있다는 것을 보여준다.

###### Toxicity in Multilingual Machine Translation at Scale (https://aclanthology.org/2023.findings-emnlp.642/)
- Anthology ID: 2023.findings-emnlp.642 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기계 번역 시스템은 중요한나 일부 오류, 특히 악성 표현 추가와 같은 치명적인 오류가 있다. 
    2. 저자들은 약 164개 언어로 만들어진 큰 평가 데이터셋을 사용하여 다양한 언어에서 추가된 독성을 평가하고 분석하였으며, 가장 많은 추가 독성을 보이는 언어는 저자들이 분석한 13가지 인구통계 축 중 제일 낮은 리소스를 가진 언어들이었다.
    3. 소스 기여에 대한 측정을 사용하여 독성의 원인을 해석하였고, 소스 기여와 독성 사이에는 유의한 상관관계가 있음을 보였다. 추가 독성을 줄이기 위해 훈련 데이터를 적절히 관리하고, 환각을 완화하고, 불안정한 변역을 확인하는 것을 권장한다.

###### Conversational Recommender System and Large Language Model Are Made for Each Other in E-commerce Pre-sales Dialogue (https://aclanthology.org/2023.findings-emnlp.643/)
- Anthology ID: 2023.findings-emnlp.643 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문은 E-commerce 사전 판매 대화에서 LLM과 CRS의 협력이 효과적일 수 있다는 것을 조사하고, 두 가지 협력 방법을 제안한다. 
    2. 협력 접근법에 대한 실험을 수행하고, E-commerce 사전 판매 대화의 네 가지 작업에 대한 두 가지 CRS와 두 가지 LLM의 협력 접근법의 영향을 분석한다. 
    3. 결과적으로 LLM과 CRS 간의 협력이 일부 경우에 매우 효과적일 수 있다는 것을 발견하였다.

###### VIP5: Towards Multimodal Foundation Models for Recommendation (https://aclanthology.org/2023.findings-emnlp.644/)
- Anthology ID: 2023.findings-emnlp.644 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 컴퓨터 비전, 자연어 처리, 추천 시스템은 독립적으로 발전하여 서로의 발전을 직접적으로 이용하기 어려운 상황이다. 
    2. 그러나 최근 foundation models의 개발로 인해, 다양한 모달리티와 추천 과제를 통합하기 위한 다중모달 foundation model(MFM)을 제안한다.
    3. 이를 위해 다중모달 개인화 프롬프트를 도입하고, 경량 어뎁터를 수행하는 매개변수 효율적인 훈련 방법을 제안하여 추천 성능을 향상시킨다.

###### A Spectral Viewpoint on Continual Relation Extraction (https://aclanthology.org/2023.findings-emnlp.645/)
- Anthology ID: 2023.findings-emnlp.645 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자립 관계 추출(CRE)은 새로운 관계 학습하면서 이전에 학습한 관계의 능력을 유지하기 위해 모델을 지속적으로 훈련시킨다. 연속적인 학습 문제에서와 마찬가지로, CRE에서는 학습된 공간이 변화하면서 표현이 변하고 이로 인해 이전 작업의 성능이 저하된다.
    2. 이 논문에서는 이러한 현상을 스펙트럼 관점에서 조명한다. 각 클래스의 형태에 대해, 그것의 고유 벡터(또는 스펙트럼 요소)가 크게 바뀌지 않는다면, 형태는 잘 유지된다는 주요 주장이다.
    3. 이분석을 기반으로, 우리는 단순하면서도 효과적인 클래스별 정규화를 제안하고, 표현 학습에서 고유값을 향상시킨다는 것을 관찰하였다. 실험 결과는 우리의 방법이 상당한 성능 향상을 보였으며, 더 큰 고유값이 더 좋은 성능을 보인다는 가설을 검증한다.

###### Learning to Follow Object-Centric Image Editing Instructions Faithfully (https://aclanthology.org/2023.findings-emnlp.646/)
- Anthology ID: 2023.findings-emnlp.646 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자연어 명령은 텍스트-이미지 확산 모델의 출력을 편집하기 위한 강력한 인터페이스이지만, 암시적 의미를 모델링해야 하는 불명확성, 편집을 수행해야 하는 위치를 찾아야 하는 배정, 편집 명령에 영향을 받지 않는 이미지 요소를 보존해야 하는 충실성과 같은 여러 가지 도전 과제가 있다.
    2. 기존 접근 방식은 자연어 명령을 사용한 이미지 편집에 자동으로 생성된 페어 데이터를 의존하고 있다. 하지만 우리의 조사에서 다루었듯이 이러한 데이터는 노이즈가 많고 때로는 무의미하여 위의 문제를 악화시킨다.
    3. 이 논문에서는 세그멘테이션, Chain-of-Thought prompting, 시각적 질문응답 등 최근의 발전을 활용하여 페어 데이터의 품질을 크게 향상시켰다. 또한, 명령에 의해 변경되어야 하는 이미지 부분을 강조하여 지도신호를 향상시킨다. 개선된 데이터로 fine-tuning된 모델은 최첨단 기준선보다 미세한 객체 중심의 편집을 더 잘 수행하며, 자동 및 인간 평가에서도 위에서 언급한 문제들을 완화시키는 것을 보여준다. 더욱이, 우리의 모델은 시각적 은유와 같은 훈련 중 보지 못한 도메인으로의 일반화도 가능하다.

###### Zero-shot Topical Text Classification with LLMs - an Experimental Study (https://aclanthology.org/2023.findings-emnlp.647/)
- Anthology ID: 2023.findings-emnlp.647 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다양한 large language models의 zero-shot 성능을 비교한 TTC23 데이터셋을 공유한다.
    2. TTC-specialized LMs(fine-tuning)이 벤치마크에서 최고의 성능을 보이며, 해당 코드와 모델은 커뮤니티에서 이용 가능하다.
    3. 본 논문의 결과는 topical text classification에 관심있는 실무자들에게 유용한 가이드가 될 것이다.

###### Are Personalized Stochastic Parrots More Dangerous? Evaluating Persona Biases in Dialogue Systems (https://aclanthology.org/2023.findings-emnlp.648/)
- Anthology ID: 2023.findings-emnlp.648 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 대형 언어 모델은 일반적이거나 특정 인구 집단과 대화에서 역할을 따라 할 수 있게 되었다. 
    2. 이 논문에서는 다음과 같은 persona의 사회적 편향성(“persona biases”)을 연구하며, 이는 대화 모델의 해로운 행동에 대한 민감도로 정의한다.
    3. 우리는 RNA/DNA, harmful expression, harmful agreement, 등 다섯 가지 측면에서 persona 편향을 평가하는 포괄적인 평가 체계를 세우면서, blender, ChatGPT, Alpaca, Vicuna와 같은 네 가지 다른 모델에서 얻은 연구 결과에서 대화 시스템의 중요한 사회적 편향성을 보이며 등장인물(persona)의 사용을 다시 검토할 필요성을 강조한다.

###### A Black-Box Attack on Code Models via Representation Nearest Neighbor Search (https://aclanthology.org/2023.findings-emnlp.649/)
- Anthology ID: 2023.findings-emnlp.649 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 적대적 코드 예시 생성 방법은 대체 변수의 제한된 가용성, 이 대체 변수의 높은 검증 비용, 그리고 주목할 만한 왜곡이 있는 적대적 샘플의 생성과 같은 여러 가지 도전 과제를 가지고 있다. 
    2. 이 논문에서는 RNNS라는 방법론을 제안하며, 과거의 공격을 기반으로 잠재적인 적대적 대체 변수를 찾기 위한 검색 시드를 사용한다. 또한, 이산적인 대체 변수 대신에 미리 훈련된 변수 이름 인코더를 사용하여 연속적인 벡터 공간으로 대체 변수를 매핑한다. 
    3. 실험 결과, RNNS는 ASR과 QT 측면에서 기준모델보다 우수한 성능을 보이며, 대체 변수의 수와 변수 길이 변화 측면에서도 기준모델에 비해 작은 왜곡을 도입한다. 또한, RNNS는 방어된 모델을 공격하는 데 효율적이며 적대적 훈련에 사용될 수 있다는 것을 실험적으로 보여준다.

###### How Well Do Text Embedding Models Understand Syntax? (https://aclanthology.org/2023.findings-emnlp.650/)
- Anthology ID: 2023.findings-emnlp.650 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 텍스트 임베딩 모델은 텍스트 데이터의 의미적 특성을 잘 포착하는 데 기여하였지만, 이러한 모델이 다양한 문법적 문맥에서 일반화를 얼마나 잘하는지는 미처 연구되지 않았다.
    2. 이 논문에서는 구조적 휴리스틱과 개념 간의 관계 이해와 같은 두 가지 중요한 문법적 측면에서 텍스트 임베딩 모델의 문법 이해 능력을 검토하는 평가 세트인 SR을 개발한다.
    3. 기존 텍스트 임베딩 모델은 이러한 문법적 이해 과제를 충분히 해결하지 못했으며, 기존의 벤치마크 데이터셋을 기준으로 평가할 때 이러한 무능력이 더욱 두드러진다는 연구 결과를 밝힌다.

###### CASSI: Contextual and Semantic Structure-based Interpolation Augmentation for Low-Resource NER (https://aclanthology.org/2023.findings-emnlp.651/)
- Anthology ID: 2023.findings-emnlp.651 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 텍스트 augmentation 기법은 NER과 같은 토큰 수준의 작업에서 주석 오염(annotation corruption) 문제로 성능 향상에 어려움을 겪고 있다.
    2. 또한, 기존 방법은 데이터셋에 다양한 문맥의 다양성을 신뢰성 있게 추가할 수 없어서 low-resource NER에 중요한 역할을 하는 것으로 알려진다.
    3. 이 논문에서는 semantic하게 유사한 두 문장을 strucutral하게 결합하여 의미적으로 올바르고 유창한 새로운 문장을 생성함으로써 주석 오염을 피하면서 고품질의 문맥적으로 다양한 augmentation을 생성하는 CASSI (Contextual and Semantic Structure-based Interpolation) 방법을 제안한다.

###### NEWTON: Are Large Language Models Capable of Physical Reasoning? (https://aclanthology.org/2023.findings-emnlp.652/)
- Anthology ID: 2023.findings-emnlp.652 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델(LLM)이 구문, 의미, 단어 의미, 상식적 지식을 포함한 것이 실험적으로 입증되었으나, 일상 객체를 이해하는 데 중요한 속성에 대한 물리적 추론 능력에 대해서는 제한적으로 연구되었다.
    2. 우리는 LLM의 물리적 추론 능력을 평가하기 위한 NEWTON이라는 새로운 저장소와 벤치마크를 소개한다. 또한, 연구자가 해당 응용 분야에 적합한 객체와 속성에 맞게 커스터마이징된 이 벤치마크의 변형을 생성할 수 있도록 파이프라인을 제공한다.
    3. 우리의 결과는 GPT-4와 같은 LLM들이 시나리오 기반 작업에서 강한 추론 능력을 보이지만, 사람과 비교했을 때 객체-속성 추론에서 일관성이 부족함을 보여준다. 또한 NEWTON 플랫폼은 언어 모델의 평가와 향상을 위한 잠재력을 나타내며, 로봇 조작과 같은 물리적으로 기반된 환경에 통합하는 길을 열어준다. Project site: https://newtonreasoning.github.io

###### Beyond Denouncing Hate: Strategies for Countering Implied Biases and Stereotypes in Language (https://aclanthology.org/2023.findings-emnlp.653/)
- Anthology ID: 2023.findings-emnlp.653 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 인터넷 상의 혐오 표현에 대처하기 위한 counterspeech는 인식 조절 (censorship) 없이 문제를 해결하는 인기 있는 방법이 되었으나, 이 격언적인 언어의 동작을 제대로 대처하기 위해서는 잘못된 고정 관념을 전도하고 이를 반박할 수 있는 능력이 필요하다. 
    2. 이 논문에서는 심리학과 철학 문헌에서 영감을 받아, 혐오 언어의 고정관념적 함축을 반박하는 여섯 가지 심리학적인 전략을 제안한다. 
    3. 실험결과에서는, 인간이 직접 작성한 counterspeech가 함축된 고정관념에 맞추어 구체적으로 반박하는 전략을 사용하는 반면, 기계 생성 counterspeech는 일반적으로 혐오 언어의 비인간성을 부인하는 전략을 사용한다.

###### On the Calibration of Large Language Models and Alignment (https://aclanthology.org/2023.findings-emnlp.654/)
- Anthology ID: 2023.findings-emnlp.654 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델은 많은 관심을 받고 널리 적용되고 있지만 신뢰성과 관련된 동시에 문제점들이 발생하고 있다.
    2. 우리는 신뢰성 평가를 위한 confidence calibration을 사용하여 deep model의 신뢰성을 측정하고 개선하는 중요한 도구로서의 역할을 연구하였다.
    3. 우리의 연구는 popular LLMs가 잘 캘리브레이션되어 있는지, 그리고 훈련 과정이 모델의 캘리브레이션에 어떤 영향을 미치는지에 대해 조명한다.

###### TCRA-LLM: Token Compression Retrieval Augmented Large Language Model for Inference Cost Reduction (https://aclanthology.org/2023.findings-emnlp.655/)
- Anthology ID: 2023.findings-emnlp.655 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. ChatGPT와 같은 큰 언어 모델의 인기가 증가함에 따라 기업들은 이 모델을 사용한 다양한 응용프로그램을 개발하고 있다. 이 논문에서는 사용자 쿼리에 대한 맥락 기반 학습 능력을 활용하여 지식 검색으로 얻은 정보를 활용해 응답을 생성하는데, 이때 발생하는 입력 토큰 크기 증가 문제를 해결하기 위해 압축 방법을 제안한다.
    2. 제안된 방법은 요약 압축과 의미 압축으로 구성된다. 요약 압축은 T5 기반 모델을 사용하여 다양한 길이의 샘플을 포함하는 데이터셋을 이용해 미세조정하고 요약을 통해 토큰 크기를 줄이는 방법이다. 의미 압축은 의미에 덜 영향을 미치는 단어를 제거하여 토큰 크기를 더욱 줄이는 방법이다.
    3. 제안된 방법들의 효과를 적절히 평가하기 위해, 임신 기간이나 영유아를 위한 음식 추천에 초점을 맞춘 FRDB라는 데이터셋을 제안하고 활용한다. 요약 압축은 토큰 크기를 65% 감소시키면서 정확성을 0.3% 향상시킬 수 있으며, 의미 압축은 토큰 크기를 20% 줄일 수 있는데 정확성은 1.6% 감소한다.

###### Identifying Conspiracy Theories News based on Event Relation Graph (https://aclanthology.org/2023.findings-emnlp.656/)
- Anthology ID: 2023.findings-emnlp.656 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사회적 미디어 짧은 텍스트에서는 여론이론이 다루어졌으나, 긴 뉴스 문서에서의 이러한 잘못된 정보에는 제한적인 관심이 있었다. 
    2. 이 논문에서는 뉴스 기사가 여론 이론을 포함하고 있는지 여부를 파악하는 것을 목표로 한다. 
    3. 이를 위해 각 기사에 이벤트 관계 그래프를 도입하여 여론 이론 식별에 필수적인 이야기의 문맥적 이해를 달성하고, 이벤트 관계 그래프를 이용하여 여론 이론 식별의 정확도와 재현율을 향상시키는 방법을 제안한다.

###### Salespeople vs SalesBot: Exploring the Role of Educational Value in Conversational Recommender Systems (https://aclanthology.org/2023.findings-emnlp.657/)
- Anthology ID: 2023.findings-emnlp.657 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 구매를 하려면 소비자는 도메인 지식을 습득하기 위해 연구하거나 판매원에게 상담을 해야하지만, 기존의 대화형 추천 시스템은 사용자의 배경 지식 부족을 간과하고 선호도만을 중점으로 한다.
    2. 이 논문에서는 제품 추천과 교육적 가치를 혼합한 대화형 에이전트를 위한 새로운 문제 공간을 정의한다.
    3. SalesOps라는 프레임워크를 소개하고, SalesBot과 ShopperBot을 소개하여 이러한 시스템을 시뮬레이션하고 평가할 수 있도록 한다.

###### Dynamic Open-book Prompt for Conversational Recommender System (https://aclanthology.org/2023.findings-emnlp.658/)
- Anthology ID: 2023.findings-emnlp.658 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Conversational Recommender System (CRS)은 대화형 대화를 통해 맞춤형 추천을 제공하고 있으나, 기존 방법들은 진행 중인 대화의 제한된 문맥에 의해 성능이 제한된다. 
    2. 이 논문에서는 Dynamic Open-book Prompt 접근법을 제안하여 학습 데이터를 추론 중에 참고할 수 있는 도구를 만들어 문맥의 한계를 해결한다.
    3. 실험 결과, 제안된 모델이 기존의 최신 방법보다 향상된 성능을 보여주었다.

###### Auto-Instruct: Automatic Instruction Generation and Ranking for Black-Box Language Models (https://aclanthology.org/2023.findings-emnlp.659/)
- Anthology ID: 2023.findings-emnlp.659 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델(LLMs)은 과제별 세부 조정이 필요하지 않고 자연어 명령에 따라 다양한 작업을 수행할 수 있지만, LLM의 성능은 명령어의 품질에 크게 영향을 받으며, 각 작업용 효과적인 명령어를 수동으로 작성하는 것은 번거롭고 주관적인 과정이다.
    2. 본 논문에서는 LLM에 제공되는 명령어의 품질을 자동으로 향상시키는 새로운 방법인 Auto-Instruct를 소개한다. 이 방법은 LLM의 생성 능력을 활용하여 주어진 작업에 대해 다양한 후보 명령어를 생성하고, 575개의 기존 NLP 작업을 사용하여 훈련된 점수 모델을 사용하여 순위를 매긴다.
    3. 118개의 비 관련 작업에 대한 실험에서, Auto-Instruct가 사람이 작성한 명령어와 기존 LLM 생성 명령어에 비해 뛰어나며, 훈련 과정에 통합되지 않은 다른 LLM에 대해서도 주목할만한 일반화 능력을 보인다.

###### DiffuSeq-v2: Bridging Discrete and Continuous Text Spaces for Accelerated Seq2Seq Diffusion Models (https://aclanthology.org/2023.findings-emnlp.660/)
- Anthology ID: 2023.findings-emnlp.660 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Diffusion 모델은 고품질의 텍스트 시퀀스를 생성하는 데 중요한 역할을 한다. 그러나 현재의 방법은 주로 연속적인 diffusion 공간에서 이산적인 텍스트를 나타내는데, 이로 인해 훈련 중에 상당한 계산 오버헤드가 발생하고 샘플링 속도가 느려진다. 이 논문에서는 이산적인 변이를 재구성하는 데 도움이 되는 소프트 흡수 상태를 도입하여 diffusion 모델이 기반이 되는 가우시안 공간을 기반으로 학습을 강화하고 조건부 신호를 복원하는 능력을 향상시킨다."
    2. "샘플링 단계에서는 최신 ODE 솔버를 사용하여 연속적인 공간에서 샘플링 과정을 가속화한다. 포괄적인 실험 평가 결과, 우리의 제안된 방법은 훈련 수렴 속도를 4배 빠르게하며, 같은 품질의 샘플을 800배 더 빠르게 생성하여 실제 적용에 크게 다가갈 수 있도록 한다."

###### M2C: Towards Automatic Multimodal Manga Complement (https://aclanthology.org/2023.findings-emnlp.661/)
- Anthology ID: 2023.findings-emnlp.661 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 멀티모달 만화 분석은 시각적 특징과 텍스트 특징을 통해 만화 이해를 개선하는데 초점을 맞추고 있으며, 이는 자연어 처리와 컴퓨터 비전 커뮤니티 모두에서 큰 주목을 받고 있다.
    2. 현재 대부분의 만화는 손으로 그리고, 누락된 페이지, 텍스트 오염, 텍스트 나이 등의 문제가 발생하여 만화 텍스트 내용이 누락되고 인간의 이해를 심각하게 방해하는 문제가 있다.
    3. 이 논문에서는 비전과 언어 이해를 위한 공유 의미 공간을 제공함으로써 이러한 문제를 해결하는 멀티모달 만화 보완(M2C) 과제를 제안하고, MCoT라는 만화 인식 방법과 FVP-M2라는 효과적인 베이스라인 방법을 설계한 후, 대규모 다국어 데이터셋을 이용한 실험을 통해 FVP-M2의 효과를 입증하였다.

###### Learn Your Tokens: Word-Pooled Tokenization for Language Modeling (https://aclanthology.org/2023.findings-emnlp.662/)
- Anthology ID: 2023.findings-emnlp.662 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 언어 모델은 일반적으로 문자들을 결합하여 'ing'과 같은 긴 표면 문자열 또는 완전한 단어로 구성하는 결정론적이고 수동형 휴리스틱 방식으로 텍스트를 서브워드로 토큰화한다. 기존 토큰화 전략의 한계점이 특히 영어 이외의 언어로 작성된 문서와 숫자 표현에 대해 반복적으로 확인되었다.
    2. 본 논문에서는 '자신만의 토큰 학습' 방법을 고려하여 단어 경계를 활용하여 바이트/문자를 단어 표현으로 결합하고, 이 표현을 넣고 기본 언어 모델에 다시 개별 문자/바이트를 병렬적으로 디코딩하는 방식을 제안한다.
    3. 실험 결과, 우리의 중간 표현의 토크나이저는 인쇄된 언어 모델링 메트릭인 다음 단어 예측에서 서브워드 및 바이트/문자 모델보다 300% 이상의 성능을 보이며, 특히 희귀한 단어에서는 30배 이상의 성능을 보인다고 밝혀졌다.

###### Towards Detecting Contextual Real-Time Toxicity for In-Game Chat (https://aclanthology.org/2023.findings-emnlp.663/)
- Anthology ID: 2023.findings-emnlp.663 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 실시간 독성 감지는 소셜 미디어와 게임 플랫폼의 증가로 인해 큰 도전이다. 우리는 ToxBuster라는 간단하고 확장 가능한 모델을 제시하며, 이 모델은 대화 내용과 메타데이터를 포함하여 실시간으로 독성 콘텐츠를 신뢰할 수 있게 감지한다. 
    2. ToxBuster는 Rainbow Six Siege, For Honor, DOTA 2를 포괄하는 인기 멀티플레이어 게임에서 기존 독성 모델보다 일관되게 우수한 결과를 보여준다. 
    3. 우리는 각 모델 구성 요소의 중요성을 평가하고 데이터셋 간의 ToxBuster의 전이성을 탐색하기 위해 연구를 수행했다. 또한, 우리는 ToxBuster가 게임 후 모더레이션에서 효과적이며, 90.0% 수준의 정확도로 82.1%의 채팅 신고된 플레이어를 탐지하는 것을 보여준다. 추가로, 신고되지 않은 독성 플레이어의 6%를 사전적으로 제한할 수 있는 방법도 제시한다.

###### JWSign: A Highly Multilingual Corpus of Bible Translations for more Diversity in Sign Language Processing (https://aclanthology.org/2023.findings-emnlp.664/)
- Anthology ID: 2023.findings-emnlp.664 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 수화 처리의 진보는 충분한 데이터의 부족으로 막혀, 인식, 번역 및 제작 작업의 발전이 방지되고 있다. 
    2. 우리는 수화 번역을 위한 새로운 대규모 다국어 데이터셋인 JWSign을 소개한다. 이 데이터셋은 98개의 수화 언어로 된 2,530 시간의 성경 번역을 포함하며, 1,500명 이상의 개별 수화사가 참여했다.
    3. 우리의 실험은 다국어 시스템이 양언 언어 기준 모델보다 뛰어나며, 고자원 시나리오에서 관련된 언어로 언어 쌍을 클러스터링하면 번역 품질이 향상됨을 보여준다.

###### Do Stochastic Parrots have Feelings Too? Improving Neural Detection of Synthetic Text via Emotion Recognition (https://aclanthology.org/2023.findings-emnlp.665/)
- Anthology ID: 2023.findings-emnlp.665 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "최근 발전된 생성 AI 기술은 고성능의 합성 텍스트 생성 기술에 초점을 맞추고 있다. 이제 이러한 모델이 광범위하게 이용 가능하고 사용이 용이해졌으므로 합성 텍스트를 인식할 수 있는 동등한 강력한 기술을 제공하는 것이 긴요하다."
    2. "우리는 심리학적 연구에서 영감을 받아 사람들이 감정에 영향을 받고 글을 쓸 때 감정을 담을 수 있다는 것을 제안하였다."
    3. "우리의 연구 결과는 우리의 감정인식 기반의 합성 텍스트 감지기가 다양한 합성 텍스트 생성기, 모델 크기, 데이터셋 및 도메인에서 시사하는 개선을 달성하였으며, ChatGPT와 비교했을 때도 상당한 성과를 나타내어 감정이 합성 텍스트를 식별하는 신호로 높은 잠재력을 보여주었다."

###### Variator: Accelerating Pre-trained Models with Plug-and-Play Compression Modules (https://aclanthology.org/2023.findings-emnlp.666/)
- Anthology ID: 2023.findings-emnlp.666 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델(Large language model, LLM)는 NLP 태스크에서 놀라운 결과를 보여주었지만, 매우 큰 파라미터 크기와 이로 인한 계산 비용이 문제가 되었다. 
    2. 이 논문에서는 Variator라는 파라미터 효율적인 가속 방법을 제안하는데, compressible 플러그인을 사용하여 계산 효율성을 향상시킨다. 
    3. Variator는 53%의 계산 비용을 절약할 수 있으며, 성능 저하는 2% 미만이며, 수십억 개의 파라미터로 확장될 때 압축되지 않은 LLM의 강력한 성능을 보인다.

###### PivotFEC: Enhancing Few-shot Factual Error Correction with a Pivot Task Approach using Large Language Models (https://aclanthology.org/2023.findings-emnlp.667/)
- Anthology ID: 2023.findings-emnlp.667 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Factual Error Correction (FEC)은 성의 없는 주장을 수정하여 지원하는 증거와 더 정확하게 일치시키는 것을 목표로한다. 그러나 거짓 주장과 그에 대한 수정 내용을 포함하는 데이터셋 부족으로 인해 이 분야의 발전이 지연되고 있다.
    2. 기존의 method들은 오류를 식별하는게 어렵기 때문에, 잘못된 에러 마스킹 문제 등 문제점이 발생한다. 이러한 도전을 극복하기 위해, 우리는 PivotFEC이라는 새로운 방법을 제안한다.
    3. PivotFEC은 대형 언어 모델을 활용하여 몇 가지 표본과 함께 FEC를 향상시키는 pivot task 접근 방식을 적용한다. PivotFEC은 널리 사용되는 SARI 메트릭을 개선하고, FEC에 직접적으로 LLM을 사용한 few-shot 대안보다 7.9 점 높은 SARI로 성능을 향상시키는 것을 실험을 통해 입증한다.

###### Semantic Similarity Covariance Matrix Shrinkage (https://aclanthology.org/2023.findings-emnlp.668/)
- Anthology ID: 2023.findings-emnlp.668 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다양한 금융 응용프로그램, 특히 포트폴리오 최적화에는 공분산 행렬의 정확한 추정이 필수적이다. 그러나 변수의 수와 관측치의 수가 비슷하거나 적을 때 샘플 공분산은 차원의 저주 문제(dimensionality curse)를 겪는다.
    2. 이 문제를 해결하기 위해 이전 작업에서는 추정된 행렬을 정규화하기 위해 선형 공분산 shrinkage를 제안했다. 하지만 제안된 방법들은 오로지 과거 가격 데이터만을 사용하여 기업의 기본 데이터를 무시한다.
    3. 본 논문에서는 텍스트 설명이나 지식 그래프에서 파생된 의미적 유사성을 활용하여 공분산 추정을 개선하기를 제안한다. 의미적 유사성을 정확한 추정자(biased estimator)로 사용하는 대신 수축(shrinkage) 대상으로 활용한다. 결과적으로 얻어지는 공분산 추정기는 의미적 유사성과 최근 가격 이력을 모두 활용하며, 다양한 금융 자산에 적용할 수 있다. 이 접근 방식의 효과는 다양한 시장 조건을 포함하는 기간에 대해 증명되었으며, 기존의 공분산 shrinkage 기법과 비교되었다.

###### LLM-in-the-loop: Leveraging Large Language Model for Thematic Analysis (https://aclanthology.org/2023.findings-emnlp.669/)
- Anthology ID: 2023.findings-emnlp.669 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 주제 분석(Thematic analysis, TA)은 많은 학문 분야에서 질적 데이터를 분석하는 데 널리 활용되고 있다. 그러나 신뢰할 수 있는 분석을 위해 동일한 데이터를 최소 두 명의 인간 코더에게 할당하는 것은 일반적이다. 
    2. 이 논문은 큰 언어 모델(Large Language Model, LLM)을 활용하여 TA를 수행하는 인간-LLM 협업 프레임워크를 제안하였다. 이 프레임워크는 LLM과의 상호작용을 통해 논의를 구성하고 TA를 위한 최종 코드북을 생성한다.
    3. 이 프레임워크는 음악 청취 경험과 비밀번호 관리자 사용과 같은 설문 데이터를 사용하여 유용성을 입증하였으며, 결과적으로 인간 코더의 분석 품질을 유지한 채 TA의 노동량과 시간을 줄일 수 있다.

###### LLM aided semi-supervision for efficient Extractive Dialog Summarization (https://aclanthology.org/2023.findings-emnlp.670/)
- Anthology ID: 2023.findings-emnlp.670 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화 형식에서 요약을 생성하는 경우, 대규모 라벨이 부여된 데이터셋이 필요하다. 이 논문에서는 라벨이 없는 데이터를 효율적으로 사용하여 고객-에이전트 대화의 추출 요약을 수행하는 방법을 제안한다.
    2. 먼저 요약을 질문-답변 문제로 정의하고, 대화에 대한 가짜 라벨을 대량의 언어 모델을 사용하여 생성한다. 그런 다음 이러한 가짜 라벨을 사용하여 대화 요약 모델을 미세 조정하여 대량의 언어 모델의 지식을 작은 전문 모델로 전달한다.
    3. 실험 결과로 TWEETSUMM 데이터셋에 대해 10%의 라벨이 달린 원본 데이터를 사용하여 ROUGE-1/-2/-L 값이 각각 65.9/57.0/61.0을 달성할 수 있었다. 전체 훈련 데이터셋에 대해 훈련된 최첨단 모델은 ROUGE-1/-2/-L에 각각 65.16/55.81/64.37를 달성하는데, 즉 최악의 경우(ROUGE-L)에도 10%의 데이터만 사용하여 성능을 94.7% 효과적으로 유지하는 것을 확인했다.

###### Investigating Multilingual Coreference Resolution by Universal Annotations (https://aclanthology.org/2023.findings-emnlp.671/)
- Anthology ID: 2023.findings-emnlp.671 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다국어 핵심 지시어 해결(MCR)은 오랜 기간 동안 도전적인 작업이었다. 이 논문에서는 새로운 다국어 핵심 지시어 데이터 셋인 CorefUD를 사용하여 핵심 지시어 작업에 대해 조사한다.
    2. 우선, 언어 수준에서 다양한 말, 개체 및 문서 수준의 데이터를 조사하여 여러 언어에서 핵심 지시어의 특성을 파악한다.
    3. 또한, CRAC 2022 공유 작업에서 고도의 힘들다고 평가된 문제들을 유니버설 어노테이션을 사용하여 오류 분석하고, 이 분석을 기반으로 유니버설 형태-통사론 어노테이션에서 특징을 추출하여 MCR 작업에 대한 잠재적 이점을 평가한다.

###### FactSpotter: Evaluating the Factual Faithfulness of Graph-to-Text Generation (https://aclanthology.org/2023.findings-emnlp.672/)
- Anthology ID: 2023.findings-emnlp.672 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 그래프를 입력받아 그래프 안의 정보에 대한 자연스럽고 충실한 텍스트로 변환하는 Graph-to-Text(G2T) 생성은 대화 생성, 질문응답 등 다양한 응용 분야가 있다. 
    2. 기존 데이터셋에 대해서 G2T 생성 문제가 어느 정도 해결되었는지와 제안된 메트릭이 생성된 텍스트를 비교할 때 어떻게 작동하는지를 조사한다. 
    3. 이 논문에서는 사실적 충실성(factual faithfulness)을 올바르게 인식하는 새로운 메트릭 FactSpotter를 제안하여 데이터 정확성, 데이터 커버리지, 일치성 등에 대한 인간 주석과 가장 높은 상관관계를 보여준다.

###### LayoutDIT: Layout-Aware End-to-End Document Image Translation with Multi-Step Conductive Decoder (https://aclanthology.org/2023.findings-emnlp.673/)
- Anthology ID: 2023.findings-emnlp.673 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이미지 안의 텍스트를 한 언어에서 다른 언어로 번역하는 Document Image Translation (DIT)은 시각적 레이아웃과 텍스트 의미를 동시에 이해해야 하는 어려운 과제이다. 그러나 기존 방법들은 실제 복잡한 문서 이미지에서 중요한 시각적 레이아웃을 포착하기 어려워한다.
    2. 논문에서는 DIT에 시각적 레이아웃 지식을 최초로 end-to-end 방식으로 통합하는 시도를 한다. 레이아웃을 고려한 인코더와 다단계의 conductive 디코더를 사용하여 문서 번역을 순차적으로 단계별로 수행한다.
    3. 실험 결과, LayoutDIT는 기존 방법들보다 더 나은 parameter efficiency와 함께 우수한 일반화 성능을 보여준다. 또한 다양하고 복잡한 레이아웃 환경에서도 좋은 일반화 능력을 갖고 있다는 것을 검증하기 위해 새로운 다중 도메인 문서 이미지 번역 데이터셋을 제작하였다.

###### Balaur: Language Model Pretraining with Lexical Semantic Relations (https://aclanthology.org/2023.findings-emnlp.674/)
- Anthology ID: 2023.findings-emnlp.674 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 의미적 관계 (LSR)는 단어들 간의 의미적인 관계를 특징짓고 어휘 추론 태스크에서 체계적인 일반화에 중요한 역할을 한다. 
    2. 기존의 사전 훈련 언어 모델 (LMs)은 hypernymy의 지식이 필요한 여러 태스크에서 여전히 어려움을 겪고 있으며, LSR의 언어적 행동과의 일치를 더 잘하기 위해 개선이 필요하다. 
    3. 이 논문에서는 모델이 사전 훈련 과정에서 LSR을 직접적으로 모델링하여 이 도전에 대처하는 Balaur 모델을 제안한다.

###### Exploring In-Context Learning for Knowledge Grounded Dialog Generation (https://aclanthology.org/2023.findings-emnlp.675/)
- Anthology ID: 2023.findings-emnlp.675 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화 생성 모델은 현실적인 시나리오에서 널리 쓰이지만, 환각과 사실적으로 부정확한 출력을 생성하는 경향이 있어 큰 우려를 불러일으킨다. 이를 해결하기 위해 우리는 IKA라는 플러그 앤 플레이 검색 기반 프레임워크를 제안하며, 이는 인과 관계를 기반으로한 지식 대화 생성을 위해 인콘텍스트 학습과 검색 기술을 활용한다.
    2. 우리는 1백만 가지 이상의 사실을 포함하는 대규모 지식 그래프를 사용하여 우리의 프레임워크의 효과와 일반화 능력을 조사하기 위해 철저한 실험을 설계했다.
    3. 실험 결과, 우리의 방법은 이전의 훈련 기반 최고 성능을 큰 폭으로 개선하였으며, 특히 BLEU4에서 46.67%, ROUGE-L에서 26.01%, BARTScore에서 122.90%, 그리고 엔터티 커버리지 F1에서 30.50%의 성능 향상을 보였다. 추가적인 분석은 LLM이 지식탄력적인 작업을 수행하는 능력을 보여주었고, 이는 이전에 약하고 잘 연구되지 않았던 부분이다.

###### Towards Enhancing Relational Rules for Knowledge Graph Link Prediction (https://aclanthology.org/2023.findings-emnlp.676/)
- Anthology ID: 2023.findings-emnlp.676 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 지식 그래프 추론에 대한 GNN 모델인 PRGNN은 관계 규칙을 이용해 관계형 다이그래프에서 누락된 지식을 추론하고, 상당한 성능을 보였다. 그러나 PRGNN의 추론 과정에서 순차적 관계 조합과 정보 전파 속도의 차이 등 두 가지 중요한 특성이 간과되어 관계 규칙 학습의 정확도가 저하된다.
    2. 따라서 이 문제를 해결하기 위해, 우리는 새로운 지식 그래프 추론 방법인 RUN-GNN을 제안한다. RUN-GNN은 순차적 관계 조합을 모델링하기 위한 쿼리 관련 퓨전 게이트 유닛과 정보 전파 지연의 부정적인 영향을 완화하기 위한 버퍼링 업데이트 메커니즘을 사용하여 관계 규칙 학습의 품질을 향상시킨다.
    3. 다양한 데이터셋에서의 실험 결과, RUN-GNN이 전이적 및 귀납적 링크 예측 작업에서 우수한 성능을 보였음을 확인할 수 있다.

###### Are NLP Models Good at Tracing Thoughts: An Overview of Narrative Understanding (https://aclanthology.org/2023.findings-emnlp.677/)
- Anthology ID: 2023.findings-emnlp.677 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. narrative understanding은 작가의 인지 과정을 이해하는 것으로, 글의 문법적 일관성을 유지하는 것 이외에 작가의 사고를 이해하는 능력이 매우 제한적이다.
    2. 본 논문에서는 narrative understanding 태스크에 대한 종합적인 조사를 진행하고, 그들의 특징, 정의, 분류, 관련 데이터셋, 훈련 목표, 평가 지표 및 제한 사항에 대해 상세히 조사한다.
    3. 또한, 우리는 모듈화된 큰 언어 모델이 새로운 narrative understanding 태스크를 해결하기 위한 잠재력을 탐구하며, narrative 이해를 향상시키기 위한 새로운 관점을 제시한다.

###### Who is Speaking? Speaker-Aware Multiparty Dialogue Act Classification (https://aclanthology.org/2023.findings-emnlp.678/)
- Anthology ID: 2023.findings-emnlp.678 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화에서 발화는 독립적으로 발생하지 않으며 발화자가 누구인지에 대한 정보를 가져야 주변 문맥을 통해 발화자의 의도를 파악할 수 있다. 이 논문에서는 발화자의 인식을 각 발화 표현에 명시적으로 추가하고, 발화자가 대화 내에서 어떻게 상호작용하는지를 모델링하는 그래프 신경망을 사용하여 발화자 표현을 학습한다. 
    2. 이를 통해 발화자 표현을 사용하여 대화 표현을 업데이트하고, MRDA와 SwDA 데이터셋에서 여러 인터락터가 참여하는 대화와 이중 대화에 대해 실험을 진행하고, 우리의 접근법의 효과를 보여준다.
    3. 다중 참여자 대화에서 대화 흐름을 이해하는 데 발화자 인식이 중요한 역할을 하며, 그래프 신경망을 사용한 발화자 모델링은 이를 성공적으로 해결할 수 있는 효과적인 방법이다.

###### Demystifying Prompts in Language Models via Perplexity Estimation (https://aclanthology.org/2023.findings-emnlp.679/)
- Anthology ID: 2023.findings-emnlp.679 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "언어 모델은 zero-shot과 few-shot in-context learning으로 다양한 작업을 수행할 수 있다. 그러나 성능은 프롬프트의 선택에 따라 크게 달라지고, 그 이유를 아직 이해하지 못하고 있다."
    2. "우리는 이 논문에서 이러한 변동성에 기여하는 요소들에 대해 분석하고, 새로운 경험적 가설을 수립한다: 프롬프트의 성능은 모델이 그 언어에 익숙한 정도에 따라 예측된다."
    3. "우리는 다양한 작업들을 통해, 합리적인 프롬프트에 대해 관련이 있는 경우, 프롬프트의 퍼플렉서티가 낮을수록 작업을 더 잘 수행할 수 있다는 것을 보여준다."

###### C2D2 Dataset: A Resource for the Cognitive Distortion Analysis and Its Impact on Mental Health (https://aclanthology.org/2023.findings-emnlp.680/)
- Anthology ID: 2023.findings-emnlp.680 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 인식 왜곡(Cognitive distortions)은 비이성적인 사고의 패턴으로, 현실의 왜곡된 인식과 정신 건강 문제로 이어질 수 있다. 
    2. 이 논문에서는 첫 번째 전문가 지도 중국어 "Cognitive Distortion Dataset"을 소개하며, 일상생활에서 7,500개의 인식 왜곡에 대한 감상을 담고 있다. 
    3. 또한, 정신장애 진단을 받은 개인들이 공유한 소셜 미디어 텍스트에서도 인식 왜곡의 존재를 검토하여, 인식 왜곡과 정신건강 상태의 연관성을 제시한다.

###### MixEdit: Revisiting Data Augmentation and Beyond for Grammatical Error Correction (https://aclanthology.org/2023.findings-emnlp.681/)
- Anthology ID: 2023.findings-emnlp.681 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "데이터 부족 문제 해결을 위해 데이터 증강은 문법 오류 교정(GEC) 분야에서 효과적으로 입증되었다. 그러나 이러한 전략들이 효과적인 이유는 여전히 잘 이해되지 않았다."
    2. "따라서 이 연구에서는 데이터 증강이 GEC 모델을 어떻게 개선하는지 명확히 설명하고자 한다."
    3. "Affinity와 Diversity 두 개의 계산적으로 효율적인 척도를 도입하여 좋은 GEC 데이터 증강 전략이 모델 성능을 향상시킬 수 있음을 밝혀냈다."

###### CCEval: A Representative Evaluation Benchmark for the Chinese-centric Multilingual Machine Translation (https://aclanthology.org/2023.findings-emnlp.682/)
- Anthology ID: 2023.findings-emnlp.682 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 국제 비즈니스 개발과 문화 교류의 증가로 인해 중국 중심의 다국어 기계 번역의 중요성이 커졌으나, 이 분야의 발전을 제한하는 중요한 요소는 대표성과 품질이 높은 평가 벤치마크의 부족이다. 
    2. CCEval은 중립적이고 대표적인 중국 중심 다국어 기계 번역 평가 데이터셋으로 이 사각지대를 채우기 위해 소개되었다. 
    3. 이 데이터셋은 2500개의 중국어 문장으로 구성되어 있으며, 다른 다국어 기계 번역 평가 벤치마크보다 다양한 언어적 특징을 포함하고 있다고 주장한다.

###### ROME: Evaluating Pre-trained Vision-Language Models on Reasoning beyond Visual Common Sense (https://aclanthology.org/2023.findings-emnlp.683/)
- Anthology ID: 2023.findings-emnlp.683 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 인류는 일반적인 상식을 넘어서는 추론 능력을 가지고 있다. 그러나 진행중인 비전-언어 모델은 비직관적인 시나리오에 대해서도 일반적인 상황을 선호하기 때문에 이런 능력을 가지지 못한다.
    2. 본 논문에서는 최신 사전 훈련된 비전-언어 모델이 비직관적인 콘텐츠를 올바르게 해석하는 추론 능력을 가지고 있는지 평가하기 위해 ROME라는 새로운 프로빙 데이터셋을 소개한다.
    3. 최신 사전 훈련된 비전-언어 모델 실험은 대부분 이러한 모델이 여전히 비직관적인 시나리오를 해석하는 능력이 크게 부족하다는 것을 보여준다. 이를 통해 ROME은 비전-언어 연구에서 일반적인 상식 지식을 넘어서는 추론 능력에 대한 추가적인 연구를 촉진할 것을 기대한다.

###### Automatic Analysis of Substantiation in Scientific Peer Reviews (https://aclanthology.org/2023.findings-emnlp.684/)
- Anthology ID: 2023.findings-emnlp.684 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 인공지능 학회에서 문제가 되는 동료 리뷰 문제가 증가함에 따라, 자동 품질 관리 방법이 긴요하게 필요합니다. 
    2. 이 논문에서는 품질 측면 중 하나인 '전증' 을 알고리즘으로 평가하기 위한 방법을 제안합니다. 
    3. 이를 위해 claim-evidence 쌍을 추출하기 위한 문제로 정의하고, 이 작업을 위한 첫 번째 주석이 달린 데이터 세트인 SubstanReview를 수집하고, 이 데이터를 기반으로 인수 광산 시스템을 훈련시킵니다.

###### Hierarchical Prompting Assists Large Language Model on Web Navigation (https://aclanthology.org/2023.findings-emnlp.685/)
- Anthology ID: 2023.findings-emnlp.685 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델(LLM)은 상호작용적 의사 결정에서 복잡한 관측을 처리하는 데 어려움을 겪는다. 이 문제를 완화하기 위해, 우리는 간단한 계층적 프롬프팅 접근법을 제안한다.
    2. 우리의 방법은 이전의 프롬프팅 접근법과 다르게 항상 전체 관측 자료(웹 페이지)를 프롬프트에 넣는 대신 별도의 Summarizer 프롬프트와 관련성이 높은 액션-다방향 관측을 먼저 구축하는 것을 제안한다.
    3. 우리의 방법은 웹 탐색과 같이 전체 관찰에는 중복되고 관련 없는 정보가 많은 복잡한 도메인에서 뛰어난 성과를 보여준다. 우리의 접근법은 동일한 LLM을 기반으로 한 이전의 최첨단 프롬프팅 메커니즘보다 작업 성공률에서 6.2%의 향상을 보여주며, 긴 관측 트레이스를 가진 상호작용적 의사 결정 과제에서의 잠재력을 보여준다.

###### Can Large Language Models Fix Data Annotation Errors? An Empirical Study Using Debatepedia for Query-Focused Text Summarization (https://aclanthology.org/2023.findings-emnlp.686/)
- Anthology ID: 2023.findings-emnlp.686 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Debatepedia는 논란이 있는 주제에 대한 주장과 반대 주장으로 이루어진 공개 데이터셋으로, 최근 단일 문서 질의 중심의 의미 요약 작업에 널리 사용되고 있다. 그러나 최근 이 데이터셋은 noise에 의해 제한되고 있으며, 대부분의 질의는 해당 문서와 관련이 없다는 것이 밝혀졌다.
    2. 본 연구에서는 대규모 언어 모델 (large language models, LLMs)이 Debatepedia 데이터셋을 정제하는 데 사용될 수 있는지 조사한다. ChatGPT와 PaLM이라는 두 개의 LLM의 언어 생성 능력을 활용하여 쿼리를 재생성한다.
    3. 실험 결과, 쿼리 교정에 있어서 대규모 언어 모델에만 의존하는 것은 데이터 정제에 그다지 유용하지 않을 수 있다는 것을 발견했다. 그러나 룰 기반 접근법을 활용하여 데이터 샘플링을 한 다음 LLMs (특히 ChatGPT)를 사용하여 재생성할 경우, 보다 일반적인 쿼리 중심 텍스트 요약 모델의 개발에 적합한 더 우수한 품질의 데이터셋을 얻을 수 있다는 것을 관찰했다.

###### TSTR: Target Similarity Tuning Meets the Real World (https://aclanthology.org/2023.findings-emnlp.687/)
- Anthology ID: 2023.findings-emnlp.687 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Target similarity tuning (TST)은 대형 언어 모델을 통해 자연어에서 코드 생성으로 관련 예제를 선택하여 성능을 향상시키는 방법이다. 이 논문에서는 실제 세계에서 TST를 적용하고 개선하기 위한 다양한 방법을 제안한다.
    2. 우리는 문장 변형기 (sentence transformer)를 더 큰 모델의 임베딩으로 대체하여 언어 분포에 대한 민감도를 줄이고, 합성적 예제 생성에 더 많은 유연성을 제공한다. 또한, 이러한 임베딩을 코드 유사성과 일치하도록 변환하는 작은 모델을 훈련시켜, 모델이 블랙 박스로 남아 있고 추론 시간에서 몇 가지 행렬 곱셈만 필요하도록 한다.
    3. 마지막으로, TST 모델을 훈련시키기 위해 효율적으로 작은 수의 훈련 예제를 선택하는 방법과 코드 생성 실험 없이도 TST를 평가하는 랭킹 기반 평가 방법을 도입한다.

###### RealBehavior: A Framework for Faithfully Characterizing Foundation Models’ Human-like Behavior Mechanisms (https://aclanthology.org/2023.findings-emnlp.688/)
- Anthology ID: 2023.findings-emnlp.688 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 인간과 유사한 행동을 파악하기 위해 심리학적 이론을 사용하는 연구가 증가하고 있으나, 이러한 이론의 결과의 충실성을 검증하지 않고 직접적으로 적용하는 경향이 있다. 
    2. 이 논문에서는 RealBehavior라는 프레임워크를 소개하여 모델의 인간형 행동을 충실하게 특성화하는 방법을 제안한다. 
    3. 우리의 연구 결과는 심리학적 도구의 단순한 적용이 모든 인간형 행동을 충실하게 특성화할 수 없음을 시사하며, 모델을 인간과 사회적 가치와 조화되게 정렬하는 영향과 제한된 특성을 갖는 모델의 생성을 방지하기 위해 다양한 정렬 목표의 필요성을 논의한다.

###### Unraveling Downstream Gender Bias from Large Language Models: A Study on AI Educational Writing Assistance (https://aclanthology.org/2023.findings-emnlp.689/)
- Anthology ID: 2023.findings-emnlp.689 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델(LLM)은 학생들에게 작문 제안을 제공하는 등 교육적인 과제에 점점 더 활용되고 있다. 하지만, LLM에는 학습자에게 부정적인 영향을 줄 수 있는 내재적인 편향이 존재한다. 이 논문에서는 LLM의 편향이 인간의 작문에 어떻게 영향을 미치는지 조사하였다.
    2. 231명의 학생들이 회사 사례 피어 리뷰를 작성하도록 한 대규모 사용자 연구를 수행하였고, 작문 지원의 다양한 단계에서 성향 편향을 평가하였다. 결과적으로, LLM 제안이 있는 그룹과 없는 그룹 간에 성향 편향에는 유의미한 차이가 없는 것으로 나타났다.
    3. 이 연구는 LLM의 편향이 학생들의 작문에 영향을 미치지 않는 환경에서 AI 작문 지원의 사용에 대해 낙관적인 결과를 제시하고 있다.

###### VERVE: Template-based ReflectiVE Rewriting for MotiVational IntErviewing (https://aclanthology.org/2023.findings-emnlp.690/)
- Anthology ID: 2023.findings-emnlp.690 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 교단의 학습 평가 시간을 줄일 수 있는 자동 MCQ 생성 기능 있으나, 현재의 평가 방법은 교육적 가치를 고려하지 않고 다만 단어의 유사성만 고려한다.
    2. 우리는 지식 종속 가능성(KDA)를 활용한 새로운 자동 평가 메트릭을 제안하고 MCQ의 대답 가능성(answerability) 및 대상 사실에 대한 학생의 지식을 평가한다.
    3. 인간 평가 결과를 통해 우리의 방법이 실제 교실 환경에서 효과적이며, KDA_disc와 KDA_cont가 높은 상관관계를 가지고 있음을 보여주었다.
    
    
    1. 최근까지 NLP 작업에서 모델의 정확성이 인간을 뛰어넘는 수준이지만, spurious pattern에 의존하는 한계로 robustness가 제한된다고 알려져 있다.
    2. 이 논문은 contrastive learning과 counterfactual augmentation을 이용하여 강건성을 높이기 위한 연구를 진행한다.
    3. 다양한 실험 결과를 통해 우리의 접근 방식이 기존에 단어 기반 합성에 영향을 받는 bias에 덜 민감하며, 많은 개선을 이루었다고 보여진다. (1. counterfactual robustness, 2. cross-domain generalization, 3. generalization from scarce data)
    
    
    1. 상담사는 motivational interviewing (MI)에서 전문성을 갖기 위해 reflective listening이라는 기본 기술을 습득해야 한다.
    2. 이 논문은 상담 응답 재작성을 소개하며, 비반사적인 발언을 반사적인 응답으로 변환한다.
    3. VERVE라는 템플릿 기반의 재작성 시스템을 소개하며, 매개 훈련 및 적응형 템플릿 업데이트를 활용하여 비반사적인 문장을 반사적인 응답으로 변환하는 방법을 제안한다.

###### Self-Knowledge Guided Retrieval Augmentation for Large Language Models (https://aclanthology.org/2023.findings-emnlp.691/)
- Anthology ID: 2023.findings-emnlp.691 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델은 과제별 세부 조정 없이 뛰어난 성능을 보였으나, 그 모델 매개 변수에 저장된 지식은 여전히 완전하지 않고 계산 비용이 큰 관계로 업데이트하기 어렵다.
    2. 해당 논문은 내부 지식과 외부 세계 지식을 모두 적절하게 활용하기 위해 모델이 스스로 알고 있는 것과 모르는 것을 인식하도록 하는 "self-knowledge"를 탐구하고, 새로운 질문을 다룰 때 이전에 겪었던 질문을 참조하고 적응적으로 외부 자원을 호출할 수 있는 간단하면서도 효과적인 방법인 Self-Knowledge guided Retrieval augmentation (SKR)을 제안한다.
    3. SKR은 InstructGPT 또는 ChatGPT를 사용하여 다양한 데이터셋에 대해 평가되었으며, 이를 통해 기존의 chain-of-thought 및 완전 검색 기반 방법보다 우수한 성능을 보여준다.

###### Pretraining Language Models with Text-Attributed Heterogeneous Graphs (https://aclanthology.org/2023.findings-emnlp.692/)
- Anthology ID: 2023.findings-emnlp.692 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 여러 현실 세계 시나리오에서 (예 : 학술 네트워크, 소셜 플랫폼) 다른 유형의 개체는 텍스트와 연결 관계로 연결되어 있는데, 해당될 수 있는 것은 텍스트 속성이 있는 이질적인 그래프로 추상화될 수 있다. 이 논문에서는 이러한 이질적인 그래프의 네트워크 연결 관계를 명시적으로 고려하는 언어 모델을 위한 새로운 사전학습 프레임워크를 제안한다.
    2. 우리는 첫째로, 특정한 순서 내에서 대상 노드의 이웃을 컨텍스트 그래프로 정의하고, 언어 모델과 보조 이질적 그래프 신경망을 동시에 최적화하여 컨텍스트 그래프에 관련된 노드를 예측하기 위한 topology-aware 사전학습 작업을 제안한다.
    3. 둘째로, 텍스트-순한 노드는 다른 노드보다 텍스트가 적을 수 있으므로, 불균형 문제를 처리하기 위해 이웃의 텍스트 정보로 텍스트가 부족한 노드를 보완하는 텍스트 보강 전략을 개발하였다.

###### CReTIHC: Designing Causal Reasoning Tasks about Temporal Interventions and Hallucinated Confoundings (https://aclanthology.org/2023.findings-emnlp.693/)
- Anthology ID: 2023.findings-emnlp.693 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델(Large language models, LLMs)은 자연어 처리에서 인상적인 역량을 보여주었으나, 시간적 개입과 언어 환시에 대한 인과관계 수립 능력은 여전히 어렵다.
    2. 이 논문은 LLM의 인과 추론 능력을 테스트하고 향상시키기 위해 고안된 CReTIHC 데이터셋을 제시한다.
    3. CReTIHC 데이터셋은 기존 인과 추론 데이터셋을 재공학하여 말의 환시와 시간적 개입 요소를 포함한 복잡한 시나리오를 생성하여 LLM이 정보를 비판적으로 평가하고 인과관계를 식별할 수 있도록 한다.

###### On the Dimensionality of Sentence Embeddings (https://aclanthology.org/2023.findings-emnlp.694/)
- Anthology ID: 2023.findings-emnlp.694 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 문장 embedding의 차원에 대한 이해는 한정되어 있으나, 이 논문은 optimal한 차원이 기본 값보다 작을 수 있다는 것을 보여준다.
    2. 성능 저하 없이 문장 embedding의 차원을 압축하기 위해, encoder와 pooler의 성능 저하를 식별하고, 이 성능 저하를 완화하기 위해 두 단계의 학습 방법을 제안한다.
    3. 7개의 STS 태스크와 7개의 문장 분류 태스크에서 실험 결과, 우리의 방법은 저차원 문장 embedding의 성능을 크게 향상시킨다.

###### Pit One Against Many: Leveraging Attention-head Embeddings for Parameter-efficient Multi-head Attention (https://aclanthology.org/2023.findings-emnlp.695/)
- Anthology ID: 2023.findings-emnlp.695 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사전 훈련된 언어 모델의 스케일링은 자연 언어 처리 작업에서 큰 성능 향상을 가져왔지만, 메모리 요구량이 매우 크다. 이 논문에서는 트랜스포머의 위치 임베딩에서 영감을 받아, 멀티 헤드 어텐션 (MHA) 메커니즘의 메모리 풋프린트를 단순화하고 줄이기 위한 대안 모듈을 제안한다.
    2. 제안된 MHE 어텐션은 다른 어텐션 메커니즘에 비해 훨씬 더 메모리 효율적이며, 다양한 하위 작업에서 기존의 MHA에 비해 높은 예측 성능 보존 비율을 달성한다.
    3. MHE 어텐션은 단일 헤드 어텐션에 비해 추가 매개변수의 무시할 만한 분수만 필요로 하며, MHA는 추가적인 매개변수를 (3n2-3n)d2-3nd만큼 필요로 한다.

###### Entity-Based Evaluation of Political Bias in Automatic Summarization (https://aclanthology.org/2023.findings-emnlp.696/)
- Anthology ID: 2023.findings-emnlp.696 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. NLP 시스템은 사회적 편견을 인코딩할 수 있다는 연구가 많이 있으나, 대표적인 정치적 편견에 대한 요약 모델의 지식은 여전히 부족하다.
    2. 우리는 entity replacement 방법을 사용하여 자동 생성된 뉴스 기사 요약에서 정치인들의 표현을 조사했다.
    3. 우리는 몇 가지 추출적 및 추상적 요약 모델의 Donald Trump과 Joe Biden에 대한 민감도를 평가하는 entity-based computational framework을 개발했고, 특히 사용된 요약에서 entity가 중요한 역할을 할 때 이러한 편견을 발견했다.

###### StyleBART: Decorate Pretrained Model with Style Adapters for Unsupervised Stylistic Headline Generation (https://aclanthology.org/2023.findings-emnlp.697/)
- Anthology ID: 2023.findings-emnlp.697 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 스타일리스트 헤드라인 생성은 기사의 내용을 요약하면서 사용자를 끌어들일 원하는 스타일을 반영하는 헤드라인을 생성하는 과제이다. 
    2. 이 연구에서는 스타일리스트 헤드라인 생성을 위한 비지도 학습 방법을 제안한다. 
    3. StyleBART는 사전 학습된 BART 모델에 어댑터를 사용하여 다양한 스타일로 헤드라인을 생성할 수 있도록 하고, 인버스 패러프레이징 작업을 통해 스타일 어댑터를 향상시킨다.

###### RSVP: Customer Intent Detection via Agent Response Contrastive and Generative Pre-Training (https://aclanthology.org/2023.findings-emnlp.698/)
- Anthology ID: 2023.findings-emnlp.698 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 고객 서비스의 대화 시스템은 사용자에게 정확한 답변과 상담원의 의도를 감지하여 상담원이 사용자의 의도에 맞게 응답하는 과업 지향 대화에서 동일환 데이터를 기반으로 사용자에게 24시간 동안 지원하는 역할을 수행하기 위해 신경망 모델을 통해 개발되었다. 
    2. 기존의 의도 감지 방법은 대규모 데이터셋을 사용하여 언어 모델을 사전학습하는 것에 과도한 의존성이 있는데, 이는 주요한 데이터 수집 비용으로 인해 우월함에 제약을 줄 수 있다. 또한, 고객의 의도에 중요한 응답에 대한 정보를 무시하는데, 이는 상담원이 응답을 고객의 의도에 맞게 조정해야 하는 역할을 수행하기 때문에 중요하다. 
    3. 본 논문에서는 의도 지향 대화를 위해 상담원의 응답을 사전학습하는 RSVP라는 자기 학습 프레임워크를 제안하였다. RSVP는 발화-응답 쌍의 관계를 포함하기 위해 두 단계로 사전학습을 수행하는 두 가지 사전학습 과제를 소개한다.

###### Improving Low-resource Question Answering by Augmenting Question Information (https://aclanthology.org/2023.findings-emnlp.699/)
- Anthology ID: 2023.findings-emnlp.699 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 모델 시대에서는 리소스가 제한된 질의응답 태스크의 성능이 떨어져 자연어처리에서 데이터 증강의 중요성이 강조된다.
    2. 우리는 Prompt Answer, Question Generation, Question Filter로 구성된 PQQ라는 혁신적인 질문 데이터 증강 방법을 소개하여 대형 모델의 내부 지식을 활용하고 질문, 문단, 답변 중 어떤 데이터 요소가 가장 많은 증강 이점을 얻을 수 있는지 결정하며 과도한 noise를 유발하지 않으면서 증강 내용의 일관성을 유지한다.
    3. 실험 결과, ChatGPT는 실험 데이터에서 성능이 저조하지만, 우리의 PQQ 방법은 기존 증강 전략을 뛰어넘는 성과를 보여주며, SQUAD1.1 및 TriviaQA와 같은 고리소스 QA 태스크에서 검증되었다.

###### InstructSafety: A Unified Framework for Building Multidimensional and Explainable Safety Detector through Instruction Tuning (https://aclanthology.org/2023.findings-emnlp.700/)
- Anthology ID: 2023.findings-emnlp.700 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 언어 모델의 고도로 발전함에 따라 안전 감지 시스템을 개발하는 것이 점점 중요해지고 있으나, 현재 사용 가능한 안전 감지 시스템은 다용도성과 해석 가능성 측면에서 한계가 있다.
    2. 이 논문에서는 7가지 일반적인 안전 감지 서브 태스크를 통합하는 InstructSafety라는 안전 감지 프레임워크를 소개한다.
    3. 다양한 데이터셋과 태스크에서 수행한 실험 결과를 통해 Safety-Flan-T5의 성능이 교육된 기준선과 제공되는 API들과 비교하여 강력함을 입증하고 있다.

###### “A Tale of Two Movements’: Identifying and Comparing Perspectives in #BlackLivesMatter and #BlueLivesMatter Movements-related Tweets using Weakly Supervised Graph-based Structured Prediction (https://aclanthology.org/2023.findings-emnlp.701/)
- Anthology ID: 2023.findings-emnlp.701 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 소셜 미디어는 온라인 사회운동의 형성을 돕는 것으로 사회적 변화의 주요 원동력이 되었다. 그러나 주장하는 입장과 반대하는 의견을 자동으로 이해하는 것은 주석이 달린 데이터를 얻기가 어렵기 때문에 어려운 과제이다.
    2. 우리는 #BackLivesMatter와 관련된 트윗에서 명시적으로 주장을 모델링하는 약한 지도학습 기반의 그래프 기반 접근법을 제안한다.
    3. 우리의 모델은 작은 양의 레이블된 예제를 사용하며, 큰 언어 모델을 사용하여 가상의 학습 예제를 생성하는 것으로 실험한 결과, 수동 주석과 비교하여 비슷한 성능을 달성한다.

###### ClusterPrompt: Cluster Semantic Enhanced Prompt Learning for New Intent Discovery (https://aclanthology.org/2023.findings-emnlp.702/)
- Anthology ID: 2023.findings-emnlp.702 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사용자 발화로부터 새로운 의도 카테고리를 발견하는 것은 에이전트의 스킬을 확장하는데 매우 중요한 작업이다. 그러나 기존의 메서드들은 의도 간 관계나 클러스터에 더욱 중점을 두고 전이 학습을 수행했다. 이 논문에서는 새로운 의도를 발견하기 위해 Cluster Semantic Enhanced Prompt Learning (CsePL)이라는 새로운 접근 방식을 제안한다. 
    2. 이 방법은 레이블 의미 정렬을 이용해 의도 클러스터의 의미 있는 표현을 학습하고, 이러한 학습된 의도 표현을 새로운 의도를 구별하는 데 사용하여 기존 의도를 억압하고 의도 클러스터를 의미 없는 새로운 의도 클러스터로 만들지 않는다. 
    3. 세 개의 공개 데이터셋에서 범위를 넓게 실험한 결과 우리의 방법이 기존의 방법보다 성능이 우수하며 의미 있는 의도 레이블을 제안하고 새로운 의도를 조기에 감지할 수 있다는 것을 보여주었다.

###### Investigating the Effect of Pre-finetuning BERT Models on NLI Involving Presuppositions (https://aclanthology.org/2023.findings-emnlp.703/)
- Anthology ID: 2023.findings-emnlp.703 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 선험적 지식(presupposition), 담화(discourse), 풍자(sarcasm) 사이의 연결을 탐구하고 전이 학습 시나리오에서 이 연결을 활용하여 NLI 모델의 선험적 지식을 포함한 사례에서의 성능을 개선하기 위한 논문이 제안되었다.
    2. 우리는 사전-세세 조정(pre-finetuning)을 활용하여 NLI 모델을 주의 깊게 선택된 과제에서 사전 조정하고 선험적 지식을 포함한 NLI 사례에서의 성능 향상을 시도한다.
    3. 실험 결과, 이러한 과제에서의 사전-세세 조정은 성능 향상을 이끌어냄을 보여주었다. 추가적인 훈련 데이터가 도움이 되고 있는 경우도 있으나 과제 선택이 성능 향상에 영향을 미친다는 것을 진단 테스트를 통해 확인하였다.

###### MRRL: Modifying the Reference via Reinforcement Learning for Non-Autoregressive Joint Multiple Intent Detection and Slot Filling (https://aclanthology.org/2023.findings-emnlp.704/)
- Anthology ID: 2023.findings-emnlp.704 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 non-autoregressive 접근법의 등장으로 Joint Multiple Intent Detection 및 Slot Filling을 위한 non-autoregressive 모델들이 빠른 추론 속도를 얻었다. 하지만, 대부분의 기존 SLU 모델들은 여러 가지 문제로 인해 참조 의도와 슬롯이 훈련에 적합하지 않을 수 있다.
    2. 이 논문에서는 MRRL이라는 새로운 방법을 제안하여 multiple intent detection 및 slot filling을 위한 non-autoregressive SLU 모델에 대해 수정된 참조를 도입하고 강화학습을 적용한다. 
    3. 실험 결과, MRRL이 기존 기준선 성능을 일관되게 향상시킬 수 있으며, 최고 성능은 MixATIS 데이터셋에서 이전 접근법 대비 3.6의 전체 정확도향상을 보였다.

###### DemoNSF: A Multi-task Demonstration-based Generative Framework for Noisy Slot Filling Task (https://aclanthology.org/2023.findings-emnlp.705/)
- Anthology ID: 2023.findings-emnlp.705 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 프롬프트 기반 생성 프레임워크는 순차적 라벨링 태스크에서 뛰어난 성능을 보이지만, 단순한 템플릿과 전통적인 코퍼스에만 의존하는 것은 알려지지 않은 입력 변동에 대한 일반화에 도전을 제시한다.
    2. 우리는 이 간극을 해결하기 위해 노이즈 슬롯 채우기를 위한 멀티태스크 데모 기반 생성 프레임워크인 DemoNSF를 제안한다. 
    3. 두 가지 벤치마크 실험에서 DemoNSF가 모든 기준선 방법을 능가하고 강력한 일반화 성능을 달성하는 것을 보여준다.

###### SHARCS: Efficient Transformers Through Routing with Dynamic Width Sub-networks (https://aclanthology.org/2023.findings-emnlp.706/)
- Anthology ID: 2023.findings-emnlp.706 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. SHARCS는 입력 샘플의 난이도를 고려한 적응 추론을 위한 기법을 제안한다. 이를 통해 SHARCS는 다양한 분류 작업에서 다른 per-sample 적응 추론 방법들에 비해 정확성과 FLOPs 기준에서 성능을 향상시킨다.
    2. SHARCS는 다양한 아키텍처에서 일반화되며, 압축되고 효율적인 transformer encoder에도 적용하여 효율성을 더욱 향상시킬 수 있다.
    3. SHARCS는 무시할 만한 정확도 하락과 함께 2배의 추론 속도 향상을 제공할 수 있다.

###### Always the Best Fit: Adaptive Domain Gap Filling from Causal Perspective for Few-Shot Relation Extraction (https://aclanthology.org/2023.findings-emnlp.707/)
- Anthology ID: 2023.findings-emnlp.707 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Cross-domain Relation Extraction"은 저자가 제안한 "CausalGF"라는 새로운 프레임워크를 사용하여 다른 도메인으로 지식을 전달하여 low-resource 상황에서의 도전에 대응한다. 
    2. 이전 연구는 주로 도메인 간 공유 특성 표현을 통해 지식을 전달하였으나, 각 도메인의 특성에 따라 데이터 편향을 발생시킬 수 있는 각 요소의 영향을 분석하지 않고 있다.
    3. "CausalGF"는 통합된 구조적 인과 모델을 구축하여 구문 구조, 레이블 분포, 엔티티 등의 요소에 대한 인과효과를 측정하고 도메인 특성을 기반으로 동적으로 조정함으로써 도메인 간 격차를 적응적으로 채우는 것을 가능하게 한다.

###### MEGClass: Extremely Weakly Supervised Text Classification via Mutually-Enhancing Text Granularities (https://aclanthology.org/2023.findings-emnlp.708/)
- Anthology ID: 2023.findings-emnlp.708 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 전통적인 텍스트 분류 방법은 비용이 많이 들거나 특화된 도메인에서는 부족할 수 있기 때문에, 클래스 의미어만을 사용하여 text classification을 수행하는 방식이 제안되었다.
    2. 그러나 기존의 방법들은 문서, 문장 또는 단어와 같은 다른 수준의 텍스트 구체성을 독립적으로 다루어, 서로간에 disagreement과 독립적인 컨텍스트들을 고려하지 않는다.
    3. MEGClass는 어휘 및 문장을 동시에 고려하여 저차원 및 고차원의 컨텍스트 신호를 이용하여 text classification을 수행하며, 다른 방법과 비교했을 때 우수한 성능을 보여주었다.

###### Causal Inference from Text: Unveiling Interactions between Variables (https://aclanthology.org/2023.findings-emnlp.709/)
- Anthology ID: 2023.findings-emnlp.709 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 관측 텍스트 데이터로부터 인과 효과를 추정하기 위해서는 잠재 배제변수(latent covariates)를 조정하는 것이 중요하다. 기존 방법들은 처리와 결과에 영향을 미치는 혼동(covariates)에만 초점을 맞추고, 비혼동 혼동 요인을 충분히 고려하지 않아 편향된 인과 효과 추정으로 이어질 수 있다.
    2. 우리는 텍스트로부터 인과 효과를 추정할 때, 다른 변수들 간의 상호작용을 파악하여 비혼동 혼동 요인을 분리시키는 것으로 이 편향을 완화하기 위해 노력한다.
    3. 실험 결과는 우리의 제안 모델이 강력한 기준과 비교하여 상당한 향상을 보였으며, 수익 전화 트랜스크립트에 대한 철저한 분석은 모델이 변수들을 효과적으로 분리할 수 있음을 보여주고, 실제 상황에 대한 추가 조사는 투자자들에게 정보를 제공하여 판단을 돕는다.

###### Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples! (https://aclanthology.org/2023.findings-emnlp.710/)
- Anthology ID: 2023.findings-emnlp.710 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델 (LLMs)은 다양한 작업에서 놀라운 성과를 보였다. 그러나 LLM이 정보 추출 (IE) 작업에 대해 일반적으로 경쟁력 있는 몇 가지 샷 솔버인지는 여전히 미개한 문제이다.
    2. 여러 실험을 통해 현재의 고급 LLM이 대부분의 설정에서 성능이 떨어지고 더 느린 응답 시간 및 증가한 예산 요구사항을 가지는 것을 보여준다. 따라서 LLM은 일반적으로 효과적인 소수샷 정보 추출기가 아니다.
    3. 그러나 적절한 프롬프팅 전략으로 LLM이 SLM을 보완하고 SLM이 처리하기 어려운 어려운 샘플을 처리할 수 있다는 것을 보여준다. 또한 LLM과 SLM의 강점을 결합하기위해 적응형 필터링 후 재정렬 패러다임을 제안한다. 이 패러다임에서 SLM은 필터로 작용하고 LLM은 재정렬기 역할을한다. SLM이 식별한 어려운 샘플의 일부를 LLM에 재정렬하도록 유도함으로써 우리의 초기 시스템은 다양한 IE 작업에서 일관된 향상 (평균 2.4% F1 점수 향상)을 안정적으로 달성한다.

###### Prompting and Evaluating Large Language Models for Proactive Dialogues: Clarification, Target-guided, and Non-collaboration (https://aclanthology.org/2023.findings-emnlp.711/)
- Anthology ID: 2023.findings-emnlp.711 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델(ChatGPT 등) 기반의 대화 시스템은 맥락 이해와 응답 생성에서 탁월한 능력을 보이지만, 모호한 질의에 대해 명확화 질문을 하지 못하거나 사용자의 불합리한 요청을 거부하는 등의 한계를 가지고 있다.
    2. 따라서 이 논문에서는 Proactive Chain-of-Thought prompting 방법을 제안하여 LLM에 목표 기반 계획능력을 부여하여 프로액티브한 대화 문제를 다룰 수 있는지 분석하였다.
    3. 명확화, 목표 지향, 비협업적 대화라는 프로액티브 대화의 세 가지 측면에 집중하여 LLM 기반 대화 시스템을 종합적으로 분석하고, 향후 연구를 촉진시키기 위한 실험 결과를 제시하였다.

###### Ecologically Valid Explanations for Label Variation in NLI (https://aclanthology.org/2023.findings-emnlp.712/)
- Anthology ID: 2023.findings-emnlp.712 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. NLP 태스크에서 인간의 라벨 다양성이 존재하는데, 모델이 라벨에 대해 해석하는 방법에 영향을 준다는 것을 직접적으로 알기 위해, LiveNLI라는 데이터셋을 구축했다. 
    2. LiveNLI 설명은 사람들이 해석에서 체계적으로 다양할 수 있고, 라벨이 같지만 선택된 이유가 다를 수 있는 것을 확인한다.
    3. 우리는 몇몇 실험에서 prompt large language model이 유효하고 유익한 설명을 생성하는 반면, 그렇지 않은 라벨을 지원하지 않는 설명도 생성한다는 것을 확인했고, 이를 개선할 방향을 제시했다.

###### A Benchmark for Semi-Inductive Link Prediction in Knowledge Graphs (https://aclanthology.org/2023.findings-emnlp.713/)
- Anthology ID: 2023.findings-emnlp.713 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 지식 그래프 (knowledge graph)에서의 반지도 학습 기반의 링크 예측(link prediction)은 새로운 엔티티에 대한 사전에 보지 못한 맥락 정보를 기반으로 사실(fact)을 예측하는 작업이다. 
    2. 본 논문에서는 대규모 지식 그래프에서 반지도 학습 기반의 링크 예측 모델을 평가하기 위한 벤치마크를 제안한다.
    3. 이 벤치마크는 Wikidata5M을 기반으로 하며, KG 구조만을 사용한 transductive task부터 텍스트 언급과 개체에 대한 자세한 설명까지 다양한 정보를 활용한 k-shot 및 0-shot LP task를 제공한다.

###### SummIt: Iterative Text Summarization via ChatGPT (https://aclanthology.org/2023.findings-emnlp.714/)
- Anthology ID: 2023.findings-emnlp.714 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존 텍스트 요약 시스템은 최근에 큰 발전을 이루었지만 일반적으로 요약을 한 번에 작성하는 방식이며, 독자의 관심사와 관련된 중요한 세부사항을 누락하거나 창작하는 경우가 있다.
    2. 이 논문에서는 SummIt이라는 반복적인 텍스트 요약 프레임워크를 제안하여 자기 평가 및 피드백을 통해 생성된 요약을 반복적으로 개선하는 것을 가능하게 한다. 
    3. 또한 지식과 주제 추출기를 프레임워크에 통합하여 요약의 충실성과 조절 가능성을 향상시키는 잠재적 이점을 탐구하였으며, Empirical 및 정성적 분석을 통해 프레임워크의 성능을 평가하였다.

###### Orthogonal Subspace Learning for Language Model Continual Learning (https://aclanthology.org/2023.findings-emnlp.715/)
- Anthology ID: 2023.findings-emnlp.715 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델 (LLM)은 언어 이해와 생성에서 탁월한 성능을 보이지만, 과도한 잊기(catastrophic forgetting)라고 알려진 순차적인 다중 작업을 수행할 때 성능이 저하된다. 
    2. 이 논문에서는 연속 학습을 위한 간단하고 효율적인 접근 방식인 orthogonal low-rank adaptation (O-LoRA)를 제안하여 새로운 작업을 학습하는 동안 catastrophic forgetting을 효과적으로 완화한다. 
    3. 실험 결과, O-LoRA는 기존 방법보다 우수한 성능을 보이고, 예전 방식과 비교했을 때 LLM의 일반화 능력을 더 잘 보존한다.

###### Attention-Enhancing Backdoor Attacks Against BERT-based Models (https://aclanthology.org/2023.findings-emnlp.716/)
- Anthology ID: 2023.findings-emnlp.716 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 연구에서는 Backdoor 공격이 자연어 처리 모델의 안전성을 위협할 수 있다고 밝혀졌다. 이 논문에서는 Backdoor 공격의 전략을 조사하여 모델의 취약점을 이해하는 데 도움을 준다.
    2. 대부분의 기존 텍스트 Backdoor 공격은 약한 트리거를 생성하거나 모델 가중치를 수정하는 데 초점을 맞추고 있다. 그러나 이 논문에서는 신경망의 내부 구조와 Backdoor 메커니즘 자체를 공격의 대상으로 삼아 새로운 Trojan Attention Loss (TAL)를 제안한다.
    3. TAL은 이러한 주의 패턴을 직접 조작함으로써 Trojan 행동을 향상시키고, 공격 성공률과 감염률을 높이기 위해 다양한 공격 방법에 적용될 수 있다. BERT, RoBERTa, DistilBERT 등 다양한 Backbone 모델과 Sentiment Analysis, Toxic Detection, Topic Classification 등의 다양한 작업에서 우리의 방법을 검증하였다.

###### Hi-ToM: A Benchmark for Evaluating Higher-Order Theory of Mind Reasoning in Large Language Models (https://aclanthology.org/2023.findings-emnlp.717/)
- Anthology ID: 2023.findings-emnlp.717 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Theory of Mind (ToM)은 개인의 정신 상태와 타인의 정신 상태에 대해 추론할 수 있는 능력이다. 이 논문은 ToM 연구에 처음으로 3차 이상의 ToM을 다루며, 더 높은 수준의 ToM 과제에서 현재의 언어 모델의 한계를 보여준다.
    2. 새로운 속임수(deception) 메커니즘을 ToM 추론에 반영하였으며, Higher Order Theory of Mind 벤치마크인 Hi-ToM을 소개한다.
    3. 다양한 대형 언어 모델(Large Language Models)을 사용한 실험적 평가 결과, 더 높은 수준의 ToM 과제의 성능이 저하되는 것을 보여주며, 이러한 실패 사례에 대한 철저한 분석과 이러한 결과의 NLP의 미래에 대한 함의를 공유한다.

###### Image and Text: Fighting the same Battle? Super Resolution Learning for Imbalanced Text Classification (https://aclanthology.org/2023.findings-emnlp.718/)
- Anthology ID: 2023.findings-emnlp.718 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 본 논문에서는 이미지와 텍스트 처리 사이의 유사성을 기반으로한 데이터 augmentation인 SRL4NLP를 제안한다. 이 방법은 저해상도 이미지의 문제를 극복하기 위해 고해상도 이미지를 사용하는 것으로, 이미지 처리에서 흔히 사용되는 기술이지만 NLP에서는 처음으로 적용되는 것이다.
    2. 저자들은 이 방법을 텍스트 분류에 적용하고, 긴급 사태 시점에 작성된 트윗을 사용한 긴급도 감지와 같이 어려운 작업에서의 효과를 평가했다.
    3. 저자들은 이 전략이 두 개의 언어로 이루어진 여러 벤치마크 데이터셋에서 경쟁 기술들과 비교했을 때 효과적임을 보였다.

###### SELFOOD: Self-Supervised Out-Of-Distribution Detection via Learning to Rank (https://aclanthology.org/2023.findings-emnlp.719/)
- Anthology ID: 2023.findings-emnlp.719 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. CE loss로 훈련된 딥 뉴럴 분류기는 일반적으로 보정이 잘 안되어서 OOD(분포에서 벗어난) 감지가 필요하지만, 기존의 OOD 감지 방법들은 상당한 비용을 들이는 in-distribution과 OOD 샘플을 수작업으로 라벨링해야 하는 문제가 있다. 
    2. 이 논문에서는 in-distribution 샘플만 있으면 되는 OOD 감지 방법인 SELFOOD를 제안한다. 
    3. SELFOOD는 inter-document intra-label (IDIL) 랭킹 문제로 OOD 감지를 다루고, 이를 위해 IDIL 손실이라는 pairwise 랭킹 손실을 사용하여 분류기를 학습한다.

###### Mind the Gap Between Conversations for Improved Long-Term Dialogue Generation (https://aclanthology.org/2023.findings-emnlp.720/)
- Anthology ID: 2023.findings-emnlp.720 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화가 시작되고 며칠, 몇 달 또는 몇 년에 걸쳐 계속되는 것은 의사소통의 자연스러운 일부로, 주제가 얼마나 중요하고 어떤 질문을 해야 하는지를 결정하는 역할을 한다. 따라서 시간을 명시적으로 모델링하지 않는 대화 시스템은 부자연스러운 응답을 생성할 수 있다.
    2. 이 연구에서는 대화 모델이 시간을 인식하도록 하는 아이디어를 탐구하고, 각 세션 사이의 시간이 다양하게 변하는 GapChat이라는 멀티 세션 대화 데이터셋을 제시한다.
    3. 우리는 모델에 시간 정보를 제공하고, 시간 및 사건 진행 상황의 다른 표현을 비교한다. 휴먼 평가에서는 시간을 인식하는 모델이 선택된 주제의 관련성 및 대화에서 얻은 정보에 대한 평가 메트릭에서 더 우수한 성능을 보였다.

###### A Structure-Aware Generative Adversarial Network for Bilingual Lexicon Induction (https://aclanthology.org/2023.findings-emnlp.721/)
- Anthology ID: 2023.findings-emnlp.721 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 양방향 어휘 인식(BLI)은 두 언어 간 단어 임베딩 공간을 일치시키는 학습된 매핑 함수로 단어 번역을 유도하는 작업이다. 기존 방법들은 단어 임베딩을 고립된 개체로 다루며, 단어 간의 공간 내 및 공간 간 위상적 관계를 고려하지 못하여 토폴로지 구조가 다른 임베딩 공간에서 단어를 일치시키는 것이 어렵다.
    2. 이 논문은 경량 그래프 합성곱 신경망(Graph Convolutional Network, GCN)을 사용하여 단어 간의 공간 내 위상적 상관관계를 이용하여 소스 및 타겟 임베딩을 생성하고, 점진적으로 소스 임베딩을 타겟 임베딩 공간으로 매핑하는 공간 간 위상 구조를 학습하기 위해 GAN 모델을 사용하는 Structure-Aware Generative Adversarial Network (SA-GAN) 모델을 제안한다.
    3. 먼 거리 및 밀접한 언어 간 관계를 가진 언어를 포함한 공개 데이터셋에서 수행된 실험 결과는 SA-GAN 모델의 효과적인 성능을 보여주었다.

###### NLP Evaluation in trouble: On the Need to Measure LLM Data Contamination for each Benchmark (https://aclanthology.org/2023.findings-emnlp.722/)
- Anthology ID: 2023.findings-emnlp.722 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 현재의 자연어 처리 (NLP) 과제의 평가 방법 중 하나인 주석이 달린 벤치마크에 기반한 평가가 문제가 있다고 주장한다. 벤치마크의 테스트 세트로 모델을 훈련한 후 동일한 벤치마크에서 평가하기 때문에 클래식한 평가 방식은 데이터 오염에 영향을 받는다고 주장한다.
    2. 데이터 오염은 오염된 모델이 비오염된 모델에 비해 대상 벤치마크 및 관련 과제에서 성능을 과대 평가하게 만들어 오해를 야기할 수 있다고 설명한다.
    3. 이 위치논문은 데이터 오염의 다양한 수준을 정의하고, 데이터가 모델에 노출되었는지 감지하는 자동 및 반자동 측정 방법을 개발하고 데이터 오염에 의해 영향받은 논문을 식별하는 것을 포함한 공동 노력을 제안한다.

###### Improving Pacing in Long-Form Story Planning (https://aclanthology.org/2023.findings-emnlp.723/)
- Anthology ID: 2023.findings-emnlp.723 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 긴 형식 이야기 작성 시스템들은 중요한 사건들을 누락하거나 사소한 세부 사항에 너무 많은 설명을 하여 독자에게 불편한 경험을 주는 문제점이 있다. 
    2. 이 논문에서는 CONCOCT 시스템을 제안하여 이야기 개요를 자동으로 생성할 때 pacing을 개선한다. 훈련된 concreteness evaluator를 사용하여 계층적 개요 생성에서 pacing을 조절하는 방법을 탐구한다.
    3. CONCOCT 시스템은 사람들에게 일관된 pacing을 제공하며, 이러한 향상은 다른 이야기들에도 영향을 미친다고 인간 평가를 통해 확인하였다.

###### Argument mining as a multi-hop generative machine reading comprehension task (https://aclanthology.org/2023.findings-emnlp.724/)
- Anthology ID: 2023.findings-emnlp.724 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 주장 마이닝은 무구조적인 주장 텍스트를 입력으로 받아 주장 구조 그래프를 생성하는 자연어 처리 작업입니다. 논문에서는 주장 구조를 "사고의 연결" 개념과 비슷하다고 설명하며, 연구에서는 multi-hop reading comprehension 작업으로 주장 마이닝을 전환하고 "사고의 연결" 정보가 주장 마이닝 작업에 도움이 된다는 것을 실험적으로 입증했습니다.
    2. 주장 텍스트를 "왜" 질문에 대한 답으로 볼 수 있으며, 학생의 에세이와 같은 특정 장르의 주장 텍스트들은 일반적으로 비슷한 "사고의 연결"을 가지고 있습니다.
    3. 실험 결과는 SOTA 결과를 초과한다는 것을 보여주었으며, 자세한 분석을 통해 "사고의 연결" 정보가 주장 마이닝 작업에 도움이 된다는 것을 확인하였습니다.

###### HuatuoGPT, Towards Taming Language Model to Be a Doctor (https://aclanthology.org/2023.findings-emnlp.725/)
- Anthology ID: 2023.findings-emnlp.725 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. HuatuoGPT는 ChatGPT로부터 얻은 압축된 데이터와 의사들의 실제 데이터를 활용한 의료 상담을 위한 대형 언어 모델이며, 이러한 접근은 ChatGPT로부터 얻은 데이터만 사용하는 것으로는 '모델 붕괴'가 발생할 수 있고, 의사들의 실제 데이터는 ChatGPT로부터 얻은 데이터와 보완적인 역할을 할 수 있기 때문에 사용된다.
    2. ChatGPT로부터 나오는 응답은 일반적으로 자세하고 유창하며 지시 사항을 따르지만, 대화식 진단을 비롯한 여러 측면에서 의사처럼 작동할 수 없다. 따라서, 의사들의 추가 데이터는 압축된 언어 모델을 의사처럼 작동시키기 위해 사용된다.
    3. 실험 결과 (GPT-4 평가, 인간 평가, 의료 벤치마크 데이터셋)는 HuatuoGPT가 오픈소스 대형 언어 모델 중 의료 상담에서 최고 성능을 보여준다는 것을 보여준다. 추가적인 실제 데이터와 RLMF의 사용을 통해, 압축된 언어 모델인 HuatuoGPT가 대부분의 경우에는 ChatGPT보다 우수한 성과를 낸다는 점에 주목할 만하다.

###### Debias NLU Datasets via Training-free Perturbations (https://aclanthology.org/2023.findings-emnlp.726/)
- Anthology ID: 2023.findings-emnlp.726 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 연구들은 자연어 이해(NLU)를 위한 고급 모델들이 편향된 특징들을 포착하고, 이러한 특징들이 작업과 독립적이지만 label과 spuriously correlated 될 수 있다는 것을 보여주었다. 이러한 모델들은 일반적으로 in-distribution (ID) 데이터셋에서는 잘 작동하지만 out-of-distribution (OOD) 데이터셋으로의 일반화에 실패한다.
    2. PDD는 ID 성능을 희생하지 않고 OOD 성능을 향상시키기 위해 학습을 요구하지 않는 Perturbations을 사용하는 디바이스 NLU 데이터셋을 위한 프레임워크이다. PDD는 사전 훈련된 마스크 언어 모델 (MLM)을 통해 반복적으로 간섭을 수행하여 작동한다.
    3. 많은 실험을 통해 PDD가 이전의 최첨단 디바이싱 전략과 경쟁력 있는 성능을 보여준다는 것을 확인했고, 모델-중심 디바이스 방법과 결합할 때 새로운 최첨단 기술을 수립한다.

###### Aspect-to-Scope Oriented Multi-view Contrastive Learning for Aspect-based Sentiment Analysis (https://aclanthology.org/2023.findings-emnlp.727/)
- Anthology ID: 2023.findings-emnlp.727 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Aspect 기반 감성 분석 (ABSA)은 특정 aspect의 감성 극성을 식별하기 위해 aspect와 해당 감성 표현을 매핑하는 것을 목표로 한다. 
    2. 기존 ABSA 방법들은 문장에 여러 가지 aspect가 존재할 때 attention mechanism과 dependency tree로 인해 소음이 발생하여 여전히 문제가 있다.
    3. 이 논문에서는 새로운 관점에서 ABSA를 재검토하고, scope-assisted multi-view graph contrastive learning framework를 제안하여 aspect와 해당 감성 의견을 aspect-specific scope로 더 정확하게 식별하고, 감성 극성과 구문/의미 정보 간의 상관 관계와 차이를 포착한다는 것을 보여준다.

###### Robustness of Named-Entity Replacements for In-Context Learning (https://aclanthology.org/2023.findings-emnlp.728/)
- Anthology ID: 2023.findings-emnlp.728 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 현대의 대형 언어 모델의 핵심 기능 중 하나인 in-context learning은 최종 query 이전에 query-answer demonstrations를 보여주는 prompting 기술로, 파라미터 업데이트 없이 새로운 규칙을 학습할 수 있는 일반화 능력을 제공한다. 하지만, demonstrations의 선택과 특정 query와의 관계는 모델 정확도에 깊은 영향을 미칠 수 있어 실제 in-context generalization 능력에 대한 우려가 있다.
    2. 본 연구에서는 entity에 주목하여 in-context learning 패러다임의 robustness를 탐색한다. 특히, 명칭 개체 변환에 대한 LLM의 in-context learning의 robustness를 이해하고자 한다.
    3. 우리는 세 가지 인기 있는 추론 태스크와 두 가지 인기 있는 LLM을 기반으로, 명칭 개체의 선택에 따라 후속 성능에 상당한 차이가 있음을 발견하였다. 특히, 테스트 세트에서의 모델 정확도는 명칭 개체 변환의 선택에 따라 -2.7에서 +8.0 점까지 편차가 나타난다고 한다. 우리의 분석은 명칭 개체에 대한 LLM in-context learning의 민감성을 드러내며, 주어진 데이터셋에 대해 명칭 개체의 하이퍼파라미터 튜닝을 통해 테스트 성능을 개선하는 간단한 방법을 제안한다. 결과 재현을 위한 코드와 데이터셋은 공개적으로 제공된다.

###### Contrastive Learning-based Sentence Encoders Implicitly Weight Informative Words (https://aclanthology.org/2023.findings-emnlp.729/)
- Anthology ID: 2023.findings-emnlp.729 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 단순한 contrastive loss fine-tuning을 통해 문장 인코더의 성능을 크게 향상시킬 수 있다.
    2. 이 논문은 contrastive 기반의 문장 인코더가 정보 이론적 양에 기반하여 단어에 가중치를 부여하는 것을 이론적으로 및 실험적으로 보여준다.
    3. 다양한 모델, 여러 데이터셋, 두 가지 모델의 암묵적 가중치 측정 방법(Integrated Gradients와 SHAP), 그리고 두 정보 이론적 양(정보 이득과 자기 정보)을 사용하여 포괄적인 실험을 수행하였으며, 그 결과 contrastive fine-tuning이 정보가 풍부한 단어에 중점을 둔다는 경험적 증거를 제공한다.

###### Legally Enforceable Hate Speech Detection for Public Forums (https://aclanthology.org/2023.findings-emnlp.730/)
- Anthology ID: 2023.findings-emnlp.730 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 혐오 발언은 사회적으로 심각한 문제를 일으킨다. 적절한 혐오 발언 법 집행은 피해를 받는 그룹을 유해하고 차별적인 언어로부터 보호하는 데 중요하다고 한다. 
    2. 기존 작업들은 혐오 발언을 어떻게 정의할지 판단하기가 복잡하고 주관적인 해석에 매우 개방적이기 때문에 목표와 일관성이 없을 수 있다. 
    3. 본 연구는 법적 정의에 기반을 둔 강제형 혐오 발언 탐지에 대한 새로운 시각과 과업을 제안하고, 법적 전문가들이 정의 하는 십일 가지 위반에 대한 데이터셋을 소개한다.

###### ConPrompt: Pre-training a Language Model with Machine-Generated Data for Implicit Hate Speech Detection (https://aclanthology.org/2023.findings-emnlp.731/)
- Anthology ID: 2023.findings-emnlp.731 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 암시적인 혐오 발언 탐지는 텍스트 분류에서 도박과 같은 명확한 단서가 없기 때문에 어려운 작업이다. 기존의 pre-trained 언어 모델은 암시적인 혐오 발언에 특화되어 있지 않다. 
    2. 이 논문에서는 머신 생성을 통해 암시적인 혐오 발언 데이터셋을 제어하며, 이를 효과적으로 활용하기 위해 ConPrompt라는 사전 훈련 방법을 제안한다. 
    3. 실험 결과, ToxiGen-ConPrompt는 다른 pre-trained 모델보다 암시적인 혐오 발언 감지에서 우수한 일반화 능력을 보이고, Identity term bias를 완화하는 효과도 있다는 것을 보여준다.

###### Incorporating Syntactic Knowledge into Pre-trained Language Model using Optimization for Overcoming Catastrophic Forgetting (https://aclanthology.org/2023.findings-emnlp.732/)
- Anthology ID: 2023.findings-emnlp.732 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 일반적인 사전 훈련된 언어 모델들은 구문 지식이 충분하지 않기 때문에 복잡하거나 긴 문장을 처리하는 많은 태스크들에서 실패한다.
    2. 이 논문에서는 구문 지식을 언어 모델에 통합하기 위해 추가적인 훈련을 탐구한다. 
    3. 구문 지식을 추가하고 원래 지식과 추가 지식 사이의 균형을 유지하기 위해 치명적인 잊기(catastrophic forgetting) 문제를 해결하였으며, 추가 구문 훈련은 성능 향상을 일관되게 보여준다.

###### Toward Human Readable Prompt Tuning: Kubrick’s The Shining is a good movie, and a good prompt too? (https://aclanthology.org/2023.findings-emnlp.733/)
- Anthology ID: 2023.findings-emnlp.733 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델은 원하는 동작을 지정하는 자연어 프롬프트를 사용하여 downstream 태스크를 제로샷 방식으로 수행할 수 있다. 하지만 이 프롬프트가 효과적인 요소는 알려져 있지 않다. 
    2. 이 연구에서는 분류 문제에서 효과적인 프롬프트의 공통 속성을 조사했다. 따라서 효과적이고 자연스러운 프롬프트의 분포를 찾기 위해 Langevin dynamics를 기반으로 하는 human readable 프롬프트 튜닝 방법 (FluentPrompt)을 제안했다.
    3. 분석결과 효과적인 프롬프트는 태스크 영역과 주어진 출력 레이블의 사전 확률을 조정하는 것이 효과적이라는 것을 알아내었으며, 이를 바탕으로 라벨이 없는 데이터만 사용하여 프롬프트를 생성하는 방법을 제안하였다. 이 방법은 세 가지 태스크에서 강력한 베이스라인을 평균 7.0% 정확도로 능가한다.

###### Chain-of-Thought Reasoning in Tabular Language Models (https://aclanthology.org/2023.findings-emnlp.734/)
- Anthology ID: 2023.findings-emnlp.734 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 표 기반 수학 추론 작업은 표와 질문으로부터 얻은 이질적인 데이터를 기반으로 다단계 연산, 정보 조회 및 숫자 계산 등을 수행하는 모델을 요구한다.
    2. 이전의 솔루션들은 강력한 대형 언어 모델 (LLM)을 사용하여 다중 점프 수학적 추론을 활용하는 추세였으나, LLM 기반 방법은 현장에서의 배포나 제한적 리소스 상황에서 사용하기 어려운 해결책이다.
    3. 본 논문에서는 TaLM을 활용하여 CoT 추론을 소규모 탭릿 언어 모델 (TaLMs)로 확장하고, CoT 생성과 답 유추에 각각 책임을질 수 있는 특별한 프레임워크 인 TaCo를 제안한다.

###### Diffusion Language Model with Query-Document Relevance for Query-Focused Summarization (https://aclanthology.org/2023.findings-emnlp.735/)
- Anthology ID: 2023.findings-emnlp.735 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Query-Focused Summarization (QFS)"은 특정 질문에 대답할 수 있는 요약을 생성하는 작업입니다. 그러나 주류인 QFS 모델들은 autoregressive 모델로서 장기 종속성 및 exposure bias의 문제에 시달리는 한계가 있습니다.
    2. 이 논문에서는 non-autoregressive diffusion language model인 "QFS-DLM"을 제안하여 QFS 작업의 적응성을 향상시킵니다. 질문과 문서 조각의 관련성을 고려하여 요약 생성 과정을 개선하고, 모델의 손실 함수에 질문과 문서 간의 전역적인 관련성 점수를 통합하여 모델이 고품질 데이터를 선호하고 저품질 데이터를 피할 수 있도록 합니다.
    3. 해당 방법은 Debatepedia와 PubMedQA 데이터셋에서 ROUGE 점수, GPT-4 및 인간 평가에서 최고 성능을 달성하였습니다.

###### Grounded and well-rounded: a methodological approach to the study of cross-modal and cross-lingual grounding (https://aclanthology.org/2023.findings-emnlp.736/)
- Anthology ID: 2023.findings-emnlp.736 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 그라운딩은 보다 완전하고 진정한 의미론적으로 유능한 인공지능 시스템의 개발에 중요한 요소로 주장되고 있다.
    2. 기존 연구들은 그라운딩이 질적으로 다른 일반화를 가능하게 한다고 주장하는 반면, 다른 사람들은 모노모달 데이터의 양으로 보상될 수 있다고 믿고 있다.
    3. 본 논문에서는 텍스트만 있는 모델에 비해 더 풍부한 입력 소스를 제공하는 것의 효과를 연구하기 위한 방법론적인 프레임워크를 제시한다. 이 프레임워크를 사용하여 실험을 한 결과, 교차 모달 그라운딩, 교차 언어 그라운딩 및 언그라운딩 모델 간에 모델 동작의 질적인 차이가 있음을 발견하였다.

###### EMO-KNOW: A Large Scale Dataset on Emotion-Cause (https://aclanthology.org/2023.findings-emnlp.737/)
- Anthology ID: 2023.findings-emnlp.737 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 요즘 몇 년동안 감정-원인 분석이 연구자들의 관심을 받고 있다. 하지만 대부분의 기존 데이터셋은 작은 규모이며 감정 범주도 제한적이다. 이 논문은 15년 동안의 980만개 트윗 데이터를 바탕으로 한 방대한 감정 원인 데이터셋을 소개한다.
    2. 우리는 데이터 수집, 정제, 라벨링, 검증을 위한 종합적인 파이프라인을 설명하며 데이터셋의 신뢰성과 풍부성을 보장한다. 48가지 감정 클래스에 걸쳐 70만 개가 넘는 트윗과 해당 감정 원인 쌍을 포함한 최종 데이터셋은 인간 평가자들로부터 검증되었다.
    3. 이 데이터셋은 다양한 감정 반응을 고려하는 감정을 고려한 시스템의 설계를 가능하게 하기 위해 감정-원인 지식 그래프를 구축하는 것을 용이하게 하는 특징을 가지고 있다. 예전의 작은 규모의 데이터셋에서는 불가능했던 이러한 능력이 이 데이터셋의 독자적인 특징이다.

###### Boosting Inference Efficiency: Unleashing the Power of Parameter-Shared Pre-trained Language Models (https://aclanthology.org/2023.findings-emnlp.738/)
- Anthology ID: 2023.findings-emnlp.738 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 리소스 제한적인 환경에서 매개 변수 공유 사전 훈련 언어 모델 (PLM)은 모델 저장 및 메모리 비용을 상당히 줄여주기 때문에 매우 성공적인 방법으로 부각되고 있다. 그러나 매개 변수 공유는 추론과 관련된 계산 부담을 완화해주지 않으므로, 시간적 제약 또는 계산 자원이 제한된 상황에서는 실용성이 떨어진다.
    2. 우리는 신경 계산 미분 방정식 (ODE)을 기반으로하여 매개 변수 공유 PLM의 추론 효율성을 향상시키는 간단한 기술을 소개한다. 또한, 전체적 또는 부분적으로 공유 모델을 구현할 수 있는 간단한 사전 훈련 기법을 제안한다.
    3. 실험 결과를 통해 의도한 방법의 효과를 자가 회귀 및 자동 인코딩 PLM에서 입증하며, 리소스가 제한된 환경에서 매개 변수 공유 모델을 더 효율적으로 활용할 수 있는 새로운 통찰력을 제공한다.

###### Natural Response Generation for Chinese Reading Comprehension (https://aclanthology.org/2023.findings-emnlp.739/)
- Anthology ID: 2023.findings-emnlp.739 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 기계 독해 (MRC) 벤치마크는 대부분 타겟 코퍼스에서 추출한 구간이나 주어진 후보들 중에서 선택된 답변에 초점을 두고 있어서 높은 품질의 응답의 자연스러운 측면을 무시하고 있다.
    2. 이를 해결하기 위해 저자들은 Penguin이라는 새로운 데이터셋을 구축하여 현실적인 시나리오에서 자연스러운 응답 생성에 대한 연구를 촉진한다.
    3. Penguin은 상대적으로 대규모인 중국어 MRC에서 자연스러운 응답 생성을 위한 첫 번째 벤치마크이며, Prompt-BART와 같은 강력한 베이스라인의 효과적인 설계를 실험 결과로 검증하였다.

###### Treepiece: Faster Semantic Parsing via Tree Tokenization (https://aclanthology.org/2023.findings-emnlp.740/)
- Anthology ID: 2023.findings-emnlp.740 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자연어처리 (NLP) 작업에서 최근에 나온 deep model들은 인과적 인과성으로 향상된 반면, spurious pattern에 의존해서 그 robustness가 제한된다는 것이 보고되었다. 
    2. 기존의 augmentation 기법은 counterfactual들을 dataset에 추가하기 위해 사람들이 작업한 것이거나, 이미 dataset에 있는 대조 사례를 찾기 위해 기계 학습된 것들이 필요했는데, 이러한 augmentation은 여전히 spurious correlation에 영향을 받는다는 한계점이 있다. 
    3. 이 논문에서는 "a set"의 counterfactuals을 합성하고 이 집합의 예측 분포에 대한 집단적인 의사 결정으로 각 용어의 인과 관계를 강력하게 지도하는 방법을 소개한다.

###### Semantic Parsing by Large Language Models for Intricate Updating Strategies of Zero-Shot Dialogue State Tracking (https://aclanthology.org/2023.findings-emnlp.741/)
- Anthology ID: 2023.findings-emnlp.741 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Zero-shot Dialogue State Tracking (DST)"는 작업 지향 대화 형식의 획득과 주석화에 대한 도전을 다루며, 멀리간 업무를 수행함에 따라 대화 상태를 효과적으로 업데이트하기 위해 효과적인 전략을 요구한다.
    2. 우리는 ParsingDST라는 새로운 In-Context Learning (ICL) 방법을 제안하여 실시간 DST에서 더욱 복잡한 업데이트 전략을 도입한다.
    3. 실험 결과, 우리의 방법은 MultiWOZ에서 기존의 ICL 방법들과 비교하여 Joint Goal Accuracy (JGA) 및 슬롯 정확도에서 상당한 향상을 보여주며, 기존의 zero-shot DST 방법을 능가한다.

###### Mitigating Framing Bias with Polarity Minimization Loss (https://aclanthology.org/2023.findings-emnlp.742/)
- Anthology ID: 2023.findings-emnlp.742 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 정치적 편향을 완화하기 위해, 우리는 다양한 정치적 견해를 가진 언론사들이 동일한 사건을 보도할 때 극성화된 언어를 사용하고 있는데 이를 감소시키기 위한 새로운 loss function을 제안한다.
    2. 우리의 실험 결과는 제안된 극성 감소 loss를 적용하면 BART 기반 다중문서 요약 모델에 비해 극성화된 편향을 크게 감소시킬 수 있음을 보여준다.
    3. 더욱 효과적인 방법은 모델이 정보적 편향 (즉, 보도할 정보의 편향된 선택)과 관련된 polarity loss를 최소화하기 위해 훈련되었을 때 나타났다.

###### Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation (https://aclanthology.org/2023.findings-emnlp.743/)
- Anthology ID: 2023.findings-emnlp.743 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. ChatGPT는 인과 추론에 있어서 좋은 해석자지만, 실제로는 좋은 인과 추론자가 아니다. 
    2. ChatGPT의 인과 추론 능력은 프롬프트에서 사용되는 단어에 민감하며, 폐쇄형 프롬프트가 개방형 프롬프트보다 더 잘 작동한다. 
    3. ChatGPT는 명시적 인과관계를 포착하는 데 우수하지만, 암묵적인 인과관계에는 미약한 성능을 보이며, 이벤트의 밀도가 낮고 이벤트 사이의 어휘적 거리가 작은 문장에서 더 잘 작동한다.

###### Steering Large Language Models for Machine Translation with Finetuning and In-Context Learning (https://aclanthology.org/2023.findings-emnlp.744/)
- Anthology ID: 2023.findings-emnlp.744 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델은 기계 번역에 유망한 방법이지만, 현재의 LLM 기반 기계 번역 시스템은 몇 가지 샷 예제의 선택에 매우 의존하며, 과 생성으로 인해 추가적인 후처리가 필요하다.
    2. 번역 지침에 대한 섬세한 조정은 계산적으로 비싸며, 논맥 학습 능력이 과도하게 특수화되어 제약을 약화할 수도 있다.
    3. 이 논문에서는 LoRA를 사용한 어탭터 기반 조정 과정이 전통적인 조정과 성능을 맞추면서 50배 적은 파라미터 수로 작동한다는 것을 보여준다. 이 방법은 몇 가지 샷 활성화 및 후처리나 논맥 예시 없이도 작동한다. 그러나 조정은 일반적으로 몇 가지 샷 성능을 저하시키며 적응 능력을 방해하는 것을 보여준다. 최선의 해결책을 얻기 위해, 우리는 기울기 조정 중 몇 가지 샷 예제를 통합하는 간단한 접근 방식을 제안한다. 10개의 언어 쌍에서 실시한 실험 결과, 우리의 제안 방법은 원래의 몇 가지 샷 가능성을 회복하면서 조정의 추가 이점을 유지한다.

###### How Many Demonstrations Do You Need for In-context Learning? (https://aclanthology.org/2023.findings-emnlp.745/)
- Anthology ID: 2023.findings-emnlp.745 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델들은 몇 개의 입출력 데모(demo)와 그 데모의 중간 추론 단계(chain of thoughts (CoT))를 제공하면 일루스트를 통해 복잡한 추론을 수행할 수 있다. 이 논문에서는 ICL에서 더 적은 수의 데모로 각 테스트 쿼리를 공부하는 방법을 연구한다. 놀랍게도, 무작위로 선택된 하나의 데모만 사용할 때도 큰 성능 하락을 관측하지 않았다.
    2. 데모를 각 테스트 쿼리에 대해 "옳은 대답을 이끄는 긍정적인 데모"와 "잘못된 대답을 만드는 부정적인 데모"로 분류하고 분석 결과, 널리 연구된 데이터셋에는 내재된 편향과 데모의 중복성이 존재한다는 것을 알 수 있다.
    3. 하나의 긍정적인 데모만을 사용한 ICL은 대부분의 이전 연구에서 채택된 다중 데모 ICL보다 더 우수한 성능을 보이며, 그 결과는 LLMs가 입력 쿼리에 대해 긍정적인 데모를 찾는 능력이 다소 약하다는 것을 보여준다. 이러한 편향된 데이터셋에서 평가하기 어렵다. 또한, 다중 데모를 사용한 ICL의 역설적인 동작이 있는데, 긍정적인 데모가 더 많은 경우 정확성이 저하(향상)된다. 이는 데모들 간의 간섭과 편향된 상관 관계 때문에 ICL이 쉽게 오도될 수 있다는 것을 의미한다. 이 분석은 LLMs 훈련, ICL 및 벤치마크 디자인에 대해 해결해야 할 몇 가지 기본적인 도전 과제를 강조한다.

###### Improving word mover’s distance by leveraging self-attention matrix (https://aclanthology.org/2023.findings-emnlp.746/)
- Anthology ID: 2023.findings-emnlp.746 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 두 문장 간의 의미적 유사성을 측정하는 것은 여전히 중요한 과제이다. 그러나, Word Mover's Distance(WMD)는 단어들의 집합 간 최적 정렬을 통해 유사성을 계산하지만 단어 순서를 고려하지 않아, 의미적으로 크게 다른데도 유사한 단어들이 많이 겹치는 문장을 구별하는 것이 어렵다.
    2. 우리는 BERT의 self-attention matrix(SAM)로 표현되는 문장 구조를 WMD에 통합하여 개선하려고 한다. 제안된 방법은 단어 임베딩의 유사성과 SAM의 유사성을 동시에 고려하여 두 문장 사이의 최적 전송을 계산하는 Fused Gromov-Wasserstein distance에 기반한다.
    3. 실험 결과, 제안된 방법은 WMD 및 그 변형에 대해 paraphrase identification에서 개선되었으며 의미적 텍스트 유사성에서 거의 동등한 성능을 보였다.

###### Improving Span Representation by Efficient Span-Level Attention (https://aclanthology.org/2023.findings-emnlp.747/)
- Anthology ID: 2023.findings-emnlp.747 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자연어 처리 태스크에서 span 예측 및 분류와 관련된 고품질의 span 표현은 매우 중요하다.
    2. 이 논문에서는 span 표현을 향상시키기 위해 span-span 상호작용과 포괄적인 span-token 상호작용을 고려한다.
    3. span간의 attention을 적용함으로써 모델의 성능을 개선하고 다양한 span 관련 태스크에서 기준 모델보다 우수한 성능을 보여준다.

###### Long-Horizon Dialogue Understanding for Role Identification in the Game of Avalon with Large Language Models (https://aclanthology.org/2023.findings-emnlp.748/)
- Anthology ID: 2023.findings-emnlp.748 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 불일치하는 이해 관계와 대화 동안의 속임수와 설득은 특히 이해 관계와 목표가 일치하지 않는 다자 간의 대화에서 핵심적인 역할을 한다. 하지만 현재의 큰 언어 모델은 속임수와 설득에 쉽게 현혹되어 장기적인 대화에서 낮은 성능을 보인다. 
    2. 본 논문에서는 Avalon: The Resistance 게임을 소개하여 큰 언어 모델의 의사 결정과 언어 처리 능력을 연구하기 위한 테스트베드와 데이터셋을 제안한다. 이 게임은 협력 및 경쟁적인 환경에서 장기적인 속임수를 보여주는 사람들의 대화를 포함한다. 
    3. 실험 결과로, 최신의 큰 언어 모델은 인간의 성능에 도달하지 못하는 것으로 나타났다. 이를 통해 클레멘슨 의사 결정과 언어 처리 능력을 조사하는 동기부여적인 벤치마크로 활용할 수 있는 데이터셋을 제공한다.

###### Improving Sequential Model Editing with Fact Retrieval (https://aclanthology.org/2023.findings-emnlp.749/)
- Anthology ID: 2023.findings-emnlp.749 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Pre-trained Language Models (PLMs)에서의 지식 오류를 효율적이고 정확하게 수정하는 sequential model editing 작업은 기존 방법들은 조금 수정하는 데에는 잘 작동하지만 수정하는 횟수가 많아지면 성능이 저하되거나 추가 주석 데이터가 필요한 문제가 있다. 
    2. 이 논문에서는 RASE (Retrieval Augmented Sequential Model Editing) 프레임워크를 제안하는데, 이는 fact-patch 메모리에서 관련 사실을 검색하여 편집 일반화를 향상시키고 편집 식별을 가이드하기 위해 사실적인 정보를 활용한다. 
    3. RASE는 대규모 PLMs 편집을 가능하게 하고 서로 다른 편집기의 성능을 높일 수 있다. 또한, ChatGPT에 통합하여 성능을 더욱 향상시킬 수 있다.

###### Battle of the Large Language Models: Dolly vs LLaMA vs Vicuna vs Guanaco vs Bard vs ChatGPT - A Text-to-SQL Parsing Comparison (https://aclanthology.org/2023.findings-emnlp.750/)
- Anthology ID: 2023.findings-emnlp.750 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. ChatGPT의 성공으로 인해 AI 경쟁이 시작되었으며, 연구자들은 상업용 모델의 언어 이해 및 생성 능력을 도달하거나 뛰어넘는 새로운 대형 언어 모델을 개발하기 위해 노력하고 있다.
    
    2. 최근에는 여러 가지 instruction tuning 방법을 통해 GPT-3.5 또는 GPT-4와 유사한 성능을 거론하는 여러 모델들이 등장하였으나, 이러한 주장에 대해 비판적인 시각으로 접근하고 이러한 모델의 실제 효과를 확인하는 것이 중요하다.
    
    3. 본 연구에서는 6개의 인기있는 대형 언어 모델을 서로 비교하여, 제로샷 및 퓨샷 시나리오를 모두 포함하는 9개의 벤치마크 데이터셋에서 Text-to-SQL 파싱 능력을 체계적으로 평가하였으며, 여러 오픈 소스 모델들이 GPT-3.5와 같은 클로즈드 소스 모델의 성능에 대한 괄목할 만한 부족함을 보여주었다. 이는 이러한 모델들 간의 성능 차이를 줄이기 위해 추가적인 연구가 필요함을 강조한다.

###### KBioXLM: A Knowledge-anchored Biomedical Multilingual Pretrained Language Model (https://aclanthology.org/2023.findings-emnlp.751/)
- Anthology ID: 2023.findings-emnlp.751 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대부분의 바이오의료 사전 학습 언어 모델은 단일 언어로만 작동하며, 다양한 언어 요구 사항을 처리할 수 없다. 도메인별 데이터셋의 부족으로 인해 다국어 바이오의료 모델을 훈련시키는 일이 어려움을 겪고 있다.
    2. 우리는 지식-rooted (knowledge-anchored) 접근 방식을 사용하여 다국어 사전 학습 모델 XLM-R을 바이오의료 도메인으로 변환하는 KBioXLM 모델을 제안한다. 이를 위해 단일 언어 데이터셋에 entity, fact, passage 수준의 지식 정합을 고려하여 바이오의료 멀티링구얼 문장을 생성한다.
    3. 실험 결과는 우리의 모델이 크로스-언어 zero-shot 및 few-shot 시나리오에서 단일 언어 및 멀티링구얼 사전 학습 모델보다 큰 개선이 있다는 것을 보여준다. 
    10+ 포인트까지 개선이 이루어진다.

###### Words, Subwords, and Morphemes: What Really Matters in the Surprisal-Reading Time Relationship? (https://aclanthology.org/2023.findings-emnlp.752/)
- Anthology ID: 2023.findings-emnlp.752 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. LLM의 예측은 subword tokenization에 기반하고, 단어를 형태소로 분해하지 않기 때문에 이는 중요한 가정이다. 
    2. 이 논문에서는 orthographic, morphological, BPE tokenization을 사용하여 surprisal estimates를 비교함으로써 이를 주의 깊게 조사한다.
    3. 결과적으로 BPE tokenization에 기반한 예측이 morphological과 orthographic 세그멘테이션에 비해 큰 차이가 없지만, 더 세밀한 분석은 BPE 기반 세그멘테이션에 의존하는 것에 대한 잠재적인 문제를 지적하고, 형태소를 고려한 surprisal estimates에서 유망한 결과를 제시하는 것을 확인할 수 있다.

###### A Zero-Shot Language Agent for Computer Control with Structured Reflection (https://aclanthology.org/2023.findings-emnlp.753/)
- Anthology ID: 2023.findings-emnlp.753 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델들은 MiniWoB++와 같은 실제 컴퓨터 환경에서 상위 수준의 목표를 계획하고 실행하는 능력이 점점 늘어나고 있다. 
    2. 이 논문에서는 trace 예제 없이도 새로운 태스크까지 자율적으로 학습하고 그 제어를 개선할 수 있는 zero-shot 에이전트를 제안한다. 
    3. MiniWoB++의 쉬운 태스크에서는 우리의 zero-shot 에이전트가 최신 기법들보다 더 효율적인 추론을 통해 뛰어난 성능을 보이며, 더 복잡한 태스크에서는 전문가 추적이나 추가 화면 정보에 대한 이전 작업의 장점을 배제하고서도 우수한 성과를 보인다.

###### SteerLM: Attribute Conditioned SFT as an (User-Steerable) Alternative to RLHF (https://aclanthology.org/2023.findings-emnlp.754/)
- Anthology ID: 2023.findings-emnlp.754 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 큰 언어 모델 (Large Language Models, LLM) 의 인간의 선호와 모델의 일치는 인공지능이 인간의 가치와 일관성 있게 도움을 줄 수 있는 가장 중요한 단계이다. 그러나 RLHF는 복잡한 학습 방식과 모델이 사용자가 실행 중에 제어할 수 없는 암묵적인 가치와 일치하는 경향 등으로 인해 고유한 한계를 가지고 있다. 
    2. SteerLM은 사용자가 유추 과정에서 응답을 조절할 수 있는 방법으로, RLHF로 훈련된 많은 최첨단 기준선보다 인간과 자동 평가자들이 선호하는 응답을 생성할 수 있으며 훈련이 훨씬 쉽다는 것을 실험을 통해 보여주고 있다.
    3. SteerLM은 명시적으로 정의된 다차원 속성 집합에 따라 응답을 조건부로 설정하여 도움이 되고 고품질의 응답을 생성하면서도 맞춤 설정 가능성을 유지하는 조정 가능한 AI를 구현한다.

###### IdealGPT: Iteratively Decomposing Vision and Language Reasoning via Large Language Models (https://aclanthology.org/2023.findings-emnlp.755/)
- Anthology ID: 2023.findings-emnlp.755 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최신 언어 모델이 VL 이해 분야에서 많은 진전을 이루었지만, multi-step 추론이 필요한 zero-shot reasoning 태스크에서 부족하다.
    2. 기존 방법들은 domain-specific sub-question decomposing 모델에 의존하고, sub-answers가 충분한 정보를 주지 않더라도 최종 답을 예측하도록 강제한다.
    3. IdealGPT는 large language models를 사용하여 VL 추론을 반복적으로 decompose하는 프레임워크로, sub-questions를 생성하는 LLM, corresponding sub-answers를 제공하는 VLM, 그리고 최종 답을 도출하는 다른 LLM을 사용한다. 이러한 세 가지 모듈이 최종 답에 대한 확신을 가질 때까지 divide-and-conquer 절차를 반복적으로 수행한다.

###### GRI: Graph-based Relative Isomorphism of Word Embedding Spaces (https://aclanthology.org/2023.findings-emnlp.756/)
- Anthology ID: 2023.findings-emnlp.756 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기계 번역에서 단일 언어 임베딩 공간을 사용한 양방향 사전의 자동 생성은 핵심적인 과제다. 현재까지의 연구들은 다른 공간들 사이의 상대적인 등동성을 제어하는 데 실패하고 있다.
    2. 이 논문에서는 상대적인 등동성을 정의하고 계산하는 데 필요한 의미적으로 유사한 단어들의 어휘적 차이의 영향을 함께 고려하는 방법인 GRI를 제안한다.
    3. 실험적 평가 결과, GRI가 기존 연구에 비해 최대 63.6%의 상대적 성능 향상을 이룬다는 것을 보여주고 있다.

###### PersonaLM: Language Model Personalization via Domain-distributed Span Aggregated K-Nearest N-gram Retrieval Augmentation (https://aclanthology.org/2023.findings-emnlp.757/)
- Anthology ID: 2023.findings-emnlp.757 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. PersonaLM은 personalization을 위해 language modeling을 개선하기 위한 "Domain-distributed Span-Aggregated K-nearest N-gram retrieval augmentation"을 소개한다. 이 방법은 흔하지 않은 도메인 관련 단어 패턴을 인식하기 위해 문맥적으로 유사한 n-gram 단어 빈도를 활용한다.
    2. 이 논문에서는 SCAN retriever라는 "Span Aggregated Group-Contrastive Neural"을 제안하여, 동일 그룹에 속하는 span 표현을 함께 묶고, 상관 없는 그룹으로부터의 span을 동의어 공간에서 멀어지도록 하는 방법으로 외부 도메인/사용자의 랭킹을 학습한다.
    3. PersonaLM은 Wikitext-103, UserLibri, 그리고 ASAP 데이터셋에서 perplexity를 10-16% 개선하고, Word Error Rate를 5-8% 줄이는 등 강력한 기준 모델을 대폭 능가한다는 실험 결과를 보여준다. SCAN retriever는 LAMP 벤치마크에서 zero-shot prompting과 few-shot fine-tuning을 통해 7-12% 정확도 향상을 달성하는 사례로 사용되기도 한다.

###### Scaling Vision-Language Models with Sparse Mixture of Experts (https://aclanthology.org/2023.findings-emnlp.758/)
- Anthology ID: 2023.findings-emnlp.758 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 NLP 분야에서는 대규모 비전-언어 모델(VLMs)의 개발을 통해 큰 진전을 이루었다. 그러나 이러한 모델들이 점점 더 크고 복잡해지면서 훈련과 배포가 어려워지는 문제가 있다. 
    2. 이 논문에서는 모델을 작은 전문 서브 모델로 분할하여 공동으로 문제를 해결하는 희소 gate 모델(MoE) 기법의 효과를 탐구한다. 
    3. MoE는 계산 비용이 동일한 밀집 모델보다 우수한 성능을 보일 수 있는 잠재력을 보여주고 있으며, VLMs의 확장에 있어 컴퓨팅 성능을 조절하는 상충 관계에 대한 통찰력을 제공한다.

###### Aspect-Category Enhanced Learning with a Neural Coherence Model for Implicit Sentiment Analysis (https://aclanthology.org/2023.findings-emnlp.759/)
- Anthology ID: 2023.findings-emnlp.759 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 소셜 네트워킹 서비스의 급격한 성장 이후로, aspect-based sentiment analysis (ABSA)는 광범위하게 연구되었지만, 명시적인 의견 단어가 없는 내재적인 감정의 인식은 아직 덜 탐구되고 있다.
    2. 본 논문에서는 aspect-category enhanced learning with a neural coherence model (ELCoM)을 제안한다. 이 모델은 대조학습을 사용하여 문서 수준의 일관성을 포착하며, 하이퍼그래프를 사용하여 문장 수준의 의견을 채굴하여 내재적인 감정 분류에 도움을 준다.
    3. 실험 결과 ELCoM은 벤치마크 데이터셋에서 최고의 성능을 달성하였다. 소스 코드와 데이터는 https://github.com/cuijin-23/ELCoM에서 공개되었다.

###### End-to-end Adversarial Sample Generation for Data Augmentation (https://aclanthology.org/2023.findings-emnlp.760/)
- Anthology ID: 2023.findings-emnlp.760 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 적대적 샘플들은 신경 NLP 모델에 큰 도전을 줍니다. 이 논문에서는 적대적 학습과 데이터 augmentation을 결합한 네트워크 NLP 모델의 robustness를 향상시키는 새로운 A3 접근 방식을 제안합니다.
    2. 우리는 조건부 paraphrasing 모델과 조건 생성기로 구성된 적대적 샘플 생성기를 제안합니다. 후자는 적대적 샘플을 생성하도록 paraphrasing 모델을 가이드하는 조건들을 생성합니다.  또한 사전 훈련된 discriminator를 도입하여 적대적 샘플 생성기가 다른 작업의 데이터 특성에 적응할 수 있도록 합니다.
    3. 실험 결과는 우리의 접근 방식이 훈련된 모델의 전체적인 성능을 향상시킨다는 것을 보여줍니다. 특히, 개선된 모델이 다양한 공격 기법에 대해 robust하다는 것이 입증되었습니다.

###### Query2Triple: Unified Query Encoding for Answering Diverse Complex Queries over Knowledge Graphs (https://aclanthology.org/2023.findings-emnlp.761/)
- Anthology ID: 2023.findings-emnlp.761 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 지식 그래프에서의 복잡한 질문에 대답하는 것은 어려운 작업이다. 이 논문에서는 질의 임베딩 방법을 제안하여 단순한 질문과 복잡한 질문을 분리하여 효율적인 학습을 가능하게 한다. 
    2. 제안된 방법은 단순한 질문에 대한 신경망 링크 오퍼레이터를 먼저 사전 학습하고, 복잡한 질문에 대한 쿼리 인코더를 학습시키는 두 단계로 이루어진다. 이를 통해 고효율로 다양한 복잡한 질문에 대한 상태-오브-더-아트 성능을 달성한다. 
    3. 복잡한 질문을 해결하기 위해 명시적인 모델링을 사용하지 않아도 되는데, 이는 Q2T가 다양한 종류의 신경망 링크 오퍼레이터에 적용 가능하고 효율적인 학습을 가능하게 한다는 것을 의미한다.

###### Self-Polish: Enhance Reasoning in Large Language Models via Problem Refinement (https://aclanthology.org/2023.findings-emnlp.762/)
- Anthology ID: 2023.findings-emnlp.762 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델의 다단계 추론 능력을 향상시키기 위해, 인간과 비슷한 근거를 명시적으로 도출하는 Chain-of-Thought (CoT) 방법을 중심으로 많은 prompting 방법들이 실험되었으나, 더 품질이 높은 문제를 작성함으로써 모델의 추론 성능을 향상시키는 잠재력은 간과되어 왔다.
    2. 이 논문에서는 Self-Polish (SP)라고 불리는 새로운 방법을 제안하여 주어진 문제를 점진적으로 개선시켜 모델의 추론을 용이하게 하는 방법을 제시한다.
    3. 제안된 방법은 CoT와 같은 답변/추론 측면의 다른 prompting 방법과 병행이 가능하며, 다양한 모델에 걸쳐 다섯 가지 추론 벤치마크에서 효과적이고 일관된 결과를 보여준다. 또한, 강건성 평가에서도 훌륭한 성능을 보여준다.

###### Breaking through Deterministic Barriers: Randomized Pruning Mask Generation and Selection (https://aclanthology.org/2023.findings-emnlp.763/)
- Anthology ID: 2023.findings-emnlp.763 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 일반적으로 크고 희박한 모델은 같은 모델 크기 제한 하에서 작고 밀집한 모델보다 더 높은 정확성을 보이는 것으로 알려져 있으며, 이를 동기로 우리는 큰 모델을 훈련시킨 후 가지고 있는 쓸모 없는 뉴런이나 가중치를 가지를 제거하는 모델 가지치기(pruning)를 제안한다. 
    2. 기존 연구들은 단일한 가지치기 기준에 의존하고 있어 다양성이 부족한데 반해, 우리는 복수의 가지치기 마스크를 디자인된 무작위 방식으로 생성한 뒤 효과적인 마스크 선택 규칙과 함께 최적의 마스크를 후보 중에서 선택한다. 
    3. 더불어, 효율성을 향상시키기 위해 여러 개의 마스크를 훈련하는 데 관련된 부하를 완화하기 위한 조기 마스크 평가 전략을 도입함으로써 이러한 접근 방식이 GLUE 데이터셋의 여덟 가지 태스크에서 최고 수준의 성능을 달성함을 보여준다.

###### Eyes Show the Way: Modelling Gaze Behaviour for Hallucination Detection (https://aclanthology.org/2023.findings-emnlp.764/)
- Anthology ID: 2023.findings-emnlp.764 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자연어처리(NLP)에서 환영 감지는 언어의 의미론적과 번역론적 측면을 깊게 이해해야 하는 중요한 과제이다. 이 논문에서는 사용자의 시각(Gaze) 신호를 활용한 심리학적 접근 방법을 제안하여 환영 감지를 수행한다.
    2. 사람들은 분포 유사성을 기반으로 텍스트의 관련 부분에 주목한다는 것을 알아냈으며, 글로벌 주의와 로컬 주의 두 가지 주의 전략을 사용한다. 이를 바탕으로 주의 편향을 반영한 새로운 환영 감지를 위한 심리학적 프레임워크를 제안한다.
    3. 실험적 평가 결과, 제안한 방법은 FactCC 데이터셋에서 87.1%의 균형 재현율을 달성하며, gaze 기반 접근 방법이 환영 감지 과제에 효과적임을 입증하고, 사람들이 불일치를 식별하는 데 사용하는 인지적 과정에도 새로운 통찰을 제공한다.

###### Noisy Pair Corrector for Dense Retrieval (https://aclanthology.org/2023.findings-emnlp.765/)
- Anthology ID: 2023.findings-emnlp.765 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대부분의 dense retrieval 모델은 training query-document pairs이 정확히 일치한다는 가정을 가지고 있는데, 실제 응용에서는 수동으로 코퍼스를 주석 달기가 비용이 많이 들기 때문에 자동으로 수집하는 경우가 많아지면서 mismatched-pair noise가 도입된다. 
    2. 따라서, 이 논문에서는 mismatched-pair noise가 있는 상황에서 효과적인 모델을 어떻게 훈련할 수 있는지를 연구한다. 
    3. 이를 해결하기 위해, detection 모듈과 correction 모듈로 구성된 새로운 방법인 Noisy Pair Corrector (NPC)를 제안한다. NPC는 주석된 positive와 쉬운 negative 문서 사이의 perplexity를 계산함으로써 noise pair를 추정하는 detection 모듈과, noise의 영향을 완화하기 위한 소프트한 지도 신호를 제공하기 위해 지수 이동 평균 (EMA) 모델을 활용하는 correction 모듈로 이루어져 있다. 실험 결과로, NPC가 synthetic와 realistic noise 모두를 처리하는 데에 우수한 성능을 보인다고 나타냈다.

###### Enhancing Accessible Communication: from European Portuguese to Portuguese Sign Language (https://aclanthology.org/2023.findings-emnlp.766/)
- Anthology ID: 2023.findings-emnlp.766 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 현재 포르투갈에서 교육용 언어로 쓰이는 포르투갈 수화 (LGP)는 수동적인 규칙에 의존하는 번역 시스템을 사용한다. 
    2. 본 논문에서는 European Portuguese와 LGP glosses 간의 자동적으로 훈련된 규칙 기반 기계 번역 시스템과 두 개의 신경망 기계 번역 모델을 제시한다.
    3. 밑바탕이 된 시스템을 통해 구축된 LGP-5-Domain 코퍼스와 LGP 전문가들에 의해 주석이 달린 골드 데이터도 제공하며, PE2LGP와 비교해 새로운 규칙 기반 모델은 항상 더 좋은 결과를 보여주고 하나의 신경망 모델과 최고 점수를 겨룬다.

###### Diversifying language models for lesser-studied languages and language-usage contexts: A case of second language Korean (https://aclanthology.org/2023.findings-emnlp.767/)
- Anthology ID: 2023.findings-emnlp.767 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 현재 사용 가능한 형태소 파서/태거가 중요성이 낮은 언어나 언어 사용 환경에서 얼마나 잘 작동하는지, 특히 두 번째 언어인 한국어(L2 Korean)에 초점을 맞추어 연구하였다.
    2. 우리는 (1) 첫 번째 언어(L1 Korean) 데이터로 사전 훈련된 신경망 모델을 다양한 L2 데이터에 대해 훈련시키고, (2) 이 모델이 L2 테스트 세트에서 형태소 파싱/POS 태깅 성능을 측정함으로써 이 문제를 연구하였다. 
    3. 결과적으로, L2 훈련된 모델은 L1 사전 훈련된 기준 모델과 비교하여 일반적으로 도메인-특정 토큰화 및 POS 태깅에서 우수한 성능을 보여주었다. 흥미롭게도, L2 훈련 데이터의 크기를 키우는 것은 모델의 성능 향상을 일관되게 이끌지 못하였다.

###### Improving generalization in large langue model by learning prefix subspaces (https://aclanthology.org/2023.findings-emnlp.768/)
- Anthology ID: 2023.findings-emnlp.768 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 본 논문은 희소 데이터 환경에서 대형 언어 모델의 (LLM) fine-tuning에 초점을 맞추고 있다. 신경망 서브스페이스를 기반으로 LLM의 일반화 능력을 향상시키는 방법을 제안한다.
    2. 기존 방법들은 훈련 데이터가 적은 상황에서 LLM의 일반화를 향상시키기 위해서는 훈련 데이터가 많아야 했으나, 이 논문에서 제안하는 방법은 훈련 데이터가 적은 상황에서도 성능을 향상시킬 수 있다.
    3. 지속적인 접두사 튜닝(prefix-tuning)을 배우는 방법으로 LLM을 훈련시켜 희소 데이터 환경에서의 평균 성능 향상을 보였다.

###### Domain Adaptation for Sentiment Analysis Using Robust Internal Representations (https://aclanthology.org/2023.findings-emnlp.769/)
- Anthology ID: 2023.findings-emnlp.769 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Sentiment analysis는 기업들이 제품 개발과 최적의 마케팅 전략을 위해 고객의 의견을 조사하는 것이 필수적이지만 많은 비용이 드는 작업이다.
    2. 따라서 여러 도메인과 제품, 서비스 간의 차이로 인한 도메인 갭을 완화하기 위해 cross-domain sentiment analysis 방법이 주목받고 있다.
    3. 우리는 데이터 분포를 일치시키고 서로 다른 클래스에 속하는 데이터 표현 사이의 큰 간격을 생성하는 도메인-비의존(embedding space)으로 학습하는 도메인 적응 방법을 개발하였다.

###### KeFVP: Knowledge-enhanced Financial Volatility Prediction (https://aclanthology.org/2023.findings-emnlp.770/)
- Anthology ID: 2023.findings-emnlp.770 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기업의 위험 프로필을 나타내기 위해 금융 변동성 예측은 중요하다. 이 논문에서는 회사의 수익 통화 통화를 통해 금융 metric 지식을 통합하여 텍스트 이해에 반영하는 방법을 제안한다.
    2. KeFVP는 지식 강화 사전 학습 (KePt)을 통해 금융 metric에 대한 지식을 텍스트 이해에 주입하고 조건부 시계열 예측 모듈을 도입하여 텍스트와 가격 정보를 효과적으로 통합한다.
    3. 실제 데이터셋에서 수행된 실험 결과 KeFVP가 다른 최신 기법보다 우수하며 효과적임을 보여준다.

###### A Frustratingly Easy Plug-and-Play Detection-and-Reasoning Module for Chinese Spelling Check (https://aclanthology.org/2023.findings-emnlp.771/)
- Anthology ID: 2023.findings-emnlp.771 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근에는, 중국어 철자 교정 (CSC)은 과연에서 더 직접적고 효율적으로 중국어에 대한 다양한 외부 지식을 활용할 수 있도록 탐지, 추론 및 탐색 (detection, reasoning, and searching) 하위태스크로 분해하는 것이 가능해졌다.
    2. 우리는 기존 SOTA 비자동 CSC 모델과 호환되는 plug-and-play detection-and-reasoning 모듈을 설계하여 성능을 더욱 향상시켰다. 하나의 모델에서 훈련된 탐지-추론 모듈은 다른 모델에도 도움이 될 수 있음을 발견했다. 
    3. 광범위한 실험과 상세한 분석을 통해 제안된 모듈의 효과와 경쟁력이 입증되었다.

###### Asking Clarification Questions to Handle Ambiguity in Open-Domain QA (https://aclanthology.org/2023.findings-emnlp.772/)
- Anthology ID: 2023.findings-emnlp.772 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 개방형 도메인 질의 응답에서 애매한 질문은 정확하고 유일한 답변을 포현하기 어려워 지속적으로 발생한다. 이 논문에서는 애매한 질문의 가능한 해석에 대해 모든 해석에 대한 구분된 질문을 요청하는 대신 사용자의 응답을 이용하여 사용자의 의도와 가장 일치하는 해석을 식별하는 "clarification question"을 요청하는 방법을 제안한다. 
    2. CAmbigNQ라는 데이터셋을 구성하고, (1) 모호성 감지, (2) clarification question 생성, (3) clarification 기반 질의응답이라는 세 가지 태스크로 파이프라인을 정의한다. 
    3. 이 논문은 세 가지 태스크에서 F1 점수를 61.3, 25.1, 40.5로 보여주면서 계속해서 개선이 필요한 것을 보여주고, 향후 연구에 경쟁력 있는 기준을 마련한다.

###### Addressing the Length Bias Challenge in Document-Level Neural Machine Translation (https://aclanthology.org/2023.findings-emnlp.773/)
- Anthology ID: 2023.findings-emnlp.773 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 문서 수준의 신경 기계 번역은 최대 문장 길이를 늘림으로써 문맥 정보를 통합함으로써 유망한 결과를 보여주었다. 그러나 이 접근 방식은 문장의 길이에 대한 편향 문제를 도입하며, 훈련 중에 최대 문장 길이보다 훨씬 짧거나 긴 문장을 디코딩 할 때 번역 품질이 크게 저하된다.
    2. 우리는 모델이 더 짧은 문장을 무시하지 않도록 훈련 데이터를 샘플링하여 서로 다른 문장 길이 간에 보다 균일한 분포를 보장함으로써 이 문제를 해결한다. 또한, 긴 문장을 처리하는 동안 주목의 발산 문제를 완화하기 위해 길이 정규화된 어텐션 메커니즘을 도입한다.
    3. 실험 결과는 우리의 방법이 여러 개의 공개된 데이터셋에서 최고 수준의 결과를 달성할 수 있으며, 더 나아가 우리의 방법이 길이 편향 문제를 크게 완화시킬 수 있음을 보여주었다.

###### EconBERTa: Towards Robust Extraction of Named Entities in Economics (https://aclanthology.org/2023.findings-emnlp.774/)
- Anthology ID: 2023.findings-emnlp.774 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 특정 도메인 내에서 일반적인 언어 모델을 적용하는 것은 효과적인 방법으로 나타났다. 이 논문에서는 경제 문헌에서 entity를 추출하는 작업을 다루고 있다.
    2. EconBERTa라는 대용량 언어 모델을 소개하고, 이를 경제학의 논문들에 pretrain시킨다. 또한, 새로운 경제학 논문들을 Named Entity Recognition (NER)을 위해 전문가에 의해 어노테이팅하여 새로운 데이터셋 ECON-IE를 발표한다.
    3. EconBERTa가 NER 작업에서 최고 성능을 달성하며, 일반화 능력을 상세하게 분석한 결과, 대부분의 오류가 entity의 일부만 감지되거나 더 긴 시퀀스에 대해 추론하지 못하는 것으로 나타났다. 이 한계는 훈련 중에 보지 못한 형태소 순서를 감지하지 못하는 능력부족 때문이다. 이 한계는 훈련 세트의 고유한 인스턴스 수가 증가할수록 줄어든다. 도메인 특화 언어 모델의 일반화 능력을 조사함으로써 인과지식 추출을 위한 NER 모델의 강건성 향상을 위한 길을 열 수 있다.

###### Consonant is all you need: a compact representation of English text for efficient NLP (https://aclanthology.org/2023.findings-emnlp.775/)
- Anthology ID: 2023.findings-emnlp.775 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자연어 처리(NLP)에서 텍스트의 표현은 언어 모델링, 감성 분석, 기계 번역과 같은 다양한 작업에서 중요한 역할을 한다. 이 논문에서는 텍스트를 자음으로만 표현하는 새로운 접근 방식을 제안하며, 성능을 희생하지 않고 향상된 효율성을 제공한다.
    2. 우리는 자음이 모음보다 구분성이 뛰어나다는 사실을 활용하고, 텍스트를 자음으로 표현함으로써 텍스트 데이터를 저장하고 처리하기 위해 필요한 메모리와 연산량을 크게 줄일 수 있다.
    3. 실험 결과, 우리의 자음 기반 표현은 표준 텍스트 표현에 비해 비슷한 성능을 보이며 훨씬 적은 계산 자원을 요구한다는 것을 보여준다. 또한, 우리의 표현은 기존 NLP 모델과 프레임워크와 원활하게 통합될 수 있다는 것을 보여주며 효율적인 텍스트 처리에 대한 실용적인 해결책을 제공한다.

###### Detrimental Contexts in Open-Domain Question Answering (https://aclanthology.org/2023.findings-emnlp.776/)
- Anthology ID: 2023.findings-emnlp.776 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 지식 집약적인 NLP 태스크에서는 더 많은 정보에 접근하는 것이 모델의 최종 성능 향상에 도움이 된다고 알려져 있다. 그러나 paradimn QA 데이터셋에서는 많은 문맥이 모델에 부정적인 영향을 미칠 수 있다는 놀라운 사실이 있다.
    2. 이 논문에서는 질문 응답에 사용되는 retrieve-then-read 아키텍처에서 passages가 어떻게 악영향을 미치는지 분석한다. 실험 결과, 현재의 read 아키텍처는 검색된 passages을 제대로 활용하지 못하며, 전체 passages를 활용하는 것보다 이들의 부분집합을 활용하는 것이 성능을 크게 저하시킨다.
    3. 우리의 연구 결과는 유해한 passages을 걸러내면 두 가지 인기 있는 QA 데이터셋에서 모델의 정확도를 10% 향상시킬 수 있다는 것을 보여준다. 또한, 이러한 결과는 추가적인 훈련이나 데이터 없이 이미 존재하는 retrieval 방법을 활용하여 얻을 수 있다.

###### PMIndiaSum: Multilingual and Cross-lingual Headline Summarization for Languages in India (https://aclanthology.org/2023.findings-emnlp.777/)
- Anthology ID: 2023.findings-emnlp.777 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문은 PMIndiaSum이라는 다국어 및 대규모 요약 말뭉치를 소개하며, 인도 언어에 집중한다. 이 말뭉치는 4개의 언어 패밀리, 14개의 언어, 그리고 196개의 언어 쌍을 대상으로 한 최대 규모의 데이터이다. 
    2. 또한, 데이터 획득, 처리, 품질 관리를 포함한 구축 워크플로우를 상세히 설명한다. 
    3. 실험 결과는 PMIndiaSum 데이터가 인도어 간 요약에 도움이 되는 중요한 역할을 한다는 것을 확인하며, 이 데이터는 공개적으로 이용 가능하며 자유롭게 수정 및 재배포할 수 있다.

###### Beyond Labels: Empowering Human Annotators with Natural Language Explanations through a Novel Active-Learning Architecture (https://aclanthology.org/2023.findings-emnlp.778/)
- Anthology ID: 2023.findings-emnlp.778 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 실제 도메인 전문가들은 (의사 등) 단순히 결정 레이블을 주지 않고도 설명을 함께 제공하는데, 기존의 저자원 학습 기법들은 단어에 초점을 맞추어 설명을 간과하고 있는 것으로 나타났습니다.
    2. 저희는 저자원 상황에서 전문가들이 라벨과 설명을 동시에 주는 현실 세계의 요구를 지원하기 위해 새로운 활성학습(AL) 아키텍처를 제안합니다.
    3. 저희의 AL 아키텍처는 인간의 설명을 가이드로 한 설명 생성 모델, 생성된 설명을 예측에 활용하는 예측 모델, 그리고 설명 주석에서 이점을 얻는 새로운 데이터 다양성 기반 AL 샘플링 전략을 활용합니다.

###### Decoding Stumpers: Large Language Models vs. Human Problem-Solvers (https://aclanthology.org/2023.findings-emnlp.779/)
- Anthology ID: 2023.findings-emnlp.779 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문은 Large Language Models (LLMs)의 문제 해결 능력을 조사하고, 사람의 퍼포먼스와 비교하여 평가한다. 
    2. 새로운 세대의 LLMs는 stumpers(짧은 질문)를 풀 때 우수한 성능을 보이며, 인간의 퍼포먼스를 앞지를 수 있다.
    3. 그러나, 인간은 동일한 문제의 해답을 검증하는 데에는 뛰어난 기술을 보인다고 한다. 이 연구는 LLMs의 인지 능력을 이해하고 다양한 분야에서 문제 해결 능력을 향상시키는 데에 참고할 수 있는 정보를 제공한다.

###### Efficient Cross-Task Prompt Tuning for Few-Shot Conversational Emotion Recognition (https://aclanthology.org/2023.findings-emnlp.780/)
- Anthology ID: 2023.findings-emnlp.780 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 감정인식 대화 (ERC)는 감정인식 가능한 감정적 기계를 개발하기 위한 중요성으로 인해 많이 연구되었다. 최근 PLMs(사전 훈련된 언어 모델)을 이용한 ERC 연구들은 대부분 데이터 중심적이며, 전체 PLMs를 fine-tuning하는 것을 요구한다. 
    2. 이 논문에서는 최소 데이터 및 계산 비용으로 매수 대화식 감정 인식을 개선하기 위해 Cross-Task Prompt Tuning (CTPT)이라고 불리는 기울기 없는 최적화 방법 제안한다.
    3. CTPT는 개별 태스크의 독립적인 지식을 학습하는 기존 방법과는 달리, 다른 소스 태스크의 외부 지식을 활용하여 희소 셋팅에서의 학습 성능을 개선하는 작업 간 공유 가능한 지식을 활용한다.

###### SYMPTOMIFY: Transforming Symptom Annotations with Language Model Knowledge Harvesting (https://aclanthology.org/2023.findings-emnlp.781/)
- Anthology ID: 2023.findings-emnlp.781 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 고위험의 의료결정에서 카카스의 효율성을 향상시키기 위해 완전 자동화 솔루션으로써가 아니라 사람의 주석 작성자의 효율성을 향상시키기 위해 노력하고 있다.
    2. 우리는 SYMPTOMIFY라고 불리는 새로운 데이터셋을 소개한다. 이 데이터셋은 개별 백신 반응에 대한 주석이 달린 예방 접종 부작용 보고서를 포함하고 있다.
    3. 우리는 어떤 방법과 학습 패러다임을 사용했는지에 대한 성능을 평가하여 앞으로 비교와 기준을 제시하는 방법을 제공한다.

###### TokenDrop + BucketSampler: Towards Efficient Padding-free Fine-tuning of Language Models (https://aclanthology.org/2023.findings-emnlp.782/)
- Anthology ID: 2023.findings-emnlp.782 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 언어 모델(LMs)의 성공은 pre-training 단계와 fine-tuning 단계 모두에서 계산적인 어려움을 동반한다. 그 중 fine-tuning 과정에서 가변 길이의 입력 시퀀스로 인해 padding 토큰이 필요하지만, 이러한 padding 토큰이 불필요한 연산을 유발하여 fine-tuning의 효율성을 저하시킨다.
    2. 이 논문에서는 TokenDrop + BucketSampler라는 프레임워크를 제안하여 fine-tuning의 효율성과 정확성을 동시에 개선한다. BucketSampler는 시퀀스 길이의 분산을 줄여 padding 토큰의 수를 감소시키는데, 이전 접근법과는 달리 정확성 감소 없이 대안을 제시한다.
    3. TokenDrop은 과적합을 방지하기 위해 매 에폭마다 각 입력 시퀀스에서 무의미한 토큰의 일부를 임의로 제거하는 새로운 정규화 방법이다. TokenDrop + BucketSampler는 기존의 fine-tuning 방법에 비해 최대 10.61배 정도의 가속을 실현하면서 1.17% 정확성 향상을 보여준다.

###### Unified Representation for Non-compositional and Compositional Expressions (https://aclanthology.org/2023.findings-emnlp.783/)
- Anthology ID: 2023.findings-emnlp.783 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 비 구성적 언어의 정확한 처리를 위해서는 해당 표현에 대한 잘 된 표현을 생성하는 것이 필요한데, 이 논문에서는 BART를 기반으로 한 PIER+이라는 언어 모델을 제안하여 영어에서 비구성적인 표현을 의미 있는 의미론적인 표현으로 만들 수 있다는 것을 보여주었다. 
    2. PIER+로 생성된 표현은 BART보다 임베딩 군집화에 더 나은 일관성 점수를 가지고 있으며, PIE 의미 분류와 구간 탐지의 경우 최신 IE 표현 모델인 GIEA와 비교했을 때 3.12%와 3.29%의 정확도 및 시퀀스 정확도 향상을 보였다.
    3. 이러한 향상은 PIER+의 NLU 작업에서의 성능 (+/- 1% 정확도)을 희생하지 않고 이루어진다.

###### Context Quality Matters in Training Fusion-in-Decoder for Extractive Open-Domain Question Answering (https://aclanthology.org/2023.findings-emnlp.784/)
- Anthology ID: 2023.findings-emnlp.784 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 검색 보완 생성 모델은 생성 중에 추가적인 관련 외부 지식(컨텍스트)을 제공하여 언어 모델로부터 지식을 확장시킨다. 그러나 컨텍스트의 양과 품질이 검색 보완 생성 모델의 성능에 영향을 주는 것이 밝혀졌으나, 이러한 특성이 모델 훈련에 어떤 영향을 미치는지에 대한 연구는 제한적이다.
    2. 본 논문에서는 모델 훈련 중 컨텍스트의 양과 품질이 추출형 개방형 도메인 질문 응답 작업에서 최고 수준의 검색 보완 생성 모델인 FiD의 성능에 어떻게 영향을 미치는지 조사한다.
    3. 실험 결과는 FiD 모델이 훈련 중에 컨텍스트 품질에 과적합되어, 다른 컨텍스트 품질로 평가할 때 최적화되지 않은 성능을 보인다는 것을 보여준다. 이러한 관찰을 바탕으로, 우리는 교차 어텐션 분포에 편향성을 도입하여 특정 컨텍스트 품질에 대한 과적합을 완화하는 방법을 제안하고, 이는 FiD 모델의 성능을 향상시키는 데 효과적임을 시연한다.

###### Error Detection for Text-to-SQL Semantic Parsing (https://aclanthology.org/2023.findings-emnlp.785/)
- Anthology ID: 2023.findings-emnlp.785 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 텍스트-SQL 의미 해석에서 상당한 진전이 있었지만, 기존 파서의 성능은 여전히 완벽하게는 못 미치고 있다. 특히, 딥 러닝을 기반으로 한 파서들은 종종 자신감이 너무 강해서 실제 사용 시 신뢰성이 의심된다.
    2. 본 논문에서는 텍스트-SQL 의미 해석을 위한 파서 독립적 오류 탐지 모델을 제안한다. 코드의 언어 모델을 기반으로 하여 자연어 질문과 SQL 쿼리의 구조적 특징을 학습하는 그래프 신경망을 이용하여 오류 탐지 모델을 개선한다.
    3. 여러 가지 디코딩 메커니즘을 가진 세 개의 강력한 텍스트-SQL 파서들과의 실험 결과, 우리의 방법이 파서 종속적인 불확실성 메트릭보다 우수한 결과를 나타낸다. 또한, 우리의 모델은 아키텍처와 상관없이 텍스트-SQL 의미 해석기의 성능과 사용성을 효과적으로 향상시킬 수 있다.

###### Ultra-Fine Entity Typing with Prior Knowledge about Labels: A Simple Clustering Based Strategy (https://aclanthology.org/2023.findings-emnlp.786/)
- Anthology ID: 2023.findings-emnlp.786 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Ultra-fine entity typing (UFET)은 주어진 개체 언급에 적용되는 다양한 fine-grained 후보들 중에서 시맨틱 타입을 추론하는 작업이다. 이 작업은 많은 타입에 대해 훈련 예제가 적기 때문에 특히 어렵다. 하지만 pre-trained label embeddings을 사용하여 레이블을 의미 도메인으로 클러스터링하는 간단한 기술을 사용하면 기존 방법들의 성능을 향상시킬 수 있다.
    2. 레이블 클러스터는 간단한 후처리 기술에 사용되어 더 나은 결과를 얻을 수 있다.
    3. 둘 다 UFET 모델을 블랙 박스로 취급하여 기존 모델의 성능을 개선하는 데 사용할 수 있다.

###### Multilingual Coarse Political Stance Classification of Media. The Editorial Line of a ChatGPT and Bard Newspaper (https://aclanthology.org/2023.findings-emnlp.787/)
- Anthology ID: 2023.findings-emnlp.787 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 뉴럴 네트워크 기반의 언어 모델이 신문 기사를 작성할 수 있게 되었을 때, 그 신문의 편견이 뉴럴 네트워크의 편견과 일치하는지, 또는 다른지 알아보려고 저자들은 평가 점수를 기반으로 한 공식적인 뉴스매체의 평가를 사용하여 다국어 코퍼스를 만들었다. 
    2. 이 실험에서 우리는 영어, 독일어, 스페인어, 카탈로니아어에서 보이는 반면, ChatGPT나 Bard로 작성된 신문과 유사한 4개 언어의 101개 기사에 이러한 분류기를 적용하여, 전통적인 신문과 마찬가지로 ChatGPT의 편집 선도 시간이 지남에 따라 변화하며, 데이터 기반 시스템이므로 생성된 기사의 성격은 언어에 따라 다르다는 것을 알 수 있었다.

###### Do “English” Named Entity Recognizers Work Well on Global Englishes? (https://aclanthology.org/2023.findings-emnlp.788/)
- Anthology ID: 2023.findings-emnlp.788 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 인기있는 영어 개체명 인식(NER) 데이터셋의 대부분은 미국이나 영국의 데이터를 포함하고 있으며, 세계 각지의 영어 사용 분석에 적합한지 여부는 불명확하다. 
    2. 이 연구에서는 Worldwide English NER Dataset이라는 신문 데이터셋을 구축하여 세계의 저자원 영어 변종에서 NER 모델의 성능을 분석한다. 
    3. CoNLL 또는 OntoNotes 데이터셋으로 훈련된 모델은 Worldwide English 데이터셋에 대한 성능이 현저히 하락함을 확인하였고, Worldwide 데이터셋과 CoNLL 또는 OntoNotes 데이터셋으로 훈련된 결합 모델은 테스트 세트에서 F1이 1-2 정도만 하락하였다.

###### Affective and Dynamic Beam Search for Story Generation (https://aclanthology.org/2023.findings-emnlp.789/)
- Anthology ID: 2023.findings-emnlp.789 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문에서는 흥미로운 이야기를 생성하기 위해 Affective Story Generator (AffGen)을 제안한다. AffGen은 Dynamic Beam Sizing과 Affective Reranking이라는 두 가지 새로운 기법을 사용하여 이야기에 "흥미로운 전개"를 도입한다. 
    2. Dynamic Beam Sizing은 문맥 기반의 다중암 바둑판 모델을 사용하여 예측되기 어려운, 더 흥미로운 단어 선택을 촉진한다. Affective Reranking은 감정 강도를 기준으로 문장 후보들을 우선순위화한다.
    3. 자동 및 인간 평가를 통해 우리는 AffGen이 감정적으로 동기를 부여하고 흥미로운 이야기를 생성하는 기존 기준들보다 우수한 성능을 보여준다는 것을 확인하였다. 우리의 분석은 AffGen의 강점과 약점에 대한 통찰력을 제공한다.

###### Multiview Clickbait Detection via Jointly Modeling Subjective and Objective Preference (https://aclanthology.org/2023.findings-emnlp.790/)
- Anthology ID: 2023.findings-emnlp.790 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 클릭베이트 타이틀은 사람들의 주의와 감정을 조작하기 위해 부정확하거나 오도하는 정보를 유포하며, 소셜미디어의 신뢰성을 크게 해치고 있다. 
    2. 기존의 클릭베이트 검출 모델은 게시물의 객관적 의미를 분석하거나 기사 내용과 연관성을 분석하는 것에만 의존하여 사용자의 주관적인 조작 의도를 파악하지 못한다. 
    3. 따라서, 이 논문에서는 주관적 및 객관적 기준을 동시에 모델링하는 다중 뷰 클릭베이트 검출 모델(MCDM)을 제안한다. MCDM은 주관적 감정과 객관적 컨텐츠 관련성을 모델링하기 위한 두 가지 새로운 보완재 모듈을 도입한다.

###### Let’s Synthesize Step by Step: Iterative Dataset Synthesis with Large Language Models by Extrapolating Errors from Small Models (https://aclanthology.org/2023.findings-emnlp.791/)
- Anthology ID: 2023.findings-emnlp.791 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 데이터 합성은 매우 적은 레이블 데이터로 작은 모델을 훈련시키는 유망한 방법이다. 그러나 합성된 데이터셋은 실제 태스크 데이터 분포와 분포적 불일치 문제가 있다. 
    2. 따라서 이 논문에서는 작은 모델을 합성된 데이터셋으로 훈련시켰을 때 작은 실제 세계 검증 데이터셋에서 대형 언어 모델을 사용하여 발생한 오류를 반복적으로 확장하여 분포 차이를 축소하는 데이터 합성 프레임워크인 S3를 제안한다. 
    3. 다양한 NLP 태스크에서의 실험 결과, S3가 합성 데이터와 실제 데이터 간의 차이를 줄여 작은 모델의 성능을 향상시켜 ZeroGen과 GoldGen에 비해 9.48%와 2.73%의 성능 향상을 보였으며, 인간 주석 데이터로 훈련된 작은 모델과 비교하여 최대 15.17%의 성능 향상을 얻을 수 있다.

###### Identifying Early Maladaptive Schemas from Mental Health Question Texts (https://aclanthology.org/2023.findings-emnlp.792/)
- Anthology ID: 2023.findings-emnlp.792 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 정서치료에서는 부정적 인식으로 인해 현실에도 불구하고 개인이 자신, 타인 또는 세상에 대해 가지는 부적응 스키마나 나쁜 생각이 있을 때, 우울증, 불안, 공황 발작 등과 같은 정신 건강 문제의 저항과 재발로 이어질 수 있습니다. 
    2. 이 논문에서는 스키마 요법기반 상담 세션에서의 필요성과, LLM (Large Language Models) 및 non-LLM 접근 방식을 사용하여 스키마 식별에 대해 연구합니다. 
    3. 우리의 평가 결과, 최신 LLM은 EMS 식별에 효과적일 수 있지만, 예측 결과의 설명 가능성이 부족하고 정확한 "프롬프트"에 지나치게 민감합니다. LLM 및 non-LLM 접근 방식 모두 EMS 라벨이 없는 경우를 신뢰성 있게 대응할 수 없습니다. 그러나 이 두 가지 접근 방식은 상호 보완적인 속성을 가지며, 함께 사용하여 EMS 식별 기술을 개발할 수 있다고 주장합니다.

###### Re-ViLM: Retrieval-Augmented Visual Language Model for Zero and Few-Shot Image Captioning (https://aclanthology.org/2023.findings-emnlp.793/)
- Anthology ID: 2023.findings-emnlp.793 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사전 훈련된 language model(LM)에 비전 인코더를 추가하면 이미지에서 텍스트로의 생성 작업에서 최첨단 성능을 얻을 수 있다. 그러나, 이러한 모델은 많은 시각적 개념과 풍부한 텍스트 설명을 모델링하기 위해 엄청난 모델 파라미터가 필요하고, 새로운 데이터를 효율적으로 포함시키기 어려워 계산량이 많이 드는 fine-tuning 과정이 필요하다.
    2. 이 논문에서는 Flamingo 모델을 기반으로한 Retrieval-augmented Visual Language Model(Re-ViLM)을 소개한다. 이 모델은 외부 데이터베이스에서 관련 지식을 검색하여 zero-shot과 in-context few-shot 이미지-텍스트 생성 작업에서 사용된다.
    3. Re-ViLM은 외부 데이터베이스에 특정 지식을 명시적으로 저장함으로써 모델 파라미터의 수를 줄이고, 데이터베이스를 갱신하는 간단한 방법으로 새로운 데이터를 쉽게 수용할 수 있다. 또한, in-context few-shot 학습 기능을 용이하게 하는 interleaved 이미지와 텍스트 데이터를 구축하였다. 이 모델은 이미지-텍스트 생성 작업에서 특히 zero-shot과 few-shot 생성에서 4배 더 적은 파라미터를 가지면서 성능을 크게 향상시킨다.

###### Syntax Matters: Towards Spoken Language Understanding via Syntax-Aware Attention (https://aclanthology.org/2023.findings-emnlp.794/)
- Anthology ID: 2023.findings-emnlp.794 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Task-oriented 대화 시스템에서 중요한 구성 요소인 Spoken Language Understanding (SLU)은 학계와 산업계에서 지속적인 관심을 받고 있다. 
    2. 우리는 구문 정보를 모델에 통합하여 사용자 발화의 이해를 향상시키고 높은 성능을 얻을 수 있는 SAT(Syntax-aware attention) 모델을 제안한다.
    3. 세 개의 데이터셋 실험 결과, 우리의 모델이 큰 향상과 훌륭한 성능을 보여준다. 또한 SAT는 다른 BERT 기반 언어 모델에 통합하여 성능을 더욱 향상시킬 수 있다.

###### Can ChatGPT Defend its Belief in Truth? Evaluating LLM Reasoning via Debate (https://aclanthology.org/2023.findings-emnlp.795/)
- Anthology ID: 2023.findings-emnlp.795 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. ChatGPT와 GPT-4와 같은 대형 언어 모델들은 복잡한 추론 과제에서 인상적인 성능을 보여주고 있다. 하지만 이 모델들이 진실과 논리에 대한 깊은 이해를 기반으로 추론을 하는지 아니면 상대적으로 표면적인 방식으로 메모리 패턴을 활용하는지에 대해서는 알기 어렵다.
    2. 본 논문에서는 논쟁과 유사한 대화를 통해 LLM의 추론을 테스트하는 방법을 제안한다. 사용자와 함께 정당한 결정을 내리기 위해 LLM에게 질문을 제시하고 논의를 통해 올바른 결론에 도달해야 한다. 이를 통해 LLM이 문제 해결에 필요한 추론의 본질을 깊게 이해하는지 테스트할 수 있다.
    3. 수학, 상식, 논리, BIG-Bench 과제 등 다양한 복잡한 추론 벤치마크에서 우리는 ChatGPT와 같은 LLM이 처음에는 올바른 단계별 해결책을 생성하는 데 탁월한 성과를 보이지만, 자주 불필요한 논증에 도전받을 때 그들의 믿음을 유지하지 못하는 것을 발견하였다.

###### Using In-Context Learning to Improve Dialogue Safety (https://aclanthology.org/2023.findings-emnlp.796/)
- Anthology ID: 2023.findings-emnlp.796 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화 모델들은 더 정확해졌지만, 독성과 편향성을 가진 대화를 생성하는 경우가 많다. 이 논문은 안전한 대화를 위해 retrieval 기반 접근 방법을 연구하고, 안전한 응답에 대한 영감을 얻기 위해 유사한 대화 상황에서 안전한 응답을 찾는 방법을 제안한다. 
    2. 이 방법은 학습 없이도 기존의 대화 안전 접근 방법들과 경쟁력 있는 성과를 보이며, 자동 및 인간 평가에서 독성을 줄이면서 동시에 매력성과 일관성을 유지할 수 있다고 보여준다. 
    3. 추가로 이 방법은 RLHF와 같은 기존의 대화 안전 접근 방법과 함께 사용될 수 있다는 점을 언급한다.

###### HEAR: Hearing Enhanced Audio Response for Video-grounded Dialogue (https://aclanthology.org/2023.findings-emnlp.797/)
- Anthology ID: 2023.findings-emnlp.797 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Video-grounded Dialogue (VGD)"는 비디오, 오디오, 대화 이력을 포함한 다중 모달 입력에 대한 질문에 대답하는 것을 목표로 한다. 
    2. 기존의 VGD 시스템은 비디오와 텍스트 정보만을 활용하여 응답의 품질을 개선할 수 있었지만, 의문에 적절한 응답을 생성하는 과정에서 오디오에서 필요한 정보를 추출하기 어려워 한다.
    3. 따라서, 논문에서는 오디오 데이터를 무시하는 현재의 시스템의 증상인 "deaf response" 문제를 극복하기 위해 HEAR (Hearing Enhanced Audio Response) 프레임워크를 제안한다. HEAR은 질문에서 필요한 경우에만 오디오에 주의를 기울여 신중하게 듣는 것을 목표로 한다.

###### Improving Consistency for Text Summarization with Energy Functions (https://aclanthology.org/2023.findings-emnlp.798/)
- Anthology ID: 2023.findings-emnlp.798 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 현재의 요약 모델은 일관되지 않은 내용을 생성하는데, 이는 출처 문서에서 직접 추론할 수 없는 텍스트이거나 세계적인 지식과 일치하지 않거나 상반된 내용일 수 있다. 이 문제들에 대해 이 논문에서는 "신뢰성(faithfulness)", "사실적임(factuality)", 그리고 "자기주장(self-supportiveness)"을 다루기 위해 새로운 일관성 갈래를 소개한다.
    2. 그러나, 최근의 일관성 개선 연구들은 대부분 "신뢰성"만을 다루고 다른 일관성 현상들을 무시하여 모델의 확장성을 제한하고 있다.
    3. 따라서, 이 연구에서는 "에너지 썸(EnergySum)"을 소개하며 각 유형의 일관성을 반영하는 에너지 스코어를 설계하여 후보 선정 과정에서 활용하는 방법을 제안한다. XSUM 및 CNN/DM 데이터셋에서의 실험 결과, EnergySum은 정확성과 일관성 사이의 trade-off를 완화시킨다.

###### Defining a New NLP Playground (https://aclanthology.org/2023.findings-emnlp.799/)
- Anthology ID: 2023.findings-emnlp.799 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델 (LLM)의 최근 성능 폭발은 자연어 처리 (NLP) 분야에서 80년 역사 중 가장 급격하고 변화를 가져왔다. 이로 인해 이 분야가 동질화되고 리소스를 많이 소요하는 우려가 생겼다.
    2. 본 논문은 이러한 새로운 상황에서 많은 학계 연구자, 특히 박사과정 학생들에게 불리한 상황을 야기하였다. 따라서 본 논문은 이를 극복하기 위해 이론적 분석, 새로운 도전적인 문제, 학습 패러다임 및 교차 학문적 응용 분야를 다루는, 20개 이상의 박사 학위 논문 수준의 연구 방향을 제안한다.

###### UPTON: Preventing Authorship Leakage from Public Text Release via Data Poisoning (https://aclanthology.org/2023.findings-emnlp.800/)
- Anthology ID: 2023.findings-emnlp.800 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "공개적인 글 작성자가 이미 적대적인 모델이 글을 분석하여 작성자를 파악하는 상황에서 '익명성'을 유지하고자 할 때 어떻게 계정이 교란(sabotage)될 수 있을까?"라는 질문에 대한 해답으로 블랙박스 데이터 조로 (black-box data poisoning methods)를 활용하여 글의 작성자 특징을 약화시켜 작성자 파악을 어렵게 만드는 새로운 방법을 소개한다.
    2. UPTON은 이전의 적대적 공격과 달리 테스트 샘플을 수정하는 것이 아닌 모델의 출력을 바꾸는 백도어 작업과도 다르다. UPTON은 실제 작성자의 청정 글을 사용하여 이미 훈련된 AA 모델에 효과적이다.
    3. 실험 결과 UPTON은 AA 모델의 정확도를 실용적이지 않은 수준(약 35%)으로 낮추면서 글은 여전히 가독성을 유지한다.

###### IAEval: A Comprehensive Evaluation of Instance Attribution on Natural Language Understanding (https://aclanthology.org/2023.findings-emnlp.801/)
- Anthology ID: 2023.findings-emnlp.801 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 인스턴스 속성(IA)은 테스트 예측과 관련하여 훈련 인스턴스를 구분하는 작업으로, 데이터 이해와 데이터 처리 최적화에 도움을 주는데, 이러한 IA 방법들의 평가에 대한 문제가 여전히 남아있다.
    2. 이 연구에서는 sufficiency, completeness, stability, plausibility라는 네 가지 요구 사항을 커버하는 체계적이고 포괄적인 평가 체계인 IAEval을 소개합니다. 이를 평가하기 위해 독자적인 메트릭을 설계하였습니다.
    3. IAEval을 사용하여 세 가지 대표적인 IA 방법을 평가하고, 이를 통해 IA 방법들을 종합적으로 비교할 수 있는 능력을 입증하였습니다. IAEval을 사용하면 연구자들은 모델 디버깅과 같은 응용 프로그램에 가장 적합한 IA 방법을 선택할 수 있습니다.

###### Scene Graph Enhanced Pseudo-Labeling for Referring Expression Comprehension (https://aclanthology.org/2023.findings-emnlp.802/)
- Anthology ID: 2023.findings-emnlp.802 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Referring Expression Comprehension (ReC)은 자연어 표현에 기반하여 이미지의 객체를 지역화하는 작업이다. 기존 방법들은 대부분 지도 학습 문제로 접근하여 이미지-텍스트 쌍이나 지역-텍스트 쌍과 같은 비용이 많이 드는 주석이 필요하다. "
    2. 저자들은 scene graph 기반 프레임워크를 제안하여 고품질 가짜 지역-질의 쌍을 자동으로 생성한다. 
    3. 실험 결과, 이 방법은 기존의 가짜 라벨링 방법보다 RefCOCO, RefCOCO+ 및 RefCOCOg에서 각각 약 10%, 12% 및 11%의 성능 향상을 보여주며, RefCOCO 데이터셋에서 최고 성능 비지도 학습 방법보다 15% 이상 우수하다.

###### Noisy Self-Training with Synthetic Queries for Dense Retrieval (https://aclanthology.org/2023.findings-emnlp.803/)
- Anthology ID: 2023.findings-emnlp.803 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 존재하는 신경 기반 정보 검색 모델들은 학습 데이터가 풍부하고 학습 데이터가 증가함에 따라 성능이 향상되는 유망한 결과를 보여주지만, 고품질의 주석이 달린 데이터를 수집하는 것은 과도하게 비용이 많이 든다. 
    2. 따라서 우리는 외부 모델에 의존하지 않고 신경 기반 정보 검색기를 자체 진화 방식으로 개선하는 새로운 노이즈 있는 자기 학습 프레임워크를 도입한다.
    3. 실험 결과, 우리의 방법은 일반 범주 (예: MS-MARCO)와 영역 밖 범주 (즉, BEIR)의 정보 검색 벤치마크에서 기존 방법보다 일관되게 향상되었다. 저자원 환경에서의 추가 분석은 우리의 방법이 데이터 효율성이 뛰어나며 레이블이 달린 학습 데이터의 30%만으로도 경쟁력 있는 기준선보다 뛰어나다는 것을 보여준다. 또한 리랭커 트레이닝을 위해 프레임워크를 확장하면, 제안된 방법은 다양한 도메인의 작업에서 추가적인 향상을 보인다.

###### Leveraging GPT-4 for Automatic Translation Post-Editing (https://aclanthology.org/2023.findings-emnlp.804/)
- Anthology ID: 2023.findings-emnlp.804 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "번역 후 편집" 작업은 NMT 모델의 출력물을 수정하고 품질을 향상시키기 위해 여전히 필요하지만, 이 연구에서는 GPT-4를 사용하여 다양한 언어 쌍에 대한 NMT 출력물을 자동으로 수정하는 방법을 탐구한다.
    2. GPT-4는 번역 후 편집 작업에 능숙하며, 번역 품질을 개선하고 다양한 종류의 주요 번역 오류를 제거하는 의미 있는 수정물을 생성한다.
    3. 그러나 GPT-4가 가끔 가상의 수정물을 생성할 수 있다는 점을 보여줌으로써, 전문 번역 후 편집기로서의 사용에 주의가 필요함을 알려준다.

###### Uniform Complexity for Text Generation (https://aclanthology.org/2023.findings-emnlp.805/)
- Anthology ID: 2023.findings-emnlp.805 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델은 요약 및 기계 번역과 같은 생성형 NLP 태스크에서 유망한 결과를 보였지만, 서술 생성의 문맥에서는 여전히 일관된 텍스트 생성 요소를 포함하지 못하는 문제점이 있다. 
    2. 이 논문에서는 텍스트 생성을 위한 통제 가능한 복잡성을 담은 벤치마크 테스트인 UCTG를 제안한다. 
    3. 실험 결과, GPT-2와 같은 모델들은 작문에서 사용된 입력 프롬프트의 복잡성을 유지하는 데 어려움이 있음을 발견하였다.

###### Cue-CoT: Chain-of-thought Prompting for Responding to In-depth Dialogue Questions with LLMs (https://aclanthology.org/2023.findings-emnlp.806/)
- Anthology ID: 2023.findings-emnlp.806 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화 시스템에는 강력한 언어 이해 및 생성 능력이 있는 ChatGPT와 같은 대형언어 모델이 있지만, 이전의 작업들은 사용자 상태에 대한 언어적 단서를 간과하고 대화 맥락을 기반으로 직접 응답을 생성하도록 유도한다.
    2. 이 논문에서는 대화 중에 나타나는 언어적 신호를 활용하여 LLM의 추론을 개선하는 Cue-CoT 방법을 제안한다. 이를 통해 더 개인 맞춤형이고 매력적인 응답을 제공할 수 있다.
    3. 실험 결과, Cue-CoT 방법은 모든 데이터셋에서 표준적인 프롬프트 방법보다 도움이되고 수용 가능성 면에서 우수한 성능을 보여주었다.

###### CONTRASTE: Supervised Contrastive Pre-training With Aspect-based Prompts For Aspect Sentiment Triplet Extraction (https://aclanthology.org/2023.findings-emnlp.807/)
- Anthology ID: 2023.findings-emnlp.807 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "기존의 효율적인 fine-tuning 기술에 초점을 맞춘 ASTE(Aspect Sentiment Triplet Extraction) 작업은 있는 반면, 우리는 여러 ABSA 작업의 성능을 동시에 향상시킬 수 있는 일반적인 접근 방식을 제안하고자 한다."
    2. 우리는 CONTRASTE라는 새로운 사전 훈련 전략을 제시하여 ASTE 성능을 향상시킨다. 또한, 우리의 기술이 ACOS, TASD, AESC와 같은 다른 ABSA 작업에서의 장점을 나타낼 수 있음을 보여준다.
    3. 우리는 aspect-based prompts를 설계하고 마스킹된 감정과 함께 aspect-aware sentiment 표현을 훈련하는 대조학습을 적용함으로써 사전 훈련을 진행한다. 또한, 태깅 기반의 Opinion Term Detector 및 회귀 기반의 Triplet Count Estimator와 기존 모델을 결합하는 멀티태스크 접근 방식을 제안한다.

###### Towards Anytime Fine-tuning: Continually Pre-trained Language Models with Hypernetwork Prompts (https://aclanthology.org/2023.findings-emnlp.808/)
- Anthology ID: 2023.findings-emnlp.808 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 빠르게 변화하는 세상에서 사전 훈련 된 모델을 다양한 도메인과 작업에 적용하기 위해 계속적 사전 훈련이 긴요하다. 이 논문에서는 기존의 계속적 사전 훈련 접근 방식의 언제든지(feel fine-tuned)의 효과를 조사하였고, 보이지 않는 도메인에서 감소하는 성능을 확인하였다.
    2. 따라서 우리는 prompt-guided continual pre-training 방법을 제안한다. 이 방법은 하이퍼 네트워크를 훈련하여 도메인 특정 프롬프트를 생성한다. 이렇게 생성된 프롬프트는 fine-tuning시에 도메인 식별기능을 줄이고 도메인 간의 지식 전달을 촉진한다.
    3. 실험 결과에서는 우리의 방법이 두 개의 실제 데이터셋에서 각각 3.57%와 3.4%의 개선 효과를 보여주었다.

###### Language Guided Visual Question Answering: Elevate Your Multimodal Language Model Using Knowledge-Enriched Prompts (https://aclanthology.org/2023.findings-emnlp.809/)
- Anthology ID: 2023.findings-emnlp.809 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 시각적 질문 응답 (VQA)은 이미지에 대한 질문에 대답하는 작업이다. VQA는 이미지와 질문에 대한 이해를 전제로 하여 자연어 응답을 제공한다. 이 논문에서는 이미지에 없는 상식 지식, 세계 지식, 아이디어와 개념에 대한 추론을 필요로 하는 지식 강화 VQA에 초점을 맞춘다.
    2. 우리는 라셔널, 이미지 캡션, 씬 그래프 등의 형태로 언어 가이던스 (LG)를 사용하는 멀티모달 프레임워크를 제안하여 질문에 보다 정확하게 답변한다.
    3. CLIP 및 BLIP 모델을 사용하여 A-OKVQA, Science-QA, VSR, IconQA 데이터셋의 다중 선택 질문 응답 작업에서 우리의 방법을 평가하고, 우리는 언어 가이던스의 사용이 시각적 질문 응답에 대한 간단하지만 강력하고 효과적인 전략임을 보여주었다.

###### XLS-R fine-tuning on noisy word boundaries for unsupervised speech segmentation into words (https://aclanthology.org/2023.findings-emnlp.810/)
- Anthology ID: 2023.findings-emnlp.810 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 발화 스트림에서 명확한 단어 경계가 없어서 비문텍스트 지도 없이 말문자열을 단어 단위로 분할하는 작업은 특히 도전적이다.
    2. 이 논문에서는 최신 self-supervised speech models을 활용하여 낮은 리소스 조건에서도 새로운 작업에 빠르게 적응하는 것을 입증한 학습 방법을 사용한다.
    3. 제안된 방법은 여러 언어를 포함한 다섯 개의 언어집합에서 측정된 F1 점수가 과거보다 약 130% 높은 새로운 최고 성능을 보이면서도 fine-tuning 도중 미처 보지 못한 언어들의 음성도 zero-shot 방식으로 세그멘트화 할 수 있다.

###### Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data (https://aclanthology.org/2023.findings-emnlp.811/)
- Anthology ID: 2023.findings-emnlp.811 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Chain-of-thought (CoT)은 복잡한 추론 작업에서 대형 언어 모델의 추론 능력을 향상시키는데 성공했지만, 대부분의 CoT 연구는 합리적인 체인들을 수동으로 디자인하여 LLMs에게 제공하여 현실적인 응용에 어려움을 가지고 있다.
    2. 이 논문은 작은 레이블된 데이터셋으로부터 합리적인 체인들을 자동으로 추가하고, 레이블에 기반하여 저품질의 체인들을 제거하여 후보 체인의 풀을 생성하는 방법인 AutomateCoT를 제안한다.
    3. Automate-CoT은 CoT 기법을 빠르게 다른 작업에 적용할 수 있도록 하며, 실험적 결과는 산술 추론, 상식적 추론, 기호적 추론 및 비추론 작업에서 경쟁력 있는 성과를 보여준다.

###### What Makes it Ok to Set a Fire? Iterative Self-distillation of Contexts and Rationales for Disambiguating Defeasible Social and Moral Situations (https://aclanthology.org/2023.findings-emnlp.812/)
- Anthology ID: 2023.findings-emnlp.812 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 도덕적 판단은 특정 맥락에 매우 의존하는데, 실생활 상황에서 인간의 도덕적 판단의 세세한 부분과 복잡성을 정확하게 나타내기 위해서는 다양한 유연한 맥락 이해가 필요하다.
    2. 이 논문에서는 행동이 도덕적으로 더 또는 덜 허용되는 상황을 설명하는 지식과 함께 상황의 이유를 정당화하는 태스크, 'defeasible moral reasoning'을 소개한다.
    3. 학습 데이터의 질을 높이기 위해 GPT-3의 작은 양의 seed knowledge로부터 시작하여, self-distillation, targeted filtering, self-imitation learning 등의 반복적인 과정을 거쳐 얻은 학생 모델을 사용하여 고품질의 데이터셋을 구축하고 최종적으로 우수한 성능을 달성했다.

###### An Empirical Study on Multiple Knowledge from ChatGPT for Emotion Recognition in Conversations (https://aclanthology.org/2023.findings-emnlp.813/)
- Anthology ID: 2023.findings-emnlp.813 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 감정 인식에서 다양한 지식(co-reference, 주제, 감정 원인 등)은 효과적이었지만, ERC에서 이러한 지식을 탐색하는 것은 주석 달린 데이터의 부족과 관련 비용이 높은 문제 때문에 아직 미개척된 상태입니다. 
    2. 대형 언어 모델(LLMs)의 등장은 이 공백을 메우는데 유망한 가능성을 제시합니다. 
    3. 우리는 LLMs에 의해 생성된 이러한 지식을 효과적으로 통합하기 위해 Multiple Knowledge Fusion Model (MKFM)을 제안하고, ERC에서 이러한 지식이 모델에 미치는 영향을 실험적으로 연구하였습니다.

###### Exploiting Contrastive Learning and Numerical Evidence for Confusing Legal Judgment Prediction (https://aclanthology.org/2023.findings-emnlp.814/)
- Anthology ID: 2023.findings-emnlp.814 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 법적인 사건에 대한 설명 텍스트가 주어졌을 때, 법적 판단 예측(LJP)은 사건의 범죄, 적용되는 법조항, 그리고 처벌기간을 예측하는 것을 목표로 한다. 이 논문에서는 텍스트의 숫자를 활용하여 처벌기간을 예측하기 위한 표현을 강화하는 방법과, 각각의 subtask에 동시에 도움을 주기 위해 positive 예측 쌍을 구성하는 최적의 전략을 탐색하기 위한 moco-based supervised contrastive learning을 제안한다. 
    2. 이전 연구에서는 표준 교차 엔트로피 분류 손실로 다양한 오류를 구분할 수 없었고, 처벌기간을 예측하기 위해 텍스트에서의 숫자를 무시했다.
    3. 실험 결과, 제안된 방법은 혼동되는 법적인 사건에 대해 특히 새로운 최고 성능을 달성한다. Ablation study도 각 구성 요소의 효과를 입증한다.

###### One For All & All For One: Bypassing Hyperparameter Tuning with Model Averaging for Cross-Lingual Transfer (https://aclanthology.org/2023.findings-emnlp.815/)
- Anthology ID: 2023.findings-emnlp.815 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다국어 언어 모델은 레이블된 인스턴스 없이도 대상 언어에서 작업을 수행할 수 있는 zero-shot cross-lingual transfer (ZS-XLT)를 가능하게 한다. 하지만, 현재 모델 선택은 소스 언어 검증에 기반하고 있으며, 이는 대상 언어에서의 성능을 최적화하는 데는 부족한 모델 선택을 한다.
    2. 이 논문에서는 하이퍼파라미터 튜닝을 대체하기 위해 다른 실행 결과의 모델을 누적 평균하는 무감독 평가 프로토콜을 제안한다. 
    3. 실험 결과, 소스 언어 검증에 기반한 기존 모델 선택은 suboptimal한 ZS-XLT 성능을 보여주고, 하지만 우리의 누적 평균 모델은 ZS-XLT 성능을 향상시키고 대상 언어 검증 성능 기반의 모델 선택과 근사한 결과를 보여준다.

###### Dimensions of Online Conflict: Towards Modeling Agonism (https://aclanthology.org/2023.findings-emnlp.816/)
- Anthology ID: 2023.findings-emnlp.816 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 민주적 대화에 있어서의 다양한 시각과 강력한 토론을 촉진하기 위해 아고니즘은 중요한 역할을 한다. 그러나 온라인 갈등의 경우, 건설적인 대화를 저해하는 혐오적인 적대감이 존재한다. 이 논문에서는 트위터 대화를 수집하여 갈등의 다양한 차원을 라벨링하는 포괄적인 주석 스키마를 제안한다.
    2. 주석 스키마를 이용하여 약 4,000개의 대화에 대해 여러 라벨을 부여한 후, 로지스틱 회귀 및 트랜스포머 기반 모델을 학습시킨다. 이를 통해 대화의 맥락을 반영하여 갈등을 식별하고 주제의 변동에 강인한 모델을 구축한다.
    3. 결과는 맥락적 라벨이 갈등을 식별하는 데 도움이 되며, 콘텐츠의 조절에 기여할 수 있는 개념화된 갈등 차원과 풍부하게 주석 달린 데이터셋을 제공한다.

###### Learning under Label Proportions for Text Classification (https://aclanthology.org/2023.findings-emnlp.817/)
- Anthology ID: 2023.findings-emnlp.817 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 데이터가 각 클래스에 대한 비율만 주어지는 LLP(Learning from Label Proportions) 환경에서 NLP 작업을 수행하는 방법을 제안한다.
    2. 기존 기법인 DLLP의 불규칙성을 파악하여 robust한 새로운 공식을 제안하였다.
    3. self-supervised 목적과 결합한 우리의 방법은 다양한 메트릭에서 장단거리 텍스트를 포함한 대규모 모델에 대해 기준선과 비교하여 약 87%의 실험 구성에서 더 좋은 결과를 도출하였다.

###### MetaReVision: Meta-Learning with Retrieval for Visually Grounded Compositional Concept Acquisition (https://aclanthology.org/2023.findings-emnlp.818/)
- Anthology ID: 2023.findings-emnlp.818 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사람들은 과거 경험에서 습득한 기본 개념을 상기하고 이 기본 개념을 새로운 조합에 대해 일반화하여 새로운 구성 개념을 학습하는 능력을 갖고 있다. 이 논문에서는 이러한 인간의 구성 학습 절차에서 영감을 받아, MetaReVision이라는 retrieval-enhanced meta-learning 모델을 제안하여 시각적으로 기반된 구성 개념 학습 문제를 해결한다.
    2. 제안된 MetaReVision은 retrieval 모듈과 meta-learning 모듈로 구성되어 있으며, 검색된 기본 개념을 지원 세트로 활용하여 시각-언어 모델을 meta-train하여 기반된 구성 개념 인식에 사용한다. 
    3. 실험 결과, MetaReVision은 경쟁적인 기준선보다 우수한 성능을 보이며, retrieval 모듈이 구성 학습 과정에서 중요한 역할을 함을 보여준다.

###### PR-MCS: Perturbation Robust Metric for MultiLingual Image Captioning (https://aclanthology.org/2023.findings-emnlp.819/)
- Anthology ID: 2023.findings-emnlp.819 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이미지 캡션 평가를 위한 자동 평가 메트릭은 lexical perturbation에 취약한 취약점이 있다. 본 논문에서는 이러한 변형에 강한 Perturbation Robust Multi-Lingual CLIPScore(PR-MCS)를 제안한다.
    2. PR-MCS는 복수의 언어에 적용 가능한 참조 없는 이미지 캡션 평가 메트릭으로, 원본 텍스트와 편집된 텍스트를 구별하기 위해 CLIP의 텍스트 인코더를 fine-tuning하는 방법을 사용하여 perturbation의 강건성을 달성한다.
    3. 실험에서 PR-MCS는 모든 다섯 개 언어에서 다양한 변형 유형의 lexical noise를 잘 포착하면서 인간의 판단과 강한 상관관계를 유지하며, 기준 메트릭을 크게 능가한다.

###### Pre-training Multi-task Contrastive Learning Models for Scientific Literature Understanding (https://aclanthology.org/2023.findings-emnlp.820/)
- Anthology ID: 2023.findings-emnlp.820 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 과학문학 이해와 같은 태스크에서 사전 훈련된 언어 모델 (LM)은 기존 작업에서의 유용성을 보여왔으며, 특히 대조학습을 통해 튜닝된 경우에 더 효과적이다. 
    2. 그러나 다양한 과학문학 이해 작업에서 사전 훈련 데이터를 공동으로 활용하는 것은 아직 탐구되지 않은 분야이다.
    3. 이 논문에서는 하나의 통합적인 프레임워크인 SciMult를 제안하며, 과학문학 이해 작업 간의 공통 지식 공유를 도모하고 작업별 특정 기술이 서로 간섭하지 않도록 하는 데 초점을 맞춘다.

###### BLM-s/lE: A structured dataset of English spray-load verb alternations for testing generalization in LLMs (https://aclanthology.org/2023.findings-emnlp.821/)
- Anthology ID: 2023.findings-emnlp.821 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 현재 NLP 모델들은 이미 잘 알려진 벤치마크에서 인간 수준의 성능을 달성하고 있는 것으로 보인다. 이에 이러한 모델들이 자연어의 더 깊은 이해를 테스트하기 위해 새로운 벤치마크가 필요하다. 
    2. 이 논문에서는 사람의 분석적 지능 테스트에 영감을 받은 Blackbird의 언어 매트릭스를 도입하여 Predicate-Argument 구조에 대한 새로운 BLM(task)을 정의하고 이를 연구하기 위한 구조화된 데이터셋을 개발한다. 
    3. 이 데이터셋은 동사 변형의 문맥 문장에서 다른 변형을 선택하는 문제를 다루고, 문장 임베딩에 동사 정보가 어떻게 인코딩되며 모델이 인수 구조의 복잡한 속성에 대해 어떻게 일반화되는지에 대한 연구를 촉진하기 위해 만들어졌다.

###### Efficiently Enhancing Zero-Shot Performance of Instruction Following Model via Retrieval of Soft Prompt (https://aclanthology.org/2023.findings-emnlp.822/)
- Anthology ID: 2023.findings-emnlp.822 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "명령어 따르기 모델의 제로샷 성능을 향상시키려면 전체 데이터셋 크기 또는 모델 크기를 확장해야 하지만, 이 논문에서는 prompt tuning을 통해 얻은 soft prompt의 검색을 통해 효율적으로 hard prompt의 제로샷 태스크 일반화를 돕는 방법을 탐구한다."
    2. "특히, prompt tuning을 통해 각 prompt에 대한 soft prompt 임베딩을 학습하고, 이를 기반으로 훈련 데이터 인스턴스와의 매핑을 저장한 다음 추론 중에 쿼리 인스턴스에 가장 가까운 훈련 인스턴스와 해당 prompt 임베딩을 검색한다."
    3. "soft prompt의 검색은 추가 파라미터를 0.007%만 소모하면, 테스트되지 않은 태스크에서 T0의 성능을 향상시키며, BIG-bench 벤치마크의 T0 평균 정확도를 2.39% 포인트 향상시킨다. 또한, 유사한 정답 선택 형식에 대해 훈련된 소스 임베딩을 검색하는 것이 유사한 태스크 유형에 대해 훈련된 소스 임베딩보다 중요하다는 흥미로운 결과를 보고한다."

###### Geographical Erasure in Language Generation (https://aclanthology.org/2023.findings-emnlp.823/)
- Anthology ID: 2023.findings-emnlp.823 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델은 방대한 양의 세계 지식을 인코딩하지만, 이러한 모델은 인터넷 데이터의 특정 그룹에 대한 정보를 지나치게 포착해 알려진 그룹에 대한 정보 불균형이 생성된 언어로 전파될 위험이 있다.
    2. 이 연구에서는 언어 모델이 특정 국가의 등장을 미리 예측하는 지리적 소거의 한 형태를 연구하고 운용한다.
    3. 훈련 코퍼스에서 특정 국가의 언급 빈도가 낮을수록 지리적 소거가 강하게 상관되는 것을 발견하였고, 특정 목적을 위해 세부적으로 조정하여 소거 현상을 완화할 수 있다.

###### Can Foundation Models Watch, Talk and Guide You Step by Step to Make a Cake? (https://aclanthology.org/2023.findings-emnlp.824/)
- Anthology ID: 2023.findings-emnlp.824 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. AI의 엄청난 발전에도 불구하고, 실제 상황에서 사람들에게 견주어진 작업을 대화를 통해 협력적인 지침을 제공하는 시스템을 개발하는 것은 여전히 큰 과제이다.
    2. 이 논문에서는 사람 사용자와 사람 강사 간의 자연스러운 상호작용을 기반으로 한 새로운 멀티모달 벤치마크 데이터셋인 WTaG를 만들었다.
    3. 다양한 작업에서 기존 모델을 빠르게 적응시킬 수 있는지 연구하였고, 양적, 질적 및 인간 평가 결과에서 일부 경우에는 특정 작업 훈련 없이도 모델이 어느 정도의 성능을 보일 수 있지만, 빠르고 신뢰할 수 있는 적응은 여전히 큰 과제로 남아있다.

###### Scaling Laws vs Model Architectures: How does Inductive Bias Influence Scaling? (https://aclanthology.org/2023.findings-emnlp.825/)
- Anthology ID: 2023.findings-emnlp.825 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Transformer 모델의 확장 특성에 대한 관심이 많아졌으나,다양한 귀납적 가중치와 모델 아키텍처의 스케일링 특성에 대한 연구가 많이 이루어지지 않았다.
    2. 이 논문은 Transformer, Switch Transformer, Universal Transformer, Dynamic convolutions, Performers, MLP-Mixers 등의 10가지 다양한 모델 아키텍처의 스케일링 특성에 대해 체계적인 연구를 수행하였고, 모델 아키텍처가 스케일링과 관련하여 중요한 고려사항임을 보여주었다.
    3. 또한, 다양한 스케일에서 최상의 성능을 보이는 모델이 다르게 변할 수 있다는 사실을 실험을 통해 입증하였다. 이 연구 결과는 현재 커뮤니티에서 모델 아키텍처를 평가하는 방법에 상당한 영향을 미칠 것으로 기대된다.

###### Not All Languages Are Created Equal in LLMs: Improving Multilingual Capability by Cross-Lingual-Thought Prompting (https://aclanthology.org/2023.findings-emnlp.826/)
- Anthology ID: 2023.findings-emnlp.826 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델은 다국어 능력이 뛰어나지만, 언어에 따라 성능이 크게 달라지는 문제가 있다.
    2. 본 연구에서는 크로스-언어적 사고 활성화 (XLT)라는 간단하고 효과적인 방법을 소개하여 LLM의 다국어 능력을 체계적으로 향상시킨다.
    3. 실험 결과, XLT는 다양한 다국어 태스크의 성능을 획기적으로 향상시키고, 다국어 간 각 태스크의 평균 성능과 최고 성능 간의 격차를 크게 줄였다. 특히, 산술적 추론 및 개방형 질의응답 태스크에서 평균 10점 이상의 성능 향상을 보였다.

###### DetectLLM: Leveraging Log Rank Information for Zero-Shot Detection of Machine-Generated Text (https://aclanthology.org/2023.findings-emnlp.827/)
- Anthology ID: 2023.findings-emnlp.827 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델과 함께 텍스트의 자동 생성이 급속히 진행되면서, 기계 생성 텍스트를 수동으로 구별하는 것은 현실적으로 불가능하다. 이를 방지하기 위해 기계 생성 텍스트를 감지하는 방법을 개발해야 한다. 
    2. 본 논문에서는 머신러닝 라인크 정보를 활용하여 기계 생성 텍스트를 감지하기 위한 두 가지 zero-shot 방법을 소개한다. 
    3. 실험 결과, 제안한 방법들은 이전 연구에 비해 3.9와 1.75 AUROC(Area Under the Receiver Operating Characteristic) point를 개선하였으며, 실제 사용에 더 적합한 DetectLLM-NPR 방법이 적은 수의 변형만으로도 동일한 성능을 달성할 수 있다는 것을 보여준다.

###### From Complex to Simple: Unraveling the Cognitive Tree for Reasoning with Small Language Models (https://aclanthology.org/2023.findings-emnlp.828/)
- Anthology ID: 2023.findings-emnlp.828 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 본 논문은 dual process theory를 기반으로 인간의 복잡한 논리적 추론 능력을 언어 모델에 적용하는 첫 번째 연구이다.
    2. 이 연구에서는 인과 시스템과 비판적 추론 시스템이라고 불리는 두 가지 주요 구성 요소를 사용하여 Cognitive Tree (CogTree)를 구성한다.
    3. 실험 결과, GPT-3.5 (175B 파라미터)와 비교하여 파라미터 수가 7B 이하로 훨씬 작은 언어 모델로도 유사한 성능을 달성할 수 있다는 것을 보여준다.

###### Macedon: Minimizing Representation Coding Rate Reduction for Cross-Lingual Natural Language Understanding (https://aclanthology.org/2023.findings-emnlp.829/)
- Anthology ID: 2023.findings-emnlp.829 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 교차 언어 자연어 이해(Cross-lingual NLU)는 NLP의 기본적인 작업 중 하나이다. 최근의 사전 훈련된 다국어 언어 모델들은 교차 언어 NLU 작업에서 탁월한 성능을 보여주었다. 그러나 이러한 모델들은 충분한 훈련 데이터를 필요로 하며, 저자원 언어에는 제한적인 데이터가 있을 경우 정확도가 떨어질 수 있다.
    2. 이 논문에서는 풍부한 고언어 자료와 제한된 저자원 언어 자료로 크로스-언어 모델을 훈련하는 방법을 연구한다. 기존의 방법들은 적대적 훈련과 상호 정보 추정을 통해 언어에 중립적인 표현을 학습하려고 하지만, 데이터가 아주 제한적인 경우에는 정확한 데이터 분포를 추정하기가 어렵다.
    3. 그래서 우리는 representation coding rate reduction 방법을 통해 언어 관련 정보를 제거하는 새로운 접근법인 Macedon을 제안한다. Macedon은 언어 관련 정보를 인코딩하는 데 추가적인 코드를 사용하지 않는다. 실험 결과 Macedon이 최신 교차 언어 NLU 접근 방식보다 우수한 성능을 보인다.

###### Adversarial Robustness for Large Language NER models using Disentanglement and Word Attributions (https://aclanthology.org/2023.findings-emnlp.830/)
- Anthology ID: 2023.findings-emnlp.830 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. LLM (Large Language Models)은 여러 응용 프로그램에 널리 사용되지만, 복잡한 명명된 엔터티 인식 (NER) 태스크에서는 fine-tuned pre-trained language models (PLM)에 비해 성능이 낮다고 알려져 있다.
    2. 이 논문은 LLM NER 모델과 그 instruction fine-tuned variant가 공격에 대해 얼마나 robust한지 조사한다.
    3. 특히, entity와 non-entity 영향을 별도로 포착하는 임베딩을 학습하는 데 도움이 되는 disentanglement와 중요한 단어를 식별하는 word attribution 기술을 이용한 새로운 공격 방법을 제안한다.

###### LLMs – the Good, the Bad or the Indispensable?: A Use Case on Legal Statute Prediction and Legal Judgment Prediction on Indian Court Cases (https://aclanthology.org/2023.findings-emnlp.831/)
- Anthology ID: 2023.findings-emnlp.831 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델 (LLM)은 법과 같은 중대한 영역에서의 효능을 검토하기 위해, 인도의 대법원 사건에 대해 최신 LLM을 사용하여 법령 예측과 판결 예측 두 가지 인기있는 작업에 적용하였다.
    2. 우리는 LLM이 법령 예측에서 우수한 예측 성능을 보이는 반면, 판결 예측에서는 여러 표준 모델과 비교했을 때 성능이 낮아지는 것을 확인하였다.
    3. LLM이 생성하는 설명은 예측과 함께 중간에서 양호한 품질을 보이며, LLM 예측 결과에는 성별 및 종교적 편향이 있는 것으로 나타났다. 또한, LLM을 이러한 중요한 법적 작업에 배치하는 윤리적 문제에 대한 법적 전문가의 의견을 제시한다.

###### You Are What You Annotate: Towards Better Models through Annotator Representations (https://aclanthology.org/2023.findings-emnlp.832/)
- Anthology ID: 2023.findings-emnlp.832 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자연어 처리(NLP) 작업에서 Annotator disagreement는 일반적이다. 이 논문은 annotators의 다양한 시각을 직접 모델링하고, annotator embeddings과 annotation embeddings을 생성하여 annotators의 혼자만의 독특한 특성을 모델링하는 방법을 제안한다.
    2. 제안된 접근 방식을 TID-8 데이터셋에서 실험한 결과, annotator disagreement를 통해 모델이 더 나은 학습을 할 수 있으며, 모델 사이즈를 1% 미만으로 증가시킬 수 있다.
    3. 이러한 embedding을 통해 개별 annotators의 독특한 경향과 주관성을 포착함으로써, 우리의 모델은 다양한 시각을 포용할 수 있게 된다.

###### Large Language Models Are Better Adversaries: Exploring Generative Clean-Label Backdoor Attacks Against Text Classifiers (https://aclanthology.org/2023.findings-emnlp.833/)
- Anthology ID: 2023.findings-emnlp.833 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 백도어 공격은 트리거 텍스트를 훈련 및 테스트 데이터에 삽입하여 모델 예측을 조작한다. 
    2. 기존의 텍스트 백도어 공격보다 실제적이고 도전적인 클린-레이블 공격에 초점을 맞추어, 균일한 스타일 기반 트리거를 텍스트에 자동으로 삽입하는 LLMBkd 공격을 제안한다. 
    3. 이 논문에서는 LLMBkd의 효과성과 효율성을 입증하며, 적은 노력과 모델 훈련 없이 다양한 스타일에 걸쳐 공격 성공률을 일관되게 높일 수 있다고 보여준다.

###### Noise-Robust Fine-Tuning of Pretrained Language Models via External Guidance (https://aclanthology.org/2023.findings-emnlp.834/)
- Anthology ID: 2023.findings-emnlp.834 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사전 학습 다음에 fine-tuning으로 이루어지는 PLMs (Pretrained Language Models)은 자연어 처리 분야에서 상당한 발전을 이루었지만, 복잡한 주석 작업으로 인해 데이터 레이블은 종종 소음이 발생하며, 이러한 소음 레이블로 PLMs을 fine-tuning하는 전략을 개발하는 것이 필수적이다.
    2. 이 논문에서는 소음 레이블을 사용하여 PLMs을 fine-tuning하기 위해 ChatGPT와 같은 Large Language Models (LLMs)의 안내를 도입한 혁신적인 접근 방식을 소개한다.
    3. 실제로 합성 및 실제 소음 데이터셋에 대한 실험을 통해 우리의 프레임워크가 최첨단 기준선에 비해 우수한 장점을 갖고 있음을 보였다.

###### Probabilistic Tree-of-thought Reasoning for Answering Knowledge-intensive Complex Questions (https://aclanthology.org/2023.findings-emnlp.835/)
- Anthology ID: 2023.findings-emnlp.835 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델(LLM)은 chain-of-thought (CoT) 추론을 통해 지식에 근거한 복잡한 질문에 대답할 수 있지만, 필요한 지식이 모델 파라미터에 없거나 최신이 아닐 때 사실적으로 잘못된 추론 결과를 생성하는 경향이 있다.
    2. 이 논문에서는 확률적 Tree-of-thought Reasoning (ProbTree)라는 새로운 접근 방식을 제안한다. 이 방법은 쿼리 트리로 복잡한 질문을 번역한 후, 확률적 추론을 사용하여 답변 가능성을 고려하며 리프 노드에서는 파라미터 지식을 사용하는 Closed-book QA와 외부 지식을 사용하는 Open-book QA의 자신감 있는 답변 중 더 좋은 답을 선택함으로써 부정적인 검색 문제를 해결한다.
    3. 본 논문에서 제안하는 ProbTree 방법은 SOTA 방법보다 우수한 성능을 나타내며, 지식에 근거한 확률적 추론의 효과를 입증한다.

###### Ensemble-Instruct: Instruction Tuning Data Generation with a Heterogeneous Mixture of LMs (https://aclanthology.org/2023.findings-emnlp.836/)
- Anthology ID: 2023.findings-emnlp.836 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. In-context learning (ICL)을 사용하여 Self-Instruct나 Alpaca와 같은 기술은 많은 양의 인간 지도를 필요로하지 않고도 강력한 대화형 에이전트를 훈련시킬 수 있다. 하지만 이러한 방법들은 매우 큰 언어 모델에 의존하므로 제한된 라이센스를 가지고 있다. 본 논문에서는 이러한 기술을 훨씬 작은 크기의 언어 모델에 적용하여 보다 효과적인 방법을 제안하였다.
    2. 제안된 방법은 ICL 템플릿을 카테고리화하고 단순화하여 언어 모델이 더 쉽게 학습할 수 있도록 하며, 여러 언어 모델 출력을 앙상블하여 고품질의 합성 예시를 선택하는 데 도움을 준다.
    3. 실험 결과, 우리는 제안된 방법이 Self-Instruct보다 더 높은 품질의 지시문 튜닝 데이터를 생성하며, 기본 언어 모델 및 지시문 튜닝 언어 모델의 성능을 크게 향상시키고, 작은 튜닝된 언어 모델이 더 유용한 예시를 생성한다는 것을 알게 되었다.

###### The Less the Merrier? Investigating Language Representation in Multilingual Models (https://aclanthology.org/2023.findings-emnlp.837/)
- Anthology ID: 2023.findings-emnlp.837 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다중 언어 모델을 사용하여 자연어 처리(NLP) 과제의 성능을 개선하는 교양 언어 모델은 여러 언어를 하나의 모델에 통합하여 교차 언어 전이 학습을 이용한다. 
    2. 그러나 현재 있는 다양한 언어 모델들은 일부 언어를 지원하지 않으며, 특히 저자원 환경에서는 성능이 떨어지는 경우가 많다. 
    3. 이 논문에서는 다중 언어 모델에 대한 다양한 언어의 언어적 표현과 모델의 성능을 조사하여 언어 그룹별로 다른 특징을 분석하고 이를 개선할 수 있는 방안을 제시한다.

###### SuperTweetEval: A Challenging, Unified and Heterogeneous Benchmark for Social Media NLP Research (https://aclanthology.org/2023.findings-emnlp.838/)
- Anthology ID: 2023.findings-emnlp.838 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 소셜 미디어를 위한 NLP의 성숙도가 일반 목적의 모델, 메트릭 및 벤치마크와 비교하면 많이 부족하다. 이로 인해 특정 task에 대해 최고의 성능을 보여주는 모델과 다른 모델과의 비교가 어렵다.
    2. 이 문제를 해결하기 위해 저자들은 SuperTweetEval이라는 통합 벤치마크를 소개한다. 이 벤치마크는 다양한 태스크와 데이터셋을 포함하며, 별도로 조합, 수정 및 구축되었다.
    3. SuperTweetEval 위에서 다양한 모델의 성능을 비교한 결과, 최신의 언어 모델 기술에도 불구하고 소셜 미디어에서의 NLP는 여전히 어려운 문제임을 보여준다.

###### Enabling Unsupervised Neural Machine Translation with Word-level Visual Representations (https://aclanthology.org/2023.findings-emnlp.839/)
- Anthology ID: 2023.findings-emnlp.839 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근에는 단일언어 말뭉치만 사용하여 상당한 성과를 내고있는 비지도형 신경 기계 번역이 중요한 발전을 이루고 있다. 그러나 이러한 방법들은 여전히 유사한 단어들을 헷갈리는 기본적인 결함이 있는데, 이러한 문제를 해결하기 위해 이 논문에서는 단어 수준에서 이미지를 사용하여 어휘 매핑을 증강하는 방법을 제안한다.
    2. 특히, 이 방법은 모델에 시각적 표현을 삽입하여 해당 임베딩 레이어 정보를 수정한다. 또한, 가시적 행렬을 채택하여 이미지가 다른 관련없는 단어에 미치는 영향을 분리한다. 
    3. 30만 개 이상의 자체 수집 이미지와 함께 수행된 실험은 더 정확한 단어 번역을 생성하는 효과가 있음을 검증하며, 최대 2.81 BLEU 점수 향상을 달성하였다. 이는 양방향 사전을 사용하는 것과 비교해 별로나아 보내도 좋다.

###### Pragmatics in Language Grounding: Phenomena, Tasks, and Modeling Approaches (https://aclanthology.org/2023.findings-emnlp.840/)
- Anthology ID: 2023.findings-emnlp.840 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사람들은 명시적으로 말하는 내용 이상의 의미를 부여하기 위해 맥락을 크게 의존하며, 간결하면서도 효과적인 커뮤니케이션을 가능하게 한다. 
    2. 인간과 자연스럽게 상호작용하기 위해서는 사용자를 대상으로 하는 AI 시스템도 유사한 논리적 스킬을 요구하며, 언어를 효과적으로 사용하기 위해 공유된 언어 목표와 관습, 시각적인 세계와 같은 다양한 유형의 맥락에 의존해야 한다. 
    3. 우리는 기존의 지면화된(settings)된 환경과 논리 모델링 접근법을 조사하고, 각 작업이 언어적 의미를 어떻게 풍부하게 하는지 분석한다. 또한, 미래의 지면화된 작업 설계에 대한 권고사항을 제시하고, 보다 폭넓은 커뮤니케이션 맥락과 기회에 초점을 맞춘 연구 방향을 제안한다.

###### MISCA: A Joint Model for Multiple Intent Detection and Slot Filling with Intent-Slot Co-Attention (https://aclanthology.org/2023.findings-emnlp.841/)
- Anthology ID: 2023.findings-emnlp.841 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 본 연구는 복잡한 현실 상황과 관련이 있는 다중 의도 감지와 슬롯 채우기 문제의 연구가 점점 인기를 얻고 있다고 말하며, 최근에는 그래프에 기반한 합성 모델이 주로 사용되지만, 이러한 모델은 의도-슬롯 간 상관관계 정보를 잘못된 레이블 노드로 전달할 수 있는 그래프 구성으로 인해 불확실성이 발생할 수 있다고 지적한다. 
    2. 본 논문에서는 이러한 문제를 해결하기 위해 MISCA라는 합성 모델을 제안한다. MISCA는 의도-슬롯 공동 어텐션 메커니즘과 레이블 어텐션 메커니즘을 도입하여 상관관계를 효과적으로 포착하고 그래프 구성에 의존하지 않고 의도와 슬롯 간의 상관관계 정보를 양방향으로 전달하도록 한다. 실험 결과는 MISCA가 이전 모델보다 우수한 성능을 보여주며 MixATIS 및 MIxSNIPS 두 개의 벤치마크 데이터셋에서 새로운 최고 성능을 달성한다고 보여준다. 
    3. 이에 MISCA의 어텐션 메커니즘의 효과적인 성능을 강조한다.

###### Enhancing Emotion Recognition in Conversation via Multi-view Feature Alignment and Memorization (https://aclanthology.org/2023.findings-emnlp.842/)
- Anthology ID: 2023.findings-emnlp.842 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화에서의 감정 인식 (ERC)은 자연어 처리 커뮤니티에서 증가하는 관심을 받고 있다. 이전 연구에서는 주로 사전학습 언어 모델 (PLM)을 fine-tuning하여 의미-전망 특징을 추출한 다음, 다양한 그래프 신경망을 통해 이러한 의미-전망 특징을 기반으로 문맥-전망 특징을 모델링하였다.
    2. 그러나 간단한 그래프 신경망만을 통해 발화 간 상호작용을 완벽하게 모델링하기는 어렵고, 의미-전망 특징과 문맥-전망 특징이 완전히 일치하지 않는다.
    3. 본 논문에서는 사전학습 대화 모델을 사전 지식 도구로 삼아 상호작용을 모델링하고 의미-전망 특징과 문맥-전망 특징을 맞추기 위해 지도 대조 학습을 채택하였다. 두 가지 전망의 특징은 보완적인 방식으로 함께 작동하여 다양한 관점에서 ERC에 기여한다. 또한, 소수의 인스턴스로부터 tail class의 패턴을 학습하기 위해 메모리화를 통한 새로운 반항적 학습 패러다임을 제안한다. 네 가지 널리 사용되는 벤치마크에서 지속적으로 최고의 결과를 얻을 수 있었다. 반복적인 실험을 통해 우리가 제안한 다중 전망 특징 정렬과 메모리화의 효과를 입증하였다.

###### Mandarin classifier systems optimize to accommodate communicative pressures (https://aclanthology.org/2023.findings-emnlp.843/)
- Anthology ID: 2023.findings-emnlp.843 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이전 연구에 따르면, 명사 분류에 대한 이전 작업들은 성별 시스템이 언어 학습과 처리에 대한 의사소통 압력을 맞추기 위해 최적화되어 있다고 주장하고 있습니다.
    2. 우리는 중국어처럼 성별이 없다고 여겨지는 언어도 성별표시기와 같은 기능적 역할을 하는 명사 분류 장치를 가지고 있다는 것을 보여줍니다.
    3. 레이피히 코퍼라스 콜렉션(LCC)에서 추출한 약 1백만 개의 중국어 명사구와 해당 fastText 임베딩을 기반으로, 우리는 명사-분류 기호 조합이 성별 시스템을 구성하는 동일한 빈도, 유사성 및 공기출현 상호작용에 민감함을 보여줍니다.

###### Probing Representations for Document-level Event Extraction (https://aclanthology.org/2023.findings-emnlp.844/)
- Anthology ID: 2023.findings-emnlp.844 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "프로빙 분류기 프레임워크는 다양한 자연어 처리 (NLP) 애플리케이션에 대한 딥 뉴럴 네트워크 모델의 해석에 사용되었다. 이 연구는 문장 수준의 NLP 태스크에 대해 주로 집중되었다. 이 논문은 문서 수준의 정보 추출 (IE)에 대한 학습된 표현에 프로빙 패러다임을 처음 적용한 것이다."
    2. "우리는 문서 수준 이벤트 추출에 관련된 표면적, 의미적 및 이벤트 이해 능력을 분석하기 위해 여덟 가지 임베딩 프로브를 설계했다. 이를 표준 데이터셋에서 학습한 세 가지 다른 LLM 기반 문서 수준 IE 접근 방식에서 배운 표현에 적용했다."
    3. "우리는 이 모델들의 훈련된 인코더들이 인자 감지와 레이블링을 어느 정도 향상시킬 수 있는 임베딩을 제공하지만, 이벤트 수준의 태스크는 약간 향상시키지만, 일관성 및 이벤트 유형 예측에 도움이 되는 정보를 포기해야 함을 발견했다."

###### Cultural Compass: Predicting Transfer Learning Success in Offensive Language Detection with Cultural Features (https://aclanthology.org/2023.findings-emnlp.845/)
- Anthology ID: 2023.findings-emnlp.845 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 언어 기술의 보편성이 증가함에 따라, 문화적 다양성을 고려하는 것이 머신 러닝 분야에서 중요해졌다는 것을 알 수 있다. 특히, 문화적 뉘앙스에 크게 의존하는 주관적인 작업인 Offensive Language Detection (OLD)과 같은 작업에 대해서도 문화적 특징이 교차 문화적 전이 학습의 성공을 정확하게 예측할 수 있는지에 대한 연구가 필요하다. 
    2. 이 연구에서는 문화적 특징과 전이 학습의 효과를 연구하였고, 연구 결과 문화적 가치 조사가 OLD 작업에서 교차 문화적 전이 학습의 성공을 예측할 수 있으며, 모욕적인 단어 간 거리를 사용하면 더욱 개선될 수 있음을 밝혀냈다.
    3. 이러한 결과를 바탕으로 우리는 문화적 정보를 데이터셋에 통합하고, 문화적 정보가 풍부한 조사와 같은 데이터 소스를 활용하여 문화적 적응력을 향상시킬 것을 권장한다. 이 연구는 포용적이고 문화적으로 민감한 언어 기술을 위한 노력의 한 걸음이라고 할 수 있다.

###### Linguistically Motivated Sign Language Segmentation (https://aclanthology.org/2023.findings-emnlp.846/)
- Anthology ID: 2023.findings-emnlp.846 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 수화 세그멘테이션은 수화 처리 시스템에서 중요한 작업이며, 수화 인식, 전사, 기계 번역과 같은 후속 작업을 가능하게 한다. 이 연구에서는 개별 수화와 몇 개의 수화로 구성된 구(phrase)로의 세그멘테이션을 고려한다.
    2. 주어진 수화 언어 말뭉치에서 관찰된 언어적 단서를 바탕으로, 두 작업을 동시에 모델링하기 위한 새로운 접근법을 제안한다. 
    3. 제안된 방법을 통해 최종 모델이 다른 수화 언어로 이루어진 도메인 외 비디오 컨텐츠에도 적용될 수 있음을 보여주며, 광학 플로우와 3D 핸드 정규화를 포함시킴으로써 모델의 효율성을 증가시킬 수 있다.

###### Re-weighting Tokens: A Simple and Effective Active Learning Strategy for Named Entity Recognition (https://aclanthology.org/2023.findings-emnlp.847/)
- Anthology ID: 2023.findings-emnlp.847 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 제한된 주석 자원으로 텍스트 및 이미지 분류 작업에서 기계 학습 모델을 향상시키기 위해 널리 사용되는 액티브 러닝은 Named Entity Recognition (NER) 분야에서 상대적으로 덜 주목받고 있다.
    2. NER에서 데이터 불균형의 난제로 인해 시퀀스 라벨러는 충분한 학습 신호를 갖지 못해 액티브 러닝의 효과가 제한되고 있다.
    3. 이 논문에서는 동적으로 부드러운 가중치를 각각의 토큰에 할당하는 새로운 재가중 기반 액티브 러닝 전략을 제안하고, 다양한 토큰 수준의 획득 함수와 호환되며 강인한 액티브 러너의 개발에 기여한다.

###### Language-Agnostic Bias Detection in Language Models with Bias Probing (https://aclanthology.org/2023.findings-emnlp.848/)
- Anthology ID: 2023.findings-emnlp.848 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사회적 편향성을 평가하기 위해 "LABDet"라는 강력하고 언어에 중립적인 기법을 사용하여 PLM에 있는 사회적 편향성을 평가한다. 
    2. 우리는 LABDet을 사용하여 훈련된 PLM에서의 인종적 편향성을 조사하고, 이는 역사적이고 정치적인 맥락과 일치하는 결과를 보임을 보여준다.
    3. LABDet은 다양한 템플릿과 언어에 대하여 신뢰성과 적용 가능성을 검증하였으며, 코드와 데이터셋을 공개하였다.

###### CompleQA: Benchmarking the Impacts of Knowledge Graph Completion Methods on Question Answering (https://aclanthology.org/2023.findings-emnlp.849/)
- Anthology ID: 2023.findings-emnlp.849 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 지식 그래프 완성(KGC)의 성공이 downstream 태스크에서 얼마나 성능 향상으로 이어지는지는 깊게 연구되지 않은 중요한 질문이다. 이 논문은 대표적인 KGC 방법이 Knowledge Graph Question Answering(KGQA)에 미치는 영향을 포괄적으로 평가하기 위해 새로운 벤치마크인 CompleQA를 소개한다.
    2. CompleQA는 5개의 독립적인 도메인에서 300만 개의 삼중자를 포함하는 지식 그래프와 5000개 이상의 질문-답변 쌍, 이러한 질문들과 일치하는 완성 데이터셋을 포함한다.
    3. 우리는 두 개의 최신 KGQA 시스템과 함께 네 가지 잘 알려진 KGC 방법을 평가하여, 효과적인 KGC가 지식 그래프의 불완전성이 질문-답변 성능에 미치는 영향을 상당히 완화시킬 수 있음을 보여준다. 놀랍게도, 최상의 성능을 낸 KGC 방법은 최고의 QA 결과로 이어지지 않을 수 있어 KGC를 수행할 때 downstream 응용 프로그램을 고려해야 함을 강조한다.

###### Improving Multi-Criteria Chinese Word Segmentation through Learning Sentence Representation (https://aclanthology.org/2023.findings-emnlp.850/)
- Anthology ID: 2023.findings-emnlp.850 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 CWS(Co-witness Segmentation) 모델들은 사전 훈련된 언어 모델의 지식과 경쟁력 있는 성능을 보였다. 하지만 이러한 모델들은 전체 문맥의 의미를 이해하는 것보다 단어 내에서의 분할 지식을 학습하는 경향이 있다.
    2. 이 문제를 해결하기 위해 우리는 다양한 드롭아웃 마스크에서 비지도학습 문장 표현 학습을 다중 기준 훈련 프레임워크에 통합하는 context-aware 접근법을 소개한다. 
    3. 실험 결과, 우리의 접근법은 9개의 CWS 벤치마크 데이터셋 중 6개의 F1 점수에서 최고 성능을 보이며, 9개 중 8개의 OOV(Out-of-vocabulary) 재현율에서도 최고 성능을 보인다. 더 나아가 다양한 문장 표현 목적으로 큰 개선을 이끌어낼 수 있다는 것을 실험으로 발견했다.

###### A Joint Matrix Factorization Analysis of Multilingual Representations (https://aclanthology.org/2023.findings-emnlp.851/)
- Anthology ID: 2023.findings-emnlp.851 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. joint matrix factorization 기반의 분석 도구를 제안하여, 다국어 및 단일 언어 모델의 잠재 표현을 비교할 수 있다.
    2. 이 도구를 사용하여 다국어 사전 훈련 모델에 의해 학습된 표현이 얼마나 그리고 어떤 방식으로 형태-문법적 특징이 반영되는지 조사하였다.
    3. 우리의 연구 결과는 상위 및 하위 레이어 간 형태-문법적 정보 인코딩의 차이를 보여주며, 이는 언어 속성에 영향을 받는 특정 카테고리의 차이를 나타낸다. 또한, 인자분해 결과의 계층적 클러스터링은 언어학자들이 수작업으로 만든 계통수와 관련이 있다.

###### Don’t Add, don’t Miss: Effective Content Preserving Generation from Pre-Selected Text Spans (https://aclanthology.org/2023.findings-emnlp.852/)
- Anthology ID: 2023.findings-emnlp.852 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근에 소개된 Controlled Text Reduction (CTR) 태스크는 전통적인 summarization-style 태스크에서 텍스트 생성 단계를 적용시키기 위해 사용되는데, 입력 텍스트의 특정 내용("하이라이트")에 맞는 일관된 텍스트를 생성하는 모델을 도전한다. 
    2. 현재 신뢰할만한 CTR 모델이 없고, 기존 기준 모델의 성능은 보통적인 유용성에는 부족하다. 
    3. 이 논문에서는 이러한 한계를 극복하기 위해 content-preservation 제약 조건을 강화하는 방법과 silver training 데이터의 품질을 개선하는 방법을 제안한다. 이를 통해 현재의 기준 모델보다 최대 30 ROUGE-L 점 향상된 신뢰할 수 있는 CTR 모델을 제공한다.

###### A Computational Interface to Translate Strategic Intent from Unstructured Language in a Low-Data Setting (https://aclanthology.org/2023.findings-emnlp.853/)
- Anthology ID: 2023.findings-emnlp.853 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 현실 세계의 많은 태스크는 인간과 AI 시스템이 협력적으로 수행하는 setup을 가진다. 이 논문에서는 인간의 고위수준 전략 의도를 해석하고 실행 가능한 목표와 제약 사항으로 변환하는 계산화 인터페이스를 제안한다.
    2. 게임 환경을 활용하여 언어 전략을 해당하는 목표와 제약 사항으로 매핑하는 데이터셋을 구축하고, 이 데이터셋으로 학습시킨 모델이 언어로부터 전략적 의도를 추론하는데 있어서 인간 해석보다 유의미한 성능을 보인다고 보여주었다. 
    3. 또한, 저자들은 이 작업에 대해 ChatGPT보다 데이터가 적은 상황에서도 (p < 0.05) 뛰어난 성능을 보인다고 보여주었다.

###### HFMRE: Constructing Huffman Tree in Bags to Find Excellent Instances for Distantly Supervised Relation Extraction (https://aclanthology.org/2023.findings-emnlp.854/)
- Anthology ID: 2023.findings-emnlp.854 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Multi-instance learning (MIL)은 multi-instance bag에서 가장 대표적인 특징을 찾기 위해 AVG (평균), ONE (최소한 하나), ATT (문장 수준 어텐션)과 같은 집계 전략을 사용한다. 그러나 이 전략들은 제 3자 벡터를 훈련시켜 문장 수준 특징을 선택하도록 하여 문장 간에 자연스럽게 존재하는 내재적 연관성을 무시한다. 
    2. 이 논문에서는 circular cosine similarity 개념을 소개하여 한 가방 내의 문장들 간에 내재적인 연관성을 명시적으로 나타낸다. 또한 이전 방법들을 어설픈 노이즈 제거 과정으로 간주하고, Huffman 트리를 기반으로 하는 relation extraction framework (HFMRE)를 구현하여 훈련 중에 노이즈와 집계된 특징을 연속적으로 탐지한다.
    3. 실험 결과는 우리의 방법이 인기 있는 DSRE 데이터셋에서 이전의 기준을 능가하는 탁월한 효과를 나타내고 있다.

###### DISCO: A Large Scale Human Annotated Corpus for Disfluency Correction in Indo-European Languages (https://aclanthology.org/2023.findings-emnlp.855/)
- Anthology ID: 2023.findings-emnlp.855 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Disfluency correction (DC)은 Automatic Speech Recognition (ASR)의 결과물에서 불필요한 요소를 제거하여 읽기 쉽고 해석 가능한 텍스트를 생성한다. 이 논문에서는 English, Hindi, German, French로 말하는 포괄적인 DC 말뭉치를 소개하고 여러 언어로 된 DC 모델의 결과를 상세히 분석한다.
    2. DC 모델의 결과로, 영어는 97.55점, 힌디어는 94.29점, 독일어는 95.89점, 프랑스어는 92.97점의 F1 스코어를 얻었다.
    3. DC의 이점을 증명하기 위해, DC를 최신 기계 번역 (MT) 시스템과 함께 사용할 때 평균적으로 BLEU 점수를 5.65점 향상시킨다는 것을 보였고, 코드와 주석 달린 데이터셋을 공개하였다.

###### Towards Being Parameter-Efficient: A Stratified Sparsely Activated Transformer with Dynamic Capacity (https://aclanthology.org/2023.findings-emnlp.856/)
- Anthology ID: 2023.findings-emnlp.856 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Sparse activation을 사용하는 MoE 모델은 낮은 계산 요구를 유지하면서 파라미터 수를 크게 증가시키는 데 효과가 있다. 그러나 최근 연구에서 이러한 MoE 모델은 전문가 수가 증가함에 따라 성능 향상이 줄어든다는 것을 밝혀냈다.
    2. 본 논문에서는 모든 전문가가 동일한 용량을 갖기 때문에 이러한 파라미터 비효율성이 발생한다고 가정하고, SMoE 모델을 제안한다. SMoE 모델은 다른 토큰이나 작업의 다양한 복잡성 요구에 동적인 용량을 할당할 수 있는 계층적 구조를 갖추고 있다.
    3. 우리는 4개, 15개, 94개 언어 쌍을 포함하는 3개의 다국어 기계 번역 벤치마크에서 SMoE의 효과를 입증한다. 우리는 SMoE가 동일하거나 더 적은 파라미터로 여러 최첨단 MoE 모델을 능가한다는 것을 보여준다.

###### Misery Loves Complexity: Exploring Linguistic Complexity in the Context of Emotion Detection (https://aclanthology.org/2023.findings-emnlp.857/)
- Anthology ID: 2023.findings-emnlp.857 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 소셜 미디어 상에서 긍정적, 부정적 감정들은 언제나 동등하게 표현되지만, 부정적 감정이 더 많은 관심을 받는다는 negativity bias에 따라 부정적 감정은 언어적으로 더 복잡하게 표현될 수 있다. 
    2. 우리는 readability와 언어적 복잡성 메트릭을 사용하여 소셜 미디어 플랫폼인 Reddit에서 온 감정의 표현을 더 잘 이해하기 위해 연구를 진행한다. 
    3. 결과적으로, 부정적 감정은 긍정적 감정에 비해 보다 복잡한 텍스트를 생성하고, 이러한 복잡성은 트랜스포머 모델의 감정 감지 성능에 영향을 미치는 것으로 나타났다.

###### Probing the “Creativity” of Large Language Models: Can models produce divergent semantic association? (https://aclanthology.org/2023.findings-emnlp.858/)
- Anthology ID: 2023.findings-emnlp.858 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존 평가 방법들은 단어의 유사성만 평가하고 교육적 가치를 고려하지 않기 때문에, 자동 MCQ 평가를 위해 지식 종속 가능성(KDA) 메트릭을 제안한 연구다.
    2. 새로운 augmentation과 contrastive learning 기법을 활용하여 NLP 모델의 robustness를 향상시켰다. 이 방법은 counterfactual을 집합적으로 조합하여 spurious correlations에 영향받지 않게 인과관계를 감독한다.
    3. 대규모 언어 모델은 상당한 예술적 콘텐츠 생성 능력을 가지고 있으며, GPT-4는 사람보다 더 창의적인 단어 연상 능력을 가진다는 연구 결과가 나왔다.

###### Code-Switching with Word Senses for Pretraining in Neural Machine Translation (https://aclanthology.org/2023.findings-emnlp.859/)
- Anthology ID: 2023.findings-emnlp.859 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. NMT에서는 polysemous 단어를 처리하는 것이 어려워 다의어성은 큰 문제다. 이 논문에서는 지식베이스(word sense-specific information)에서 정보를 얻어 NMT 모델을 pretraining 하는 Word Sense Pretraining for NMT (WSP-NMT)를 소개하고, 번역 품질을 향상시키는 것을 보였다.
    2. WSP-NMT는 다양한 도전적인 데이터와 자원 부족한 상황에서도 안정성 있는 결과를 보여주었으며, DiBiMT disambiguation 벤치마크에서도 미세한 정확도 향상을 보였다.
    3. 이 연구는 NMT를 위한 다국어 pretraining에서 단어의 의미 정보와 구조화된 지식을 통합하는 장점과 어려움에 대한 흥미로운 새로운 통찰력을 얻었다.

###### DiffusionSL: Sequence Labeling via Tag Diffusion Process (https://aclanthology.org/2023.findings-emnlp.860/)
- Anthology ID: 2023.findings-emnlp.860 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 시퀀스 레이블링은 기존에는 조건부 분포를 잡기 위해 판별 모델을 사용했으나, 본 논문에서는 생성 모델을 이용하여 Tag Diffusion Process를 생성하여 discrete tag 데이터를 생성한다.
    2. BTConverter를 통해 고도의 정제 기능을 가지는 Diffusion 모델을 활용하여, DiffusionSL은 다양한 벤치마크 데이터셋과 여러 태스크에서 기존 SOTA baseline을 압도하고 gpt-3.5-turbo를 크게 능가하는 성능을 보여준다.
    3. Discrete 특성의 문제를 해결하기 위해, Bit-Tag Converter (BTConverter)를 제안하고 노이즈 제거 과정을 모델링하기 위해 Bit Diffusion Transformer (BitDiT)를 소개한다.

###### COMET-M: Reasoning about Multiple Events in Complex Sentences (https://aclanthology.org/2023.findings-emnlp.861/)
- Anthology ID: 2023.findings-emnlp.861 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "말하는 사람의 의도된 의미를 이해하는 것은 텍스트에 명시되지 않은 것들을 추론하여 이해하는 것을 필요로 한다. 복잡한 문장에서는 문맥적 지식을 기반으로 이벤트 간의 관계를 이해하는 것이 필요하다."
    2. 본 논문에서는 다중 이벤트 문장에서 특정 이벤트를 위한 상식 추론을 생성할 수 있는 COMET-M(다중 이벤트)를 제안한다. COMET-M은 단순한 문장에서 이벤트 중심의 추론을 생성하는 COMET에 비해 복잡한 다중 이벤트 문장에서 더 나은 성능을 보인다.
    3. COMET-M은 자연어 텍스트와 관련된 코레퍼런스 해결, 대화 및 이야기 이해와 같은 하위 작업에 대한 잠재력을 가지고 있다.

###### On Event Individuation for Document-Level Information Extraction (https://aclanthology.org/2023.findings-emnlp.862/)
- Anthology ID: 2023.findings-emnlp.862 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 정보 추출(IE) 시스템이 전체 문서를 처리하는 데 능숙해짐에 따라, 전통적인 템플릿 채우기 작업이 문서 수준의 IE 벤치마크로 새롭게 다시 관심을 받고 있다. 그러나 이 연구에서는 템플릿 채우기가 이러한 목적에 적합한지에 대해 의문을 제기한다. 
    2. 이 연구에서는 이 작업이 "이벤트 개별화(event individuation)"라 불리는 어려운 질문에 대한 명확한 답변을 요구하며, 심지어 전문가들 사이에서도 의견이 분분한 문제에 대해 논의한다. 
    3. 주석 작업 및 오류 분석을 통해 이는 템플릿 채우기 메트릭의 유용성, 작업에 대한 데이터셋의 품질 및 모델의 학습 능력에 대한 우려를 제기하며, 가능한 해결책을 고려한다.

###### AniEE: A Dataset of Animal Experimental Literature for Event Extraction (https://aclanthology.org/2023.findings-emnlp.863/)
- Anthology ID: 2023.findings-emnlp.863 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문은 바이오 의학 분야에서의 이벤트 추출 (extraction)과 관련된 데이터셋인 AniEE를 소개한다.
    2. 이 데이터셋은 동물 실험 단계에 초점을 맞추어 생성되었으며, 분산된 entity와 중첩된 이벤트를 포함한 고품질의 데이터셋을 제공한다.
    3. 최근의 우수한 NER 및 EE 모델에서 이 데이터셋을 평가하고 비교하였다.

###### From Words to Wires: Generating Functioning Electronic Devices from Natural Language Descriptions (https://aclanthology.org/2023.findings-emnlp.864/)
- Anthology ID: 2023.findings-emnlp.864 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 본 연구에서는 최근의 언어 모델이 코드 생성과 유사하게 고급 텍스트 설명으로부터 전자 회로 설계 능력을 가지고 있다는 것을 보여준다. 
    2. 우리는 두 가지 벤치마크인 PINS100과 MICRO25를 소개하는데, 전자 부품에 대한 모델의 지식을 평가하고, 진단 생태계에서 일반적인 마이크로컨트롤러 회로와 코드를 설계하는 능력을 평가한다.
    3. GPT-4와 Claude-V1 같은 모델은 전체 디바이스를 생성할 때 60%부터 96%의 Pass@1 결과를 달성하였으며, 복잡한 회로 설계와 실용적인 유틸리티를 향상시키기 위해 개발 영역을 제안하며, 만족스러운 성능의 양적 분석 결과와 평가 도전 과제를 제시한다.

###### Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training (https://aclanthology.org/2023.findings-emnlp.865/)
- Anthology ID: 2023.findings-emnlp.865 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 본 논문에서는 액티브 러닝을 활용하여 구조화된 레이블 공간의 주석 비용을 줄이는 실용적인 방법을 제안한다. 이 방법은 부분 주석을 활용하여 정보가 가장 풍부한 하위 구조만 주석 작업을 진행하여 구조화된 결과의 주석 비용을 줄인다.
    2. 또한, 현재 모델의 자동 예측을 가상의 레이블로 사용하여 미주석 하위 구조에 대한 의사 레이블로 활용하는 self-training을 활용한다.
    3. 이러한 부분 주석과 self-training의 조합을 효과적으로 활용하기 위해, 현재 모델의 능력에 따라 적응적으로 부분 선택 비율을 결정하기 위한 오차 추정기(error estimator)를 도입한다. 이를 통해 독립된 4가지 구조화된 예측 작업을 평가한 결과, 읽기 시간을 고려한 공정한 비교 기준에서 부분 주석과 적응적 선택 비율을 사용하는 self-training은 강력한 전체 주석 기준에 비해 주석 비용을 감소시키는 것을 확인하였다.

###### Explicit Alignment and Many-to-many Entailment Based Reasoning for Conversational Machine Reading (https://aclanthology.org/2023.findings-emnlp.866/)
- Anthology ID: 2023.findings-emnlp.866 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 'Conversational Machine Reading (CMR)'은 주어진 문서를 기반으로 multi-turn 대화 상호작용을 통해 사용자의 초기 질문에 대답하는 작업이다. 이 논문에서는 진행 기반 질문 생성 및 중간 의사 결정에 중요한 역할을 하는 document와 사용자가 제공한 정보 사이의 정렬을 고려한 pipeline framework를 제안한다.
    2. 제안된 방법은 explicit한 방식으로 document와 사용자 정보를 정렬하고, 가볍고 많은-many entailment 추론 모듈을 사용하여 결정을 내린다. 또한, 문서와 이전 질문을 기반으로 질문을 생성한다.
    3. 실험 결과 제안된 방법은 CMR 벤치마크 데이터셋 ShARC에서 state-of-the-art 성능을 달성하였다.

###### Harnessing Dataset Cartography for Improved Compositional Generalization in Transformers (https://aclanthology.org/2023.findings-emnlp.867/)
- Anthology ID: 2023.findings-emnlp.867 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 신경망은 언어 모델링을 혁신하고 다양한 하위 과제에서 뛰어난 성능을 보이지만, 신경망 모델이 인간의 인지 능력에 비해 구조적 일반화(compositional generalization)를 어느 정도 달성하는지는 여전히 논쟁의 여지가 있다.
    2. 이 논문에서는 기존의 아키텍처와 학습 패러다임 대신 데이터셋 매핑의 힘을 활용하는 혁신적인 방법론을 제안한다.
    3. 이 방법을 사용하여 요약의 데이터 중 일부를 선택함으로써 모델의 정확성을 현저히 향상시키고, CFQ 및 COGS 데이터셋에서 최대 10%의 향상을 얻을 수 있다는 결과를 보였다.

###### Roles of Scaling and Instruction Tuning in Language Perception: Model vs. Human Attention (https://aclanthology.org/2023.findings-emnlp.868/)
- Anthology ID: 2023.findings-emnlp.868 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 대형 언어 모델(LLM)은 자연어를 이해하는 능력을 갖추었으나, 이러한 성능을 얻기 위해 scaling과 instruction tuning이 어떤 영향을 미치는지는 알려져 있지 않다.
    2. 이 연구는 여러 크기의 LLMs (LLaMA, Alpaca, Vicuna)의 self-attention과 인간의 독서 주의를 비교하여 scaling과 instruction tuning이 언어 관찰에 미치는 영향을 평가한다.
    3. 실험 결과, scaling은 편패 패턴에 의존성을 줄이고, 실질적인 어텐션 향상으로 인간의 독서와 유사하게 만든다는 것을 보여주었으며, instruction tuning은 이러한 효과를 보이지 않는다는 것을 보여준다. 하지만, instruction tuning은 모델이 명령에 민감하게 반응하는 능력을 향상시킨다.

###### Efficient Data Learning for Open Information Extraction with Pre-trained Language Models (https://aclanthology.org/2023.findings-emnlp.869/)
- Anthology ID: 2023.findings-emnlp.869 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. OpenIE (Open Information Extraction)은 문장에서 모든 트리플 (주어, 술어, 목적어)을 추출하는데 어려움이 있는 자연어 처리 작업이다. 이 논문에서는 T5 모델의 사전 훈련 과제를 이용하여 OpenIE의 작업 형태를 전환시키고, 대량의 훈련 데이터가 필요하지 않도록 하는 'OK-IE'라는 새로운 프레임워크를 소개한다.
    2. 또한, '앵커'라는 혁신적인 개념을 도입하여 모델의 출력 순서를 제어하는 기능을 추가하였으며, 이를 통해 모델 수렴에 영향을 미치는 순서 페널티의 영향을 제거하고 훈련 시간을 크게 줄일 수 있다.
    3. 실험 결과, 기존 SOTA 방법에 비해 OK-IE는 훈련 데이터의 1/100 (900개 인스턴스)와 훈련 시간의 1/120 (3분)만으로도 비슷한 결과를 얻을 수 있다.

###### Survival of the Most Influential Prompts: Efficient Black-Box Prompt Search via Clustering and Pruning (https://aclanthology.org/2023.findings-emnlp.870/)
- Anthology ID: 2023.findings-emnlp.870 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 프롬프트 기반 학습은 pretrained language model (LLM)들에게 효과적인 패러다임이다. 이 논문은 프롬프트 기반 검색 공간의 설계와 최적화의 중요성을 강조하며, 클러스터링과 가지치기를 통해 영향력 있는 프롬프트 토큰에 초점을 맞추는 블랙박스 검색 방법인 ClaPS를 제안했다.
    2. ClaPS는 단순한 검색 방법을 사용하여 복잡한 방식보다 우수한 성능을 보이면서 검색 비용을 크게 줄였다. ClaPS는 다양한 task와 LLM에서 최고의 성능을 달성하며, 검색 공간 설계와 최적화의 중요성을 강조한다.
    3. 이 연구에서는 프롬프트 기반 학습의 유용성과 효율성을 향상시키는데 검색 공간 설계와 최적화의 역할이 중요하다는 것을 밝혀냈다.

###### Towards Zero-shot Learning for End-to-end Cross-modal Translation Models (https://aclanthology.org/2023.findings-emnlp.871/)
- Anthology ID: 2023.findings-emnlp.871 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 음성 번역에서의 주요 문제 중 하나는 다른 모달리티 간의 불일치입니다. 두 번째 문제인 다중 모달리티를 포함하는 병렬 데이터의 희소성은 end-to-end 다중 모달 모델이 카스케이드 모델보다 성능이 좋지 않은 경향이 있습니다. 
    2. 우리는 이러한 문제들에 대해, 두 개의 사전 훈련된 단일 모달 모듈을 단어 회전자의 거리를 통해 연결하여 end-to-end 제로샷 음성 번역 모델을 제안합니다.
    3. 우리의 실험은 MuST-C 벤치마크에서 우리의 end-to-end 제로샷 접근 방식이 CTC 기반 카스케이드 모델보다 더 나은 성능을 발휘하며, 지도 학습을 통해 훈련된 end-to-end 모델이 최신 베이스라인에 맞추어주는 것을 보여줍니다.

###### LLMaAA: Making Large Language Models as Active Annotators (https://aclanthology.org/2023.findings-emnlp.872/)
- Anthology ID: 2023.findings-emnlp.872 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 NLP에서의 supervised learning 방법은 대량의 품질 좋은 주석이 담긴 데이터를 필요로 하지만, 실제로 이러한 데이터를 획득하는 것은 비용이 많이 든다. 
    2. 이 논문에서는 대규모 언어 모델을 주석자로 사용하여 효율적으로 주석을 달고 학습하는 active learning 방법을 제안한다.
    3. 실험 결과, LLMaAA 모델은 수백개의 주석된 예제로 학습했을 때 기존 방법보다 더 우수한 성능을 보여준다.

###### NLMs: Augmenting Negation in Language Models (https://aclanthology.org/2023.findings-emnlp.873/)
- Anthology ID: 2023.findings-emnlp.873 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 부정은 문장의 의미를 뒤집는 자연어 처리에서 기본 구성 요소이다. 그러나 사전 훈련된 언어 모델에서는 학습이 덜 이루어져 잘못된 추론 결과를 내면서 부정의 중요성이 충분히 반영되지 않는다.
    2. 이 논문은 사전 훈련된 언어 모델에서 부정의 이해를 향상시키기 위해 가중 교차 엔트로피 손실과 탄성 가중치 결합 규제를 포함한 언어 모델 목적을 제안한다.
    3. 실험 결과로는, 부정화된 LAMA 데이터셋에서 BERT-base의 평균 top 1 오류율을 1.1%, BERT-large를 0.78%, RoBERTA-base를 3.74%, RoBERTA-large를 0.01%로 줄였다. 이는 BERT 오류율을 8%로 줄이며 기존 방법들보다 우수한 결과를 보여준다. 본 논문은 또한 부정화된 augmented 모델이 원래의 자연어 추론 작업 및 부정화된 벤치마크에서 고전적인 모델보다 우수한 결과를 보여준다는 실험적 증거를 제공한다.

###### Parameter-Efficient Prompt Tuning Makes Generalized and Calibrated Neural Text Retrievers (https://aclanthology.org/2023.findings-emnlp.874/)
- Anthology ID: 2023.findings-emnlp.874 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Prompt tuning"은 사전 훈련된 모델의 몇 개의 작업 특정 파라미터를 업데이트하는 것을 말하는데, 이 방법은 언어 이해 및 생성 작업에서 전체 파라미터 튜닝과 비교할 만한 성능을 보여주고 있다.
    2. 이 논문에서는 텍스트 검색에 대한 prompt tuning 문제를 연구한다. in-domain, cross-domain 및 cross-topic 설정에 대해 효율적인 파라미터 튜닝 방법을 소개하고 있다.
    3. 실험 결과 0.1%의 모델 파라미터만 업데이트하여 prompt tuning 전략은 전체 파라미터를 업데이트하는 전통적인 방법보다 검색 모델의 일반화 성능을 크게 향상시킬 수 있다고 보여주었다.

###### X-SNS: Cross-Lingual Transfer Prediction through Sub-Network Similarity (https://aclanthology.org/2023.findings-emnlp.875/)
- Anthology ID: 2023.findings-emnlp.875 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다국어 언어 모델의 "Cross-lingual transfer (XLT)" 기능은 미세 조정(fine-tuning)과정에서 포함되지 않은 언어에서도 해당 작업에서 모델의 성능을 상당한 정도로 보존한다는 것을 알려주고 있다.
    2. 이 논문은 XLT의 효능을 고려하고 특정 조건에 기반하여 가장 적합한 원본 언어를 선택함으로써 XLT의 효과를 강화하는 방법을 제안한다.
    3. 실험에서는 sub-network의 유효성도 확인하며 제안하는 방법이 다양한 작업에서 기존 기준 모델 보다 효과적임을 보여주었다.

###### Noise-Robust Semi-Supervised Learning for Distantly Supervised Relation Extraction (https://aclanthology.org/2023.findings-emnlp.876/)
- Anthology ID: 2023.findings-emnlp.876 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 노이즈가 있는 DSRE에서 기존 방법들은 노이즈가 있는 라벨에 영향을 받을 수밖에 없으며, 이러한 접근법은 개별 문장에 대한 관계 라벨 추출에 적합하지 않다.
    2. 이러한 문제를 해결하기 위해, 우리는 세미-슈퍼바이즈드-러닝 (Semi-Supervised-Learning) 기법을 사용한 새로운 DSRE 프레임워크를 제안한다.
    3. 실험 결과, 우리의 프레임워크는 기존 최고 수준의 방법들과 비교하여 문장 수준의 관계 추출 성능을 크게 향상시켰다.

###### Towards Concept-Aware Large Language Models (https://aclanthology.org/2023.findings-emnlp.877/)
- Anthology ID: 2023.findings-emnlp.877 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. LLMs는 토큰 수준에서 작동하기 때문에 인간 개념과 그 구조를 얼마나 잘 포착하는지 분석한다.
    2. 컨셉을 사용하여 LLM의 사전 학습 방법과 기존 LLM의 출력을 사용하는 간단한 접근법을 탐구한다.
    3. 이러한 결과는 컨셉을 고려한 LLM의 가능성을 보여준다.

###### ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning (https://aclanthology.org/2023.findings-emnlp.878/)
- Anthology ID: 2023.findings-emnlp.878 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근에는 대형 언어 모델(Large Language Models, LLM)이 자연어 처리(NLP) 분야에서 가장 중요한 획기적인 발전으로 등장하여 연구와 개발을 근본적으로 변화시키고 있다. 그 중 ChatGPT는 최근 개발된 가장 흥미로운 LLM 시스템 중 하나로, 언어 생성 능력과 대중의 관심을 끌 정도로 인상적인 기술을 보여준다. 이 연구는 ChatGPT와 유사한 LLM을 다양한 언어와 대규모 데이터셋에서 평가하여, 다양한 다국어 NLP 응용에 대해 더 포괄적인 정보를 제공하기 위한 목적을 가지고 있다.
    
    2. 이 연구에서는 ChatGPT를 7가지 다른 과제에 대해 37개의 다양한 언어로 평가하고, 언어 리소스의 상, 중, 하 및 극도로 낮은 수준을 고려한다. 기존 모델의 성능과 비교해 본 결과, ChatGPT의 다양한 NLP 과제와 언어에 대한 성능이 좋지 않음을 보여준다. 따라서 이는 더 나은 모델과 다국어 학습에 대한 더 나은 이해를 개발하기 위해 추가적인 연구를 요구한다.
    
    3. ChatGPT와 유사한 LLM 모델을 이용한 다국어 NLP 응용에 대한 포괄적인 정보를 제공하기 위해, 다양한 언어와 과제에 대해 ChatGPT의 성능을 평가하고, 기존 모델과의 비교를 통해 더 나은 모델과 다국어 학습에 대한 이해의 필요성을 제시한다.

###### Subspace Chronicles: How Linguistic Information Emerges, Shifts and Interacts during Language Model Training (https://aclanthology.org/2023.findings-emnlp.879/)
- Anthology ID: 2023.findings-emnlp.879 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 언어 모델링을 통해 학습된 표현 공간은 자연어 처리에 필수적이다. 그러나 다양한 유형의 언어적 정보가 어떻게 훈련 중에 특정 시기에 나타나고 상호작용하는지에 대한 이해는 제한적이다.
    2. 정보 이론적 접근법을 이용하여 훈련된 표현 공간의 서브스페이스뿐만 아니라 작업 성능의 직접적인 비교를 가능하게 하는 새로운 분석 도구를 활용하여 구문, 의미, 추론 등을 다루는 9가지 작업을 분석하였다.
    3. 우리는 작업과 시간에 따라 표현 서브스페이스가 어떻게 나타나고 정보를 공유하며 나중에 특화될 수 있는 중요한 학습 단계를 식별하였다. 특히 구문적 지식은 전체 훈련의 0.5% 이후 빠르게 습득되며, 의미와 추론 작업은 후반부에서 장거리 문맥적인 특성과 고도의 특화를 통해 성능이 개선된다.

###### Not All Demonstration Examples are Equally Beneficial: Reweighting Demonstration Examples for In-Context Learning (https://aclanthology.org/2023.findings-emnlp.880/)
- Anthology ID: 2023.findings-emnlp.880 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 대형 언어 모델 (LLM)은 모델의 스케일 업으로 한정된 수의 데모 예제가 입력 시퀀스에 추가될 때 하류 작업에 빠르게 적응할 수 있는 In-Context Learning (ICL) 능력을 갖추었다. 그러나, 현재의 ICL은 모든 데모 예제를 동등하게 처리하는데, 이는 일반적으로 예제의 품질이 균일하지 않아서 개선이 필요하다.
    2. 우리는 이 논문에서 어떻게 대략적으로 최적의 데모 예제 가중치를 결정하고 ICL 중에 이를 적용하는지 조사한다. 우리는 또한 추가적인 유효성 검사 데이터 없이 가중치의 품질을 평가하기 위해 마스크된 자체 예측 (MSP) 점수를 설계하였다.
    3. 실험 결과, 8개의 텍스트 분류 작업에서 우리의 접근법은 기존의 ICL에 비해 큰 성능 향상을 보였다.

###### Difference-Masking: Choosing What to Mask in Continued Pretraining (https://aclanthology.org/2023.findings-emnlp.881/)
- Anthology ID: 2023.findings-emnlp.881 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 랜덤 마스킹 방식에서는 토큰을 임의로 가리지만, 어떤 토큰을 가릴지 결정하는 것이 학습 결과를 크게 개선할 수 있다는 직관이 있다.
    2. 이 논문에서는 self-supervised objective를 기반으로한 Difference-Masking 이라는 마스킹 전략을 소개하고, 사전훈련된 모델이 도메인별 데이터에서 계속 사전훈련을 하면서 어떤 토큰을 가릴지 자동으로 결정한다.
    3. 실험적으로, Difference-Masking은 다양한 언어와 멀티모달 비디오 작업에서 계속된 사전훈련 설정에서 다른 기준 모델보다 우수한 성능을 보여주었다.

###### Learn From One Specialized Sub-Teacher: One-to-One Mapping for Feature-Based Knowledge Distillation (https://aclanthology.org/2023.findings-emnlp.882/)
- Anthology ID: 2023.findings-emnlp.882 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Knowledge distillation"은 과잉 파라미터화된 language model을 압축하는 데 효과적인 기술로 알려져 있다. 이 논문에서는 이 과제를 N개의 지역적 하위 과제로 분할하는 새로운 방법을 제안하였다. 특정 서브 티처(sub-teacher)로부터 특정 서브 스튜던트(sub-student)가 학습을 진행하도록 하는 이 방법은 성능을 향상시킨다고 확인되었다.
    2. 제안된 방법은 다른 distillation 기법과 결합될 수 있으며, 벤치마크 데이터셋 대부분에서 더 높은 성능을 유지한다는 것이 실험적으로 입증되었다.
    3. 더 나아가, "Masked One-to-One Mapping"이라는 제안된 방법의 변형은 학습 단계마다 일부 서브 과제(sub-task)에 집중하여 학습함으로써 이식된 지식을 효과적으로 소화하고 높은 성과를 이끌어냈다.

###### IMU2CLIP: Language-grounded Motion Sensor Translation with Multimodal Contrastive Learning (https://aclanthology.org/2023.findings-emnlp.883/)
- Anthology ID: 2023.findings-emnlp.883 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. IMU2CLIP는 Inertial Measurement Unit (IMU) 모션 센서 레코딩을 텍스트와 비디오로 대응시키기 위한 새로운 사전 훈련 접근 방식으로, Contrastive Language-Image Pre-training (CLIP)의 공간에 IMU 데이터를 투영하여 사용한다.
    2. 이 방식을 통해 IMU2CLIP은 IMU 센서로 측정된 인간의 동작을 해당하는 텍스트 설명과 비디오로 변환할 수 있으며, 이 모달리티 간의 의사소통과 투명성(transitivity)을 유지한다.
    3. 또한, 우리는 운동 센서 데이터를 활용한 운동 기반 미디어 검색 또는 LM 기반의 운동 센서 데이터와의 다중모달 추론과 같은 IMU 기반 웨어러블 AI 응용 프로그램을 소개한다. 뿐만 아니라, IMU2CLIP는 각 응용 프로그램에 맞게 fine-tuning을 수행하여 downstream 성능을 크게 향상시키는 것을 보여주고 있으며, 이는 이 접근 방식이 새로운 사전 훈련 리소스로서의 범용성을 증명한다.

###### Conditioning on Dialog Acts improves Empathy Style Transfer (https://aclanthology.org/2023.findings-emnlp.884/)
- Anthology ID: 2023.findings-emnlp.884 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 연구에서는 대화 행위(dialog acts)가 스타일 변환에 미치는 역할을 탐구한다. 특히, 공감 감정을 전달하는 스타일 변환에 초점을 맞추고 있다. 
    2. 이 논문에서는 two novel few-shot prompting strategies를 사용하여 대상 행위(target act)나 대화 행위 조건(dialog-act-conditioned)에 따라 문장을 공감적으로 변환한다. 
    3. 실험 결과, 대상 행위 prompt는 문맥의 의미를 유지한 채 공감 감정을 효과적으로 향상시키는 반면, 대화 행위 조건 prompt는 의미와 대화 행위 유형을 보존하면서 공감을 강화시킨다는 것을 보여주었다. 각각의 대화 행위는 다른 프롬프팅 방법에서 다양하게 혜택을 받으며, 대화 행위의 역할에 대한 추가적인 연구의 필요성을 강조한다.

###### Systematic Assessment of Factual Knowledge in Large Language Models (https://aclanthology.org/2023.findings-emnlp.885/)
- Anthology ID: 2023.findings-emnlp.885 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존 연구들은 대규모 언어 모델의 저장된 지식을 평가하기 위해 기존의 질문-답변 벤치마크를 사용해왔으나, 이 방법은 대부분 예비 훈련 데이터와 중복되는 일반적인 도메인에만 초점을 맞추기 때문에 사실적인 지식의 범위에 제한이 있다.
    2. 이 논문에서는 지식 그래프(KG)를 활용하여 대규모 언어 모델의 사실적인 지식을 체계적으로 평가하는 프레임워크를 제안한다. 이 프레임워크는 주어진 KG에 저장된 사실들로부터 질문과 기대되는 답변의 세트를 자동으로 생성하고, 대규모 언어 모델이 이러한 질문에 대한 정확성을 평가한다.
    3. 실험 결과, 우리는 ChatGPT가 모든 도메인에서 일관되게 우수한 성능을 보여준다는 것을 발견했다. 또한, 지시어 세부 튜닝, 도메인 및 질문 복잡성에 따라 대규모 언어 모델의 성능이 달라지며, 적대적인 문맥에 취약하다는 것을 발견했다.

###### From Speculation Detection to Trustworthy Relational Tuples in Information Extraction (https://aclanthology.org/2023.findings-emnlp.886/)
- Anthology ID: 2023.findings-emnlp.886 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Speculation detection은 텍스트의 사실성을 파악하기 위한 중요한 NLP 태스크이다. 그러나 추출된 추측 정보들은 구조가 없어 downstream 태스크에서 직접적으로 활용하기 어렵다.
    2. 이 논문에서는 speculations를 OIE 튜플에서 연구하고, 각 튜플이 추측적인지 판단하는 새로운 연구 과제를 정의한다.
    3. LSOIE 데이터셋을 분석하고, 이 새로운 연구 과제를 위한 기준 모델인 SpecTup을 제안한다.

###### Tokenization Consistency Matters for Generative Models on Extractive NLP Tasks (https://aclanthology.org/2023.findings-emnlp.887/)
- Anthology ID: 2023.findings-emnlp.887 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 추출적인 작업에서 생성 모델은 널리 사용되어 왔으며, 최근 추출형 질문 답변(QA)에서도 최고 성과를 보여주고 있다. 그러나 본 논문에서는 모델을 훈련할 때 자주 간과되는 토큰화 불일치 문제에 대해 연구하였다.
    2. 토큰화 불일치 문제는 토크나이저에 의해 입력과 출력이 일관되지 않게 토큰화되어 추출 작업의 특성을 손상시키고 성능 하락 및 공허한 결과를 초래한다. 
    3. 우리는 이 문제에 대한 간단하면서도 효과적인 해결책을 제안하고, 추출적인 QA에 대한 사례 연구를 수행하였다. 일관된 토큰화를 통해 모델이 도메인 내 및 도메인 외 데이터셋에서 더 좋은 결과를 보여주며, 특히 BART 모델을 SQuAD에서 학습하고 8개의 QA 데이터셋에서 평가할 때 평균 F1값이 +1.7 상승하는 것을 확인했다.

###### Dialogue Medical Information Extraction with Medical-Item Graph and Dialogue-Status Enriched Representation (https://aclanthology.org/2023.findings-emnlp.888/)
- Anthology ID: 2023.findings-emnlp.888 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 여러 턴의 의사-환자 대화에는 환자의 증상, 의사의 진단 및 처방과 같은 풍부한 의료 지식이 포함되어 있습니다. 이러한 의료 지식을 적절하게 채굴하고 표현할 경우, 진단 보조 및 처방 권장과 같은 다양한 임상 응용에 도움이 될 수 있습니다.
    2. 우리는 자유로운 텍스트 대화에서 구조화된 지식을 추출하기 위해 "대화 의료 정보 추출"이라는 중요한 과제를 목표로 합니다. 이 작업은 사전에 정의된 임상적인 의미 있는 의료 항목(증상, 수술 등) 및 그 상태(양성, 음성 등)를 대화에서 인식하는 것을 목표로 합니다.
    3. 기존 접근 방식과 달리 우리는 상호 그래프를 제안하여 항목 간의 관계를 모델링합니다. 또한 대화와 상태를 기반으로 하는 두 가지 연속적인 주의 메커니즘을 제안하여 항목 표현을 개선합니다. 이 방법으로 DMIE 작업에서 의료 항목과 상태 간의 관계를 모델링할 수 있습니다.

###### LogicAttack: Adversarial Attacks for Evaluating Logical Consistency of Natural Language Inference (https://aclanthology.org/2023.findings-emnlp.889/)
- Anthology ID: 2023.findings-emnlp.889 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 대형 언어 모델들은 NLI(자연어 추론) 태스크에서 높은 성능을 보였지만, 이러한 모델들은 평가 데이터의 단순한 휴리스틱이나 아티팩트에 의존하여 이러한 높은 성과를 달성하고 있으며, 이는 여전히 논리적 일관성에 결여되어 있다는 것을 시사한다.
    2. 논리적 일관성을 평가하기 위해 우리는 다양한 논리 형태의 전제와 가설을 사용하여 NLI 모델을 공격하는 LogicAttack이라는 방법을 제안한다.
    3. 우리의 접근법은 명제 논리학에서의 추리 규칙들, 예를 들어 Modus Tollens와 Bidirectional Dilemma 등을 활용하여 효과적인 적대적 공격을 생성하고, 여러 NLI 모델에 걸쳐 공통적인 취약점을 식별해낸다.

###### Decomposed Prompt Tuning via Low-Rank Reparameterization (https://aclanthology.org/2023.findings-emnlp.890/)
- Anthology ID: 2023.findings-emnlp.890 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Prompt tuning의 전통적인 방법과는 다르게 저자들은 soft prompt 초기화를 위해 저차원 행렬로 다양한 방식을 제안한다.
    2. Empirical studies를 통해 low-rank 행렬이 효과적인 초기화 방법임을 보여주며, 기존 방법에 비해 trainable parameter 개수를 크게 줄임과 동시에 효과를 유지한다.
    3. high-resource와 low-resource 시나리오에서 SuperGLUE 벤치마크 실험 결과, 제안된 방법의 효과를 입증한다.

###### SGP-TOD: Building Task Bots Effortlessly via Schema-Guided LLM Prompting (https://aclanthology.org/2023.findings-emnlp.891/)
- Anthology ID: 2023.findings-emnlp.891 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 대화 연구에서 최소한의 인간 노력으로 end-to-end 태스크 봇을 구축하고 유지하는 것은 오랜 동안의 과제이다. 본 논문에서는 SGP-TOD라는 새로운 방법을 소개하는데, 큰 언어 모델을 기반으로 Task-Oriented 대화 시스템을 쉽게 구축하는데 사용된다. 
    2. SGP-TOD는 사용자와 상호작용하는 LLM, belief instruction 및 대화 정책을 추적하는 DST Prompter, 그리고 제공된 대화 정책을 따르는 적절한 응답을 생성하기 위해 LLM을 지시하는 Policy Prompter로 구성된다.
    3. Multiwoz, RADDLE, STAR 데이터셋에 대한 실험 결과에서 SGP-TOD는 훈련 데이터 없이 학습하는 전략으로 최고 수준의 zero-shot 성능을 보여주며, 적은 수의 데이터로 학습하는 방법을 현저히 능가한다. 또한 도메인 확장 환경에서는 단순히 부가적인 스키마 규칙을 추가함으로써 적절하게 새로운 기능에 적응한다.

###### Ethical Reasoning over Moral Alignment: A Case and Framework for In-Context Ethical Policies in LLMs (https://aclanthology.org/2023.findings-emnlp.892/)
- Anthology ID: 2023.findings-emnlp.892 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 position paper에서는 LLMs를 특정한 윤리 원칙에 동화시키는 대신, 일반적인 윤리적 추론 능력을 주입하여 그들이 전 세계적으로 가치 다양성을 다룰 수 있도록 해야 한다는 주장을 한다.
    2. 우리는 윤리 정책을 제공하면, LLM은 그 정책에 윤리적으로 일관된 결정을 내릴 수 있어야 한다고 주장한다.
    3. 우리는 도덕적 딜레마를 다양한 형식의 도덕적 이론과 다른 추상화 수준에서 다루는 프레임워크를 개발하였으며, GPT-x 모델들과의 초기 실험 결과는 GPT-4가 거의 완벽한 윤리적 추론자이지만, 여전히 모델들은 서양과 영어권 사회의 도덕적 가치에 편향성을 가지고 있다.

###### Vector-Quantized Prompt Learning for Paraphrase Generation (https://aclanthology.org/2023.findings-emnlp.893/)
- Anthology ID: 2023.findings-emnlp.893 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자연어의 딥 생성 모델링은 유창한 문장을 생성하거나 한 언어에서 다른 언어로 번역하는 등 여러 성과를 거두었다. 
       하지만 파라프레이즈 생성을 위한 생성 모델링 기술의 발전은 표현 다양성과 의미 보존 간의 복잡한 충돌을 다루는 것에 아직 크게 뒤처져 있다.
    2. 이 논문에서는 사전 훈련된 모델과 인스턴스에 따라 다른 프롬프트를 활용하여 다양하고 고품질의 파라프레이즈를 생성하는 방법을 제안한다.
    3. 실험 결과는 제안된 방법이 Quora, Wikianswers, MSCOCO 등 3개의 벤치마크 데이터셋에서 우수한 성과를 달성했음을 보여준다.

###### Rethinking the Construction of Effective Metrics for Understanding the Mechanisms of Pretrained Language Models (https://aclanthology.org/2023.findings-emnlp.894/)
- Anthology ID: 2023.findings-emnlp.894 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사전 훈련된 언어 모델의 내부 관계를 보존하면서 입력 텍스트를 벡터 집합으로 효과적으로 매핑하는 것이 기대되지만, 내재적으로 해석 가능성이 떨어지는 경우는 해석 가능한 흰 상자 모델을 설계하고 메트릭을 계산하는 것이 어려워진다.
    2. 이 논문에서는 흰 상자 모델의 해석 가능성을 달성하고 메트릭 계산의 엄격성을 보장하는 새로운 메트릭 구성을 위한 접근 방식을 제안한다. tree topological probe라는 모델을 사용하여 이러한 메트릭을 계산한다.
    3. 실험 결과를 바탕으로 BERT-large에서 토폴로지 프로브를 사용하여 BERT와 비슷한 사전 훈련된 언어 모델의 동작 메커니즘과 특정 하위 모듈의 성능 향상 전략에 대한 짐작을 제시한다.

###### PARROT: Zero-Shot Narrative Reading Comprehension via Parallel Reading (https://aclanthology.org/2023.findings-emnlp.895/)
- Anthology ID: 2023.findings-emnlp.895 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 'Parrot'은 병렬 독서를 통해 일련의 이야기를 이해하기 위한 영감을 제공함으로써, 이야기 이해에 대한 zero-shot 접근 방식을 제시한다.
    2. 이 방법은 한 이야기를 다른 이야기의 지도 신호로서 활용하여 텍스트 내용을 추상화하고 진정한 이야기 이해를 발전시킨다.
    3. 두 가지 이야기 이해 벤치마크에서 진행한 평가에서 'Parrot'은 이전 zero-shot 접근법을 능가하며 완전한 지도 모델의 성능과 비슷한 결과를 달성한다.

###### BioDEX: Large-Scale Biomedical Adverse Drug Event Extraction for Real-World Pharmacovigilance (https://aclanthology.org/2023.findings-emnlp.896/)
- Anthology ID: 2023.findings-emnlp.896 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 의약품 안전 모니터링을 향상시키기 위해 자연어 처리를 이용한 BioDEX라는 대형 리소스를 소개하고, 의약품이나 환자에 대한 핵심 정보를 예측하는 작업을 진행한다.
    2. 65,000개의 초록과 19,000개의 전문 논문, 256,000개의 의약품 안전 보고서로 구성된 BioDEX를 사용하여 의약품 부작용 이벤트를 추출하고, 이를 통해 전문가들을 돕는 모델을 구축한다.
    3. Human performance는 72.0% F1이지만, 우리의 모델은 59.1% F1 (검증 시 62.3%)를 달성하여 큰 발전 가능성을 보여준다. 또한, 이 모델이 전문가들을 돕는 방식도 탐구한다.

###### Coarse-to-Fine Dual Encoders are Better Frame Identification Learners (https://aclanthology.org/2023.findings-emnlp.897/)
- Anthology ID: 2023.findings-emnlp.897 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Frame identification은 문장에서 대상 단어와 관련된 의미적 프레임을 찾는 것을 목표로 한다. 그러나 최근 연구들은 프레임 정의를 모델링하여 대상과 후보 프레임 간의 유사성이나 일치 점수를 측정하지만, 이러한 연구들은 정의의 충분한 표현 학습이 부족하거나 1000개가 넘는 후보 프레임 중에서 가장 적합한 프레임을 효과적으로 선택하는 데 어려움이 있다.
    2. 우리는 CoFFTEA라는 새로운 아키텍처를 제안한다. CoFFTEA는 대조 학습과 두 개의 인코더를 사용하여 프레임과 대상 간의 정렬을 효율적으로 모델링한다. CoFFTEA는 더 높은 유사도의 프레임을 구별하기 위해 점진적 학습 방법을 사용한다. 실험 결과는 CoFFTEA가 이전 모델보다 0.93점의 전체 점수와 1.53점의 R@1을 달성했음을 보여준다.
    3. 추가 분석 결과 CoFFTEA는 프레임과 프레임, 대상과 대상 간의 관계를 더 잘 모델링할 수 있다는 것을 시사한다.

###### Sound of Story: Multi-modal Storytelling with Audio (https://aclanthology.org/2023.findings-emnlp.898/)
- Anthology ID: 2023.findings-emnlp.898 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 현재까지의 이야기 이해 및 전달에 관한 연구들은 소리에 대해 거의 주의를 기울이지 않았다. 그러나 실생활에서는 이야기를 전달할 때 이야기 자체와 함께 시각화 및 소리를 사용한다. 따라서 본 논문에서는 소리가 이야기의 의미를 전달하는 중요한 역할을 한다며, 이야기 이해 및 전달 연구 영역을 소리를 고려하는 방향으로 확장시키기 위해 배경음 사운드를 도입하는 것을 제안한다.
    2. 이를 위해 "Sound of Story (SoS)"라는 새로운 데이터셋을 소개하는데, 해당 데이터셋은 이미지와 텍스트 시퀀스와 이야기에 해당하는 사운드 또는 배경 음악을 갖춘 쌍으로 구성되어 있다. 음악 역시 이야기의 의미를 전달하기 때문에 음악 없이 정리된 대형 데이터셋이어서 이야기에 관한 다중모달 이해를 연구하는데 유용하다.
    3. 이러한 데이터셋을 활용하여 소리와 관련된 이야기 이해와 생성 작업의 벤치마크를 설정하고, 각 작업에 대한 강력한 기준선을 제시한다. 제안된 데이터셋과 작업은 다중모달 이해 관점에서 이야기를 탐색하는 데에 도움이 될 것으로 기대한다.

###### Synthesize, if you do not have: Effective Synthetic Dataset Creation Strategies for Self-Supervised Opinion Summarization in E-commerce (https://aclanthology.org/2023.findings-emnlp.899/)
- Anthology ID: 2023.findings-emnlp.899 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 전자상거래에서 의견 요약은 제품 리뷰에서 제시된 의견을 좁히는 과정이다. 그러나 대량의 지도 데이터셋이 없어 특정 측면 및 일반 의견 요약 생성에 어려움이 있다. 
    2. 이 논문에서는 범용 및 특정 측면 의견 요약에 맞춘 SDC 전략을 제안한다. 
    3. 실험 결과, 우리의 모델은 다른 모델에 비해 입력 리뷰에 대해 더 충실한 요약을 생성하며, 이슈별 의견 요약에서도 인간이 지정한 측면이나 씨드 단어의 도움 없이 기존 기법을 능가하는 결과를 보였다.

###### Leveraging Contrastive Learning and Knowledge Distillation for Incomplete Modality Rumor Detection (https://aclanthology.org/2023.findings-emnlp.900/)
- Anthology ID: 2023.findings-emnlp.900 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 온라인 소셜 미크로블로그를 통해 루머는 상대적으로 적은 비용으로 빠르게 퍼지며 우리 일상생활에서 상당한 경제적 손실과 부정적인 결과를 초래한다. 
    2. 기존의 루머 탐지 모델은 다중모달 게시물의 텍스트와 이미지 간의 의미적 일관성과 단일 모달 게시물에서 불완전한 모달에 의한 도전과제를 간과하는 경우가 많다.
    3. 이 논문에서는 Incomplete Modality Rumor Detection을 위한 새로운 CLKD-IMRD 프레임워크를 제안한다. CLKD-IMRD는 텍스트와 이미지 간의 의미적 일관성을 파악하는 데 Contrastive Learning과 Knowledge Distillation을 사용하면서 개별 게시물 내의 불완전한 모달에 대한 모델 일반화를 강화한다. 실험 결과, CLKD-IMRD가 소셜 미디어에서의 루머 탐지를 위한 두 개의 영어 및 중국어 벤치마크 데이터셋에서 최첨단 기법보다 우수한 성능을 보였다.

###### Beyond Testers’ Biases: Guiding Model Testing with Knowledge Bases using LLMs (https://aclanthology.org/2023.findings-emnlp.901/)
- Anthology ID: 2023.findings-emnlp.901 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 현재의 모델 테스팅 연구는 주로 테스트 케이스를 생성하는 데 초점을 맞추고 있으며, 테스트할 내용을 식별하는 단계는 주로 무시되고 지원도 부족하다.
    2. 우리는 모델 테스팅을 안내하기 위해 요구 사항을 도출하는 데 도움을 주는 인터랙티브 도구인 Weaver를 제안한다.
    3. Weaver는 대화 형식으로 큰 언어 모델을 활용하여 지식 베이스를 생성하고 그 중에서 컨셉을 추천함으로써 테스터가 추가 테스트 요구 사항을 도출할 수 있게 한다.

###### CAR: Conceptualization-Augmented Reasoner for Zero-Shot Commonsense Question Answering (https://aclanthology.org/2023.findings-emnlp.902/)
- Anthology ID: 2023.findings-emnlp.902 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Zero-shot commonsense question answering"을 위한 기존 접근 방식은 CommonSense 지식 베이스에서 합성 QA 쌍으로 모델을 사전 학습시키는 것이지만, 이는 CSKB의 내재적 불완전성으로 인해 semantic coverage를 제한하고, 샘플된 negative examples이 불충분하고 모순되는 경우가 있다는 문제가 있다.
    2. 따라서 CAR라는 zero-shot commonsense question-answering 프레임워크를 제안한다. 이 프레임워크는 CAR이름 때문에 알려져 있다. CAR은 CSKB의 커버리지를 높이고 false negative distractors를 선택할 확률을 줄이기 위해 common sense 지식 쌍을 다양한 고수준 인스턴스로 추상화한다.
    3. 다양한 실험을 통해 CAR은 GPT3.5, ChatGPT 같은 큰 언어 모델을 포함한 기존 방법들보다 zero-shot commonsense 시나리오에 대해 더 강력하게 일반화할 수 있음을 입증하였다.

###### kNN-CM: A Non-parametric Inference-Phase Adaptation of Parametric Text Classifiers (https://aclanthology.org/2023.findings-emnlp.903/)
- Anthology ID: 2023.findings-emnlp.903 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 반모수 모델은 매개변수화 모델과 비매개변수화 모델의 속성을 가지며, 다음 단어 예측 언어 모델링에서 효과적임이 입증되어왔다.
    2. 그러나 이러한 모델의 텍스트 구별 능력에 대한 연구가 부족하다. 우리는 학습된 매개변수 텍스트 분류기의 능력을 향상시키기 위해 간단한 근접 이웃 탐색을 통해 k-최근접 이웃 분류 모델(kNN-CM)이라는 추론 단계 접근 방식을 제안한다.
    3. 실험 결과는 SuperGLUE 과제 8개, ANLI 데이터셋 3개, QA 데이터셋 11개, 그리고 감성 분류 데이터셋 2개에서 일관된 성능 향상을 보여준다.

###### Cross-modality Data Augmentation for End-to-End Sign Language Translation (https://aclanthology.org/2023.findings-emnlp.904/)
- Anthology ID: 2023.findings-emnlp.904 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "End-to-end sign language translation" (SLT)은 중간 표현 없이 수화 동영상을 말로 된 텍스트로 직접 변환하는 것을 목표로 한다. 그러나 레이블된 데이터 부족과 수화 동영상과 텍스트 간의 모달리티 간격으로 인해 어려움이 있었다. 이 문제를 해결하기 위해, 우리는 Cross-modality Data Augmentation (XmDA) 프레임워크를 제안하여 수어 번역 능력을 전달하는 것을 목표로 한다.
    2. XmDA는 크로스 모달리티 믹스업과 크로스 모달리티 지식 증류라는 두 가지 주요 구성 요소로 이루어져 있다. 전자는 수어 동영상 특징과 수어 표현 간의 일치를 증진하여 모달리티 간격을 줄인다. 후자는 수어에서 텍스트로의 번역 지식을 활용하여 말로 된 텍스트 생성을 안내한다.
    3. PHOENIX-2014T 및 CSL-Daily와 같은 두 가지 널리 사용되는 SLT 데이터셋에서의 실험 결과는 XmDA 프레임워크가 베이스라인 모델보다 유의하게 성능이 향상됨을 보여준다. 또한 광범위한 분석 결과는 XmDA가 수화 동영상과 수어 표현 간의 표현 거리를 줄이고, 저빈도 단어 및 긴 문장의 번역을 개선함으로써 엔드 투 엔드 수어 번역을 향상시킨다는 것을 확인한다.

###### Consistency is Key: On Data-Efficient Modality Transfer in Speech Translation (https://aclanthology.org/2023.findings-emnlp.905/)
- Anthology ID: 2023.findings-emnlp.905 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 ST에서는 data scarcity를 극복하기 위해 MT 데이터를 사용하는 progressive training이 흔한 연구 사례가 되었으나, 실제로 효과가 없다는 것을 실험 결과로 확인하였다.
    2. 우리는 학습-잊어버림 trade-off를 critical obstacle로 확인하고, consistency learning (CL)이 이 trade-off를 극복할 수 있다는 가설을 세웠고 검증하였다.
    3. 우리의 CL과 knowledge distillation (KD)을 결합한 방법은 추가 데이터 없이도 이전 연구 방법들보다 MuST-C dataset에서 우수한 성능을 보여주며, consistency-informed KD가 KD+CL보다 더 나은 결과를 달성했다.

###### Relation-Aware Question Answering for Heterogeneous Knowledge Graphs (https://aclanthology.org/2023.findings-emnlp.906/)
- Anthology ID: 2023.findings-emnlp.906 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 멀티합 특정 지식 베이스 질문 응답(KBQA)은 다중 단계 추론이 필요한 지식 그래프(KG)에서 답변 entity를 찾는 것을 목표로 한다. 기존의 검색 기반 접근 방식은 각 단계별로 특정 관계에 집중하고 추론 경로 내의 중간 entity를 예측하여 이 작업을 해결한다. 그러나 이러한 모델들은 head-tail entity의 정보와 관계 사이의 의미적 연결을 활용하여 현재 관계 표현을 강화하는 것을 실패하며, 이는 지식 그래프 내의 관계 정보를 제대로 캡처하지 못하게 한다.
    
    2. 이 문제를 해결하기 위해, 우리는 두개의 관계 그래프가 있는 이중 관계 그래프를 구성한다. 각 노드는 원래 KG의 관계를 나타내고, 동일한 head 또는 tail entities를 공유하는 관계 사이에 에지를 생성한다. 그런 다음, 우리는 원래 entity 그래프 추론, 이중 관계 그래프 정보 전파 및 이 두 그래프 사이의 상호 작용을 반복적으로 수행한다. 이렇게 하면 entity와 관계 간의 상호 작용이 강화되고, 더 좋은 entity와 관계 표현을 얻게 된다.
    
    3. WebQSP와 CWQ라는 두 개의 공개 데이터셋을 대상으로 한 실험 결과, 우리의 접근 방식이 이전 최상위 수준보다 상당한 성능 향상을 이뤘다.

###### InstOptima: Evolutionary Multi-objective Instruction Optimization via Large Language Model-based Instruction Operators (https://aclanthology.org/2023.findings-emnlp.907/)
- Anthology ID: 2023.findings-emnlp.907 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사전 훈련된 언어 모델에서는 instruction 기반 언어 모델링이 주목받고 있다. 하지만 instruction engineering의 효율성은 여전히 낮으며 instruction의 품질에 영향을 미치는 길이나 complexity와 같은 중요한 목표를 고려하지 못하고 있다.
    2. 본 논문에서는 instruction 생성을 다목적 최적화 문제로 취급하고, instruction 연산자(돌연변이, 교배 등)들을 모사하는 대형 언어 모델(LLM)을 활용하는 새로운 접근 방법을 제안한다.
    3. 실험 결과는 세부 조정 성능의 향상과 다양한 고품질 instruction 셋의 생성을 보여준다.

###### Less than One-shot: Named Entity Recognition via Extremely Weak Supervision (https://aclanthology.org/2023.findings-emnlp.908/)
- Anthology ID: 2023.findings-emnlp.908 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 극도로 약한 지도 하에서 XWS(X-NER) 방식의 명명체 인식 문제를 연구한 결과, 단 한개의 예제 개체가 컨텍스트-프리 방식으로 주어지는 상황에서도 X-NER 방법이 최신 1-shot NER 방법보다 우수한 성능을 보이는 것을 알 수 있었다.
    2. 우리는 우선 미탐지 훈련 데이터로부터 예제 개체와 유사한 entity span들을 추출하였고, entity span을 대체하기 전과 후의 컨텍스트 분포를 비교하는 것이 좋은 성능을 보였다.
    3. X-NER은 1-shot 지도와 ChatGPT 어노테이션 보다 우수한 성능을 보이며, 다국어 능력을 향후 연구에 상속시켜 갖고 있다는 장점을 가지고 있다.

###### Focus on the Core: Efficient Attention via Pruned Token Compression for Document Classification (https://aclanthology.org/2023.findings-emnlp.909/)
- Anthology ID: 2023.findings-emnlp.909 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 NLP 태스크에서 트랜스포머 기반 모델들은 우수한 성능을 보여주지만, BERT와 같은 사전 훈련된 모델은 계산 비용이 많이 드는 자기 어텐션 메커니즘을 갖고 있어서, 분류 성능에 부정적인 영향을 미치는 토큰을 포함하여 모든 토큰과 상호 작용한다.
    2. 이 논문에서는 두 가지 전략, 토큰 가지치기와 토큰 결합, 을 통합하여 이러한 문제를 해결하는 방법을 제안한다.
    3. 이 두 가지 접근 방식을 통합함으로써, 모델의 성능을 향상시키고 계산 요구 사항을 줄일 수 있다. 다양한 데이터셋과의 실험에서 기존 모델과 비교하여 우수한 성능을 보여주며, 메모리 비용을 0.61배로 줄이고 1.64배 가속화된다.

###### Semantic Decomposition of Question and SQL for Text-to-SQL Parsing (https://aclanthology.org/2023.findings-emnlp.910/)
- Anthology ID: 2023.findings-emnlp.910 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Text-to-SQL의 semantic parsing은 cross-domain과 complex한 쿼리에 일반화하는 데 어려움을 겪고 있다. 이 논문에서는 Question Decomposition 전략을 사용하여 복잡한 SQL 쿼리의 파싱을 향상시키는 방법을 제안한다.
    2. QPL(Query Plan Language)은 모듈식으로 SQL 쿼리를 분해하여 간단하고 정규적인 서브 쿼리로 분할하는 새로운 방법을 제안한다. QPL은 기존의 semantic-parsing 아키텍처에 이점을 제공하며, 기존의 semantic-parsing보다 semantically equivalent한 쿼리에 대해서 QPL을 사용하여 학습하는 것이 더 효과적이다.
    3. QPL은 database schema에 민감한 data retrieval을 위한 Question Decomposer를 만드는 데 도움이 되며, 복잡한 쿼리에 대해서 비전문가도 쉽게 접근할 수 있어 semantic parser의 해석 가능한 출력을 도출할 수 있다.

###### Time-Aware Language Modeling for Historical Text Dating (https://aclanthology.org/2023.findings-emnlp.911/)
- Anthology ID: 2023.findings-emnlp.911 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자동 텍스트 데이터화는 텍스트에 명시적인 시간적 언급이 일반적으로 나타나지 않기 때문에 어려운 작업이다. 
    2. 기존의 최첨단 접근법은 언어 모델을 통해 단어 표현을 학습하지만, 대부분의 접근법은 단어의 시간 변화를 무시하고 텍스트 모델링의 노력에 영향을 미칠 수 있다.
    3. 이 논문에서는 TALM이라는 시간감각 언어 모델을 제안하여, 특정 시기에 맞는 언어 모델을 일반 도메인 언어 모델에서 전이학습하여 시간적 단어 표현을 학습한다. 이러한 방법은 시간 경과에 따른 문서 표현을 위해 계층적 모델링 접근법을 구축한다. 실험 결과는 우리의 모델이 단어의 암묵적인 시간적 정보를 효과적으로 포착하며, 역사적 텍스트 데이터화 작업에서 최첨단 접근법을 능가한다는 것을 보여준다.

###### A Read-and-Select Framework for Zero-shot Entity Linking (https://aclanthology.org/2023.findings-emnlp.912/)
- Anthology ID: 2023.findings-emnlp.912 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Zero-shot entity linking (EL)"는 보편화 능력을 도전하기 위해 보이지 않는 엔티티에 엔티티 멘션을 정렬하는 것을 목표로 한다. 
    2. 기존 방법들은 후보 추출 단계에 주로 초점을 맞추고, 후보 순위 결정 단계를 무시한다. 반면 이 논문에서는 "read-and-select (ReS)" 프레임워크를 제안하여 후보 선정 문제를 순차적 라벨링 문제로 설명하고, 모든 후보 표현을 통합하여 엔티티 간 비교를 가능하게 한다.
    3. 이 방법은 대부분의 이전 연구에 사용된 노동 집약적 다상(pre-training) 없이도 "ZESHEL" 데이터셋에서 최고 성능을 달성하며, 멘션-엔티티 상호작용과 엔티티 간 상호작용의 효과를 보여준다.

###### Multi-Task Learning of Query Generation and Classification for Generative Conversational Question Rewriting (https://aclanthology.org/2023.findings-emnlp.913/)
- Anthology ID: 2023.findings-emnlp.913 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화 검색 환경에서 질문을하고 대화의 일부로 답변을 받는 상황에서 질문의 모호성은 주요한 도전 과제이며, 대화 기록에서 문맥 정보를 활용하여 효과적으로 다룰 수 있다. 
    2. 기존 접근 방식들은 주제의 연속성을 분류 작업으로 다루거나, 재구성된 질문을 생성하는 텍스트 생성 작업으로 다루고 있다. 하지만 이 논문에서는 두 작업을 모두 포함하여 대화 중 모호한 질문을 효과적으로 식별하는 Multi-Task Learning (MTL) 접근 방식을 제안하고 있다. 
    3. BART와 T5를 기반으로 한 모델을 사용하여 대화식 질문 재작성과 추론 질문 식별 작업을 동시에 수행하는 모델을 학습하였으며, 다양한 테스트 세트에서 평가하여 단일 작업 학습 기준을 능가하는 결과를 보였다.

###### DepNeCTI: Dependency-based Nested Compound Type Identification for Sanskrit (https://aclanthology.org/2023.findings-emnlp.914/)
- Anthology ID: 2023.findings-emnlp.914 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다중 구성 복합어는 산스크리트어에서 흔한 현상이며, 복합어의 구성 요소의 내재적 구조를 이해하는 것은 의미를 해독하는 데 중요하다. 본 논문에서는 다중 구성 복합어 유형 식별 문제를 제안하고, 이를 위해 새로운 주석이 달린 데이터셋과 DepNeCTI라는 새로운 프레임워크를 제안한다.
    2. 기존 기법들은 이진 복합어에 초점을 맞추고 다중 구성 복합어를 무시해왔지만, 본 논문에서는 다중 구성 복합어의 내재적 의미 관계를 해석하기 위해 이와 같은 문제를 처음으로 제안한다.
    3. 실험 결과, DepNeCTI는 기존 기준선 기법과 비교하여 라벨링된 구간 점수(LSS)에서 평균 절댓값 13.1점의 F1-score 향상과 추론 효율성의 5배 향상을 달성한다.

###### HeQ: a Large and Diverse Hebrew Reading Comprehension Benchmark (https://aclanthology.org/2023.findings-emnlp.915/)
- Anthology ID: 2023.findings-emnlp.915 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 현재 히브리어 자연어 처리 (NLP)에 대한 벤치마크는 주로 형태-문법적인 작업에 초점을 맞추고, 언어 이해의 의미적인 차원을 무시하고 있다.
    2. 우리는 이 간극을 좁히기 위해 히브리어 기계 독해 (MRC) 데이터셋을 제공하기로 결정했다. 
    3. 우리는 새로운 가이드라인, 통제된 크라우드소싱 프로토콜 및 수정된 평가 메트릭을 개발하여 히브리어 특유의 풍부한 형태학적 특성에 적합하도록 한다.

###### HANSEN: Human and AI Spoken Text Benchmark for Authorship Analysis (https://aclanthology.org/2023.findings-emnlp.916/)
- Anthology ID: 2023.findings-emnlp.916 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 작문 분석(Stylometry)은 자연어처리(NLP)에서 오랫동안 중요한 요소로 다뤄져 왔으나 최근 대형 언어 모델(LLMs)의 발전에 따라 작문 분석은 사람이 쓴 텍스트와 AI가 생성한 텍스트를 구분하는 데 더욱 중요해졌다.
    2. 그러나 이 작문 분석 작업은 주로 작성된 텍스트에 초점을 맞추어 왔고, 구어 텍스트는 고려하지 않았다. 
    3. 따라서 우리는 구어 텍스트를 위한 가장 큰 벤치마크인 HANSEN(Human And ai Spoken tExt beNchmark)를 소개하며 인식된 인간 데이터셋과 AI생성 구어 텍스트 데이터셋을 활용하여 Authorship Attribution (AA) 및 Author Verification (AV)를 수행하고 최첨단 모델을 사용하여 인간 대 AI 텍스트 감지 작업을 수행한다.

###### Data Augmentation for Code Translation with Comparable Corpora and Multiple References (https://aclanthology.org/2023.findings-emnlp.917/)
- Anthology ID: 2023.findings-emnlp.917 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 프로그래밍 언어 간의 코드 번역은 병렬 훈련 데이터가 부족한 문제 때문에 주요한 어려움을 가지고 있다. 본 논문에서는 기능이 유사한 코드 쌍을 갖는 비교 가능한 문서나 기존의 병렬 데이터에 다중 참조 번역을 추가하는 데이터 증강 기법 두 가지를 제안한다. 
    2. 자연어 문서에서 코드 생성 모델을 사용하여 생성된 프로그램을 포함한 여러 유형의 비교 가능한 문서를 분석한다. 게다가, 다중 참조 번역을 자동으로 생성하고 유닛 테스트로 번역을 필터링하여 단일 참조 번역에 대한 과적합을 줄인다. 이렇게 함으로써 목표 번역에 다양성을 추가할 수 있다. 
    3. 실험 결과, 우리의 데이터 증강 기법은 Java, Python 및 C++ 간의 번역에서 CodeT5의 계산 정확도 (CA@1)를 평균 7.5% 향상시킨다. 이는 실행을 통해 번역의 정확성을 확인하는 것이다.

###### Multilingual Generation and Answering of Questions from Texts and Knowledge Graphs (https://aclanthology.org/2023.findings-emnlp.918/)
- Anthology ID: 2023.findings-emnlp.918 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. QG와 QA를 다양한 NLP 응용 분야에 도움이 되는 다중 모달리티(KG와 NL)를 가진 자동 평가를 위한 QA 기반 방법들을 연결할 수 있는 능력이 있다.
    2. 이 논문에서는 QG-QA에 대한 멀티링귤러(Multilingual)와 멀티모달 (Multimodal) (KG와 NL) 기능을 초록어와 러시아어로 확장시켰다.
    3. 이 연구에서는 그래프와 텍스트 간에 맞춤된 QG-QA 데이터를 만들기 위해 합성 데이터 생성과 기계 번역을 활용하여 멀티모달, 멀티태스크 모델을 훈련시켜 멀티모달 QG와 QA를 포르투갈어와 러시아어로 수행할 수 있음을 보였다.

###### InfoDiffusion: Information Entropy Aware Diffusion Process for Non-Autoregressive Text Generation (https://aclanthology.org/2023.findings-emnlp.919/)
- Anthology ID: 2023.findings-emnlp.919 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 텍스트 생성 모델에서 "쉬운 것부터" 생성하는 기존 방식과 인간의 "키워드부터" 생성하는 방식 사이에는 큰 차이가 있는데, 이 논문에서는 이 차이를 줄이기 위해 자동회귀적이지 않은 InfoDiffusion 모델을 제안한다. 
    2. 제안한 모델은 "키워드-정보부터" 생성 전략을 도입하고 텍스트 정보량을 기반으로한 잡음 스케줄을 사용한다.
    3. 실험 결과, InfoDiffusion은 텍스트 생성 품질과 다양성에서 기준 모델을 능가하며 샘플링 효율성이 더 높음을 보여준다.

###### Enhancing Scalability of Pre-trained Language Models via Efficient Parameter Sharing (https://aclanthology.org/2023.findings-emnlp.920/)
- Anthology ID: 2023.findings-emnlp.920 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문에서는 사전 훈련된 언어 모델(PLMs)의 깊이를 확장하기 위한 매우 parameter-efficient한 방법을 제안한다. 
    2. 다른 이전의 연구들은 모든 parameter를 공유하거나 추가 블록을 사용하는 반면, 이 연구에서는 효율적인 텐서 분해 방법인 MPO를 기반으로 더 강력한 parameter-sharing 아키텍처를 설계한다. 
    3. 실험 결과, 우리가 제안한 모델은 확장성을 개선하고 더 적은 parameter로 BERT-large와 비슷한 성능을 달성하는 것을 보여주었다.

###### Boosting Prompt-Based Self-Training With Mapping-Free Automatic Verbalizer for Multi-Class Classification (https://aclanthology.org/2023.findings-emnlp.921/)
- Anthology ID: 2023.findings-emnlp.921 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 prompt-based fine-tuning은 몇 개의 예시만 가지고도 텍스트 분류 작업을 수행할 수 있는 중요한 기술로 주목받고 있으나, 다중 클래스 분류에 대한 prompt-based self-training 연구가 충분히 이루어지지 않았다.
    2. 이 연구에서는 Mapping-free Automatic Verbalizer (MAV)라는 효율적인 Verbalizer 구조를 소개하고, MLM 예측에서 모든 정보를 활용하여 자동으로 필요한 단어 특징을 추출하여 분류하는 기능을 한다.
    3. 다섯 개의 다중 클래스 분류 데이터셋에 대한 실험결과 MAV의 superior self-training 효과가 입증되었다.

###### On the Impact of Cross-Domain Data on German Language Models (https://aclanthology.org/2023.findings-emnlp.922/)
- Anthology ID: 2023.findings-emnlp.922 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 대형 언어 모델은 일반적인 웹 데이터나 특정 도메인 데이터에서 훈련되었으나, 최근 대규모 언어 모델의 성공은 도메인 간 데이터 다양성의 이점을 보여준다.
    2. 우리는 5개 도메인의 텍스트를 포함하는 독일어 데이터셋과 고품질 데이터를 포함하는 다른 데이터셋을 제시하고, 두 데이터셋에서 122M에서 750M 파라미터까지의 모델을 훈련함으로써 다양한 후속 작업에 대한 포괄적인 벤치마크를 수행한다.
    3. 우리의 결과는 도메인 간 데이터셋에서 훈련된 모델이 단독으로 훈련된 고품질 데이터보다 우수한 성능을 보이며, 이로 인해 이전 최고 성능 대비 최대 4.45%의 성능 향상을 나타낸다.

###### Dialect-to-Standard Normalization: A Large-Scale Multilingual Evaluation (https://aclanthology.org/2023.findings-emnlp.923/)
- Anthology ID: 2023.findings-emnlp.923 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 텍스트 정규화 방법은 주로 역사적 언어나 사용자 생성 콘텐츠에 적용되었지만, 방언적 표기에는 덜 사용되었다. 이 논문에서는 방언에서 표준어로의 정규화를 독립된 문장 수준의 문자 변환 문제로 소개하고, 방언에서 표준어로의 정규화 방법에 대한 대규모 분석을 제공한다.
    2. 네 가지 언어 (핀란드어, 노르웨이어, 스위스 독일어, 슬로베니아어)를 커버하는 다국어 데이터셋을 구축하고, 자동 정규화에 대한 다양한 use case에 해당하는 세 가지 다른 데이터 분할을 제공한다.
    3. 토큰화 접근 방식과 문맥 크기에 따라 텍스트 정규화 작업에 제안된 가장 성공적인 시퀀스-투-시퀀스 모델 아키텍처를 평가하고, 핀란드어, 스위스 독일어, 슬로베니아어의 경우 3개 단어의 슬라이딩 윈도우로 훈련된 문자 수준 Transformer가 가장 잘 작동한다는 것을 발견했다.

###### Re-Examining Summarization Evaluation across Multiple Quality Criteria (https://aclanthology.org/2023.findings-emnlp.924/)
- Anthology ID: 2023.findings-emnlp.924 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자동 평가 메트릭의 평가는 zuverlässige 인간 평가에서 얻은 시스템 순위와의 상관관계를 측정하여 더 높은 상관관계가 더 좋은 평가 메트릭을 의미한다.
    2. 그러나 여러 Quality Criteria (QCs)가 있는 NLP 태스크의 경우 이 방법론의 타당성에 관한 의문을 제기한다.
    3. 결론적으로 여러 QCs가 있는 경우에는 metric 평가 방법론을 더 조사해야 함을 강조한다.

###### A Parallel Corpus for Vietnamese Central-Northern Dialect Text Transfer (https://aclanthology.org/2023.findings-emnlp.925/)
- Anthology ID: 2023.findings-emnlp.925 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 베트남어는 3개의 주요 지역, 북부, 중부 및 남부에 밀접하게 결합된 방언 변형을 포함하고 있습니다. 현재 NLP 모델은 베트남어 중앙 방언 텍스트를 이해하지 못하는 것으로 관측되었으며, 이는 리소스의 부족으로 인한 것입니다.
    2. 베트남어 중앙북 방언 텍스트 전송 작업에서 단일 언어 모델이 다중 언어 모델보다 우위를 보이는 것을 발견했습니다.
    3. 풍부한 번역 및 텍스트-이미지 검색 작업 결과를 통해 세부적으로 베트남어 중앙 방언 도메인에서 기존 NLP 시스템의 성능을 향상시킬 수 있는 것을 보였습니다.

###### A Comprehensive Evaluation of Tool-Assisted Generation Strategies (https://aclanthology.org/2023.findings-emnlp.926/)
- Anthology ID: 2023.findings-emnlp.926 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 연구는 언어 모델에 툴 (예: 검색 엔진, 계산기)을 추가하여 누락된 지식이나 잘못된 논리적 추론과 같은 단점을 극복하는 방법을 조사하고 있다. 
    2. 이 논문에서는 다양한 few-shot tool-usage 전략들을 체계적으로 비교하고, 툴을 활용하지 않는 강력한 베이스라인과의 비교를 수행한다. 
    3. 연구 결과, 툴을 효과적으로 사용하는 것은 여전히 어려운 문제이며, 지식 검색 작업에서는 잘못된 출력을 툴을 사용하여 수정하는 전략이 성능 면에서 더 우수하다는 것을 보여준다. 그러나 툴을 사용한 전략은 토큰 수에 비례하여 많은 비용이 들지만 성능 향상에는 큰 기여를 하지 않는다고 다는 것을 발견하였다.

###### InheritSumm: A General, Versatile and Compact Summarizer by Distilling from GPT (https://aclanthology.org/2023.findings-emnlp.927/)
- Anthology ID: 2023.findings-emnlp.927 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. GPT-3와 같은 큰 모델들은 zero-shot 및 few-shot 요약 작업에서 뛰어난 성능을 보이지만, 그들의 많은 서빙 및 fine-tuning 비용은 다양한 응용 분야에서의 활용을 어렵게 한다.
    2. 그러나 이전 연구에서는 자동 메트릭은 작은 fine-tuned 모델들을 선호하지만, 인간 평가자들에 따르면 그들이 생성하는 요약의 품질은 GPT-3와 같은 큰 모델들보다 열악하다고 발견되었다.
    3. 이 문제를 해결하기 위해 우리는 GPT-3.5에서 축소(distillation)를 통해 도출된 다재다능하고 간결한 요약 모델인 InheritSumm을 제안한다. InheritSumm은 GPT-3.5와 비교할만한 zero-shot 및 few-shot 요약 능력을 가지며 fine-tuning 목적으로 충분히 간결하다. 실험 결과 InheritSumm은 zero-shot 및 few-shot 설정에서 GPT-3.5와 유사하거나 우수한 성능을 보여준다. 또한, prefix-tuning 및 전체 데이터 fine-tuning 시나리오에서 이전에 확립된 최상의 작은 모델들보다 우수한 성능을 발휘한다.

###### Learning to love diligent trolls: Accounting for rater effects in the dialogue safety task (https://aclanthology.org/2023.findings-emnlp.928/)
- Anthology ID: 2023.findings-emnlp.928 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 챗봇은 모욕적인 발언을 생성할 위험이 있으며, 이를 피해야 한다. 이 논문은 사용자의 피드백으로부터 얻은 대화/레이블 쌍을 이용하여 챗봇을 지속적으로 개선하는 방법을 제안한다. 
    2. 이전 연구들에서는 고객 간 교차 검증 에러를 기준으로 오인된 훈련 데이터를 제거해왔으나, 이는 비용이 많이 든다. 본 연구에서는 여러 사용자가 각 발언을 평가하고 이를 통해 올바른 레이블을 추론하기 위해 잠재적 클래스 분석(LCA)을 사용하는 AES와 비슷한 해결책을 제안한다.
    3. 실험 결과, 적대적인 사용자들 사이에서 일관성이 있을 때 AES와 비슷한 해결책은 높은 정확도로 훈련 레이블을 추론할 수 있다는 것을 보였다.

###### Can ChatGPT Perform Reasoning Using the IRAC Method in Analyzing Legal Scenarios Like a Lawyer? (https://aclanthology.org/2023.findings-emnlp.929/)
- Anthology ID: 2023.findings-emnlp.929 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근에는 ChatGPT와 같은 대형 언어 모델들이 다양한 법률 작업을 수행할 수 있는 능력으로 인해 법률 분야에서 많은 관심을 받고 있다. 그러나 여전히 LLMs가 변호사들과 동일한 방식으로 법률 케이스를 분석하고 추론할 수 있는지는 알려져 있지 않다. 
    2. 이 연구에서는 법률 전문가들이 법률 분석을 위해 널리 사용하는 IRAC 방법론을 활용하여 ChatGPT를 적용하여 케이스 분석을 수행하기 위한 독특한 말뭉치를 구축하였다. 
    3. 실험 결과는 LLMs와 법률 전문가들의 분석 간의 일치를 개선하기 위한 가능한 미래 연구 방향을 알려주고 있다.

###### Coverage-based Example Selection for In-Context Learning (https://aclanthology.org/2023.findings-emnlp.930/)
- Anthology ID: 2023.findings-emnlp.930 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "In-context learning (ICL)은 큰 언어 모델이 몇 가지 태스크 예제로 조건부로 작업을 수행하는 능력인데, 이때 예제들은 테스트 인스턴스에 대해 정보를 제공해야한다."
    2. 기존 방식은 각각 독립적으로 순위를 매기고 가장 유사한 예제를 선택하는데, 이 방식은 중복되는 예제들을 선택하면서 중요한 정보를 빠뜨리는 문제가 있다.
    3. 이 논문에서는 BERTScore-Recall (BSR)이 테스트 입력의 중요한 측면인 추론 패턴 등을 더 잘 보여주는 더 좋은 예제를 선택한다는 것을 보였으며, Set-BSR을 사용하여 셋 수준에서 최적화 가능한 메트릭을 확장시켜 새로운 방식의 선택 방법을 제안한다.

###### Are Structural Concepts Universal in Transformer Language Models? Towards Interpretable Cross-Lingual Generalization (https://aclanthology.org/2023.findings-emnlp.931/)
- Anthology ID: 2023.findings-emnlp.931 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대규모 언어 모델(LLM)은 다양한 언어 간의 암묵적인 지식 전달을 통해 상당한 교차 언어 일반화 능력을 보여주었지만, 저자원 언어에 대해서는 특히 도전적인 문제가 있습니다. 
    2. 본 논문에서는 언어 간 개념적 관련성을 명시적으로 정렬하여 교차 언어 일반화를 향상시키는 가능성을 조사합니다. 
    3. 실험 결과, 우리의 방법은 최첨단 방법과 경쟁력 있는 결과를 보여주며, 특히 자원이 제한된 언어에 큰 이점을 제공합니다.

###### Thorny Roses: Investigating the Dual Use Dilemma in Natural Language Processing (https://aclanthology.org/2023.findings-emnlp.932/)
- Anthology ID: 2023.findings-emnlp.932 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대용도 언어 모델(LLM)들이 점점 발전하고 접근성이 높아지면서, 그들의 의도적 오용 위험이 더욱 두드러지는 자연어 처리(NLP)에서의 이중 사용은 불명확한 문제이다. 
    2. 이 논문에서는 NLP 연구자와 실무자들의 의견을 반영하여 이중 사용에 대한 NLP 특정 정의를 제시한다. 
    3. 더 나아가, NLP에서 이중 사용에 초점을 맞춘 체크리스트를 제안하며, 이는 기존의 학회 윤리 프레임워크에 통합할 수 있다.

###### BYOC: Personalized Few-Shot Classification with Co-Authored Class Descriptions (https://aclanthology.org/2023.findings-emnlp.933/)
- Anthology ID: 2023.findings-emnlp.933 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 텍스트 분류는 다양한 NLP 응용 분야를 위한 잘 연구된 기술이다. 그러나 기존 방법들은 모델을 학습시키기 위해 큰 어노테이션된 말뭉치를 필요로 하거나, 큰 언어 모델을 사용할 때는 prompt를 조심스럽게 작성하고 많은 예제를 수용할 수 있는 긴 문맥이 필요하다.
    2. 우리는 이 문제를 해결하기 위해 LLM을 사용하여 페워샷(few-shot) 텍스트 분류에 새로운 접근 방법을 제안한다. LLM은 페워샷 예제 대신 각 클래스의 중요한 특징을 설명하는 프롬프트를 받는다. 이후 사용자와 LLM은 상호작용하면서 프롬프트를 작성한다.
    3. 실험 결과 우리의 접근 방법은 큰 데이터셋으로 학습한 모델의 성능 기준 79%를 달성하면서, 학습 데이터셋의 1%만을 사용하여 높은 정확도의 분류기를 얻을 수 있음을 보여주고, 30명의 참가자와 진행한 연구에 따르면 엔드 유저들은 특정한 요구에 맞는 분류기를 만들 수 있다는 것을 보여주었다.

###### Approximating CKY with Transformers (https://aclanthology.org/2023.findings-emnlp.934/)
- Anthology ID: 2023.findings-emnlp.934 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문은 transformer 모델이 CKY 알고리즘을 근사화하는 능력을 조사하고, 이를 통해 CKY 알고리즘의 문장 길이에 대한 세제곱 의존성을 피하는 방법을 제안한다.
    2. 일반적인 구문 구문 분석 벤치마크에서, 이 접근 방식은 CKY를 사용하는 유사한 파서보다 경쟁력있는 성능 또는 더 뛰어난 성능을 달성하는 동시에 속도도 빠르다.
    3. 또한, 무작위 PCFG(확률적 구문 구조) 하에서의 파싱 가능성을 평가한 결과, 문법이 더 모호해질수록 성능이 저하되는 것을 발견하였고, 추가적인 귀납적 편향을 포함하는 것이 도움이 된다는 것을 확인하였다.

###### DialGuide: Aligning Dialogue Model Behavior with Developer Guidelines (https://aclanthology.org/2023.findings-emnlp.935/)
- Anthology ID: 2023.findings-emnlp.935 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화 모델은 일관되고 유창한 응답을 생성할 수 있지만, 제어하기 어렵고 매력이 없는, 안전하지 않은 결과물을 생성할 수도 있다. 이러한 예측할 수 없는 특성은 사용자의 신뢰를 약화시키고 모델의 실세계에서의 사용을 어렵게 할 수 있다. 
    2. 이를 해결하기 위해, 우리는 DialGuide라는 새로운 프레임워크를 소개한다. DialGuide는 자연어 규칙 또는 가이드라인을 사용하여 대화 모델의 행동을 제어할 수 있다. 
    3. 우리는 DialGuide를 오픈 도메인 대화 응답 생성의 세 가지 작업에 대해평가하였다. 우리의 데이터셋은 두 도메인 (잡담과 안전)에서 10,737개의 양성 및 15,467개의 음성 대화 문맥-응답-지침 세트를 포함하고 있다.

###### RWKV: Reinventing RNNs for the Transformer Era (https://aclanthology.org/2023.findings-emnlp.936/)
- Anthology ID: 2023.findings-emnlp.936 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 트랜스포머는 NLP 태스크에서 차세대 기술로 평가받지만, 시퀀스 길이에 대해 제곱에 비례하는 메모리와 연산 복잡성을 가지고 있다.
    2. 이와는 달리 재귀 신경망(RNN)은 선형 스케일링을 갖고 있지만, 병렬화와 확장성 등의 한계로 트랜스포머와 비교하여 성능을 내기 어렵다.
    3. 따라서 저자들은 효율적인 트레이닝 기법과 결합한 새로운 모델 아키텍처인 Receptance Weighted Key Value (RWKV)를 제안하고, 이를 통해 트랜스포머나 RNN 중 어느 방식으로 모델을 적용할지 선택할 수 있도록 하여 트레이닝은 병렬화하고 추론은 일정한 계산 및 메모리 복잡성을 유지할 수 있다는 것을 보여주었다.

###### Who Wrote it and Why? Prompting Large-Language Models for Authorship Verification (https://aclanthology.org/2023.findings-emnlp.937/)
- Anthology ID: 2023.findings-emnlp.937 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 저자 검증(AV)은 법의학 분석, 표절 탐지, 속임수 있는 콘텐츠 식별 등에서 활용되는 자연어 처리(NLP)와 계산 언어학의 기본 작업이다. 기존 AV 기술은 데이터 요구 사항과 설명 가능성의 한계를 갖고 있다.
    2. 이 논문에서는 PromptAV라는 새로운 기술을 제안하여 대규모 언어 모델을 활용하여 AV를 수행한다. PromptAV는 단계별 기술적 설명 프롬프트를 제공하여 사람들이 해석하기 쉬운 설명을 통해 성능을 크게 향상시킨다.
    3. PromptAV는 최첨단 기준선에 비해 우수한 성능을 발휘하며, 제한된 학습 데이터로도 효과적으로 작동하고 해석 가능성을 향상시킴으로써 AV 작업에 효과적이고 해석 가능한 솔루션으로의 잠재력을 보여준다.

###### Transitioning Representations between Languages for Cross-lingual Event Detection via Langevin Dynamics (https://aclanthology.org/2023.findings-emnlp.938/)
- Anthology ID: 2023.findings-emnlp.938 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이전 연구는 representation matching 기법에 초점을 맞춰 고-저 자원 언어 간의 cross-lingual transfer learning (CLTL)을 가능하게 해왔다. 그러나 representation을 변경하게 되므로, 실제 예측을 위해 source-language의 교육 데이터로부터 학습한 ED에 대한 구분력 있는 특징들을 상실할 수 있다.
    2. 우리는 Langevin Dynamics와 semantic preservation 프레임워크를 소개하여 cross-lingual ED에 대한 새로운 접근법을 제시한다. 이를 통해 target-language 예제의 representation만 source-language의 공간으로 전환하여 source language의 표현과 구분력 있는 정보를 보존할 수 있다.
    3. 세 가지 언어에 대한 실험 결과, 우리의 방법은 CLTL에서 ED에 대한 최고 수준의 성능을 보여준다.

###### VISIT: Visualizing and Interpreting the Semantic Information Flow of Transformers (https://aclanthology.org/2023.findings-emnlp.939/)
- Anthology ID: 2023.findings-emnlp.939 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 인터프리터빌리티(해석가능성)의 진보들은 transformer 기반 언어 모델의 가중치와 hidden states를 vocabulary로 변환하여 인간이 해석하기 더 쉽도록 할 수 있다는 것을 제안한다. 
    2. 본 논문에서는 LM attention heads와 memory values를 분석하여 어텐션 메커니즘 내의 정보 흐름 패턴을 파악한다.
    3. 우리의 시각화 도구는 GPT의 forward pass를 인터랙티브한 플로우 그래프로 시각화하여 모델 내부 작업을 간단히 파악할 수 있게 한다.

###### Is Robustness Transferable across Languages in Multilingual Neural Machine Translation? (https://aclanthology.org/2023.findings-emnlp.940/)
- Anthology ID: 2023.findings-emnlp.940 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 신뢰성 있는 NLP 시스템 개발을 위해, 모델의 robustness는 성능을 지속하는 능력이 강조되고 있다. 특히 기계 번역에서는, 최근의 연구들이 adversarial training과 data augmentation을 통해 모델의 robustness를 개선하는데 성공하였으나, 이러한 연구들은 단일 번역 방향에 대한 이중 언어 기계 번역에 중점을 두고 있다.
    2. 본 논문에서는 다국어 신경 기계 번역에서 다양한 언어들 간의 robustness 전이 가능성을 조사한다. 특히, 다국어 신경 기계 번역 모델의 특정 번역 방향을 character, word, multi-level noises로 공격하여 다른 번역 방향의 robustness를 평가한다.
    3. 연구 결과, 한 번역 방향에서 얻은 robustness가 다른 번역 방향으로 전이될 수 있음을 실험적으로 확인하였으며, 특히 character-level noise와 word-level noise에 대한 robustness 전이가 더 가능한 경우를 확인하였다.

###### Arabic Mini-ClimateGPT : A Climate Change and Sustainability Tailored Arabic LLM (https://aclanthology.org/2023.findings-emnlp.941/)
- Anthology ID: 2023.findings-emnlp.941 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기후 변화는 사회적으로 맞닥뜨리는 가장 중요한 도전 중 하나이다. 이 논문에서는 기후변화와 지속가능성에 대한 500,000개 이상의 지시문을 보유한 아랍어 데이터셋으로 특별히 조정된 경량 아랍어 Mini-ClimateGPT 모델을 제안한다.
    2. 이 모델은 대화형 스타일의 지시조정(curated instruction tuning)에 특히 초점을 맞춘 오픈소스 LLM(대용량 언어 모델)을 기반으로 구축되었다. ChatGPT 기반 평가에서 기준 모델을 88.3%의 경우에서 능가했으며, 인간 전문가 평가에서는 81.6%의 선호도를 얻었다.
    3. 이를테면, 이 논문에서 제안된 기타 오픈소스 모델보다 우리 모델의 응답을 더 선호하는 사람들이 81.6%를 차지한다.

###### Interpreting Answers to Yes-No Questions in User-Generated Content (https://aclanthology.org/2023.findings-emnlp.942/)
- Anthology ID: 2023.findings-emnlp.942 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 소셜 미디어에서 예/아니오 질문에 대한 답변을 해석하는 것은 어렵다. 예와 아니오 키워드는 흔하지 않고, 이러한 키워드를 포함한 답변들도 키워드가 제안하는 바와는 다르게 해석되는 경우가 많다.
    2. 본 논문에서는 트위터로부터 얻은 4,442개의 예/아니오 질문-답변 쌍의 새로운 말뭉치를 제시한다. 예나 아니오로 해석되는 답변의 언어적 특성과 알려지지 않은 해석을 가진 답변에 대해 논의한다.
    3. 해당 문제에 대해 사회적 미디어 외부에서의 말뭉치를 세밀하게 조정하고 결합한 후에도, 대형 언어 모델이 이 문제를 해결하는 데는 여전히 멀었다는 것을 보여준다.

###### Task-Aware Self-Supervised Framework for Dialogue Discourse Parsing (https://aclanthology.org/2023.findings-emnlp.943/)
- Anthology ID: 2023.findings-emnlp.943 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화 문맥 파싱은 다중 선택 문제 생성, 대화 요약 및 대화에서의 감정 인식 등 다양한 대화 관련 태스크에 유용한 자연 언어 처리 태스크이다. 
    2. 기존 파싱 접근법들은 사전에 정의된 관계 유형에 제한되어 있어 파서의 태스크에 대한 적응성이 제한될 수 있다. 
    3. 이 논문에서는 태스크에 대한 인식 패러다임을 도입하여 파서의 다양성을 향상시킨다.

###### Selective Demonstrations for Cross-domain Text-to-SQL (https://aclanthology.org/2023.findings-emnlp.944/)
- Anthology ID: 2023.findings-emnlp.944 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 대규모 언어 모델(Large language models, LLMs)은 in-context learning을 통해 도메인 내 주석을 사용하지 않고도 교차 도메인 텍스트-투-SQL 작업에서 탁월한 일반화 능력을 보였다. 그러나 도메인 내 사례를 통합하면 LLMs의 성능이 크게 향상되는 것으로 나타났다. 
    2. 본 논문에서는 도메인 내 사례 내에서 성능 향상에 기여하는 주요 요소를 탐구하고, 도메인 주석에 의존하지 않고도 이러한 이점을 활용할 수 있는지 연구한다. 
    3. 그 결과, ODIS라는 사례 선택 프레임워크를 제안하고, 도메인 외 사례와 합성된 도메인 내 사례를 모두 활용하여 사례를 구성한다. ODIS는 하이브리드 소스에서 사례를 검색함으로써 양쪽의 장점을 활용하며, 단일 데이터 소스에 의존하는 기준 모델에 비해 효과적이다. 또한, ODIS는 두 개의 교차 도메인 텍스트-투-SQL 데이터셋에서 최신 접근 방법을 능가하며, 실행 정확도에서 각각 1.1 및 11.8 포인트의 개선을 나타낸다.

###### DocSplit: Simple Contrastive Pretraining for Large Document Embeddings (https://aclanthology.org/2023.findings-emnlp.945/)
- Anthology ID: 2023.findings-emnlp.945 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 모델 사전학습 방법은 로컬 정보만 고려하는데, 그 결과로 토큰 마스킹 전략을 사용하면 가까운 단어가 먼 단어보다 더 중요하게 여겨지기 때문에 문장 임베딩의 품질은 높지만 큰 문서에 대한 임베딩은 품질이 낮아진다.
    2. 우리는 전체적인 글로벌 문맥을 고려하도록 모델을 강제하는 DocSplit이라는 새로운 사전학습 방법을 제안한다.
    3. 우리의 실험 결과, DocSplit은 문서 분류, 퓨-샷 학습 및 정보 검색 작업에서 다른 사전학습 방법을 능가한다.

###### TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks (https://aclanthology.org/2023.findings-emnlp.946/)
- Anthology ID: 2023.findings-emnlp.946 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. LLMs가 전통적인 대화 상황에서 텍스트를 이해하고 생성하는 데 큰 성공을 보였지만, 복잡한 task를 수행하는 능력은 아직 연구되지 않았고 벤치마크되지 않았다.
    2. 이 논문에서는 다양한 task에 대한 프롬프트의 다양성과 성능에 대한 taxonomy를 제안한다. 이를 통해 향후 연구들에서 특정 task를 비교할 수 있게 되며, 연구자들은 LLMs의 성능에 대해 더 정확한 결론을 내릴 수 있다.
    3. 이 taxonomy는 다양한 연구를 통해 공통된 기준을 세워 LLMs의 복잡한 task 수행 능력을 평가하는데 도움을 줄 것이다.

###### IntenDD: A Unified Contrastive Learning Approach for Intent Detection and Discovery (https://aclanthology.org/2023.findings-emnlp.947/)
- Anthology ID: 2023.findings-emnlp.947 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화 발화로부터 의도를 식별하는 것은 과제 지향 대화 시스템의 중요한 구성 요소입니다. 의도 관련 작업은 일반적으로 분류 작업으로 정의되며, 발화를 사전에 정의된 카테고리로 분류하거나 새로운 의도 카테고리를 발화에서 발견해야 하는 클러스터링 작업으로 모델링됩니다.
    2. 기존 방법들은 일반적으로 이러한 작업들을 별도의 작업으로 모델링하지만, 우리는 IntenDD라는 통합적인 접근 방법을 제안하여 공유 발화 인코딩 백본을 활용합니다. IntenDD는 표현 학습을 위해 완전히 비지도 대조학습 전략을 사용하며, 렉시컬 특징을 기반으로 레이블이 없는 발화에 가상 레이블을 생성합니다.
    3. 다양한 벤치마크 데이터셋에서의 광범위한 평가를 통해 IntenDD가 모든 세 가지 작업에서 경쟁력 있는 기준 모델보다 일관적으로 우수한 성능을 보였습니다. 평균적으로, IntenDD는 다중 분류(few-shot MC), 다중 레이블 (few-shot ML), 의도 발견 작업에서 각각 해당 지표에 대해 2.32% , 1.26%, 1.52%의 향상률을 보고하였습니다.

###### INarIG: Iterative Non-autoregressive Instruct Generation Model For Word-Level Auto Completion (https://aclanthology.org/2023.findings-emnlp.948/)
- Anthology ID: 2023.findings-emnlp.948 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 컴퓨터 보조 번역(CAT)은 인간 번역 효율을 향상시키는데 중요한데, 이 중에서도 Word-Level Auto Completion (WLAC)은 기존 방법들을 개선하여 가장 정확한 결과를 도출해냈다.
    2. 기존의 방법들은 타겟 단어의 양쪽 문맥을 고려하기 위해 단어 분류 모델을 사용하거나, 오른쪽 문맥의 의존성을 무시하는 문제가 있다.
    3. 이 논문에서는 INarIG(Iterative Non-autoregressive Instruct Generation) 모델을 제안하여 입력된 정보를 완전히 활용하기 위해 인간이 작성한 시퀀스를 Instruction Unit으로 구성하고 하위 단어를 사용한 반복적 디코딩 기법을 도입하여 낮은 빈도 단어에 대해서도 높은 예측 정확도를 달성하였다.

###### Is the Answer in the Text? Challenging ChatGPT with Evidence Retrieval from Instructive Text (https://aclanthology.org/2023.findings-emnlp.949/)
- Anthology ID: 2023.findings-emnlp.949 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근에는 생성형 언어 모델이 텍스트 상황에서의 질문에 대한 정답을 생성하는 데 놀라운 성과를 보이고 있다. 그러나 이러한 답변은 환영에 걸려있거나, 잘못된 증거를 인용하거나, 오도적인 정보를 퍼뜨릴 수 있다.
    2. 이 연구에서는 ChatGPT라는 최신 생성 모델을 기계 독해 시스템으로 사용하여 이 문제를 다루고자 한다.
    3. 제안된 방법으로 ChatGPT는 신뢰할 수 있는 교육적 텍스트에서 다양하고 개방적인 질문에 대한 답을 검색하도록 요청하며, WHERE라는 평가 벤치마크가 도입된다. 이 데이터셋은 WikiHow 기사들을 대상으로 하며, 질문에 대한 증거 문장이 철저하게 주석 달려 있으며, 모든 질문이 기사의 주제에 관한 것인데도 불구하고 제공된 문맥을 사용하여 대답할 수 있는 것은 아니다.

###### PaRaDe: Passage Ranking using Demonstrations with LLMs (https://aclanthology.org/2023.findings-emnlp.950/)
- Anthology ID: 2023.findings-emnlp.950 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 연구결과에서는, 대형 언어 모델이(first stage retrieval method인 BM25를 포함하여) 효과적으로 zero-shot passage re-ranking을 수행할 수 있다는 것을 보여준다.
    2. 이 연구에서 우리는 프롬프트에 포함시킬 few-shot demonstrations를 알고리즘적으로 선택함으로써 LLM 기반의 re-ranking을 개선한다.
    3. 우리 연구는 어려움에 기반한 새로운 demonstrations 선택 전략을 제안하고, 랭킹에 도움이 되는 demonstrations은 질문 생성에서도 효과적임을 밝힌다.

###### Learning Dynamic Representations for Discourse Dependency Parsing (https://aclanthology.org/2023.findings-emnlp.951/)
- Anthology ID: 2023.findings-emnlp.951 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. discourse dependency parsing 문제에서는 기존 작업들이 transition history로부터 얻은 arcs를 무시하고 transition 상태를 일부 EDUs로만 특징화한다. 
    2. 이 논문에서는 이전 transition 단계에서 구성된 sub-trees에 대해 GAT 기반 인코더를 사용하여 동적 표현을 학습하는 것을 제안한다. 
    3. 실험 결과, 우리의 모델은 RST-DT, SciDTB, CDTB를 포함한 다양한 데이터셋에서 최고 성능을 달성할 수 있다는 것을 보여준다.

###### K-HATERS: A Hate Speech Detection Corpus in Korean with Target-Specific Ratings (https://aclanthology.org/2023.findings-emnlp.952/)
- Anthology ID: 2023.findings-emnlp.952 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 수많은 online hate 확산 방지를 위한 데이터셋이 제안되었지만, 이들의 대부분은 영어 위주이고, 주로 혐오 표현의 명시적인 형태에 초점을 맞추었다. 
    2. 이 연구의 목표는 미묘한 혐오 표현을 포함한 다양한 언어로 고품질의 코퍼스를 개발하는 것이다. 
    3. K-HATERS 데이터셋은 대상 특정적인 혐오 표현을 포함한 약 192,000개의 한국어 뉴스 댓글로 구성되어 있으며, 3점 Likert 척도로 대상별 불쾌감 정도를 평가하였다. 이 데이터셋은 한국어에서 다양한 정도의 혐오 표현을 감지할 수 있도록 구성되었다고 한다.

###### Mitigating Data Imbalance and Representation Degeneration in Multilingual Machine Translation (https://aclanthology.org/2023.findings-emnlp.953/)
- Anthology ID: 2023.findings-emnlp.953 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다중 언어 신경기계번역(MNMT)에서 데이터의 불균형과 표현의 역행에 대한 두 가지 주요 도전 과제가 여전히 존재한다고 주장한다.
    2. Bi-ACL을 제안하여 MNMT 모델의 성능을 향상시키기 위해 목표측 단일언어 데이터와 양방향 자동인코더, 양방향 대조학습 등의 모듈을 활용한다.
    3. 다양한 실험에서 제안된 방법이 나흘 언어와 고자원 언어에서 강력한 기준 모델보다 더 효과적임을 보여주며, 영역 및 언어 간의 지식 이전도 가능함을 입증한다.

###### BotPercent: Estimating Bot Populations in Twitter Communities (https://aclanthology.org/2023.findings-emnlp.954/)
- Anthology ID: 2023.findings-emnlp.954 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 트위터 봇 탐지는 가짜 정보와 소셜 미디어 대화의 정품성을 보호하기 위해 중요하다. 그러나 악성 봇은 점점 더 정교하고 개인화되고 있으며, 기존의 봇 탐지 방법은 이러한 봇들이 작동하는 소셜 환경(커뮤니티)을 고려하지 않으며 정확도가 떨어진다.
    2. 본 연구에서는 커뮤니티별 봇 탐지를 소개하며, 커뮤니티의 문맥을 고려하여 봇의 비율을 추정한다. BotPercent라는 방법은 트위터 봇 탐지 데이터셋과 특징, 텍스트, 그래프 기반 모델의 결합으로 이루어져 있다.
    3. 실험 결과, BotPercent는 균형 잡힌 클래스 분포와 불균형한 클래스 분포 설정에서 커뮤니티 수준 트위터 봇 탐지에서 state-of-the-art 성능을 보여주며, 트위터 커뮤니티 내 봇 인구의 편향이 적은 추정치를 제공한다. 봇이 존재하는 트위터 그룹(언론매체, 정치 커뮤니티 등)에서 봇 비율을 분석한 결과, 봇의 존재는 일정하지 않고 지리적-시간적 분포에서 상당한 이질성을 보여줌을 발견했다.

###### The Locality and Symmetry of Positional Encodings (https://aclanthology.org/2023.findings-emnlp.955/)
- Anthology ID: 2023.findings-emnlp.955 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. positional encodings (PEs)은 transformer 기반 언어 모델에 단어 순서 정보를 주입하는 데 사용되지만, 최근의 연구에서 여러 positional encodings가 단어 순서에 무감각하다는 사실에 대한 설명은 제대로 이루어지지 않았다. 
    2. 우리는 Bidirectional Masked Language Models (BERT-style)에서 positional encodings에 대한 체계적인 연구를 진행하여 (1) 두 가지 공통 속성, Locality와 Symmetry을 확인함으로써 PEs의 핵심 기능을 밝혀냈다. (2) 두 속성이 downstream tasks의 성능과 밀접한 상관관계를 가지고 있는 것을 보였다. (3) 우리는 현재의 PEs가 결과적으로 성능이 낮게 나오는 두 가지 새로운 probing tasks를 도입하여 현재 PEs의 약점을 양적 평가하였다. 
    3. 우리는 이러한 결과가 transformer 기반 언어 모델의 좀 더 나은 PEs 개발의 기초가 될 것이라고 믿고 있다.

###### Towards a Deep Understanding of Multilingual End-to-End Speech Translation (https://aclanthology.org/2023.findings-emnlp.956/)
- Anthology ID: 2023.findings-emnlp.956 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 22개 언어로 학습된 다중 언어 음성 번역 모델에서 학습된 표현을 평가하기 위해 Singular Value Canonical Correlation Analysis (SVCCA)를 사용한다. 이를 통해 다국어 음성 번역의 기능성과 다국어 신경망 기계 번역과의 관련성을 이해할 수 있다.
    2. 특정 언어의 학습 데이터가 제한적인 경우 다국어 음성 번역에서 언어적 유사성의 효과가 떨어진다.
    3. 제한된 데이터를 가진 저자원 언어와 언어적으로 연관된 고자원 언어를 결합하여 다국어 음성 번역의 효율적인 접근 방식을 제안한다.

###### An Empirical Investigation of Implicit and Explicit Knowledge-Enhanced Methods for Ad Hoc Dataset Retrieval (https://aclanthology.org/2023.findings-emnlp.957/)
- Anthology ID: 2023.findings-emnlp.957 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Ad hoc 데이터셋 검색은 웹에서 데이터를 찾는 중요한 방법이 되었으며, 해당 문제의 핵심은 데이터셋의 쿼리에 대한 관련성을 어떻게 측정할 것인가이다."
    2. 이 논문에서는 해당 특화된 작업에서 시용 가능한 지식 향상 검색 방법을 구현하고 평가하며, 명시적 및 암시적 지식 향상 검색 방법에 대해 다양한 설정에서 연구해 결과를 제시한다.
    3. 결과적으로 이 작업의 독특한 특성을 밝히며, 다양한 방법의 보간(interpolation)이 최상의 실천 방법이라는 것을 제안한다.

###### A Multi-Modal Multilingual Benchmark for Document Image Classification (https://aclanthology.org/2023.findings-emnlp.958/)
- Anthology ID: 2023.findings-emnlp.958 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 문서 이미지 분류는 양식, 이메일 등과 같은 문서의 내용과 구조를 이해하여 문서를 분류하는 것으로, 일반 텍스트 문서 분류와는 다르다고 한다.
    2. 기존 데이터셋의 한계를 극복하기 위해 새롭게 만들어진 WIKI-DOC와 MULTIEURLEX-DOC라는 다국어 데이터셋을 제시하고, 다양한 시각적인 문서 이해 혹은 Document AI 모델이 이 데이터셋 위에서 잘 동작하지 않는 한계를 밝힌다.
    3. 시험적인 실험 결과는 다국어 Document AI 모델의 특성상 매우 다른 언어 간의 cross-lingual transfer에 한계가 있음을 보여주고, 이러한 데이터셋과 결과는 Document AI 모델의 개선에 대해 미래 연구의 문을 열 수 있다.

###### Unnatural language processing: How do language models handle machine-generated prompts? (https://aclanthology.org/2023.findings-emnlp.959/)
- Anthology ID: 2023.findings-emnlp.959 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 수동으로 만든 의미론적이고 문법적으로 잘 구성된 프롬프트는 주로 단어 시퀀스에 기반한 자동 생성 프롬프트에 의해 능가된다.
    2. 기계가 생성한 프롬프트를 사용하여 모델이 자연어가 아닌 입력에 대해 어떻게 응답하는지 조사했다. 
    3. 기계 생성 프롬프트와 사람이 생성한 자연어 프롬프트에 대한 모델의 동작을 비교해 보여줬으며, 비슷한 출력을 만들더라도 각각 다른 응답 패턴을 가진다.

###### Investigating the Effectiveness of Multiple Expert Models Collaboration (https://aclanthology.org/2023.findings-emnlp.960/)
- Anthology ID: 2023.findings-emnlp.960 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 연구는 다양한 도메인에서 공정한 조건에서 여러 기계 번역(MT) 모델과 집계 방법의 효과를 조사하고, 다중 도메인 MT를 처리하는 방향을 탐구한다.
    2. 모든 도메인을 공동으로 훈련시키는 단일 모델 접근법과, 특정 집계 전략을 사용하는 다중 전문가 모델 접근법의 성능을 비교한다.
    3. 여러 도메인 전문가 모델을 조합하는 것이 모든 도메인 데이터를 훈련시킨 큰 모델보다 우수한 성능을 낼 수 있다는 것을 실험을 통해 입증한다.

###### Gradually Excavating External Knowledge for Implicit Complex Question Answering (https://aclanthology.org/2023.findings-emnlp.961/)
- Anthology ID: 2023.findings-emnlp.961 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 대형 언어 모델 (LLM)은 인간 수준의 능력과 막대한 잠재력으로 인해 큰 관심을 받고 있다. 그러나 오픈 도메인의 묵시적 질의응답 문제에 대해서는 LLM이 최적의 해결책이 아닐 수 있다. 
    2. 이 논문에서는 오픈 도메인 복잡한 질문 응답을 위한 점진적 지식 발굴 프레임워크를 제안한다. 
    3. LLM은 점진적으로 외부 정보를 습득하고 그에 따라 추론을 수행하여 최종 답을 찾아가는 방식으로 복잡한 질문에 대한 해결을 진행한다.

###### Evaluating Subjective Cognitive Appraisals of Emotions from Large Language Models (https://aclanthology.org/2023.findings-emnlp.962/)
- Anthology ID: 2023.findings-emnlp.962 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 본 연구는 CovidET-Appraisals라는 가장 포괄적인 데이터셋을 제시함으로써, 대화형 랭귀지 모델이 인지적 평가를 자동으로 평가하고 설명하는 능력을 평가하는 이상적인 테스트 베드를 제공한다.
    2. 최고의 모델이 성능이 좋음에도 불구하고 오픈소스 LLMs는 이 작업에서 부족한 것으로 나타났다.
    3. 많은 NLP 태스크에서 뛰어난 능력을 가진 랭귀지 모델의 미래 발전을 위한 새로운 도전 과제로 이어지는 결과를 보임.

###### Exploring Linguistic Properties of Monolingual BERTs with Typological Classification among Languages (https://aclanthology.org/2023.findings-emnlp.963/)
- Anthology ID: 2023.findings-emnlp.963 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. transformer 모델의 인상적인 성과로 인해 NLP 연구자들은 이 모델이 자연어의 기저 구조를 어떻게 표현하는지 조사하기 위해 깊이 파고들게 되었다. 
    2. 본 논문에서는 언어 간 유형론적 유사성을 사용하여 모노링구얼(transformer) 모델이 구조적 정보를 어떻게 인코딩하는지 관찰하는 새로운 접근법을 제안한다.
    3. 중앙 커널 얼라인먼트를 사용하여 weight matrices(가중치 행렬) 간 유사성을 측정하는 연구를 수행한 결과, 구문적 유형론적 유사성이 일반적으로 구문 인코딩을 담당하는 사전 학습된 BERT 레이어에 대한 가중치의 유사성과 일치한다는 것을 발견하였다.

###### Discourse Sense Flows: Modelling the Rhetorical Style of Documents across Various Domains (https://aclanthology.org/2023.findings-emnlp.964/)
- Anthology ID: 2023.findings-emnlp.964 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 얕은 담화파싱 연구에서는 특히 명시적 연결어와 대안적 어휘화 등 담화 관계 신호의 역할에 대해 새롭게 주목받고 있다.
    2. 우리는 먼저 Penn Discourse Treebank v3 말뭉치를 기반으로 명시적 연결어와 대안적 어휘화의 신호를 추출하고 의미를 분류하는 새로운 모델을 개발한다.
    3. 그 후 이 모델을 다양한 원시 말뭉치에 적용하고, PDTB의 의미에 의한 담론 스타일을 문서의 연결관계의 선형 순서로 모델링하는 'discourse sense flows'를 소개한다.

###### HierarchicalContrast: A Coarse-to-Fine Contrastive Learning Framework for Cross-Domain Zero-Shot Slot Filling (https://aclanthology.org/2023.findings-emnlp.965/)
- Anthology ID: 2023.findings-emnlp.965 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. task-oriented 대화 시나리오에서, 교차 도메인 제로샷 슬롯 채우기는 주요한 역할을 한다. 기존의 zero-shot slot filling 방법들은 타겟 도메인에서의 일반화 능력이 제한되어 있다. 
    2. 이 논문에서는 HiCL이라는 새로운 위계적 대조학습 프레임워크를 제안하여, 훈련 단계에서 보지 못한 슬롯 타입에도 일반화할 수 있도록 한다. 
    3. 강건한 성능을 갖는 이 방법을 사용하여 제로샷 슬롯 채우기를 수행하면 기존의 방법을 능가하는 성능을 보여줄 수 있다.

###### A Confederacy of Models: a Comprehensive Evaluation of LLMs on Creative Writing (https://aclanthology.org/2023.findings-emnlp.966/)
- Anthology ID: 2023.findings-emnlp.966 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 본 연구에서는 상상력, 일관성, 스타일을 요구하는 어려운 상황에서 최신 언어 모델 (LLM)들을 평가하였다. 결과적으로, 일부 상용 LLM은 대다수의 측면에서 우리 작가들과 비슷한 성능을 나타내었다. 
    2. 그러나 오픈소스 LLM은 이와 비교하여 뒤처지는 경향을 보였다. 
    3. 우리는 창의성에서 인간이 앞세워지고, 유머 측면에서는 일부 LLM만 인간과 비슷한 성능을 나타내는 바이너리(이분적) 구분을 볼 수 있다고 발견하였다.

###### 1-PAGER: One Pass Answer Generation and Evidence Retrieval (https://aclanthology.org/2023.findings-emnlp.967/)
- Anthology ID: 2023.findings-emnlp.967 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 1-Pager는 Transformer 기반 모델과 decoding 과정을 사용하여 질문에 답변하고 증거를 검색하는 첫 번째 시스템으로, 'retrieve-and-read' 대안과 비교해 검색 및 답변 정확성 측면에서 경쟁력을 보인다.
    2. 1-Pager는 증거 코퍼스에 기반하여 예측을 내리는 것으로, '닫힌 책' 형태의 질문 응답 모델보다 성능이 우수하다.
    3. 1-Pager는 더 많은 문서를 읽은 후에 답변을 생성하는 더 비용이 많이 드는 시스템과는 아직 동등한 성능은 아니지만, 이는 NLP에서 우월한 sequence-to-sequence 패러다임에 검색을 접목하여 발전시키는 중요한 단계를 제공한다는 주장이다. 또한, 코퍼스를 파티션하기 위해 사용된 검색 경로들은 읽고 이해하기 쉬우며, 해석 가능한 신경 검색에 대한 발전 방향을 제시한다.

###### Context-faithful Prompting for Large Language Models (https://aclanthology.org/2023.findings-emnlp.968/)
- Anthology ID: 2023.findings-emnlp.968 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델(Large Language Models, LLMs)은 세계적 사실에 대한 지식을 효율적으로 인코딩할 수 있으나, 맥락에 민감한 NLP 태스크에서는 맥락에 관련된 단서를 간과하여 잘못된 예측을 할 수 있다. 
    2. 이 논문에서는 LLMs의 맥락적 충실성을 평가하고 향상시키기 위해 주어진 조건에 맞는 질문 방식을 사용하여 최대한 효과적인 방법을 찾아냈다. 
    3. 실험 결과, 해당 방식을 적용하면 기존 모델에 비해 더 맥락에 충실한 예측이 가능하다는 것을 확인할 수 있었다.

###### InfoCL: Alleviating Catastrophic Forgetting in Continual Text Classification from An Information Theoretic Perspective (https://aclanthology.org/2023.findings-emnlp.969/)
- Anthology ID: 2023.findings-emnlp.969 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 지속적 학습(Continual learning)은 기존의 과제를 잊어버리지 않는 동안 새로운 지식을 지속적으로 배우는 것을 목표로 한다. 
    2. 이 논문에서는 텍스트 분류 과제에서 감소하는 성능 문제를 해결하기 위해 정보 병목 현상의 압축 효과를 다루고, 플레이백 기반의 새로운 지속적 텍스트 분류 방법을 제안한다. 
    3. 실험 결과, InfoCL은 잊음 문제를 효과적으로 완화하고 세 가지 텍스트 분류 과제에서 최고의 성능을 달성한다.

###### Sparse Frame Grouping Network with Action Centered for Untrimmed Video Paragraph Captioning (https://aclanthology.org/2023.findings-emnlp.970/)
- Anthology ID: 2023.findings-emnlp.970 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문은 이벤트 주석 없는 비트림된 동영상에 대한 문단 캡션을 생성하는 것이 동시에 정확성을 높이고 반복을 최소화하는 것은 어렵다는 도전에 대해 다루고 있다. 
    2. 이를 해결하기 위해, 이 논문은 Sparse Frame Grouping (SFG)이란 모듈을 제안하였다. 이 모듈은 전체 비디오에 대한 행동 정보로부터 이벤트 정보를 동적으로 그룹화하고 사전 정의된 클립 내에서 중복된 프레임을 제외한다.
    3. 실험 결과, SFG는 ActivityNet Captions와 YouCook2 데이터셋에서 모든 지표에서 최고 수준의 성능을 보여주고 있다.

###### Unsupervised Binary Code Translation with Application to Code Clone Detection and Vulnerability Discovery (https://aclanthology.org/2023.findings-emnlp.971/)
- Anthology ID: 2023.findings-emnlp.971 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 바이너리 코드 분석은 소프트웨어 보안 연구 분야에서 엄청난 중요성을 가지고 있다. 그러나 다양한 Instruction Set Architecture (ISA)에서 소프트웨어가 빈번하게 컴파일되는 경우, ISA를 건너뛴 바이너리 코드 분석은 신생 문제가 되었다. 본 논문에서는 NMT (Neural Machine Translation)의 개념과 기법을 바이너리 코드 분석에 적용하여 데이터 부족 문제를 해결하고 교차 아키텍처 바이너리 코드 분석을 용이하게 한다.
    2. 우리는 저 자원 ISA에서 효과적으로 교차 아키텍처 바이너리 코드 분석을 할 수 있도록, 저 자원 ISA의 바이너리를 고 자원 ISA (예: x86)로 번역하여 테스트한다. 이를 위해 고 자원 ISA에서 훈련된 모델을 사용하는데, 우리의 모델인 UNSUPERBINTRANS를 구현하고 그 성능을 평가하였다.
    3. 우리는 코드 유사성 감지와 취약점 탐지 두 가지 하위 태스크에서 실험을 진행하였고, 양쪽 모두에서 높은 정확도를 달성하였다.

###### Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering (https://aclanthology.org/2023.findings-emnlp.972/)
- Anthology ID: 2023.findings-emnlp.972 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문은 zero-shot long document evidence retrieval 작업에 큰 언어 모델(Large Language Models, LLMs)이 얼마나 적용 가능한지를 평가하는 것을 목표로 한다. 그러나 현재 LLMs는 제한된 문맥 길이만을 입력으로 받기 때문에 문서 청크를 입력으로 제공하는 것은 글로벌 문맥을 간과하고 세그먼트 간 의존성을 제대로 캡처하지 못할 수도 있다.
    2. 따라서 우리는 독특한 문서 구조를 활용하는 기술들을 제안하여 이러한 도전을 해결한다. 이 구조를 활용하여 문서를 간결하게 표현하고 서로 다른 부분 간의 관계를 더 포괄적으로 이해하고 분석할 수 있다. 
    3. 전체 토큰의 26%만을 처리하면서 최고의 방법과 비교하여 99.6%의 성능을 유지할 수 있음을 보여주고, gold evidence 사용을 통한 zero-shot 성능에 근접한 복잡한 multi-hop 질문 응답에서도 우리의 접근 방식이 어떻게 최상의 zero-shot 성능을 달성할 수 있는지 설명한다.

###### Emergent Inabilities? Inverse Scaling Over the Course of Pretraining (https://aclanthology.org/2023.findings-emnlp.973/)
- Anthology ID: 2023.findings-emnlp.973 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 연구는 언어 모델의 성능이 학습 과정 동안 감소할 수 있다는 것을 조사하여 태스크별로 성능이 감소하는 경우가 있는지 알아보았다.
    2. Pythia 12B 모델의 경우, 학습 과정에서 성능이 감소하는 태스크 8개를 발견했다. 그 중 5개 태스크의 경우, 더 큰 언어 모델일수록 성능 감소가 더 크게 나타났으며, 전반적으로는 성능이 향상되더라도 성능 감소가 지속되는 것을 보였다.
    3. 이는 모델이 추가 데이터로 학습될 때 모든 관련 벤치마크에서 성능을 테스트하는 것의 중요성을 강조하며, 전반적인 성능이 향상되더라도 주의가 필요하다.

###### Alignment Precedes Fusion: Open-Vocabulary Named Entity Recognition as Context-Type Semantic Matching (https://aclanthology.org/2023.findings-emnlp.974/)
- Anthology ID: 2023.findings-emnlp.974 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이름 있는 entity 인식 모델들의 개발에서 이루어진 큰 성과에도 불구하고, 새로운 유형으로의 확장은 여전히 현실 세계에서 어렵다. 
    2. 지속적인 학습 및 zero-shot 학습 방법들은 새로운 유형을 처리하기 위해 인간 지도보다 적은 자동 지도를 사용하여 시도되었으나, 지도 학습 방법에 비해 성공적으로 적용되지 못했다.
    3. 이 논문에서는 인간 수준의 능력을 모방하기 위해 open-vocabulary named entity recognition(OVNER)이라는 더 현실적이고 도전적인 상황을 고려한다.
    
    (논문 초록을 토대로 한 번더 요약하자면) 
    산업 현장에서 개발된 이름 entity 인식 모델로도 새로운 유형의 entity에 대한 대응이 어려워 여러가지 학습 방법론을 실험하였으나, 지도 학습 방식에 비해 성과가 좋지 않았다. 이 논문은 그와 같은 개선을 위해 실제 사람의 능력을 모방하기 위한 상황을 가정하였으며 이를 위한 메커니즘을 제안한다.

###### Representation Projection Invariance Mitigates Representation Collapse (https://aclanthology.org/2023.findings-emnlp.975/)
- Anthology ID: 2023.findings-emnlp.975 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사전 학습된 언어 모델에서 학습된 문맥화된 표현을 미세 조정하는 것은 NLP에서 흔히 사용되는 방법이지만, 이 과정에서 representation degradation 문제가 발생할 수 있다. 본 논문에서는 Representation Projection Invariance (REPINA)라는 새로운 정규화 방법을 제안하여 미세 조정하는 동안 표현의 정보 내용을 유지하고 representation collapse를 감소시킨다.
    2. 실험 결과, REPINA는 다른 기준선과 비교했을 때 대부분의 과제에서 (13개 중 10개) 가장 우수한 성능을 보였으며, 분야 내 성능 뿐만 아니라 분야 외 성능도 향상시켰다. 
    3. 또한, REPINA는 소량 데이터 및 레이블 변동에 대해 강건하며, representation collapse를 측정하기 위한 여러 메트릭을 제안하였으며, 이를 통해 본 논문의 방법이 representation collapse를 완화하는 데 효과적임을 입증하였다.

###### Tunable Soft Prompts are Messengers in Federated Learning (https://aclanthology.org/2023.findings-emnlp.976/)
- Anthology ID: 2023.findings-emnlp.976 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Federated Learning(FL)은 분산된 데이터 소스를 사용하여 협업적으로 기계 학습 모델을 교육하는 것을 가능하게 한다. 하지만 FL에서 모델 개인 정보 보호가 부족해지는 문제가 발생하며, 특허 상표의 대형 언어 모델을 기반으로 모델을 연방 수정하고 싶을 때 특히 도전이 된다.
    2. 이 연구에서는 튜닝 가능한 소프트 프롬프트를 통해 참가자들 간의 정보 교환을 수행하는 새로운 FL 훈련 접근법을 제안한다. 이러한 소프트 프롬프트는 서버와 클라이언트 간에 업데이트되고 전달되는데, 글로벌 모델 파라미터의 역할을 가지며 로컬 데이터와 글로벌 모델에서 유용한 지식을 전달하는 메신저 역할을 한다.
    3. 제안된 접근 방식은 글로벌 모델이 공유되지 않으며 로컬 훈련이 글로벌 모델보다 적은 파라미터를 가진 보조 모델을 기반으로 진행되므로, FL에서 통신 및 계산 비용을 줄이면서 글로벌 모델을 보호한다. 실험적 결과는 제안된 접근 방식의 효과를 여러 기준과 비교하여 보여준다.

###### Style-Aware Radiology Report Generation with RadGraph and Few-Shot Prompting (https://aclanthology.org/2023.findings-emnlp.977/)
- Anthology ID: 2023.findings-emnlp.977 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 의료 이미지로부터 자동으로 생성된 보고서는 영상의과학자들의 업무 효율성을 향상시킬 수 있으나, 보고서의 내용 (영상 속 사항 등)을 포맷과 단어의 선택과 함께 생성하는 기존 방식은 잘못된 보고서를 생성할 수 있다.
    2. 본 연구에서는 라디오로지 보고서 생성을 위해 두 단계의 접근법을 제안한다. 먼저 이미지로부터 내용을 추출한 다음 추출된 내용을 특정 영상의과학자의 스타일에 맞춰 보고서로 변환한다.
    3. 실험결과, 우리의 방법은 유용한 성능 향상을 이끌어냄을 보여주었으며, 임상평가자들에게서 얻은 결과는 AI가 생성한 보고서가 몇 가지 예시를 사용하여 개별 영상의과학자의 스타일에 맞는 맞춤형 보고서로 전환이 가능하다는 것을 보여준다.

###### Incorporating Probing Signals into Multimodal Machine Translation via Visual Question-Answering Pairs (https://aclanthology.org/2023.findings-emnlp.978/)
- Anthology ID: 2023.findings-emnlp.978 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문은 문장이 완전한 경우에 MMT 시스템이 이미지 정보에 대한 감성이 감소한다는 일반적인 이해를 자세히 연구하였다. 이 현상은 이미지 정보의 중복이 아닌 교차 모달 상호작용 부족에 기인한다고 주장한다.
    2. 소스 텍스트에서 VQA 스타일의 병렬 한영 쌍을 생성하여 더 강력한 교차 모달 상호작용을 유발하기 위한 새로운 접근 방식을 제안한다.
    3. Multi30K-VQA 데이터셋을 만들기 위해 MMT에서 VQA 스타일 데이터로 프로빙(probing) 신호를 명시적으로 모델링하고, 이를 MMT 훈련 과정에 통합하는 MMT-VQA 다중 작업 학습 프레임워크를 도입한다.

###### GenKIE: Robust Generative Multimodal Document Key Information Extraction (https://aclanthology.org/2023.findings-emnlp.979/)
- Anthology ID: 2023.findings-emnlp.979 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 스캔된 문서로부터 중요한 정보를 추출하는 Key information extraction(KIE)은 다양한 분야에서 응용 가능성으로 인해 점점 더 주목을 받고 있다. 
    2. 이 논문에서는 OCR 오류를 다루거나 번거롭게 토큰 수준의 레이블링을 필요로 하지 않는 새로운 생성 모델인 GenKIE를 제안한다. 
    3. GenKIE는 시각, 레이아웃 및 텍스트 기능을 포함하여 여러 가지 입력 기능을 임베딩하는 다중모달 인코더와 원하는 결과를 생성하는 디코더를 사용하는 시퀀스-시퀀스 다중모달 생성 모델이다.

###### Improving Multimodal Sentiment Analysis: Supervised Angular margin-based Contrastive Learning for Enhanced Fusion Representation (https://aclanthology.org/2023.findings-emnlp.980/)
- Anthology ID: 2023.findings-emnlp.980 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 복합감성분석에서 다중 형상(fusion representation) 품질이 모델의 효과에 크게 의존하며, 이는 여러 modal의 표현이 예측 벡터에 편향을 줌으로써 발생한다. 
    2. 이러한 한계를 극복하기 위해 우리는 "Supervised Angular-based Contrastive Learning for Multimodal Sentiment Analysis"라는 프레임워크를 소개한다. 
    3. 이 프레임워크는 복합감성분석에서 다중 모달 표현의 식별력과 일반성을 향상시키고, 퓨전 벡터의 편향을 극복하는데 효과적임을 실험적으로 입증하였다.

###### Efficient Multilingual Language Model Compression through Vocabulary Trimming (https://aclanthology.org/2023.findings-emnlp.981/)
- Anthology ID: 2023.findings-emnlp.981 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다국어 언어 모델에서 모델 파라미터가 크기 때문에 이 논문에서는 대상 언어에 대한 언어별 어휘만을 사용하여 여전히 좋은 성능을 유지하는 어휘 트리밍 (VT) 방법을 제안한다.
    2. VT는 기존 다국어 언어 모델의 어휘를 축소시켜 원래 모델로부터 어떤 언어에 대해서도 작동할 수 있다.
    3. 실험 결과, VT는 원래의 다국어 언어 모델과 비교해 크기가 상당히 작으면서도 성능을 유지할 수 있었으며, 특히 특정 언어에 대해 모델을 재학습할 필요 없이 작업과 관련된 언어의 특징을 유지하는 데 도움이 될 수 있다.

###### ICU: Conquering Language Barriers in Vision-and-Language Modeling by Dividing the Tasks into Image Captioning and Language Understanding (https://aclanthology.org/2023.findings-emnlp.982/)
- Anthology ID: 2023.findings-emnlp.982 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다국어 이미지 캡션 생성을 위한 ICU (Image Caption Understanding)은 V&L 모델이 영어로 이미지에 대한 캡션을 생성하고, 이를 다국어 언어 모델(mLM)에 입력하여 다국어 언어 이해를 수행하는 두 단계로 V&L 작업을 분할하여 언어 장벽을 극복한다. 
    2. ICU는 다국어 텍스트 데이터가 풍부하고 품질이 높은 특징을 활용하여 V&L 모델에서 다국어 처리의 부담을 줄인다. 
    3. IGLUE 벤치마크에서 9개 언어로 진행한 실험 결과, ICU는 5개 언어에서 새로운 최고 성능을 달성하고, 나머지 언어에서는 비교 가능한 결과를 나타냈다.

###### GTA: Gated Toxicity Avoidance for LM Performance Preservation (https://aclanthology.org/2023.findings-emnlp.983/)
- Anthology ID: 2023.findings-emnlp.983 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. GPT-4와 같은 언어 생성 모델의 발전은 다양한 NLP 생성 태스크에서 놀라운 결과를 보여주었지만, 인종이나 성에 관련된 모욕적인 단어를 생성할 수 있기 때문에 피해 단어의 발생을 완화하기 위해 다양한 Controllable Text Generation (CTG) 방법들이 제안되었다.
    2. 그러나 기존의 CTG 방법들은 독성을 줄일뿐만 아니라 주제 일관성, 문법, 난해도 등 언어 모델의 생성 성능에도 부정적인 영향을 미친다.
    3. 이 논문은 이전 방법들의 한계를 탐구하고, 어떤 CTG 방법에도 적용할 수 있는 간단한 Gated Toxicity Avoidance (GTA)로 해결책을 제시한다. 제안된 GTA의 효과를 다양한 데이터셋과 최신 CTG 방법과 비교함으로써 검증하였으며, 결과는 독성 감소 수준은 유지하면서 언어 모델의 생성 성능을 보존하는 것을 보여준다.

###### LMGQS: A Large-scale Dataset for Query-focused Summarization (https://aclanthology.org/2023.findings-emnlp.984/)
- Anthology ID: 2023.findings-emnlp.984 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Query-focused summarization (QFS)은 주어진 질문에 직접 답변하거나 관련이 있는 요약문을 입력 문서에서 추출하거나 생성하는 작업이다. 그러나 문서, 질문, 요약으로 이루어진 대규모 데이터셋의 부족으로 모델 개발이 어려웠다고 한다."
    2. 저자들은 "일반적인 summarization 어노테이션에는 각각의 요약 문장마다 숨겨진 질문이 존재하며, 이를 복원하기 위해 대규모 사전 훈련된 언어 모델을 활용한다"라고 가설을 세우고, 이를 통해 네 가지 일반적인 요약 벤치마크를 QFS 벤치마크 데이터셋인 LMGQS로 변환한다.
    3. LMGQS에서 언어 모델을 파인튜닝함으로써 기존 QFS 벤치마크에서 zero-shot과 지도 학습 기반의 최고 성능을 달성하며, LMGQS의 고품질과 다양성을 입증한다.

###### ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models (https://aclanthology.org/2023.findings-emnlp.985/)
- Anthology ID: 2023.findings-emnlp.985 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델 (LLM)은 다양한 평가 벤치마크에서 우수한 성능을 보여주었지만, 특정 지식과 다중 점프 추론을 필요로 하는 복잡한 추론 작업에서 여전히 어려움을 겪는다.
    2. ChatCoT는 대화 기반 LLM (예 : ChatGPT)을 위한 도구보강된 chain-of-thought 추론 프레임워크로서, 여러 번의 대화로 구성된 추론을 모델링하여 도구를 보다 자연스러운 방식으로 활용한다.
    3. ChatCoT는 대화 기반 LLM의 다중 턴 대화 능력을 효과적으로 활용하며, 연속적인 단계적 도구보강 추론을 수행하기 위해 도구 사용과 추론 과정을 통합하는 방법을 제안한다. 최근 연구와 비교해 7.9% 상대적 개선을 이루어 복잡한 추론 작업에서의 효과를 입증하였다.

###### Non-Autoregressive Document-Level Machine Translation (https://aclanthology.org/2023.findings-emnlp.986/)
- Anthology ID: 2023.findings-emnlp.986 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근에 제안된 non-autoregressive translation (NAT) 모델들은 문장 수준의 기계 번역에서 auto-regressive translation (AT) 모델들에 비해 비슷한 성능과 높은 속도를 보이지만, 문서 수준의 기계 번역에서의 능력은 아직 알려지지 않아서 실제 상황에서의 활용이 어렵다.
    2. 본 논문에서는 문서 수준의 기계 번역에서 일반적인 NAT 모델들을 철저히 조사하고, 소스와 타겟 사이의 문장 정렬에 대해 간단하지만 효과적인 설계를 제안한다.
    3. 실험 결과, NAT 모델들은 문서에서 높은 가속화를 달성하며, 문장 정렬은 그들의 성능을 크게 향상시킨다. 그러나 현재 NAT 모델들은 여전히 AT 모델들에 비해 상당한 성능 차이가 있다.

###### Exploring the Effectiveness of Multi-Lingual Commonsense Knowledge-Aware Open-Domain Dialogue Response Generation (https://aclanthology.org/2023.findings-emnlp.987/)
- Anthology ID: 2023.findings-emnlp.987 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존 연구들은 대화 생성 시 일상적 상식 지식을 활용하여 정보성을 높이고 환상적인 내용을 줄이는 것에 대한 유망한 결과를 보여주었으나, 대화 맥락과 언어가 일관된 단일 언어의 상식 지식만 사용할 수 있다는 제한점이 있다.
    2. 이 논문에서는 다른 언어의 상식 지식을 활용하여 현재의 대화 생성을 향상시키기 위해 Multi-Lingual Commonsense Knowledge-Aware Response Generation (MCKRG)라는 새로운 과제를 제안한다.
    3. MCK-Dialog라는 7개 언어로 구성된 데이터셋을 생성하고, 제안된 MCK-T5 모델을 사용하여 다국적 상식 지식의 효과를 검증하였다. 풍부한 실험 결과는 다국적 상식 지식을 효과적으로 활용할 수 있는 높은 자원과 낮은 자원 언어에서의 큰 잠재력을 보여준다. 이 연구는 다국적 상식 지식을 활용한 대화 생성에 대한 첫 번째 시도이다.

###### Mixture of Soft Prompts for Controllable Data Generation (https://aclanthology.org/2023.findings-emnlp.988/)
- Anthology ID: 2023.findings-emnlp.988 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델(Large language models, LLMs)은 자연어 패턴을 따를 때 유창한 텍스트를 효과적으로 생성하지만, 구조화된 예측 작업에서는 출력 형식이 제한되어 있어 이러한 제한을 고려하지 않고 훈련된 모델들도 고민하는 문제가 발생한다.
    2. 이 논문에서는 LLM을 직접 예측하는 대신 데이터 augmentation을 위한 도구로 활용하여 문제의 접근 방식을 바꿨다. 제안된 Mixture of Soft Prompts(MSP)은 제어된 방식으로 다중 속성 데이터를 생성하기 위한 매개변수 효율적인 절차로서 작동한다.
    3. 실험을 통해 MSP가 다양하고 자연스러운 텍스트를 생성하면서도 레이블 의미를 보존한다는 것을 확인할 수 있었고, 강력한 베이스라인과 비교했을 때 세 가지 벤치마크에서 최고 성능을 달성한다. 이러한 방법은 복잡한 예측 작업에 LLM을 적용하기 위한 대체적인 데이터 중심 접근 방식을 제공한다.

###### A Boundary Offset Prediction Network for Named Entity Recognition (https://aclanthology.org/2023.findings-emnlp.989/)
- Anthology ID: 2023.findings-emnlp.989 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 명명된 entity recognition (NER)은 텍스트에서 명명된 entity를 식별하고 분류하는 자연 언어 처리의 기본적인 작업이다. 하지만 NER에 대한 span 기반 방법은 일반적으로 텍스트 span에 entity 타입을 할당하며, 결과적으로 불균형한 샘플 공간을 가지며 non-entity와 entity span 간의 연결을 무시한다.
    2. 이 문제를 해결하기 위해, 우리는 경계 간격에 대한 예측 네트워크인 BOPN(Boundary Offset Prediction Network)라는 NER를 위한 새로운 접근 방식을 제안한다. BOPN은 non-entity와 entity span 간의 연결을 설정하기 위해 경계 간격의 안내 semantics를 활용하여, non-entity span이 entity 탐지에 추가적인 양성 샘플로 작동할 수 있게 한다.
    3. 게다가, 우리의 방법은 entity 타입과 span 표현을 통합하여 entity 타입을 검출 대상으로 사용하는 대신 타입 인식 경계 간격을 생성한다. 우리는 여덟 가지의 널리 사용되는 NER 데이터셋에서 실험을 수행하고, 결과는 우리의 제안된 BOPN이 이전 최첨단 방법보다 뛰어난 성능을 보여준다.

###### Prefix-Tuning Based Unsupervised Text Style Transfer (https://aclanthology.org/2023.findings-emnlp.990/)
- Anthology ID: 2023.findings-emnlp.990 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 비지도 텍스트 스타일 변환은 병렬 데이터를 사용하지 않고 입력 문장의 스타일을 변경하면서 내용을 보존하는 생성 모델을 훈련하는 것을 목표로 한다. 이 논문에서는 능력있는 사전 훈련된 대형 언어 모델을 활용하여 비지도 텍스트 스타일 변환에 대한 새로운 prefix-tuning 기반 방법을 제안한다.
    2. 우리는 공유 프리픽스(shared prefix), 스타일 프리픽스(style prefix), 내용 프리픽스(content prefix)의 세 가지 다른 종류의 프리픽스를 구성하여 각각 과제 특정 정보, 대상 스타일 및 입력 문장의 내용 정보를 인코딩한다.
    3. 이 논문에서 제안하는 방법은 이전 작업에서 사용된 임베딩보다 더 풍부한 정보를 제공할 수 있는 프리픽스를 사용하며, 재귀적인 방식으로 언어 모델을 사용하여 스타일 변환 과정에서 입력 문장과 GPT-2간의 상호작용을 더욱 효과적으로 처리한다. 이를 통해 우리의 방법은 유명한 데이터셋에서 상태-of-the-art 기준을 능가하는 결과를 보여주었다.

###### Evaluating and Enhancing the Robustness of Code Pre-trained Models through Structure-Aware Adversarial Samples Generation (https://aclanthology.org/2023.findings-emnlp.991/)
- Anthology ID: 2023.findings-emnlp.991 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. CodePTMs (Code Pre-Trained Models)의 robustness를 평가하기 위해 이전의 방법들은 텍스트적인 측면을 중점으로하지만, 코드의 구조를 고려하지 않았다. 
    2. 이 논문에서는 코드의 내재적인 구조를 기반으로 한 새로운 robustness 평가 방법을 제안한다. 
    3. 코드의 식별자 토큰 및 서브트리 구조에 대한 적대적 공격을 수행하고, 동등한 정보를 가진 입력 샘플에 대한 모델의 민감도도 탐색하여 평가한다.

###### Annotation Sensitivity: Training Data Collection Methods Affect Model Performance (https://aclanthology.org/2023.findings-emnlp.992/)
- Anthology ID: 2023.findings-emnlp.992 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 학습 데이터가 인간 주석가로부터 수집되는 경우 주석기 계약의 디자인, 주석기에 제공되는 명령, 주석기의 특성 및 상호작용이 학습 데이터에 영향을 미칠 수 있다. 
    2. 본 연구는 주석 도구를 작성할 때 디자인 선택이 결과 주석에 훈련된 모델에도 영향을 미친다는 것을 보여준다.
    3. 우리는 주석 데이터 수집 방법이 주석 자체와 하류 모델 성능 및 예측에 미치는 영향을 가리키는 "annotation sensitivity"라는 용어를 소개한다.

###### Qualitative Code Suggestion: A Human-Centric Approach to Qualitative Coding (https://aclanthology.org/2023.findings-emnlp.993/)
- Anthology ID: 2023.findings-emnlp.993 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Qualitative coding"은 연구자가 어떤 텍스트 말뭉치를 읽고 구절에 서술적 레이블 또는 질적 코드를 할당하는 콘텐츠 분석 방법이다. 이 연구는 기존의 NLP 기술을 사용하여 질적 코드 작성자를 돕는 데 큰 도움이 될 수 있다고 본다.
    2. 기존 시도들은 질적 코딩을 완전히 자동화 가능한 분류 문제로 설정하지만, 이 논문에서는 질적 코드 제안(QCS) 작업을 협력적인 방식으로 정의한다.
    3. QCS는 이전에 할당된 질적 코드의 순위가 지정된 구절로부터 추천된다. 또한 QCS는 사용자 중심이며, 구절의 주석 순서, 희귀 코드의 중요성 및 코드 작성자 간 주석 스타일의 차이와 같은 질적 코딩의 이전에 무시된 특성을 통합한다.

###### D2TV: Dual Knowledge Distillation and Target-oriented Vision Modeling for Many-to-Many Multimodal Summarization (https://aclanthology.org/2023.findings-emnlp.994/)
- Anthology ID: 2023.findings-emnlp.994 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. M3S (Many-to-many multimodal summarization) 작업은 어떤 언어로든 문서 입력과 해당 이미지 시퀀스로 요약을 생성하는 작업이다. 기존의 MMS (multimodal monolingual summarization)나 MXLS (multimodal cross-lingual summarization) 작업과 다르게 M3S 작업에 대한 연구는 적은 편이다.
    2. 이 논문에서는 M3S 작업에 대한 일반적이고 실용적인 프레임워크를 제안한다. 빼려지지 않은 시각적 정보를 버리기 위해 target-oriented contrastive objective를 사용하고, dual knowledge distillation 방법을 사용하여 MMS와 MXLS 간의 지식을 상호 전달하고 서로 상호 작용할 수 있도록 보장한다.
    3. 많은 실험을 통해 제안된 접근 방식의 효과를 보여주며, 또한 44개 언어의 많은-많은 multimodal summarization 데이터셋인 lmttM3Sum을 제공하여 향후 연구에 도움을 준다.

###### Improving Input-label Mapping with Demonstration Replay for In-context Learning (https://aclanthology.org/2023.findings-emnlp.995/)
- Anthology ID: 2023.findings-emnlp.995 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "In-context learning (ICL)은 다운스트림 NLP 태스크의 모델 이해력을 향상시키기 위해 모델 파라미터를 직접 조정하지 않고 입력-라벨 증명을 입력에 추가하는 방식으로, 대규모 언어 모델의 적용 능력 중 하나이다."
    2. "ICL은 대규모 언어 모델의 강력한 언어 모델링 능력으로 인해 효과적이며, 입력과 라벨 사이의 매핑을 학습할 수 있다. 그러나 ICL의 인과성 특성으로 인해 언어 모델링은 역방향만 고려하며, 전체 입력-라벨 정보를 포착하지 못하고 모델의 성능을 제한한다."
    3. "이 논문에서는 Repeated Demonstration with Sliding Causal Attention(RdSca)라는 독특한 ICL 방법을 제안한다. RdSca는 나중에 나오는 증명을 중복시켜 앞쪽에 연결함으로써 모델이 인과적 제약에도 불구하고 나중 정보를 '관찰'할 수 있게 한다. 또한 정보 노출을 피하기 위해 인과적 어텐션을 맞춤화하는 슬라이딩 인과주의도 소개한다. 실험 결과는 우리의 방법이 ICL 증명에서 입력-라벨 매핑을 크게 개선한다는 것을 보여주었다. 또한 학습 없이 인과주의 어텐션을 사용자 맞춤화하는 방법에 대한 깊이있는 분석도 수행하였다."

###### Enhancing Text-to-SQL Capabilities of Large Language Models: A Study on Prompt Design Strategies (https://aclanthology.org/2023.findings-emnlp.996/)
- Anthology ID: 2023.findings-emnlp.996 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 인공지능 (AI) 모델들은 대규모 언어 모델을 활용하여 일부 예시나 과제별 지시사항으로 보완된 문맥을 기반으로 예측하는 "In-context learning (ICL)"이라는 새로운 접근 방법이 자연어처리 태스크에 등장하였다.
    2. 이 연구에서는 이 방법을 구조화된 지식 소스를 활용하는 질의응답 (Question Answering) 태스크로 확장하고, LLM을 활용한 Text-to-SQL 시스템을 향상시키기 위한 다양한 프롬프트 디자인 전략을 탐구한다.
    3. 연구 결과, 다양성과 유사성을 모두 고려하는 예시 선택 방법은 성능을 향상시키며, 또한 데이터베이스 관련 지식의 보강이 LLM에 이익을 준다는 것을 보여준다. 따라서 이 방법은 Text-to-SQL 태스크에 LLM을 적용하는데 효과적이며, 성공적인 전략의 요인을 분석한다.

###### Cross-lingual Open-Retrieval Question Answering for African Languages (https://aclanthology.org/2023.findings-emnlp.997/)
- Anthology ID: 2023.findings-emnlp.997 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 아프리카 언어들은 디지털로 이용 가능한 내용이 매우 적어, 질문 답변 시스템이 사용자의 정보 요구를 충족시키는 것이 어렵다. 그래서 우리는 크로스-언어 개방형 검색 기반 질문 답변 (Cross-lingual open-retrieval question answering, XOR QA) 시스템을 통해 이 공백을 채울 수 있는 방법을 제공한다.
    2. 우리는 아프리카 언어에 초점을 맞춘 최초의 크로스-언어 QA 데이터셋인 Our Dataset을 만들었다. Our Dataset은 10개의 아프리카 언어를 대상으로 12,000개 이상의 XOR QA 예시를 포함하고 있다.
    3. 이전 데이터셋들은 대상 언어의 정보 커버리지를 보완하는 방식으로 주로 사용되었다. 하지만 Our Dataset은 크로스-언어 답변이 높은 커버리지의 유일한 소스인 언어에 초점을 맞춘다. 이를 통해 우리는 아프리카 언어가 XOR QA의 가장 중요하고 현실적인 사용 사례 중 하나라고 주장한다.

###### Viewing Knowledge Transfer in Multilingual Machine Translation Through a Representational Lens (https://aclanthology.org/2023.findings-emnlp.998/)
- Anthology ID: 2023.findings-emnlp.998 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다국어 신경 기계 번역에서는 번역 품질만으로는 지식 전달을 측정하는 데 충분한 지표가 되지 않는다는 주장이 있다. 
    2. 우리는 표현적 전달 잠재력(RTP)을 도입하여 언어 간의 표현적 유사성을 측정한다. RTP는 긍정적 전달과 부정적 전달(간섭) 모두를 측정할 수 있으며, 번역 품질의 변화와 강한 상관관계가 있으며, 이는 전달이 발생한다는 것을 보여준다. 
    3. 또한, 전달에 관련된 데이터 및 언어 특성을 조사하였고, 다중 병렬 중복(multi-parallel overlap)이 중요한 특징임을 발견하였다. 이를 바탕으로, 우리는 다중 병렬 데이터를 활용하여 언어 간 불변성을 장려하는 보조 유사도 손실(auxiliary similarity loss)을 사용하는 새로운 훈련 방법을 개발하였다. 이 방법은 다양한 데이터 및 모델 설정에서 저자원 언어의 번역 품질을 향상시킨다.

###### Aligning Predictive Uncertainty with Clarification Questions in Grounded Dialog (https://aclanthology.org/2023.findings-emnlp.999/)
- Anthology ID: 2023.findings-emnlp.999 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 효과적인 협업을 위해서는 명확하지 않은 부분을 물어볼 필요가 있다. 이 논문에서는 예측 불확실성을 기반으로 질문의 필요성을 근거화하는 방법을 제안한다. 
    2. T5 인코더-디코더 아키텍처를 사용하여 Minecraft 협업 건축 과제를 해결하는 인공 에이전트를 학습한다. 명확하고 모호한 지시 사이의 분포적 차이를 더 잘 달성하는 불확실성 metric을 식별한다.
    3. 또한, 잘 보정된 예측 확률이 모호한 지시사항을 탐지하는 데 도움이 됨을 보여주고, 불확실성과 대화 기록 길이간의 관계에 대한 신규한 분석을 제시하여 감지에 어려움을 가지는 중요한 특성을 강조한다.

###### Cache me if you Can: an Online Cost-aware Teacher-Student framework to Reduce the Calls to Large Language Models (https://aclanthology.org/2023.findings-emnlp.1000/)
- Anthology ID: 2023.findings-emnlp.1000 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 소규모 및 중소기업들은 큰 규모의 훈련 데이터셋을 만들거나 큰 규모의 언어 모델을 사전 훈련하는 비용을 감당할 수 없기 때문에 LLM을 사용해야 하는데, 현재 이러한 서비스는 호출당 결제해야 하는 형태로 운영 비용이 많이 든다.
    2. 또한, 고객의 입력내용은 시간이 지나도 매우 유사한 경우가 많아 LLM에게 유사한 입력을 반복해서 요청하는 문제가 있다.
    3. 이 논문에서는 이러한 문제를 해결하기 위해 이전 LLM의 응답을 캐시화하고 이를 사용하여 SME 측에서 저렴한 지역 모델을 훈련시키는 방법을 제안한다. 실험 결과, 약간의 성능 저하와 함께 상당한 운영 비용 절감이 가능함을 보여준다.

###### ParroT: Translating during Chat using Large Language Models tuned with Human Translation and Feedback (https://aclanthology.org/2023.findings-emnlp.1001/)
- Anthology ID: 2023.findings-emnlp.1001 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. ChatGPT와 같은 대형 언어 모델은 다양한 기계 번역 역량을 보여주지만, 이러한 모델은 제한된 API를 통해서만 접근 가능하고 이는 연구 및 발전에 제한을 가한다. 
    2. 따라서, 우리는 ParroT이라는 프레임워크를 제안하는데, 이는 오픈 소스 언어 모델 (예 : LLaMA), 인간이 작성한 번역 및 피드백 데이터를 기반으로 채팅 중 번역 능력을 향상시키고 규제하는 것을 목표로 한다.
    3. 번역 지시, 대조 지시 및 오류 안내 지시와 같은 세 가지 지시 유형을 활용하여 ParroT 모델을 finetuning하는 방법을 제안하며, 실험결과 번역 지시는 기본 LLM의 번역 성능을 크게 개선하고, 오류 안내 지시는 더 나은 결과를 이끌 수 있다는 것을 보여준다.

###### Dense Retrieval as Indirect Supervision for Large-space Decision Making (https://aclanthology.org/2023.findings-emnlp.1002/)
- Anthology ID: 2023.findings-emnlp.1002 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대부분의 NLU 태스크는 많은 라벨을 가지고 있는데, training instance 당 라벨이 부족하고 다양한 세부 라벨 중에서 선택하는 것이 어렵기 때문에, 이러한 큰 라벨 공간에서의 결정을 학습하는 것은 특히 어렵다. 
    2. 이 논문에서는 단지 로짓만 예측하는 것이 아니라, 학습 데이터에서 결정항목을 검색함으로써 큰 공간의 결정 문제를 학습하는 학습-검색 문제로 재구성하여, 더 의미 있는 대표적인 결정 공간 표현과 함께 예측 일반화를 향상시키는 해결책 DDR을 제안한다. 
    3. 라벨 크기가 수백에서 수십 만까지 변하는 태스크에서 NLU를 수행하여 평가한 결과, DDR은 기존의 강력한 베이스라인보다 높은 성능을 보인다.

###### One-Model-Connects-All: A Unified Graph Pre-Training Model for Online Community Modeling (https://aclanthology.org/2023.findings-emnlp.1003/)
- Anthology ID: 2023.findings-emnlp.1003 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "온라인 커뮤니티는 커뮤니티, 사용자, 사용자 생성 텍스트 콘텐츠로 구성되어 있으며 사회 문제 해결에 도움이 될 수 있는 다양한 정보를 가지고 있다. 이전 연구에서는 이 세 가지 구성 요소와 그들 사이의 관계를 완전히 활용하지 못했으며, 다양한 하위 작업에 대응할 수 없었다."
    2. "이 논문에서는 동시에 커뮤니티, 사용자 및 텍스트를 고려하는 프레임워크에 초점을 맞추고 있으며, 이는 소셜 미디어와 관련된 다양한 하위 작업과 쉽게 연결될 수 있다. 구체적으로, 우리는 온라인 커뮤니티를 모델링하기 위해 삼중 이질적 그래프를 사용한다."
    3. "텍스트 재구성과 엣지 생성을 통해 커뮤니티, 사용자, 텍스트 간의 구조적 및 의미적 지식을 학습한다. 미리 훈련된 이 모델을 활용하여 위반 감지, 감성 분석, 커뮤니티 추천과 같은 다양한 하위 작업에서 유망한 결과를 얻을 수 있다. 우리의 탐구는 온라인 커뮤니티 모델링을 개선할 것이다."

###### In-Image Neural Machine Translation with Segmented Pixel Sequence-to-Sequence Model (https://aclanthology.org/2023.findings-emnlp.1004/)
- Anthology ID: 2023.findings-emnlp.1004 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "In-Image Machine Translation (IIMT)"는 이미지에 있는 텍스트를 한 언어에서 다른 언어로 번역하는 것을 목표로 한다. 기존의 cascade 방법은 OCR을 이용한 후 NMT와 텍스트 렌더링을 순차적으로 사용했으나, 이 방법은 OCR과 NMT의 오차가 누적되어 번역 품질이 저하된다.
    2. 이 논문에서는 end-to-end 모델을 제안하여 OCR, NMT, 텍스트 렌더링 파이프라인 대신 사용한다. 이 모델은 segmented pixel sequences를 입력과 출력으로 사용하는 encoder-decoder 패러다임을 채택한다. 
    3. end-to-end 학습을 통해 우리의 모델은 오차 전파를 피하고 번역 품질을 높이는데 성공하며, 도메인 데이터에서의 강건성을 보여주고 불완전한 단어에 대해 둔감하다. 실험 결과, 우리의 방법은 cascade 방법과 현존하는 end-to-end 모델보다 우수한 성능을 보인다.

###### NarrativeXL: a Large-scale Dataset for Long-Term Memory Models (https://aclanthology.org/2023.findings-emnlp.1005/)
- Anthology ID: 2023.findings-emnlp.1005 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이 논문에서는 GPT 3.5를 사용하여 Project Gutenberg의 1,500권의 소설에서 각 장면을 요약하고, 이를 기반으로 대규모 읽기 이해 데이터셋을 구축한다. 데이터셋은 990,595개의 질문으로 구성되어 있으며, 가장 가까운 대안들보다 1개의 차원 크기가 크다.
    
    2. 이 데이터셋은 대부분의 질문에 대한 "정착 요구"를 가지고 있어서 얼마나 오래 기억 능력이 필요한지를 알 수 있다. 따라서 오랜 기간의 기억 성능 평가에 도움이 될 것이다.
    
    3. 이 데이터셋은 유용한 정보이며, 기존 언어 모델에서도 기억 요구가 컨텍스트 길이를 초과하지 않는 한에도 질문이 쉽지 않음을 보여준다. 또한, 이 데이터셋을 적은 인력 투입으로 확장할 수 있는 코드도 제공된다.
    
    (Most of the technical terms are already in English)

###### Dialogue Act-Aided Backchannel Prediction Using Multi-Task Learning (https://aclanthology.org/2023.findings-emnlp.1006/)
- Anthology ID: 2023.findings-emnlp.1006 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화에서 청취자의 작은 응원 표현인 backchanneling은 자연스러운 대화에 필수적이며 말하는 사람의 의도와 발화 유형과 밀접한 관계가 있다. 
    2. 우리는 multi-task learning 접근법을 제안하여 대화 행위 분류와 함께 backchannel 예측을 위한 텍스트 표현을 학습한다.
    3. 이를 통해 "Yeah" 또는 "Really?"와 같은 구체적인 backchannel의 예측을 F1에서 최대 2.0% 개선할 수 있음을 보였다.

###### mReFinED: An Efficient End-to-End Multilingual Entity Linking System (https://aclanthology.org/2023.findings-emnlp.1007/)
- Anthology ID: 2023.findings-emnlp.1007 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 end-to-end 다국어 entity linking (MEL) 방법은 entity mentions가 주어진 상태로 가정하고, 낮은 품질의 다국어 훈련 말뭉치로 인해 entity mention detection 단계를 건너뛰었다.
    2. 이 논문에서는 mReFinED라는 첫 번째 end-to-end 다국어 entity linking을 제안하고, bootstrapping mention detection 프레임워크를 도입하여 훈련 말뭉치의 품질을 개선한다.
    3. 실험 결과, mReFinED는 최고의 기존 작업을 능가하면서도 44배 더 빠른 속도로 end-to-end MEL 작업을 수행한다.

###### Sub-network Discovery and Soft-masking for Continual Learning of Mixed Tasks (https://aclanthology.org/2023.findings-emnlp.1008/)
- Anthology ID: 2023.findings-emnlp.1008 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 지금까지 Continual learning(CL) 연구에서는 catastrophic forgetting(CF) 문제를 해결하는 것에만 초점을 맞추었었으나, 이 논문은 지식 전달(KT) 측면에서도 성과를 보이고 있다.
    2. 이 논문은 각각의 작업에 대한 지식을 발견하여 서브 네트워크를 통해 각 작업의 지식을 완벽하게 유지하여 catastrophic forgetting을 극복하는 방법을 제안한다.
    3. 또한, 이전 지식을 보존하고 새로운 작업이 과거의 지식을 활용하여 transfer learning을 이룩할 수 있도록 소프트-마스킹 메커니즘을 제안하였으며, 다양한 작업 혼합에서 강력한 베이스라인보다 일관되게 우수한 성능을 보여주었다.

###### PIVOINE: Instruction Tuning for Open-world Entity Profiling (https://aclanthology.org/2023.findings-emnlp.1009/)
- Anthology ID: 2023.findings-emnlp.1009 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기존의 닫힌 세계 정보 추출(Closed-world IE)과 달리, 개방 세계 정보 추출에서는 미리 정의된 체계를 벗어난 entity와 relation이 존재할 수 있는 상황을 고려한다.
    2. 우리는 instruction tuning을 통해 원하는 entity profile을 추출할 수 있는 인공지능 모델을 개발하고, INSTRUCTOPENWIKI라는 다양한 instruction을 활용한 대규모 데이터셋을 구축한다.
    3. 실험 결과, 우리의 모델인 PIVOINE은 전통적인 방법과 ChatGPT 기반의 기준선을 훌륭히 능가하며, 보지 못한 instruction과 체계 외의 경우에서도 탁월한 일반화 능력을 보여준다. 따라서, PIVOINE은 개방 세계 entity profiling의 해결책으로서 희망찬 가능성을 보여준다.

###### DiQAD: A Benchmark Dataset for Open-domain Dialogue Quality Assessment (https://aclanthology.org/2023.findings-emnlp.1010/)
- Anthology ID: 2023.findings-emnlp.1010 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화 평가에서 기존 연구들은 실제 사용자 설정과 멀리 떨어진 대화들의 일관성과 같은 하위 메트릭만을 제공하며, 온전한 대화와 인간-학습적인 평가 데이터셋을 제공하기 어렵다. 
    2. 본 논문에서는 오픈 도메인 대화의 품질을 자동 평가하기 위해 대규모 대화 품질 평가 데이터셋(DiQAD)을 공개한다. 
    3. 이 데이터셋은 인간 판단을 따르는 차원에 기반한 평가 기준을 수립하고, 약 10만개의 실제 사용자 간 대화를 이 기준에 따라 어노테이트하여 구성되었다.

###### Tuna: Instruction Tuning using Feedback from Large Language Models (https://aclanthology.org/2023.findings-emnlp.1011/)
- Anthology ID: 2023.findings-emnlp.1011 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 오픈 소스 대규모 언어 모델 (LLM)인 LLaMA와 같은 모델에 Instruct-GPT 및 GPT-4와 같은 더 강력한 LLM의 직접적인 출력을 사용하여 모델 동작을 인간의 선호도에 맞추는 것은 경제적인 방법이지만, instruction-tuned 모델은 하나의 입력당 하나의 응답만을 보고있어 더 좋은 응답의 지식이 부족하다.
    2. 이 연구에서는 확률적 순위 지정과 문맥적 순위 지정 접근 방식을 사용하여 instruction-tuned LLM을 fine-tuning하여 더 나은 응답 생성 확률을 높이는 방법을 제안한다. 확률적 순위 지정은 instruction-tuned 모델이 teacher LLM에서 고품질 및 저품질 응답의 상대적 순위를 물려 받도록 하며, 문맥적 순위 지정을 통해 모델은 강력한 LLM의 문맥 이해 능력을 사용하여 자체적으로 응답 분포를 개선할 수 있다.
    3. 또한, 우리는 확률적 순위 지정과 문맥적 순위 지정을 instruction-tuned LLM에 순차적으로 적용한다. 이를 Tuna라고 부르는 결과 모델은 Super Natural Instructions (119개의 테스트 과제), LMentry (25개의 테스트 과제), Vicuna QA에서 일관되게 성능을 향상시키며, 몇 가지 강력한 강화 학습 기준선보다 더 좋은 결과를 얻을 수 있다.

###### Emptying the Ocean with a Spoon: Should We Edit Models? (https://aclanthology.org/2023.findings-emnlp.1012/)
- Anthology ID: 2023.findings-emnlp.1012 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근에 인기를 끄는 직접적인 모델 편집 방법은 사실적인 오류를 LLM(Large Language Models) 생성물에서 수정하는 수단으로 사용되지만, 이 방법에 대해 의문을 제기합니다.
    2. 우리는 모델 편집을 정의되고 목적이 더 잘 정의된 세 가지 유사한 접근법과 비교합니다: (1) retrieval-based architectures, (2) concept erasure methods, 그리고 (3) attribution methods.
    3. 우리는 직접 모델 편집을 LLM의 단점을 해결하기 위한 체계적인 해결책으로 신뢰할 수 없고, 모델 설명 가능성을 향상시키는데는 잠재력이 있지만, 사실성을 신뢰할 수 있다는 개념을 강화함으로써 위험을 초래할 수 있다고 주장합니다. 따라서 LLM 배치 프로세스의 일부로 모델 편집의 신중한 홍보와 적용, 그리고 편집을 중요한 구성 요소로 의존하지 않는 경우에만 LLM의 사용 사례를 책임 있게 제한할 것을 요구합니다.

###### A Causal View of Entity Bias in (Large) Language Models (https://aclanthology.org/2023.findings-emnlp.1013/)
- Anthology ID: 2023.findings-emnlp.1013 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사전학습 모델들은 entity bias로 인해 부적절한 예측을 하는데, 이러한 문제를 개선하기 위해 인과성 기반의 방법을 제안한다. 제안한 방법은 원래 entity를 주변 entity로 대체하여 편향 정보를 줄이고 의미 정보를 보존하는 인과적 개입 기술을 사용한다.
    2. 인과 구조 모델을 기반으로 한 훈련 시 개입은 관계 추출 및 기계 독해 작업에서 사전 학습 모델의 OOD 성능을 향상시키는 것으로 보입니다.
    3. 그리고 상황에 따른 개입은 GPT-3.5의 엔터티 기반 지식 충돌을 효과적으로 줄여 기계 독해 작업의 정확도를 향상시키는 것으로 보입니다.

###### T5Score: Discriminative Fine-tuning of Generative Evaluation Metrics (https://aclanthology.org/2023.findings-emnlp.1014/)
- Anthology ID: 2023.findings-emnlp.1014 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 생성된 텍스트를 평가하기 위한 임베딩 기반 메트릭은 주로 두 가지 패러다임으로 나눌 수 있다. 유인적인 평가 메트릭은 감독된 인간 주석에 따라 어떤 출력물이 더 높은 품질을 가지는지 직접 예측하는데 훈련되고, 생성적인 평가 메트릭은 생성 모델의 확률에 따라 텍스트를 평가하는 것을 훈련한다.
    2. 본 논문에서는 두 가지 방식의 장점을 결합하여, 사용 가능한 데이터로부터 감독 및 비감독 신호를 모두 사용하는 프레임워크를 제안한다.
    3. 실험 결과, T5Score는 segment 수준에서 기존 최고의 메트릭에 비해 모든 데이터셋에서 가장 우수한 성능을 달성한다.

###### T-Projection: High Quality Annotation Projection for Sequence Labeling Tasks (https://aclanthology.org/2023.findings-emnlp.1015/)
- Anthology ID: 2023.findings-emnlp.1015 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 주어진 sequence labeling task와 언어에 대해 레이블링된 데이터가 적을 때, annotation projection은 자동으로 주석이 달린 데이터를 생성하기 위한 전략 중 하나로 제안되었다.
    2. 본 논문에서는 annotation projection을 위한 새로운 접근 방식인 T-Projection을 제안한다. 이 방법은 사전 훈련된 텍스트 대 텍스트 언어 모델과 최신 기계 번역 기술을 활용한다.
    3. 실험 결과, T-Projection은 이전의 annotation projection 방법보다 뛰어난 성능을 보여주었으며, 고품질 훈련 데이터 부족 문제를 자동으로 해결하는데 도움을 줄 수 있다고 한다.

###### MTGER: Multi-view Temporal Graph Enhanced Temporal Reasoning over Time-Involved Document (https://aclanthology.org/2023.findings-emnlp.1016/)
- Anthology ID: 2023.findings-emnlp.1016 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 문서의 사실과 시간은 복잡하게 얽혀 있어 문서에서의 시간적 추론이 어렵다. 이전 연구는 시간을 암묵적으로 모델링하여 이러한 복잡한 관계를 처리하기 어렵다. 
    2. 우리는 이 문제에 대응하기 위해, 시간이 관련된 문서에 대한 시간적 추론을 위한 새로운 Multi-view Temporal Graph Enhanced Reasoning (MTGER) 프레임워크를 제안한다. 
    3. MTGER는 다양한 시간 그래프를 통해 사실들 간의 시간적 관계를 명시적으로 모델링하며, multi-view 메카니즘을 통해 time-focused와 fact-focused 정보를 모두 포착하여 상호 보완할 수 있도록 한다.

###### MSCFFN: A New FFN with Multi-Space Cross to Accelerate Transformer (https://aclanthology.org/2023.findings-emnlp.1017/)
- Anthology ID: 2023.findings-emnlp.1017 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Transformer 모델은 다양한 자연어 처리 작업에서 인상적인 성과를 거두었지만, 몇몇 분야에서는 사용이 제한되고 있으며, 무거운 계산 복잡성이 주요한 제한 사항 중 하나이다. 
    2. 이 논문에서는 Transformer의 FFN (feed forward network) 구조를 재설계하여 계산 복잡성을 줄이고 정확한 결과를 보장하는 MSCFFN이라는 새로운 구조를 제안한다. 
    3. Long-Range Arena 벤치마크에서 실험을 통해 제안한 방법의 효과를 검증하였으며, 결과로는 MSCFFN이 더 빠른 속도로 비슷하거나 더 나은 정확도를 달성할 수 있다는 것을 보여준다.

###### Dialect Transfer for Swiss German Speech Translation (https://aclanthology.org/2023.findings-emnlp.1018/)
- Anthology ID: 2023.findings-emnlp.1018 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 스위스 독일어는 공식적인 글자체가 없으며 다양한 방언으로 구성되어 있으며, 약 5백만 명의 사용자만 있는 자원이 부족한 언어이다. 
    2. 이 논문은 스위스 독일어와 표준 독일어 간의 차이와 다양한 방언의 포함 및 배제가 스위스 독일어 음성 번역 모델의 성능에 어떤 영향을 미치는지에 대해 연구하였다.
    3. 방언 다양성과 언어적 차이가 스위스 독일어 음성 번역에 상당한 어려움을 초래하며, 이는 경험적 연구에서 유추된 언어학적 가설과 일치한다는 것을 보였다.

###### Masked Path Modeling for Vision-and-Language Navigation (https://aclanthology.org/2023.findings-emnlp.1019/)
- Anthology ID: 2023.findings-emnlp.1019 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 자연어 지시에 기반한 시각-언어 네비게이션 (VLN) 에이전트는 실제 환경에서 학습되어 진다. VLN의 주요 도전은 학습 데이터의 한정성으로 인해 모델의 효과적인 일반화 능력이 제한되는 것이다. 이 논문에서는 외부 도구를 사용하여 pseudo-labeled 데이터를 생성하거나 훈련 중 web-scaled 이미지-텍스트 쌍을 통합함으로써 이 문제를 완화하려는 기존의 방법들을 소개한다. 
    2. 이 논문에서 제안하는 MPM (Masked Path Modeling)은 자체 수집한 데이터를 사용하여 에이전트를 사전 훈련함으로써 외부 도구의 필요성을 없앤다. 에이전트는 탐색 환경을 탐험하고 해당 에이전트 동작과 함께 탐험한 경로를 기록한다. 그 다음에는 훈련 데이터를 사용하여 원래의 동작 순서를 복원하도록 훈련시킨다. 
    3. 실험 결과는 MPM의 성공률에서 유의미한 개선을 보여주었으며, 훈련 전에 에이전트가 저물지 않은 환경을 탐색할 수 있는 경우 추가적인 개선 가능성을 보여주었다.

###### Learning Interpretable Style Embeddings via Prompting LLMs (https://aclanthology.org/2023.findings-emnlp.1020/)
- Anthology ID: 2023.findings-emnlp.1020 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 글 작가 스타일에 대한 내용-독립적인 표현을 학습하는 스타일 표현 학습은 해석 가능한 표현이 아니기 때문에 감독되고 설명이 가능한 작가 식별과 같은 하위 응용 프로그램에서 활용이 복잡한 과제가 있다.
    2. 이 연구에서는 프롬프트를 사용하여 많은 수의 텍스트에서 스타일 메트릭을 수행하여 합성 스타일 메트릭 데이터셋을 생성한다. 이 합성 데이터를 사용하여 LISA 임베딩이라고 불리는 사람이 읽고 이해할 수 있는 스타일 표현을 학습한다.
    3. 우리는 이 연구를 통해 합성 데이터셋(StyleGenome)과 해석 가능한 스타일 임베딩 모델(LISA)을 리소스로 공개한다.

###### Exploring Context-Aware Evaluation Metrics for Machine Translation (https://aclanthology.org/2023.findings-emnlp.1021/)
- Anthology ID: 2023.findings-emnlp.1021 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 기계 번역 평가 연구는 주로 개별 문장의 질에 초점을 맞추었으며, 문맥 정보의 중요성을 간과해왔다.
    2. 이 논문에서는 Cont-COMET이라는 문맥-인식 기계 번역 평가 메트릭을 제안하였다. 이 접근 방식은 평가할 문장의 이전과 다음 문맥을 동시에 고려하고, 인간 주석 기준에 맞게 메트릭을 학습한다.
    3. WMT의 공식 테스트 프레임워크에서 수행된 실험과 평가 결과, Cont-COMET은 시스템 수준과 문장 수준 모두에서 개선되었다.

###### GRACE: Discriminator-Guided Chain-of-Thought Reasoning (https://aclanthology.org/2023.findings-emnlp.1022/)
- Anthology ID: 2023.findings-emnlp.1022 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다단계 추론에서, 언어 모델은 쉽게 잘못된 단계에도 높은 확률을 할당할 수 있다. 이 문제를 해결하기 위해, 우리는 GRACE라고 불리는 단계별 디코딩 방법을 제안한다. 
    2. GRACE는 실제와 잘못된 단계 사이의 대조적인 손실을 통해 훈련된 판별기를 사용하여 디코딩 과정에서 다음 단계 후보들을 평가한다. 
    3. GRACE는 유의미한 성능 향상을 보여주며, greedy decoding, 검증자, 그리고 self-consistency와 비교해 대부분의 설정에서 우수한 결과를 낸다.

###### QADYNAMICS: Training Dynamics-Driven Synthetic QA Diagnostic for Zero-Shot Commonsense Question Answering (https://aclanthology.org/2023.findings-emnlp.1023/)
- Anthology ID: 2023.findings-emnlp.1023 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. '영상 대응 Question-Answering(QA)'는 일부 특정 벤치마크를 넘어선 일반적인 상황에 대해 모델이 추론할 수 있어야 한다. 
    2. 우리는 QA에서 LLMs를 사용하는 일련의 과정에서 생기는 잡음과 문법 오류, 그리고 잘못된 정답을 제거하고, 진단 및 보정을 위한 훈련 동태 구조 기반 프레임워크인 QADYNAMICS를 제안한다. 
    3. 실험 결과, 우리의 접근 방식은 33%의 합성 데이터만 사용하여 모든 베이스라인 모델들보다 성능이 뛰어났으며, 전문가 평가에서도 QA의 품질을 크게 향상시켰다.

###### RexUIE: A Recursive Method with Explicit Schema Instructor for Universal Information Extraction (https://aclanthology.org/2023.findings-emnlp.1024/)
- Anthology ID: 2023.findings-emnlp.1024 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Universal Information Extraction (UIE)는 다양한 대상, 이질적인 구조 및 수요별 스키마에 의해 도전적인 영역이다. 
    2. 기존 작업들은 Named Entity Recognition (NER) 및 Relation Extraction (RE)과 같은 몇 가지 작업들을 통합함으로써 성공을 거두었으나, quadruples 및 quintuples와 같은 일반적인 스키마를 추출할 때는 진정한 UIE 모델로서 부족하다. 
    3. 이 논문에서는 거의 모든 추출 스키마를 포괄하는 형식적인 정의를 통해 진정한 UIE를 재정의하였으며, RexUIE라는 Recursive Method with Explicit Schema Instructor for UIE를 제안한다.

###### PromptARA: Improving Deep Representation in Hybrid Automatic Readability Assessment with Prompt and Orthogonal Projection (https://aclanthology.org/2023.findings-emnlp.1025/)
- Anthology ID: 2023.findings-emnlp.1025 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "가독성 평가는 독자의 독해 능력에 따라 텍스트를 자동으로 분류하는 것을 목표로 한다. 하이브리드 ARA 모델은 심층 및 언어적 특징을 모두 사용하여 최근 주목을 받고 있다. 그러나 심층 특징은 훈련 데이터 부족으로 완전히 탐구되지 않았으며, 심층 및 언어적 특징의 퓨전은 기존의 하이브리드 ARA 모델에서는 효과적이지 않다."
    2. 우리는 PromptARA라는 신규 하이브리드 ARA 모델을 제안하여 심층 특징 표현을 개선하기 위해 prompt를 활용하고 심층 및 언어적 특징을 퓨전하기 위해 직교 투영 계층을 사용한다.
    3. 4개의 영어와 2개의 중국어 말뭉치에서 수행된 일련의 실험 결과는 제안된 모델의 효과적임을 보여준다. 실험 결과는 제안된 모델이 최고의 성능을 가진 모델에 우월하다는 것을 나타낸다.

###### Does Listener Gaze in Face-to-Face Interaction Follow the Entropy Rate Constancy Principle: An Empirical Study (https://aclanthology.org/2023.findings-emnlp.1026/)
- Anthology ID: 2023.findings-emnlp.1026 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 언어 (문자와 말)는 일반적으로 엔트로피 비율 일정성 (ERC) 원칙을 따른다고 가정되며, 텍스트의 정보 밀도는 시간에 따라 일정하다. 최근에는 독발에서 사용되는 비언어적 제스처에서도 이 원칙이 발견되었지만, 청취자의 비언어적 신호에도 ERC 원칙이 적용되는지 여전히 불분명하다.
    2. 우리는 대화에서 추출한 청취자의 시선 행동에 초점을 맞추고, 비디오로 기록된 대화의 시선 데이터를 처리하고 정보 밀도를 계산하기 위해 transformer 기반 신경 시퀀스 모델을 훈련시켰다. 또한 사전 훈련된 언어 모델을 사용하여 해당 말의 정보 밀도를 계산한다. 
    3. 우리의 결과는 (1) 대화에서 청취자의 시선 행동이 대체로 ERC 원칙을 따르고, (2) 말의 정보 밀도와 청취자의 시선 행동 간에 일치가 있는 것을 보여준다.

###### Incorporating Object-Level Visual Context for Multimodal Fine-Grained Entity Typing (https://aclanthology.org/2023.findings-emnlp.1027/)
- Anthology ID: 2023.findings-emnlp.1027 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Fine-grained entity typing(FGET)에서는 entity를 언급하는 문맥에서 적절한 세부 유형을 지정하는 것이 중요한데, 기존 접근 방식은 텍스트 문맥 정보만 사용하였다. 
    2. 이 논문에서는 visual context도 활용하기 위해 멀티모달 fine-grained entity typing(MFGET)이라는 새로운 작업을 제안하고, MFGET를 위한 대규모 데이터셋인 MFIGER를 구축한다. 
    3. 실험 결과는 우리의 접근 방식이 기존 텍스트 기반 방법보다 분류 성능이 우수함을 보여주었다.

###### Exploring the Numerical Reasoning Capabilities of Language Models: A Comprehensive Analysis on Tabular Data (https://aclanthology.org/2023.findings-emnlp.1028/)
- Anthology ID: 2023.findings-emnlp.1028 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 금융, 경제, 과학과 같은 실제 세계 도메인에서는 숫자 데이터가 중요한 역할을 한다. 따라서 숫자를 이해하고 추론하는 능력은 이러한 분야에서 필수적이다.
    2. 이 논문에서는 표현, 숫자 감각, 조작, 복잡한 추론 등 네 수준을 포함하는 숫자 추론 기술을 위한 완전한 계층적 분류 체계를 제안한다.
    3. 최신 모델들의 모든 추론 유형에 대한 포괄적인 평가를 실시하고, 다양하고 포괄적인 숫자 확인 도구를 개발하여 다른 모델 유형에 대한 도전적인 추론 유형을 식별한다. FlanT5와 GPT3.5는 다른 모델에 비해 강력한 숫자 추론 능력을 보인다.

###### Assessing Privacy Risks in Language Models: A Case Study on Summarization Tasks (https://aclanthology.org/2023.findings-emnlp.1029/)
- Anthology ID: 2023.findings-emnlp.1029 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델들은 다양한 태스크에서 최고의 성능을 보여주면서 NLP 분야를 혁신했지만, 이러한 모델들이 학습 데이터의 정보를 공개할 수 있다는 우려가 있다. 
    2. 이 연구에서는 요약 태스크에 대해 멤버십 추론(MI) 공격을 연구하며, 샘플과 모델의 API에 대한 블랙박스 접근권을 통해 샘플이 학습 데이터의 일부인지 판단할 수 있는지 조사한다. 
    3. 우리는 텍스트 유사성과 문서 수정에 대한 모델의 내성을 MI 신호로 활용하고, 널리 사용되는 데이터셋에서의 효과를 평가한다. 결과적으로, 요약 모델은 참조 요약이 없는 경우에도 데이터 멤버십을 공개할 위험이 있다는 것을 보여준다. 또한, MI 공격에 대비하여 요약 모델을 훈련하기 위한 여러 가지 안전장치에 대해 논의하고, 개인정보 보호와 유효성 사이의 본질적인 trade-off에 대해 논의한다.

###### BERT Has More to Offer: BERT Layers Combination Yields Better Sentence Embeddings (https://aclanthology.org/2023.findings-emnlp.1030/)
- Anthology ID: 2023.findings-emnlp.1030 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. BERT 기반 모델의 문장 표현을 특징 추출기로 사용하는 것은 BERT를 전체적으로 fine-tune 하는 것보다 한 번의 전처리로 데이터의 표현을 계산한 후 후속 작업에 사용함으로써 시간을 훨씬 절약할 수 있다.
    2. 이 논문에서는 BERT 기반 모델의 특정 레이어의 조합이 데이터셋과 모델에 따라 훨씬 좋은 결과를 얻을 수 있다고 제안한다.
    3. 다양한 BERT 기반 모델과 작업, 데이터셋에 대해 우리의 방법의 효과를 실험적으로 보여주었는데, 7개의 표준 의미론적 텍스트 유사성 데이터셋에서는 Spearman correlation을 최대 25.75% 향상시키고 평균 16.32% 향상시켰다.

###### Extrapolating Multilingual Understanding Models as Multilingual Generators (https://aclanthology.org/2023.findings-emnlp.1031/)
- Anthology ID: 2023.findings-emnlp.1031 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 마스크된 언어 모델을 통해 사전 훈련된 다국어 이해 모델은 많은 언어 이해 태스크에서 좋은 결과를 달성했지만, 디코더 기반의 인과 언어 모델과 비교했을 때 품질이 낮은 텍스트를 생성하는 능력이 부족합니다.
    2. 우리는 적은 수의 추가 매개 변수를 사용하여 다국어 인코더를 다국어 생성기로 적응시키기 위해 '의미 기반 정렬-덴오이징' (Semantic-Guided Alignment-then-Denoising, SGA) 접근법을 제안합니다. 실험 결과, 이 접근 방법은 초기화 기반 방법보다 우수한 성능을 보여주며, 기계 번역에서 9.4 BLEU, 질문 생성에서 8.1 Rouge-L, 이야기 생성에서 5.5 METEOR의 개선 효과를 얻었습니다.
    3. 그러나 mBERT와 비교했을 때 단순히 SGA로 XLM-Rlarge가 지도학습 환경에서 여전히 뒤쳐지는 것을 관찰하였으며, 이는 이해 모델이 강력한 생성기로 발전시키기 위해 더 많은 탐구가 필요함을 보여줍니다.

###### SAC3: Reliable Hallucination Detection in Black-Box Language Models via Semantic-aware Cross-check Consistency (https://aclanthology.org/2023.findings-emnlp.1032/)
- Anthology ID: 2023.findings-emnlp.1032 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 현대 언어 모델의 신뢰성을 이해하기 위한 핵심 단계로 환각 탐지(Hallucination detection)가 있다. 본 연구에서는 어떤 증상 확인방식인 self-consistency로는 파악할 수 없는 1) 질문 수준과 2) 모델 수준의 환각에 대해 다시 살펴보았다.
    2. 우리는 이 발견을 바탕으로 Self-consistency checking의 원칙을 기반으로 한 새로운 샘플링 기반 방법인 semantic-aware cross-check consistency (SAC3)를 제안한다.
    3. 우리의 SAC3 방식은 의미론적으로 동등한 질문 왜곡과 크로스 모델 응답 일관성 확인과 같은 발전된 기술을 활용하여 질문 수준과 모델 수준의 환각을 모두 감지할 수 있는 추가적인 메커니즘을 포함하고 있다.

###### Test-Time Self-Adaptive Small Language Models for Question Answering (https://aclanthology.org/2023.findings-emnlp.1033/)
- Anthology ID: 2023.findings-emnlp.1033 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근의 instruction-finetuned large language models(LMs)는 다양한 태스크에서 현저한 성능을 보여주었으나, 특정 태스크에 대해서는 전이와 지식 적응 능력이 제한적이기 때문에 최적이 아닐 수 있다.
    2. 이 논문에서는 unlabeled test data만 가지고 작동하는 self-adaptive LMs의 능력을 보여주고 조사한다. 
    3. 우리의 제안된 self-adaption 전략은 높은 복원력과 다양한 프롬프트에 대한 안정성을 가진 벤치마크 QA datasets에서 유의한 성능 향상을 보여준다.

###### ExpNote: Black-box Large Language Models are better Task Solvers with Experience Notebook (https://aclanthology.org/2023.findings-emnlp.1034/)
- Anthology ID: 2023.findings-emnlp.1034 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대형 언어 모델은 다양한 작업을 푸는 데 큰 힘을 보이고 일반적인 문제 해결자로 간주되지만, 특정 작업에서는 여전히 실패한다. 이 논문에서는 검은 상자 언어 모델의 능력을 향상시키는 문제에 초점을 맞추고 있으며, 훈련 데이터로부터 경험을 반영하고 기억된 경험을 테스트 중에 외부 메모리에서 검색하는 자동화된 프레임워크인 ExpNote를 제안한다.
    2. ExpNote를 다양한 작업에서 평가하였고 실험 결과로는 검은 상자 언어 모델의 성능이 크게 향상되었음을 보여주었다.
    3. ExpNote의 데이터와 코드는 https://github.com/forangel2014/ExpNote에서 확인할 수 있다.

###### Evaluating Parameter-Efficient Finetuning Approaches for Pre-trained Models on the Financial Domain (https://aclanthology.org/2023.findings-emnlp.1035/)
- Anthology ID: 2023.findings-emnlp.1035 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 수백만, 수십억, 심지어 수조 개의 trainable한 파라미터를 가진 대규모 언어 모델들이 인기를 끌고 있다. 하지만 이 모델들은 빠르게 오버피티마이즈(over-parameterize) 되는 위험성을 가지고 있으며, 완전히 fine-tuning하기 위한 적응 비용이 크게 증가한다.
    2. 미세조정하는 동안 미리 훈련된 가중치를 모두 고정시키는 'parameter-efficient tuning' 접근 방식은 전통적인 fine-tuning 대안으로 인기를 얻고 있다.
    3. 이 논문은 금융과 같은 도메인별 분야에서 parameter-efficient tuning 방법을 활용하여 일련의 금융 BERT 모델의 성능을 완전히 fine-tuned 모델과 비교하였고, 시간과 자원 효율성에서 이득을 얻으면서도 전통적인 fine-tuning과 성능이 비슷하다는 것을 확인하였다.

###### Can Retriever-Augmented Language Models Reason? The Blame Game Between the Retriever and the Language Model (https://aclanthology.org/2023.findings-emnlp.1036/)
- Anthology ID: 2023.findings-emnlp.1036 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 미세 조정 전처리 언어 모델에 retriever를 추가하는 것이 자연어처리에 있어서 인기가 있는데, 이 논문에서는 이러한 모델들의 강점과 약점을 다양한 태스크를 통해 평가하였고, 판단에 필요한 정보를 검색하기 위한 단순 유사도 측정은 충분하지 않음을 보였다. 
    2. 또한, 필요한 문장만 주어진 경우에도 언어 모델들은 강한 판단 능력을 보이지 않았으며, 첨가된 retriever의 성능이 저하되는 현상도 발견되었다.
    3. 더 큰 언어 모델은 성능을 향상시키지만, 개선의 여지가 여전히 많은 것으로 나타났으며, 멀티합-검색-읽기는 GPT-3.5와 같은 대형 언어 모델에 대해 효과적인 방법이지만 다른 언어 모델(예: Flan-T5-xxl)에는 일반화되지 않는다는 것을 분석했다.

###### BERTwich: Extending BERT’s Capabilities to Model Dialectal and Noisy Text (https://aclanthology.org/2023.findings-emnlp.1037/)
- Anthology ID: 2023.findings-emnlp.1037 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 다이얼렉트, 비공식적이거나 맞춤법이 틀린 텍스트와 같은 비표준 텍스트를 다루는 NLP 애플리케이션에서는 BERT와 같은 언어 모델의 성능이 저하된다. BERT의 모델링 능력을 비표준 텍스트에 대응시키기 위해 어떻게 해야 할까?
    2. fine-tuning은 모델을 특정 작업에 맞게 조정하는 데 도움이 되지만, 비표준 언어에 모델을 적응시키기 위해 필요한 깊이 있는 변화를 가져오지 못한다. 
    3. 이 논문에서는 BERT의 인코더 스택을 추가적인 인코더 층으로 둘러싸는 기존 아이디어를 소개하며, 이 방법이 최근 연구를 통해 미세 조정 데이터에 문자 수준의 노이즈를 포함시킴으로써 다이얼렉트 텍스트로의 zero-shot 전이를 촉진하고 단어와 그와 대응되는 노이즈가 있는 단어 사이의 임베딩 공간의 거리를 줄일 수 있는 것을 발견했다.

###### Closed Boundary Learning for Classification Tasks with the Universum Class (https://aclanthology.org/2023.findings-emnlp.1038/)
- Anthology ID: 2023.findings-emnlp.1038 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "Universum class"는 관심 클래스에 속하지 않는 샘플들의 모음으로, 관계 추출, 개체명 인식, 감성 분석 등 NLP의 많은 분류 기반 작업에서 일반적으로 등장한다. 하지만, 기존 방법들은 Universum 클래스를 관심 클래스와 동등하게 처리하여, 과적합, 잘못된 분류, 모델의 강성 감소와 같은 문제가 발생한다.
    2. 이 논문에서는 closed boundary learning 방법을 제안하여, 관심 클래스에는 닫힌 결정 경계를 적용하고 특징 공간에서 모든 닫힌 경계 외부를 Universum 클래스의 공간으로 지정한다.
    3. 제안된 방법은 Universum 클래스의 독특한 특성에 맞춰 닫힌 경계를 임의의 모양으로 정의하고, Universum 클래스의 규칙 기반 확률 추정 및 경계 학습 손실을 제안하여, 분류 모델의 정확성과 강성을 동시에 향상시킨다.

###### Revisiting Entropy Rate Constancy in Text (https://aclanthology.org/2023.findings-emnlp.1039/)
- Anthology ID: 2023.findings-emnlp.1039 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "균일한 정보 밀도 (UID) 가설은 인간들이 발화나 담화에 정보를 균등하게 분배하는 경향이 있다고 주장한다."
    2. 기존 연구에서 영어 텍스트의 확률에 대한 n-gram 언어 모델을 기반으로 엔트로피 비율 일정성 원리를 제안했으나, 이 논문은 피드포워드 언어 모델을 사용하여 해당 가설을 재평가하였다.
    3. 실험 결과는 엔트로피 비율 일정성을 지지하는 명확한 증거를 찾지 못하였으며, 이는 균일한 정보 밀도 가설과 효율적인 의사소통에 대한 언어학적 이론에 대한 함의를 논의한다.

###### Calibrated Seq2seq Models for Efficient and Generalizable Ultra-fine Entity Typing (https://aclanthology.org/2023.findings-emnlp.1040/)
- Anthology ID: 2023.findings-emnlp.1040 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 정보 추출에서의 초 세부 entity typing은 텍스트 안의 entity 언급에 대해 미세한 의미론적 유형을 예측하여 정보 추출에 중요한 역할을 한다. 그러나 이 작업은 출력 공간 내 이종의 entity 타입 때문에 상당한 어려움을 가지고 있다.
    2. 이 논문에서는 CASENT라고 불리는 seq2seq 모델을 소개하여 교정된 신뢰 점수로 초 세부 유형을 예측한다.
    3. UFET 데이터셋에서 상당한 실험을 진행하였고 이전의 모델보다 F1 점수와 교정 오차에서 뛰어난 성능을 보여주며 추론 속도를 50배 이상 향상시켰으며, 훈련 시보지 않은 다섯 가지 특수 도메인 entity typing 데이터셋에서도 일반화 능력을 보였다.

###### Learning Semantic Role Labeling from Compatible Label Sequences (https://aclanthology.org/2023.findings-emnlp.1041/)
- Anthology ID: 2023.findings-emnlp.1041 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. SRL (Semantic role labeling)은 여러 개의 분리된 label set을 가지고 있지만, 이들을 어떻게 상호 도움을 줄 수 있는지에 대한 질문이 있다. 이 논문에서는 VerbNet과 PropBank 라벨을 하나의 시퀀스로 모델링하는 방식을 제안하고, Semlink 제약 조건을 활용하여 디코딩을 함께 수행하여 전반적인 F1 스코어를 향상시키고 있다.
    2. 이 모델은 VerbNet과 PropBank 사이에서의 cross-task interaction을 적용하고 있는데, 특히 Constrained Marginal Model을 활용하여 Semlink에 정의된 지식을 사용하여 PropBank-only 데이터로부터 더 많은 효과를 얻고 있다.
    3. CoNLL05 기준으로, 이 모델은 state-of-the-art F1 스코어를 달성하고 있으며, in-domain 모델에 비해 3.5 (VerbNet)와 0.8 (PropBank) 점수로 우수한 성능을 보여주고 있다.

###### QUADRo: Dataset and Models for QUestion-Answer Database Retrieval (https://aclanthology.org/2023.findings-emnlp.1042/)
- Anthology ID: 2023.findings-emnlp.1042 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사전에 계산된 데이터베이스로부터 효과적으로 답변을 검색하는 자동 질문응답(QA) 시스템을 설계하기 위한 효과적인 방법은 훈련/테스트 데이터의 부족이다.
    2. 이 논문에서는 이런 문제를 해결하기 위해 15,211개의 입력 질문과 각각 30개의 비슷한 질문/답변 쌍으로 구성된 소스를 제공한다. 
    3. 뿐만 아니라 이 리소스에 대한 포괄적인 실험 결과를 보고하며, 답변 관련성, 훈련 전략 및 모델 입력 구성과 같은 QA 시스템의 다양한 중요한 측면에 대한 품질과 특성을 테스트한다.

###### Give Me the Facts! A Survey on Factual Knowledge Probing in Pre-trained Language Models (https://aclanthology.org/2023.findings-emnlp.1043/)
- Anthology ID: 2023.findings-emnlp.1043 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Pre-trained Language Models (PLMs)는 방대한 라벨 없는 데이터로 훈련되어 다양한 세계지식이 담겨 있다. 이는 PLMs의 다운스트림 태스크 성능과 지식 베이스로서의 사용을 정당화하는 데에 관심이 모여왔다. 
    2. 본 논문에서는 PLMs의 사실적인 지식을 조사하는 방법과 데이터셋에 대해 조사한다.
    3. 저자들은 사실적인 조사 방법과 데이터셋을 주제로 하여, PLMs를 지식 베이스로 사용하기 위해 지식 보존과 prompt 최적화에 대한 연구 방향을 제안한다.

###### Is ChatGPT the ultimate Data Augmentation Algorithm? (https://aclanthology.org/2023.findings-emnlp.1044/)
- Anthology ID: 2023.findings-emnlp.1044 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. GPT-3.5인 ChatGPT의 활용성을 평가하기 위해 zero-shot learning, 새로운 데이터 생성 또는 사람 주석가의 대체와 같은 방법을 사용하여 주석 비용을 절감하는 연구가 이루어져왔다.
    2. ChatGPT를 사용하여 paraphrasing 및 zero-shot 생성으로 새로운 데이터를 생성하고, 이를 다른 7개 알고리즘과 비교한다.
    3. ChatGPT는 어떤 간단한 데이터에서는 탁월한 성능을 보이지만, 전반적으로 다른 알고리즘보다 더 우수한 성능을 보이지 않으며, 민감한 내용으로 인해 종종 답변을 거부하는 경향이 있기 때문에 실무자에게 더 큰 부담을 요구한다.

###### Enhanced Simultaneous Machine Translation with Word-level Policies (https://aclanthology.org/2023.findings-emnlp.1045/)
- Anthology ID: 2023.findings-emnlp.1045 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 SiMT (Simultaneous Machine Translation) 분야에서는 번역 과정의 각 단계마다 READ할지, WRITE할지를 결정하는 정책들의 도입으로 주목할 만한 발전이 있었다. 그러나 많은 기존 연구에서는 subword 단위에서 연산이 수행되는 것으로 가정하고 있으나, 대부분의 실제 시나리오에서는 입력과 출력의 표준 단위가 보통 단어 수준이기 때문에, 이 논문에서 subword 단위에서 개발 및 검증된 정책이 단어 수준에서 작동하는 정책에 비해 훌륭하다는 것을 증명하였다.
    2. 또한, 논문에서는 언어 모델(LMs)을 사용하여 SiMT 모델을 향상시키는 방법을 제안하였는데, 이때 제안된 단어 수준 정책은 LMs와 SiMT 모델 간의 subword 차이를 해결하는데 핵심적인 역할을 한다.
    3. WordSiMT의 코드는 https://github.com/xl8-ai/WordSiMT에서 확인할 수 있다.

###### Causal Intervention-based Few-Shot Named Entity Recognition (https://aclanthology.org/2023.findings-emnlp.1046/)
- Anthology ID: 2023.findings-emnlp.1046 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "작은 수의 labeled 샘플로 새로운 entity 클래스를 인식하는 few-shot NER 시스템은 abundant한 데이터셋에 비해 overfitting 문제를 직면한다."
    2. "우리는 spurious correlation으로부터 발생하는 이 overfitting 문제를 해결하기 위해 인과적 개입 기반 few-shot NER 방법을 제안한다."
    3. "우리의 실험 결과는 우리의 접근법이 새로운 최고 성능을 달성한다는 것을 보여준다."

###### TADI: Topic-aware Attention and Powerful Dual-encoder Interaction for Recall in News Recommendation (https://aclanthology.org/2023.findings-emnlp.1047/)
- Anthology ID: 2023.findings-emnlp.1047 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 뉴스 추천 시스템에서 뉴스 리콜은 사용자의 관심에 따라 뉴스를 추천하는 중요한 부분이다. 기존 뉴스 리콜 연구들은 모든 단어를 동일하게 인코딩하는 문제와 관련 단어의 혼란을 해결하지 못한다. 하지만, TADI 모델은 뉴스 주제에 따라 단어들에 가중치를 부여하여 관련 단어 중요도 문제를 해결한다.
    2. TADI는 Dual-encoder Interaction (DI)이라 불리는 강력한 상호작용 모듈을 제공하여 두 개의 인코더가 강력하게 상호작용하도록 한다. DI는 두 개의 보조 타겟을 기반으로 강력한 상호작용을 도와준다.
    3. 다양한 실험을 통해 TADI와 최신 기법들을 비교한 결과, TADI의 효과를 확인하였다.

###### Unveiling the Power of Argument Arrangement in Online Persuasive Discussions (https://aclanthology.org/2023.findings-emnlp.1048/)
- Anthology ID: 2023.findings-emnlp.1048 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 이전의 온라인 토론에 대한 연구는 개별 댓글을 조사하고 토론의 상호 작용적인 성격을 무시하는 경향이 있다. 
    2. 이 논문에서는 개별 댓글을 의미론적인 논쟁 단위의 시퀀스로 표현하며, 논평이 상반된 관점에 대한 논쟁을 해결하는 것은 필수적이므로, 이 모델을 확장하여 다양한 논쟁 배열 패턴으로 타입 시퀀스를 군집화하고 토론을 이러한 패턴의 시퀀스로 표현한다.
    3. 이러한 패턴 시퀀스는 토론의 전반적인 구조를 포착하는 논쟁 전략의 상징적인 표현이며, 이 새로운 접근 방식을 통해 Change My View 온라인 토론 포럼의 34,393개의 토론에서 전략을 심층 분석하여, 우리의 토론 모델이 신뢰성 예측에 효과적임을 보여주었고, LLM 기반 분류기를 능가하였다.

###### FFAEval: Evaluating Dialogue System via Free-For-All Ranking (https://aclanthology.org/2023.findings-emnlp.1049/)
- Anthology ID: 2023.findings-emnlp.1049 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 오픈 도메인 대화 시스템 평가는 아직 미해결된 문제이다. 자동 평가 메트릭은 대화 생성 작업에서 인간 평가와의 상관관계가 낮다. 본 연구에서는 FFAEval이라는 신뢰성과 효율성을 갖춘 인간 평가 프레임워크를 제안한다.
    2. 이 프레임워크는 대화 기록을 공유함으로써 평가자들이 여러 대화 시스템과 동시에 다중 턴으로 대화할 수 있도록 한다.
    3. FFAEval은 기존 평가 방법에 비해 점수 기반 인간 평가와 강한 상관관계를 가지며, 효율성과 안정성을 증명한 추가 실험도 진행되었다.

###### Orca: A Few-shot Benchmark for Chinese Conversational Machine Reading Comprehension (https://aclanthology.org/2023.findings-emnlp.1050/)
- Anthology ID: 2023.findings-emnlp.1050 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대화식 기계 독해(CMRC) 태스크는 대화에서의 질문에 대답하는 것을 목표로 하며, 폭넓은 응용 분야로 인해 최근 연구 주제로 떠오르고 있다. 
    2. 하지만 기존의 CMRC 벤치마크는 각 대화마다 정적인 Passage를 할당받기 때문에 실제 시나리오와 일치하지 않아 모델의 이해력을 합리적으로 평가하기 어렵다.
    3. 이 논문에서는 실제 시나리오와 일치하도록 Conversational Knowledge-driven Comprehension Benchmark (Orca)를 제안하고, 다양한 도메인에 대한 모델의 일반화 능력을 평가하기 위해 제로샷/퓨샷 설정도 제공한다.

###### VER: Unifying Verbalizing Entities and Relations (https://aclanthology.org/2023.findings-emnlp.1051/)
- Anthology ID: 2023.findings-emnlp.1051 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 실제 세계에서 개체와 개체 간의 관계는 매우 중요하다. 우리는 개체와 관계를 이해함으로써 세계를 이해한다. 이 논문에서는 VER: Verbalizing Entities and Relations을 제안하여 개체와 관계를 문장으로 표현하는 모델을 구축한다.
    2. 우리의 모델은 임의의 개체 또는 개체 집합을 입력으로 받아서 개체와 관계를 표현하는 문장을 생성한다. 실험 결과, 우리의 모델은 개체와 개체 관계를 높은 품질의 문장으로 표현할 수 있으며, 정의 모델링, 관계 모델링 및 생성적 상식 추론과 같은 다양한 개체 및 관계 작업을 용이하게 한다.
    3. 이 모델은 사전을 참조하는 것과 같이 사람들이 개체와 관계를 이해하기 위해 자연어 설명을 활용하고, 개체 간의 관계를 표현하기 위해 문장을 생성하는 방법을 사용한다.

###### The Linearity of the Effect of Surprisal on Reading Times across Languages (https://aclanthology.org/2023.findings-emnlp.1052/)
- Anthology ID: 2023.findings-emnlp.1052 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "심리 언어학에서는 '놀람 이론'이라는 것이 있는데, 사람이 문맥에 따라 단어를 처리하는데 사용하는 노력은 해당 단어의 놀람과 긍정적으로 상관관계를 가진다고 한다."
    2. "이 논문에서는 이전 연구들이 영어에 초점을 맞춰 조사한 놀람의 독서 시간에 대한 선형성을 보완해서, 7개의 언어(덴마크어, 네덜란드어, 영어, 독일어, 일본어, 중국어, 러시아어)의 시선 추적 말뭉치를 분석하는 것으로 연장한다."
    3. "우리는 일부 언어에서 초선형성을 관찰할 수 있었으나, 결과는 놀람을 추정하기 위해 어떤 언어 모델을 사용했느냐에 따라 크게 영향을 받는다."

###### Adversarial Text Generation by Search and Learning (https://aclanthology.org/2023.findings-emnlp.1053/)
- Anthology ID: 2023.findings-emnlp.1053 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 연구에서는 텍스트 공격 방법을 사용하여 자연어 처리 모델의 강건성을 평가하는 것이 중요하다는 것이 밝혀졌습니다. 그러나 대부분의 기존 텍스트 공격 방법은 단어 수준에서 대체 단어를 생성하기 위해 휴리스틱 대체 전략 또는 언어 모델만을 사용합니다. 공격 성공률을 높이는 맹목적 추구는 생성된 적대적인 텍스트의 품질을 보장하기 어렵게 합니다.
    2. 이 연구는 블랙 박스 텍스트 공격을 비지도 텍스트 생성 문제로 처리하고, 검색과 학습을 통한 Adversarial Text Generation by Search and Learning (ATGSL)를 위한 검색 및 학습 프레임워크를 제안합니다. 이를 위해 세 가지 적대적 공격 방법(ATGSL-SA, ATGSL-BM, ATGSL-FUSION)을 개발합니다.
    3. 우리는 우선 휴리스틱 검색 공격 알고리즘 (ATGSL-SA)과 언어 동의어집을 적용하여 의미적 유사성이 높은 적대적 샘플을 생성합니다. 그 후 이 과정을 거치고 검색 노이즈를 완화하면서 검색 결과로부터 조건부 생성 모델을 학습시킵니다. 또한 텍스트 생성기를 기반으로 효율적인 ATGSL-BM 공격 알고리즘을 설계합니다. 더 나아가 ATGSL-SA와 ATGSL-BM의 장점을 통합하여 공격 효과를 높이는 하이브리드 공격 방법 (ATGSL-FUSION)을 제안합니다. 제안된 공격 알고리즘은 공격 효율성과 적대적 텍스트 품질 측면에서 가장 진보된 방법보다 크게 우수합니다.

###### Measuring Pointwise 𝒱-Usable Information In-Context-ly (https://aclanthology.org/2023.findings-emnlp.1054/)
- Anthology ID: 2023.findings-emnlp.1054 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. "인-컨텍스트 학습 (ICL)은 대규모 언어 모델의 발전과 함께 인기있는 새로운 학습 패러다임이다. 본 연구에서는 최근 제안된 hardness metric인 pointwise 𝒱-usable information (PVI)를 인-컨텍스트 버전으로 적용한다. 인-컨텍스트 PVI는 원래 PVI에 비해 더 효율적으로 동작하며 몇 개의 예시만을 필요로 하고 fine-tuning이 필요하지 않는다."
    2. "우리는 인-컨텍스트 PVI의 신뢰성을 평가하기 위해 포괄적인 실험 분석을 수행하였다. 결과로써, 인-컨텍스트 PVI 추정치가 원래 PVI와 유사한 특성을 가짐을 보였다. 특히 인-컨텍스트 환경에서 인-컨텍스트 PVI 추정치는 다양한 예시 선택 및 샷 수에 걸쳐 일관성을 유지한다는 것을 보여준다."
    3. "또한, 우리는 인-컨텍스트 PVI를 활용하여 어려운 문제를 식별하는 방법을 보여준다. 우리의 연구는 인-컨텍스트 PVI의 잠재력을 강조하며 ICL의 능력에 대한 새로운 통찰력을 제시한다."

###### SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities (https://aclanthology.org/2023.findings-emnlp.1055/)
- Anthology ID: 2023.findings-emnlp.1055 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Multi-modal large language models은 AGI 달성을 위한 중요한 단계로 간주되고, Cascade 패러다임으로 동작하는 현재의 음성-언어 모델들은 inter-modal 지식 전달을 방해한다. 
    2. 본 논문에서는 SpeechGPT라는 큰 규모의 다중 모달 언어 모델을 제안하며, 이 모델은 다중 모달 콘텐츠를 인식하고 생성할 수 있는 내재적인 교차 모달 대화 능력을 갖춘다. 
    3. 실험 결과는 SpeechGPT가 교차 모달 인간 지시를 따라갈 수 있는 능력을 갖추고, 하나의 모델로 여러 모달리티를 다룰 수 있는 잠재력을 강조한다.

###### Unleashing the Multilingual Encoder Potential: Boosting Zero-Shot Performance via Probability Calibration (https://aclanthology.org/2023.findings-emnlp.1056/)
- Anthology ID: 2023.findings-emnlp.1056 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 사전 학습된 다국어 인코더 모델은 크로스-언어 작업이나 언어 분석을 할 수 있는데, 라벨 단어를 예측하여 모델 매개변수를 갱신할 필요 없이 입력 예시를 클로즈 스타일로 바꾸면 된다.
    2. 그러나 이 방법의 성능은 사전 학습 단계에서 빈도가 높은 라벨 단어를 예측하는 모델의 편향으로 인해 제한된다.
    3. 우리는 이 문제를 해결하기 위해 모델이 예측하는 라벨 단어의 확률을 수정하는 보정 기법을 사용하였고, 이러한 보정 기법을 적용한 다국어 인코더는 다양한 작업에서 상당한 성능 향상을 보였다.

###### A Thorough Examination on Zero-shot Dense Retrieval (https://aclanthology.org/2023.findings-emnlp.1057/)
- Anthology ID: 2023.findings-emnlp.1057 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 최근 강력한 pre-trained language models (PLM)를 기반으로 한 dense retrieval (DR)은 벤치마크 데이터셋에서 우수한 성능을 보여주었으나, zero-shot retrieval 설정에서는 전통적인 sparse retrieval 모델 (예: BM25)보다 경쟁력이 부족하다는 것이 밝혀져 있다.
    2. 이 연구에서는 DR 모델의 zero-shot 능력에 대한 철저한 분석을 제시한다. 출처 트레이닝 세트와 관련된 여러 핵심 요소의 영향, 대상 데이터셋으로부터의 잠재적 편향, 그리고 기존의 zero-shot DR 모델들을 분석하고 비교한다.
    3. 이 연구 결과는 zero-shot DR 모델을 이해하고 발전시키기 위한 중요한 증거를 제시한다.

###### Contrastive Pre-training for Personalized Expert Finding (https://aclanthology.org/2023.findings-emnlp.1058/)
- Anthology ID: 2023.findings-emnlp.1058 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. Community Question Answering (CQA)에서는 전문가를 신속하게 찾아 특정 질문에 답변할 수 있는 능력이 중요하다. 따라서 질문 텍스트 기사에 따라 전문가와 질문의 정확한 표현을 학습하는 것이 필수적이다.
    2. 이 논문에서는 미세 조정(fine-tuning) 방식으로 사전 교육(pre-training)된 모델을 사용하여 CQA를 위한 Contrastive Pre-training framework for Expert Finding (CPEF)을 제안한다.
    3. 실험 결과, CPEF 방법론은 다양한 실제 데이터셋에서 우수한 성능을 달성할 수 있음을 보여준다.

###### Mitigating Intrinsic Named Entity-Related Hallucinations of Abstractive Text Summarization (https://aclanthology.org/2023.findings-emnlp.1059/)
- Anthology ID: 2023.findings-emnlp.1059 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 추상적 텍스트 요약은 중요하면서도 도전적인 과제이다. 이 논문은 최근 연구 결과, 추상적 요약은 여전히 다양한 형태의 환각(hallucination)에 직면하고 있으며, 그 중 상당 부분은 named entity와 관련이 있다는 것을 보여준다.
    2. 데이터에 내재된 확실한 원인은 복잡하며 학습 조건 역시 다양하다. 이 논문은 데이터가 제기하는 다양한 학습 조건을 해결하기 위해 두 가지 entity-alignment 학습 방법을 제안한다.
    3. 실험 결과, 우리의 방법은 사용된 기준 모델과 비교하여 자동 평가 점수를 향상시켰다. 인간 평가도 우리의 방법이 사용된 기준 모델과 비교하여 내재적 named entity와 관련된 환각을 상당히 감소시킨다는 것을 보여준다.

###### Towards Informative Few-Shot Prompt with Maximum Information Gain for In-Context Learning (https://aclanthology.org/2023.findings-emnlp.1060/)
- Anthology ID: 2023.findings-emnlp.1060 
- Volume: Findings of the Association for Computational Linguistics: EMNLP 2023 
- Summary: 
    1. 대용량 언어 모델은 적은 수의 샘플을 기반으로 새로운 downstream 태스크에서 사례 기반 학습을 수행할 수 있는 능력을 가지고 있지만, 이러한 학습 패러다임은 입력 분포, 샘플의 순서, 프롬프 형식과 같은 요인들에 의해 유발되는 variance 때문에 불안정하다.
    2. 이 논문은 이러한 요인들을 일정하게 유지해도, 랜덤으로 선택된 샘플은 여전히 높은 variance를 보인다는 것을 보여준다. 따라서 우리는 주어진 예제 후 예측을 통해 얻은 정보 이득을 측정하여 정보 이득이 최대인 샘플을 샘플링하도록 제안한다.
    3. 또한, 우리는 템플릿 편향의 존재를 확인하였으며, 이는 샘플링 과정에서 정보 이득의 공정한 평가를 방해할 수 있다. 이 편향을 완화하기 위해 Calibration Before Sampling 전략을 제안한다. 실험 결과는 우리의 제안 방법이 여섯 개의 분류 작업에서 세 가지 LLM 모델을 사용하여 평균 상대 개선율 14.3%를 제공할 수 있음을 보여준다.

## Proceedings of ArabicNLP 2023
###### Proceedings of ArabicNLP 2023 (https://aclanthology.org/2023.arabicnlp-1.0/)
- Anthology ID: 2023.arabicnlp-1.0 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Violet: A Vision-Language Model for Arabic Image Captioning with Gemini Decoder (https://aclanthology.org/2023.arabicnlp-1.1/)
- Anthology ID: 2023.arabicnlp-1.1 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이미지 캡셔닝은 다양한 응용 분야에서 사용될 수 있으나, 영어 이외의 언어에서는 아직까지 충분한 발전을 이루지 못했다. 특히, 아랍어 같은 경우 4억 명 이상의 사용자가 사용하는 모국어임에도 불구하고 이 분야에서 크게 무시되었다. 
    2. 이 논문에서는 아랍어에 특화된 새로운 비전-언어 모델인 Violet을 제안한다. Violet은 비전 인코더와 Gemini 텍스트 디코더로 구성되어 있으며, 비전과 언어 구성 요소 사이의 융합을 허용하면서도 캡션 생성의 유창성을 유지한다.
    3. Violet은 기존의 베이스 라인보다 모든 평가 데이터셋에서 큰 개선을 보이며, 수동 주석 달린 데이터셋에서 61.2의 CIDEr 점수를 달성하며 Flickr8k에서 13점의 개선을 이뤄냈다.

###### Nâbra: Syrian Arabic Dialects with Morphological Annotations (https://aclanthology.org/2023.arabicnlp-1.2/)
- Anthology ID: 2023.arabicnlp-1.2 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문은 스와이어 아라비아 (Syrian Arabic) 방언의 형태학적 주석이 달린 다양한 코퍼스 (corpora)인 Nâbra를 제시한다.
    2. Nâbra는 여러 소스 (소셜 미디어 게시글, 영화 및 시리즈 대본, 노래 가사, 지역 속담 등)에서 수집된 6,000개 이상의 문장과 약 60,000개의 단어로 이루어져 있다.
    3. 9명의 주석가들이 문맥에 따른 완전한 형태학적 주석을 통해 60,000개의 토큰을 주석 처리하였고, F1과 𝜅 일치도 점수가 74%에서 98%까지 다양한 기능들에서 나타나며, Nâbra 주석의 높은 품질을 보여준다.

###### HICMA: The Handwriting Identification for Calligraphy and Manuscripts in Arabic Dataset (https://aclanthology.org/2023.arabicnlp-1.3/)
- Anthology ID: 2023.arabicnlp-1.3 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 약 3억 1,300만 명 이상의 사용자를 보유하고 있는 아라비아어는 전 세계에서 가장 많이 사용되는 언어 중 하나이다. 아라비아어 필기체는 서예 및 다양한 스타일의 필기체가 사용되는 특징이 있다. 본 논문에서는 아라비아어 필기체와 콜리그라피 텍스트에 대한 실제 데이터셋인 Handwriting Identification of Manuscripts and Calligraphy in Arabic (HICMA)를 공개적으로 첫 번째로 제안하고 있다.
    2. HICMA 데이터셋은 다양한 스타일의 실제 아라비아어 필기체 텍스트를 포함하며, 각 이미지에는 이미지-텍스트 쌍과 스타일 레이블이 포함되어 있다.
    3. HICMA 데이터셋은 현재 최고 수준의 아라비아어 광학 문자 인식 모델들과의 성능 비교를 제시하며, 앞으로의 연구에 대한 기준으로 사용될 수 있다. 이 데이터셋과 평가 도구는 CC BY-NC 4.0 라이선스로 공개되었으며, 이를 통해 복잡한 아라비아어 텍스트 인식의 향상을 위한 문을 열 수 있는 기회가 되길 바란다.

###### Automated De-Identification of Arabic Medical Records (https://aclanthology.org/2023.arabicnlp-1.4/)
- Anthology ID: 2023.arabicnlp-1.4 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 전자 의료 기록 (EHR)이 전 세계적으로 퍼지면서 (아랍어권 국가를 포함하여) 환자의 개인정보 보호와 데이터를 연구와 질적 향상에 활용하기 위한 이중 요구가 늘고 있다. 
    2. 본 논문은 아랍어에 특화된 의료 텍스트를 위한 자동 디-식별 파이프라인을 소개한다. 이는 개인 정보를 식별하기 위한 정확한 의료명 사전 인식(NER), 민감한 entities를 가짜 entities로 대체하는 데이터 은닉 모델 및 대형 데이터셋에서도 네이티브로 확장할 수 있는 구현을 포함한다. 
    3. 실험 결과, 이 파이프라인은 17가지 민감한 entities에서 테스트 데이터셋에 대해 0.94에서 0.98까지 미세 F1 스코어를 보여주어, 전문가에 의한 수동 디-식별과 비슷한 정확도를 달성함을 보여준다. 이는 자동 및 확장 가능한 프로세스가 가능해졌다는 것을 시사한다.

###### ArTST: Arabic Text and Speech Transformer (https://aclanthology.org/2023.arabicnlp-1.5/)
- Anthology ID: 2023.arabicnlp-1.5 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. ArTST는 아랍어 텍스트 및 음성 변환기로, 오픈 소스 아랍어 음성 기술을 지원하기 위해 개발되었다. 
    2. 이 모델은 통합된 모델의 구조를 따르며, Modern Standard Arabic(MSA)에 중점을 두고 있으며, 향후에는 사투리 및 코드 스위치된 아랍어를 위한 확장된 버전도 제공할 예정이다.
    3. 실험 결과, ArTST는 SpeechT5와 기존의 결과와 비교하여 세 가지 작업에서 현재 최고 수준과 동등하거나 그 이상의 성능을 보였으며, 특히 저자원 환경에서의 TTS 작업에는 일반화가 쉽게 이루어진다는 것을 확인하였다.

###### TARJAMAT: Evaluation of Bard and ChatGPT on Machine Translation of Ten Arabic Varieties (https://aclanthology.org/2023.arabicnlp-1.6/)
- Anthology ID: 2023.arabicnlp-1.6 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. ChatGPT와 Bard와 같은 instruction-finetuned large language model (LLM)은 다국어 능력이 있다고 주장되었지만, 이러한 모델의 언어 포용력은 부족하게 연구되고 있다.
    2. 본 연구에서는 Bard와 ChatGPT (GPT-3.5와 GPT-4 모두 포함)의 기계 번역 능력을 아랍어의 10가지 다양한 변형들에 대해 철저히 평가한다.
    3. 연구 결과, LLMs는 공개 데이터셋이 제한적인 방언에 대해서는 어려움을 겪을 수 있지만, 평균적으로는 기존 상용 시스템보다 우수한 번역자로 나타났다. 그러나 Classical Arabic (CA)와 Modern Standard Arabic (MSA)에 대해서는 Google Translate와 같은 상용 시스템보다 뒤쳐지는 결과를 나타냈다.

###### Leveraging Domain Adaptation and Data Augmentation to Improve Qur’anic IR in English and Arabic (https://aclanthology.org/2023.arabicnlp-1.7/)
- Anthology ID: 2023.arabicnlp-1.7 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 본 연구에서는 neural IR에서 콰란 관련 정보 검색 문제를 다룬다. domain-specific 데이터 부족 문제를 해결하기 위해 큰 양의 일반 domain 데이터로 학습한 후 in-domain 데이터로 추가 학습한다. 데이터 증강 기술을 사용하여 MRR@10 및 NDCG@5 지표에서 뚜렷한 개선을 이루어 분야 최첨단 수준의 콰란 정보 검색 결과를 얻었다.
    2. 영어와 아랍어 모두에서 콰란 정보 검색을 위한 Islamic corpus 및 domain-specific model이 구축되지 않은 상황에서, 이러한 리소스의 부족 문제에 대응하기 위해 Islamic corpus 컴파일 및 domain-specific language model (LM) 사전 학습을 수행하였다.
    3. 콰란 정보 검색 작업에서 공유하는 공통 백본으로 domain-specific LM을 사용하는 검색 모델의 성능을 향상시키기 위해, 효과적으로 콰란 정보 검색 작업을 수행하는 Arabic 언어 모델을 선택하기 위한 실험들을 수행하였다. 또한, Arabic 검색 작업에 대한 부족한 일반 domain 데이터를 학습에 활용하기 위해 영어에서 성공적인 실험을 아랍어로 확장한 실험들을 수행하였다.

###### LANS: Large-scale Arabic News Summarization Corpus (https://aclanthology.org/2023.arabicnlp-1.8/)
- Anthology ID: 2023.arabicnlp-1.8 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 텍스트 요약은 여러 언어에서 꾸준히 연구되어 왔지만, 아랍어 텍스트 요약은 아직 초기 단계에 있다. 기존의 ATS 데이터셋은 작거나 다양성이 부족하다. 
    2. 우리는 LANS라는 대규모이며 다양성이 있는 아랍어 텍스트 요약 데이터셋을 구축했다. LANS는 1999년부터 2019년까지 신문 사이트의 메타데이터에서 추출한 840만 건의 기사와 요약을 제공한다. 
    3. LANS의 내재적 평가를 자동 및 인간 평가로 수행하였고, 1,000개의 랜덤 샘플의 인간 평가는 수집한 요약문에 대해 95.4%의 정확도를 보고하였으며, 자동 평가는 요약문의 다양성과 추상성을 측정하였다.

###### Beyond English: Evaluating LLMs for Arabic Grammatical Error Correction (https://aclanthology.org/2023.arabicnlp-1.9/)
- Anthology ID: 2023.arabicnlp-1.9 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 최근에는 인간의 지침을 따르도록 조정된 대형 언어 모델 (LLM)이 다양한 영어 NLP 태스크에서 상당한 능력을 보이고 있으나, 문법 오류 수정 (GEC)에서의 성능은 아직 충분히 탐구되지 않았다. 
    2. 본 연구에서는 풍부한 형태론 때문에 어려운 작업인 아라비아어 GEC에서 지시사 전달된 LLM의 능력을 평가했다. 
    3. 여러 가지 프롬프트 방법과 (in-context) few-shot learning을 결합한 결과, GPT-4는 전문가 프롬프트에서 65.49 F1 점수를 달성하며 (기존 베이스라인 대비 약 5점 높음), 양질의 결과를 보였다.

###### Aswat: Arabic Audio Dataset for Automatic Speech Recognition Using Speech-Representation Learning (https://aclanthology.org/2023.arabicnlp-1.10/)
- Anthology ID: 2023.arabicnlp-1.10 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 최근의 자기 지도 음성 표현 학습을 통한 자동 음성 인식 (ASR) 접근법은 저렴한 데이터 라벨링으로 많은 벤치마크 결과를 크게 개선시켰다. 
    2. 본 논문에서는 wav2vec 및 data2vec라는 두 개의 자기 지도 프레임워크를 ASR에 대해 훈련시키고, 결과를 분석함으로써 여러 가지 실험을 수행한다. 
    3. 또한, 아랍어 ASR에서 낮은 단어 오류율(WER)을 달성하기 위해 사전 훈련 작업에 사용할 수 있는 732시간의 아랍어 발화가 포함된 Aswat 데이터셋을 소개한다.

###### Analyzing Multilingual Competency of LLMs in Multi-Turn Instruction Following: A Case Study of Arabic (https://aclanthology.org/2023.arabicnlp-1.11/)
- Anthology ID: 2023.arabicnlp-1.11 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 다양한 작업에 대한 대형 언어 모델의 평가는 상당한 진전이 이루어져 왔으나, 아라비아어와 같이 적게 테스트된 언어로 여러 단계의 지시에 대한 응답 능력은 체계적으로 평가되지 않았다.
    2. 본 논문은 아라비아어에서의 이러한 시나리오에서 오픈 LLM의 능력을 상세히 조사한다. 
    3. 우리는 다양한 개방형 작업에서 LLM의 성능을 평가하고 비교하기 위해 MT-Bench 벤치마크 스위트의 아라비아어 버전을 사용하여 GPT-4를 사용한다는 것을 밝혀냈다.

###### Cross-Dialectal Named Entity Recognition in Arabic (https://aclanthology.org/2023.arabicnlp-1.12/)
- Anthology ID: 2023.arabicnlp-1.12 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 본 논문에서는 아랍 언어 사이의 Named Entity Recognition (NER) 모델의 전이성에 대해 연구하였다. MSA와 같이 풍부한 데이터셋이 없는 다른 아랍 언어 사이에서 MSA에서 훈련된 NER 모델이 어떻게 수행되는가에 대한 질문이 중요하다.
    2. 연구자들은 MSA 데이터셋에서 미리 훈련된 언어 모델의 위에 span-based NER 모델을 훈련시켜 다른 데이터셋에서의 성능을 zero-shot 설정에서 연구하였다.
    3. 여러 프리트레인된 언어 모델 인코더들의 성능을 연구한 결과, 주석 작업 없이도 허용 가능한 수준의 성능을 달성함을 보였다.

###### Enhancing Arabic Machine Translation for E-commerce Product Information: Data Quality Challenges and Innovative Selection Approaches (https://aclanthology.org/2023.arabicnlp-1.13/)
- Anthology ID: 2023.arabicnlp-1.13 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 전자 상거래에서 제품 정보는 보통 기계 번역(MT) 시스템을 사용하여 현지화된다. 
    2. 이 논문에서는 아라비아어 MT의 품질 문제를 해결하기 위해 수집한 데이터의 품질을 주기적으로 확인하기 위한 방법을 제안한다. 
    3. 제안된 방법은 온라인 및 오프라인 실험에서 효과적으로 작동하며, 고객들에게 더 나은 쇼핑 경험을 제공한다.

###### IDRISI-D: Arabic and English Datasets and Benchmarks for Location Mention Disambiguation over Disaster Microblogs (https://aclanthology.org/2023.arabicnlp-1.14/)
- Anthology ID: 2023.arabicnlp-1.14 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 소셜 미디어 데이터에서 지리 정보를 추출하고 해석하는 것은 재난 관리에 효과적으로 도움을 준다. 그러나 자원과 도구의 부족으로 인해 재난 관리 영역에서 Location Mention Disambiguation (LMD) 모델의 개발과 평가가 어려워진다.
    2. 이 논문은 최대 규모의 영어 및 처음으로 아라비아어 공개 LMD 데이터셋인 IDRISI-D를 소개한다. 또한, LMD 시스템의 효과적인 평가를 위한 수정된 계층적 평가 프레임워크도 제안한다.
    3. 우리는 대표적인 기준선을 활용하여 IDRISI-D 데이터셋을 평가하고 BERT 기반 모델의 경쟁력을 입증한다.

###### CamelParser2.0: A State-of-the-Art Dependency Parser for Arabic (https://aclanthology.org/2023.arabicnlp-1.15/)
- Anthology ID: 2023.arabicnlp-1.15 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. "CamelParser2.0은 오픈소스 파이썬 기반의 아랍어 의존 구문 분석기로서 Columbia Arabic Treebank (CATiB)와 Universal Dependencies (UD)라는 두 가지 인기 있는 아랍어 의존 구문 형식을 대상으로 한다."
    2. "CamelParser2.0은 raw 텍스트 처리와 토큰화, 형태소 분석 기능 등을 제공한다."
    3. "CamelParser2.0의 개발 과정에서 파싱 모델 아키텍처와 사전 훈련 언어 모델 선택과 같은 시스템 디자인 하이퍼파라미터를 탐구하면서, 골드 및 예측 토큰화 설정에서 다양한 아랍어 장르에서 최고의 성능을 달성하였다."

###### GARI: Graph Attention for Relative Isomorphism of Arabic Word Embeddings (https://aclanthology.org/2023.arabicnlp-1.16/)
- Anthology ID: 2023.arabicnlp-1.16 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. "언어처리에서 한 언어로 훈련된 단어 임베딩 공간을 다른 언어의 임베딩 공간과 밀접하게 연결시켜주는 BLI는 NLP에서 주요한 도전과제 중 하나이다. 기존의 방법들은 서로 다른 임베딩 공간의 상대적 동형성을 조절하기 위해 시도되었지만, 모델 훈련 목적에 의미적으로 관련된 단어들의 영향을 포함시키지 못했다."
    2. "이를 해결하기 위해, 우리는 GARI를 제안한다. GARI는 분포적인 훈련 목적과 그래프 어텐션 네트워크에 의해 도움을 받는 다중 동형성 손실을 결합한다. GARI는 단어의 의미적 변이의 영향을 고려하여 임베딩 공간의 상대적 동형성을 정의한다."
    3. "아라비아어 데이터셋을 사용한 실험적 평가에서 GARI는 기존 연구와 비교하여 도메인 일치 및 일치하지 않는 설정에서 평균 P@1을 증가시켜 상대적인 점수로 최대 40.95%와 76.80%까지 향상시킨다."

###### ArTrivia: Harvesting Arabic Wikipedia to Build A New Arabic Question Answering Dataset (https://aclanthology.org/2023.arabicnlp-1.17/)
- Anthology ID: 2023.arabicnlp-1.17 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 우리는 다양한 주제를 다루는 18,000개 이상의 아라비아어 질문-답변 쌍과 관련 텍스트를 포함하는 아라비아어 질문-답변 데이터셋인 ArTrivia를 제안한다. 
    2. 우리는 아라비아어 위키피디아에서 다양한 구조화된 데이터 소스를 활용하여 데이터셋을 생성했으며, 각 구성 요소의 성능을 평가하기 위해 포괄적인 통계 분석도 수행했다.
    3. 우리의 평가 결과는 답변 정규화와 같은 데이터셋 생성에서 자주 간과되는 측면이 QA 데이터셋의 품질을 향상시키는 데 중요하다는 점을 강조하며, ArTrivia가 TyDi로부터 더 도전적이고 분포와 다른 질문을 제시하여 TyDi의 보완 데이터셋으로 사용하는 것의 타당성에 대해 의문을 제기한다.

###### ArSarcasMoji Dataset: The Emoji Sentiment Roles in Arabic Ironic Contexts (https://aclanthology.org/2023.arabicnlp-1.18/)
- Anthology ID: 2023.arabicnlp-1.18 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문은 아랍어 자연어 처리(NLP)에서의 이모지 이용이 아랍어의 복잡성 때문에 조심스럽게 다뤄진다는 이유로 주의를 기울이는데, 이 맥락에서 이 논문은 24,630개의 이모지가 포함된 텍스트 데이터셋 ArSarcasMoji를 소개한다.
    2. 연구 결과, 우리는 아랍어 텍스트에서 일상화된 특정 이모지 패턴들이 우아크론(irony)을 나타내며, 그들이 갖는 감정 역할에 주의를 기울이는 것이 우아크 텍스트 이해에 이모지의 중요성을 보여주며, 아랍어 디지털 콘텐츠에서 정확한 우아크 탐지의 잠재력을 시사한다.
    3. 이 논문은 아랍어 텍스트에서 이모지가 아이러니를 이해하는 데 있어 중요한 역할을 하는 것을 강조하며, 이모지의 아랍어 디지털 콘텐츠에서의 우아크 감지 정확성의 잠재력에 대해 논한다.

###### Performance Implications of Using Unrepresentative Corpora in Arabic Natural Language Processing (https://aclanthology.org/2023.arabicnlp-1.19/)
- Anthology ID: 2023.arabicnlp-1.19 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 위키피디아 문서는 아랍어와 같은 저자원 언어들을 위한 NLP 연구에서 널리 사용되는 학습 데이터 소스이다. 그러나, 특히 주어진 언어의 많은 항목들이 다른 언어로 직접 번역되거나 자동으로 생성될 때, 이러한 데이터가 원어민의 대표적인 기여를 얼마나 반영하는지 이해하는 것이 중요하다.
    2. 이 논문에서는 위키피디아의 '유기적이지 않은' 데이터가 언어 모델링과 단어 표현과 같은 두 가지 NLP upstream task의 성능에 미치는 영향을 연구한다.
    3. 실험 결과, 좋은 NLP 성능을 위해서는 크고 유기적인 코퍼스가 필요하며, 이 둘 중 하나만으로는 충분하지 않음을 보여준다.

###### Octopus: A Multitask Model and Toolkit for Arabic Natural Language Generation (https://aclanthology.org/2023.arabicnlp-1.20/)
- Anthology ID: 2023.arabicnlp-1.20 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 아라비아어 텍스트의 이해와 인간과 유사한 응답 생성은 어려운 작업이다. 여러가지 연구자들은 개별적인 문제를 위한 모델과 솔루션을 제안했지만, 다양한 작업을 처리할 수 있는 포괄적인 아라비아어 자연어 생성 툴킷의 부족이 있다.
    2. 본 연구에서는 AraT5v2라고 불리는 강력한 아라비아어 텍스트-텍스트 Transformer 모델을 제안한다. 이 모델은 다양하고 폭넓은 데이터로 체계적으로 학습되었으며, 2,048 토큰의 확장된 시퀀스 길이를 사용한다.
    3. 또한, 우리는 새로운 Python 기반의 패키지 및 명령 줄 툴킷인 OCTOPUS를 개발하고 공개하였는데, 이는 하나의 모델을 활용하여 여덟 가지 아라비아어 생성 작업에 대응할 수 있다.

###### AlGhafa Evaluation Benchmark for Arabic Language Models (https://aclanthology.org/2023.arabicnlp-1.21/)
- Anthology ID: 2023.arabicnlp-1.21 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 최근 아라비아어 대용량 언어 모델의 발전으로 실용적인 응용 분야가 많이 개발되었으나, 아라비아어 대용량 언어 모델의 훈련 데이터 부족과 평가 자원의 한정성으로 인해 영어와 비교했을 때 여전히 어려움이 있는 상황이다.
    2. 우리는 이 계속 성장하는 분야에 기여하기 위해 아라비아어 대용량 언어 모델에 대한 새로운 다중 선택지 평가 벤치마크인 AlGhafa를 소개한다. 우리는 공개된 데이터셋과 80억 개의 토큰으로 이루어진 새로운 HandMade 데이터셋을 사용하여 다양한 모델을 훈련시키고, 여러 아라비아어 모델의 독선적 디코더 모델 중 최대인 140억 개의 매개변수 모델을 개발했다.
    3. 마지막으로, 여러 아라비아어 모델의 정량적, 정성적 독성을 탐색하고, 우리 모델을 기존의 공개 아라비아어 대용량 언어 모델과 비교한다.

###### ArBanking77: Intent Detection Neural Model and a New Dataset in Modern and Dialectical Arabic (https://aclanthology.org/2023.arabicnlp-1.22/)
- Anthology ID: 2023.arabicnlp-1.22 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. ArBanking77은 은행 도메인에서 의도 탐지를 위한 큰 규모의 아라비아어 데이터셋이다.
    2. ArBanking77 데이터셋은 원래 영어 Banking77 데이터셋을 아랍어로 번역하여 로컬라이즈하였으며, 77개의 클래스(의도)로 분류된 31,404개의 Modern Standard Arabic (MSA)와 Palestinian dialect의 쿼리가 포함되어 있다.
    3. ArBanking77을 기반으로 fine-tuning된 AraBERT 기반의 신경망 모델은 MSA에서 0.9209, Palestinan dialect에서 0.8995의 F1-score를 달성하였으며, 저자들은 낮은 리소스 환경에서 모델을 실험하였으며, 해당 데이터셋과 모델은 공개적으로 사용할 수 있다고 밝혔다.

###### ArabIcros: AI-Powered Arabic Crossword Puzzle Generation for Educational Applications (https://aclanthology.org/2023.arabicnlp-1.23/)
- Anthology ID: 2023.arabicnlp-1.23 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문은 고급 AI 기술에 의해 구동되는 최초의 아라비아 십자말 퍼즐 생성기를 소개한다. 
    2. GPT4, GPT3-Davinci, GPT3-Curie, GPT3-Babbage, GPT3-Ada, 그리고 BERT와 같은 첨단 언어 모델들을 활용하여 생성기는 독특하고 도전적인 단서들을 만든다.
    3. 교육적인 십자말 퍼즐은 기억력을 향상시키고 어휘력을 확장시키며 문제 해결 능력을 촉진시키는 데 기여하여, 재미있고 매력적인 방식으로 학습 경험을 증진시키며 전통적인 학습 방법의 풍경을 재구성한다.

###### Machine Translation of Omani Arabic Dialect from Social Media (https://aclanthology.org/2023.arabicnlp-1.24/)
- Anthology ID: 2023.arabicnlp-1.24 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. "현대 표준 아랍어(MSA)와 영어 간의 기계 번역(MT)에 대한 연구는 많지만, 오마니 아랍어(OA) 방언과 영어 간의 MT에 대한 연구는 매우 희박하다."
    2. 오만 방언에 대한 병렬 데이터셋의 부족과 OA에서 영어로의 MT에 초점을 맞추는 연구로, 소셜 미디어 데이터를 사용하여 오만 방언의 실제 병렬 텍스트를 구축한다.
    3. 구글 번역, 마이크로소프트 번역 및 Marian NMT를 사용하여 이 데이터셋에 대한 베이스라인 결과를 제시하며, 가장 일반적인 언어적 오류의 분류를 사용하여 NMT 시스템이 번역한 결과를 분석하여 향후 개선 방향을 제시한다. 마지막으로, 오만 방언에 대한 Marian NMT의 전이 학습을 사용하여 BLEU 점수에서 9.88 포인트 향상을 이룩했다.

###### Arabic Fine-Grained Entity Recognition (https://aclanthology.org/2023.arabicnlp-1.25/)
- Anthology ID: 2023.arabicnlp-1.25 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 기존 NER 시스템은 개략적인 entity의 카테고리를 인식하는 데 중점을 두고 있고, 미세한 하위 유형의 entity들에 대한 분류에는 관심이 적다.
    2. 이 논문은 미세한 entity를 고려한 아라비아어 NER를 개선하기 위해 Wojood 데이터셋을 확장한다.
    3. WojoodFine은 Wojood의 GPE, LOC, ORG, FAC 4개의 entity 유형에 31개의 하위 유형을 추가하여 만들어진 도구로, Cohen의 Kappa와 F1 점수를 사용하여 높은 IAA(Inter-Annotator Agreement)를 보였다.

###### Investigating Zero-shot Cross-lingual Language Understanding for Arabic (https://aclanthology.org/2023.arabicnlp-1.26/)
- Anthology ID: 2023.arabicnlp-1.26 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 다양한 언어 배경 사이에서 언어 이해력을 전이(transfer)할 수 있는 가능성을 연구했다. 
    2. 다른 언어들을 훈련시킨 언어 모델들이 아랍어 이해력을 향상시킬 수 있는 것을 실험으로 보였다. 
    3. 특히, 문제 해결과 자연어 추론 같은 과제에서, 러시아어와 같은 풍성한 형태적 특징을 가진 언어들이 아랍어와 유사한 특성을 보였다.

###### Evaluating ChatGPT and Bard AI on Arabic Sentiment Analysis (https://aclanthology.org/2023.arabicnlp-1.27/)
- Anthology ID: 2023.arabicnlp-1.27 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. ChatGPT와 Bard AI와 같은 대형 언어 모델이 다양한 NLP 태스크에서 뛰어난 성능을 발휘하여 큰 관심을 받았다. 그러나 저자들은 이러한 모델들이 저자원 언어와 방언 (예: 영어와 아랍어 방언)에서의 성능을 알아보지 못했다고 말하며, 이 논문에서는 아랍어 방언에 대한 sentiment analysis를 위해 세 가지 LLM을 평가한다.
    2. 저자들은 Saudi dialect Twitter 데이터셋을 사용하여 LLM의 감성 텍스트 분류 및 생성 능력을 평가한다. 그들은 fully fine-tuned Arabic BERT 기반 모델의 분류 성능을 few-shot 설정에서 LLM과 비교하고, 생성된 새로운 감성 샘플의 품질을 인간 및 자동 평가 방법을 사용하여 평가한다.
    3. 실험 결과, GPT-4는 감성 분석 분류에서 GPT-3.5와 Bard AI를 앞지르며, 최고의 fully supervised BERT 기반 언어 모델과 견줄만한 성능을 보였다. 그러나 데이터 생성 측면에서는 수작업으로 주석이 달린 정통 아랍어 텍스트와 비교했을 때 생성 모델이 감성 분석에 적합한 고품질 아랍어 방언 텍스트를 생성하는 데 어려움이 있는 것으로 나타났다.

###### In-Context Meta-Learning vs. Semantic Score-Based Similarity: A Comparative Study in Arabic Short Answer Grading (https://aclanthology.org/2023.arabicnlp-1.28/)
- Anthology ID: 2023.arabicnlp-1.28 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 짧은 답변 평가를 자동화 시스템에 위임함으로써 교사는 핵심적인 비인간 중심 교육 측면에 더 많은 시간을 할애할 수 있으며, 자동 답변 평가 (ASAG)의 연구는 인스턴스 기반 또는 참고 기반 관점에서 문제에 접근하고 있다.
    2. 이 연구에서는 아랍어 ASAG 데이터셋을 사용하여 두 가지 접근 방식을 비교한다. 인스턴스 기반 방법에는 in-context 메타-러닝을 적용하고, 참고 기반 방법에는 시맨틱 점수 기반 유사도를 활용한다.
    3. 결과적으로 두 가지 방법 모두 기준 선을 능가하여 기준점 이상의 성능을 보이지만, 특히 시맨틱 점수 기반 유사도 방법은 제로샷 환경에서 뛰어난 성능을 보여준다.

###### SALMA: Arabic Sense-Annotated Corpus and WSD Benchmarks (https://aclanthology.org/2023.arabicnlp-1.29/)
- Anthology ID: 2023.arabicnlp-1.29 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. SALMA는 국소 자원이 없었던 아라비아어에 대한 첫 번째 의미주석된 말뭉치로, 각 토큰이 의미주석이 되어 있다. 
    2. SALMA는 하나의 토큰이 하나의 의도된 의미에만 연결되는 대신 여러 개의 의미에 연결하고 각 의미마다 점수를 부여하는 형식으로 구성되어 있다. 
    3. SALMA 코퍼스와 주석 도구는 오픈 소스로 제공되며, Word Sense Disambiguation 시스템을 구축하고 성능을 평가하는 데 활용될 수 있다.

###### Arabic dialect identification: An in-depth error analysis on the MADAR parallel corpus (https://aclanthology.org/2023.arabicnlp-1.30/)
- Anthology ID: 2023.arabicnlp-1.30 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 본 논문은 MADAR 병렬 말뭉치를 사용하여 아라비아 사투리 인식 작업에서 최첨단 모델의 성능을 체계적으로 분석하고 비교한다. 사전 훈련된 transformer 언어 모델과 다양한 특성을 갖춘 Naive Bayes 모델 기반 접근 방식을 테스트하였다. 데이터와 오류 분석을 통해 두 가지 접근 방식의 강점과 약점에 대해 유용한 통찰력을 제공한다.
    2. 논문에서는 어떤 사투리가 구별하기 어려운지, 그리고 오류의 잠재적인 원인을 분석하였다. 또한, MADAR-26 말뭉치의 테스트 세트에서 사투리 클래스별로 동일한 문장이 있는 중요한 문제를 발견하였는데, 이는 모든 분류기를 혼동시킬 수 있다. 
    3. 이 연구는 또한 테스트된 접근 방식들이 밀접한 관련이 있는 사투리들 사이의 미묘한 차이를 포착하지 못한다는 것을 보여준다.

###### Arabic Dialect Identification under Scrutiny: Limitations of Single-label Classification (https://aclanthology.org/2023.arabicnlp-1.31/)
- Anthology ID: 2023.arabicnlp-1.31 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 자동 아랍어 방언 식별(ADI) 시스템은 아랍어 마이크로 방언을 구분하기 어렵다고 보고되고 있다. 
    2. 이 논문은 ADI 작업을 단일 레이블 분류 문제로 접근하는 한계를 지적하고, 이것이 ADI 시스템의 평가에 어떻게 영향을 미치는지를 보여준다. 
    3. 따라서, 우리는 ADI를 여러 개의 레이블 분류 작업으로 접근하도록 제안하고, 새로운 ADI 데이터셋을 설계하기 위한 권장 사항을 제시한다.

###### Arabic Topic Classification in the Generative and AutoML Era (https://aclanthology.org/2023.arabicnlp-1.32/)
- Anthology ID: 2023.arabicnlp-1.32 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 최근 아라비아어 주제 분류 모델은 기존의 사전 훈련된 transformer 모델을 활용하고 제한된 수의 카테고리를 대상으로 한다. 
    2. 본 논문에서는 AraboNeClass라는 새로운 아라비아어 데이터셋과 그를 바탕으로한 주제 분류기를 제안한다. 
    3. ArGTClass는 다른 모델들 (Vertex AI, AutoML, AutoTrain) 보다 우수한 성능을 보여주었다.

###### On Enhancing Fine-Tuning for Pre-trained Language Models (https://aclanthology.org/2023.arabicnlp-1.33/)
- Anthology ID: 2023.arabicnlp-1.33 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 자연어 모델의 놀라운 능력은 그들이 다양한 분야에서 널리 사용되는 발판을 마련했으나, 특정 작업에 적용하기 위해서는 시간이 많이 소요되는 미세 조정 과정을 거쳐야 한다.
    2. 우리는 레이어 선택에 대한 매개변수 조작 만으로 제한된 접근법을 제안하여 함께 시간 최적화와 성능 보존 사이의 최적의 균형을 제공하는 레이어를 식별하였다.
    3. 다양한 하위 작업에서 이 접근법을 검증한 결과, 성능을 5% 미만의 무시할 수 있는 편차로 유지하면서 미세 조정 시간을 최대 50%까지 감소시킬 수 있는 잠재성을 보였다.

###### Multi-Parallel Corpus of North Levantine Arabic (https://aclanthology.org/2023.arabicnlp-1.34/)
- Anthology ID: 2023.arabicnlp-1.34 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 저 자원은 Indo-European 언어로 된 문장 120,600개를 다국어로 번역한 것으로, 저자들은 이 자원이 Arabic Machine Translation 연구에 어떻게 기여할 수 있는지 살펴본다.
    2. 이 자료는 Dialectal Arabic에 대한 연구에서 MSA와 dialects을 커버하고 있으며, English, French, German, Greek, Spanish의 여러 언어로 번역되었다.
    3. 훈련 및 세밀한 튜닝 실험을 통해 이 자원이 Arabic MT 연구에 어떻게 기여할 수 있는지 탐색한다.

###### Simplify: Automatic Arabic Sentence Simplification using Word Embeddings (https://aclanthology.org/2023.arabicnlp-1.35/)
- Anthology ID: 2023.arabicnlp-1.35 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 자동 텍스트 단순화는 원래 의미를 보존하면서 언어 복잡성을 단순화하는 것을 의미한다. 이 연구는 아라비아어에 대한 어휘 단순화 시스템을 개발하는데 초점을 맞추고 있다.
    2. FastText와 Arabert 사전 학습된 임베딩 모델을 이용하여 다양한 단순화 모델을 생성했다. 어려운 단어를 식별하고, 대체어들을 생성하며, 문장 내에서 어려운 단어를 대체하기 위한 선택 작업이 이루어졌다.
    3. 우리는 이러한 모델들이 실제로 어려운 단어를 정확하게 식별하고 선택하는데 효과적인지를 BERTScore를 사용하여 평가하였다.

###### Offensive Language Detection in Arabizi (https://aclanthology.org/2023.arabicnlp-1.36/)
- Anthology ID: 2023.arabicnlp-1.36 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. "저해성 언어를 리소스가 제한된 언어에서 탐지하는 것은 소셜 미디어 플랫폼에게 실제적인 도전입니다."
    2. "이 논문은 아라비츠어에서의 저해성 언어 탐지에 초점을 맞춘 첫 번째 연구입니다."
    3. "우리는 다양한 BERT 모델을 사용하여 아라비츠어에서의 저해성 언어 탐지의 가능성을 고도로 정확하게 보였습니다."

###### Yet Another Model for Arabic Dialect Identification (https://aclanthology.org/2023.arabicnlp-1.37/)
- Anthology ID: 2023.arabicnlp-1.37 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문에서는 ADI-5와 ADI-17 이라는 두 가지 벤치마크 데이터셋에서 이전에 발표된 결과를 일관되게 능가하는 아랍어 방언 식별 (ADI) 모델을 설명한다.
    2. ResNet과 ECAPA-TDNN 두 가지 아키텍처 변형과 MFCC와 UniSpeech-SAT Large에서 추출된 기능, 그리고 네 가지 변형을 결합한 퓨전을 탐색한다.
    3. 개별적으로 ECAPA-TDNN 네트워크가 ResNet보다 우수하며, UniSpeech-SAT 기능을 사용한 모델이 MFCC 기능을 사용한 모델을 큰 폭으로 능가하는 것을 발견한다. 또한, 네 가지 변형의 퓨전은 일관되게 개별 모델보다 우수한 성능을 보여준다. 최상의 모델들은 ADI-5와 ADI-17에서 각각 84.7%와 96.9%의 정확도로 이전에 보고된 결과를 능가한다.

###### VoxArabica: A Robust Dialect-Aware Arabic Speech Recognition System (https://aclanthology.org/2023.arabicnlp-1.38/)
- Anthology ID: 2023.arabicnlp-1.38 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 아랍어는 세계적으로 약 4억 5천만 명이 사용하는 많은 다양한 다이얼렉트와 변형이 있는 언어이다. 언어적 다양성 때문에 아랍어에 대한 강력하고 일반화된 자동 음성 인식 (ASR) 시스템을 구축하는 것은 어렵다. 
    2. 이 논문에서는 아랍어의 다이얼렉트 인식 (DID)과 ASR을 위한 VoxArabica 시스템을 개발하고 시연한다. DID 모델은 MSA를 포함한 17개의 다이얼렉트를 식별하기 위해 훈련되었고, ASR 모델은 MSA, 이집트어, 모로코어 및 혼합 데이터로 미세조정되었다.
    3. VoxArabica는 다양한 기능을 갖춘 단일 웹 인터페이스로 통합되어 있으며, 오디오 녹음, 파일 업로드, 모델 선택 및 잘못된 출력에 대한 깃발을 올릴 수 있는 옵션 등의 기능을 제공한다. 이 시스템은 아랍어 연구에 관심있는 다양한 사용자에게 유용할 것으로 기대된다.

###### KSAA-RD Shared Task: Arabic Reverse Dictionary (https://aclanthology.org/2023.arabicnlp-1.39/)
- Anthology ID: 2023.arabicnlp-1.39 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문은 아랍어를 위한 Reverse Dictionary(RD) 시스템을 개발하기 위한 KSAA-RD 공유 작업에 대해 개요를 제시한다. 
    2. RD는 사용자가 의미나 정의를 기반으로 단어를 찾을 수 있게 해준다.
    3. 이 공유 작업에는 아랍어 RD와 다국어 반대 사전(CLDR) 두 가지 하위 작업이 포함되어 있으며, 각 팀은 대응하는 단어의 가장 유사한 단어 임베딩을 찾기 위해 경쟁한다.

###### UWB at Arabic Reverse Dictionary shared task: Computing the meaning of a gloss (https://aclanthology.org/2023.arabicnlp-1.40/)
- Anthology ID: 2023.arabicnlp-1.40 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. MCQ 생성에 대한 기존 평가 메트릭은 교육적 가치를 고려하지 않으며, 새로운 평가 메트릭 KDA는 대답 가능성과 대상 사실에 대한 학생의 지식을 평가하고 이들과의 강한 상관관계를 보여줍니다.
    2. 최근의 deep model은 NLP 태스크에서 뛰어난 정확성을 보이지만, spurious pattern에 의존하고 있다는 문제가 있습니다. 이 논문에서는 counterfactual augmentation과 contrastive learning을 통해 robustness를 향상시키고 다양한 차원에서 개선되었습니다.
    3. 단어들의 인과관계를 파악하기 위해 여러 개의 counterfactual을 생성하고, 집합적 의사 결정을 통해 더 robust한 방법을 제안합니다.

###### Qamosy at Arabic Reverse Dictionary shared task: Semi Decoder Architecture for Reverse Dictionary with SBERT Encoder (https://aclanthology.org/2023.arabicnlp-1.41/)
- Anthology ID: 2023.arabicnlp-1.41 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 역사전은 특정 개념에 대한 설명 문구를 입력하면 해당 문구와 일치하는 단어와 정의를 반환한다. 많은 역사전이 영어와 같은 언어에 맞춰져 있고 온라인에서 쉽게 이용할 수 있지만 아랍어에 대한 비슷한 자원은 부족하다. 
    2. 이 논문은 아랍어 역사전에 대한 공유 작업에 참여한 내용을 소개한다. 제안된 방법은 두 가지 주요 단계로 구성되며, 첫 번째로 단어 정의를 다차원 벡터로 변환한다. 그런 다음 이러한 인코딩된 벡터를 목표 작업에 대해 Semi-Decoder 모델로 학습시킨다.
    3. Electra와 Sgns의 임베딩에 기반한 요소 검색 기준에 따라 우리의 시스템은 2위를 차지했다.

###### Abed at KSAA-RD Shared Task: Enhancing Arabic Word Embedding with Modified BERT Multilingual (https://aclanthology.org/2023.arabicnlp-1.42/)
- Anthology ID: 2023.arabicnlp-1.42 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 본 논문에서는 BERT Multilingual 모델과 수정된 augmentation, multi attention head를 활용하여 WANLP 2023의 Arabic Reverse Dictionary 공유 작업에 대한 새로운 접근 방법을 제안한다.
    2. 제안된 방법은 모노링구얼 및 크로스링구얼 상황에서 아라비아어 정의에 대한 단어 임베딩 이해와 생성의 성능을 향상시키기 위해 개발되었다.
    3. 제안된 방법은 공유 작업 1과 2에서 벤치마크 및 다른 모델과 비교하여 좋은 결과를 얻었다.

###### Rosetta Stone at KSAA-RD Shared Task: A Hop From Language Modeling To Word–Definition Alignment (https://aclanthology.org/2023.arabicnlp-1.43/)
- Anthology ID: 2023.arabicnlp-1.43 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 역사전은 사용자가 단어의 정의 또는 의미를 제공하면 해당 단어를 찾을 수 있는 도구입니다. 이 논문에서는 아랍어 역사전 작업에서 우승한 솔루션을 제시합니다.
    2. 첫 번째 하위 작업에서는 아랍어 정의를 입력으로 사용하며, 우리의 접근법은 파인튜닝된 아랍어 BERT 기반 모델 앙상블을 활용하여 주어진 정의에 대한 단어 임베딩을 예측합니다.
    3. 두 번째 하위 작업에서는 영어 테스트 정의를 아랍어로 번역하여 첫 번째 하위 작업에 사용된 모델에 적용하는 것이 가장 효과적인 해결책입니다. 이 간단한 방법은 두 하위 작업 모두에서 가장 높은 점수를 달성합니다.

###### ArAIEval Shared Task: Persuasion Techniques and Disinformation Detection in Arabic Text (https://aclanthology.org/2023.arabicnlp-1.44/)
- Anthology ID: 2023.arabicnlp-1.44 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문은 ArabicNLP 2023 회의의 일환으로 진행된 ArAIEval 공유 작업에 대한 개요를 제공한다. ArAIEval은 아라비아어 텍스트에 대해 두 가지 작업을 제공한다: (1) 설득 기법 감지는 트윗과 뉴스 기사에서 설득 기법을 식별하는 데 중점을 둔다. (2) 트윗에서 이변 정보 탐지는 이변 정보를 이진 및 다중 클래스 설정에서 식별한다. 
    2. 총 20개의 팀이 최종 평가 단계에 참여했으며, Task 1과 Task 2에 각각 14개와 16개의 팀이 참여했다. 두 작업 모두 AraBERT와 같은 transformer 모델의 fine-tuning이 대부분의 참가 시스템의 핵심인 것으로 관찰되었다. 
    3. 데이터셋 구축 및 평가 설치에 대한 설명과 참가 시스템에 대한 간략한 개요를 제공한다. 이 공유 작업의 모든 데이터셋과 평가 스크립트는 연구 커뮤니티에 공개되었으며, 아라비아어 NLP 커뮤니티에서 이러한 중요한 작업에 대한 추가적인 연구를 가능하게 할 것이다.

###### DetectiveRedasers at ArAIEval Shared Task: Leveraging Transformer Ensembles for Arabic Deception Detection (https://aclanthology.org/2023.arabicnlp-1.45/)
- Anthology ID: 2023.arabicnlp-1.45 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문은 아랍 소셜 미디어에서의 가짜 정보 대응을 위한 방법론을 제시하고 있으며, 해당 전략은 ArabicNLP 2023 컨퍼런스의 ArAIEval 공유 작업에서 2A 및 2B 과제에서 1위를 차지했습니다.
    2. DetectiveRedasers 팀은 아랍어를 위한 BERT 기반 모델을 중심으로 하고 soft-voting 앙상블 전략을 개선하여 하이퍼파라미터를 최적화한 파이프라인을 개발하였습니다.
    3. 테스트 데이터셋에서의 평가 결과, 앙상블은 일반적으로 견고하지만 항상 개별 모델을 능가하지는 못한다는 것을 확인하였으며, 본 논문의 주요 기여는 2A와 2B의 가짜 정보 분류 과제에서 우승 솔루션을 찾기 위한 다양한 전략입니다.

###### HTE at ArAIEval Shared Task: Integrating Content Type Information in Binary Persuasive Technique Detection (https://aclanthology.org/2023.arabicnlp-1.46/)
- Anthology ID: 2023.arabicnlp-1.46 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 광고는 대중 의견에 영향을 주고 인식을 조작하기 위해 많은 설득 전략을 사용하는데, 이 논문은 이러한 설득 기법을 탐지하기 위해 컨텐츠 유형 정보를 추가 기능으로 포함시키거나 멀티태스크 학습 설정에서 추가 학습 목적으로 변환기 기반 모델을 제안한다.
    2. 최고의 모델은 텍스트에서 설득 기법의 존재를 탐지하는 것뿐만 아니라, 부가적인 작업으로 텍스트 장르 (유형)에 기반하여 사용되는 구문적 및 어휘적 단서를 학습한다.
    3. 이 모델은 ArabicNLP2023-ArAIEval 공유 작업의 일부로 공식 결과에 따르면 13개 참가자 중 1A 공유 작업에서 가장 높은 점수를 달성하였으며, 매크로-F1은 73.21%, 마이크로-F1은 76.34%이다.

###### USTHB at ArAIEval’23 Shared Task: Disinformation Detection System based on Linguistic Feature Concatenation (https://aclanthology.org/2023.arabicnlp-1.47/)
- Anthology ID: 2023.arabicnlp-1.47 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 연구 논문에서는 surface preprocessing, morphological preprocessing, FastText 벡터 모델, TF-IDF 기능의 가중 퓨전 등 여러 가지 요인이 ArAIEval'2023 공유 작업에서 아라비아 디스인포메이션 탐지의 성능에 영향을 미치는지에 대해 종합적인 조사를 수행한다.
    2. 선형 서포트 벡터 분류 (LSVC) 모델을 사용하여 분류 작업을 수행한다. 
    3. 우리의 시스템은 이 작업의 두 번째 하위 작업에 제출된 다른 시스템들이 얻은 평균 F1 micro 점수와 유사하게 바이너리 및 다중 분류 시나리오에서 각각 76.70%와 50.46%의 F1 micro 점수를 달성하여 상당한 결과를 보여준다.

###### Mavericks at ArAIEval Shared Task: Towards a Safer Digital Space - Transformer Ensemble Models Tackling Deception and Persuasion (https://aclanthology.org/2023.arabicnlp-1.48/)
- Anthology ID: 2023.arabicnlp-1.48 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문은 "Arabic AI Tasks Evaluation (ArAiEval) Shared Task 2023"에서의 우리의 접근 방식을 강조한다. 
    2. 우리는 해당 공유 작업의 task 1-A와 task 2-A에 대한 접근 방식을 제시한다. 
    3. 위 과제는 설득 기법 감지와 잘못된 정보 감지에 초점을 맞추고, 아라비아어로 작성된 트윗과 뉴스 기사의 다양한 장르 스니펫을 이진 분류 문제로 제공한다.

###### KnowTellConvince at ArAIEval Shared Task: Disinformation and Persuasion Detection in Arabic using Similar and Contrastive Representation Alignment (https://aclanthology.org/2023.arabicnlp-1.49/)
- Anthology ID: 2023.arabicnlp-1.49 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 디지털 커뮤니케이션 시대에서 허위정보를 식별하고 대응하는 것은 매우 중요한 과제가 되었다. 그러나, 영어와 비교했을 때 아랍어로 이 다중 측면 문제를 해결하기 위한 자원과 전략은 상대적으로 희박하다.
    2. 이 논문은 ArAIEval 2023의 과제에 대한 솔루션을 제시한다. 태스크 1은 설득 기법을 탐지하는데 초점을 맞추고, 태스크 2는 아랍어 텍스트 내에서 허위정보를 탐지하는 것에 중점을 둔다.
    3. 다중 헤드 모델 아키텍처, 파인튜닝 기술, 순차 학습, 혁신적인 활성화 함수를 활용하여, 이 논문의 기여는 설득 기법과 허위정보 탐지 정확도를 크게 향상시켰다. 이를 통해 아랍어 콘텐츠 분석에 대한 공백을 채우고 아랍어권의 정보 소스 신뢰성을 유지하고자 하는 개인, 커뮤니티, 디지털 플랫폼을 지원한다.

###### PTUK-HULAT at ArAIEval Shared Task Fine-tuned Distilbert to Predict Disinformative Tweets (https://aclanthology.org/2023.arabicnlp-1.50/)
- Anthology ID: 2023.arabicnlp-1.50 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 디지털 세상에서 disinformation이 퍼짐에 따라, 소셜 미디어에서 disinformative한 정보를 식별하기 위한 자동 분류 모델이 필요하다. 
    2. 이 논문에서는 DistilBERT multilingual model을 fine-tune하여 Twitter 상에서 dis-informative 여부를 분류하는 것에 성공하였고, 기존의 베이스라인보다 우수한 결과를 달성했다. 
    3. 이 시스템은 전체 참가자 중 11위를 기록하며, F1 micro 87%와 F1 macro 80%로 잘 분류하였음을 보여주었다.

###### AraDetector at ArAIEval Shared Task: An Ensemble of Arabic-specific pre-trained BERT and GPT-4 for Arabic Disinformation Detection (https://aclanthology.org/2023.arabicnlp-1.51/)
- Anthology ID: 2023.arabicnlp-1.51 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 소셜 미디어를 통한 disinformation의 신속한 번성은, 빠른 접근성, 낮은 비용 및 사용 편의성과 같은 소셜 미디어의 기능 덕분에 사람들의 사고, 시각, 행동에 영향을 미치고 속일 위험성으로 인해 가장 위험한 방법 중 하나가 되었다. 
    2. 따라서 disinformation을 탐지하는 것은 어려워지고 있다. 이 논문에서는 disinformation 탐지에 대한 ArAIEval 대회의 일환으로 4가지 모델 (MARBERT, 제안된 앙상블 모델, GPT-4의 제로샷과 Few-shot)을 평가하였고, GPT-4는 79.01%이고 앙상블 모델은 76.83%의 micro-F1 score를 달성했다.
    3. 개발 데이터셋에서 앙상블로 수행한 micro-F1 점수 향상은 없었지만, 테스트 데이터셋에 대한 예측을 위해 여전히 앙상블 접근 방식을 사용했다. 다른 분류기들을 결합하는 것이 시스템의 예측 정확도를 향상시킬 수 있을 것으로 기대하였다.

###### rematchka at ArAIEval Shared Task: Prefix-Tuning & Prompt-tuning for Improved Detection of Propaganda and Disinformation in Arabic Social Media Content (https://aclanthology.org/2023.arabicnlp-1.52/)
- Anthology ID: 2023.arabicnlp-1.52 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 디지털 시대에 프로파간다와 잘못된 정보의 증가로 인해 기만적 정보의 확산을 막기 위해 효과적인 탐지 방법을 개발하는 것이 필요하다.
    2. 이 논문에서는 ArAIEval 공유 작업에 대한 정보 전파와 잘못된 정보 탐지를 위한 우리의 접근 방식을 소개하고 있다.
    3. 우리의 제안된 접근 방식은 prompt-learning 기반의 지식 확장과 prefix-tuning을 활용한 다양한 사전 학습된 BERT 기반 모델을 사용하여 성능을 향상시켰으며, 일반적인 fine-tuning 방법보다 prompt-tuning 기반과 prefix-tuning 기반 모델이 더 우수한 결과를 보였다.

###### Itri Amigos at ArAIEval Shared Task: Transformer vs. Compression-Based Models for Persuasion Techniques and Disinformation Detection (https://aclanthology.org/2023.arabicnlp-1.53/)
- Anthology ID: 2023.arabicnlp-1.53 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 소셜 미디어는 미신이 퍼지는 것을 크게 증폭시켰고, 자연어 처리와 머신러닝 기술을 사용하여 해당 플랫폼에서 거짓 정보를 식별하고 분류하는 데 이용되었다. 그러나 아라비아어 거짓 뉴스 감지에 대한 연구는 아직 많이 이루어지지 않았다.
    2. 본 논문은 2023 ArAIEval 공유 작업의 어려움을 해결하기 위해 사용된 방법을 설명한다. 모노링구얼 아라비아어와 다중 언어 사전훈련 언어 모델을 사용하여 실험을 진행했다. 모노링구얼 아라비아어 모델이 모든 4개 하위 작업에서 뛰어난 성과를 보였다.
    3. 또한 우리는 손실 없는 압축 방법을 사용하여 신경망 성능을 능가하지 못하였지만, 향후 실험에서 비슷한 결과를 더 효율적이고 신속하게 달성하기 위한 흥미로운 가능성을 제시하였다.

###### ReDASPersuasion at ArAIEval Shared Task: Multilingual and Monolingual Models For Arabic Persuasion Detection (https://aclanthology.org/2023.arabicnlp-1.54/)
- Anthology ID: 2023.arabicnlp-1.54 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 본 논문은 다국어 시스템을 사용하여 아라비아어 데이터에서 설득 감지(persuasion detection)를 향상시키기 위한 연구를 수행하였다.
    2. 본 연구는 다양한 시스템을 종합적으로 평가하여 그들의 성능을 비교하고 가장 효과적인 방법을 식별하기 위한 목표로 22개의 실험을 실시하였다. 
    3. 실험 결과, *ReDASPersuasion* 시스템이 다국어 "XLM-RoBERTa"와 모노링구얼 pre-trained transformer를 결합할 때 아라비아어 사투리("CAMeLBERT-DA SA")에서 NLP 분류 작업에 가장 우수한 성능을 보였다.

###### UL & UM6P at ArAIEval Shared Task: Transformer-based model for Persuasion Techniques and Disinformation detection in Arabic (https://aclanthology.org/2023.arabicnlp-1.55/)
- Anthology ID: 2023.arabicnlp-1.55 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문에서는 피설등 문제와 디스인포메이션 과제의 감지를 위한 참가 시스템을 소개한다. 
    2. 논문에서 제안된 시스템은 사전 훈련된 transformer-based 언어 모델과 분류기를 사용하여 성능을 검증했다.
    3. 실제 테스트 세트에서 시스템은 Sub-Task 1A, 1B, 2A 및 2B에 대해 각각 4위, 1위, 3위 및 2위의 순위를 기록하였다.

###### AAST-NLP at ArAIEval Shared Task: Tackling Persuasion technique and Disinformation Detection using Pre-Trained Language Models On Imbalanced Datasets (https://aclanthology.org/2023.arabicnlp-1.56/)
- Anthology ID: 2023.arabicnlp-1.56 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. AAST-NLP 팀은 설득 기법 탐지 및 거짓정보 탐지 공유 작업을 처리하기 위해 개발한 파이프라인을 제안하였다. 
    2. 이 논문에서는 주어진 데이터셋에서 AraBERT를 finetuning하고 각 subtask에 대해 적합한 몇 가지 절차를 수행하는 시스템을 제안한다. 
    3. 실험 결과로, 각 sub-task에서 좋은 성능을 보이며, 특히 sub-task 1B에서 3등을 차지하였다.

###### PD-AR at ArAIEval Shared Task: A BERT-Centric Approach to Tackle Arabic Disinformation (https://aclanthology.org/2023.arabicnlp-1.57/)
- Anthology ID: 2023.arabicnlp-1.57 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 본 연구는 최신 NLP 모델을 사용하여 중요한 자연어 처리 과제인 아라비아어 허위 정보 식별에 대해 탐구한다.
    2. 우리는 다국어와 아라비아어 특화된 기준 모델을 포함한 기준 모델들과의 시스템 모델의 성능을 강조하고, 도메인 특화 사전 훈련 모델의 효과를 보여준다.
    3. 이 연구는 NLP에서 맞춤형 사전 훈련 모델의 채택을 주장하며, 다양한 언어를 이해하는 데 그들의 중요성을 강조한다. 고급 NLP 기법을 도메인 특화 사전 훈련과 결합함으로써 아라비아어 허위 정보 식별을 발전시킨다.

###### Nexus at ArAIEval Shared Task: Fine-Tuning Arabic Language Models for Propaganda and Disinformation Detection (https://aclanthology.org/2023.arabicnlp-1.58/)
- Anthology ID: 2023.arabicnlp-1.58 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. "허구 정보와 선전적 콘텐츠의 확산은 사회적 조화를 위협하고, 정확한 의사결정과 신뢰할 수 있는 소식원에 대한 신뢰를 약화시킨다. 온라인 플랫폼은 종종 이러한 콘텐츠의 번식지로 작용하며, 악의적인 주체들은 대중의 취약점을 이용하여 대중 의견을 조작한다."
    2. "소셜미디어 콘텐츠에서 허위 정보와 선전을 자동으로 식별하기 위한 연구 노력이 있었지만, 성능 관점에서 여전히 어려움이 남아있다."
    3. "이 논문에서는 ArAIEval 공유과제에 우리가 참여한 것에 대해 논의한다. 우리는 1A 서브태스크와 2A 서브태스크에 참가하여 각각 9위와 10위의 위치를 차지하였다. 우리는 transformer 모델을 세밀하게 조정하고 GPT-4와 zero-shot 및 few-shot 학습을 활용한 실험을 진행하였다."

###### Frank at ArAIEval Shared Task: Arabic Persuasion and Disinformation: The Power of Pretrained Models (https://aclanthology.org/2023.arabicnlp-1.59/)
- Anthology ID: 2023.arabicnlp-1.59 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 우리는 ArAIEval 공유 과제의 일환으로, 아랍어 트윗에서 설득력을 탐지하기 위해 mBERT transformer를 사용했고, 아랍어 트윗에서의 허위정보를 식별하기 위해 MARBERT transformer를 사용했다. 설득력 탐지 시스템은 13.2%의 성능 향상으로 마이크로-F1 값이 0.745를 기록하였으며, 전체 점수로 측정한 매크로-F1 값은 0.717이었다.
    2. 마찬가지로, 허위정보 탐지 시스템은 6.7%의 성능 향상으로 마이크로-F1 값이 0.816를 기록하였으며, 매크로-F1 값은 0.637였다. 
    3. 또한, 우리는 다양한 사전 훈련 모델에 대한 예비 결과를 제시한다. 총 순위에서 우리의 시스템은 Subtask 1A에서 16개 팀 중 7위, 2A에서 17개 팀 중 12위에 해당한다.

###### Raphael at ArAIEval Shared Task: Understanding Persuasive Language and Tone, an LLM Approach (https://aclanthology.org/2023.arabicnlp-1.60/)
- Anthology ID: 2023.arabicnlp-1.60 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 사회적 미디어와 주류 미디어 플랫폼에서의 선전 및 비판 정보의 광범위한 전파는 정부기관과 사회적 미디어 기업과 같은 다양한 이해 관계자들의 관심을 받으며 긴급한 문제가 되었다. 이 논문에서는 아랍어와 같은 연구되지 않은 언어로의 속이기 기술 탐지 방법에 대한 접근 방식을 개요로 설명한다.  
    2. 우리는 텍스트에서 톤과 잠재적 설득 기술을 구분하기 위해 GPT-3를 활용하고, 다양한 기본 언어 모델을 탐구하며, 지정된 하위 작업들에 대해 다중 작업 학습 접근법을 사용하는 주요 기여를 하였다.
    3. 우리는 ArAIEval 2023의 공유 작업 1에 우리의 시스템을 제출하였으며, 이는 아랍어 트윗과 뉴스 기사 문단에서의 설득 기술 탐지를 다루고 있다.

###### Legend at ArAIEval Shared Task: Persuasion Technique Detection using a Language-Agnostic Text Representation Model (https://aclanthology.org/2023.arabicnlp-1.61/)
- Anthology ID: 2023.arabicnlp-1.61 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문은 Task 1에 초점을 맞춰, 트윗과 뉴스 기사에서 설득 기술을 식별하는 것을 다룬다. 
    2. XLM-RoBERTa를 사용하여 언어에 구애받지 않는 텍스트 표현 모델을 학습하여, 아라비아어 텍스트에서 설득 기술을 감지한다. 
    3. 의사 결정이나 dialog system 등 다양한 NLP 작업에 유용한 이 방법으로, 대회의 서브태스크 A에서 0.64의 높은 F1 스코어를 달성하였다.

###### NADI 2023: The Fourth Nuanced Arabic Dialect Identification Shared Task (https://aclanthology.org/2023.arabicnlp-1.62/)
- Anthology ID: 2023.arabicnlp-1.62 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. "Nuanced Arabic Dialect Identification Shared Task (NADI 2023)"는 표준화된 조건 하에서 협업 경쟁을 위해 연구팀들에게 기회를 제공함으로써 아랍어 NLP의 최신 기술을 발전시키기 위한 목적을 가지고 있다. 
    2. NADI 2023는 아랍어 방언 인식(Subtask 1)과 방언-MSA 기계 번역(Subtask 2 및 Subtask 3)에 초점을 맞춘다. 
    3. 결과적으로, 세 가지 subtask 모두 도전적이며, 앞으로의 연구에 동기를 부여한다.

###### DialectNLU at NADI 2023 Shared Task: Transformer Based Multitask Approach Jointly Integrating Dialect and Machine Translation Tasks in Arabic (https://aclanthology.org/2023.arabicnlp-1.63/)
- Anthology ID: 2023.arabicnlp-1.63 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 약 4억 명의 사용자를 가진 아라비아어는 세계적으로 5번째로 많이 사용되는 언어로, 자연어 처리 분야에서의 발전이 필요하다. 
    2. 이 논문에서는 EMNLP 2023의 Nuanced Arabic Dialect Identification (NADI) 과제의 하위 과제에 사용된 접근 방법에 대한 시스템 설명을 제공한다. 
    3. Closed country-level dialect identification 분류에는 두 개의 아라비아어 언어 모델 앙상블을 사용하고, closed dialect to Modern Standard Arabic (MSA) 기계 번역에는 아라비아어 특화 데이터셋에서 훈련된 sequence-to-sequence 모델을 결합한 접근 방법을 사용하였다.

###### UoT at NADI 2023 shared task: Automatic Arabic Dialect Identification is Made Possible (https://aclanthology.org/2023.arabicnlp-1.64/)
- Anthology ID: 2023.arabicnlp-1.64 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문에서는 우리가 아랍 사투리 식별을 위해 사용한 접근 방식을 제시한다. 사투리 식별을 위해 여러 기법들을 시도해보고, 수정된 학습 데이터셋으로 사전 학습된 MARBERTv2 모델을 세밀하게 조정함으로써 최상의 결과를 얻었다.
    2. 학습 데이터셋을 사투리 기준으로 정렬하고, 인접한 두 개의 트윗을 연결하여 새로운 트윗으로 추가함으로써 학습 데이터셋을 확장했다.
    3. 우리는 F1 점수 82.87을 달성하였고, 16개 참가자 중 일곱 번째로 성과를 얻었다.

###### SANA at NADI 2023 shared task: Ensemble of Layer-Wise BERT-based models for Dialectal Arabic Identification (https://aclanthology.org/2023.arabicnlp-1.65/)
- Anthology ID: 2023.arabicnlp-1.65 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. NADI-23에서 제출된 우리 시스템은 닫힌 계층별 방식으로 세밀한 아라비아 방언 식별 문제를 처리한다.
    2. 우리는 BERT 기반 모델의 layer-wise fine-tuning 앙상블을 기반으로 하는 모델을 제안한다.
    3. 제안된 모델은 16개 제출 중 네 번째로 랭킹되며 F1-macro 점수는 85.43이다.

###### ISL-AAST at NADI 2023 shared task: Enhancing Arabic Dialect Identification in the Era of Globalization and Technological Progress (https://aclanthology.org/2023.arabicnlp-1.66/)
- Anthology ID: 2023.arabicnlp-1.66 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 아랍어 방언은 중요성과 많은 사용자를 가지고 있지만, 기술적 진보와 세계화로 인해 중요한 변화가 일어나고 있다. 이 연구는 18개 국가의 방언을 카테고리화하고 있는데, 이를 위해 MARABERT와 MARABERT v2 모델을 활용하여 감정 분석을 수행하고 있다.
    2. MARABERT v2의 은닉층에 평균 앙상블과 연결을 적용하고, 결과 출력을 합성곱층에 투입함으로써 가장 효과적인 모델을 얻을 수 있었다.
    3. 다양한 방법에 대해 앙상블 기법을 적용함으로써 모델의 성능을 향상시킬 수 있었고, 연구 결과는 First subtask에서 상위 성과 중 6위를 차지하며 F1 점수 83.73%를 달성하였다.

###### Frank at NADI 2023 Shared Task: Trio-Based Ensemble Approach for Arabic Dialect Identification (https://aclanthology.org/2023.arabicnlp-1.67/)
- Anthology ID: 2023.arabicnlp-1.67 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 본 연구에서는 NADI의 Subtask 1을 위해 고안된 시스템을 소개하는데, 이는 ArabicNLP 2023의 일환이다. 
    2. 저희 접근 방식에서는 MARBERT, MARBERTv2 (A), MARBERTv2 (B)와 같은 모델을 활용하였다. 
    3. 이를 토대로 majority voting ensemble을 만들어 전체적인 성능을 향상시켰으며, 16개 팀 중 5위를 차지했다.

###### NLPeople at NADI 2023 Shared Task: Arabic Dialect Identification with Augmented Context and Multi-Stage Tuning (https://aclanthology.org/2023.arabicnlp-1.68/)
- Anthology ID: 2023.arabicnlp-1.68 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문은 팀의 접근 방식을 설명하고 나무지기 아랍어 방언 식별(NADI) 2023 공유 작업의 세부적인 작업에 대해 다룬다.
    2. 아랍어 특정 언어 모델, 클러스터링 및 검색 방법을 활용한 추가 문맥 제공, 2020년과 2021년 공유 작업에서 제공된 데이터를 사용한 fine-tuning 전략, 그리고 여러 모델의 예측을 앙상블하는 방법으로 Subtask 1에 접근한다.
    3. 제출한 결과는 매크로 평균 F1 점수가 87.27로, 이 작업의 다른 참가자들 중에서 1등을 차지했다.

###### USTHB at NADI 2023 shared task: Exploring Preprocessing and Feature Engineering Strategies for Arabic Dialect Identification (https://aclanthology.org/2023.arabicnlp-1.69/)
- Anthology ID: 2023.arabicnlp-1.69 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 본 논문에서는 NADI'2023의 아라비아 방언 식별에 영향을 미치는 여러 요소들을 깊이 있는 분석을 통해 조사하였으며, 특히 국가 수준의 방언 식별 부분에 초점을 맞추었다.
    2. 표면 전처리, 형태학적 전처리, FastText 벡터 모델, TF-IDF 특징의 가중된 연결 등 여러 요소가 성능에 미치는 영향을 조사하였다.
    3. 평가 단계에서는 Linear Support Vector Classification (LSVC) 모델을 사용하여 뛰어난 결과를 보였으며, F1 점수가 62.51%로, 이는 첫 번째 서브태스크에 제출된 다른 시스템의 평균 F1 점수인 72.91%와 유사한 결과를 보였다.

###### rematchka at NADI 2023 shared task: Parameter Efficient tuning for Dialect Identification and Dialect Machine Translation (https://aclanthology.org/2023.arabicnlp-1.70/)
- Anthology ID: 2023.arabicnlp-1.70 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 방언 식별 시스템은 음성 및 언어 기술, 언어 교육, 사회언어학 연구 지원, 언어 다양성 보전, 텍스트 음성 변환 시스템을 향상시키는 등 다양한 분야와 응용에서 중요한 역할을 한다.
    2. 본 논문에서는 국가 수준의 방언 식별 및 방언에서 MSA(Moderate Shared Arabic)로의 기계 번역(MT)을 위한 NADI 2023 공유 작업에서의 연구 결과를 제시한다.
    3. 실험 단계에서 제안된 모델은 전통적인 fine-tuning과 비교하여 성능이 향상된 매개변수 효율적인 훈련 방법을 사용한다.

###### UniManc at NADI 2023 Shared Task: A Comparison of Various T5-based Models for Translating Arabic Dialectical Text to Modern Standard Arabic (https://aclanthology.org/2023.arabicnlp-1.71/)
- Anthology ID: 2023.arabicnlp-1.71 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문은 너안스 아라비아 방언 식별(NADI) 2023 공유 작업을 위해 개발한 방법들을 소개한다. 
    2. 아라비아어 사투리 (이집트, 아랍에미리트, 요르단, 팔레스타인)로 쓰인 텍스트를 표준 아라비아어로 문장 수준 기계 번역하는 두 가지 하위 작업에 대해서 주로 타겟으로 삼는다.
    3. 저자들의 팀인 UniManc은 mT5, mT0, AraT5와 같은 T5를 기반으로 한 모델들을 사용하였고, J-R (joint model training for all regional dialects) 및 I-R (independent model training for every regional dialect) 두 가지 구성에 따라 모델을 훈련시켰다. 결과적으로 I-R AraT5 모델이 제일 높은 BLEU 점수를 얻어 그 부문에서 1위를 차지했다.

###### IUNADI at NADI 2023 shared task: Country-level Arabic Dialect Classification in Tweets for the Shared Task NADI 2023 (https://aclanthology.org/2023.arabicnlp-1.72/)
- Anthology ID: 2023.arabicnlp-1.72 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 본 논문에서는 NADI2023 shared task에 대한 참여 방법과 아랍어 방언 트윗의 분류를 위한 모델 개발을 제시한다.
    2. 실험 결과, Arabertv2-Large, Arabertv2-Base, CAMeLBERT-Mix DID MADAR과 같은 큰 언어 모델이 SVM, XGBOOST, Multinomial Naive Bayes, AdaBoost, Random Forests와 같은 전통적인 방법들보다 일관적으로 좋은 성능을 보였다.
    3. 총 18개의 아랍 국가로부터 수집된 트윗을 분류하기 위해 여러 가지 머신러닝 모델을 활용하는 접근법을 기술하였다.

###### The Helsinki-NLP Submissions at NADI 2023 Shared Task: Walking the Baseline (https://aclanthology.org/2023.arabicnlp-1.73/)
- Anthology ID: 2023.arabicnlp-1.73 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 헬싱키-NLP 팀은 아랍어 방언 번역 NADI 2023의 공유 작업에 7개의 제출물로 참여했다. 우리는 통계적(SMT) 및 신경망 기계 번역(NMT) 방법을 사용하고, 문자 및 서브워드 기반의 데이터 전처리를 탐구했다.
    2. 우리의 제출물은 양 트랙 모두 2등을 차지했다. 오픈 트랙에서 우리의 우승 제출물은 Modern Standard Arabic 언어 모델을 추가한 문자 수준의 SMT 시스템이었다.
    3. 닫힌 트랙에서는 leave-as-is 베이스라인과 입력의 단순한 복사, 그리고 SMT 시스템이 뒤를 이었으며, AraT5 또는 ByT5와 같은 기존 다국어 모델의 fine-tuning은 SMT와 비교했을 때 우수한 성능을 제공하지 않았다.

###### Mavericks at NADI 2023 Shared Task: Unravelling Regional Nuances through Dialect Identification using Transformer-based Approach (https://aclanthology.org/2023.arabicnlp-1.74/)
- Anthology ID: 2023.arabicnlp-1.74 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. "Nuanced Arabic Dialect Identification (NADI) Shared Task 2023"를 위한 접근 방식을 소개한다. 우리는 나라별 방언 식별(subtask 1)을 위한 방법론을 강조한다. 방언 인식은 음성 인식과 번역과 같은 다양한 NLP 태스크의 성능을 향상시키는 데 중요한 역할을 한다.
    2. 트위터 데이터셋(TWT-2023)을 사용하여, 다양한 아라비아어 transformer 기반 모델을 나라별 방언 식별에 활용한다.
    3. 제공된 데이터셋에서 최첨단 모델들을 fine-tuning하고, 앙상블 기법을 사용하여 시스템의 성능을 개선한다. 테스트 데이터셋에서 F1-score 76.65를 달성했다.

###### ANLP-RG at NADI 2023 shared task: Machine Translation of Arabic Dialects: A Comparative Study of Transformer Models (https://aclanthology.org/2023.arabicnlp-1.75/)
- Anthology ID: 2023.arabicnlp-1.75 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문은 NADI-2023 공유 과제(Subtask 2)의 맥락에서 결과를 제시한다. 이 과제는 마더 병렬 코퍼스(MADAR)를 사용하여 팔레스타인, 요르단, 아랍 에미리트, 이집트 방언으로부터 현대 표준 아랍어(MSA)로의 번역 모델 개발을 포함한다.
    2. 이 논문에서는 마더 코퍼스를 학습 자료로 사용하여 다양한 transformer 모델의 fine-tuning 결과를 비교 분석하고 에미리트 방언에 대한 병렬 하위 셋이 없는 경우에 대한 도전을 다룬다.
    3. 추가로, 기존의 번역 도구의 효과를 평가하여 번역 목표를 달성하는 데 어떤지 확인하였으며, 최고 성능 모델은 dev set에서 11.14%, test set에서 10.02%의 BLEU 점수를 달성하였다.

###### Qur’an QA 2023 Shared Task: Overview of Passage Retrieval and Reading Comprehension Tasks over the Holy Qur’an (https://aclanthology.org/2023.arabicnlp-1.76/)
- Anthology ID: 2023.arabicnlp-1.76 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. Holy Qur'an에 대한 지식 기반 질문 응답 시스템의 필요성을 바탕으로 Qur'an QA 2023이 개최되었다. 이 공유 과제는 두 가지 하위 과제인 passage retrieval (PR) task와 machine reading comprehension (MRC) task로 구성되어 있으며, Holy Qur'an에 대한 상위 연구를 장려하기 위해 진행되었다.
    2. 공유 과제에는 PR task에 9개의 팀이 22개의 실행 결과를 제출하였고, MRC task에는 6개의 팀이 17개의 실행 결과를 제출하였다.
    3. 이 논문에서는 공유 과제의 개요를 제시하고, 각 하위 과제에 참여한 팀들의 접근 방식에 대해 개요를 제공한다.

###### AHJL at Qur’an QA 2023 Shared Task: Enhancing Passage Retrieval using Sentence Transformer and Translation (https://aclanthology.org/2023.arabicnlp-1.77/)
- Anthology ID: 2023.arabicnlp-1.77 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 연구는 약 20억의 무슬림에게 영향을 미치고 언어적 풍부함과 복잡성으로 알려진 성전 꾸란에 대한 태스크 A에 참여했다. 문장 변환기와 OpenAI의 임베딩을 사용하여 두 가지 모델을 사용하고 아랍어 질의를 해석하고 이를 아랍어로 번역하여 검색 결과를 도출하는 기능을 제공하는 모델이 아랍어 질의응답 시스템의 성능을 향상시킬 수 있는 것을 보였다.
    2. 기계 번역 기능을 도입하면 아랍어 질의응답 시스템의 성능이 향상되는 것을 실험을 통해 확인하였다.
    3. 상당한 성능 향상을 보인 번역 모델은 모든 메트릭에서 비번역 모델에 비해 우수한 성능을 보였다.

###### LowResContextQA at Qur’an QA 2023 Shared Task: Temporal and Sequential Representation Augmented Question Answering Span Detection in Arabic (https://aclanthology.org/2023.arabicnlp-1.78/)
- Anthology ID: 2023.arabicnlp-1.78 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 퀴란은 신학적, 역사적 중요성을 가지고 있으며, 이 성서로부터 질문에 대답하는 기술 기반 솔루션을 개발하는 것이 매우 중요하다.
    2. 본 논문에서는 QRCD를 활용하여 퀴란 구절로부터 정확하고 문맥적인 답변을 추출하기 위해 혁신적인 기술과 고급 모델을 제안한다.
    3. Start 및 End logits, LSTM 네트워크, 퓨전 메커니즘을 활용한 접근법은 기술과 영성이 교차되는 분야에서의 지속적인 대화에 기여한다.

###### GYM at Qur’an QA 2023 Shared Task: Multi-Task Transfer Learning for Quranic Passage Retrieval and Question Answering with Large Language Models (https://aclanthology.org/2023.arabicnlp-1.79/)
- Anthology ID: 2023.arabicnlp-1.79 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 본 논문은 크루안(코란)과 같은 고전 텍스트에 대한 질문 응답의 도전과제에 대해 다루고 있다.
    2. 이 논문에서는 두 가지 작업인 passage retrieval과 reading comprehension을 소개한다.
    3. 아라일렉트라(AraElectra)라는 모델을 사용하여 읽기 이해 작업에서 기존 모델보다 23% 성능 향상을 보였다.

###### LKAU23 at Qur’an QA 2023: Using Transformer Models for Retrieving Passages and Finding Answers to Questions from the Qur’an (https://aclanthology.org/2023.arabicnlp-1.80/)
- Anthology ID: 2023.arabicnlp-1.80 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. Qur’an QA 2023 공유 작업에는 Passage Retrieval (PR) task와 Machine Reading Comprehension (MRC) task가 있으며, 우리는 PR task에 참여하여 Sentence-Transformers 아키텍처를 사용하여 몇 가지 아라비아 문장 사전 학습 모델을 추가로 훈련시키고 최고의 성능을 낼 수 있는 모델들을 앙상블하였다. 개발 세트의 결과와 테스트 세트의 결과가 일치하지 않았다.
    2. MRC task에도 참여하여 기존의 AraBERT의 베이스와 큰 변형을 Classical Arabic과 Modern Standard Arabic 데이터셋을 사용하여 더 잘 fine-tuning했다. 베이스 AraBERT는 개발 세트에서 가장 좋은 결과를 보여주었으며, pAP가 0.49, 테스트 세트에서는 0.5를 달성했다.
    3. 이 외에도 최고의 성능을 보이는 모델들을 앙상블하고 후처리 단계를 적용하여 최종 결과를 얻었다. 개발 세트의 실험에서는 제안한 모델이 0.537의 pAP를 달성했으며, 테스트 세트에서는 pAP 점수가 0.49가 되었다.

###### TCE at Qur’an QA 2023 Shared Task: Low Resource Enhanced Transformer-based Ensemble Approach for Qur’anic QA (https://aclanthology.org/2023.arabicnlp-1.81/)
- Anthology ID: 2023.arabicnlp-1.81 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. Qur'an QA 2023 공유 작업 A와 B에 대한 접근 방식을 제공한다. 훈련 데이터의 부족으로 인한 도전에 대처하기 위해, 여러 번의 실험을 통해 예측의 안정성을 향상시키기 위해 전이 학습과 투표 앙상블을 사용한다. 또한, 각 작업에 대해 다양한 아라비아어 사전 훈련된 트랜스포머 모델의 아키텍처와 학습 메커니즘을 사용한다.
    2. 대답할 수 없는 질문을 식별하기 위해 임계값 기반의 메커니즘을 제안한다.
    3. 성능이 우수한 시스템은 숨겨진 분할에서 기준 성능을 크게 뛰어넘으며, 과업 A에서 MAP 점수 25.05%, 과업 B에서 부분 평균 정밀도 (pAP) 57.11%를 달성한다.

###### Al-Jawaab at Qur’an QA 2023 Shared Task: Exploring Embeddings and GPT Models for Passage Retrieval and Reading Comprehension (https://aclanthology.org/2023.arabicnlp-1.82/)
- Anthology ID: 2023.arabicnlp-1.82 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 본 논문은 실행 가능한 평가 척도로 "Knowledge Dependent Answerability" (KDA)을 제안하여 자동 생성된 Multiple Choice Questions (MCQ)의 교육적 가치를 평가한다.
    2. 이 논문은 contrastive learning과 counterfactual augmentation을 활용하여 deep learning 모델의 강건성을 향상시킨다.
    3. 이 연구에서는 OpenAI의 "text-embedding-ada-002" 임베딩 모델과 GPT-4 언어 모델을 활용하여 Holy Qur'an과 관련된 데이터셋에 대한 텍스트 기반 자연어처리 태스크를 수행하는 종합 시스템을 제안한다.

###### WojoodNER 2023: The First Arabic Named Entity Recognition Shared Task (https://aclanthology.org/2023.arabicnlp-1.83/)
- Anthology ID: 2023.arabicnlp-1.83 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. "WojoodNER-2023는 국문명 개체 인식(Named Entity Recognition, NER)의 첫번째 아라비아어 공유 작업이다."
    2. "이 작업은 아라비아어 NER에 초점을 맞추어 새로운 NER 데이터셋과 다양한 NER 접근법 간의 유의미한 비교를 용이하게 하기 위한 서브태스크 정의를 제공한다."
    3. "WojoodNER-2023에는 FlatNER과 NestedNER 두 가지 서브태스크가 포함되었으며, 총 45개의 팀이 참가하고 최종 승자는 각각 91.96과 93.73의 F1 스코어를 달성하였다."

###### ELYADATA at WojoodNER Shared Task: Data and Model-centric Approaches for Arabic Flat and Nested NER (https://aclanthology.org/2023.arabicnlp-1.84/)
- Anthology ID: 2023.arabicnlp-1.84 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. "우리는 WojoodNER 공유 과제에 대한 참가 결과를 설명하는 논문입니다. 우리는 flat과 nested Named Entity Recognition (NER) 두 가지 하위 과제에 참여했습니다."
    2. "우리의 시스템은 Nested NER에서 8개 팀 중 1위, Flat NER에서 11개 팀 중 3위로 랭크되었습니다."
    3. "우리의 주요 제출물은 DiffusionNER 모델을 기반으로 하며, nested WojoodNER에서는 93.73%의 높은 신뢰도를 가지는 최고의 결과를 얻었습니다. Flat sub-task에서는 91.92%의 micro F1-score로 세 번째로 좋은 성능을 보였습니다."

###### Lotus at WojoodNER Shared Task: Multilingual Transformers: Unveiling Flat and Nested Entity Recognition (https://aclanthology.org/2023.arabicnlp-1.85/)
- Anthology ID: 2023.arabicnlp-1.85 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. "Wojood"의 Arabic NER detection 공유 과제에서 Subtask 1과 Subtask 2를 위해 개발한 시스템을 소개한다. 
    2. Subtask 1에서는 단일 분류기를 사용하여 XLM-R 모델을 적용하여 주어진 토큰에 대한 Flat NER 레이블을 예측한다. 
    3. Subtask 2에서는 21개의 개별 분류기를 구축하여 XLM-R 인코더를 사용하며, 각 분류기는 특정 레이블의 존재 여부를 결정하기 위해 설계되었다.

###### AlexU-AIC at WojoodNER shared task: Sequence Labeling vs MRC and SWA for Arabic Named Entity Recognition (https://aclanthology.org/2023.arabicnlp-1.86/)
- Anthology ID: 2023.arabicnlp-1.86 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 명명된 개체 인식(NER)은 아라비아어 자연어 처리에서 많은 어려운 과제 중 하나이다. 또한 주요 동향과 대중 의견을 이해하는 데 도움이 되는 다양한 중요한 하위 작업의 기반이 되기도 한다. 
    2. 본 논문은 아라비아어 NLP 2023의 NER Shared Task에 대한 참가 결과를 설명한다. Flat NER Subtask에서는 간단한 기계 독해 기반 기술을 사용하여 리더보드에서 8위를 차지하였으며, Nested NER Subtask에서는 언어 모델을 fine-tuning하여 리더보드에서 3위에 올랐다.

###### UM6P & UL at WojoodNER shared task: Improving Multi-Task Learning for Flat and Nested Arabic Named Entity Recognition (https://aclanthology.org/2023.arabicnlp-1.87/)
- Anthology ID: 2023.arabicnlp-1.87 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 우리는 플랫(flat)과 네스티드(nested) 아라비아어 명칭 엔티티 인식(NER)을 다루는 WojoodNER 공유 태스크를 위해 제출한 시스템을 제안한다. 객체는 BERT 기반 멀티태스크 학습 모델을 기반으로 하며, 아라비아어 사전훈련 언어 모델(Arabic Pretrained Language Models)을 활용하여 입력 문장을 인코딩한다. 
    2. 모델의 성능을 개선하기 위해 멀티태스크 손실 분산 벌칙과 크로스 엔트로피 손실, 다이스 손실, 트베르스키 손실, 포칼 손실 등 여러 학습 목적을 결합하여 사용하였다. 
    3. 공식 테스트 세트에서 우리의 시스템은 플랫 NER(서브태스크 1)에서 0.9113의 마이크로-F1 점수를, 네스티드 NER(서브태스크 2)에서는 0.9303의 점수를 얻었고 각각 해당 서브태스크에서 참가 시스템 중 6위와 2위를 기록하였다.

###### AlphaBrains at WojoodNER shared task: Arabic Named Entity Recognition by Using Character-based Context-Sensitive Word Representations (https://aclanthology.org/2023.arabicnlp-1.88/)
- Anthology ID: 2023.arabicnlp-1.88 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이 논문은 single-task와 multi-task learning을 활용한 아라비아어 Named Entity Recognition(NER) 모델을 제안한다.
    2. 모델은 단어 시퀀스의 입력 레이어에서 character-based contextualized Embeddings from Language Model (ELMo)를 사용하여 개발되었다.
    3. 싱글 태스크 모델이 멀티 태스크 모델보다 더 우수한 성능을 보이며, 플랫과 네스트된 annotations에 대해 각각 0.8751과 0.8884의 micro F1-score을 달성하였다.

###### LIPN at WojoodNER shared task: A Span-Based Approach for Flat and Nested Arabic Named Entity Recognition (https://aclanthology.org/2023.arabicnlp-1.89/)
- Anthology ID: 2023.arabicnlp-1.89 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. Wojood Named Entity Recognition (NER) shared task는 한정된 Arabic 자원에 대한 도전을 해결하기 위한 포괄적인 Arabic NER 데이터셋을 소개한다.
    2. 이 논문에서는 NER을 span classification 문제로 처리하고, 사전 훈련된 언어 모델과 신경망 분류기를 사용하여 두 가지 하위 작업을 다루는 LIPN 팀의 접근 방식을 소개한다.
    3. LIPN 팀은 flat NER에서 91.96의 F-스코어로 1위, nested NER에서 92.45의 F-스코어로 4위를 달성하였다.

###### Alex-U 2023 NLP at WojoodNER shared task: AraBINDER (Bi-encoder for Arabic Named Entity Recognition) (https://aclanthology.org/2023.arabicnlp-1.90/)
- Anthology ID: 2023.arabicnlp-1.90 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. 이름 인식(Named Entity Recognition, NER)은 텍스트로부터 중요한 정보를 추출하는데 도움이 되는 자연어 처리의 중요한 작업입니다. 그러나 아라비아어로 NER를 수행하는 것은 해당 언어의 특성으로 인해 큰 도전이 있습니다.
    2. 이 논문에서는 우리의 AraBINDER (Arabic Bi-Encoder for Named Entity Recognition)를 소개합니다. AraBINDER는 두 개의 트랜스포머 인코더를 활용하며 대상 텍스트 범위와 엔터티 유형을 동일한 벡터 표현 공간으로 매핑하기 위해 대조 학습을 사용합니다.
    3. AraBINDER는 Wojood 데이터셋에서 Flat NER의 경우 0.918의 마이크로 F-1 점수와 Nested NER의 경우 0.9의 마이크로 F-1 점수를 달성했습니다.

###### El-Kawaref at WojoodNER shared task: StagedNER for Arabic Named Entity Recognition (https://aclanthology.org/2023.arabicnlp-1.91/)
- Anthology ID: 2023.arabicnlp-1.91 
- Volume: Proceedings of ArabicNLP 2023 
- Summary: 
    1. Named Entity Recognition (NER)은 위치, 조직, 인물, 화폐와 같은 개체에 해당하는 단어를 식별하는 작업이다. 이 논문에서는 아랍어에서 flat-entity classification 작업을 다루며, 각 단어에 대해 하나의 개체를 식별해야 한다.
    2. 우리는 StagedNER라는 새로운 기술을 제안하여 NER 다운스트림 작업의 fine-tuning을 수행한다. 이 기술은 transformer 모델의 학습 과정을 두 단계로 나누어 시퀀스 태그와 개체 태그를 따로 학습함으로써 분류 문제를 해결한다.
    3. 이 방법을 사용하여 두 개의 기본 모델의 앙상블을 만들고, 개발 집합에서의 점수는 XXX이며, 검증 집합에서의 F1 성능은 90.03%이고 테스트 집합에서의 F1 성능은 91.95%이다.

## Proceedings of the 10th Workshop on Argument Mining
###### Proceedings of the 10th Workshop on Argument Mining (https://aclanthology.org/2023.argmining-1.0/)
- Anthology ID: 2023.argmining-1.0 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Detecting Argumentative Fallacies in the Wild: Problems and Limitations of Large Language Models (https://aclanthology.org/2023.argmining-1.1/)
- Anthology ID: 2023.argmining-1.1 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 기존의 자연어 텍스트에서 오류를 식별하는 방법은 실험 환경을 국한시키기 때문에 실제 상황에서의 적용성과 유용성을 이해하기 어렵다. 본 논문에서는 자연어 텍스트에서의 오류 식별에 대한 데이터 기반 방법의 한계를 분석한다.
    2. 이를 위해 우리는 첫째로 자연어 논증 체계로 이루어진 검증용 말뭉치를 생성하였으며, 둘째로 자연어 텍스트에서의 오류 식별 작업에 대한 새로운 경험적 결과를 제공한다.
    3. 또한 새로운 검증용 말뭉치를 고려하여 테스트 데이터 도메인 외부에서 관찰된 오류들을 분석하고, 이에 대한 중요한 한계점을 지적하며 향후 연구에 반영해야 할 사항들을 제시한다. 특히, 우리가 이러한 시스템을 실제 현장에 도입하려면.

###### Using Masked Language Model Probabilities of Connectives for Stance Detection in English Discourse (https://aclanthology.org/2023.argmining-1.2/)
- Anthology ID: 2023.argmining-1.2 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 이 연구는 주장의 입장을 탐지하기 위해 담화 연결어의 역할을 operation하는 접근법을 소개한다. 
    2. 이 연구는 주장과 그를 지지하거나 반대하는 전제 사이에 삽입된 담화 연결어의 확률을 이용하여 그 유틸리티를 조사한다. 
    3. LightGBM 분류기를 사용하여 영어 담화에서 주장 탐지를 위한 유망한 결과를 보여주며, 이러한 특징들이 주장 탐지를 포함한 논거 분석 작업을 향상시키는 잠재력을 강조한다.

###### Teach Me How to Argue: A Survey on NLP Feedback Systems in Argumentation (https://aclanthology.org/2023.argmining-1.3/)
- Anthology ID: 2023.argmining-1.3 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 교육에서 논증을 사용하는 것은 학생들의 비판적 사고 기술을 향상시키는 데 도움이되었고, 논증을 위한 컴퓨터 모델도 개발되어이 프로세스를 더 지원하고 있다. 
    2. 그러나 이러한 모델은 논증의 특정 점수를 예측한 이유, 즉 왜 논쟁이 좋거나 나쁜지 설명할 수 없기 때문에, 사용자에게 건설적인 피드백을 제공하여 비판적 사고 기술을 강화하기가 어렵다.
    3. 이 논문에서는 NLP 피드백 시스템을 탐색하고 각각의 피드백을 "풍부성, 시각화, 상호 작용 및 개인화"라는 네 가지 중요한 피드백 차원으로 분류한다.

###### Constituency Tree Representation for Argument Unit Recognition (https://aclanthology.org/2023.argmining-1.4/)
- Anthology ID: 2023.argmining-1.4 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 기존의 문장에서 주제를 추출하는 방법은 단어의 근접성에만 의존하기 때문에 문장의 통사구조를 고려하지 않는다. 우리는 문장의 구성성 트리 표현을 활용하여 토큰 수준에서 주장 단위(ADU)를 예측하는 이점을 조사한다.
    2. 우리는 문장 내의 주장의 구조 특성을 포착하기 위해 구성성 트리 표현을 사용하는 효과를 평가한다. 우리는 근접한 단어 간의 단순한 선형 의존성보다 구성성 구조가 더 효과적임을 경험적으로 보여준다.
    3. 우리의 접근 방식은 구성성 트리와 함께 그래프 신경망을 활용하여 주장 단위 인식을 위해 특정하게 적용한다. 우리의 모델은 토큰 수준에서 주장 단위를 인식하는 기존의 방법보다 우수한 결과를 보여준다.

###### Stance-Aware Re-Ranking for Non-factual Comparative Queries (https://aclanthology.org/2023.argmining-1.5/)
- Anthology ID: 2023.argmining-1.5 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 비팩티브 비교 쿼리를 기반으로 랭킹을 재정렬하는 방식을 제안하고, 비교 대상에 대한 태도를 표현하는 결과를 고려하여 검색 효과를 향상시킨다. 
    2. Touché 2022에서 비교적인 인수 검색에 대해 제출된 26개의 결과에 적용하여, 완벽한 오라클 스탠스 레이블이 사용 가능할 때 우리의 스탠스-의식적 재랭킹은 모든 결과에 대해 검색 효과를 크게 향상시킨다. 
    3. GPT-3.5를 기반으로 한 실용적인 스탠스 탐지기를 사용할 때 우리의 재랭킹은 모든 결과에 대해 효과를 향상시키지만, 유의한 향상은 단 6개뿐이다.

###### Legal Argument Extraction from Court Judgements using Integer Linear Programming (https://aclanthology.org/2023.argmining-1.6/)
- Anthology ID: 2023.argmining-1.6 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 법적 주장은 법적 지식의 핵심 요소 중 하나이며, 법원 판결의 비구조적인 텍스트에서 다양한 방식으로 표현된다. 법원 판결에서 주장을 추출하여 범주화하고 구조화된 형식으로 저장하여 과거 주장의 대량 데이터베이스를 생성할 수 있다. 이러한 데이터베이스는 새로운 사건에 적합한 주장을 제안하는 데 유용할 것이다.
    2. 이 논문에서는 minimal supervision을 사용하여 인도의 최고 법원 판결에서 주장을 추출하는 것에 초점을 맞추었다. 
    3. 우리는 먼저 주장 추출에 유용한 일부 문장 수준의 주장 표식을 식별하고, Integer Linear Programming (ILP)를 사용하여 여러 개의 약한 증거를 결합하여 전체 문서 수준의 최적 법적 주장을 얻는 유연한 텍스트 분할 문제로 법적 주장 추출 문제를 모델링했다.

###### Argument Detection in Student Essays under Resource Constraints (https://aclanthology.org/2023.argmining-1.7/)
- Anthology ID: 2023.argmining-1.7 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 비교적 변덕스러운 패턴에 의존하는 딥 모델의 robustness 한계로 인해, 대조 학습과 반사적 augmentation을 활용하여 robustness를 향상시키려고 한다.
    2. 여러 counterfactual들을 종합하여 예측 분포를 공동 결정하여 각 용어의 인과관계를 강하게 지도하는 새로운 augmentation을 제안한다.
    3. 실험 결과는 집합적 의사 결정 기반 새로운 방법을 사용하여 task model 이펙트(bias)에 덜 민감하며, 다양한 차원에서 효과적으로 개선되었음을 보여준다.
    
    1. 학생들의 비판적 사고 발달과 교육, 직업 발전에 있어서 효과적인 주장력은 중요하다. 주장 요소를 탐지하는 것은 학생들의 주장력 평가 시스템 개발에 중요하다.
    2. 기존의 지도 학습 방법은 대량의 신뢰할 수 있는 학습 예제가 필요하지만, 학생 작문에 대해서는 사용하기 어려울 수 있다.
    3. low-resource argument detection을 위한 intrinsic entailment 관계와 prompt-tuning 전략을 결합하여 데이터 및 계산 요구를 줄이는 low-resource classification 접근 방법을 제안한다. 실험 결과는 예측 정확도를 저해하지 않으면서도 argument detection 모델의 훈련에 필요한 데이터와 계산 요구를 줄이는 우리의 방법의 효과적임을 보여준다.

###### Towards Fine-Grained Argumentation Strategy Analysis in Persuasive Essays (https://aclanthology.org/2023.argmining-1.8/)
- Anthology ID: 2023.argmining-1.8 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 우리는 argumentation 전략을 효과적이고 설득력 있는 텍스트를 작성하는 데 사용되는 수단으로 정의하였다. 이전 연구들은 상대적으로 대략적인 분석을 수행했으나, 우리는 더 상세한 분석을 위해 더 나아갈 것이다.
    2. 우리는 Argument Annotated Essays corpus의 주장과 전제의 특정 유형에 대한 주석을 확장하고, 이들을 자동으로 식별하기 위한 모델을 제안하고 첫 번째 결과를 제시한다.
    3. 또한, 에세이 구조, argument 구성 요소의 "흐름", 주장-전제 구성 요소의 형성 방식, 에세이 종류 및 개별 작성자의 역할과 관련하여 나타나는 사용 패턴에 대해 논의한다.

###### Dimensionality Reduction for Machine Learning-based Argument Mining (https://aclanthology.org/2023.argmining-1.9/)
- Anthology ID: 2023.argmining-1.9 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 기계 학습 알고리즘을 훈련시키는 데 사용되는 고차원 언어 기능 벡터 대신에, 입력 데이터의 차원을 줄이는 것의 잠재적 이점을 조사하였고, argument mining 작업에서 효과적인 결과를 보여주었다.
    2. 새로운 argumentative corpus(논문에서는 e-participation)에 SVD, PCA, LDA 기법을 적용하여 차원을 줄이는 실험을 실시하여, 계산 효율성과 논증 정보 추출 효과에 긍정적인 결과를 얻었다.
    3. argumentative fragment detection, argument component classification, argumentative relation recognition 등의 주요 argument mining 작업에서, 입력 기능 수의 3-4% 정도의 차원에서도 전체 corpus를 사용한 경우와 비교할 때 약 95-97%의 성능을 얻을 수 있었다.

###### On the Impact of Reconstruction and Context for Argument Prediction in Natural Debate (https://aclanthology.org/2023.argmining-1.10/)
- Anthology ID: 2023.argmining-1.10 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 토론 자연성은 작고 구조화된 주제 중심의 상황에서 크고 자발적이며 제약이 적은 환경까지 다양하게 범위가 있다.
    2. 우리는 대화 기여를 복원하여 대화 구문 분석이 인과관계 예측에 어떤 영향을 미치는지 연구하고, 문맥 정보를 결합하는 효과를 조사한다.
    3. 우리의 초기 가정과는 달리 복원은 예측을 향상시키지 않으며, 문맥은 제안과 결합해서만 사용할 때만 예측을 향상시킨다는 것을 발견했다.

###### Unsupervised argument reframing with a counterfactual-based approach (https://aclanthology.org/2023.argmining-1.11/)
- Anthology ID: 2023.argmining-1.11 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. "프레이밍은 토론에 참여하는 참가자들이 자신의 견해를 지원하는 측면이나 차원을 강조하는 중요한 메커니즘이다. 
    2. 우리는 eXplainable AI (XAI) 분야에서 카운터팩투얼 설명 생성 방법으로부터 영감을 받아 인자 재프레이밍의 비지도 학습 방법을 제안한다. 
    3. 우리의 방법은 프레임을 제거하고 대상 프레임과 관련된 다른 토큰으로 바꾸는 마스크-앤-리플레이스 접근 방식으로 공식화되며, XAI에서 사용되는 여러 메트릭과 유사한 지표를 기반으로 재프레임에 적합한 카운터팩투얼을 찾기 위한 재판정 기법을 사용한다."

###### Overview of ImageArg-2023: The First Shared Task in Multimodal Argument Mining (https://aclanthology.org/2023.argmining-1.12/)
- Anthology ID: 2023.argmining-1.12 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. ImageArg 공유 작업은 Argument Mining 워크샵과 함께 열린 최초의 다중모달 (multimodal) Argument Mining 공유 작업 자세한 개요를 제공한다.
    2. Subtask-A는 토론 대상에 대한 이미지와 텍스트를 포함한 트윗의 입장 (stance) 판별을 수행하며, Subtask-B는 이미지가 트윗 텍스트를 더 설득력있게 만드는지를 분류한다.
    3. 이 공유 작업은 6개 국가에서 9개의 다른 팀으로부터 Subtask-A에는 31개 제출, Subtask-B에는 21개의 제출을 받았으며, 각각 최고의 성능을 보인 F1-score는 각각 0.8647과 0.5561이다.

###### IUST at ImageArg: The First Shared Task in Multimodal Argument Mining (https://aclanthology.org/2023.argmining-1.13/)
- Anthology ID: 2023.argmining-1.13 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. ImageArg는 다중 모달 설득 기술을 발전시키기 위한 10th ArgMining Workshop에서의 공유 과제로, ImageArg 데이터셋을 활용한다.
    2. 이 도전은 두 가지 다른 하위 과제로 구성되는데, 1) 주장적 입장 (AS) 분류: 주어진 트윗이 주장적인 입장을 취하는지를 평가한다. 2) 이미지 설득력 (IP) 분류 : 트윗 이미지가 트윗의 설득력을 향상시키는지 여부를 결정한다.
    3. 우리는 두 하위과제에서 다양한 실험을 진행하였으며, 9개 팀 중 6위를 차지했다.

###### TILFA: A Unified Framework for Text, Image, and Layout Fusion in Argument Mining (https://aclanthology.org/2023.argmining-1.14/)
- Anthology ID: 2023.argmining-1.14 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. Argument Mining (AM)은 작가의 입장을 분석하는 것이 주요 목표인데, 이 논문에서는 텍스트뿐만 아니라 이미지도 포함하는 AM 데이터셋을 소개한다.
    2. 본 논문에서는 TILFA라는 새로운 프레임워크를 제안하여 텍스트 이해 뿐만 아니라 이미지의 광학 문자와 레이아웃 세부사항을 감지할 수 있다.
    3. KnowComp 팀의 모델은 이미지 및 텍스트 퓨전에 우수한 성능을 보여 기존 베이스라인보다 훨씬 뛰어나며, 이번 대회의 Argumentative Stance Classification 하위태스크에서 1위를 차지했다.

###### A General Framework for Multimodal Argument Persuasiveness Classification of Tweets (https://aclanthology.org/2023.argmining-1.15/)
- Anthology ID: 2023.argmining-1.15 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 텍스트에 이미지를 첨부하여 텍스트의 설득력을 높이는 것이 중요한데, ImageArg 싱글 테스크에서는 텍스트와 이미지에 대한 분류와 이미지가 텍스트의 설득력에 미치는 영향을 예측하였다.
    2. 이 논문에서는 사전 훈련된 모델을 사용하여 텍스트와 이미지 특징을 추출하고 이를 과제별 분류 모델에 사용하는 방법을 제안하였다.
    3. 실험 결과, CLIP 모델이 특히 과제 A에서의 특징 추출에 중요한 역할을 하는 것으로 확인되었다.

###### Webis @ ImageArg 2023: Embedding-based Stance and Persuasiveness Classification (https://aclanthology.org/2023.argmining-1.16/)
- Anthology ID: 2023.argmining-1.16 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. Webis는 ImageArg 2023의 두 가지 subtask에 참여했으며, argumentative stance classification subtask에서는 BERT 모델을 사용하여 F1 스코어 0.84를 달성했다.
    2. image persuasiveness classification subtask에서는 CLIP 임베딩과 신경망 모델을 사용하여 F1 스코어 0.56을 달성하여 이 대회에서 이 subtask에서 최고의 성능을 보였다.
    3. 우리의 분석 결과, "I support gun control"와 같이 분명한 문장도 우리의 경쟁력 있는 stance classifier에 여전히 문제가 있으며, 트윗 텍스트를 무시한 이미지 설득력 예측 모델은 최고 성능 모델과 유사한 효과를 갖는다는 것을 보여준다.

###### GC-Hunter at ImageArg Shared Task: Multi-Modal Stance and Persuasiveness Learning (https://aclanthology.org/2023.argmining-1.17/)
- Anthology ID: 2023.argmining-1.17 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 소셜 미디어의 중요성이 증가함에 따라 사용자들은 글에 이미지를 삽입하는 경우가 많아졌다. 이러한 트렌드로 인해 소셜 미디어 메시지의 자동 처리에 새로운 도전이 발생하고 있다.
    2. 본 논문에서는 ImageArg 공유 작업의 두 가지 주요 목표에 대해 다루고 있다. 첫째로, 다중모달 트윗에 대한 태도(stance)를 결정하는 것이다. 우리는 트윗 텍스트와 이미지 텍스트를 연결(concatenation)하여 transformer 기반 모델을 fine-tuning 하는 강력한 베이스라인을 제시한다.
    3. 둘째로, 다중모달 트윗에서 이미지의 설득력에 대한 예상을 하는 것이다. 우리는 데이터에 대해 비전 모델과 언어 모델을 훈련시키고, 다른 특징 집합을 모델과 병합하여 예측력을 향상시켜 이미지의 설득력을 캡처한다. 이러한 목표들은 결국 소셜 미디어에서의 다중모달 메시지와 이미지와 텍스트의 관계를 이해하는 더 큰 목표에 기여한다.

###### Argumentative Stance Prediction: An Exploratory Study on Multimodality and Few-Shot Learning (https://aclanthology.org/2023.argmining-1.18/)
- Anthology ID: 2023.argmining-1.18 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 다중 모달 문제로서의 주장 의견 예측을 진전시키기 위해, 다중 모달 주장 분석의 첫번째 공유 작업은 gun control과 abortion과 같은 중요한 사회적 주제에서 주장 의견 예측을 진행했다.
    2. 우리의 실험적 연구는 트윗에서 주장 의견 예측에 대한 이미지의 필요성을 평가하고, out-of-the-box 텍스트 기반 큰 언어 모델을 적은 양의 데이터에서 세부 조정된 유니모달 및 다중 모달 모델과 비교한다.
    3. 결과로서 텍스트 기반 언어 모델의 앙상블 (0.817 F1-score)이 다중 모달 (0.677 F1-score) 및 최신의 상위 성능을 내는 텍스트 기반 적은 양의 데이터 예측 (0.550 F1-score)보다 우수함을 나타내고, 이미지 내용을 자연어로 요약하는 것이 다중 모달 모델의 성능 향상에 도움이 된다는 것을 보여준다.

###### SPLIT: Stance and Persuasion Prediction with Multi-modal on Image and Textual Information (https://aclanthology.org/2023.argmining-1.19/)
- Anthology ID: 2023.argmining-1.19 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. "설득력은 연설자가 청중의 신념, 태도, 의지, 동기 및 행동에 영향을 끼칠 수 있는 두드러진 성격 특성이다."
    2. "ImageArg 과제는 EMNLP 2023의 10번째 ArgMining 워크샵에서 다중모달 설득 기술을 발전시키기 위해 ImageArg 데이터셋의 잠재력을 활용하는데 초점을 맞추고 있다."
    3. "우리는 이 연구에서 양두모달 데이터셋의 활용과 세 가지 다른 다중모달 모델을 평가한다. 최첨단 모델의 장점과 제약을 보여주기 위해 다중모달 데이터셋을 개선한다."

###### Semantists at ImageArg-2023: Exploring Cross-modal Contrastive and Ensemble Models for Multimodal Stance and Persuasiveness Classification (https://aclanthology.org/2023.argmining-1.20/)
- Anthology ID: 2023.argmining-1.20 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 해당 논문은 이미지에 대한 트윗의 태도를 식별하고, 특정 주제에 대한 설득력 점수를 결정하는 ImageArg-2023 공유 작업에 대한 시스템을 설명합니다.
    2. 텍스트 기반의 접근 방식을 사용하여 트윗의 논쟁적 태도를 분류하기 위해 여러 개의 변형 모델을 사용합니다.
    3. 놀랍게도, 트윗의 텍스트 기반 접근 방식이 다중 모달 접근 방식보다 성능이 더 우수함을 보였습니다.

###### Overview of PragTag-2023: Low-Resource Multi-Domain Pragmatic Tagging of Peer Reviews (https://aclanthology.org/2023.argmining-1.21/)
- Anthology ID: 2023.argmining-1.21 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. Peer review는 과학에서 핵심 품질 통제 메커니즘이다. Peer review의 핵심 요소는 리뷰 보고서로, 리뷰어가 작업을 평가하고 저자에게 제안을 하는 논쟁적인 텍스트이다.
    2. 기존 NLP 연구는 주로 기계 학습 컨퍼런스의 리뷰에 집중해 왔으나, NLP 모델은 도메인 변화에 취약하며, 새로운 연구 커뮤니티의 리뷰에 적용할 때 성능이 저하될 수 있다.
    3. 피어 리뷰 데이터는 일반적으로 입수하기 어렵고 비싸게 라벨링해야 하는 어려움이 있다. 따라서 피어 리뷰의 저자별 문장 분류 작업에서 도메인 강인성을 높이고 데이터 부족 문제를 해결하기 위한 방법을 탐구하는 PragTag-2023 Shared Task가 소개되었다.

###### CATALPA_EduNLP at PragTag-2023 (https://aclanthology.org/2023.argmining-1.22/)
- Anthology ID: 2023.argmining-1.22 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 이 논문은 PragTag-2023 Shared Task에 대한 기여를 설명한다. 문장 분류, 문장 유사도 및 시퀀스 태깅을 기반으로 한 다양한 접근 방식을 설명하고 비교한다.
    2. 문장 분류 기반의 BERT를 사용한 접근 방식이 시퀀스 태깅 및 SBERT를 기반으로 한 문장 분류보다 우수한 성능을 보인다.
    3. 또한, 다른 접근 방식을 결합하는 것의 잠재력을 강조하는 분석 결과를 제시한다.

###### DeepBlueAI at PragTag-2023:Ensemble-based Text Classification Approaches under Limited Data Resources (https://aclanthology.org/2023.argmining-1.23/)
- Anthology ID: 2023.argmining-1.23 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 리뷰 데이터의 부족과 주석 작업의 고비용으로 인해, 이 논문에서는 한정된 데이터를 사용하여 사전 훈련된 모델의 규모 조정에 중점을 두고 있다.
    2. 모델의 강건성을 향상시키기 위해 적대적 훈련 기법을 사용한다.
    3. 약간의 변형을 도입하여 모델이 적대적 공격과 능숙하게 대응하고 입력 데이터의 안정성을 향상시키도록 한다.

###### MILAB at PragTag-2023: Enhancing Cross-Domain Generalization through Data Augmentation with Reduced Uncertainty (https://aclanthology.org/2023.argmining-1.24/)
- Anthology ID: 2023.argmining-1.24 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. PragTag task에 대한 논문에서는 동료 리뷰의 각 문장을 6가지 유형의 pragmatic 태그 중 하나로 분류하기 위한 접근 방식을 설명한다. 
    2. 도메인의 불일치로 인해 어렵기 때문에, pseudo-labeling과 synonym generation과 같은 데이터 증강 기술을 사용하여 데이터 불균형과 부족 문제를 해결하려고 한다. 
    3. 실험 결과, zero 조건에서는 첫 번째 순위, full과 low 조건에서는 세 번째 순위를 달성하며 우리의 접근법이 효과적임을 입증하였다.

###### NUS-IDS at PragTag-2023: Improving Pragmatic Tagging of Peer Reviews through Unlabeled Data (https://aclanthology.org/2023.argmining-1.25/)
- Anthology ID: 2023.argmining-1.25 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. "우리는 EMNLP-2023에서의 Pragmatic Tagging of Peer Reviews Shared Task를 위한 모델에 대해 설명한다. 우리는 위의 대회 과제에 대해 다양한 최신 transformer 모델을 사용하여 다중 문장 분류 모델을 훈련시켰다."
    2. "무감독 데이터에 대한 여러 모델의 예측을 결합하여 미분류 인스턴스를 임시로 라벨을 지정하고 예측 과제에서의 성능 향상을 위해 데이터셋을 증강했다."
    3. "특히, F1000RD corpus에서는 전체 훈련 데이터의 10%만 사용하면서도 100% 훈련 데이터로 훈련된 모델과 비슷한 성능을 내었다. 대회 데이터셋 전체에서 다양한 데이터 조건에 대해 상위 2위 중에 속한다."

###### SuryaKiran at PragTag 2023 - Benchmarking Domain Adaptation using Masked Language Modeling in Natural Language Processing For Specialized Data (https://aclanthology.org/2023.argmining-1.26/)
- Anthology ID: 2023.argmining-1.26 
- Volume: Proceedings of the 10th Workshop on Argument Mining 
- Summary: 
    1. 대부분의 transformer 모델은 Wikipedia와 Reddit와 같은 포럼에서 얻은 영어 언어 말뭉치로 학습되는데, 이러한 모델은 과학적 피어 리뷰, 법률 및 의료와 같은 특수 분야에서 사용되지만, 이러한 특화된 도메인과 관련된 데이터에 포함된 정보가 없기 때문에 성능이 좋지 않다. 
    2. 이러한 모델이 특화된 도메인에서 최대한 좋은 성능을 내기 위한 방법 중 하나는 해당 도메인의 레이블이 지정된 데이터를 수집하여 선택한 transformer 모델에 대해 fine-tuning하는 것이다. 
    3. 그러나 이는 많은 레이블이 지정된 데이터를 수집해야 하고, 상당한 수작업이 필요하다는 어려움이 있다. 따라서 레이블이 지정되지 않은 도메인 특정 데이터를 사용하여 transformer 모델을 사전 학습하고 이 모델을 레이블이 지정된 데이터로 fine-tuning하는 방법도 있다.

## Proceedings of the First Workshop on Bangla Language Processing (BLP-2023)
###### Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) (https://aclanthology.org/2023.banglalp-1.0/)
- Anthology ID: 2023.banglalp-1.0 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Offensive Language Identification in Transliterated and Code-Mixed Bangla (https://aclanthology.org/2023.banglalp-1.1/)
- Anthology ID: 2023.banglalp-1.1 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 온라인 커뮤니티를 안전하게 만들기 위해서는 소셜 미디어에서의 모욕적인 콘텐츠를 식별하는 것이 중요하다. 본 논문은 다국어 사회에서 일반적인 언어 현상인 표기변경과 코드믹싱으로 구성된 텍스트에서 모욕적 언어를 식별하는 방법을 탐구한다. 
    2. 우리는 5,000개의 수작업으로 주석이 달린 코멘트가 포함된 표기변경된 방글라어 모욕적 언어 데이터셋인 TB-OLID를 소개한다. 
    3. TB-OLID에서 기계 학습 모델을 훈련 및 세밀화한 후 이 데이터셋에서 결과를 평가한 결과, fBERT와 HateBERT와 같은 영어로 사전 훈련된 transformer 기반 모델이 가장 우수한 성능을 보여주었다.

###### BSpell: A CNN-Blended BERT Based Bangla Spell Checker (https://aclanthology.org/2023.banglalp-1.2/)
- Anthology ID: 2023.banglalp-1.2 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 방글라어 타이핑은 주로 영어 키보드를 사용하며, 조합된 문자와 비슷한 발음의 문자 때문에 맞춤법이 많이 틀리다. 
    2. 이 논문에서는 문장 수준에서 단어를 단어별로 수정하기 위해 BSpell 이라는 특화된 BERT 모델을 제안한다. 
    3. BSpell은 스펠링 에러가 있는 상황에서 highly inflected 방글라 단어에 특화된 CNN 하위 모델인 SemanticNet과 특화된 보조 손실을 포함하고 있다.

###### Advancing Bangla Punctuation Restoration by a Monolingual Transformer-Based Method and a Large-Scale Corpus (https://aclanthology.org/2023.banglalp-1.3/)
- Anthology ID: 2023.banglalp-1.3 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 문장부호 복구는 텍스트 내 누락되거나 잘못 된 문장부호를 복원하고 온문에서 모호성을 제거하기 위한 작업이다. 하지만 방글라어에서는 이 작업이 적게 주목받아왔으며, 이를 위한 transformer 기반 방법과 대규모 말뭉치의 활용 등의 문제가 여전히 해결되지 않은 상태이다.
    2. 본 연구에서는 Jatikarok이라는 단일 언어 transformer 기반 방법을 제안하고, 전이 학습의 효과를 철저히 조사하며 이전의 문제를 해결하기 위해 1.48M개의 소스-타겟 쌍을 포함하는 대규모 말뭉치를 제공하였다.
    3. Jatikarok은 BanglaPRCorpus, Prothom-Alo Balanced, BanglaOPUS 말뭉치에서 95.2%, 85.13%, 91.36%의 정확도를 달성하여 BanglaT5 및 T5-Small 대비 우수한 성능으로 state-of-the-art 방법임을 입증하였다. Jatikarok과 BanglaPRCorpus는 공개적으로 사용 가능하다.

###### Pipeline Enabling Zero-shot Classification for Bangla Handwritten Grapheme (https://aclanthology.org/2023.banglalp-1.4/)
- Anthology ID: 2023.banglalp-1.4 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 이 연구는 Zero-Shot Learning (ZSL)을 조사하고 CycleGAN 기반의 이미지 합성과 정확한 레이블 매핑을 제안하여 레이블과 그래프 사이에 강한 연관성을 형성한다. 이를 통해 보이지 않는 클래스를 탐지하는 모델의 정확성을 향상시키는 것을 목표로 한다. 
    2. 본 연구는 복잡한 벵골어 문자 인식 문제를 다룬다. 그래프의 복잡한 배열로 인해 문자 조합은 영어보다 많은 약 13,000개의 고유한 변형을 만들어 낼 수 있다. 
    3. 벵골어 OCR의 진척을 향상시키기 위해 생성 모델과 신중한 레이블링 기술을 결합하는 새로운 ZSL 전략을 제시한다. 이는 인도 하위대륙의 교육 자원의 디지털화에 상당한 영향을 미치고자 하는 것이다.

###### Low-Resource Text Style Transfer for Bangla: Data & Models (https://aclanthology.org/2023.banglalp-1.5/)
- Anthology ID: 2023.banglalp-1.5 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 주어진 텍스트의 언어적 스타일을 변경하면서 핵심 콘텐츠를 유지하는 텍스트 스타일 변환 작업이 있다. 그러나 이 논문은 이러한 작업을 수행하는 데에 어려움이 있는 방글라어 언어로 된 텍스트 스타일 변환에 대해 다루고 있다.
    2. 방글라어를 이용한 텍스트 감정 전환 데이터셋을 제안함으로써 이 작업의 어려움을 극복하려고 한다. 이 데이터셋을 사용하여 긍정적인 감정 문장을 부정적으로 변환하거나 그 반대로 변환할 수 있도록 한다.
    3. 더 나은 연구를 위해 기존의 영어 데이터셋을 정제하고 수정하고, 영어 자료와 유사한 방글라어 데이터셋을 소개한다. 또한 데이터셋을 검증하고 더 나은 연구를 위한 베이스라인으로 사용될 수 있는 여러 벤치마크 모델을 제공한다.

###### Intent Detection and Slot Filling for Home Assistants: Dataset and Analysis for Bangla and Sylheti (https://aclanthology.org/2023.banglalp-1.6/)
- Anthology ID: 2023.banglalp-1.6 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 음성 어시스턴트가 우리의 기술적으로 선진화된 사회에서 자리를 잡으면서, 비공식적인 형태의 저자원 언어를 포함한 다양한 언어적 환경에 대응할 필요가 여전히 존재한다.
    2. 이 연구는 형식적인 방글라어, 비공식적인 방글라어, 실헤티어에서의 의도 감지와 슬롯 채우기에 대한 포괄적인 데이터셋을 처음으로 제시한다.
    3. 우리의 분석 결과는 대용량 언어 모델의 강건성과 작은 데이터로도 다양한 하위 작업을 처리하는 능력을 보여준다. 또한, GPT-3.5 모델은 비공식적인 방글라어에서 의도 감지에서 0.94의 F1 점수, 슬롯 채우기에서 0.51의 F1 점수를 달성한다.

###### BEmoLexBERT: A Hybrid Model for Multilabel Textual Emotion Classification in Bangla by Combining Transformers with Lexicon Features (https://aclanthology.org/2023.banglalp-1.7/)
- Anthology ID: 2023.banglalp-1.7 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 다중 수준 텍스트 감성 분류는 텍스트 데이터에서 감정을 추출하는 작업으로, 고대용량 언어에 대해서는 상당한 진전이 있었으나 Bangla와 같은 저자원 언어에는 상대적으로 덜 주목되고 있다.
    2. 본 논문에서는 Bangla 언어를 위해 lexicon 특징과 transformers를 결합한 하이브리드 모델을 제안한다.
    3. 실험 결과 lexicon 특징을 transformers와 통합하는 것이 성능을 크게 향상시킨다는 것을 보였으며, 제안한 하이브리드 접근법은 BanglaBERT와 감정 lexicon을 사용하여 가장 높은 성능을 달성한다.

###### Assessing Political Inclination of Bangla Language Models (https://aclanthology.org/2023.banglalp-1.8/)
- Anthology ID: 2023.banglalp-1.8 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 인공지능 주도 언어 모델의 발전으로 자연어 처리는 텍스트 생성부터 질문에 답하기까지 넓은 범위에서 적용되고 있다. 
    2. 그러나 이 모델들은 다양한 데이터 소스에서 사전 학습되는 과정에서 훈련 데이터 내에서 포함된 다양한 시각을 무의식적으로 흡수하게 된다. 
    3. 이 논문은 저자들이 사회적, 경제적 차원에 초점을 맞추어 방글라 언어 모델 내에 존재하는 편향성을 포괄적으로 분석하고, 배울 점과 주의해야 할 윤리적 고려사항과 한계에 대한 통찰을 제공한다.

###### Vio-Lens: A Novel Dataset of Annotated Social Network Posts Leading to Different Forms of Communal Violence and its Evaluation (https://aclanthology.org/2023.banglalp-1.9/)
- Anthology ID: 2023.banglalp-1.9 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 이 논문에서는 방글라데시와 인도 서벵갈 지역의 사회적 폭력에 관련된 데이터셋을 생성하고, 평가하기 위한 계산적 접근 방식을 제안한다.
    2. 소셜 미디어가 종교적·인종적 혐오를 조장하여 실제 폭력으로 이어지는 문제를 해결하기 위해, 우리는 적응형 질문 기반 접근 방식을 사용하여 온라인 게시물을 분류하는 프레임워크를 제안한다.
    3. 수작업으로 선택된 폭력 조장 동영상에서 168,000개 이상의 YouTube 댓글을 수집하고, 비구조화된 데이터에 대해 비지도 및 반지도 학습 기법을 사용하여 평화와 폭력에 관련된 주요 단어 집합을 발견하였으며, 이를 통해 레이블이 부여된 6,046개의 게시물을 검증하기 위해 언어적 특징 및 문장 변형기법을 적용하여 최고 성능 모델에서 약 71%의 매크로 F1 점수로 평가하였다.

###### BanglaCHQ-Summ: An Abstractive Summarization Dataset for Medical Queries in Bangla Conversational Speech (https://aclanthology.org/2023.banglalp-1.10/)
- Anthology ID: 2023.banglalp-1.10 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 온라인 건강 상담은 환자들이 의료 문의를 나누는 플랫폼으로 인기를 얻고 있으며 COVID-19 대유행으로 인하여 더 많은 질문이 달려, 한정된 의료진에게 부담을 주고 있다.
    2. 추상적 텍스트 요약은 이 도전에 대한 유망한 솔루션이며, CHQ(Consumer Health Questions)를 답변하는 데 필요한 정보만 요약함으로써 불필요한 정보를 파싱하는 데 필요한 시간을 줄일 수 있는 장점을 가진다. 이 요약 과정은 최종적으로 자동 의료 질문-응답 시스템을 개발하기 위한 중간 단계로서도 활용될 수 있다.
    3. 이 논문은 예를 들어, 2,350개의 질문-요약 쌍으로 구성된 배제어 요약 데이터셋인 'BanglaCHQ-Summ'을 제공하며, Bangla 및 다국어 텍스트 생성 모델과의 벤치마크를 제시하였다. 최고 성능을 내는 BanglaT5 모델은 ROUGE-L 점수 48.35%를 달성하였고, 인간 평가를 통해 요약에 대한 기존 자동 메트릭스의 한계를 해결하였다.

###### Contextual Bangla Neural Stemmer: Finding Contextualized Root Word Representations for Bangla Words (https://aclanthology.org/2023.banglalp-1.11/)
- Anthology ID: 2023.banglalp-1.11 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 기존의 스테머(stemmer) 방법은 NLP에서 단어를 뿌리 형태로 줄이는 데 사용되지만, 이 과정에서 중요한 정보가 손실되고 잘못된 뿌리 형태가 생성되어 NLP 작업의 정확성에 영향을 미칠 수 있다.
    2. 이 논문에서는 방글라어를 위한 문맥적 신경 스테머(Contextual Bangla Neural Stemmer)를 제안하여 단어 표현을 향상시킨다. 
    3. 실험 결과로 우리는 vanilla 방법에 비해 약 5%의 평균 성능 향상을 보였고, BERT 재학습을 회피하면서 OOV(out-of-vocabulary) 단어 및 서브워드 문제를 해결하고 뿌리 단어 감지에 초점을 맞춘 메소드입니다.

###### Investigating the Effectiveness of Graph-based Algorithm for Bangla Text Classification (https://aclanthology.org/2023.banglalp-1.12/)
- Anthology ID: 2023.banglalp-1.12 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 이 연구에서는 방글라 텍스트 분류 작업에 대한 여러 그래프 기반 모델들의 동작을 조사하고 분석한다. 그래프 기반 알고리즘은 텍스트 데이터로부터 이질적 그래프를 생성한다. 각 노드는 단어나 문서를 나타내고, 각 엣지는 두 단어나 단어와 문서 간의 관계를 나타낸다.
    2. BERT 모델과 TextGCN, GAT, BertGAT, BertGCN과 같은 다양한 그래프 기반 모델들을 방글라 텍스트에 대해 SentNoB, Sarcsam detection, BanFakeNews, Hate speech detection, Emotion detection 데이터셋을 사용하여 평가했다.
    3. BERT 모델이 정확도, Macro F1 스코어, weighted F1 스코어 측면에서 TextGCN과 GAT 모델을 큰 차이로 앞서고, BertGCN과 BertGAT이 단독 그래프 모델 및 BERT 모델보다 우수한 성능을 보였다. BertGAT은 Emotion detection 데이터셋에서 높은 성능을 보여주었으며, Sarcasm detection, Hate speech detection, BanFakeNews 데이터셋에서 BERT 성능에 1%-2%까지 향상되었다. BertGCN은 SetNoB, BanFakeNews 데이터셋에서 BertGAT을 1% 이상 앞섰으며, Sarcasm detection, Hate Speech, Emotion detection 데이터셋에서 2% 이상의 성능 향상이 있었다. 그래프 구조의 다양한 변화와 그 영향도 분석했다.

###### SynthNID: Synthetic Data to Improve End-to-end Bangla Document Key Information Extraction (https://aclanthology.org/2023.banglalp-1.13/)
- Anthology ID: 2023.banglalp-1.13 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 엔드투엔드 문서 핵심 정보 추출 모델은 실제 데이터셋에서 잘 작동하기 위해 많은 계산량과 레이블된 데이터가 필요하다. 특히 도메인별 다중모달 문서 데이터셋이 제한적인 번글라(Bangla)와 같은 저자원 언어에 대해서는 이것이 도전적이다.
    2. 우리는 SynthNID라는 시스템을 도입하여 OCR 없는 엔드투엔드 핵심 정보 추출 시스템을 훈련시키기 위한 도메인별 문서 이미지 데이터를 생성했다.
    3. 우리는 생성된 데이터가 실제 데이터셋에서 추출 모델의 성능을 향상시키고, 이 시스템은 다양한 문서 이해 작업에 대해 다른 유형의 스캔된 문서를 생성하는 데 쉽게 확장할 수 있다는 것을 보였다.

###### BaTEClaCor: A Novel Dataset for Bangla Text Error Classification and Correction (https://aclanthology.org/2023.banglalp-1.14/)
- Anthology ID: 2023.banglalp-1.14 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 방글라 언어에서는 다양한 요인으로 인해 온라인 사용자들이 언어를 비틀거나 오류를 만들기 쉽다. 이 논문에서는 기계 학습과 심층 학습 모델을 사용하여 이러한 오류를 탐지, 분류 및 교정하려고 한다. 
    2. 방글라BERT는 오류 범주 분류에서 우수성을 보이며, BanglaT5는 텍스트 교정에 효과적임을 강조한다. 
    3. 이 연구는 방글라어 사용자 커뮤니티에서 디지털 토론의 품질을 향상시키고, 온라인 상호작용에서 언어의 정확성과 일관성을 촉진하는 데 중요한 진전을 나타내고 있다.

###### Crosslingual Retrieval Augmented In-context Learning for Bangla (https://aclanthology.org/2023.banglalp-1.15/)
- Anthology ID: 2023.banglalp-1.15 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 대형 언어 모델 (LLM)은 자연어 처리에서의 성능이 한글 등의 저자원 언어에서 제한되는 문제로 인해 항상 암묵적인 가능성이 가려지고 있었다.
    2. 이를 해결하기 위해 본 논문은 cross-lingual retrieval과 augmented in-context learning을 활용한 선구적인 접근 방식을 제시한다.
    3. 고립된 저자원 언어에서 성능을 획기적으로 향상시키기 위해 고자원 언어로부터 의미론적으로 유사한 프롬프트를 추출하여 다국어 사전훈련 언어 모델 (MPLM)에서 실제로 개선되는 것을 실험 확증하였다.

###### Pseudo-Labeling for Domain-Agnostic Bangla Automatic Speech Recognition (https://aclanthology.org/2023.banglalp-1.16/)
- Anthology ID: 2023.banglalp-1.16 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 낮은 자원 언어에 대한 자동 음성 인식 (ASR) 개발의 주요 도전 중 하나는 도메인 특정 변동성이 있는 레이블이 지정된 데이터에 제한적으로 접근할 수 있다는 점이다.
    2. 우리는 거시적 도메인에 관계없는 ASR 데이터셋을 개발하기 위해 의사 라벨링 접근법을 제안한다. 우리는 다양한 주제, 발화 스타일, 방언, 잡음이 있는 환경 및 대화 시나리오를 포함하는 20,000시간 이상의 Bangla 음성 데이터셋을 개발했다.
    3. 우리의 결과는 의사 라벨 데이터로 훈련된 모델이 공개적으로 사용 가능한 Bangla 데이터셋과 설계된 테스트셋에서의 효과를 입증한다. 실험 자료는 공개적으로 사용 가능하다.

###### BanglaNLP at BLP-2023 Task 1: Benchmarking different Transformer Models for Violence Inciting Text Detection in Bangla (https://aclanthology.org/2023.banglalp-1.17/)
- Anthology ID: 2023.banglalp-1.17 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 본 논문은 방글라어에서 폭력을 선동하는 텍스트를 감지하는 공유 과제를 해결하는 동안 개발한 시스템을 소개한다.
    2. 우리는 전통적인 방법과 최근의 방법을 사용하여 모델을 학습시키기 위해 사용한 접근 방식을 설명한다.
    3. 한정된 데이터셋이 있는 경우 데이터 증강의 영향을 연구하였고, 실험 결과에서 다른 transformer 기반 모델과 비교하여 멀티링귈러-e5-base 모델의 fine-tuning이 최상의 성능을 보였다. 채점에서 우리의 성과는 리더보드에서 23위로 평가되었다.

###### Team CentreBack at BLP-2023 Task 1: Analyzing performance of different machine-learning based methods for detecting violence-inciting texts in Bangla (https://aclanthology.org/2023.banglalp-1.18/)
- Anthology ID: 2023.banglalp-1.18 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 소셜 미디어의 급격한 성장은 소통을 용이하게 해줌과 동시에 혐오 표현에 대한 문제를 야기한다. 이 논문은 폭력 유인 텍스트 탐지를 위한 시스템을 구축하기 위해 다양한 기법을 시도하였다. 
    2. 논문에서는 뱅글라BERT 언어 모델을 fine-tuning 함으로써 가장 좋은 성능을 얻었으며, 대회가 끝난 후에는 데이터 전처리를 통해 성능을 개선할 수 있다고 밝혔다.
    3. 이 연구에서는 폭력 유인 텍스트를 비폭력, 수동 폭력, 직접 폭력으로 분류하는 시스템을 구축하려고 시도하였고, 최종 리더보드에서 27개 팀 중 21위를 차지하였다.

###### EmptyMind at BLP-2023 Task 1: A Transformer-based Hierarchical-BERT Model for Bangla Violence-Inciting Text Detection (https://aclanthology.org/2023.banglalp-1.19/)
- Anthology ID: 2023.banglalp-1.19 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 인터넷의 보편화로 인해 사람들은 소셜 미디어를 통해 정보를 쉽게 공유할 수 있게 되었다. 하지만 악의적인 의도를 가진 사람들은 소셜 미디어를 통해 쉽게 폭력적인 콘텐츠를 공유할 수 있다. 따라서 본 연구는 소셜 미디어에서 방글라 폭력 선동 텍스트를 감지하는 것을 목표로 한다.
    2. BLP 워크샵에서는 방글라 폭력 선동 텍스트 감지를 위한 공유 태스크가 진행되었으며, 이를 위해 VITD 데이터셋을 제공했다. 여러 가지 머신 러닝 및 딥러닝 기법을 사용하여 모델을 구현하고 VITD 데이터셋으로 각 모델을 학습하고 평가한 결과, Hierarchical-BERT 모델이 가장 우수한 결과를 제공했다.
    3. Hierarchical-BERT 모델은 테스트 세트에서 F1 스코어 0.73797의 성능을 보여주었으며, BLP 워크샵의 공유 태스크 1에서 9위를 차지했다.

###### nlpBDpatriots at BLP-2023 Task 1: Two-Step Classification for Violence Inciting Text Detection in Bangla - Leveraging Back-Translation and Multilinguality (https://aclanthology.org/2023.banglalp-1.20/)
- Anthology ID: 2023.banglalp-1.20 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 본 논문에서는 Bangla 언어 처리 (BLP) 워크샵과 함께 열린 Violence Inciting Text Detection (VITD) 공유 태스크에 대한 nlpBDpatriots 의 참가 결과를 논의한다.
    2. 이 태스크의 목표는 파생적인 반합법적 폭력행위를 부추기는 폭력 위협을 식별하고 분류하는 것이다.
    3. Back translation과 multilinguality를 사용한 두 단계 분류가 최고 수행 결과로 27개 팀 중 6위를 차지하며 macro F1 스코어는 0.74이다.

###### Score_IsAll_You_Need at BLP-2023 Task 1: A Hierarchical Classification Approach to Detect Violence Inciting Text using Transformers (https://aclanthology.org/2023.banglalp-1.21/)
- Anthology ID: 2023.banglalp-1.21 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 리소스가 제한된 언어(방글라)에서 폭력성 텍스트를 식별하기 위한 전이 학습 방법론을 제안함. 
    2. 방글라BERT, XLM-R, m-BERT와 같은 transformer 모델을 사용하여 다단계 분류 모델 개발. 
    3. 수행한 시스템은 72.37의 정확도를 얻어 14위를 차지함.

###### Mavericks at BLP-2023 Task 1: Ensemble-based Approach Using Language Models for Violence Inciting Text Detection (https://aclanthology.org/2023.banglalp-1.22/)
- Anthology ID: 2023.banglalp-1.22 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 이 논문은 Bangla 언어 처리에 대한 첫 번째 워크샵의 Violence Inciting Text Detection 공유 과제에 대한 작업을 제시한다. 소셜 미디어는 혐오와 폭력을 부추기는 언어의 전파를 가속화시킨다. 이러한 텍스트의 전파를 탐지하고 억제하기 위한 효율적인 메커니즘을 개발하는 것이 중요하다.
    2. 폭력을 부추기는 텍스트의 탐지 문제는 연구와 데이터가 희소한 저자원 환경에서 더 악화된다.
    3. 우리는 여러 BERT 기반 모델을 시도하고 평가한 후 최종 제출을 위해 모델의 앙상블을 사용한다. 우리의 제출은 macro F1 점수 0.737로 최종 리더보드에서 10위에 해당한다.

###### VacLM at BLP-2023 Task 1: Leveraging BERT models for Violence detection in Bangla (https://aclanthology.org/2023.banglalp-1.23/)
- Anthology ID: 2023.banglalp-1.23 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 이 논문에서는 VITD (Violence Inciting Text Detection) 과제에 대한 VacLM 팀의 시스템을 소개한다. 텍스트 내의 폭력을 감지하기 위해 다양한 transformer-based 모델들의 영향을 분석하였다.
    2. BanglaBERT가 다른 경쟁 모델들보다 우수한 성능을 보였다. transformer-based 모델들은 Passive Violence와 Direct Violence를 구분하는 데는 능숙하지 않았지만, 텍스트 내의 폭력을 감지하는 데에는 우수한 성과를 보였다.
    3. BLP Shared Task에서는 72.656%의 macro F1-score로 12위를 차지했다.

###### Aambela at BLP-2023 Task 1: Focus on UNK tokens: Analyzing Violence Inciting Bangla Text with Adding Dataset Specific New Word Tokens (https://aclanthology.org/2023.banglalp-1.24/)
- Anthology ID: 2023.banglalp-1.24 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. BLP-2023 Task 1은 Bangla YouTube 댓글에서 위협을 감지하고 분석하기 위한 자연어 추론 시스템을 개발하는 것을 목표로 한다.
    2. BanglaBERT와 같은 Bangla 언어 모델은 다양한 Bangla 자연어 처리 작업에서 높은 성능을 보여주었다.
    3. 우리는 BanglaBERT를 사용하여 폭력 감지 작업에 적용하고 새로운 토큰을 도입하여 모델의 성능을 향상시켰다. 이로써 우리의 모델은 테스트 세트에서 76.90%의 매크로 F1 점수를 달성하였다.

###### SUST_Black Box at BLP-2023 Task 1: Detecting Communal Violence in Texts: An Exploration of MLM and Weighted Ensemble Techniques (https://aclanthology.org/2023.banglalp-1.25/)
- Anthology ID: 2023.banglalp-1.25 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 본 연구에서는 벵갈 지역의 폭력적 사건과 관련된 YouTube 댓글에서 폭력 선동 텍스트를 분류하는 공유 작업을 다루고 있다.
    2. 우리는 다양한 종류의 비공식 텍스트에서 사전에 존재하는 Masked Language Model을 꼼꼼히 fine-tuning 함으로써 도메인 적응 기술을 원활하게 통합했다. 이뿐만 아니라 Transfer Learning, Stacking, Ensemble 기법을 결합하여 모델의 성능을 향상시켰다.
    3. Fine-tuning된 BanglaBERT 모델과 Weighted Ensemble 접근법을 통합한 우리의 통합 시스템은 매크로 F1 점수가 각각 71%와 72%로 향상되어 해당 참가자 중 18위를 기록함으로써 디지털 영역 내에서 폭력적인 내러티브의 민감한 감지와 분류에 대한 우리의 제안된 패러다임의 강건성과 정밀성을 강조한다.

###### the_linguists at BLP-2023 Task 1: A Novel Informal Bangla Fasttext Embedding for Violence Inciting Text Detection (https://aclanthology.org/2023.banglalp-1.26/)
- Anthology ID: 2023.banglalp-1.26 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. "폭력 자극 텍스트 탐지" 작업에 대한 비용 효율적인 솔루션을 설계하기 위해 소개된 새로운 informal Bangla word  embedding은 폭력을 분류하고 추가적인 폭력을 일으킬 수 있는 텍스트를 분류하는 분류 시스템을 개발하는 작업에 초점을 맞추었다. 
    2. 우리는 informal Bangla FastText embedding에 대한 반지도 학습 접근법을 제안하며, 작업 특정 데이터셋에서 경량 모델로 fine-tuning을 수행하여 초기 메소드인 BanglaBERT를 대체하는 경쟁력있는 결과를 얻었다.
    3. 우리는 제안된 embedding의 효율성 및 폭력 분류에 대한 일반성, 그리고 작업 데이터셋에 대한 커버리지를 평가하기 위해 포괄적인 실험을 수행하였고, 제안된 Bangla IFT embedding은 경쟁력있는 macro average F1 점수 70.45%를 달성했다.

###### UFAL-ULD at BLP-2023 Task 1: Violence Detection in Bangla Text (https://aclanthology.org/2023.banglalp-1.27/)
- Anthology ID: 2023.banglalp-1.27 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. BLP Shared Task 1: Violence Inciting Text Detection (VITD)에서 UFAL-ULD 팀의 시스템을 소개한다. 이 과제는 폭력 선동 텍스트를 직접, 간접 또는 비폭력 수준으로 분류하는 것을 목표로 한다.
    2. XLM-RoBERTa, BanglaBERT, Bangla BERT Base 및 Multilingual BERT를 포함한 여러 사전 훈련된 sequence classification 모델을 실험하였다.
    3. XLM-RoBERTa 기반의 모델이 최고의 성능을 보여 기준 모델을 능가했고, UFAL-ULD 팀의 시스템은 과제에 참여한 27개 팀 중 20위를 차지했다.

###### Semantics Squad at BLP-2023 Task 1: Violence Inciting Bangla Text Detection with Fine-Tuned Transformer-Based Models (https://aclanthology.org/2023.banglalp-1.28/)
- Anthology ID: 2023.banglalp-1.28 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. Transformer 기반 모델을 사용하여 폭력 위협을 식별하는 연구를 수행하였다.
    2. 실험 결과, BanglaBERT은 기준선에 근사한 F1 점수를 얻었다.
    3. 연구 결과는 온라인 플랫폼의 안전 조치를 향상시키기 위한 귀중한 통찰력을 제공하며, 대용량 모델의 성능 저하에 대해 추가적인 조사가 필요하다는 점을 강조한다.

###### LowResourceNLU at BLP-2023 Task 1 & 2: Enhancing Sentiment Classification and Violence Incitement Detection in Bangla Through Aggregated Language Models (https://aclanthology.org/2023.banglalp-1.29/)
- Anthology ID: 2023.banglalp-1.29 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. Youjin et al. (2023)은 MCQ 평가를 위한 새로운 지식 종속 가능성(KDA) 평가 메트릭을 제안하였다. 이는 MCQ가 대상 사실의 학생 학습 지식과 상관관계를 평가한다.
    2. Lee et al. (2023)은 deep learning 모델의 강건성을 향상시키기 위해 contrastive learning과 counterfactual augmentation을 활용한다. 그들의 방법은 초점을 두 테스크에서 좋은 성능을 보여준다: 1) counterfactual 강건성, 2) cross-domain 일반화, 3) 희소 데이터로부터의 일반화.
    3. Bangla 언어에서 낮은 리소스 문제로 인해, Rahman et al. (2023)은 violence incitement detection과 sentiment analysis를 위한 혁신적인 접근 방식을 제안한다. 이들의 방법은 fine-tuning, MLM training 및 다국적 BERT를 결합하여 Bangla 텍스트의 정확도를 크게 향상시킨다.

###### Team Error Point at BLP-2023 Task 1: A Comprehensive Approach for Violence Inciting Text Detection using Deep Learning and Traditional Machine Learning Algorithm (https://aclanthology.org/2023.banglalp-1.30/)
- Anthology ID: 2023.banglalp-1.30 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 현재의 디지털 환경에서, 소셜 미디어 플랫폼은 전례 없는 연결성을 도모하면서도 광범위한 폭력 선동 콘텐츠로 인해 어두운 면을 가지고 있다. 이 연구는 벵골어 소셜 미디어에서 폭력 선동 텍스트 분류에 대해 머신러닝과 딥러닝 모델을 다양하게 사용하여 콘텐츠 관리와 온라인 안전을 향상시키는 전략에 대한 통찰력을 제공한다.
    2. 기술과 사회적 책임의 교차점에 위치한 이 연구는 플랫폼과 커뮤니티가 온라인 폭력과 싸우는 데 도움을 주기 위한 것이다.
    3. 이 연구는 모델 선택과 방법론에 대한 통찰력을 제공하여 디지털 시대의 어두운 면이 가져오는 도전에 대한 지속적인 대화에 큰 기여를 한다.

###### NLP_CUET at BLP-2023 Task 1: Fine-grained Categorization of Violence Inciting Text using Transformer-based Approach (https://aclanthology.org/2023.banglalp-1.31/)
- Anthology ID: 2023.banglalp-1.31 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 최근 인터넷 사용자의 증가로 인해 소셜 미디어 게시물, 온라인 채팅, 웹 포털 등을 통해 온라인 텍스트 컨텐츠 양이 크게 증가하였으나, 사이버 폭력을 부추기는 텍스트를 감지하는 시스템을 개발하는 것은 어렵다.
    2. 이 논문에서는 저자들은 Bangla 언어로 된 폭력적인 텍스트를 분류하기 위해 deep learning, machine learning, transformers 및 GAN 기반 모델을 사용하여 해결책을 제시한다.
    3. GAN+Bangla-ELECTRA 모델은 BLP-2023 Task 1에서 3위를 차지하며, 가장 높은 macro f1-score (74.59)을 달성하였다.

###### Team_Syrax at BLP-2023 Task 1: Data Augmentation and Ensemble Based Approach for Violence Inciting Text Detection in Bangla (https://aclanthology.org/2023.banglalp-1.32/)
- Anthology ID: 2023.banglalp-1.32 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 이 논문은 BLP Workshop 1에서 진행된 EMNLP 2023의 Task1 (VITD)에 대한 참가 결과를 설명하며, 폭력과 관련된 위협을 감지하고 분류하는 작업에 초점을 맞추었다.
    2. 우리의 접근 방식은 사전 훈련된 transformer 모델의 fine-tuning과 self-training, 데이터 증강, 앙상블 학습 등의 기술을 활용하는 것이다.
    3. 우리의 결과는 앙상블 방법과 데이터 증강 기법이 방글라 텍스트 분류에서 효과적임을 강조하며, 참가자 중 19위에 랭크되었으나 경쟁 후 실험을 통해 성능을 높였음을 보여준다.

###### BLP-2023 Task 1: Violence Inciting Text Detection (VITD) (https://aclanthology.org/2023.banglalp-1.33/)
- Anthology ID: 2023.banglalp-1.33 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 이 논문은 VITD (Violence Inciting Text Detection) 공유 작업의 결과에 대한 포괄적인 기술 설명을 제공한다. 
    2. 이 작업은 다양한 텍스트에서 폭력 선동 수준을 분류하기 위해 시작되었다.
    3. 이 논문에서는 VITD의 기준 성능, 제출된 모델의 오류 분석 및 참가 팀이 적용한 계산 기법에 대해 종합적인 요약을 제공한다.

###### BanglaNLP at BLP-2023 Task 2: Benchmarking different Transformer Models for Sentiment Analysis of Bangla Social Media Posts (https://aclanthology.org/2023.banglalp-1.34/)
- Anthology ID: 2023.banglalp-1.34 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 방글라(Bangla)는 전 세계에서 7번째로 많이 사용되는 언어로, 2억 3천 4백만 명의 주요 사용자가 있다. 그러나 그 언어는 자연어 처리 및 음성 커뮤니티에서 저자원 언어로 분류되어 있다.
    2. 저자원 언어에서 변환 모델을 사용하는 실험 결과, 전이학습은 이 언어의 모델 학습에 큰 도움이 된다는 것을 보여준다. 트위터 데이터로 이미 학습된 모델을 업데이트한 결과, 다른 모델보다 성능이 가장 좋았다.
    3. 성능 분석을 통해 정답 레이블을 확인해야 할 일부 경우가 발견되었다. 오차 분석을 통해 테스트 세트에서 67.02%의 micro-F1와 21위의 성과를 달성하였다.

###### Knowdee at BLP-2023 Task 2: Improving Bangla Sentiment Analysis Using Ensembled Models with Pseudo-Labeling (https://aclanthology.org/2023.banglalp-1.35/)
- Anthology ID: 2023.banglalp-1.35 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 이 논문은 Bangla Language Processing (BLP) 워크숍에서 Sentiment Analysis Shared Task에 대한 submission 내용을 개요로 소개한다. 
    2. 본 논문에서는 BanglaBERT를 기반으로한 방법을 제안하여, 데이터 확장을 위해 pseudo-label을 생성하고, 이를 사용하여 최종 모델을 훈련시켰다.
    3. 평가 과정에서, 30개 팀 중 우리 시스템은 두 번째로 높은 성능을 내었다. (F1 score: 0.7267)

###### M1437 at BLP-2023 Task 2: Harnessing Bangla Text for Sentiment Analysis: A Transformer-based Approach (https://aclanthology.org/2023.banglalp-1.36/)
- Anthology ID: 2023.banglalp-1.36 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 소셜 미디어에서 대중의 감정을 분석하는 것은 어떠한 주제에 대한 대중의 감정을 이해하는 데 도움이 된다. 
    2. BLP 워크샵에서 George Mason University의 M1437 팀은 Bangla 언어 처리 (BLP) 워크샵의 감성 분석 공유 과제에 참여하였다. 
    3. 문서는 BanglaBERTlarge라는 Bangla 텍스트로 사전 학습한 언어 모델이 다른 BERT 기반 모델보다 우수한 성능을 보였다고 보고한다.

###### nlpBDpatriots at BLP-2023 Task 2: A Transfer Learning Approach towards Bangla Sentiment Analysis (https://aclanthology.org/2023.banglalp-1.37/)
- Anthology ID: 2023.banglalp-1.37 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 이 논문은 Bangla Sentiment Analysis를 위한 nlpBDpatriots의 정교한 접근 방식에 대해 논의한다. 이는 EMNLP 주최로 개최된 Bangla Language Processing (BLP) 워크숍에서 공유된 과제이다.
    2. 이 과제의 주요 목표는 소셜 미디어 콘텐츠의 감성 극성을 식별하는 것이다. 30개의 NLP 열정가 그룹들이 이 공유 과제에 참여하였고, 우리가 가장 성과가 좋은 방법은 데이터 증강과 전이 학습을 결합한 것이다.
    3. 이 방법으로 우리는 이 경연에서 12위를 차지하여 매우 높은 0.71의 마이크로 F1 점수를 얻었다.

###### Ushoshi2023 at BLP-2023 Task 2: A Comparison of Traditional to Advanced Linguistic Models to Analyze Sentiment in Bangla Texts (https://aclanthology.org/2023.banglalp-1.38/)
- Anthology ID: 2023.banglalp-1.38 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. BLP Workshop-2023 Task-2의 Sentiment Analysis 과제에 대한 분석 접근 방식을 설명하는 논문이다. 우리는 DistilBERT를 사용하여 과제를 제출했으며, 추가적인 하이퍼파라미터 튜닝과 전처리를 통해 vanilla LSTM으로 결과를 개선하였다. 
    2. 데이터 불균형 문제를 해결하기 위해 oversampling 방법을 사용한 데이터 증강 및 언어 의미의 표현을 효과적으로 캡처하기 위한 attention masking과 masked language modeling을 적용한 기여도 있다. 
    3. 해당 시스템은 competition에서 초반에 대략 0.26의 micro-F1 점수를 받아 30위에 들었으나, LSTM과 XLM-RoBERTa-base 모델을 사용하여 결과를 각각 0.68과 0.65로 개선하였다.

###### EmptyMind at BLP-2023 Task 2: Sentiment Analysis of Bangla Social Media Posts using Transformer-Based Models (https://aclanthology.org/2023.banglalp-1.39/)
- Anthology ID: 2023.banglalp-1.39 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 소셜 미디어 플랫폼의 인기로 인해 매일 많은 양의 디지털 텍스트 데이터가 생성되고 있으며, 이에 대한 감정 분석은 실제로 많은 응용 분야에서 중요한 주제이다. 
    2. 그러나 영어와 같이 언어 자원이 풍부한 언어에 대한 연구가 많이 이루어져 왔지만, Bangla와 같은 저자원 언어에 대한 연구는 제한적이다. 
    3. 이 논문에서는 Bangla 감정 분석을 위해 다양한 transformer-based 모델을 finetune하고, BLP 워크샵과 EMNLP-2023의 공유 작업에서 제공된 데이터셋을 사용하여 모델을 훈련 및 평가하였다. 또한, Bangla 감정 분석을 위해 다양한 기계 학습 모델, 딥 러닝 모델, transformer-based 모델을 비교적으로 연구하여 BanglaBERT (Large) 모델이 최상의 결과를 달성하였음을 확인하였다.

###### RSM-NLP at BLP-2023 Task 2: Bangla Sentiment Analysis using Weighted and Majority Voted Fine-Tuned Transformers (https://aclanthology.org/2023.banglalp-1.40/)
- Anthology ID: 2023.banglalp-1.40 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 이 논문은 방글라 소셜 미디어 게시글의 감성 분석을 위한 공유 작업 2에서의 제출물에 대한 접근 방식을 설명한다. 
    2. 스마트폰과 소셜 미디어의 급격한 성장으로 인해 자동 감성 분석의 응용이 증가하고 있으나, 대부분의 연구는 영어에 기반한다.
    3. 본 연구에서는 다양한 다국어 및 사전 훈련된 BERT 기반 모델을 실험하고 성능을 향상시키기 위해 다수 투표 및 가중 앙상블 모델을 사용하는 접근 방식을 제안한다.

###### Semantics Squad at BLP-2023 Task 2: Sentiment Analysis of Bangla Text with Fine Tuned Transformer Based Models (https://aclanthology.org/2023.banglalp-1.41/)
- Anthology ID: 2023.banglalp-1.41 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. Bangla 언어와 같은 다양한 언어적 특성을 가지는 맥락에서 Sentiment analysis (SA)는 자연어 처리에서 중요한 작업이다.
    2. 이 논문에서는 BLP-2023 Shared Task 2의 Bangla text SA에 대한 여섯 가지 transformer 기반 모델의 성능을 조사하고, fine-tuning 및 포괄적인 성능 평가를 진행했다.
    3. BanglaBERT Small을 사용하여 한국어BERT는 대회 리더보드에서 20위를 기록했으며, BanglaBERT는 71.33%의 정확도로 다른 모델들을 능가하였다.

###### Aambela at BLP-2023 Task 2: Enhancing BanglaBERT Performance for Bangla Sentiment Analysis Task with In Task Pretraining and Adversarial Weight Perturbation (https://aclanthology.org/2023.banglalp-1.42/)
- Anthology ID: 2023.banglalp-1.42 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 이 논문에서는 "Aambela"라는 방법을 소개하며, "Bangla Social Media Posts"의 감정 분석 작업에 대한 최고 성과 방법을 소개한다.
    2. 접근 방식은 세 가지 명확한 분류 헤드를 가진 Bangla 언어 모델을 fine-tuning하는 것이다.
    3. 최종 예측을 위해 다양한 모델의 예측을 결합한 모드 기반 앙상블 방법을 사용하여 대회에서 1위를 차지하였다.

###### Z-Index at BLP-2023 Task 2: A Comparative Study on Sentiment Analysis (https://aclanthology.org/2023.banglalp-1.43/)
- Anthology ID: 2023.banglalp-1.43 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 이 논문에서는 BLP-2023 shared task의 Task 2에 참여한 결과를 보고한다. 이 과제의 주요 목표는 주어진 텍스트의 감정 (긍정, 중립, 부정)을 결정하는 것이었다.
    2. 우리는 URL, 해시태그 등을 제거하고 전통적인 방법과 사전 학습된 언어 모델을 적용했다. 우리는 리더보드에 여러 시스템을 제출하였고, 토큰화된 데이터와 함께 사용한 BanglaBERT가 가장 좋은 결과를 나타내었으며 F1-micro 점수 71.64로 대회에서 5위를 차지했다.
    3. 우리의 연구는 사전 학습된 언어 모델에서 토큰화의 중요성이 감소하고 있음을 보고한다. 또한, 우리의 평가에서 BanglaBERT가 다른 모델보다 우수한 결과를 나타내었고, 중립 클래스를 예측하는 것은 모든 모델에게 여전히 도전적인 문제임을 보여준다.

###### Team Error Point at BLP-2023 Task 2: A Comparative Exploration of Hybrid Deep Learning and Machine Learning Approach for Advanced Sentiment Analysis Techniques. (https://aclanthology.org/2023.banglalp-1.44/)
- Anthology ID: 2023.banglalp-1.44 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 본 연구는 감성 분석을 위해 사용되는 다양한 모델과 기술에 대해 철저하고 포괄적인 조사를 제시한다. 이 연구의 차별점은 감성 분석의 효과를 향상시키기 위해 목적 화된 데이터 증강 기술을 의도적으로 도입한다는 것이다.
    2. 우리는 LSTM (Long Short-Term Memory) 및 LSTM-CNN (Convolutional Neural Network) Combine과 같은 고급 모델부터 Logistic Regression, Decision Tree, Random Forest, Multi-Naive Bayes, Support Vector Machine, Stochastic Gradient Descent와 같은 전통적인 기계 학습 모델, 전처리 기술을 포함하여 다양한 접근법을 체계적으로 탐색했다.
    3. 우리의 연구는 데이터 증강이 모델 정확도 향상과 방글라어 감성의 미묘한 특징 이해에 미치는 상당한 영향을 강조한다. 또한, 우리는 LSTM 모델이 방글라어 텍스트의 장거리 상관 관계를 포착하는 능력을 강조한다.

###### UFAL-ULD at BLP-2023 Task 2 Sentiment Classification in Bangla Text (https://aclanthology.org/2023.banglalp-1.45/)
- Anthology ID: 2023.banglalp-1.45 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. BLP 공유 작업 2에서 우리 UFAL-ULD 팀은 Bangla 소셜 미디어 게시물의 감성 분석을 위한 시스템을 제시한다.
    2. XLM-RoBERTa-base 아키텍처를 기반으로 한 우리의 최상의 성능 모델은 베이스라인 모델보다 우월하며, 30개 팀 중 19위에 랭크되었다.
    3. Pre-trained 시퀀스 분류 모델인 XLM-RoBERTa, BanglaBERT, Bangla BERT Base 및 Multilingual BERT를 사용하여 일련의 실험을 수행했다.

###### Embeddings at BLP-2023 Task 2: Optimizing Fine-Tuned Transformers with Cost-Sensitive Learning for Multiclass Sentiment Analysis (https://aclanthology.org/2023.banglalp-1.46/)
- Anthology ID: 2023.banglalp-1.46 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 이 연구는 Bangla 소셜 미디어 포스트에 대한 감성 분석 작업에서 발생하는 두 가지 중요한 도전 과제에 대해 다룬다. 첫 번째 도전 과제는 모델 성능 향상을 위해 클래스 불균형을 해결하기 위한 oversampling 기술을 채용할 때 발생하는 광범위한 학습 시간과 메모리 제약이다. 
    2. 우리는 클래스 불균형을 해결하기 위해 cost-sensitive 접근 방식을 통해 모델 성능을 향상시키기 위한 방법을 사용하여 이러한 도전 과제를 극복한다. 
    3. 추가 실험을 통해 BanglaBERT-Large 모델과 자기 조정 Dice 손실 함수를 결합하여 F1-micro 점수를 0.7186으로 높일 수 있었다.

###### LowResource at BLP-2023 Task 2: Leveraging BanglaBert for Low Resource Sentiment Analysis of Bangla Language (https://aclanthology.org/2023.banglalp-1.47/)
- Anthology ID: 2023.banglalp-1.47 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. 이 논문은 소셜 미디어 플랫폼에서 수집된 공개 게시물과 댓글들을 대상으로 한 감성 분석을 수행하는 BLP-2023의 Task 2에 대한 LowResource 팀의 시스템을 설명한다.
    2. Bangla corpus에서 사전 훈련된 BERT 모델인 BanglaBert를 다양한 전략을 활용하여 활용하고, fine-tuning, 무작위 토큰 제거, 여러 외부 데이터셋 사용 등을 포함한다.
    3. 우리의 최종 모델은 세 가지 다른 BanglaBert 변형의 앙상블로, 참여한 30개 팀 중 테스트 세트에서 전체 3위를 차지하여 0.718의 점수를 달성했다.

###### BLP-2023 Task 2: Sentiment Analysis (https://aclanthology.org/2023.banglalp-1.48/)
- Anthology ID: 2023.banglalp-1.48 
- Volume: Proceedings of the First Workshop on Bangla Language Processing (BLP-2023) 
- Summary: 
    1. "BLP Sentiment Shared Task"는 소셜 미디어 텍스트에서 감성(sentiment)을 감지하는 작업으로, 이 작업에는 71명의 참가자 중 29명과 30개의 팀이 각각 개발 및 평가 단계에서 시스템을 제출했다.
    2. 제출된 시스템의 접근 방식은 고전적인 기계 학습 모델, 사전 훈련된 모델의 파인튜닝, 제로샷 및 퓨샷 설정에서의 대형 언어 모델(Large Language Model, LLM)을 활용하는 방법 등이다.
    3. 본 논문에서는 데이터셋 개발 및 평가 설정을 포함하여 작업의 상세한 설명과 참가자가 제출한 시스템의 간략한 개요를 제공한다. 모든 데이터셋과 평가 스크립트는 연구 커뮤니티에 공개되어 이 도메인에서의 추가 연구를 촉진하기 위해 사용할 수 있다.

## Proceedings of the Big Picture Workshop
###### Proceedings of the Big Picture Workshop (https://aclanthology.org/2023.bigpicture-1.0/)
- Anthology ID: 2023.bigpicture-1.0 
- Volume: Proceedings of the Big Picture Workshop 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Where are We in Event-centric Emotion Analysis? Bridging Emotion Role Labeling and Appraisal-based Approaches (https://aclanthology.org/2023.bigpicture-1.1/)
- Anthology ID: 2023.bigpicture-1.1 
- Volume: Proceedings of the Big Picture Workshop 
- Summary: 
    1. 텍스트의 감정 분석은 컴퓨터가 감정을 이해할 수 있도록 하는 다양한 자연어 처리 작업을 포함한다. 
    2. 이 논문에서는 감정 역할 지정 (emotion role labeling)과 이벤트 중심 감정 분류 (event-focused emotion classification)이 분리되어 연구되어왔다고 주장하며, 두 관점을 상황에 맞게 제안하고 연구 질문을 논의한다. 
    3. 감정은 이벤트에 의해 발생하고 가리키는데, 이 논문은 자연어 처리에 감정 역할 지정 시 이벤트 개념을 도입하는 것을 제안한다.

###### Working Towards Digital Documentation of Uralic Languages With Open-Source Tools and Modern NLP Methods (https://aclanthology.org/2023.bigpicture-1.2/)
- Anthology ID: 2023.bigpicture-1.2 
- Volume: Proceedings of the Big Picture Workshop 
- Summary: 
    1. 우리는 특히 우랄어에 초점을 맞춘 멸종 언어 문서화를 위한 인프라 구축에 대한 연구를 제시한다. 
    2. 우리의 인프라는 항목이 XML 형식으로 구조화된 사전을 작성할 수 있는 도구들로 이루어져 있다. 
    3. 우리는 룰과 어휘를 통해 훈련 데이터를 생성하여 최신 최첨단 신경망 모델을 사용하여 이러한 사전과 도구를 개선하는 작업을 적극적으로 수행한다.

###### Computational Narrative Understanding: A Big Picture Analysis (https://aclanthology.org/2023.bigpicture-1.3/)
- Anthology ID: 2023.bigpicture-1.3 
- Volume: Proceedings of the Big Picture Workshop 
- Summary: 
    1. 본 논문에서는 computational narrative understanding 분야의 주요 연구 목표를 개요로 제공한다. 
    2. 이 분야는 사람들의 행동을 설명하는 핵심 메커니즘으로서 이야기를 중점으로 하는 몇 가지 연구 도메인이 있다.
    3. 본 논문은 narrative의 요소를 개요로 제공하면서 narrative의 다중성, 시간적 패턴, 사회 문화적 schema 등 세 가지 주요 연구 동향을 소개한다.

###### The Case for Scalable, Data-Driven Theory: A Paradigm for Scientific Progress in NLP (https://aclanthology.org/2023.bigpicture-1.4/)
- Anthology ID: 2023.bigpicture-1.4 
- Volume: Proceedings of the Big Picture Workshop 
- Summary: 
    1. 이 논문은 언어 구조에 대한 확장 가능하고 데이터 기반의 이론 개발을 중심으로 한 NLP의 과학적 진보 패러다임을 제안한다.
    2. 말뭉치에서 주어진 관심 행동 현상의 철저한 어노테이션을 가능하게 하는 방식으로 데이터를 수집한 뒤, 머신 러닝을 사용하여 이러한 현상에 대한 설명적인 이론을 구축함으로써 인공 지능 시스템에 활용할 수 있는 기반 블록을 구성한다.
    3. 이 논문은 데이터 수집과 이론적 모델링에 대한 원칙을 제시하여 AI에서의 언어 동작에 대한 복잡성을 다루고, 앞으로의 과학적 진보에 도움이 될 수 있다.

###### Thesis Distillation: Investigating The Impact of Bias in NLP Models on Hate Speech Detection (https://aclanthology.org/2023.bigpicture-1.5/)
- Anthology ID: 2023.bigpicture-1.5 
- Volume: Proceedings of the Big Picture Workshop 
- Summary: 
    1. 나의 박사학위 논문에서는 NLP 모델의 편향이 혐오 발언 감지 작업에 미치는 영향을 설명 가능성, 공격적인 초상화 편향 및 공정성 측면에서 조사하였다. 
    2. 그리고 이 논문에서는 내 논문의 주요 결론과 이를 NLP 커뮤니티에서 어떻게 활용할 수 있는지에 대해 논의한다. 
    3. 마지막으로, NLP 모델의 편향을 측정하고 완화하는 현재의 한계를 효과적으로 극복하기 위해 사회과학을 공부에 접목시키는 것이 필요하다는 결론을 도출하였다.

###### Large Language Models as SocioTechnical Systems (https://aclanthology.org/2023.bigpicture-1.6/)
- Anthology ID: 2023.bigpicture-1.6 
- Volume: Proceedings of the Big Picture Workshop 
- Summary: 
    1. 대형 언어 모델(LLMs)의 기대는 이들이 작동하는 더 큰 사회 기술적 참조 프레임을 무시하였다. 이 논문에서는 LLM의 추상화와 공정성과 관련된 문제를 논의하고, Selbst et al.(2019)의 다섯 가지 문제 상황 - The Framing Trap, The Portability Trap, The Formalism Trap, The Ripple Effect Trap, The Solutionism Trap - 을 LLM의 맥락에서 논의한다.
    2. 이전 연구와 예시에서 얻은 교훈을 바탕으로 LLM이 빠지는 함정을 각각 논의하고, 사회 기술적 렌즈를 통해 LLM 실패 지점을 파악하는 방법을 제안한다.
    3. 이러한 논의는 사회 기술적 관점에서 LLM을 보는 넓은 시각을 제공하며, 우리의 권고사항은 다양한 기술 및 사회 이해관계자들 사이에서 책임을 명확히 하고 미래의 LLM 연구를 영감을 줄 수 있다고 기대한다.

###### Towards Low-resource Language Generation with Limited Supervision (https://aclanthology.org/2023.bigpicture-1.7/)
- Anthology ID: 2023.bigpicture-1.7 
- Volume: Proceedings of the Big Picture Workshop 
- Summary: 
    1. 다양한 자연어 생성(NLG) 작업에 대한 언어 기술을 저리자원 언어(LRL)에 적용하기 위한 연구 내러티브를 제시한다.
    2. 전 세계적으로 약 7,000개의 언어가 사용되는데 그 중 많은 언어들은 모델 학습을 위한 리소스가 부족하다.
    3. 이 연구에서는 전이 학습과 제한적 감독 기법을 효과적으로 활용하여 LRL에 대한 언어 기술을 가능하게 하는 세 가지 연구를 소개한다.

###### Transformers as Graph-to-Graph Models (https://aclanthology.org/2023.bigpicture-1.8/)
- Anthology ID: 2023.bigpicture-1.8 
- Volume: Proceedings of the Big Picture Workshop 
- Summary: 
    1. 이 논문은 Transformers가 본질적으로 그래프 간 모델이며, sequence가 그 중 특수한 경우라고 주장한다. Transformer의 attention weights는 그래프의 엣지와 기능적으로 동등하다.
    2. 그래프 간 Transformer 아키텍처는 이 능력을 명시적으로 표현하기 위해 그래프의 엣지를 attention 가중치 계산에 입력하고 attention과 유사한 함수로 그래프 엣지를 예측하며, 사전 학습된 Transformer가 학습한 잠재 그래프에 명시적 그래프를 통합한다.
    3. 반복적인 그래프 개선을 추가함으로써 입력, 출력 및 잠재 그래프의 공동 임베딩을 제공하며, 임의의 파이프 라인 또는 디코딩 전략 없이 완전한 그래프를 최적화하는 비자기 회귀 그래프 예측이 가능하다. 실험 결과는 이 아키텍처가 다양한 언어 구조를 모델링하는 데 최고 수준의 정확도를 달성한다는 것을 보여준다.

###### It’s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk (https://aclanthology.org/2023.bigpicture-1.9/)
- Anthology ID: 2023.bigpicture-1.9 
- Volume: Proceedings of the Big Picture Workshop 
- Summary: 
    1. MBR (Minimum Bayes Risk) 디코딩은 기계 학습 시스템의 출력을 확률적으로 가장 높은 것이 아니라 여러 후보 중에서 리스크(예상 오류)가 가장 낮은 출력으로 선택하는 방법이다.
    2. 우리는 최근의 몇 가지 방법들이 MBR의 특수한 경우로 쓰일 수 있음을 보여준다. 이를 통해 이러한 방법들의 성능에 대한 이론적인 근거를 제공하고 이전에는 경험적인 결과에 근거한 것으로만 보이던 몇 가지 결과를 설명한다. 
    3. 우리는 다양한 MBR 변형의 효과에 대한 이론적 및 경험적 결과를 제시하고, NLP 모델에 MBR을 적용하는데 대한 구체적인 권고사항과 이 분야에서의 미래 방향을 제안한다.

###### Analyzing Pre-trained and Fine-tuned Language Models (https://aclanthology.org/2023.bigpicture-1.10/)
- Anthology ID: 2023.bigpicture-1.10 
- Volume: Proceedings of the Big Picture Workshop 
- Summary: 
    1. 2018년 transformer 기반의 언어 모델이 소개된 이후, 현재의 NLP 모델들은 학문적인 벤치마크와 실제 응용 프로그램에서 놀라운 성능을 보여주고 있다. 그러나 이러한 진전은 대량의 텍스트로 사전 학습된 모델을 좁은 분야로 fine-tuning하는 단순하고 일반적인 파이프라인에 기반한 것이다.
    2. 이 논문에서는 pre-trained와 fine-tuned 된 언어 모델이 왜 잘 작동하는지, 어떤 언어 지식이 fine-tuning에 의해 어떻게 영향을 받는지에 대한 이해를 향상하기 위해 다양한 분석을 제시한다.
    3. 이 논문은 pre-trained와 fine-tuned 된 언어 모델의 능력과 이전에 설명되지 않았던 현상에 대한 새로운 통찰력을 제공하며, 모델의 일반화에 대한 적응 기술의 선택이 어떻게 영향을 미치는지에 대한 철저한 분석을 제공한다.

## Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP
###### Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP (https://aclanthology.org/2023.blackboxnlp-1.0/)
- Anthology ID: 2023.blackboxnlp-1.0 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Knowledge-Grounded Natural Language Recommendation Explanation (https://aclanthology.org/2023.blackboxnlp-1.1/)
- Anthology ID: 2023.blackboxnlp-1.1 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. 추천 시스템의 의사 결정에 대한 설명은 사용자가 시스템에 대한 신뢰를 높이는 데 도움이 될 수 있으며, 최근 연구는 사람이 읽기 쉬운 형식으로 자연어 설명을 생성하는 데 집중하고 있다. 
    2. 이 논문에서는 사용자가 구매한 기록을 기반으로, 사용자의 선호도를 고려하면서 아이템에 대한 객관적인 설명을 생성하는 방법을 제안한다. 
    3. 실험 결과에서 제안하는 방법이 이전에 제안된 최신 모델들보다 자연어 설명 가능 추천 메트릭에서 뛰어난 성능을 보인다는 것을 보여준다.

###### Emergent Linear Representations in World Models of Self-Supervised Sequence Models (https://aclanthology.org/2023.blackboxnlp-1.2/)
- Anthology ID: 2023.blackboxnlp-1.2 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. 시퀀스 모델은 어떻게 의사 결정 과정을 표현하는가? 선행 연구는 오셀로를 두는 신경망이 보드 상태의 비선형 모델을 학습했다고 제안하였다. 
    2. 이 연구에서는 보드 상태의 관련된 선형 표현을 제시하고, "내 색깔" 대비 "상대의 색깔"에 대한 탐사(probing)가 모델의 내부 상태를 해석하는 간단하면서도 강력한 방법일 수 있다는 것을 보여준다. 
    3. 이러한 내부 표현의 정확한 이해는 단순한 벡터 산술로 모델의 동작을 제어하는 것을 가능하게 한다. 이러한 선형 표현은 해석 가능성에 대한 중요한 진전을 이룰 수 있으며, 이를 검증하기 위해 세계 모델이 어떻게 계산되는지 더 탐구한다.

###### Explaining Data Patterns in Natural Language with Language Models (https://aclanthology.org/2023.blackboxnlp-1.3/)
- Anthology ID: 2023.blackboxnlp-1.3 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. 대규모 언어 모델 (LLM)은 복잡한 작업을 수행하기 위해 자연어를 잘 활용할 수 있는 능력을 보여주고 있다. 이 능력을 활용하여 데이터에서 패턴을 찾고 설명할 수 있는지 알아보고자 한다. 
    2. 기존의 데이터 예시와 사전 훈련된 LLM을 사용하여 해석 가능한 자연어 문자열을 생성하는 Interpretable Autoprompting (iPrompt)을 적용한다. 
    3. 여러 데이터셋에 대한 실험에서 iPrompt는 인간이 이해할 수 있는 데이터셋 설명을 정확하게 찾아내어 유의미한 인사이트를 제공하며, 상대적으로 작은 모델 (예: 60억 개의 매개변수)을 사용하여 비교적 효율적으로 작동한다는 것을 보여준다. 또한, 과학적인 데이터셋에 대한 실험은 iPrompt가 과학적 발견에 도움이 될 수 있는 잠재력을 보여준다.

###### Probing Quantifier Comprehension in Large Language Models: Another Example of Inverse Scaling (https://aclanthology.org/2023.blackboxnlp-1.4/)
- Anthology ID: 2023.blackboxnlp-1.4 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. 크기가 커짐에 따라 대형 언어 모델(Large Language Models, LLMs)은 언어 이해 작업에서 점점 더 뛰어난 성능을 보이지만, 부정이나 양자 이해와 같은 간단한 언어 테스트에서는 여전히 실패한다. 
    2. 이 논문에서는 LLMs의 양자 이해력을 측정하기 위한 대안적인 방법을 제안하고, LLMs가 크기가 커질수록 "조금(type)"과 "대부분(type)" 양자의 의미 차이를 더 잘 이해한다는 것을 보여준다. 
    3. 그러나 크기가 커질수록 LLMs의 대부분 유형 양자의 이해력은 인간의 심리 언어학 실험 및 이전 연구와 달리 나빠진다는 역방향 scaling 관찰도 한다. 이는 LLMs의 양자 이해능력을 평가하는 데 있어 가능한 원인과 관련성을 검토한다.

###### Disentangling the Linguistic Competence of Privacy-Preserving BERT (https://aclanthology.org/2023.blackboxnlp-1.5/)
- Anthology ID: 2023.blackboxnlp-1.5 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. 텍스트-텍스트 개인 정보 보호 과제에는 차별화된 프라이버시 (DP)가 필요하다. 그러나 텍스트-텍스트 개인 정보 보호는 변형된 텍스트로 훈련된 언어 모델의 성능을 저하시킴으로써 알려져 있다.
    2. 우리는 변형된 전체 텍스트에 대해서 BERT로부터 추출된 내부 표현에 대한 해석 기법을 적용하여, 텍스트-텍스트 개인 정보 보호가 어떻게 언어적 레벨에서 왜곡을 초래하는지 파악하고자 한다.
    3. 실험 결과로부터 나타나는 대표적 유사성 분석을 통해 내부 표현의 전반적 유사성이 상당히 감소하는 것을 확인할 수 있다. 이러한 불일치를 풀기 위해 탐사 작업을 사용하면, 우리는 텍스트-텍스트 개인 정보 보호가 여러 형식에 걸쳐 언어 역량에 영향을 미침을 발견하며, 단어의 지역적 특성을 인코딩하는 데 문제가 있으며 단어 구간 사이의 문맥적 관계를 인코딩하지 못한다는 것을 알 수 있다.

###### “Honey, Tell Me What’s Wrong”, Global Explanation of Textual Discriminative Models through Cooperative Generation (https://aclanthology.org/2023.blackboxnlp-1.6/)
- Anthology ID: 2023.blackboxnlp-1.6 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. 복잡한 머신러닝에 대한 보편화된 설명 알고리즘의 중요성이 높아져서, 이 논문에서는 모델에 상관없는 설명 방법을 제안한다. 
    2. Therapy라는 방법은 텍스트에 적용되는 첫 번째 전역적이고 모델에 상관없는 설명 방법이며, 초기 데이터를 필요로 하지 않는다. 
    3. 실험 결과, 초기 데이터 없이도 설명을 생성할 수 있으며, 기존 방법들보다도 더 좋은 결과를 제공한다.

###### Self-Consistency of Large Language Models under Ambiguity (https://aclanthology.org/2023.blackboxnlp-1.7/)
- Anthology ID: 2023.blackboxnlp-1.7 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. 일관성이 기대되는 태스크 (예: 질문 답변, 설명 등)에 대해서도 다양한 맥락에서 일관된 답변을 주지 않는 대규모 언어 모델 (LLM)은 문제가 있습니다. 이 논문은 두 개 이상의 답이 올바른 경우의 미사양 상황에서 자기 일관성을 평가하기 위한 평가 벤치마크를 제시합니다.
    2. OpenAI 모델 스위트에서 애매한 정수 수열 완성 작업에 대한 일련의 행동 실험을 실시하였으며, 모델의 일관성 평균은 67%에서 82%로 나타났으며, 모델의 일관성이 무작위인 경우보다 훨씬 높았으며, 모델 능력이 향상됨에 따라 증가합니다.
    3. 또한, 모델은 화자 변경 및 시퀀스 길이 변경을 포함한 일련의 견고성 검사를 통해 자기 일관성을 유지하는 경향을 보이며, 이 결과는 자기 일관성이 특별히 그런 것이 아니라 신회 기능으로 나타난다는 것을 나타냅니다.

###### Character-Level Chinese Backpack Language Models (https://aclanthology.org/2023.blackboxnlp-1.8/)
- Anthology ID: 2023.blackboxnlp-1.8 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. "Backpack"은 영어 언어 모델에 대한 해석 가능성을 높이기 위해 예측을 토큰 센스 구성 요소의 가중합으로 분해하는 Transformer 대안이다. 그러나 Backpack은 토큰으로 정의된 의미에 의존하기 때문에 영어 이외의 언어에서 얼마나 유용할 수 있는지 의문이 제기된다.
    2. 이 논문에서는 중국어에서 Character로 토큰화된 Backpack 언어 모델을 훈련하고 평가하여 이의 의미를 해석하고 제어한다. 결과적으로 중국어 Backpack 언어 모델은 Transformer와 비교하여 우수한 성능을 발휘하며, 문자 수준에서 풍부한 의미를 학습하는 것을 확인하였다.
    3. 이 연구는 Backpack의 인과관계를 특정 character sense로 정확히 지역화하고 편향성을 감소시키는 것과 같은 해석 가능성을 통해 모델을 제어함으로써 효과적으로 문제를 해결할 수 있다는 것을 보여준다.

###### Unveiling Multilinguality in Transformer Models: Exploring Language Specificity in Feed-Forward Networks (https://aclanthology.org/2023.blackboxnlp-1.9/)
- Anthology ID: 2023.blackboxnlp-1.9 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. 최근 연구에 따르면 Transformers의 feed-forward 모듈은 입력에서 특정 패턴을 캡처하는 키-밸류 메모리의 모음으로 볼 수 있다고 한다. 이로 인해 예측과정이 점진적으로 이뤄지며 출력층에 가까워질수록 최종 토큰 선택에 수렴한다. 이러한 흥미로운 관점은 다국어 모델이 이 메커니즘을 어떻게 활용할 수 있는지에 대한 질문을 제기한다. 
    2. 특히, 두 개 이상의 언어로 훈련된 오토리그레시브 모델의 경우, 모든 뉴런 (레이어 전체)이 모든 언어에 동일하게 반응합니까? 답변은 아니다! 저자들의 가설은 pre-training 단계에서 특정 모델 매개변수가 강한 언어별 특징을 학습하고 다른 값은 언어에 구애받지 않는 특징을 학습한다는 것이다. 
    3. 이 가설을 검증하기 위해, 초기 pre-training에서 사용한 두 언어의 병렬 코퍼스를 활용한 실험을 수행하였다. 결과는 네트워크의 입력 또는 출력에 가까운 레이어는 중간 레이어보다 언어별 특징을 더 많이 나타내는 것을 보여주었다.

###### Why Bother with Geometry? On the Relevance of Linear Decompositions of Transformer Embeddings (https://aclanthology.org/2023.blackboxnlp-1.10/)
- Anthology ID: 2023.blackboxnlp-1.10 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. Transformer 임베딩은 일련의 인수들의 합으로 선형 분해될 수 있으며, 이러한 분해와 네트워크 입력 또는 구성 요소와의 관계가 잘 정의되어 있는 것으로 알려져 있지만, 이러한 수학적 재정의가 실증적으로 의미 있는지에 대한 연구는 아직 불충분한 상태이다.
    2. 본 연구에서는 기계 번역에 사용되는 Transformer 디코더의 표현을 두 가지 임베딩 분해 방법을 사용하여 연구하였다.
    3. 결과적으로, 분해로 얻은 지표들은 모델 성능과 효과적으로 상관관계를 가지지만, 여러 실행 간의 변동성은 이러한 문제에 대한 보다 미묘한 접근이 필요하다는 것을 시사한다.

###### Investigating Semantic Subspaces of Transformer Sentence Embeddings through Linear Structural Probing (https://aclanthology.org/2023.blackboxnlp-1.11/)
- Anthology ID: 2023.blackboxnlp-1.11 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. Transformer 기반 언어 모델의 각 레이어가 어떤 언어 정보를 인코딩하는지는 NLP 커뮤니티에 매우 흥미로운 문제이다. 그러나 기존 연구는 주로 단어 수준의 표현과 마스크 토큰 학습 목적을 가진 encoder-only 언어 모델에 초점을 맞추었다. 
    2. 이 연구에서는 semantic structural probing라는 방법을 소개하여 문장 수준 표현을 연구하는데 사용하였다. 우리의 방법을 encoder-only, decoder-only, encoder-decoder 모델과 다양한 크기의 언어 모델에 적용하였고, 두 가지 작업인 의미적 텍스트 유사성과 자연어 추론의 문맥에서 모델 패밀리는 성능과 레이어의 동적을 많이 다르게 나타냈다. 
    3. 하지만 결과는 모델의 크기에 대한 영향이 크게 없음을 발견하였다.

###### Causal Abstraction for Chain-of-Thought Reasoning in Arithmetic Word Problems (https://aclanthology.org/2023.blackboxnlp-1.12/)
- Anthology ID: 2023.blackboxnlp-1.12 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. 최근 연구는 큰 언어 모델이 최종 답변 이전에 중간 추론 단계, 즉 chain of thought (CoT)를 생성하게 되면 다단계 추론 과제에서 더 높은 정확성을 보인다고 제안하고 있다. 하지만 CoT가 어떻게 언어 모델의 정확성을 향상시키는지, 특히 언어 모델이 CoT를 사용하여 최종 답변을 도출하는지에 대해서는 여전히 불분명하다.
    2. 본 논문은 산술 문제를 다루며 이 질문에 대한 답을 찾기 위해 (i) 언어 모델의 CoT의 정확성을 평가하고, (ii) 인과 추상화를 사용하여 CoT에 따라 생성된 중간 토큰이 언어 모델의 최종 답변에 인과적인 영향을 미치는지를 평가한다.
    3. 연구 결과, CoT-prompted된 언어 모델들은 산술 문제에서 정확한 답변과 CoT 사이에 매우 높은 상관관계를 가지며, 정확한 CoT를 생성할 때는 CoT에 기술된 추론과 거의 유사한 인과 모델을 실현한다. 이러한 실현 정도가 산술 문제 전체의 정확성과 더불어 관련이 있는 것으로 나타났다. 이러한 결과는 일부 CoT-prompted된 언어 모델들이 최종 답변을 도출하기 위해 CoT를 사용하여 다단계 산술 추론에서 더 좋은 결과를 얻을 수 있다는 것을 시사한다. 하지만 어떤 언어 모델들은 다른 내부 과정도 관여할 수 있다.

###### Enhancing Interpretability Using Human Similarity Judgements to Prune Word Embeddings (https://aclanthology.org/2023.blackboxnlp-1.13/)
- Anthology ID: 2023.blackboxnlp-1.13 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. NLP의 해석 가능성 메서드는 특정 시스템 아키텍처의 의미론에 대한 통찰력을 제공하기 위해 개발되었다. 이 논문에서는 단어 임베딩에 초점을 맞춘 감독 학습 방법을 제안하고, 주어진 도메인(예: 스포츠, 직업)에서 사람의 유사성 판단 예측에 크게 기여하는 모델 특징의 하위 집합을 식별한다.
    2. 이 방법은 8개의 독립적인 의미적 도메인에서 원래의 임베딩의 20-40%만 유지하며, 도메인마다 다른 특징 집합을 유지하는 것을 보여준다.
    3. 이 논문에서는 유지된 특징들의 의미론을 해석하기 위해 두 가지 접근 방식을 제시한다. 첫 번째는 유지된 임베딩의 첫 번째 주성분에 도메인 단어들의 점수를 얻고, 이 점수 프로필을 따라 가장 관련 있는 용어를 추출한다. 이 분석은 인간들이 예를 들어 스포츠를 성별 포함성과 국제성에 따라 구분한다는 것을 드러낸다. 두 번째 접근 방식은 유지된 특징들을 535개의 단어 데이터셋에 대해 65개 의미적으로 주석이 달린 차원을 예측하는 조사 작업의 변수로 사용한다. 직업에 유지된 특징이 인지, 감정 및 사회적 차원을 가장 잘 예측하는 반면, 과일 또는 야채에 유지된 특징은 맛 차원을 가장 잘 예측한다. 인공지능 시스템과 인간의 지식 간의 조화에 대한 함의에 대해 논의한다.

###### When Your Language Model Cannot Even Do Determiners Right: Probing for Anti-Presuppositions and the Maximize Presupposition! Principle (https://aclanthology.org/2023.blackboxnlp-1.14/)
- Anthology ID: 2023.blackboxnlp-1.14 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. 대형 언어 모델(Large Language Model, LLM)들의 언어 능력을 조사하는 연구에서, 선결 가정(presupposition) 현상과 그 원리인 Maximize Presupposition! (MP!)의 연구가 아직 이루어지지 않은 현상을 연구하였다.
    2. 실험을 통해 언어 모델이 다양한 반선결 가정(anti-presupposition)을 어떻게 다루고, MP! 원리를 적용하는지 조사하였다.
    3. 연구 결과, LLM은 MP! 원리를 따르는 것보다 문맥 기반 n-gram을 복제하는 경향이 있으며, 자연어 추론 데이터로 세밀한 조정을 해도 MP! 원리에 충실하지 않음을 발견하였다. 특히, 상대적으로 간단한 언어적 맥락에서 LLM은 한정사를 올바르게 예측하는 데 어려움을 겪는 것으로 나타났다.

###### Introducing VULCAN: A Visualization Tool for Understanding Our Models and Data by Example (https://aclanthology.org/2023.blackboxnlp-1.15/)
- Anthology ID: 2023.blackboxnlp-1.15 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. 예시는 복잡한 개념과 연결을 이해하는 데 도움이 되는 강력한 도구이다. 본 논문에서는 문자열, 그래프, 트리, 정렬, 어텐션 등을 시각화해주는 visualization tool인 VULCAN에 대해 설명한다. VULCAN은 언어적 구조와 신경망 모델의 속성을 동시에 시각화할 수 있는 독특한 능력을 가지고 있어 신경 기호주의 모델(neuro-symbolic models)에 매우 적합하다. 
    
    2. 신경 기호주의 모델은 신경망을 언어적으로 기반된 구조와 결합하여 순전히 신경망 기반의 블랙박스 end-to-end 모델의 해석 가능성을 높이는 것을 목표로 한다. VULCAN은 이러한 해석 가능성을 실용적으로 돕기 위해 설계되었으며, 사용하기 쉽고 강력한 기능을 제공한다. 
    
    3. VULCAN은 open-source 소프트웨어로, 조사자들이 신경 기호주의 모델의 시각화를 통해 복잡한 개념과 모델의 동작을 더 잘 이해할 수 있도록 돕는다.

###### The Self-Contained Negation Test Set (https://aclanthology.org/2023.blackboxnlp-1.16/)
- Anthology ID: 2023.blackboxnlp-1.16 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. 최근에는 사전 학습 언어 모델(PLM)이 부정을 해석하는 능력을 평가하기 위한 다양한 방법이 제안되었다. 
    2. 이 논문에서는 Gubelmann and Handschuh (2022) 연구를 기반으로 하여 PLM의 예측이 입력의 극성에 따라 어떻게 변경되는지를 연구했다.
    3. 개선된 버전인 Self-Contained Neg Test를 소개하여 roberta와 bert 모델의 부정에 대한 민감도를 평가했고, roberta의 결과가 기대에 부합하는 반면 bert는 부정에 거의 민감하지 않음을 보여주었다.

###### Investigating the Effect of Discourse Connectives on Transformer Surprisal: Language Models Understand Connectives, Even So They Are Surprised (https://aclanthology.org/2023.blackboxnlp-1.17/)
- Anthology ID: 2023.blackboxnlp-1.17 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. 최근의 neural language models(NLMs)은 Transformer를 기반으로 한다. 이 연구에서는 discourse connectives가 NLMs에 미치는 영향과 Transformer Surprisal 점수에 대해 연구하였다.
    2. 큰 규모의 NLMs는 감탄점 connective가 사용될 때 인간의 행동 데이터와 유사한 패턴을 보였다. 그러나 대조적인 connective의 경우 connective와 관련된 효과가 사라지는 경향을 보였다.
    3. 연장된 데이터셋을 사용하여 GPT-Neo로 결과를 검증한 결과, 대체로 일관된 패턴을 확인할 수 있다.

###### METAPROBE: A Representation- and Task-Agnostic Probe (https://aclanthology.org/2023.blackboxnlp-1.18/)
- Anthology ID: 2023.blackboxnlp-1.18 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. "컨텍스처에 의존한 표현을 조사하는 것은 과제 특정 모델 예측을 근거로하는 언어적인 레이블의 진실과의 비교를 포함한다. 그러나 이 방법은 어떤 정보가 분류기에 의해 복구될 수 있는지를 보여주지만, 분류기가 표현을 활용하여 결정을 내리는 방식은 보여주지 않는다."
    2. "우리는 이후의 문제를 해결하기 위해 다음을 묻습니다: 과제 분류자들은 임베딩 공간에서 표현 및 과제에 독립적인 기하학적 패턴에 의존합니까?"
    3. "우리는 MetaProbe라는 접근법을 개발하여 표현의 기하학적 특성을 사용하여 과제 특정 분류자의 동작을 예측합니다. 우리의 실험은 분류자의 예측을 예측할 수 있는 표현 간의 보편적인 기하학적 패턴의 존재를 보여줍니다. 결과적으로, 우리는 컨텍스트에 의존하는 표현의 놀라운 성능에 대한 기하학적 설명을 제시할 수 있습니다."

###### How Much Consistency Is Your Accuracy Worth? (https://aclanthology.org/2023.blackboxnlp-1.19/)
- Anthology ID: 2023.blackboxnlp-1.19 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. "Contrast set consistency"는 모델이 같은 지식을 기반으로 한 번 더미처럼 비슷하지만 최소한의 차이를 가진 예시에 올바른 응답을 정확하게 준다는 것을 평가하는 robustness 측정이다.
    2. 상대 일관성(relative consistency)과 일관성을 보완하여 모델의 일관성을 평가한다. 100% 상대 일관성을 가진 모델은 정확성에 대한 일관성이 최고점에 도달한 것이다. 
    3. 우리는 일관성에 대한 이전 연구들을 검토하고, 상대 일관성이 다른 모델과 비교했을 때 모델의 일관성 평가를 변경할 수 있다는 사실을 관찰한다. 우리의 제안된 측정법과 관련된 통찰력이 모델의 일관된 행동을 촉진하는 미래의 연구에 영향을 미칠 것으로 예상된다.

###### Investigating the Encoding of Words in BERT’s Neurons Using Feature Textualization (https://aclanthology.org/2023.blackboxnlp-1.20/)
- Anthology ID: 2023.blackboxnlp-1.20 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. 사전훈련 언어 모델(PLMs)은 대부분의 최신 NLP 기술의 기반이지만, 이들은 본질적으로 블랙박스이다. 특히 개별 뉴런에서 표현되는 지식을 사람들은 명확하게 이해하지 못한다. 
    2. 우리는 시각 모델의 뉴런들에 대한 분해적 해석 기법인 특징 시각화를 영감으로 하여 Activation maximization을 NLP에 적용한 첫 대규모 시도에 대해 조심스러운 사례를 제시한다. 
    3. 우리는 BERT 모델에 feature textualization 기술을 적용하여 개별 뉴런에 인코딩된 지식을 해석하고 상징화할 수 있는지 조사한다. 우리는 개별 뉴런이 단어와 같은 명확한 기호적 단위를 표현하지 않는다는 것을 발견했다.

###### Evaluating Transformer’s Ability to Learn Mildly Context-Sensitive Languages (https://aclanthology.org/2023.blackboxnlp-1.21/)
- Anthology ID: 2023.blackboxnlp-1.21 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. 최근 연구들은 Transformer 모형이 일부 정규 및 문맥 자유 언어조차도 학습하는 데 제한되어 있다는 이론적 한계가 있다고 주장하고 있다.
    2. 이 논문에서는 Transformer의 얕게 문맥에 의존적인 언어를 학습하는 능력을 실험하고, 기존의 LSTM보다는 성능이 좋지 않음을 발견하였다.
    3. 학습된 self-attention 패턴과 표현은 종속성 관계를 모델링하고, 카운팅 동작을 보여주었으며, 이는 모형이 언어를 해결하는 데 도움이 되었을 것이다.

###### Layered Bias: Interpreting Bias in Pretrained Large Language Models (https://aclanthology.org/2023.blackboxnlp-1.22/)
- Anthology ID: 2023.blackboxnlp-1.22 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. GPT와 PALM과 같은 대형 언어 모델은 텍스트 생성, 질문 답변, 번역과 같은 다양한 NLP 태스크에서 뛰어난 성과를 보이고 있지만, 사회적 편향이 내재되어 있다.
    2. 최근 연구에서는 반복적인 공간 투영 (INLP) 및 대조적 데이터 증강 (CDA)과 같은 편향 제거 기법을 제안하고 있다. 또한, 이러한 모델의 복잡성을 이해하는 데 관심이 증가하고 있다.
    3. 본 연구에서는 OPT, LLaMA 및 LLaMA2와 그들의 편향 제거된 버전을 사용하여 최신 LLM을 성능 평가하고, Logit Lens라는 방법을 사용하여 편향과 다른 transformer 레이어와의 관계를 조사한다.

###### Not Wacky vs. Definitely Wacky: A Study of Scalar Adverbs in Pretrained Language Models (https://aclanthology.org/2023.blackboxnlp-1.23/)
- Anthology ID: 2023.blackboxnlp-1.23 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. 단어의 의미를 표현하는 벡터 공간 모델들은 비슷한 문맥에서 등장하는 단어들은 비슷한 의미를 가진다고 가정하는데, 이러한 모델들은 논리적 추론을 수행하는 NLP 응용 프로그램에 어려움이 있다. 
    2. 그러나 사전 훈련된 언어 모델들(BERT, RoBERTa, GPT-2, GPT-3)의 논리적 작업 성능에 대한 보고는 상반된다. 
    3. 본 연구에서는 BERT, RoBERTa, GPT-2, GPT-3 모델들이 scalar adverbs라고 불리는 단어들을 얼마나 알고 있는지 조사하였고, 논리적 의미의 어떤 측면을 포착하고 있는지 알 수 있었다.

###### Rigorously Assessing Natural Language Explanations of Neurons (https://aclanthology.org/2023.blackboxnlp-1.24/)
- Anthology ID: 2023.blackboxnlp-1.24 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. 자연어는 대량의 언어 모델이 정보를 처리하고 저장하는 방식을 설명하는 데 유용한 매체입니다. 그러나 이러한 설명의 충실성을 평가하는 것은 도전적입니다.
    2. 우리는 자연어 설명이 특정 개념을 나타내는 텍스트 입력에 대한 한 뉴런이 표현한다고 주장하는 것을 평가하기 위해 두 가지 평가 모드를 개발합니다.
    3. 우리의 프레임워크를 GPT-4로 생성된 GPT-2 XL 뉴런의 설명에 적용하여, 가장 확신하는 설명도 오류율이 높고 인과 효능이 전혀 없음을 보여줍니다. 이 논문은 자연어가 설명에 적합한 선택인지, 그리고 뉴런이 최상의 분석 레벨인지에 대해 비판적으로 평가를 마칩니다.

###### NPIs Aren’t Exactly Easy: Variation in Licensing across Large Language Models (https://aclanthology.org/2023.blackboxnlp-1.25/)
- Anthology ID: 2023.blackboxnlp-1.25 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. 큰 규모 언어 모델에서 부정적 극성 항목(NPIs)의 허가에 대해 조사하여, 모델이 NPI를 어떻게 학습하고, 구문-의미 인터페이스에서 언어 현상으로써 이해하는지에 대한 풍부한 그림을 제시합니다.
    2. NPI는 특정 허가 문맥에서만 나타나는 단어들로, 부정이 전형적인 예입니다. 기존의 많은 연구들과는 달리, 우리는 NPI와 그 허가 환경이 통합된 클래스가 아니라 다양한 환경에서 가능한 다른 NPI를 고려합니다.
    3. 다양한 모델에서 이 현상을 연구함으로써, 모델 아키텍처의 특징, 훈련 데이터의 속성 및 NPI 현상의 언어적 특성이 성능에 어떤 영향을 미칠지 탐구할 수 있습니다.

###### Memory Injections: Correcting Multi-Hop Reasoning Failures During Inference in Transformer-Based Language Models (https://aclanthology.org/2023.blackboxnlp-1.26/)
- Anthology ID: 2023.blackboxnlp-1.26 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. "다중 단계 추론 질문에 대답하기 위해서는 다양한 정보를 알맞게 찾아내고 종합해야 한다. 하지만 대규모 언어 모델은 이러한 추론을 일관되게 수행하기 어렵다는 문제가 있다. 
    2. 우리는 대상 언어 모델의 특정 어텐션 헤드에 주요 정보를 집중적으로 주입하여 다중 단계 추론 실패를 정확하게 찾아내고 수정하는 방식을 제시한다.
    3. 우선, GPT-2 모델의 layer별 활성화를 분석하여 단일 단계와 다중 단계의 입력에 대한 모델의 반응을 알아봤다. 그리고 우리는 추론 시 특정 위치에서 관련된 정보를 주입하는 "기억"을 사용자가 삽입할 수 있는 메커니즘을 제안한다. 이렇게 모델이 추론 중에 추가적인 관련 정보를 통합하도록 하는 것으로 다중 단계 입력의 품질을 향상시킨다. 실험적으로, 핵심 어텐션 레이어에 간단하고 효율적인 타겟된 메모리 주입은 다중 단계 작업에서 원하는 다음 토큰의 확률을 최대 424% 증가시킬 수 있다."

###### Systematic Generalization by Finetuning? Analyzing Pretrained Language Models Using Constituency Tests (https://aclanthology.org/2023.blackboxnlp-1.27/)
- Anthology ID: 2023.blackboxnlp-1.27 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. 구성성 테스트(replicate constituency tests)를 수행하는데 성능이 충분하지 않음을 보여주는 선행 pre-trained sequence-to-sequence language models(BART, T5)의 fine-tuning 설정이 다르게 되어 있으면 어떤 영향을 미치는지 조사하였다.
    2. fine-tuning 도중 구성성 테스트와 문장 유형의 다양한 조합을 사용하여 평가 설정을 설계하였는데, 모델은 fine-tuning 중에 보았던 특정 유형의 문장에서만 언어 변환을 재현할 수 있으며, 다른 설정에서는 성능이 크게 저하되어 체계적인 일반화 부족을 보여준다.
    3. 이러한 결과는 모델이 종종 문장을 표면적인 수준에서 구성 성분 수준의 문법 구조와 관련이 없도록 학습하는 것을 보여준다. 이러한 결과는 pre-trained language models가 downstream tasks에서 취약성을 보이는 이유의 일부를 설명할 수 있다.

###### On Quick Kisses and How to Make Them Count: A Study on Event Construal in Light Verb Constructions with BERT (https://aclanthology.org/2023.blackboxnlp-1.28/)
- Anthology ID: 2023.blackboxnlp-1.28 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. "Psycholinguistic 연구들은 사건을 인지하는데 있어 우리의 정신적 인식은 단순히 그것을 설명하는데 사용된 어휘뿐 아니라 구문 구조에도 의존한다고 제안했습니다." 
    2. 우리는 BERT를 사용하여 문법 구조가 사건 지속 시간과 유사성에 미치는 영향을 조사하기 위해 영어 자극을 사용한 두 가지 실험을 제시합니다. 
    3. 우리는 i) BERT 벡터 차원이 인간의 결과와 일치하여 count 구문에서 점동 및 지속적인 사건에 대해 더 짧은 지속 시간을 인코딩한다는 것을 보여주었으며, 반대로 ii) BERT 의미 유사성은 count 구문에서 지속적인 사건이 향해야 하는 개념적 변화를 포착하지 못한다는 것을 발견했습니다.

###### Identifying and Adapting Transformer-Components Responsible for Gender Bias in an English Language Model (https://aclanthology.org/2023.blackboxnlp-1.29/)
- Anthology ID: 2023.blackboxnlp-1.29 
- Volume: Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP 
- Summary: 
    1. 언어 모델(LMs)은 훈련 데이터에서 학습한 성별 편향을 포함하여 다양한 유형의 원치 않는 편향을 보여주고 강조한다. 그러나 우리는 일반적인 언어 모델링 성능에 손상을 주지 않고 이러한 행동을 효과적으로 변경할 수 있는 도구가 부족하다. 
    2. 이 논문에서는 인과 관계를 찾기 위한 세 가지 방법을 고찰하는데, 인과 매개 분석, 자동 회로 탐색 및 Differential Masking을 기반으로 한 DiffMask+라는 새로운 효율적인 방법을 사용한다. 
    3. GPT-2 작은 모델과 성별 편향 문제에 이러한 방법을 적용하고, 발견한 구성요소를 사용하여 편향 완화를 위한 매개 효율적인 fine-tuning을 수행한다. 그 결과, 방법의 계산 요구 사항에 큰 차이가 있음에도 불구하고 특정 부분에서 중복이 크게 나타나며, 일반 언어 모델링에 대한 손상이 덜한 상태로 성별 편향을 완화하는데 성공한다.

## Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching
###### Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching (https://aclanthology.org/2023.calcs-1.0/)
- Anthology ID: 2023.calcs-1.0 
- Volume: Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching 
- Summary: 
    요약문을 생성할 수 없습니다.

###### TongueSwitcher: Fine-Grained Identification of German-English Code-Switching (https://aclanthology.org/2023.calcs-1.1/)
- Anthology ID: 2023.calcs-1.1 
- Volume: Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching 
- Summary: 
    1. 이 연구는 독일어-영어 코드 스위칭 연구에 기여한다. 우리는 독일어 텍스트에 영어가 포함된 자연스러운 독일어-영어 코드 스위칭 코퍼스를 제공하며 코드 스위칭 식별을 위한 두 가지 방법을 제시한다.
    2. 첫 번째 방법은 규칙 기반으로, 단어 목록과 형태학적 처리를 활용한다. 이 방법을 사용하여 독일어-영어 코드 스위칭을 적용한 2,560만 개의 트윗 코퍼스를 작성한다.
    3. 두 번째 방법에서는 이 코퍼스에서 신경 언어 모델의 사전 학습을 이어서 진행하고 해당 언어 모델의 임베딩을 기반으로 토큰을 분류한다. 우리의 시스템은 새로운 코퍼스와 기존 독일어-영어 코드 스위칭 벤치마크에서 소타(SoTA)를 성립한다. 특히, 문맥에서만 해결할 수 있는 언어-모호 단어와 영어와 독일어 형태소가 혼합된 단어에 대해 체계적으로 코드 스위칭을 연구하였다.

###### Towards Real-World Streaming Speech Translation for Code-Switched Speech (https://aclanthology.org/2023.calcs-1.2/)
- Anthology ID: 2023.calcs-1.2 
- Volume: Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching 
- Summary: 
    1. code-switching (CS), 즉 한 문장에서 여러 언어를 섞는 현상은 많은 자연어 처리(NLP) 상황에서 도전적일 수 있으며, 이에 대한 연구는 오프라인 시나리오에 제한되어 왔다.
    2. 우리는 실제 세계의 CS 음성 번역을 위해 두 가지 핵심적이고 탐구되지 않은 영역에 초점을 맞추고자 한다: 스트리밍 설정 및 소스에 포함되지 않은 제3 언어로의 번역.
    3. 이를 위해 Fisher와 Miami 테스트 및 검증 데이터셋을 확장하여 스페인어와 독일어로 변환하는 모델을 학습하고, 오프라인 및 스트리밍 ST의 기준 결과를 수립한다.

###### Language Preference for Expression of Sentiment for Nepali-English Bilingual Speakers on Social Media (https://aclanthology.org/2023.calcs-1.3/)
- Anthology ID: 2023.calcs-1.3 
- Volume: Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching 
- Summary: 
    1. 네팔-영어 코드 스위칭은 특히 소셜 미디어에서 네팔 사회에서 확장되고 있는 현상이다. 코드 스위칭 텍스트는 다중 언어 사용자의 사회 언어 행동을 이해하는 데 활용될 수 있다.
    2. 본 논문에서는 이러한 다중 언어 사용자의 감정 표현에 대한 언어 선호도를 연구한다. 나쁜 감정을 표현하는 데 동종 언어 사용의 선호도가 높은 것으로 나타났다.
    3. 기계 학습 및 트랜스포머 기반 모델을 사용하여 해당 데이터셋에 대해 기준 모델로서 감성 분류를 수행하였고, 이 데이터셋은 공개되었다.

###### Text-Derived Language Identity Incorporation for End-to-End Code-Switching Speech Recognition (https://aclanthology.org/2023.calcs-1.4/)
- Anthology ID: 2023.calcs-1.4 
- Volume: Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching 
- Summary: 
    1. CS(speech의 code-switching) 인식은 짧은 단일 언어 세그먼트에서의 제한된 언어적 맥락으로 인해 자동 음성인식 시스템에 어려움을 줄 수 있는데, LID(language identity)는 이러한 문제를 완화하기 위해 음성인식 시스템에 통합된다. 
    2. 이전 연구는 주로 음성 신호에서 LID를 추출하는데 초점을 맞추었지만 본 논문은 순수한 텍스트 데이터에서 LID를 학습하는 새로운 접근법을 소개한다. 
    3. 텍스트 기반 LID를 통합하는 두 가지 전략인 LID 상태 퓨전과 언어 사후 편향을 탐구하여 LID를 엔드 투 엔드 ASR(음성인식) 시스템에 통합한다.

###### Prompting Multilingual Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages (https://aclanthology.org/2023.calcs-1.5/)
- Anthology ID: 2023.calcs-1.5 
- Volume: Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching 
- Summary: 
    1. 음성 인터페이스의 행동 모델의 의사결정 차이를 기존의 절대 성능 측정 지표로는 정확히 파악하기 어렵다.
    2. 이 논문에서는 두 대화 행동 모델의 유사도를 계산하는 일반적인 방법론을 제안하고, 의미 및 텍스트 수준에서 점수를 계산하는 다양한 방식을 조사한다.
    3. 절대 성능 측정 기준을 보완하기 위해, 우리는 이러한 점수를 세 가지 다른 작업에 적용하고 측정 방법의 실용성을 보여준다.

###### CONFLATOR: Incorporating Switching Point based Rotatory Positional Encodings for Code-Mixed Language Modeling (https://aclanthology.org/2023.calcs-1.6/)
- Anthology ID: 2023.calcs-1.6 
- Volume: Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching 
- Summary: 
    1. 코드믹스(CM)는 두 개 이상의 언어를 혼용하는 것으로, 트랜스포머와 같은 NLP 모델은 많은 태스크에서 효과적이었으나, CM에 대해서는 아직 잘 연구되지 않은 분야이다.
    2. 이 논문에서는 트랜스포머의 비결정적인 특성으로 인해 위치 정보를 항상 인코딩할 수 없다는 문제점을 제시하고, 위치 인코딩을 통해 단어 정보를 풍부하게 만들고 위치 정보를 결합하여 CM 언어 모델링에 특히 switching points에 주의를 기울인다.
    3. 실험 결과, rotatory positional encoding과 switching point 정보를 결합한 방법이 가장 좋은 결과를 얻는 것을 보여주었다. CONFLATOR은 코드믹스된 힌디어와 영어 (힌글리쉬)를 기반으로 하는 두 가지 태스크인 감성 분석 및 기계 번역에서 최신 기술을 능가한다.

###### Unified Model for Code-Switching Speech Recognition and Language Identification Based on Concatenated Tokenizer (https://aclanthology.org/2023.calcs-1.7/)
- Anthology ID: 2023.calcs-1.7 
- Volume: Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching 
- Summary: 
    1. Code-Switching (CS) 다중 언어 자동음성인식(ASR) 모델은 대화 중에 두 개 이상의 번갈아가며 사용되는 언어를 변환할 수 있다. 
    2. 본 논문에서는 (1) 완전히 단일 언어 데이터 소스에서 code-switching ASR 데이터셋을 생성하는 새로운 방법과 (2) 기존의 단일 언어 토크나이저를 재사용하면서 ASR 모델이 각 발행된 텍스트 토큰에 대한 언어 ID를 생성할 수 있는 새로운 Concatenated Tokenizer를 제안한다. 
    3. 제안된 방법들은 영어-힌디어 및 영어-스페인어 두 언어 쌍에 대해 CS ASR 모델을 구축하는 데 효과적이며, Miami Bangor CS 평가 말뭉치에서 새로운 최첨단 결과를 달성한다. 또한, 제안된 Concatenated Tokenizer 모델은 경쟁력 있는 ASR 성능과 함께, FLEURS 데이터셋에서 98% 이상의 언어 식별 정확도를 달성한다.

###### Multilingual self-supervised speech representations improve the speech recognition of low-resource African languages with codeswitching (https://aclanthology.org/2023.calcs-1.8/)
- Anthology ID: 2023.calcs-1.8 
- Volume: Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching 
- Summary: 
    1. 저 자원 언어를 구사하는 많은 사용자들이 다른 지역 언어나 영어로 코드 스위칭(code-switching)을 자주하는 반면, 코드스위치된 음성 데이터셋은 맞춤형 음향 모델을 처음부터 훈련하거나 언어 모델 재스코어링을 할 만큼 충분하지 않다.
    2. 우리는 self-supervised speech representations (wav2vec 2.0 XLSR)을 코드스위치 데이터 인식에 fine-tuning 하는 방법을 제안한다.
    3. 실험 결과, 유한한 훈련 데이터 상황에서 self-supervised 표현의 fine-tuning이 성능 면에서 더 좋은 결과를 보여주는 것으로 나타나며, 유망한 대안이 될 수 있다.

## Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL)
###### Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) (https://aclanthology.org/2023.conll-1.0/)
- Anthology ID: 2023.conll-1.0 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Can Language Models Be Tricked by Language Illusions? Easier with Syntax, Harder with Semantics (https://aclanthology.org/2023.conll-1.1/)
- Anthology ID: 2023.conll-1.1 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 언어 모델은 인간과 유사한 문법적 판단 작업에서 상당한 중복이 있다고 주장되었다. 그러나 인간이 언어 처리에서 일관적인 오류를 만들 때, 우리는 언어 모델이 인지 모델처럼 행동하고 인간의 행동을 모방할 것으로 기대해야 할까? 이 논문에서는 "언어 환각"에 관련된 미묘한 판단에 대해 언어 모델의 동작을 조사하여 이 질문에 대답한다.
    2. 언어 모델의 확률은 비교 환각이나 depth-charge 환각과 같은 심층적인 의미 이해를 요구하지만, NPI 환각의 경우에는 인간의 판단과 더 일치하는 경향이 있다. 어떤 언어 모델 또는 메트릭도 일관된 결과를 제공하지 않는다.
    3. 결국, 우리는 언어 모델이 인간의 언어 처리의 인지 모델로 쓸 수 있는 한계가 있으며, 복잡한 언어 자료에서 섬세하고 중요한 정보를 인식하는 능력도 한정되어 있다는 것을 보여준다.

###### ToMChallenges: A Principle-Guided Dataset and Diverse Evaluation Tasks for Exploring Theory of Mind (https://aclanthology.org/2023.conll-1.2/)
- Anthology ID: 2023.conll-1.2 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. "Theory of Mind (ToM), 즉 다른 사람의 정신 상태를 이해하는 능력은 다양한 실용적인 응용분야에 필수적이다. 그러나 대형 언어 모델 (LLM)의 ToM 작업 수행 능력에 대한 논란이 있다. 이 논문에서는 ToMChallenges라는 다양한 과제 세트가 포함된 Sally-Anne, Smarties 테스트에 기반한 ToM 평가를 위한 데이터셋을 제안한다."
    2. "우리는 davinci, turbo, gpt-4 세 가지 모델을 테스트해본 결과, LLM은 프롬프트와 작업에 따라 불일치하는 행동을 보이며 ToM 작업을 안정적으로 수행하는 것은 여전히 어려운 도전임을 보여준다."
    3. "또한, 우리의 논문은 LLM에서 ToM을 평가하는 데 대한 인식을 높이고, LLM의 능력을 더 잘 평가할 수 있는 ToM 과제와 프롬프트를 설계하기 위해 더 많은 논의를 이끌기 위한 것이다."

###### The Zipfian Challenge: Learning the statistical fingerprint of natural languages (https://aclanthology.org/2023.conll-1.3/)
- Anthology ID: 2023.conll-1.3 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 이 논문은 사람의 언어가 다른 소통 시스템과 기본적으로 다른 점을 구분해내는 것에 대한 "Zipfian Challenge"를 표준 분류 과제로 접근하는 것을 제안한다.
    2. 다양한 글쓰기 시스템과 언어, 심볼적이고 비복잡한 시스템 등을 포함한 텍스트 자료로 구성된 말뭉치를 사용하여 이진 분류 알고리즘을 훈련하고 테스트한다.
    3. 결과적으로 사람의 언어는 큰 단위 종류, 높은 엔트로피와 인접 단위의 반복 횟수가 적은 통계적 특징을 가지며, 이 특징은 다른 심볼적이고 비심볼적인 시스템과 구분하기 위해 사용될 수 있다.

###### On the Effects of Structural Modeling for Neural Semantic Parsing (https://aclanthology.org/2023.conll-1.4/)
- Anthology ID: 2023.conll-1.4 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 시멘틱 파싱은 자연어 문장을 논리 형식 또는 프로그래밍 언어와 같은 사전 정의된 형식 언어로 매핑하는 작업이다. 이 논문에서는 시멘틱 파싱과 관련하여 자연어와 형식 언어를 시퀀스로 처리하는 시멘틱 파서들의 구조 모델링 기법들을 평가하고, 구조 선택에 대한 메트릭을 제안하여 특정 데이터셋과 도메인에 대한 문법 설계의 자동화를 촉진할 수 있다고 주장하고 있다.
    2. 구조를 고려하는 시멘틱 파서들은 자연어와 형식 언어의 구조를 모델링하고, 모델의 소스와 타깃 측에 대한 구조 선택이 중요하다는 것을 밝혀냈다.
    3. 특정 데이터셋과 일반화 수준에 따라 구조가 설계되어야 하며, 소스와 타깃 측의 구조 선택보다는 양쪽을 조합하는 선택이 중요하다는 것을 발견하였다.

###### Humans and language models diverge when predicting repeating text (https://aclanthology.org/2023.conll-1.5/)
- Anthology ID: 2023.conll-1.5 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 다음 단어 예측을 학습한 언어 모델은 단어 예측과 읽기 속도에 있어 인간의 행동을 정확하게 모델링한다고 알려져 왔지만, 본 연구에서는 인간과 언어 모델의 성능이 다른 경우를 소개한다. 
    2. 반복되는 텍스트 구간을 가진 5개의 자극에 대한 인간의 다음 단어 예측 데이터셋을 수집하였고, 처음에는 인간과 GPT-2 언어 모델의 예측이 강하게 일치하지만, 기억력 (또는 문맥 학습)이 작용하기 시작하면 성능이 빠르게 차이가 나기 시작한다.
    3. 이 차이의 원인은 중간 레이어의 특정 어텐션 헤드에서 추적되었으며, 이러한 어텐션 헤드에 거듭 제곱 법칙의 최근성 바이어스를 추가하면 모델이 인간과 유사한 성능을 보인다. 이 연구는 언어 모델을 인간의 행동에 더 가깝게 만들기 위한 미래 연구를 촉진할 것을 기대한다.

###### Investigating the Nature of Disagreements on Mid-Scale Ratings: A Case Study on the Abstractness-Concreteness Continuum (https://aclanthology.org/2023.conll-1.6/)
- Anthology ID: 2023.conll-1.6 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 인간들은 척도에 대해 강한 합의를 보이지만 (예: 고양이는 매우 구체적으로 평가된다), 중간 단어에 대한 판단은 더 많은 불일치를 보인다. 그러나 수집된 평가 기준은 학문 분야 전반에 걸쳐 적용된다. 
    2. 이 연구는 구체성 평가에 초점을 맞추고, (i) 상관 관계와 감독 분류를 구현하여 중간 단어의 중요한 다중 모달 특성을 식별하고, (ii) 하드 클러스터링을 적용하여 평가자 간 체계적인 불일치 패턴을 식별한다. 
    3. 결과는 중간 척도 대상 단어를 세밀 조정하거나 거르기를 권장한다.

###### ArchBERT: Bi-Modal Understanding of Neural Architectures and Natural Languages (https://aclanthology.org/2023.conll-1.7/)
- Anthology ID: 2023.conll-1.7 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 최근 몇 년 동안 멀티모달 언어 모델 구축이 트렌드인데, 이미지, 비디오, 음성 등의 추가적인 모달리티를 자연어와 함께 학습한다. 
    2. 그러나 다양한 모달리티로 이루어진 멀티모달 언어 모델은 신경망 아키텍처와 자연어 간의 연결을 위한 기존 솔루션이 없다.
    3. 이 논문에서는 신경망 아키텍처와 자연어의 학습 및 이해를 위한 이중 학습 모델인 ArchBERT를 제안하며, 이를 통해 뉴럴 아키텍처나 간단한 텍스트 쿼리를 통한 AutoML 접근 방법을 개선하는데 도움을 줄 수 있다는 가치를 제시한다.

###### A Comparative Study on Textual Saliency of Styles from Eye Tracking, Annotations, and Language Models (https://aclanthology.org/2023.conll-1.8/)
- Anthology ID: 2023.conll-1.8 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 최근의 자연어 처리 파이프라인에서는 시선 추적 데이터와 같은 인간 언어 처리의 암묵적인 측정치를 통합하는 데에 대한 관심이 커지고 있다. 
    2. 이 논문은 언어 처리 데이터가 인간들의 언어 이해에 대한 독특한 통찰력을 포함하고 있으며 언어 모델에 의해 활용될 수 있다고 주장한다. 
    3. EyeStyliency라는 이름의 눈 추적 데이터셋을 소개하고, 이 데이터가 인간 주석 방법과 모델 기반의 중요도 점수와 어떻게 일치하는지 조사한다.

###### PROPRES: Investigating the Projectivity of Presupposition with Various Triggers and Environments (https://aclanthology.org/2023.conll-1.9/)
- Anthology ID: 2023.conll-1.9 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 발화의 사전추론은 다른 유추(entailment)와는 다르게 projectivity를 가지고 있는데, 여태까지는 이를 고려하지 않은 기존 자연언어 이해 연구들이 존재한다.
    2. 이 논문에서는 새로운 데이터셋인 PROPRES를 도입하며, 6가지 trigrer와 5가지 환경을 포함한 12,000개의 문장 쌍을 사용하여 모델의 성능을 평가한다.
    3. 사람들의 판단의 변동성과 언어학적인 항목의 조합을 고려하는 유용성 평가를 통해 DeBERTa 모델은 projectivity를 완전히 포착하지 못한다는 것을 보여준다.

###### A Minimal Approach for Natural Language Action Space in Text-based Games (https://aclanthology.org/2023.conll-1.10/)
- Anthology ID: 2023.conll-1.10 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. Text-based games에서는 language models (LMs)와 knowledge graphs (KGs)를 사용하여 대화형 환경을 다루는데, 이러한 기술이 필요한지 혹은 과도하게 사용되었는지에 대해 불분명하다.
    2. 본 논문에서는 action space를 탐색하는 문제에 다시 초점을 맞추고, admissible한 액션들을 활용하는 minimal한 𝜖-admissible exploration을 제안한다.
    3. 본 연구는 Jericho의 10개 게임을 기준으로, KG나 LM을 사용하지 않고 오로지 게임 관측 정보만을 활용해 텍스트 명령을 생성하는 text-based actor-critic (TAC) 에이전트를 제시한다. 이 방법은 강력한 베이스라인 및 최신 기법을 뛰어넘는 성능을 보여주며, 지수적으로 큰 액션 공간을 효과적으로 탐색하기 위해 더 가벼운 모델 디자인과 환경 내 정보의 새로운 관점을 강조한다.

###### Structural Ambiguity and its Disambiguation in Language Model Based Parsers: the Case of Dutch Clause Relativization (https://aclanthology.org/2023.conll-1.11/)
- Anthology ID: 2023.conll-1.11 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 이 논문은 네덜란드어 관계 절의 구조적 모호함에 대해 다룬다. '지지를 통한 모호함 해소' 작업을 통해, 이전 문장의 존재가 관계 절의 모호함을 해소하는 방법을 연구한다. 이 방법을 두 개의 구문 분석 구조에 적용하여 현대 신경망 구문 분석기의 구문 분석과 언어 모델 구성 요소를 분석한다.
    2. 결과는 proof nets을 기반으로 한 neurosymbolic 구문 분석기가 universal dependencies를 기반으로 한 접근 방식보다 데이터 편향 보정에 더 개방적이지만, 두 가지 설정 모두 유사한 초기 데이터 편향에 문제가 있다.
    3. (이 외에는 다른 특별한 내용이 없는 것 같으므로 더이상 추가로 요약하지 않겠습니다.)

###### On the utility of enhancing BERT syntactic bias with Token Reordering Pretraining (https://aclanthology.org/2023.conll-1.12/)
- Anthology ID: 2023.conll-1.12 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 최근에는 자기 지도 학습 언어 모델이 사전 훈련에 대한 기본 선택 사항이 되었지만, Token Reordering (TOR) 사전 훈련 목표는 토큰 예측 이상으로 깊게 연구되지 않았다.
    2. 이 연구에서는 일부 토큰 입력이 주어졌을 때 두 토큰이 인접한지 여부를 예측하는 새로운 TOR 사전 훈련 목표를 설계하였다.
    3. 결과적으로 TOR는 GLUE 언어 이해 벤치마크에서 MLM에 대비해 경쟁력이 있으며, 특히 구문 종속적인 데이터셋에서는 몇몇 샷 학습 설정에서 약간 우위에 있다.

###### Quirk or Palmer: A Comparative Study of Modal Verb Frameworks with Annotated Datasets (https://aclanthology.org/2023.conll-1.13/)
- Anthology ID: 2023.conll-1.13 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 일상 대화에서 사용되는 모달 동사는 발화자의 관점을 전달하는 데에 널리 사용되지만, 그 사용 방법과 문맥에 따라 의미가 크게 달라질 수 있다. 그러나 모달 동사의 의미 분류에 대해서는 언어학자들 간에 합의가 없다. 
    2. 본 논문에서는 MoVerb 데이터셋을 소개하는데, 이 데이터셋에는 사회적 대화에서 하나 이상의 문장을 포함한 4,540개의 발화에 대한 27,240개의 모달 동사 의미 주석이 포함되어 있다. 
    3. MoVerb 데이터셋을 사용하여 RoBERTa 기반 분류기를 훈련시키고, Quirk와 Palmer 프레임워크에 대해 각각 82.2와 78.3의 F1 스코어를 달성하여 모달 동사의 의미 모호성 해결이 쉬운 작업이 아님을 보여주었다.

###### Quantifying Information of Tokens for Simple and Flexible Simultaneous Machine Translation (https://aclanthology.org/2023.conll-1.14/)
- Anthology ID: 2023.conll-1.14 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. Simultaneous Translation (ST)은 전체 소스 입력이 아닌 일부 소스 입력만으로 번역하는 것으로 번역 품질의 저하 가능성이 있다. 이전 접근 방식은 번역 품질과 응답 지연 시간의 균형을 맞추기 위해 합리적인 정책을 가진 오프라인 모델을 활용하는 것이 더 효과적이라는 것을 보였다.
    2. 그러나 오프라인 모델 사용은 부분 소스 입력으로 훈련되지 않았기 때문에 분포 변화를 일으키며, 언제 번역을 수행할지 알려주는 추가 모듈을 통해 개선할 수 있다.
    3. 본 논문에서는 소스와 대상 정보를 모델링하여 오프라인 모델이 번역에 충분한 정보를 가지고 있는지 판단하는 정보 양자 (IQ)를 제안한다. IQ는 정보를 양자화함으로써 Simultaneous Translation을 위한 적합한 정책을 구성하는 데 도움이 되며, 품질과 지연 시간 사이의 균형을 자연스럽게 제어할 수 있다. 여러 언어 쌍에서의 실험 결과, 제안한 모델이 기준 모델보다 우수한 성능을 보였다.

###### Enhancing Code-mixed Text Generation Using Synthetic Data Filtering in Neural Machine Translation (https://aclanthology.org/2023.conll-1.15/)
- Anthology ID: 2023.conll-1.15 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 코드믹싱은 다중 언어 사회에서 흔히 사용되는 의사소통 현상이지만, 데이터의 품질이 NLP 시스템에 큰 제약을 둔다. 이 논문에서는 인간의 판단을 활용하여 고품질의 코드믹싱 문장을 생성하는 신경 기계 번역 방법을 제안한다.
    2. 인견 판단을 기반으로 필터를 훈련시켜 합성된 코드믹싱 문장에서 자연스러운 코드믹싱 문장을 식별하는 여러 프레러럴 코퍼스를 생성한다. 이를 활용하여 다중 언어 인코더-디코더 모델을 학습시키고, 더 나은 코드믹싱 생성 결과를 얻을 수 있다.
    3. 힌디어-영어 뿐만 아니라, 저자원 언어인 텔루구어의 코드믹싱 문장 생성에도 효과적이다.

###### Towards Better Evaluation of Instruction-Following: A Case-Study in Summarization (https://aclanthology.org/2023.conll-1.16/)
- Anthology ID: 2023.conll-1.16 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 최근의 발전에도 불구하고, 대형 언어 모델이 사용자 지시를 얼마나 잘 따르는지 평가하는 것은 여전히 열려 있는 문제이다.
    2. 언어 모델의 평가 방법은 prompt 기반 접근법에 대한 연구가 늘어났으나, 이러한 방법들의 정확성에 대한 연구는 제한적이다.
    3. 우리는 grounded query-based 요약을 통해 언어 모델의 지시 따르기 능력을 정확하게 측정하는 다양한 메트릭의 메타-평가를 수행하였다.

###### Syntactic Inductive Bias in Transformer Language Models: Especially Helpful for Low-Resource Languages? (https://aclanthology.org/2023.conll-1.17/)
- Anthology ID: 2023.conll-1.17 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. BERT와 같은 Transformer 기반 언어 모델의 구문 인지 편향은 많은 데이터를 필요로 하지 않고 훈련을 강화시킬 수 있을 것이라는 이론에 기반하여 개발되었다. 하지만 이러한 방법들은 영어와 같은 high-resource 언어에서 주로 테스트되었다. 
    2. 따라서 본 연구에서는 이러한 방법들이 low-resource 언어의 데이터 부족 문제를 보완할 수 있는지 조사하였고, low-resource 언어에서의 효과가 더 크다는 가설을 세웠다.
    3. 우리는 Uyghur, Wolof, Maltese, Coptic, 그리고 Ancient Greek이라는 다섯 가지의 low-resource 언어를 실험 대상으로 하였고, 이러한 구문 인지 편향 방법들이 low-resource 환경에서 일정하지 않은 결과를 도출하며, 대부분의 경우에 놀랍도록 적은 혜택을 제공한다는 사실을 발견하였다.

###### Attribution and Alignment: Effects of Local Context Repetition on Utterance Production and Comprehension in Dialogue (https://aclanthology.org/2023.conll-1.18/)
- Anthology ID: 2023.conll-1.18 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 현대 대화 시스템의 기반으로 자주 사용되는 언어 모델은 대량의 작성된 유창한 언어로 사전 학습된다. 하지만 대화에서는 반복이 중요한 요소이다. 이 연구에서는 (a) 언어 모델이 대화에서 인간과 유사한 수준의 반복을 생성하는지, (b) 이해과정에서 어휘 재사용과 관련된 처리 메커니즘에 대해 평가한다. 
    2. 우리는 모델 생성과 이해 행동의 공동 분석이 인지적 영감을 받은 대화 생성 시스템의 개발에 도움을 줄 수 있다고 믿는다. 
    3. 사람들은 로컬하게 반복하고 파트너에게 특정 반복을 사용하며, 이는 인간 사용자가 선호하며 대화에서 더 성공적인 커뮤니케이션으로 이어진다.

###### The Validity of Evaluation Results: Assessing Concurrence Across Compositionality Benchmarks (https://aclanthology.org/2023.conll-1.19/)
- Anthology ID: 2023.conll-1.19 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 최근 NLP 모델은 많은 데이터셋을 통해 성능을 평가하였지만, 특정 데이터셋 설계 선택이 모델 능력에 대한 결론에 어떤 영향을 미치는지에 대한 의문이 남아있다.
    2. 이 연구에서 우리는 합성성 일반화의 도메인에서 6가지 모델링 접근 방식을 4개 데이터셋에 걸쳐 조사하였고, 8가지 합성 분할 전략에 따라서도 성능을 평가하였다. 결과는 다음과 같다: i) 합성 일반화를 평가하기 위해 설계된 데이터셋은 각기 다른 모델링 접근 방식에 대해 다르게 선호하는 경향이 있었다. ii) 사람이 생성한 데이터셋은 인공적인 데이터셋 보다 서로 더 일치하였다. iii) 데이터셋의 원본이 같은지 여부가 구성적 합성의 해석을 유지하는지 여부보다 모델 순위에 더 많은 예측력을 가지고 있었다. iv) 데이터셋 내의 특정 어휘 항목이 측정 일관성에 영향을 미치는 것으로 나타났다.
    3. 전체적으로, 우리의 결과는 인기 있는 평가 데이터셋이 의도한 바를 측정하는지 여부를 평가하는 데에는 아직 많은 작업이 남아있고, 보다 엄격한 기준을 제시함으로써 평가 세트의 타당성을 확립하는 것이 이 분야에 도움이 될 수 있다는 것을 시사한다.

###### Mind the instructions: a holistic evaluation of consistency and interactions in prompt-based learning (https://aclanthology.org/2023.conll-1.20/)
- Anthology ID: 2023.conll-1.20 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 현재 NLP에서 사전 학습 언어 모델을 작업에 적응하는 가장 좋은 방법을 찾는 것은 큰 도전이다. 이 논문은 in-context-learning(ICL)이나 instruction tuning(IT)을 통해 작업에 적응된 모델들이 어떤 상황에서는 강건하고, 다른 상황에서는 그렇지 않은 이유에 대해 상세한 분석을 제시한다.
    2. 먼저, TT 모델에서 알려진 문제인 입력 분포와 레이블 사이의 의미 없는 상관관계는 prompted 모델에서는 거의 문제가 되지 않는다는 것을 보여준다.
    3. 그런 다음, prompting 설정에서 예측에 영향을 미치는 다양한 요소들을 체계적으로 ganz리적으로 평가한다. 이들 요소의 모든 가능한 조합을 테스트하고, 다양한 크기의 일반 LLM과 instruction-tuned LLM에서 결과를 통계적으로 분석하여 가장 영향력이 크거나 상호작용하는 요소들, 그리고 가장 안정적인 요소들을 보여준다.

###### Med-HALT: Medical Domain Hallucination Test for Large Language Models (https://aclanthology.org/2023.conll-1.21/)
- Anthology ID: 2023.conll-1.21 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 이 연구 논문은 대형 언어 모델(LLM)에서 발생하는 환각에 초점을 맞추고 있으며, 특히 의료 분야에서의 환각 문제를 다룹니다.
    2. Med-HALT (의료 분야 환각 테스트)라는 새로운 벤치마크와 데이터셋을 제안하여 환각을 평가하고 줄이는 데에 목적이 있습니다.
    3. Med-HALT는 다양한 국가에서 수행된 의료 검사를 기반으로 한 다양한 테스트 모달리티를 포함하고 있으며, LLM의 문제 해결 및 정보 검색 능력을 평가하는 데 사용됩니다.

###### Revising with a Backward Glance: Regressions and Skips during Reading as Cognitive Signals for Revision Policies in Incremental Processing (https://aclanthology.org/2023.conll-1.22/)
- Anthology ID: 2023.conll-1.22 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. NLP에서 incremental processors는 언어 입력의 접두사에 기반하여 출력을 단계적으로 생성한다. 하지만 모델이 왜 수정을 하는지에 대해서는 잘 알려져 있지 않다. 
    2. 수정이 필요한 시점을 감지하는 정책은 효율성을 향상시킬 수 있다. 하지만 수정 정책을 훈련시키기 위한 적절한 신호를 찾는 것은 여전히 문제이다. 
    3. 이 연구에서는 인간의 독해 시간에 따른 회귀(regressions)와 스킵(skips)이 수정을 위한 신호로 사용될 수 있는지 조사하였으며, 다양한 언어에 대해 BiLSTM 및 Transformer 모델에 일관된 결과를 얻었다.

###### ChiSCor: A Corpus of Freely-Told Fantasy Stories by Dutch Children for Computational Linguistics and Cognitive Science (https://aclanthology.org/2023.conll-1.23/)
- Anthology ID: 2023.conll-1.23 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 이 논문에서는 자연적인 맥락에서 어린이들이 자유롭게 이야기하는 619개의 판타지 이야기를 포함한 새로운 코퍼스인 ChiSCor를 소개한다.
    2. ChiSCor는 어린이의 인지와 언어를 이해하기 위한 계산 도구로 해당 이야기들을 연구하기 위해 구성되었다.
    3. ChiSCor는 언어와 인지의 발전에 따른 어린이의 캐릭터 시각화 방식을 연구하는데 유용하며, Zipf의 법칙에도 잘 부합된다는 사실과 함께 언어 처리를 위한 설명 벡터를 학습하기에 충분히 풍부하다는 것을 보여주고 있다.

###### HNC: Leveraging Hard Negative Captions towards Models with Fine-Grained Visual-Linguistic Comprehension Capabilities (https://aclanthology.org/2023.conll-1.24/)
- Anthology ID: 2023.conll-1.24 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 이미지-텍스트 매칭(ITM)은 비전과 언어에서 대량 말뭉치로부터 일반화된 표현을 학습하기 위한 방법 중 하나이다. 하지만 웹에서 수집한 이미지-텍스트 쌍 간의 약한 연관성으로 인해 모델들은 이 모달리티의 결합된 의미를 세밀하게 이해하지 못한다.
    2. 따라서 우리는 세밀한 교차 모달 이해를 달성하기 위해 ITM 학습에 사용되는 traiing set을 위한 어려운 부정적인 캡션이 포함된 HNC라는 자동 생성된 데이터셋을 제안한다.
    3. 우리의 결과는 HNC에서의 학습이 임상적인 작업에서 미스매치 감지의 제로샷 능력을 향상시키고, 잡음이 있는 시각적 입력 시나리오에서 강력한 성능을 발휘함을 보여준다. 또한 HNC 모델이 세밀 조정을 위한 비교적 좋은 초기화를 제공한다는 것을 보여준다.

###### Theory of Mind in Large Language Models: Examining Performance of 11 State-of-the-Art models vs. Children Aged 7-10 on Advanced Tests (https://aclanthology.org/2023.conll-1.25/)
- Anthology ID: 2023.conll-1.25 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 큰 언어 모델 (LLMs)에는 Theory of Mind (ToM)과 같은 의도와 믿음에 대한 추론 능력을 어느 정도 부여해야 할까요? 이 논문에서는 (i) 대세인 잘못된 믿음 패러다임 외에도 ToM과 관련된 능력을 11개의 베이스-LLMs와 인스트럭션 튜닝 된 LLMs로 테스트하고, (ii) 표준화된 테스트의 새로운 버전을 사용하여 LLMs의 강건성을 평가하고, (iii) 폐쇄적 질문 외에도 개방형 질문 점수화를 위한 프롬프트와 점수화를 수행하며, (iv) 동일한 태스크에서 7-10세 어린이와 LLM의 실적을 벤치마킹합니다.
    2. GPT 계열의 인스트럭션 튜닝 LLMs이 다른 모델보다 우수한 성능을 보이며, 종종 어린이보다 뛰어납니다. 베이스 LLMs는 대부분 특화된 프롬프트로도 ToM 태스크를 해결할 수 없습니다.
    3. 우리는 언어와 ToM의 상호 연결된 진화와 발달이 인스트럭션 튜닝이 추가되는 이유를 설명하는 데 도움이 될 수 있다고 제안합니다. 상대방과 맥락을 고려한 협력적인 커뮤니케이션을 보상하는 것입니다. LLMs에서 ToM에 대한 세심한 관점을 주장합니다.

###### A Block Metropolis-Hastings Sampler for Controllable Energy-based Text Generation (https://aclanthology.org/2023.conll-1.26/)
- Anthology ID: 2023.conll-1.26 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 최근의 연구는 에너지 기반 언어 모델링이 임의의 판별기를 유연하게 통합할 수 있는 효과적인 텍스트 생성 프레임워크임을 입증했습니다.
    2. 그러나 전체 정규화를 수행하는 에너지 기반 언어 모델은 추론에 Metropolis-Hastings (MH)와 같은 근사 기법을 필요로 합니다.
    3. 이 논문에서는 대조적으로, 한 번의 단계에서 전체 시퀀스를 다시 작성하는 새로운 MH 샘플러를 개발하여, 더 효율적이고 정확한 대상 분포 샘플링이 가능해집니다.

###### How Fragile is Relation Extraction under Entity Replacements? (https://aclanthology.org/2023.conll-1.27/)
- Anthology ID: 2023.conll-1.27 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. Relation Extraction (RE)은 텍스트 컨텍스트에서 엔티티 간의 관계를 추출하는 것을 목표로 한다. 하지만 기존의 모델은 텍스트 컨텍스트 대신 엔티티 이름 패턴을 기억하여 예측하기 때문에, 문장에 있는 관계가 무시된다고 밝혀졌다.
    2. 본 논문에서는 대체된 엔티티에 대한 복원력 있는 RE 모델의 필요성을 제기하고, TACRED 데이터셋에서 상태-of-the-art RE 모델의 자리에 랜덤하고 타입 제한 조건이 있는 엔티티를 대체하여 실험을 진행하였다.
    3. 실험 결과, 상태-of-the-art RE 모델이 엔티티 대체에 대해 30%~50% F1 score 하락을 보였으며, 이는 엔티티 대체에 강건한 효과적인 RE 모델 개발을 위해 더 많은 노력이 필요하다는 것을 시사한다.

###### JaSPICE: Automatic Evaluation Metric Using Predicate-Argument Structures for Image Captioning Models (https://aclanthology.org/2023.conll-1.28/)
- Anthology ID: 2023.conll-1.28 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 이미지 캡션 생성은 BLEU와 METEOR과 같은 자동 평가 메트릭에 많이 의존하는데, n-gram 기반 메트릭은 인간 평가와 상관관계가 낮다고 보고되어, 영어를 위한 SPICE와 같은 대체 메트릭이 제안되었다.
    2. 이 연구에서는 일본어 자막을 scene graph를 기반으로 평가하는 자동 평가 메트릭인 JaSPICE를 제안한다. 제안된 방법은 의존성과 술어-인자 구조를 통해 scene graph를 생성하고, 동의어를 활용하여 그래프를 확장한다.
    3. STAIR Captions와 PFN-PIC에서 학습한 10개의 이미지 캡션 모델을 실험에 활용하고, 103,170개의 인간 평가를 포함하는 Shichimi 데이터셋을 구축하여, 우리의 평가 메트릭이 인간 평가와 상관관계에서 기준 메트릭보다 우수한 성능을 보였다.

###### MuLER: Detailed and Scalable Reference-based Evaluation (https://aclanthology.org/2023.conll-1.29/)
- Anthology ID: 2023.conll-1.29 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. MuLER은 기계번역 (MT)을 비롯한 텍스트 생성의 참조 기반 평가 메트릭을 세밀한 분석 도구로 변환하는 새로운 방법론을 제안한다. MuLER은 선택한 메트릭이 특정 오류 유형 (예: 위치 이름 번역 오류)에 얼마나 엄격한지를 정량화하여 세부적인 오류 분석이 가능하게 한다.
    2. MT 평가뿐만 아니라 요약 등 다른 작업에서 MuLER의 유용성을 보여주기 위해 합성 및 자연적인 환경에서 실험을 수행하였다. 2014-2020년 WMT의 모든 제출물을 분석한 결과, 일관된 트렌드를 발견했는데, 명사와 동사가 가장 빈번한 POS 태그 중 하나지만 번역하기 가장 어렵다는 것이다.
    3. 요약 작업을 통한 초기 실험 결과도 유사한 트렌드를 보여주었다.

###### The Impact of Familiarity on Naming Variation: A Study on Object Naming in Mandarin Chinese (https://aclanthology.org/2023.conll-1.30/)
- Anthology ID: 2023.conll-1.30 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 동일한 객체 또는 개체에 대해 다른 화자는 종종 다른 이름을 사용하며, 이러한 이름의 변동은 잘 이해되지 않는다.
    2. 우리는 중국어에 대한 언어 및 비전 데이터셋을 만들어보고, 주어진 객체에 대한 익숙함과 주제 간의 명명 변동의 정도와의 관계를 조사한다.
    3. 우리는 익숙함이 두 가지 경쟁적인 방식으로 명명 변동에 영향을 미친다고 제안하는데, 익숙함은 어휘를 확장시켜 변동을 높일 수도 있고, 일반적인 이름으로 수렴을 촉진하여 변동을 줄일 수도 있다.

###### PSST! Prosodic Speech Segmentation with Transformers (https://aclanthology.org/2023.conll-1.31/)
- Anthology ID: 2023.conll-1.31 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 우리는 비번역화된 대화형 영어 음성에서 주곡선 구분을 감지하기 위한 모델을 개발하고 조사한다. 
    2. 이 모델은 Transformer 기반 음성-텍스트(STT) 모델을 fine-tuning하여, 음성 인식 작업과 Intonation Unit (IU) 경계 식별을 통합한 것이다. 
    3. 우리는 모델이 다양한 사투리와 전사 프로토콜을 대표하는 분포 외의 데이터에서도 강건한 성능을 보이며, 프로소딕 구조를 알리는데 일반적으로 이해되는 음향적 정보만이 아니라 오디오에서 추론된 어휘 및 구문 정보에 의존하는 것을 확인하였다.

###### Alignment via Mutual Information (https://aclanthology.org/2023.conll-1.32/)
- Anthology ID: 2023.conll-1.32 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 많은 언어 학습 태스크들은 두 모드 간의 데이터 상응관계를 추론하는 것을 요구한다. 종종 이러한 상응관계는 다대다 및 문맥 종속적이다.
    2. 저자들은 문맥 종속적이고 다대다 매핑을 위해 정보 이론적 접근방법을 설명한다. 저자들은 먼저 마스킹된 순서 모델을 학습하여 (소스, 타겟) 순서의 빠진 구간에 대한 분포를 배치한다. 그런 다음 이 모델을 사용하여 문맥에 조건부로 소스와 타겟 구간 간의 점별 상호정보를 계산한다.
    3. 제안된 이 방법은 구조화된 방법과 신경망 기반 기준을 모두 능가하는 성능을 보여주며, 조건부 상호정보는 일반적인 도메인에서 상응관계 문제를 형식화하는 효과적인 프레임워크를 제공한다는 것을 보여준다.

###### Challenging the “One Single Vector per Token” Assumption (https://aclanthology.org/2023.conll-1.33/)
- Anthology ID: 2023.conll-1.33 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 이 논문은 각 토큰이 하나의 벡터로 표현되어야 한다는 네트워크 내의 전체적인 가정에 대해 의문을 제기한다.
    2. 실험 결과, 의존 문법 분석에서 각 토큰을 벡터의 시퀀스로 표현하는 것이 더 나은 성능을 보인다는 것을 보여준다.
    3. 이 결과는 순환 신경망에서 토큰을 처리하는 방식에 대한 추가적인 연구가 필요하다는 것을 시사한다.

###### Strategies to Improve Low-Resource Agglutinative Languages Morphological Inflection (https://aclanthology.org/2023.conll-1.34/)
- Anthology ID: 2023.conll-1.34 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 형태학적 변형은 형태학 분야에서 중요한 과제로, 보통은 시퀀스 변환 작업으로 간주된다. 최근 몇 년간 많은 연구자들의 관심을 받아 상당한 진전을 이루었으며, 고-저자원 언어에 대해 인상적인 성능을 달성하였다. 그러나 훈련 데이터셋의 인스턴스 분포가 변경되거나, 새로운 lemma나 특징 레이블이 예측되는 상황에서 모델의 정확도는 떨어진다.
    2. 접착어(agglutinative) 언어에서는 형태학적 변형 시 새로운 단어를 생성하면서 음운 사상(phonological phenomena)이 관여하며, 이는 원형(lemma)과 접미사 사이의 음절 패턴을 변경시킬 수 있다.
    3. 이 논문에서는 저자원 접착어 언어에 적용할 수 있는 4가지 전략을 제안한다. 이를 통해 모델의 일반화 능력을 향상시킬 수 있는데, 이는 합성어의 음절과 피처 레이블의 순서를 학습하거나, 원형 내에서 공통 부분 문자열을 인식하여 단어로 복사하는 등의 방식을 포함한다. 실험결과, 제안된 모델이 다른 베이스라인 모델보다 우수한 성능을 보였다.

###### Exploring Transformers as Compact, Data-efficient Language Models (https://aclanthology.org/2023.conll-1.35/)
- Anthology ID: 2023.conll-1.35 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 대부분의 트랜스포머 모델은 매우 크기 때문에 한정된 컴퓨팅 자원을 가진 사람들은 이 모델들을 사용할 수 없다.
    2. 이 논문에서는 5.7백만 개의 파라미터로도 트랜스포머 모델을 축소시킬 수 있으며, 대부분의 downstream 능력을 유지할 수 있다는 것을 보여준다.
    3. 또한, 5백만 단어의 pretraining 데이터로 훈련된 트랜스포머 모델도 상당한 결과를 유지할 수 있으며, 복잡한 모델 압축 방법이 항상 훨씬 우수한 것은 아니라는 것을 보여준다.

###### Tree-shape Uncertainty for Analyzing the Inherent Branching Bias of Unsupervised Parsing Models (https://aclanthology.org/2023.conll-1.36/)
- Anthology ID: 2023.conll-1.36 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 이 논문은 tree-shape uncertainty의 형식화를 제안하여, 텍스트만을 사용하여 비지도 파싱 모델의 내재적인 분기 경향(branching bias)을 분석할 수 있게 한다. 
    2. 이전 연구들은 훈련된 파서의 출력을 골드 문법 트리와 비교하여 비지도 파싱 모델의 분기 경향을 분석했지만, 이러한 접근은 텍스트가 서로 다른 문법에서 생성될 수 있다는 점을 고려하지 않고 모델이 학습한 훈련 데이터의 편향과 모델의 내재적인 편향을 명확하게 분리하지 못할 수 있다.
    3. 이를 위해, 우리는 tree-shape uncertainty를 공식화하고, 편향된 정보가 없을 것으로 예상되는 텍스트를 생성하기 위해 사용할 수 있는 충분한 조건을 도출한다. 실험에서는 이러한 편향이 없는 텍스트로 파서를 훈련시키면 기존의 비지도 파싱 모델의 분기 편향을 효과적으로 탐지할 수 있음을 보여준다.

###### Future Lens: Anticipating Subsequent Tokens from a Single Hidden State (https://aclanthology.org/2023.conll-1.37/)
- Anthology ID: 2023.conll-1.37 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 개별 입력 토큰에 대응하는 숨겨진 상태 벡터는 몇 개의 토큰을 정확하게 예측하는 데 충분한 정보를 포함한다고 추측한다.
    2. 이 논문은 단일 토큰의 숨겨진 (내부) 표현을 통해 t + 2 이상의 위치에 나타날 토큰을 신뢰성 있게 예측할 수 있는지 알아보고 있다.
    3. GPT-J-6B에서 선형 대략화와 인과적 개입 방법을 측정하여 네트워크의 개별 숨겨진 상태가 미래의 숨겨진 상태와 토큰 출력을 예측하기에 충분한 신호를 포함하는 정도를 평가한다고 한다.

###### Cross-Document Event Coreference Resolution: Instruct Humans or Instruct GPT? (https://aclanthology.org/2023.conll-1.38/)
- Anthology ID: 2023.conll-1.38 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 본 논문에서는 대형 언어 모델을 사용하여 Cross-Document Event Coreference Resolution (CDEC) 주석을 수행하고, 다양한 수준의 학습을 받은 사람 주석자와 어떻게 맞선지 평가한다.
    2. GPT-4 기반의 zero-shot 학습 결과, 대부분의 경우 사람 주석자보다 우수한 성능을 보이며 학습된 주석자와 비교 가능한 수준의 성능을 나타낸다.
    3. 그러나 GPT-4는 과도하게 자신감이 있으며, 충분한 정보가 없는 경우에도 강제적으로 주석 결정을 내릴 수 있다는 특성을 보인다.따라서 본 연구는 LLM시대에서 CDEC와 같은 복잡한 주석을 수행하는 방법에 대한 함의가 있다. 고품질 데이터를 확보하기 위해서 LLM의 장점과 학습된 인간 주석자의 강점을 결합하는 것이 가장 효율적인 방법일 것이다.

###### Implications of Annotation Artifacts in Edge Probing Test Datasets (https://aclanthology.org/2023.conll-1.39/)
- Anthology ID: 2023.conll-1.39 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. 엣지 프로빙 테스트는 LLM과 같은 문맥 인코더에서 나온 토큰 표현에 문법 지식이 인코딩되어 있는지를 확인하는 분류 작업이다. 많은 LLM 인코더가 이러한 테스트에서 높은 성능을 보여줌에 따라 언어 지식을 인코딩하는 능력에 대한 추측이 제기되었다.
    2. 그러나 많은 연구에서는 이러한 테스트가 LLM의 인코딩 능력을 측정하는 것이 아니라 분류기의 문제 학습 능력을 반영한다는 것을 주장하고 있다. 특히, LLM 대 무작위 인코더를 사용할 때 분류기의 정확도가 매우 유사한 경우가 많다.
    3. 이 논문에서는 널리 사용되는 엣지 프로빙 테스트 데이터셋에는 외움을 포함한 다양한 편향이 있다는 것을 보여준다. 이러한 편향이 제거되면 단순한 비정보 이론적 프로브라도 LLM 인코더와 무작위 인코더 사이에 유의미한 차이가 나타난다.

###### REFER: An End-to-end Rationale Extraction Framework for Explanation Regularization (https://aclanthology.org/2023.conll-1.40/)
- Anthology ID: 2023.conll-1.40 
- Volume: Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL) 
- Summary: 
    1. "인간-주석 기반 텍스트 설명은 설명 가능한 자연어 처리에서 점점 중요해지고 있다. 이 논문에서는 다음을 목표로 하는 rationale extraction을 제안한다. 이는 예측에 가장 큰 영향을 미친 입력을 강조하여 모델의 행동을 신뢰할 만한 설명을 제공함과 동시에 성능을 희생시키지 않는다."
    2. "기존 작업에서는 주로 plausibility 최적화를 위해 인간의 주석을 사용해 rationale extractor를 훈련시키고, task model은 task 예측 정확도와 faithfulness을 동시에 최적화하는 방식을 사용했다."
    3. "우리는 REFER라는 프레임워크를 제안하여 rationale extraction 과정에 back-propagation을 허용하는 differentiable rationale extractor를 사용하는 것의 효과를 분석했다. 실험 결과, REFER는 신뢰성, 타당성, 그리고 새로운 데이터에서도 downstream task 정확도 측면에서 이전 기준점들보다 크게 향상된 결과를 보여준다."

## Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning
###### Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning (https://aclanthology.org/2023.conll-babylm.0/)
- Anthology ID: 2023.conll-babylm.0 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Findings of the BabyLM Challenge: Sample-Efficient Pretraining on Developmentally Plausible Corpora (https://aclanthology.org/2023.conll-babylm.1/)
- Anthology ID: 2023.conll-babylm.1 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    Sorry, there seems to be an error in obtaining the abstract. Could you please provide the abstract again?

###### GPT-wee: How Small Can a Small Language Model Really Get? (https://aclanthology.org/2023.conll-babylm.2/)
- Anthology ID: 2023.conll-babylm.2 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    본 논문은 MCQ 생성에 대한 평가 메트릭으로 KDA를 제안한다. 기존의 평가 방법들은 교육적 가치를 고려하지 않고 단어 유사성만을 측정한다. KDA는 학생들의 응답을 기반으로 문제해결 능력을 측정하는데 완전한 지식에 기반하여 MCQ의 대답 가능성(answerability)을 측정하는 메트릭이다. 
    
    최근의 deep learning 모델은 NLP 태스크에서 뛰어난 성능을 보여주지만, 데이터에 나타나는 특징들에 대한 의존성으로 인해 robustness가 제한된다. 이 논문에서는 contrastive learning과 counterfactual augmentation을 이용하여 robustness를 개선하고자 한다. 본 연구에서는 여러 counterfactual을 생성하고, 이를 통해 단어들의 인과관계를 더 robust하게 파악할 수 있는 방법을 제안한다.

###### Tiny Language Models Enriched with Multimodal Knowledge from Multiplex Networks (https://aclanthology.org/2023.conll-babylm.3/)
- Anthology ID: 2023.conll-babylm.3 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    이 논문은 MCQ 생성의 교육적 가치를 평가하기 위한 새로운 자동 평가 메트릭 KDA를 제안한다. 기존의 평가 메트릭은 생성된 MCQ와 골드 샘플 사이의 단어 유사도를 비교하는데 집중하며 교육적 가치를 고려하지 않는다. KDA는 학생 응답을 기반으로 MCQ의 대답 가능성과 해당 대상 사실에 대한 학생 지식을 평가한다. 
    
    이 논문은 contrastive learning과 counterfactual augmentation을 활용하여 NLP 모델의 강건성을 향상시키는 것을 목표로 한다. 기존의 augmentation 방법은 데이터셋에 counterfactual을 추가하는 작업이나 이미 데이터셋에 있는 근처 counterfactual을 자동으로 찾아내는 것을 요구한다. 하지만 이 논문에서 제안하는 augmentation은 여러 개의 counterfactual을 생성하여 이들에 대한 예측 결과 분포를 고려하는 집단적 의사 결정을 통해 각 단어의 인과관계를 강건하게 파악한다. 
    
    이 논문은 NLP 태스크에서 딥 모델의 강건성을 향상시켜 다양한 측면에서 성능 개선을 이룩한다. 이를 통해 카운터팩투얼 강건성, 도메인 간 일반화, 희소 데이터 일반화 등의 측면에서 유의한 향상을 보인다.

###### Mini Minds: Exploring Bebeshka and Zlata Baby Models (https://aclanthology.org/2023.conll-babylm.4/)
- Anthology ID: 2023.conll-babylm.4 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    Please provide the abstract for the third paper as well. Thank you.

###### Grammar induction pretraining for language modeling in low resource contexts (https://aclanthology.org/2023.conll-babylm.5/)
- Anthology ID: 2023.conll-babylm.5 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    This paper proposes a novel automatic evaluation metric, called Knowledge Dependent Answerability (KDA), for assessing the educational value of automatically generated Multiple Choice Questions (MCQ). The existing evaluation metrics focus on similarity to gold samples and fail to evaluate the MCQ's ability to assess students' knowledge. The proposed KDA metric measures the answerability of MCQs given knowledge of the target fact. Through human studies, the authors demonstrate strong correlations between KDA_disc and KDA_cont with both KDA and usability in a classroom setting.

###### ChapGTP, ILLC’s Attempt at Raising a BabyLM: Improving Data Efficiency by Automatic Task Formation (https://aclanthology.org/2023.conll-babylm.6/)
- Anthology ID: 2023.conll-babylm.6 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Penn & BGU BabyBERTa+ for Strict-Small BabyLM Challenge (https://aclanthology.org/2023.conll-babylm.7/)
- Anthology ID: 2023.conll-babylm.7 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Too Much Information: Keeping Training Simple for BabyLMs (https://aclanthology.org/2023.conll-babylm.8/)
- Anthology ID: 2023.conll-babylm.8 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Can training neural language models on a curriculum with developmentally plausible data improve alignment with human reading behavior? (https://aclanthology.org/2023.conll-babylm.9/)
- Anthology ID: 2023.conll-babylm.9 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### CLIMB – Curriculum Learning for Infant-inspired Model Building (https://aclanthology.org/2023.conll-babylm.10/)
- Anthology ID: 2023.conll-babylm.10 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Acquiring Linguistic Knowledge from Multimodal Input (https://aclanthology.org/2023.conll-babylm.11/)
- Anthology ID: 2023.conll-babylm.11 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Large GPT-like Models are Bad Babies: A Closer Look at the Relationship between Linguistic Competence and Psycholinguistic Measures (https://aclanthology.org/2023.conll-babylm.12/)
- Anthology ID: 2023.conll-babylm.12 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Baby’s CoThought: Leveraging Large Language Models for Enhanced Reasoning in Compact Models (https://aclanthology.org/2023.conll-babylm.13/)
- Anthology ID: 2023.conll-babylm.13 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### ToddlerBERTa: Exploiting BabyBERTa for Grammar Learning and Language Understanding (https://aclanthology.org/2023.conll-babylm.14/)
- Anthology ID: 2023.conll-babylm.14 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### CogMemLM: Human-Like Memory Mechanisms Improve Performance and Cognitive Plausibility of LLMs (https://aclanthology.org/2023.conll-babylm.15/)
- Anthology ID: 2023.conll-babylm.15 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### BabyStories: Can Reinforcement Learning Teach Baby Language Models to Write Better Stories? (https://aclanthology.org/2023.conll-babylm.16/)
- Anthology ID: 2023.conll-babylm.16 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Byte-ranked Curriculum Learning for BabyLM Strict-small Shared Task 2023 (https://aclanthology.org/2023.conll-babylm.17/)
- Anthology ID: 2023.conll-babylm.17 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### McGill BabyLM Shared Task Submission: The Effects of Data Formatting and Structural Biases (https://aclanthology.org/2023.conll-babylm.18/)
- Anthology ID: 2023.conll-babylm.18 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Mean BERTs make erratic language teachers: the effectiveness of latent bootstrapping in low-resource settings (https://aclanthology.org/2023.conll-babylm.19/)
- Anthology ID: 2023.conll-babylm.19 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Not all layers are equally as important: Every Layer Counts BERT (https://aclanthology.org/2023.conll-babylm.20/)
- Anthology ID: 2023.conll-babylm.20 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### WhisBERT: Multimodal Text-Audio Language Modeling on 100M Words (https://aclanthology.org/2023.conll-babylm.21/)
- Anthology ID: 2023.conll-babylm.21 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### A surprisal oracle for active curriculum language modeling (https://aclanthology.org/2023.conll-babylm.22/)
- Anthology ID: 2023.conll-babylm.22 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Mmi01 at The BabyLM Challenge: Linguistically Motivated Curriculum Learning for Pretraining in Low-Resource Settings (https://aclanthology.org/2023.conll-babylm.23/)
- Anthology ID: 2023.conll-babylm.23 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Baby Llama: knowledge distillation from an ensemble of teachers trained on a small dataset with no performance penalty (https://aclanthology.org/2023.conll-babylm.24/)
- Anthology ID: 2023.conll-babylm.24 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### BabyLM Challenge: Curriculum learning based on sentence complexity approximating language acquisition (https://aclanthology.org/2023.conll-babylm.25/)
- Anthology ID: 2023.conll-babylm.25 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Better Together: Jointly Using Masked Latent Semantic Modeling and Masked Language Modeling for Sample Efficient Pre-training (https://aclanthology.org/2023.conll-babylm.26/)
- Anthology ID: 2023.conll-babylm.26 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Lil-Bevo: Explorations of Strategies for Training Language Models in More Humanlike Ways (https://aclanthology.org/2023.conll-babylm.27/)
- Anthology ID: 2023.conll-babylm.27 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Towards more Human-like Language Models based on Contextualizer Pretraining Strategy (https://aclanthology.org/2023.conll-babylm.28/)
- Anthology ID: 2023.conll-babylm.28 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Increasing The Performance of Cognitively Inspired Data-Efficient Language Models via Implicit Structure Building (https://aclanthology.org/2023.conll-babylm.29/)
- Anthology ID: 2023.conll-babylm.29 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Pre-training LLMs using human-like development data corpus (https://aclanthology.org/2023.conll-babylm.30/)
- Anthology ID: 2023.conll-babylm.30 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### On the effect of curriculum learning with developmental data for grammar acquisition (https://aclanthology.org/2023.conll-babylm.31/)
- Anthology ID: 2023.conll-babylm.31 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Optimizing GPT-2 Pretraining on BabyLM Corpus with Difficulty-based Sentence Reordering (https://aclanthology.org/2023.conll-babylm.32/)
- Anthology ID: 2023.conll-babylm.32 
- Volume: Proceedings of the BabyLM Challenge at the 27th Conference on Computational Natural Language Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

## Proceedings of The Sixth Workshop on Computational Models of Reference, Anaphora and Coreference (CRAC 2023)
###### Proceedings of The Sixth Workshop on Computational Models of Reference, Anaphora and Coreference (CRAC 2023) (https://aclanthology.org/2023.crac-main.0/)
- Anthology ID: 2023.crac-main.0 
- Volume: Proceedings of The Sixth Workshop on Computational Models of Reference, Anaphora and Coreference (CRAC 2023) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Filling in the Gaps: Efficient Event Coreference Resolution using Graph Autoencoder Networks (https://aclanthology.org/2023.crac-main.1/)
- Anthology ID: 2023.crac-main.1 
- Volume: Proceedings of The Sixth Workshop on Computational Models of Reference, Anaphora and Coreference (CRAC 2023) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### CAW-coref: Conjunction-Aware Word-level Coreference Resolution (https://aclanthology.org/2023.crac-main.2/)
- Anthology ID: 2023.crac-main.2 
- Volume: Proceedings of The Sixth Workshop on Computational Models of Reference, Anaphora and Coreference (CRAC 2023) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Towards Transparency in Coreference Resolution: A Quantum-Inspired Approach (https://aclanthology.org/2023.crac-main.3/)
- Anthology ID: 2023.crac-main.3 
- Volume: Proceedings of The Sixth Workshop on Computational Models of Reference, Anaphora and Coreference (CRAC 2023) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Scalar Anaphora: Annotating Degrees of Coreference in Text (https://aclanthology.org/2023.crac-main.4/)
- Anthology ID: 2023.crac-main.4 
- Volume: Proceedings of The Sixth Workshop on Computational Models of Reference, Anaphora and Coreference (CRAC 2023) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Better Handling Coreference Resolution in Aspect Level Sentiment Classification by Fine-Tuning Language Models (https://aclanthology.org/2023.crac-main.5/)
- Anthology ID: 2023.crac-main.5 
- Volume: Proceedings of The Sixth Workshop on Computational Models of Reference, Anaphora and Coreference (CRAC 2023) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### The pragmatics of characters’ mental perspectives in pronominal reference resolution (https://aclanthology.org/2023.crac-main.6/)
- Anthology ID: 2023.crac-main.6 
- Volume: Proceedings of The Sixth Workshop on Computational Models of Reference, Anaphora and Coreference (CRAC 2023) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### MARRS: Multimodal Reference Resolution System (https://aclanthology.org/2023.crac-main.7/)
- Anthology ID: 2023.crac-main.7 
- Volume: Proceedings of The Sixth Workshop on Computational Models of Reference, Anaphora and Coreference (CRAC 2023) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Towards Harmful Erotic Content Detection through Coreference-Driven Contextual Analysis (https://aclanthology.org/2023.crac-main.8/)
- Anthology ID: 2023.crac-main.8 
- Volume: Proceedings of The Sixth Workshop on Computational Models of Reference, Anaphora and Coreference (CRAC 2023) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Integrated Annotation of Event Structure, Object States, and Entity Coreference (https://aclanthology.org/2023.crac-main.9/)
- Anthology ID: 2023.crac-main.9 
- Volume: Proceedings of The Sixth Workshop on Computational Models of Reference, Anaphora and Coreference (CRAC 2023) 
- Summary: 
    요약문을 생성할 수 없습니다.

## Proceedings of the CRAC 2023 Shared Task on Multilingual Coreference Resolution
###### Proceedings of the CRAC 2023 Shared Task on Multilingual Coreference Resolution (https://aclanthology.org/2023.crac-sharedtask.0/)
- Anthology ID: 2023.crac-sharedtask.0 
- Volume: Proceedings of the CRAC 2023 Shared Task on Multilingual Coreference Resolution 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Findings of the Second Shared Task on Multilingual Coreference Resolution (https://aclanthology.org/2023.crac-sharedtask.1/)
- Anthology ID: 2023.crac-sharedtask.1 
- Volume: Proceedings of the CRAC 2023 Shared Task on Multilingual Coreference Resolution 
- Summary: 
    1. 논문은 멀티링귀언어(CorefUD 데이터셋)의 공동 참조 해결(shared task)에 대한 두 번째 에디션에 대한 요약이다. 작년과 같이 공동 참조 해결을 위한 학습 가능한 시스템을 생성하는 참가자들의 참여가 이뤄졌지만, 이번에는 조금 다른 주요 평가 점수와 12개 언어에 대한 17개 데이터셋을 사용했다.
    2. 이번에는 학습 및 평가 데이터로 CorefUD 데이터셋의 1.1 버전을 사용했다. 
    3. 이번에는 7개 시스템이 이 공동 참조 해결(shared task)에 참가했다.

###### Multilingual coreference resolution: Adapt and Generate (https://aclanthology.org/2023.crac-sharedtask.2/)
- Anthology ID: 2023.crac-sharedtask.2 
- Volume: Proceedings of the CRAC 2023 Shared Task on Multilingual Coreference Resolution 
- Summary: 
    1. CRAC 공유 작업 2023을 위해 제출된 두 개의 다국어 coreference resolution 시스템을 소개하며, DFKI-Adapt 시스템은 4.9 F1 점으로 공식 기준치를 능가하는 성능을 보인다.
    2. DFKI-Adapt 시스템은 문자 임베딩, 어댑터 모듈, 공동 사전 훈련 및 손실 기반 재훈련 등 다양한 특징과 학습 설정의 조합을 사용한다.
    3. 다른 제출인 DFKI-MPrompt는 mention generation을 위해 프롬프트를 사용하는 혁신적인 접근법을 채택하였으며, 훈련을 단 5회만 시행하여 좋은 결과를 제공한다.

###### Neural End-to-End Coreference Resolution using Morphological Information (https://aclanthology.org/2023.crac-sharedtask.3/)
- Anthology ID: 2023.crac-sharedtask.3 
- Volume: Proceedings of the CRAC 2023 Shared Task on Multilingual Coreference Resolution 
- Summary: 
    1. 형태론이 풍부한 언어에서는 단어가 형태소로 구성되어 있어 형태소 수준의 표현을 사용해야 할 수도 있고, 이 연구에서는 transformer 기반 단어 임베딩에 형태론 정보를 통합하여 다국어 end-to-end coreference resolution 시스템을 소개한다.
    2. 형태론 정보를 명시적으로 coreference resolution에 포함시키면 특히 형태론이 풍부한 언어에서 (예: 카탈로니아어, 헝가리어, 터키어) 성능이 향상된다.
    3. 이 모델은 CoNLL F-score가 59.53%로 기준 모델보다 평균적으로 2.57% 포인트 우수한 성능을 달성한다.

###### ÚFAL CorPipe at CRAC 2023: Larger Context Improves Multilingual Coreference Resolution (https://aclanthology.org/2023.crac-sharedtask.4/)
- Anthology ID: 2023.crac-sharedtask.4 
- Volume: Proceedings of the CRAC 2023 Shared Task on Multilingual Coreference Resolution 
- Summary: 
    1. CorPipe는 다국어 코어퍼런스 해결 CRAC 2023 공유 작업에서 우승한 시스템으로, 다른 참가자들을 4.5% 이상 앞섰다.
    2. CorPipe는 먼저 멘션 탐지를 수행하고 그 후에 검색된 스팬에서 속기 원칙을 적용하여 코어퍼런스 링크를 수행한다.
    3. CorPipe는 모든 사용 가능한 말뭉치를 공유 사전 학습 언어 모델을 사용하여 함께 학습시키며, 512개의 subwords보다 큰 입력과 멘션 디코딩 변경 및 앙상블 지원을 포함한 주요 개선 사항이 있다.

###### McGill at CRAC 2023: Multilingual Generalization of Entity-Ranking Coreference Resolution Models (https://aclanthology.org/2023.crac-sharedtask.5/)
- Anthology ID: 2023.crac-sharedtask.5 
- Volume: Proceedings of the CRAC 2023 Shared Task on Multilingual Coreference Resolution 
- Summary: 
    1. CRAC 2023 공유 작업을 위해 제출된 우리의 모델은 12개 언어를 포함한 17개 데이터셋을 공동 학습한 엔티티 순위 모델로, 이전에 제출된 모델들을 F1 스코어 차이 +8.47로 앞선 성능을 보여주어, 공유 작업에서 4등을 달성했다.
    2. 데이터 전처리, 사전 훈련된 인코더, 데이터 혼합과 관련된 설계 결정에 대해 탐구하였다. 
    3. 우리의 모델은 최종적으로 F1 스코어 65.43을 달성하여 공유 작업에서 우수한 성과를 보여주었다.

## Proceedings of the 1st GenBench Workshop on (Benchmarking) Generalisation in NLP
###### Proceedings of the 1st GenBench Workshop on (Benchmarking) Generalisation in NLP (https://aclanthology.org/2023.genbench-1.0/)
- Anthology ID: 2023.genbench-1.0 
- Volume: Proceedings of the 1st GenBench Workshop on (Benchmarking) Generalisation in NLP 
- Summary: 
    요약문을 생성할 수 없습니다.

###### 90% F1 Score in Relation Triple Extraction: Is it Real? (https://aclanthology.org/2023.genbench-1.1/)
- Anthology ID: 2023.genbench-1.1 
- Volume: Proceedings of the 1st GenBench Workshop on (Benchmarking) Generalisation in NLP 
- Summary: 
    1. 지식 베이스 구축을 위한 텍스트에서 관계적인 triple을 추출하는 것은 중요한 과제이다. 기존의 모델들은 실제적인 실험 환경과 비현실적인 데이터셋에서 평가되어 왔다. 이 논문에서는 실제적인 환경에서 최신 모델들을 벤치마크로 평가하는 연구를 제시한다.
    2. 이 논문은 기존 모델들은 zero triple을 가지는 문장을 무시하여 작업을 단순화하였고, 이로 인해 실제적인 실험 환경에서 성능이 상당히 저하되는 것을 보였다.
    3. 이 논문에서는 더 실제적인 환경에서의 성능 향상을 위해, 간단한 BERT 기반 분류기를 활용하는 두 단계의 모델링 접근법을 제안한다. 이는 실제적인 실험 환경에서 전반적인 성능 향상을 이끌어냈다.

###### GenCodeSearchNet: A Benchmark Test Suite for Evaluating Generalization in Programming Language Understanding (https://aclanthology.org/2023.genbench-1.2/)
- Anthology ID: 2023.genbench-1.2 
- Volume: Proceedings of the 1st GenBench Workshop on (Benchmarking) Generalisation in NLP 
- Summary: 
    1. 언어 모델들은 소프트웨어 개발자들에게 생산성을 높일 수 있는 가치있는 도구로 사용될 수 있다. 그러나 기존의 훈련 데이터는 주로 인기 있는 프로그래밍 언어에 초점을 맞추고 있어서 저-resource 프로그래밍 언어들을 간과한다. 
    2. 우리는 Hupkes et.,al.에 의해 제안된 NLP 일반화 탐색법에 영감을 받아, 언어 모델의 프로그래밍 언어 이해 일반화 능력을 체계적으로 평가하기 위한 벤치마크 데이터셋인 GenCodeSearchNet (GeCS)을 제안한다. 
    3. R은 컴퓨터 과학 분야에서 벗어난 연구자들에게 널리 사용되는 인기있는 프로그래밍 언어이지만, 그 동안 크게 다루어지지 않은 언어로, 이를 중점적으로 다루는 Manuelly curated subset인 StatCodeSearch를 도입한다.

###### Adapt and Decompose: Efficient Generalization of Text-to-SQL via Domain Adapted Least-To-Most Prompting (https://aclanthology.org/2023.genbench-1.3/)
- Anthology ID: 2023.genbench-1.3 
- Volume: Proceedings of the 1st GenBench Workshop on (Benchmarking) Generalisation in NLP 
- Summary: 
    1. Text-to-SQL 문장 파싱의 cross-domain과 cross-compositional generalization은 어려운 작업이다. 기존 모델들은 테스트할 Natural Language (NL) 쿼리마다 추론 시간에 적은 수의 exemplar를 training set에서 추출하여 실행 시 prompt를 합성하는 방식을 사용한다. 그러나 우리는 오프라인 샘플링을 통해 학습 데이터에서 최소한의 few-shot을 선택하는 알고리즘을 개발하여 매번 expensive 한 exemplar 검색 시간을 피하고, 다양한 exemplar로 구성된 고정된 Generic Prompt (GP)을 합성함으로써 NL 테스트 쿼리에 대한 완전한 커버리지를 제공한다.
    2. 우리는 또한 대상 데이터베이스 도메인에 맞게 GP를 자동으로 적응시키는 DA-GP를 추가로 개발하여 cross-domain generalization을 더 잘 다룰 수 있다. 그리고 cross-compositional generalization을 다루기 위해 Least-To-Most-Prompting (LTMP-DA-GP)를 분해하는 방법을 사용한다.
    3. 우리의 접근 방식은 Text-to-SQL 작업의 일반화 능력을 평가하기 위해 설계된 KaggleDBQA 데이터셋에서 우수한 성능을 보여준다. 또한 KaggleDBQA의 다양한 LLMs와 데이터베이스에서 GP 대비 LTMP-DA-GP의 일관된 성능 향상을 보여주며, prompt 기반의 적응과 분해 방식의 효과와 모델에 구애받지 않는 이점을 강조한다.

###### Evaluating Neural Language Models as Cognitive Models of Language Acquisition (https://aclanthology.org/2023.genbench-1.4/)
- Anthology ID: 2023.genbench-1.4 
- Volume: Proceedings of the 1st GenBench Workshop on (Benchmarking) Generalisation in NLP 
- Summary: 
    1. "Neural language models (LMs)는 기술적인 작업에서의 성공을 통해 언어 습득과의 차이가 명확한데도 불구하고 언어 과제에서의 과학적인 이론으로의 잠재적인 관련성을 가져왔다."
    2. "문법적 능력 평가의 주요한 벤치마크가 LMs의 요구사항을 충분히 견뎌낼 수 없을 수 있다고 주장한다."
    3. "우리는 언어의 구조적 기반을 탐구하기 위해 경험적으로 연구된 데이터셋의 사용을 주장하며, 특히 LI-Adger 데이터셋에 대한 실험 결과를 언급한다."

###### Robust Code Summarization (https://aclanthology.org/2023.genbench-1.5/)
- Anthology ID: 2023.genbench-1.5 
- Volume: Proceedings of the 1st GenBench Workshop on (Benchmarking) Generalisation in NLP 
- Summary: 
    1. 이 논문은 고급 transformer 기반 언어 모델을 사용하여 코드 summarization의 복잡성을 다룬다. 텍스트적 단서에 의존하는 것이 아닌 코드의 의미를 실제로 이해하는 지 알아보기 위해 함수와 변수 이름을 변경하여 코드 summarization의 효과를 검증한다.
    2. 우리는 Python, Javascript, Java 세 가지 프로그래밍 언어로 된 코드에서 dead code, commented code와 같은 adversary를 도입하여 모델의 이해력을 더욱 구체적으로 조사한다.
    3. 최종적으로, 우리의 연구는 transformer 기반 언어 모델의 내부 작동 방식에 대한 가치 있는 통찰을 제공하여 코드를 이해하는 능력을 향상시키고 효율적인 소프트웨어 개발 및 유지보수 워크플로에 기여하고자 한다.

###### Temporal Generalizability in Multimodal Misinformation Detection (https://aclanthology.org/2023.genbench-1.6/)
- Anthology ID: 2023.genbench-1.6 
- Volume: Proceedings of the 1st GenBench Workshop on (Benchmarking) Generalisation in NLP 
- Summary: 
    1. 시간적 변화가 다중모달 모델에 대한 성능에 어떤 영향을 미치는지 조사한 실험 결과, 모델 성능은 시간에 따라 점차 하락하는 것으로 나타났다. 이 연구는 시간적 변화에 대비하지 않은 전통적인 평가 전략과 비교하여, 훈련 데이터에 나타나지 않는 시간 대의 데이터에서 모델을 평가하는 것이 매크로 F1에서 비선형적이고 7-8%의 성능 저하를 초래한다는 것을 확인하였다.
    2. 시간적 변화의 일반화를 어렵게 만드는 두 가지 요인인 내용 변화와 클래스 분포 변화에 대한 조사 결과, 내용 변화가 리콜에 더 큰 영향을 미침을 발견하였다.
    3. 허위정보 탐지에서의 분류 세부 정보를 고려한 실험결과, 특정 허위정보 클래스는 내용 변화에 대해 상대적으로 안정적인 것으로 나타났으며, 미래의 연구에서는 실제 성능을 잘 반영하기 위해 허위정보의 시간적 특성을 명확히 고려해야 한다는 결론을 얻었다.

###### Robust Generalization Strategies for Morpheme Glossing in an Endangered Language Documentation Context (https://aclanthology.org/2023.genbench-1.7/)
- Anthology ID: 2023.genbench-1.7 
- Volume: Proceedings of the 1st GenBench Workshop on (Benchmarking) Generalisation in NLP 
- Summary: 
    1. 리소스 제한된 환경에서는 일반화가 특히 중요하다. 우리는 지식 분리 모델의 일반화 능력을 조사하고, 보지 않은 텍스트 장르에서의 성능을 평가하여 이를 메꾸는 전략을 실험한다.
    2. Weight decay 최적화, 출력 노이즈 제거 및 반복적인 가짜 레이블링을 사용하여 분포와 다른 데이터에서의 성능 차이를 줄일 수 있는 방법을 실험한다.
    3. Mayan 언어 Uspanteko로 작성된 문장을 사용하여 수행한 실험에서, 이러한 전략을 통해 보지 않은 장르의 텍스트에서 2% 성능 향상을 달성하였다.

###### Walking a Tightrope – Evaluating Large Language Models in High-Risk Domains (https://aclanthology.org/2023.genbench-1.8/)
- Anthology ID: 2023.genbench-1.8 
- Volume: Proceedings of the 1st GenBench Workshop on (Benchmarking) Generalisation in NLP 
- Summary: 
    1. 고위험 도메인에서의 언어 모델의 정확성과 안전성은 중요한 문제이다. 대형 언어 모델 (LLMs)의 ChatGPT와 같은 모델들의 고위험 도메인 내에서의 성능은 여전히 불분명하다.
    2. 우리는 고위험 도메인에서의 instruction-tuned LLM의 성능을 분석하고, 사실적인 정확성과 안전 준수를 중점적으로 평가하는 실험을 진행하였다.
    3. 고위험 도메인에서의 LLM의 한계를 강조하며, LLM의 능력을 개선하는 것뿐만 아니라 도메인 특화된 지표의 완화와 안전성 및 사실적 신뢰성 강화를 위해 인간 중심 접근법을 채택하는 것이 중요하다는 결론을 도출하였다.

###### Latent Feature-based Data Splits to Improve Generalisation Evaluation: A Hate Speech Detection Case Study (https://aclanthology.org/2023.genbench-1.9/)
- Anthology ID: 2023.genbench-1.9 
- Volume: Proceedings of the 1st GenBench Workshop on (Benchmarking) Generalisation in NLP 
- Summary: 
    1. 소셜 미디어의 증가로 인해 유해 콘텐츠의 확산이 늘고 견고한 혐오 발언 탐지 시스템의 필요성도 높아졌다. 
    2. 이 논문에서는 모델의 숨은 표현(clustering of models' hidden representations)을 기반으로 기존 데이터셋을 새롭게 분할하여 특정 키워드에 대한 과적합 문제를 돋보이게 하고 모델의 잠재 공간의 blind spot에서의 실패를 확인한다.
    3. 이 연구 결과는 한 모델에서 분할을 개발하고 다른 모델에서 평가할 때에도 일반화된다. 반면 성능 저하와 관련된 데이터 분할의 표면적 속성은 명확하지 않으며, 이는 과제의 난이도가 항상 사람이 해석 가능하지는 않음을 강조한다.

###### Syntax-Guided Transformers: Elevating Compositional Generalization and Grounding in Multimodal Environments (https://aclanthology.org/2023.genbench-1.10/)
- Anthology ID: 2023.genbench-1.10 
- Volume: Proceedings of the 1st GenBench Workshop on (Benchmarking) Generalisation in NLP 
- Summary: 
    1. "합성 일반화"는 지능 모델이 새로운 조합에 대한 이해를 완화하는 능력으로, 특히 다중 모달 환경에서의 AI 연구에서 매우 중요하고 어려운 요소이다.
    2. 이 연구에서는 언어의 문법 구조를 활용하여 합성 일반화를 강화한다. 특히, 텍스트 입력 구문 분석에서 파생된 어텐션 마스킹 기술을 통해 문법적 경험을 활용하는 것이 중요하다.
    3. 우리는 의존성 파싱(dependency parsing)을 사용하는 것의 장점과 Transformer 인코더에서 가중치 공유를 활용할 때 다양한 작업에서 합성 일반화를 향상시킬 수 있다는 것을 평가하고, 이를 통해 다중 모달 연결과 매개 변수 효율적 모델링을 위한 최신 기술을 제안한다.

###### mSCAN: A Dataset for Multilingual Compositional Generalisation Evaluation (https://aclanthology.org/2023.genbench-1.11/)
- Anthology ID: 2023.genbench-1.11 
- Volume: Proceedings of the 1st GenBench Workshop on (Benchmarking) Generalisation in NLP 
- Summary: 
    1. 최근에 나타난 언어 모델들은 다양한 태스크에서 놀라운 결과를 보이지만, 합성 일반화 벤치마크에서 여전히 어려움을 겪는다.
    2. 이 논문에서는 이러한 벤치마크의 평가 결과가 다른 언어로 일반화될 수 있는지에 대한 질문을 제기한다.
    3. 이 질문에 대한 초기 단계로, 저자들은 SCAN 데이터셋의 다국어 버전인 mSCAN을 소개하고, 이를 통해 몇 가지 문맥 학습 실험과 GPT3.5 및 다국어 대형 언어 모델 BLOOM을 평가한다.

###### Inductive Bias Is in the Eye of the Beholder (https://aclanthology.org/2023.genbench-1.12/)
- Anthology ID: 2023.genbench-1.12 
- Volume: Proceedings of the 1st GenBench Workshop on (Benchmarking) Generalisation in NLP 
- Summary: 
    1.유한한 증거로부터 인식된 시스템 일반화는 귀납적 편향의 존재에 결정적으로 의지한다. 이 연구는 Kharitonov and Chaabouni (2021)의 연구에서 영감을 받아, CNN, LSTMs (with and without attention), transformers와 같은 다양한 유형의 sequence-to-sequence 신경망 모델에서 귀납적 편향을 조사한다.
    2. 하지만 중요한 점은, 이 연구에서는 그들의 연구보다 더 넓은 범위의 가능한 귀납적 편향을 고려한다.
    3. hierarchical generalization과 counting strategy를 비교하기 위해, 우리는 transformers는 hierarchical generalization을 선호하지 않고 counting strategy를 선호한다는 Kharitonov and Chaabouni (2021)의 결과와 달리, hierarchical generalization을 선호하지 않음을 발견했다.또한 다양한 조합성에 대한 편향을 조사했고, Kharitonov and Chaabouni (2021)의 테스트셋에서 교란을 제어함으로써 일반적으로 더 일관성 없는 일반화를 발견하고, 고려된 두 가지 유형의 generalization 이외의 타입으로 응답이 많이 나왔다. 그럼에도 불구하고, 우리는 모든 유형의 모델에서 원시 데이터와 기능의 조합을 기반으로 한 검증 세트에서 일관된 구성적 일반화를 관찰했으나, 훈련 세트에서 원시 요소가 다른 함수와 함께 나타날 때에만 일어난다는 결과를 관찰했다. 이 성공의 패턴은 이러한 유형의 모델들의 일반화가 그들의 훈련 데이터의 분포적 특성에 극도로 민감하다는 것을 나타낸다.

###### Blackbird Language Matrices Tasks for Generalization (https://aclanthology.org/2023.genbench-1.13/)
- Anthology ID: 2023.genbench-1.13 
- Volume: Proceedings of the 1st GenBench Workshop on (Benchmarking) Generalisation in NLP 
- Summary: 
    1. 인간과 유사한 언어 능력을 가진 시스템을 개발하기 위해서는 현재 시스템의 일반화 능력과 구성 능력을 이해해야 한다. 
    2. 우리는 시각 지능 테스트에서 영감을 받아 구성적이고 구조화된 데이터를 생성하여 이를 통해 문제 해결자들이 이미지 시퀀스에서 객체와 그들의 절대적 및 상대적 특성을 분리할 수 있는지 확인한다. 
    3. 우리는 프랑스어에서 주어-동사 일치와 영어에서 동사 교체를 모델링하는 두 가지 언어 현상에 대한 데이터셋을 제안하고, 이를 활용하여 LLM이 언어적 객체와 그들의 문법적 및 의미적 특성 등을 어떻게 인코딩하고 이를 조합하여 각 문제를 올바르게 해결하는지 조사할 수 있다.

###### In-Context Learning for Text Classification with Many Labels (https://aclanthology.org/2023.genbench-1.14/)
- Anthology ID: 2023.genbench-1.14 
- Volume: Proceedings of the 1st GenBench Workshop on (Benchmarking) Generalisation in NLP 
- Summary: 
    1. 다중 선택 문제(MCQ) 생성의 자동화는 교육자가 학습 평가에 소비하는 시간을 줄일 수 있는 잠재력이 있으나, 기존 평가 메트릭은 교육적 가치를 고려하지 않고 단어 유사성만을 측정한다.
    2. 이 논문에서는 Knowledge Dependent Answerability (KDA)라는 새로운 자동 평가 메트릭을 제안하여 MCQ의 대답 가능성을 측정하고 대상 사실에 대한 학생의 지식을 평가한다.
    3. KDA_disc와 KDA_cont는 실제 강의환경에서의 사용성과 강한 상관관계를 가지며, n-gram 기반 유사성 메트릭과 결합하면 다양한 MCQ 품질 지표를 강하게 예측할 수 있다.
    
    1. 최근 NLP 과제에서 딥 모델은 초인적인 정확도를 보이지만, 특정 패턴에 의존하여 강건성이 제한된다. 
    2. 이 논문에서는 대조 학습과 반사상 augmentation을 활용하여 강건성을 향상시키고자 한다.
    3. "집합적 의사 결정 (collective decisions)"을 통해 여러 개의 반사상을 합성하여 인과관계를 강건하게 감독할 수 있으며, 이로 인해 카우스와 적절한 분포를 바탕으로 향상된 결과를 얻을 수 있다.
    
    1. 많은 라벨을 가진 과제를 위해 큰 언어 모델을 사용한 "인컨텍스트 학습 (ICL)"은 제한된 문맥 창으로 인해 도전적이다.
    2. 이 논문에서는 사전 훈련된 밀집 검색 모델을 사용하여 이 제한을 우회하고 각 추론 호출마다 전체 라벨 공간의 부분적인 정보만 모델에 제공한다.
    3. 기존 모델에 비해 더 나은 성능을 나타내며, 인컨텍스트 예제 갯수와 모델 크기에 따른 성능을 분석하고, in-context 예제의 유사성, 클래스 이름의 의미적 내용, 예제와 라벨 간의 올바른 대응을 분석하였다.

###### GQG: Generalized Quantifier Generalization - A Dataset for Evaluating Quantifier Semantics Understanding in Language Models (https://aclanthology.org/2023.genbench-1.15/)
- Anthology ID: 2023.genbench-1.15 
- Volume: Proceedings of the 1st GenBench Workshop on (Benchmarking) Generalisation in NLP 
- Summary: 
    1. 본 논문은 언어 모델의 일반화 능력을 평가하기 위해 다양한 양화식들로 이루어진 새로운 데이터셋을 제안한다.
    2. 이 데이터셋은 다양한 양화식을 포함하고 있으며, 이 도메인에서 의미 이해를 평가하는 새로운 프레임워크를 형성한다.
    3. 제안된 데이터셋을 사용하여 4억1000만에서 69억까지의 Pythia 모델을 테스트한 결과, 현재의 언어 모델에게 양화식 기반 작업은 도전적임을 보여준다.

###### Cross-Lingual Data Augmentation For Thai Question-Answering (https://aclanthology.org/2023.genbench-1.16/)
- Anthology ID: 2023.genbench-1.16 
- Volume: Proceedings of the 1st GenBench Workshop on (Benchmarking) Generalisation in NLP 
- Summary: 
    1. 이 논문은 낮은 자원을 가진 언어 (특히 태국어)에서 Question Answering (QA) 모델의 견고성을 향상시키기 위해 설계된 데이터 품질 관리와 함께 혁신적인 데이터 확장 프레임워크를 제시한다.
    2. 훈련 데이터의 부족과 품질이라는 어려움을 인식하여, 우리는 단일 언어 및 교차 언어 환경에서 데이터 확장 기술을 활용한다.
    3. 우리의 접근 방식은 원래 데이터셋을 확장하고 향상시켜 언어적 다양성과 견고성을 높이며, 낮은 자원 언어 환경에서 훈련 데이터를 효과적으로 증가시키고 모델의 일반화를 향상시킬 수 있는 데이터 확장 방법의 잠재력을 실험적으로 입증한다. 이는 데이터 확장 분야에 대한 유망한 방향을 제시한다.

###### On using distribution-based compositionality assessment to evaluate compositional generalisation in machine translation (https://aclanthology.org/2023.genbench-1.17/)
- Anthology ID: 2023.genbench-1.17 
- Volume: Proceedings of the 1st GenBench Workshop on (Benchmarking) Generalisation in NLP 
- Summary: 
    1. NLP와 기계 학습에 적용된 Compositional generalisation(CG)은 대부분 인공 데이터셋을 사용하여 평가되었다. 이 논문에서는 실제 자연어 태스크에서 CG를 평가하기 위한 벤치마크를 개발하고자 한다. 
    2. DBCA(Distribution-based compositionality assessment) 프레임워크를 사용하여 Europarl 번역 코퍼스를 학습 데이터와 테스트 데이터로 분할하여 CG 능력이 필요한 테스트 세트를 만든다. 
    3. 이는 자연어 compositionality 벤치마크를 자동으로 생성하는 간단하고 비용 효율적인 방법으로, 다른 데이터셋과 언어에도 적용하기 쉽다.

###### Shifted PAUQ: Distribution shift in text-to-SQL (https://aclanthology.org/2023.genbench-1.18/)
- Anthology ID: 2023.genbench-1.18 
- Volume: Proceedings of the 1st GenBench Workshop on (Benchmarking) Generalisation in NLP 
- Summary: 
    1. Semantic parsing은 대규모 사용자-컴퓨터 상호작용의 접근성 향상에 중요한 역할을 한다. Spider 데이터셋과 그 개량버전인 PAUQ는 영어와 러시아어로 된 자연어 질문과 SQL 쿼리가 포함되어 있다. 이 논문에서는 제안된 스플릿을 사용하여 text2SQL 모델을 평가하고, 컴포지셔널리티와 다국어 일반화를 측정한다.
    2. 기존 Spider와 PAUQ 데이터셋은 독립적이고 동일한 분포를 가정한다. 이 논문에서는 타겟 길이 스플릿과 다국어 i.i.d 스플릿을 제안한다.
    3. 실험 결과와 컨텍스트-프리 문법을 통한 평가를 제시하고, 스플릿 데이터는 HuggingFace hub에서 공개되어 있다.

## Proceedings of the 4th Workshop on Computational Approaches to Historical Language Change
###### Proceedings of the 4th Workshop on Computational Approaches to Historical Language Change (https://aclanthology.org/2023.lchange-1.0/)
- Anthology ID: 2023.lchange-1.0 
- Volume: Proceedings of the 4th Workshop on Computational Approaches to Historical Language Change 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Literary Intertextual Semantic Change Detection: Application and Motivation for Evaluating Models on Small Corpora (https://aclanthology.org/2023.lchange-1.1/)
- Anthology ID: 2023.lchange-1.1 
- Volume: Proceedings of the 4th Workshop on Computational Approaches to Historical Language Change 
- Summary: 
    1. "Lexical semantic change detection은 단어의 의미변화를 연구하는 것인데, 일부 연구자들은 digital humanities와 같은 작은 corpus에 적용하기 위해 더 작은 데이터셋으로 평가할 필요가 있다."
    2. 저자들은 SemEval-2020 Task 1 corpus를 downsampling할 수 있는 방법과 코드 파이프라인을 제안한다. 
    3. 이 때 downsampling한 corpus로 학습된 state-of-the-art 모델들은 성능이 크게 저하되었고(high variance), 저자들은 semantic change detection이 digital humanities 분야에서도 유용하게 사용될 수 있다는 케이스 스터디를 제시한다.

###### Domain-Adapting BERT for Attributing Manuscript, Century and Region in Pre-Modern Slavic Texts (https://aclanthology.org/2023.lchange-1.2/)
- Anthology ID: 2023.lchange-1.2 
- Volume: Proceedings of the 4th Workshop on Computational Approaches to Historical Language Change 
- Summary: 
    1. 이 연구는 슬라브어 사전-현대어의 교차언어 및 단기 시기 분석을 위한 여섯 가지 다른 슬라브어 텍스트로 구성된 계층화된 데이터셋을 제공한다.
    2. 저자들은 저자유형, 세기, 복사 지역 분류를 위한 문헌출처 판별을 목적으로 이 낮은 자원의 역사적 슬라브어 변형에 대해 BERT의 무감독 도메인 적응과 지도학습으로 파인튜닝의 성능을 보여주었다.
    3. 저자들은 이 데이터셋을 도입하여 BERT 변형 모델의 활용 가능성을 조사하였고, 높은 F-스코어로 텍스트 스니펫의 시간, 지리, 문헌 출처를 판별할 수 있었다. 모델의 오분류에 대한 질적 분석도 수행되었다.

###### Representing and Computing Uncertainty in Phonological Reconstruction (https://aclanthology.org/2023.lchange-1.3/)
- Anthology ID: 2023.lchange-1.3 
- Volume: Proceedings of the 4th Workshop on Computational Approaches to Historical Language Change 
- Summary: 
    1. 역사 언어학의 재구성에는 불확실성이 내재적이지만, 대부분의 학자들은 프로토형을 제안할 때 불확실성을 나타내지 않는다.
    2. 최근 제안된 전통적인 비교 방법의 일부를 자동화하는 방법들이 성공적으로 적용되면서, 프로토형의 형식적 표현도 개선되었다.
    3. 이 논문에서는 지도된 음운 복구의 최근 발전에 기초하여, 언어학적 데이터에서 흐린 재구성을 계산하기 위한 새로운 프레임워크를 제안한다.

###### GHisBERT – Training BERT from scratch for lexical semantic investigations across historical German language stages (https://aclanthology.org/2023.lchange-1.4/)
- Anthology ID: 2023.lchange-1.4 
- Volume: Proceedings of the 4th Workshop on Computational Approaches to Historical Language Change 
- Summary: 
    1. 정적 임베딩은 기존에도 많이 사용되었지만, 최근에는 BERT와 같은 언어 모델을 활용하여 역사적 텍스트에서 의미 변화를 파악한다. 그러나 최근의 변화를 감지하는 데는 유용하지만 그 이전으로 갈수록 모델의 학습 데이터와 상당히 다른 언어의 변화를 파악하기엔 적합하지 않다.
    2. 이 논문에서는 독일어의 역사적 데이터를 사용하여 처음부터 훈련된 BERT 기반 언어 모델인 GHisBERT를 제안한다. 기존의 German BERT-base 모델과 비교해 보았을 때, GHisBERT 모델이 과거의 개념 간 유사성 및 시간이 지남에 따른 개념 내 유사성을 평가하는 면에서 가장 우수한 성능을 보여준다는 것을 실험 결과로 보여준다.
    3. 이는 역사적 언어 데이터 작업 시에는 역사적 언어 모델을 처음부터 사전 훈련하는 것이 필요하다는 것을 보여준다.

###### A longitudinal study about gradual changes in the Iranian Online Public Sphere pre and post of ‘Mahsa Moment’: Focusing on Twitter (https://aclanthology.org/2023.lchange-1.5/)
- Anthology ID: 2023.lchange-1.5 
- Volume: Proceedings of the 4th Workshop on Computational Approaches to Historical Language Change 
- Summary: 
    1. Mahsa Amini의 사망은 이란 사회에 큰 충격을 주었고, 그 후의 비극은 현실 공간 뿐만 아니라 트위터를 포함한 사이버 공간에서도 엄청난 영향을 미쳤다.
    2. 우리는 Mahsa Amini의 사망 이후 90일 동안 이란 사용자들의 감정을 분석하여 트위터가 어떻게 변화했는지 알아보고, 단어의 의미와 이웃하는 단어의 변화를 추적하였다.
    3. 마지막으로 우리는 단어 클러스터링 방법을 사용하여 주제 모델링을 수행하였다.

###### Political dogwhistles and community divergence in semantic change (https://aclanthology.org/2023.lchange-1.6/)
- Anthology ID: 2023.lchange-1.6 
- Volume: Proceedings of the 4th Workshop on Computational Approaches to Historical Language Change 
- Summary: 
    1. 본 연구에서는 정치적 도그휘슬이 언어 변화 측정을 통해 관찰될 수 있는지 테스트한다. 특히, 도그휘슬의 "숨겨진" 메시지가 시간이 지남에 따라 커뮤니티 간 의미 변화의 차이로 나타나는지 알아본다.
    2. 연구는 스웨덴어로 된 이민 논쟁과 관련된 스웨덴어 도그휘슬을 대상으로, 스웨덴어 커뮤니티 포럼인 Flashback과 Familjeliv 사이에서 시간에 따른 의미 변화의 속도 차이를 측정한다.
    3. 분석 결과, Flashback에서는 해당 기간 동안 의미 변화가 발생하지만 Familjeliv에서는 그렇지 않으며, 다양한 모델링 접근법도 커뮤니티 간 의미 변화에 민감하게 반응한다는 것을 확인하였다.

###### EvoSem: A database of polysemous cognate sets (https://aclanthology.org/2023.lchange-1.7/)
- Anthology ID: 2023.lchange-1.7 
- Volume: Proceedings of the 4th Workshop on Computational Approaches to Historical Language Change 
- Summary: 
    1. "다의어인 polysemies은 "colexifications"라고도 불리는데, 동일한 어휘로 표현되는 의미들은 개념적으로 유사하고 의미 변화의 공통 경로에 위치할 가능성이 높기 때문에 인지 및 역사 언어학에서 큰 관심을 받고 있다."
    2. 이 논문에서는 이러한 추론이 lexeme의 다의어보다는 cognate set의 다의어 (dialexifications)로부터 더 신뢰성 있게 제시될 수 있다고 주장한다.
    3. Evosem이라는 크로스-언어적 etymologies 데이터베이스를 소개하며, 이 데이터베이스를 기반으로 각각의 의미 쌍이 얼마나 자주 "dialexified"되는지 측정하여 개념적 및 역사적인 근접성을 나타내는 가중치 dialexification 그래프를 구축한다.

###### Multi-lect automatic detection of Swadesh list items from raw corpus data in East Slavic languages (https://aclanthology.org/2023.lchange-1.8/)
- Anthology ID: 2023.lchange-1.8 
- Volume: Proceedings of the 4th Workshop on Computational Approaches to Historical Language Change 
- Summary: 
    1. 본 논문은 Swadesh list 항목을 원시 말뭉치에서 자동으로 탐지하는 새로운 다중-강의 (multi-lect) 자연어처리 (NLP) 과제를 소개한다. 이 과제는 연구자가 추가 분석을 위해 단어 목록을 작성하는 고대 언어학 연구의 초기 단계를 돕는다.
    
    2. 본 논문에서는 동부 슬라브어 강의 (East Slavic lects) 데이터를 사용해 다중-강의 자동 탐지를 테스트한다. 훈련 데이터는 우크라이나어, 벨라루스어, 러시아어 자료로 구성되며, 훈련 시 데이터 증강 기법을 도입하여 탐색 대상의 이해를 높인다. 테스트 데이터는 고대 동부 슬라브어 텍스트로 구성된다.
    
    3. HMM, CRF, mBERT 모델을 훈련하고, harmonic F1 점수로 평가한다. 기준 모델은 Random Forest 분류자이다. 본 논문은 두 가지 다른 하위 과제를 소개하는데, 첫 번째 하위 과제는 새로운 Swadesh list 항목을 찾는 것으로 현재 기계 학습 방법에 거의 이길 수 없는 동시에 다양하고 모호한 Swadesh list의 특성으로 인해 도전적이다. 반면에 두 번째 하위 과제는 더 쉽고, mBERT 모델은 0.57의 F1 스코어를 달성한다. 이는 특정하고 테마가 다양한 개념 집합에 대한 토큰 소속을 형식화하기가 얼마나 어려운지를 고려할 때 인상적인 결과이다.

###### Anchors in Embedding Space: A Simple Concept Tracking Approach to Support Conceptual History Research (https://aclanthology.org/2023.lchange-1.9/)
- Anthology ID: 2023.lchange-1.9 
- Volume: Proceedings of the 4th Workshop on Computational Approaches to Historical Language Change 
- Summary: 
    1. 이 연구에서는 개념적인 연구를 지원하기 위해 간단한 개념 추적 방법을 소개한다.
    2. 사전을 사용하여 개념의 주요 의미 차원을 나타내는 "앵커"를 식별하고, 이러한 차원과 관련하여 특정 개념이 역사적인 말뭉치에서 시간이 지남에 따라 어떻게 변화하는지 보여주는 plot을 생성한다.
    3. COHA corpus에서 여러 개의 핵심 개념의 변화를 시각화하여 이 방법을 보여준다.

###### ChiWUG: A Graph-based Evaluation Dataset for Chinese Lexical Semantic Change Detection (https://aclanthology.org/2023.lchange-1.10/)
- Anthology ID: 2023.lchange-1.10 
- Volume: Proceedings of the 4th Workshop on Computational Approaches to Historical Language Change 
- Summary: 
    1. 최근 연구에서는 언어 모델이 어휘 의미 변화를 측정하는 데 효과적인 도구임을 제안했다.  
    2. 본 논문에서는 중국어의 의미 변화에 대한 그래프 기반 평가 데이터셋을 첫 번째로 제공한다.
    3. 기존의 프레임워크 DURel을 활용하여 40개의 대상에 대해 61,000개 이상의 인간의 의미 유사성 판단 결과를 수집하였다.

###### Towards Detecting Lexical Change of Hate Speech in Historical Data (https://aclanthology.org/2023.lchange-1.11/)
- Anthology ID: 2023.lchange-1.11 
- Volume: Proceedings of the 4th Workshop on Computational Approaches to Historical Language Change 
- Summary: 
    1. 언어 변화 연구는 특정 도메인 (예: 혐오 발언)에서의 변화를 감지하기에 적합하지 않은 것으로 알려져 왔다.
    2. 이 연구에서는 역사적 텍스트에서 혐오 발언과 관련된 어휘 의미의 변화를 식별하는 과제를 제시한다.
    3. NLP와 역사학을 결합한 접근 방식을 소개하며, 16세기 초기 근대 영어 종교 문학을 포함한 데이터셋과 어휘 의미 변화 및 혐오성에 대한 주석을 제공한다.

###### Changing usage of Low Saxon auxiliary and modal verbs (https://aclanthology.org/2023.lchange-1.12/)
- Anthology ID: 2023.lchange-1.12 
- Volume: Proceedings of the 4th Workshop on Computational Approaches to Historical Language Change 
- Summary: 
    1. 이 논문에서는 단어 벡터를 기반으로 독일과 네덜란드의 저지 독일어에서 부수적인 동사와 범용동사의 사용을 조사하고, 현대 언어의 변화를 중세 저지 독일어와 비교한다.
    2. 대부분의 기능어는 어휘 대체에 영향을 받지 않았지만, 주어진 언어와의 접촉으로 인한 사용 변화를 관찰할 수 있다.
    3. 주어진 상황에서 언어 동네마다 단어 사용의 진화를 분석하여, 시간의 흐름과 변화 동향을 이해하고 있다.

###### Semantic Shifts in Mental Health-Related Concepts (https://aclanthology.org/2023.lchange-1.13/)
- Anthology ID: 2023.lchange-1.13 
- Volume: Proceedings of the 4th Workshop on Computational Approaches to Historical Language Change 
- Summary: 
    1. 본 연구는 1970년부터 2016년까지의 시간적으로 선명하게 구분된 학술 및 일반 말뭉치에서 정신 건강 관련 개념의 의미 변화를 평가한다.
    2. 이 연구는 정신 건강 개념이 덜 심각한 현상을 포함하고 있을 뿐만 아니라, 병리학적인 내용과 더 관련이 있는지를 평가한다.
    3. 발견된 결과는 일부 정신 건강 개념들이 정상화되거나/병리화되었음을 보여주며, 이는 사회 및 문화적인 의의를 갖고 있다.

###### Automating Sound Change Prediction for Phylogenetic Inference: A Tukanoan Case Study (https://aclanthology.org/2023.lchange-1.14/)
- Anthology ID: 2023.lchange-1.14 
- Volume: Proceedings of the 4th Workshop on Computational Approaches to Historical Language Change 
- Summary: 
    1. 본 연구에서는 언어학적 계통학 추론을 자동화하는 새로운 방법을 제안한다. 기존에는 언어학 전문가가 필요한 부분을 신경망이 대체하여 음운 변화로부터 중간 음운 변화 단계를 예측할 수 있게 한다.
    2. 실험 결과에서는 전문가 주석을 사용한 방법보다 더 나은 성능을 보이며, Tukanoan 언어에서 평균화 주법거리 (Generalized Quartet Distance)가 0.12로 나타났다.
    3. 자동 음운법 추출을 위한 최소한의 일반화 학습자를 실험했으나, 전문가 주석보다 효과가 낮았다. 자신의 코드도 공개되어 있다.

###### Scent and Sensibility: Perception Shifts in the Olfactory Domain (https://aclanthology.org/2023.lchange-1.15/)
- Anthology ID: 2023.lchange-1.15 
- Volume: Proceedings of the 4th Workshop on Computational Approaches to Historical Language Change 
- Summary: 
    1. 본 연구에서는 특정 원천에서 방출되는 냄새의 설명이 시간이 지남에 따라 어떻게 변화했는지를 조사한다.
    2. 냄새 정보 추출 시스템을 사용하여 미리 정의된 냄새 원천 주변의 의미론적 역할을 표시하여 영어 텍스트 코퍼스를 라벨링한다.
    3. 분석 결과, 냄새 원천에 대한 특성을 설명하는 역할이 시간이 지남에 따라 어떻게 변화하는지와 어떻게 인지 변화를 특징짓는지를 통계적 접근과 비교하여 분석한다.

###### From Diachronic to Contextual Lexical Semantic Change: Introducing Semantic Difference Keywords (SDKs) for Discourse Studies (https://aclanthology.org/2023.lchange-1.16/)
- Anthology ID: 2023.lchange-1.16 
- Volume: Proceedings of the 4th Workshop on Computational Approaches to Historical Language Change 
- Summary: 
    1. 이 논문은 Semantic Difference Keywords (SDKs)라는 개념을 소개한다. SDK는 두 개 이상의 말뭉치에서 사용되는 의미적 차이가 상대적으로 높은 키워드로 정의된다. 
    2. 이들은 시간적 어휘 의미 변화를 식별하는 데 사용되는 방법을 적용하여 추출되며, 통계 키워드와 유사하게 대상 말뭉치의 독특성을 포착한다.
    3. SDK는 의미적 다툼의 부분인 적용 개념들을 식별하는 데 성공하였으며, 이는 (컴퓨터를 이용한) 토의 연구 및 텍스트 기반의 디지털 인문학에 유용한 기여라고 할 수 있다.

## Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL)
###### Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) (https://aclanthology.org/2023.mrl-1.0/)
- Anthology ID: 2023.mrl-1.0 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### UniBriVL: Robust Audio Representation and Generation of Audio Driven Diffusion Models (https://aclanthology.org/2023.mrl-1.1/)
- Anthology ID: 2023.mrl-1.1 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Meta-learning For Vision-and-language Cross-lingual Transfer (https://aclanthology.org/2023.mrl-1.2/)
- Anthology ID: 2023.mrl-1.2 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Counterfactually Probing Language Identity in Multilingual Models (https://aclanthology.org/2023.mrl-1.3/)
- Anthology ID: 2023.mrl-1.3 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### A General-Purpose Multilingual Document Encoder (https://aclanthology.org/2023.mrl-1.4/)
- Anthology ID: 2023.mrl-1.4 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Zero-Shot Cross-Lingual Sentiment Classification under Distribution Shift: an Exploratory Study (https://aclanthology.org/2023.mrl-1.5/)
- Anthology ID: 2023.mrl-1.5 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### To token or not to token: A Comparative Study of Text Representations for Cross-Lingual Transfer (https://aclanthology.org/2023.mrl-1.6/)
- Anthology ID: 2023.mrl-1.6 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Adapt and Prune Strategy for Multilingual Speech Foundational Model on Low-resourced Languages (https://aclanthology.org/2023.mrl-1.7/)
- Anthology ID: 2023.mrl-1.7 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Multilingual Word Embeddings for Low-Resource Languages using Anchors and a Chain of Related Languages (https://aclanthology.org/2023.mrl-1.8/)
- Anthology ID: 2023.mrl-1.8 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### TalaMT: Multilingual Machine Translation for Cabécar-Bribri-Spanish (https://aclanthology.org/2023.mrl-1.9/)
- Anthology ID: 2023.mrl-1.9 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Mergen: The First Manchu-Korean Machine Translation Model Trained on Augmented Data (https://aclanthology.org/2023.mrl-1.10/)
- Anthology ID: 2023.mrl-1.10 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Improving Cross-Lingual Transfer for Open Information Extraction with Linguistic Feature Projection (https://aclanthology.org/2023.mrl-1.11/)
- Anthology ID: 2023.mrl-1.11 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Geographic and Geopolitical Biases of Language Models (https://aclanthology.org/2023.mrl-1.12/)
- Anthology ID: 2023.mrl-1.12 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Task-Based MoE for Multitask Multilingual Machine Translation (https://aclanthology.org/2023.mrl-1.13/)
- Anthology ID: 2023.mrl-1.13 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Does the English Matter? Elicit Cross-lingual Abilities of Large Language Models (https://aclanthology.org/2023.mrl-1.14/)
- Anthology ID: 2023.mrl-1.14 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### CAPIVARA: Cost-Efficient Approach for Improving Multilingual CLIP Performance on Low-Resource Languages (https://aclanthology.org/2023.mrl-1.15/)
- Anthology ID: 2023.mrl-1.15 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Code-switching as a cross-lingual Training Signal: an Example with Unsupervised Bilingual Embedding (https://aclanthology.org/2023.mrl-1.16/)
- Anthology ID: 2023.mrl-1.16 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Learning to translate by learning to communicate (https://aclanthology.org/2023.mrl-1.17/)
- Anthology ID: 2023.mrl-1.17 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Contrastive Learning for Universal Zero-Shot NLI with Cross-Lingual Sentence Embeddings (https://aclanthology.org/2023.mrl-1.18/)
- Anthology ID: 2023.mrl-1.18 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### UD-MULTIGENRE – a UD-Based Dataset Enriched with Instance-Level Genre Annotations (https://aclanthology.org/2023.mrl-1.19/)
- Anthology ID: 2023.mrl-1.19 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Embedding Structure Matters: Comparing Methods to Adapt Multilingual Vocabularies to New Languages (https://aclanthology.org/2023.mrl-1.20/)
- Anthology ID: 2023.mrl-1.20 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Multi-EuP: The Multilingual European Parliament Dataset for Analysis of Bias in Information Retrieval (https://aclanthology.org/2023.mrl-1.21/)
- Anthology ID: 2023.mrl-1.21 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Generating Continuations in Multilingual Idiomatic Contexts (https://aclanthology.org/2023.mrl-1.22/)
- Anthology ID: 2023.mrl-1.22 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### CUNI Submission to MRL 2023 Shared Task on Multi-lingual Multi-task Information Retrieval (https://aclanthology.org/2023.mrl-1.23/)
- Anthology ID: 2023.mrl-1.23 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Findings of the 1st Shared Task on Multi-lingual Multi-task Information Retrieval at MRL 2023 (https://aclanthology.org/2023.mrl-1.24/)
- Anthology ID: 2023.mrl-1.24 
- Volume: Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL) 
- Summary: 
    요약문을 생성할 수 없습니다.

## Proceedings of the 4th New Frontiers in Summarization Workshop
###### Proceedings of the 4th New Frontiers in Summarization Workshop (https://aclanthology.org/2023.newsum-1.0/)
- Anthology ID: 2023.newsum-1.0 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Is ChatGPT a Good NLG Evaluator? A Preliminary Study (https://aclanthology.org/2023.newsum-1.1/)
- Anthology ID: 2023.newsum-1.1 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Summary: 
    1. 최근에는 ChatGPT의 등장으로 컴퓨터 언어학 커뮤니티에서 많은 관심을 받고 있다. 하지만 ChatGPT가 평가 지표로 사용될 수 있는 능력은 아직 탐구되지 않았다. 이 논문에서는 ChatGPT를 자연어 생성 모델(NLG)의 평가 지표로 사용하기 위한 메타-평가를 수행하였다. 
    2. ChatGPT를 사람의 판단자로 간주하여 NLG 모델의 생성 결과를 평가하도록 유도하고, NLG 메타-평가 데이터셋에 대한 실험 결과를 보여준다. 결과는 이전의 자동 평가 메트릭과 비교하여 대부분에서 사람의 판단과 상당한 상관관계를 가지고 있음을 보여준다.
    3. 그러나 ChatGPT 평가자의 효과는 메타-평가 데이터셋의 생성 방법에 따라 영향을 받을 수 있다. 레퍼런스에 크게 의존하여 편향된 메타-평가 데이터셋의 경우에는 ChatGPT 평가자의 효과가 떨어질 수 있다.

###### Zero-Shot Cross-Lingual Summarization via Large Language Models (https://aclanthology.org/2023.newsum-1.2/)
- Anthology ID: 2023.newsum-1.2 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Summary: 
    1. 소스 언어로 된 문서가 주어졌을 때, 크로스-리지널 요약(CLS)은 다른 대상 언어로 요약문을 생성하는 것을 목표로 한다. 
    2. 이 논문에서는 다양한 프롬프트를 사용하여 대형 언어 모델 (LLM)이 다른 패러다임 (end-to-end 및 pipeline)으로 제로샷 CLS를 수행하는 데 어떻게 활용될 수 있는지를 실험적으로 평가한다.
    3. 실험 결과, ChatGPT와 GPT-4는 원래 자세한 정보가 포함된 긴 요약문을 생성하는 경향이 있지만, 상호작용적인 프롬프트의 도움으로 정보성과 간결성을 균형있게 조절하여 CLS 성능을 크게 향상시킬 수 있다는 것을 보여준다.

###### SimCSum: Joint Learning of Simplification and Cross-lingual Summarization for Cross-lingual Science Journalism (https://aclanthology.org/2023.newsum-1.3/)
- Anthology ID: 2023.newsum-1.3 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Summary: 
    1. 최근에 소개된 Cross-lingual science journalism은 비전문가 독자를 위해 원본 언어와 다른 언어로 과학 기사를 요약하는 작업이다.
    2. 기존의 파이프라인 모델은 텍스트 간략화와 크로스-리지날 summarization을 결합하여 이 작업을 수행했으나, 우리는 멀티 태스크 학습 아키텍처를 도입하여 이 작업을 확장한다.
    3. 우리의 접근 방식은 우리가 제안한 SimCSum에서 크로스-리지날 popular science summary를 생성하기 위해 두 가지 NLP tasks를 공동으로 훈련하는 것이다.

###### Extract, Select and Rewrite: A Modular Sentence Summarization Method (https://aclanthology.org/2023.newsum-1.4/)
- Anthology ID: 2023.newsum-1.4 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Summary: 
    1. 모듈식 접근법은 대부분의 end-to-end 모델과 비교했을 때 합성 가능성과 제어 가능성이 있다는 장점을 가지고 있다.
    2. 본 논문에서는 Extract-Select-Rewrite (ESR)라는 세 단계의 추상적 문장 요약 방법을 제안한다.
    3. ESR은 요약을 세 단계로 분해하여 지식 추출, 내용 선택, 그리고 재작성으로 나누고, 최고 수준의 end-to-end 모델과 비교하여 경쟁력을 보이면서 보다 충실한 결과를 얻을 수 있다.

###### Summarization-based Data Augmentation for Document Classification (https://aclanthology.org/2023.newsum-1.5/)
- Anthology ID: 2023.newsum-1.5 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Summary: 
    1. 사전학습 언어 모델은 일반적인 자연어 이해 작업에서 널리 쓰이지만, 긴 글 (document)과 같은 텍스트를 이해하는 것은 데이터 희소성의 문제로 여전히 어렵다고 할 수 있다.
    2. 우리는 사람들이 짧은 텍스트를 읽고 긴 텍스트를 이해하는 능력을 개발하는 것에서 영감을 받아, document 분류를 위한 간단하고 효과적인 요약 기반 데이터 증강 (data augmentation)인 SUMMaug를 제안한다.
    3. 우리는 우리의 방법이 강건성과 정확성 측면에서 기존 기준선 방법들과 비교하여 이점을 확인하기 위해 두 데이터셋에서의 실험 결과를 발표하며, 코드와 데이터를 공개한다.

###### In-context Learning of Large Language Models for Controlled Dialogue Summarization: A Holistic Benchmark and Empirical Analysis (https://aclanthology.org/2023.newsum-1.6/)
- Anthology ID: 2023.newsum-1.6 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Summary: 
    1. 대규모 언어 모델 (LLM)은 요약 및 제어 텍스트 생성을 포함한 다양한 NLP 작업에서 뛰어난 성능을 보였다. 그 중 하나인 in-context learning (ICL)은 모델이 파라미터 업데이트 없이 prompt의 입력-출력 쌍을 사용하여 새로운 작업을 학습하는 기능이다.
    2. 그러나 LLM의 few-shot 요약 대화 요약에서의 성능은 아직 충분히 탐구되지 않았다. 이 연구는 SAMSum 데이터셋을 기반으로 다양한 최신 LLM 모델을 few-shot framework에서 평가한다.
    3. 우리는 제어된 설정 (엔티티 제어, 길이 제어, 인물 중심 계획)과 제어되지 않은 설정에서 이러한 모델을 평가하고, few-shot 대화 요약에 대한 포괄적인 벤치마크를 제시한다.

###### From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting (https://aclanthology.org/2023.newsum-1.7/)
- Anthology ID: 2023.newsum-1.7 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Summary: 
    1. 요약문 작성에서 적절한 정보의 양을 선택하는 것은 어려운 일이다. 좋은 요약문은 세부적이고 개체 중심적인데 너무 밀집되어 이해하기 어렵지 않아야 한다. 
    2. 이 논문에서는 "밀도 체인"(CoD) 프롬프트를 사용하여 GPT-4 요약문의 밀도 변화에 대해 더 잘 이해하고자 한다. GPT-4는 길이를 늘리지 않고 빠진 중요한 개체를 점차 포함시키는 과정을 통해 요약문을 생성한다.
    3. 100개의 뉴스 기사에 대한 인간 선호도 조사 결과, GPT-4 요약문 중 CoD를 사용한 요약문이 기존 요약문보다 더 밀집되며, 사람이 작성한 요약문과 거의 비슷한 선호도를 보였다. 인과관계 및 가독성 사이에는 트레이드오프가 존재한다는 것을 질적 분석을 통해 확인하였다.

###### Generating Extractive and Abstractive Summaries in Parallel from Scientific Articles Incorporating Citing Statements (https://aclanthology.org/2023.newsum-1.8/)
- Anthology ID: 2023.newsum-1.8 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Summary: 
    1. 모든 과학 논문에 대한 요약은 문서의 내용에만 초점을 맞추고, 인용 논문의 통찰력을 간과하기 쉽다. 
    2. 우리는 소스 및 인용 문서의 정보를 활용하여 과학 문서를 요약하는 모델을 개발했다. 
    3. 이 모델은 추상적 및 추출적 요약을 동시에 생성하며, 각각이 다른 요약 기법을 보완하여 고품질 요약을 만든다.

###### Supervising the Centroid Baseline for Extractive Multi-Document Summarization (https://aclanthology.org/2023.newsum-1.9/)
- Anthology ID: 2023.newsum-1.9 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Summary: 
    1. Centroid 방법은 extractive multi-document summarization을 위한 간단한 접근 방식이지만, 문장 선택에 beam search 과정을 추가하고 centroid estimation attention 모델을 도입하여 결과를 향상시켰다.
    2. 이를 여러 개의 multi-document summarization 데이터셋에서 증명하였고, 다국어 시나리오에서도 적용할 수 있는 것을 보였다.

###### DebateKG – Automatic Policy Debate Case Creation with Semantic Knowledge Graphs (https://aclanthology.org/2023.newsum-1.10/)
- Anthology ID: 2023.newsum-1.10 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Summary: 
    1. 최근 연구에서는 논쟁 분야에서 발견된 문제를 해결하기 위해 자연어처리 시스템의 적용 가능성을 보여주고 있다. 이 연구에서는 "Policy Debate"라는 유형의 경쟁 토론에서 경쟁자들이 고품질 토론 주제를 만드는 작업에 대해 조사하고 있다.
    2. 우리는 인수적 의미 지식 그래프를 사용하여 제약 최단 경로 탐색을 통해 효과적인 토론 주제를 구축할 수 있다는 것을 보여주었다.
    3. 또한, 우리는 "DebateSum"이라고 불리는 대규모 데이터셋을 보완하여 53180개의 새로운 예제와 각각의 예제에 대한 추가적인 메타데이터를 도입하였다.

###### Unsupervised Opinion Summarization Using Approximate Geodesics (https://aclanthology.org/2023.newsum-1.11/)
- Anthology ID: 2023.newsum-1.11 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Summary: 
    1. 의견 요약은 사용자 리뷰에서 인기있는 의견을 요약하는 작업이며, 이 논문에서는 GeoSumm이라는 새로운 시스템을 소개한다. GeoSumm은 의견 요약을 수행하기 위한 encoder-decoder 기반의 표현 학습 모델로, 토피컬 표현을 생성하여 텍스트의 기저 의미를 포착한다.
    2. GeoSumm은 사전 훈련된 텍스트 표현의 여러 계층에서 사전 학습을 통해 토피컬 표현을 생성하고, 이를 사용하여 신규 거리 기반 점수화 메커니즘을 통해 리뷰 문장의 중요성을 측정한다.
    3. GeoSumm은 일반적이고 측면별 요약을 구성하기 위해 중요도 점수를 사용하며, 3개의 의견 요약 데이터셋에서 강력한 성능을 달성한다. 추가 실험을 통해 모델의 기능을 분석하고, GeoSumm의 도메인 간 일반화 능력을 보여준다.

###### Analyzing Multi-Sentence Aggregation in Abstractive Summarization via the Shapley Value (https://aclanthology.org/2023.newsum-1.12/)
- Anthology ID: 2023.newsum-1.12 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Summary: 
    1. 개요 요약 시스템은 입력 문서의 가장 핵심적인 정보를 자기 말로 간결하게 요약하는 것을 목표로 한다. 이를 위해 여러 정보 조각을 모아 결합하는 과정, aggregation이 필요하다. 그러나 기존에는 벤치마크 데이터셋의 참조 요약과 시스템 생성 요약이 얼마나 aggregation을 필요로 하는지 알 수 없다.
    2. 이 논문에서는 AggSHAP라는 aggregation 정도를 측정하기 위한 지표를 제안한다. 그리고 자동 및 인간 평가를 통해 AggSHAP가 여러 문장을 모으는 작업을 단문 추출이나 단문 재구성과 구분할 수 있다는 것을 보여준다. 
    3. 참조나 모델 생성 요약에서 AggSHAP에 기반한 aggregation 정도가 높은 문장은 매우 적다는 것을 발견했으며, 또한 AggSHAP와 다른 요약 품질 점수와의 음의 상관관계도 보였다. 이러한 결과는 요약에서 여러 문장 aggregation을 촉진하는 새로운 작업과 데이터셋을 개발해야 한다는 필요성을 시사한다.

###### Improving Multi-Stage Long Document Summarization with Enhanced Coarse Summarizer (https://aclanthology.org/2023.newsum-1.13/)
- Anthology ID: 2023.newsum-1.13 
- Volume: Proceedings of the 4th New Frontiers in Summarization Workshop 
- Summary: 
    1. "다단계 장문 요약은 긴 문서를 여러 세그먼트로 나누고 각 세그먼트를 사용하여 다단계로 일반적인 요약을 생성하는 유연한 접근 방식이다." 
    2. "기존의 다단계 요약에서 코스 요약기는 최종 요약을 생성하는 데 유용하지 않은 데이터 세그먼트로 미세하게 훈련된다." 
    3. "본 논문에서는 최종 요약 생성에 필요한 관련 세그먼트로만 새로운 세그먼트 쌍을 생성하고 대조 학습을 통해 미세 요약 모델을 훈련하는 새로운 다단계 장문 요약 방법을 제안한다."

## Proceedings of the Workshop on Novel Ideas in Learning-to-Learn through Interaction (NILLI 2023)
###### Proceedings of the Workshop on Novel Ideas in Learning-to-Learn through Interaction (NILLI 2023) (https://aclanthology.org/2023.nilli-1.0/)
- Anthology ID: 2023.nilli-1.0 
- Volume: Proceedings of the Workshop on Novel Ideas in Learning-to-Learn through Interaction (NILLI 2023) 
- Summary: 
    요약문을 생성할 수 없습니다.

## Proceedings of the Natural Legal Language Processing Workshop 2023
###### Proceedings of the Natural Legal Language Processing Workshop 2023 (https://aclanthology.org/2023.nllp-1.0/)
- Anthology ID: 2023.nllp-1.0 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Anthropomorphization of AI: Opportunities and Risks (https://aclanthology.org/2023.nllp-1.1/)
- Anthology ID: 2023.nllp-1.1 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. 인간형화(Anthropomorphization)는 인간과 비인간 사물에 인간과 같은 특성을 돌리는 경향이다. 
    2. 이 논문에서는 대규모 언어 모델(Large Language Model, LLMs)을 사용하여 사용자의 인간형화 경향과 이에 따른 법적 문제, 심리적 측면을 탐구한다. 
    3. 실험 결과, 인간형화된 LLMs은 사용자에게 영향력을 미치고, 인간-인공지능 상호작용의 본질을 근본적으로 변화시켜서 조작과 부정적 영향을 줄 수 있다는 것을 알 수 있다. 이에 따라 우리는 신뢰성 향상을 위해 인간형화 사용에 대한 보수적인 전략을 제안한다.

###### NOMOS: Navigating Obligation Mining in Official Statutes (https://aclanthology.org/2023.nllp-1.2/)
- Anthology ID: 2023.nllp-1.2 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. 법적 텍스트에서 의무 사항을 식별하는 것은 직관적인 작업이 아니다. 법적 문서는 길고 문장도 길기 때문이다. 이 논문은 기계와 딥러닝 접근법을 사용하여 의무 사항을 식별하는 문제를 다룬다.
    2. NOMOS라는 새로운 방법론을 제안하여 Positional Embeddings (PE)와 Temporal Convolutional Networks (TCNs)를 결합하여 의무 사항을 식별한다.
    3. 법적 규정에 대한 양적, 질적 실험을 통해 제안된 방법의 효과를 입증한다.

###### Long Text Classification using Transformers with Paragraph Selection Strategies (https://aclanthology.org/2023.nllp-1.3/)
- Anthology ID: 2023.nllp-1.3 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. 법적 분야에서는 법원 판결과 같이 아주 긴 문서에 대한 분류 작업을 자주 수행하지만, 이러한 문서들은 수천 개의 단어를 포함하고 있기 때문에 모델링 작업에 도전을 제기한다.
    2. 저자들은 Transformers와 전통적인 NLP 모델을 사용하여 문서 청크를 선택하는 전략을 결합하여 긴 텍스트 분류를 수행하는 다양한 전략을 철저히 평가한다.
    3. 저자들은 RoBERTa, Longformer, HAT, MEGA, LegalBERT와 같은 최신 Transformer 모델을 평가하고, 기존의 기준이 되는 TF-IDF + Neural Network (NN) 모델과 비교하여 대용량 말뭉치에서 사전 훈련, 파인 튜닝 전략 및 전이 학습 기술의 효과성을 조사한다.

###### Do Language Models Learn about Legal Entity Types during Pretraining? (https://aclanthology.org/2023.nllp-1.4/)
- Anthology ID: 2023.nllp-1.4 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. Language Model (LM)은 다운스트림 태스크에서 부수적인 감독(supervision)을 제공할 수 있으나, 법률 문서와 같은 특정 도메인에 특화된 지식을 검색하는 연구는 제한적이다.
    2. 우리는 Entity Typing 태스크를 통해 법률 지식을 평가하는 프록시로 사용하여, 다양한 유형과 길이의 Entity, 일반적이고 도메인 특화된 Entity, 의미와 구문 신호, LM 사전학습 코퍼스와 아키텍처를 비교한다.
    3. 실험 결과, 특정 Entity에서 Llama2가 잘 수행되며, 최적화된 프롬프트 템플릿으로 큰 개선이 가능함을 보여준다. 법률 지향 LM은 일관된 성능이 나오지 않으며, Llama2는 문법적 신호를 자주 무시하는 경향이 있다.

###### Pretrained Language Models v. Court Ruling Predictions: A Case Study on a Small Dataset of French Court of Appeal Rulings (https://aclanthology.org/2023.nllp-1.5/)
- Anthology ID: 2023.nllp-1.5 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. 법률 도메인에서 NLP 시스템이 법적 기관 또는 산업에서 점점 더 많이 사용되고 있어 그 강점과 약점을 특성화하고 내부 작동 방식을 이해하는 것이 절박하다. 
    2. 이 연구는 프랑스 압수법원에서 작은 데이터셋을 사용하여 판결 예측 작업에 대한 사례 연구를 제시한다. 
    3. 프랑스의 사전 훈련된 언어 모델(Flaubert, JuriBERT)을 기반으로한 분류기조차도 합리적인 정확성으로 판별하지 못하는 것으로 나타났다. 하지만 입력에 결정이 포함되어 있을 때에는 결정을 추출할 수 있다. 이러한 결과를 바탕으로 법적 NLP 데이터셋을 자동으로 구성할 때 강한 경고가 있다고 주장한다.

###### Italian Legislative Text Classification for Gazzetta Ufficiale (https://aclanthology.org/2023.nllp-1.6/)
- Anthology ID: 2023.nllp-1.6 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. 이 연구는 이탈리아의 입법 텍스트에 대한 다중 라벨 분류를 위한 혁신적이고 포괄적인 주석이 달린 말뭉치를 소개한다. 이 말뭉치는 이탈리아 국가의 공식 입법 정보인 Gazzetta Ufficiale에서 가져온 법적 행위들을 기반으로 한다.
    2. 주석이 달린 데이터셋은 1988년부터 2022년까지 30년간의 363,000개 이상의 입법 행위 제목을 포함한다.
    3. 또한, 우리는 이 데이터셋에서 텍스트 분류를 위한 네 가지 모델을 평가하였으며, 제목만을 사용하여 대단원 수준의 분류 성능을 달성할 수 있으며, 마이크로 F1-점수는 0.87이다. 우리의 분석은 이탈리아 도메인 적응 법률 모델이 일반 목적 모델에 비해 더 나은 성능을 발휘하지 않음을 보여준다.

###### Mixed-domain Language Modeling for Processing Long Legal Documents (https://aclanthology.org/2023.nllp-1.7/)
- Anthology ID: 2023.nllp-1.7 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. 최근 법과 같은 특정 도메인에 자연어 처리(NLP)를 적용하는 관심이 증가하고 있다. 그러나 대부분의 언어 모델은 법적 용어와 문법에 제한된 추론 능력을 갖거나 비용이 높은 모델이다.
    2. 이 논문에서는 법적 손해배상 텍스트에 특화된 언어 모델인 LEGALRELECTRA를 제안한다. 이 모델은 법적과 의료분야 코퍼스를 합쳐 훈련시켜 성능을 개선시켰다.
    3. 이 모델은 ELECTRA 프레임워크를 사용하되 BERT 대신 REFORMER를 활용하여 긴 텍스트의 처리와 이해력을 향상시켰다.

###### Questions about Contracts: Prompt Templates for Structured Answer Generation (https://aclanthology.org/2023.nllp-1.8/)
- Anthology ID: 2023.nllp-1.8 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. 계약서의 특정 조항에 대한 법적 질문의 답을 찾는 것은 법적 워크플로우에서 중요한 분석이다. 이 논문에서는 대규모 언어 모델을 사용하여 법적 질문에 (부분적으로) 구조화된 답을 만드는 것에 대한 조사를 제시한다.
    2. 기존의 의미 일치 방법은 이 작업을 원하는 정확도로 수행할 수 없음을 보여주며, 질문 특정 프롬프트가 생성 모델의 다양한 범위에서 합리적인 정확도를 달성하는 방법을 보여준다.
    3. 마지막으로, 질문 특정 프롬프트 대신 일반화된 프롬프트 템플릿을 사용할 경우 이 효과의 대부분을 유지할 수 있음을 보여준다.

###### Legal Judgment Prediction: If You Are Going to Do It, Do It Right (https://aclanthology.org/2023.nllp-1.9/)
- Anthology ID: 2023.nllp-1.9 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. Legal Judgment Prediction (LJP) 연구 분야에서는 최근 10년 동안 큰 성장이 있었지만, 150개 이상의 논문 조사 결과, 발표된 논문들 중에서는 법원 판결을 예측하는 것만 약 7%에 불과하다는 사실이 드러났다.
    2. 이 연구는 예측 실험의 결함과 신뢰성이 떨어지는 이유를 살펴보며, 법률 분야에서의 유용성이 제한되는 것을 강조한다.
    3. 이를 해결하기 위해, 이 논문에서는 작업에 적합한 데이터 사용, 설명 가능성 다루기, 모델 보고 및 평가에 응용 중심적 접근법 채택을 강조하는 "LJP를 올바르게 수행하기 위한 실용적 체크리스트"를 제공한다.

###### Beyond The Text: Analysis of Privacy Statements through Syntactic and Semantic Role Labeling (https://aclanthology.org/2023.nllp-1.10/)
- Anthology ID: 2023.nllp-1.10 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. 본 논문은 "Contextual Integrity"이라는 사회 이론 프레임워크를 통해 개인정보 정책에서 개인정보 파라미터를 추출하는 새로운 과제를 정의한다.
    2. CI 기반 도메인 특화 지식을 BERT 기반 SRL 모델에 통합하면 최고의 정밀도와 재현율을 달성하여 F1 점수가 84%가 나타난다.
    3. 이 연구를 통해 개인정보 분야에 대한 NLP 애플리케이션 구축에 대한 새로운 연구를 독려하고자 한다.

###### Towards Mitigating Perceived Unfairness in Contracts from a Non-Legal Stakeholder’s Perspective (https://aclanthology.org/2023.nllp-1.11/)
- Anthology ID: 2023.nllp-1.11 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. 상업 계약서는 프로젝트 특정 요구사항을 유도하기 위한 귀중한 자료로 알려져 있으나, 계약 협상은 주로 관련 당사자의 법률 자문사들 사이에서 이루어진다. 이 방법으로서 여러 측면에서 부정적으로 보일 수 있다. 
    2. 이 논문에서는 이런 계약 중에서 비공정한(clauses) 점들을 식별하는 중요성을 제시한다.
    3. 사전 훈련된 언어 모델(PLMs)을 사용하여 계약 문장에서 비공정성을 식별하고, BERT 기반 fine-tuning을 사용하여 재산권 계약으로 구성된 데이터셋에서 84%의 정확도를 달성했다고 보고하고 있다.

###### Connecting Symbolic Statutory Reasoning with Legal Information Extraction (https://aclanthology.org/2023.nllp-1.12/)
- Anthology ID: 2023.nllp-1.12 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. 법률 추론은 지정된 법률(법의 일부분)이 특정 법적 사례에 적용되는지 여부를 결정하는 작업이다. 이전 연구에서는 구조화된 논리적 표현을 사용하여 법률 추론을 수행할 수 있음을 보였으나, 비용이 많이 드는 인간의 구조화 작업에 의존한다.
    2. 본 논문에서는 SARA 사례 위에 법률 정보 추출을 수행하는 방법을 알아보고, 이 작업을 높은 성능으로 수행할 수 있다는 것을 보여준다. 
    3. 또한, 후속 기호적 추론의 성능은 정보 추출의 품질과 직접적으로 상관관계가 있음을 보여준다.

###### Retrieval-based Evaluation for LLMs: A Case Study in Korean Legal QA (https://aclanthology.org/2023.nllp-1.13/)
- Anthology ID: 2023.nllp-1.13 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. 대규모 언어 모델(LLM)은 텍스트 생성에서 상당한 능력을 보여주었으나, 법률과 같은 도메인 특화 전문성이 요구되는 분야에서의 활용은 신중히 접근해야 한다.
    2. 이 논문에서는 Eval-RAG라는 새로운 LLM 생성 텍스트 평가 방법을 제안한다. Eval-RAG는 기존 방법과 달리, retriever에서 수집한 관련 문서를 기반으로 생성된 텍스트의 타당성을 평가한다.
    3. 실험 결과, Eval-RAG를 사용하면 기존의 LLM 기반 평가 방법이 Lawyer의 평가와 더욱 일치할 수 있음을 보였으며, 기존 평가 방법으로는 찾을 수 없었던 사실적 오류를 성공적으로 발견할 수 있다는 것을 정성적인 분석을 통해 확인하였다.

###### Legal NLP Meets MiCAR: Advancing the Analysis of Crypto White Papers (https://aclanthology.org/2023.nllp-1.14/)
- Anthology ID: 2023.nllp-1.14 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. 암호자산 시장에서 화이트 페이퍼(white paper)는 투자자 안내에 필수적인 문서이다. 이 논문에서는 이러한 화이트 페이퍼를 분석하고 규제 준수를 돕기 위해 자연어 처리(NLP)를 활용하는 방법에 대해 다루고 있다.
    2. 먼저, 비규제 암호자산 화이트 페이퍼에 대한 텍스트 분석의 기존 응용 사례를 조사하고, 다양한 학문 분야의 협업을 통해 이를 연결할 수 있는 연구 간극을 찾았다.
    3. 그런 다음, MiCAR(Markets in Crypto-Assets Regulation)에 의해 도입된 변경 사항을 분석하여 NLP를 새로운 규제 프레임워크에 통합하는데 있어서의 기회와 도전점을 강조하였다. 이 연구 결과는 규제 기관, 암호자산 발행자 및 투자자들에게 혜택을 제공할 수 있는 잠재적인 연구를 위한 기반이 마련되었다.

###### Low-Resource Deontic Modality Classification in EU Legislation (https://aclanthology.org/2023.nllp-1.15/)
- Anthology ID: 2023.nllp-1.15 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. 법에는 의무, 허가, 금지, 권리, 권한과 같은 카테고리, 즉 deontic modalities를 구별하는 것이 중요하다. 이 논문에서는 LEGAL-BERT와 Fusion 모델이 저자의 저자들의 낮은 리소스 환경에서 deontic modality를 분류하는 성능을 평가한다.
    2. 유럽 연합(EU) 법안에서 무작위 조항을 추출하여 다중 클래스 분류를 위한 일반화된 데이터셋을 만들었다.
    3. 실험 결과, 저자들의 저작으로 디자인된 데이터셋에서 fusion 모델이 더 좋은 성능을 보여주며, class imbalance 문제를 해결하기 위해 focal loss를 적용하면 더욱 향상된다는 것을 보여준다.

###### Automatic Anonymization of Swiss Federal Supreme Court Rulings (https://aclanthology.org/2023.nllp-1.16/)
- Anthology ID: 2023.nllp-1.16 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. 법원 결정문의 공개는 관련된 당사자들을 보호하기 위해 적절한 익명화에 의존한다. 스위스 연방 최고법원은 기존의 컴퓨터 기반 방법과 인간 전문가를 결합한 시스템을 사용하고 있다.
    2. 본 논문에서는 개체를 익명화해야할 대규모 데이터셋을 활용하여 기존의 익명화 소프트웨어를 개선한다. BERT 기반 모델과 도메인 내 데이터로 사전 훈련된 모델을 비교하였다.
    3. 결과적으로, 도메인 내 데이터를 사용하여 모델을 사전 훈련하면 F1-스코어가 기존 모델에 비해 5% 이상 향상된다는 것을 보여준다. 기존 정규식과 머신러닝을 결합하면 수동 작업을 더욱 줄이고 자동 제안을 향상시킬 수 있다는 것을 본 논문에서 입증하였다.

###### Exploration of Open Large Language Models for eDiscovery (https://aclanthology.org/2023.nllp-1.17/)
- Anthology ID: 2023.nllp-1.17 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. 최근의 대형언어모델(LLMs)은 다양한 자연어처리(NLP) 작업에 광범위하게 활용되고 있으나, 전자 발견(eDiscovery)의 기술 지원 검토(TAR) 과정은 인공지능 도구들에 대한 교육과 세부 조정이 필요하다. 이 연구에서는 LLMs의 TAR에의 적용을 탐색하고 예측 코딩의 성능 개선을 위해 특정 주제에 대한 지시 연구를 수행하였다. 
    2. 실험결과, 상업적으로 사용 가능한 LLMs와 비교해 out-of-the-box 발화 방식에서는 LLMs의 성능이 상대적으로 뒤쳐지지만, 특정 주제에 대한 지시 연구를 통해 LLMs의 효과적인 성능 개선 및 인간이 작성한 추론에 유사한 고품질 추론을 생성할 수 있다는 것을 보였다.
    3. 또한 eDiscovery의 전문가들의 사용자 연구를 통해, instruction-tuned open LLMs가 상업적 LLMs와 비교해 마찬가지로 높은 품질의 추론을 생성할 수 있다는 것을 확인하였다.

###### Retrieval-Augmented Chain-of-Thought in Semi-structured Domains (https://aclanthology.org/2023.nllp-1.18/)
- Anthology ID: 2023.nllp-1.18 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. 기존의 질문 응답(QA) 시스템을 법률과 금융과 같은 전문 분야에 적용하는 것은 도메인 전문 지식이 필요한 문제로, 이에 대한 도전이 존재한다.
    2. 일반적인 언어 모델들은 문맥 안에서 긴 입력을 처리하는 능력이 제한되어 있다.
    3. 이 연구에서는 법률과 금융 데이터의 반구조적 성격을 이용하여 관련 문맥을 효율적으로 검색하는 방법을 탐구하고, 도메인 전문화 QA를 위해 언어 모델을 사용하는 결과를 제시한다.

###### Joint Learning for Legal Text Retrieval and Textual Entailment: Leveraging the Relationship between Relevancy and Affirmation (https://aclanthology.org/2023.nllp-1.19/)
- Anthology ID: 2023.nllp-1.19 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. 법률 텍스트 처리 및 추론에서는 일반적으로 입력 질문의 관련 문서를 찾기 위해 정보 검색을 수행하고, 그런 다음 텍스트 결론을 이끌어내기 위해 텍스트 입증을 수행한다. 
    2. 우리는 복수의 상호 지원 관계를 최대로 활용하기 위해 이러한 두 가지 작업에 대한 다중 작업 학습 모델을 제안한다. 
    3. COLIEE 데이터셋에서 의제 4의 정보 (결론)을 사용하여 의제 3 (질문과 관련된 법적 규정을 검색)의 성능을 향상시킨다는 것을 실험적으로 확인했다.

###### Super-SCOTUS: A multi-sourced dataset for the Supreme Court of the US (https://aclanthology.org/2023.nllp-1.20/)
- Anthology ID: 2023.nllp-1.20 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. 미국 대법원의 복잡성을 고려할 때, 다양한 절차와 자원이 법원 시스템에 기여하지만, 대부분의 연구는 특정 관점 (partisanship 또는 voting) 에서 법원을 분석할 때, 법원 의견이나 구술 논쟁과 같은 제한된 자원에 초점을 맞추고 있다.
    2. 미국 대법원의 법적 시스템에서 이러한 관점을 더 잘 이해하기 위해서는 다양한 소스를 다양한 절차 단계에서 연결하는 보다 포괄적인 데이터셋이 필요하다.
    3. 우리는 법원 소스를 다양한 절차적 단계에서 언어 문서와 상세한 메타데이터와 연결하는 multi-sourced dataset을 제공하며, 서로 다른 법원 문서가 사건의 결정 방향 (보수적 vs. 진보적) 을 어떻게 나타내는지에 대한 사례 연구를 통해 이 데이터셋의 유용성을 보여준다.

###### Transferring Legal Natural Language Inference Model from a US State to Another: What Makes It So Hard? (https://aclanthology.org/2023.nllp-1.21/)
- Anthology ID: 2023.nllp-1.21 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. 이 연구는 한 미국 주의 데이터로 훈련된 법률 자연어 추론(NLI) 모델이 다른 주로 이전될 수 있는지 조사한다. 이 논문에서는 테네시 주 유언장 데이터셋과 아이다호 주 유언장 데이터셋을 사용하여 사전 훈련된 모델을 미세조정하고, 동일 주와 다른 주에서의 모델 성능을 비교한다. 모델을 다른 주로 전이할 수 있다는 것을 발견했지만, 도메인 외 데이터에서의 모델 성능 저하도 확인되었다.
    2. 테네시 주 모델과 아이다호 주 모델의 F1 점수는 동일한 주의 데이터를 예측할 때 각각 96.41과 92.03이다. 하지만 다른 주의 데이터를 예측할 때는 각각 66.32와 81.60으로 점수가 떨어진다. 오류 분석 결과, 두 가지 주요 오류 원인이 밝혀졌다. 첫째, 모델은 법률 간 단어 스타일 차이가 있는 경우 동등한 법률을 인식하지 못한다. 둘째, 주간 법 조문 번호 체계의 차이로 인해 모델이 예측 대상 사건과 관련된 법률을 찾기 어렵다.
    3. 이 분석은 향후 NLI 시스템의 개선 방향을 제시한다. 또한, 법률 전문가가 법률 문서의 표준화를 주장하는데 이 연구 결과는 실증적인 지원을 제공한다.

###### Large Language Models are legal but they are not: Making the case for a powerful LegalLLM (https://aclanthology.org/2023.nllp-1.22/)
- Anthology ID: 2023.nllp-1.22 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. 최근 자연어 처리(NLP) 분야의 발전을 법률 분야에 적용하는 것은 매우 긴 시퀀스 길이, 법률 전문가만 이해할 수 있는 특수 어휘, 데이터 불균형 등과 같은 어려운 문제를 가지고 있다.
    2. 우리는 일반 LLM(대형 언어 모델)과 법률 분야 모델의 성능을 비교하여 어떻게 일반 LLM이 법률 분야에서 수행하는지 평가하고자 한다.
    3. 법적 데이터에 명시적으로 학습되지 않았음에도 불구하고, LLM들은 대부분의 경우 테마를 올바르게 분류할 수 있는 능력을 가지고 있지만, 법률 분야에 세부적으로 학습된 작은 모델과 비교했을 때 mic-F1/mac-F1 성능이 19.2/26.8% 낮아지는 것을 발견하여 보다 강력한 법률 분야 LLM의 필요성을 강조한다.

###### On the Potential and Limitations of Few-Shot In-Context Learning to Generate Metamorphic Specifications for Tax Preparation Software (https://aclanthology.org/2023.nllp-1.23/)
- Anthology ID: 2023.nllp-1.23 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. 미국의 소득세 법률이 점점 더 복잡해지면서, 소득세 신고에 택스 소프트웨어가 이용되는 사람들의 수도 증가하고 있다. 이 논문에서는 소프트웨어의 정확성을 보장하기 위해 메타모르피즘 테스팅을 사용하여 법적으로 중요한 세금 소프트웨어를 테스트하는 방법을 제시한다.
    2. 메타모르피즘 테스팅은 시스템의 성질을 하나의 입력과 약간 변형된 쌍둥이 입력 사이의 관계로 표현하는 것이다.
    3. 이 논문에서는 세금 문서에서 추출된 성질을 자연어로 표현된 대비적 일차 논리 형태로 번역하는 과제를 기계 번역 태스크로 제시한다.
    
    (Note: The term "tax software" can be translated as "세금 소프트웨어" for consistency with the previous sentence, although "tax preparation software" is more accurate)

###### AsyLex: A Dataset for Legal Language Processing of Refugee Claims (https://aclanthology.org/2023.nllp-1.24/)
- Anthology ID: 2023.nllp-1.24 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. 최근 자연어 처리(NLP)와 언어 모델의 발전은 법률 분야에서 자동 분석과 이해를 가능하게 하여 법적 텍스트에 사용되는 머신러닝 모델의 개발에 큰 잠재력을 보여주었다. 그러나 법률 NLP의 강건한 모델 개발은 데이터 부족으로 인해 큰 도전을 겪고 있다.
    2. 본 논문은 이런 이슈를 해결하기 위해 특히 난민법에 적용될 수 있는 AsyLex 데이터셋을 제시한다. 이 데이터셋은 1996년부터 2022년까지의 캐나다 난민 신분 결정에 관련된 59,112개의 문서를 포함하고 있으며, 법률 연구와 사례 리뷰를 위한 NLP 모델의 훈련과 평가에 필요한 중요한 자료를 제공한다.
    3. 이 데이터셋은 사례 리뷰의 entity 추출과 결과 예측 작업을 위해 19,115개의 골드 표준 인간 레이블 애너테이션과 1,682개의 사례 결과에 대한 골드 표준 레이블이 포함되어 있다. 법률 전문가의 도움을 받아 20개의 법적으로 관련된 entity 유형을 선별하였다.

###### A Comparative Study of Prompting Strategies for Legal Text Classification (https://aclanthology.org/2023.nllp-1.25/)
- Anthology ID: 2023.nllp-1.25 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. 이 연구에서는 다양한 prompt engineering 접근 방식을 사용하여 법적 텍스트 분류에서 대형 언어 모델 (LLMs)의 성능을 탐색한다.
    2. 이전 연구는 다양한 prompt 기법이 LLMs가 수행하는 다양한 작업의 성능을 향상시킬 수 있다는 것을 입증했다. 그러나 이 연구에서는 전문 문서, 특히 법률 문서가 LLMs에게 독특한 도전 과제를 제시한다.
    3. 우리는 여러 LLM과 zero/few-shot prompting, prompt ensembling, chain-of-thought, activation fine-tuning과 같은 다양한 prompt 기법을 실험하고 법적 데이터셋에서의 성능을 비교한다. 그러나 법적 도메인의 복잡성인 긴 문서와 도메인 특정 언어와 같은 이유로 모든 prompting 접근 방식과 모델이 법적 도메인에 적합하지 않을 수 있다는 결과를 발견하였다.

###### Tracing Influence at Scale: A Contrastive Learning Approach to Linking Public Comments and Regulator Responses (https://aclanthology.org/2023.nllp-1.26/)
- Anthology ID: 2023.nllp-1.26 
- Volume: Proceedings of the Natural Legal Language Processing Workshop 2023 
- Summary: 
    1. 미국 연방 규제기관은 매년 100만 건이 넘는 사업체, 이해단체, 일반인으로부터 제안된 규제에 대한 의견서를 받으며, 이러한 의견은 공공 정책에 큰 영향을 미친다고 알려져 있다. 그러나 규제기관은 어떤 의견에 대해 응답해야하지만 어떤 의견에 대해 응답하는지 구체적으로 명시할 필요는 없기 때문에, 특정 의견의 영향을 측정하는 것은 어렵다.
    2. 우리는 이 문제에 대해 간단하면서도 효과적인 해결책을 제안한다. 규제기관이 쓴 응답과 대중의 의견서 텍스트를 매칭하기 위해 반복적 contrastive 방법을 사용하여 신경망 모델을 훈련시킨다.
    3. 우리의 제안은 인간이 주석을 달아준 테스트 셋에서 일련의 텍스트 매칭 베이스라인보다 큰 성능을 보여주며, 가장 강력한 언어모델인 GPT-4와 비교했을 때 비용 효율성을 가지고 더 큰 규모의 의견과 규제자의 의견 매칭을 처리한다.

## Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023)
###### Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) (https://aclanthology.org/2023.nlposs-1.0/)
- Anthology ID: 2023.nlposs-1.0 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### calamanCy: A Tagalog Natural Language Processing Toolkit (https://aclanthology.org/2023.nlposs-1.1/)
- Anthology ID: 2023.nlposs-1.1 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. calamanCy는 spaCy를 기반으로한 Tagalog 자연어 처리 (NLP) 파이프라인을 구축하기 위한 오픈 소스 툴킷이다. 
    2. calamanCy는 의존 파싱, 품사 태깅, 개체명 인식과 같은 작업을 위한 general-purpose multitask 모델을 제공하여 NLP 애플리케이션 개발에 일관된 API를 제공한다. 
    3. calamanCy는 분리된 자원을 통합된 프레임워크로 통합하고자 하며 Tagalog NLP의 발전을 가속화하기 위해 공개되었다.

###### Jina Embeddings: A Novel Set of High-Performance Sentence Embedding Models (https://aclanthology.org/2023.nlposs-1.2/)
- Anthology ID: 2023.nlposs-1.2 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. Jina Embeddings는 텍스트로부터 의미를 캡처하는 수치적 표현으로 변환하는 고성능 문장 임베딩 모델 세트이다. 
    2. 이 논문에서는 Jina Embeddings의 개발 과정을 상세히 설명하며, 데이터 클리닝, 모델 훈련 프로세스 등에 대한 통찰력을 제공하고, Massive Text Embedding Benchmark (MTEB)을 사용하여 종합적인 성능 평가를 수행한다. 
    3. 또한, 문법적 부정에 대한 모델의 인식을 향상시키기 위해 부정된 문장과 부정되지 않은 문장으로 구성된 독창적인 훈련 및 평가 데이터셋을 구축하였다.

###### Deepparse : An Extendable, and Fine-Tunable State-Of-The-Art Library for Parsing Multinational Street Addresses (https://aclanthology.org/2023.nlposs-1.3/)
- Anthology ID: 2023.nlposs-1.3 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 주소 구분을 위한 파서 (address parsing)는 record linkage부터 geocoding과 package delivery까지 많은 응용 분야에서 필수적인 과정으로 여겨진다.
    2. 본 논문에서는 Deepparse라 불리는 오픈소스 파서를 소개하며, 이 파서는 최첨단 딥러닝 알고리즘을 사용하여 다국적 주소를 파싱하는 기능을 제공한다. 
    3. 미리 학습된 모델은 평균 99%의 정확도를 보이며, 새로운 데이터 fine-tuning을 지원하여 사용자 정의 주소 파서를 생성할 수 있다.

###### PyThaiNLP: Thai Natural Language Processing in Python (https://aclanthology.org/2023.nlposs-1.4/)
- Anthology ID: 2023.nlposs-1.4 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. PyThaiNLP는 파이썬으로 구현된 태국어 자연어 처리(NLP) 라이브러리로, 태국어에 대한 다양한 소프트웨어, 모델, 데이터셋을 제공한다. 
    2. PyThaiNLP의 기능, 데이터셋, 사전 훈련된 언어 모델에 대해 간략히 소개하고, 개발 이전의 태국어 도구에 대한 역사적 문맥을 설명한다. 
    3. 산업 및 연구 커뮤니티에서 PyThaiNLP를 어떻게 활용하는지를 설명하고, 해당 라이브러리를 https://github.com/pythainlp/pythainlp에서 무료로 사용할 수 있다고 마무리한다.

###### Empowering Knowledge Discovery from Scientific Literature: A novel approach to Research Artifact Analysis (https://aclanthology.org/2023.nlposs-1.5/)
- Anthology ID: 2023.nlposs-1.5 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 다양한 연구 분야에서 투명성, 재현성, 혁신을 촉진하기 위해 과학 문헌으로부터 지식을 추출하는 것은 주요한 문제이다.
    2. 이 논문에서는 과학 문헌 내의 데이터셋과 코드/소프트웨어 언급을 식별, 추출 및 분석하기 위한 혁신적인 접근 방식을 제시한다.
    3. ChatGPT를 사용하여 합성된 데이터셋을 소개하고, 인간 중심 프로세스를 통해 실제 과학 텍스트 조각을 사용하여 철저히 만들고 보강하고 확장했다.

###### Zelda Rose: a tool for hassle-free training of transformer models (https://aclanthology.org/2023.nlposs-1.6/)
- Anthology ID: 2023.nlposs-1.6 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. Zelda Rose는 명령 줄 인터페이스로, transformer 기반 모델의 사전 훈련을 위한 것이다. 
    2. 이 도구는 사용자가 더 포괄적이면서도 복잡한 프레임워크와 라이브러리 간의 복잡한 상호작용과 관련 없이 간편하게 모델을 훈련할 수 있도록 한다. 
    3. 또한 유지 보수 비용을 낮추기 위해 코드를 모듈화하고 제3자 라이브러리를 활용하여 ad-hoc 코드를 최소한으로 유지하는 것에 중점을 둔다.

###### GPT4All: An Ecosystem of Open Source Compressed Language Models (https://aclanthology.org/2023.nlposs-1.7/)
- Anthology ID: 2023.nlposs-1.7 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 최근 많은 언어 모델은 전문적이고 학문적인 기준에서 사람 수준의 성능을 보이지만, 이러한 모델에 대한 접근성은 성능에 미치지 못하고 있다.
    2. 이 논문은 GPT4All이라는 인기있는 오픈 소스 저장소를 통해 LLM에 대한 접근성을 더욱 폭넓게 하기 위한 기술적인 세부 사항과 프로젝트의 변화에 대해 설명한다.
    3. 이 논문은 GPT4All 모델과 오픈 소스 생태계의 성장을 기술적으로 개괄하면서 GPT4All이 개방형 생태계로 성장한 사례 연구로서의 역할을 수행하기를 희망한다.

###### Kani: A Lightweight and Highly Hackable Framework for Building Language Model Applications (https://aclanthology.org/2023.nlposs-1.8/)
- Anthology ID: 2023.nlposs-1.8 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 언어 모델 응용 프로그램은 점점 인기가 있고 복잡해지고 있지만, 기존의 프레임워크는 개발자들이 프롬프트를 어떻게 포맷팅해야 하는지를 결정하고 사용자 정의성과 재현성을 제한하는 경향이 있다.
    2. Kani는 언어 모델 응용 프로그램을 구축하기 위한 가볍고 유연하며 모델에 구애받지 않는 오픈소스 프레임워크를 제공한다.
    3. Kani는 개발자들이 모델과 상호 작용, 채팅 관리, 강력한 함수 호출을 위한 핵심 기능을 구현하는 데 도움이 되며, 사용자 정의 기능을 할 수 있도록 함으로써 개발자들에게 개발을 가속화하면서 상호 운용성과 세밀한 제어를 유지할 수 있는 유용한 도구로 제공된다.

###### Beyond the Repo: A Case Study on Open Source Integration with GECToR (https://aclanthology.org/2023.nlposs-1.9/)
- Anthology ID: 2023.nlposs-1.9 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 저희는 교육평가서비스의 제품과 프로토타입에 사용되는 NLP 파이프라인에 오픈 소스 GECToR 코드와 모델을 통합하는 노력을 서술한 사례 연구를 제시합니다. 
    2. 이 논문에서는 통합 과정에서 마주친 문제들과 우리의 해결책, 오픈 소스 프로젝트 통합에 대한 교훈, 그리고 여정의 일환으로 만든 오픈 소스 기여에 대해 논의하고 있습니다.

###### Two Decades of the ACL Anthology: Development, Impact, and Open Challenges (https://aclanthology.org/2023.nlposs-1.10/)
- Anthology ID: 2023.nlposs-1.10 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. ACL Anthology는 컴퓨터 언어학과 NLP의 연구 논문을 위한 주요 자원으로, 개방 소스와 커뮤니티 주도형 프로젝트로 유지되고 있다. Anthology는 Gildea 등의 논문(2018)을 기반으로한 상태 및 계획 방향성을 보고한 이후, 주요한 기술적인 변경이 이루어졌다.
    2. 우리는 이러한 변경사항이 장기적인 유지 관리성과 커뮤니티 참여에 어떤 영향을 미쳤는지에 대해 논의하며, Anthology가 현재 제공하는 오픈 소스 데이터와 소프트웨어 도구를 설명하고, Anthology를 주요 데이터 원천으로 사용한 문헌 조사를 제공한다.

###### nanoT5: Fast & Simple Pre-training and Fine-tuning of T5 Models with Limited Resources (https://aclanthology.org/2023.nlposs-1.11/)
- Anthology ID: 2023.nlposs-1.11 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. T5와 같은 최신 언어 모델은 NLP 분야에 혁명적인 영향을 끼치지만, 그 계산 요구량 때문에 연구 커뮤니티의 많은 부분에 제한을 가하고 있다.
    2. nanoT5는 T5 모델의 효율적인 사전 훈련과 세밀 조정을 위한 특별히 최적화된 PyTorch framework 로 이러한 도전에 대응하고 있다.
    3. nanoT5를 통해 T5-Base 모델은 성능의 손실 없이 단 한 개의 GPU에서 16시간만에 사전 훈련이 가능하며, 이 오픈 소스 프레임워크를 통해 언어 모델링 연구의 접근성을 넓히고 사용자 친화적인 T5 (Encoder-Decoder) 구현에 대한 커뮤니티의 요구에 부응하길 희망한다.

###### AWARE-TEXT: An Android Package for Mobile Phone Based Text Collection and On-Device Processing (https://aclanthology.org/2023.nlposs-1.12/)
- Anthology ID: 2023.nlposs-1.12 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. AWARE-text 패키지는 안드로이드 모바일 기기에서 텍스트 데이터를 수집하기 위한 오픈 소스 소프트웨어 패키지를 제공한다.
    2. 이 패키지는 raw 데이터 수집 외에도 표준 텍스트 기반 측정치를 수집할 수 있도록 설계되었으며, 이는 민감하고 식별 가능한 정보를 포함할 수 있는 모바일 폰의 경우 특히 중요하다.
    3. AWARE-text 패키지는 개인(평생 SMS 히스토리), 대화(SMS 대화 및 그룹 채팅의 양쪽), 메시지(단일 SMS), 문자(애플리케이션 전체에서 입력 된 개별 키 스트로크)의 다양한 상호작용 수준에서 개인 정보를 보호하는 동시에 텍스트 정보를 수집할 수 있다.

###### SOTASTREAM: A Streaming Approach to Machine Translation Training (https://aclanthology.org/2023.nlposs-1.13/)
- Anthology ID: 2023.nlposs-1.13 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 기계 번역 도구의 데이터 준비과정은 트레이너가 직접 사용할 수있는 텐서 형식으로 원시 데이터를 변환하는 단계를 포함하는데, 이러한 처리 단계는 일반적인 훈련 시간 요구 사항 (예 : 서브워드 샘플링)을 어렵게 만든다.
    2. 본 논문에서는 데이터 생성과 데이터 사용을 분리하는 대안적인 접근 방식을 제안한다. 데이터 생성은 원시 훈련 데이터의 무한한 순열 스트림을 생성하고, 트레이너는 이를 텐서로 변환하여 사용한다.
    3. 이러한 데이터 스트림은 데이터 정규화, 증강 또는 필터링과 같은 사용자 정의 연산자에 의해 실시간으로 수정될 수 있으며, 이러한 접근 방식은 훈련 시간을 단축시키고 유연성을 높이며 실험 관리 복잡성을 감소시키고 디스크 공간을 줄이면서 훈련된 모델의 정확성에 영향을주지 않는다.

###### An Open-source Web-based Application for Development of Resources and Technologies in Underresourced Languages (https://aclanthology.org/2023.nlposs-1.14/)
- Anthology ID: 2023.nlposs-1.14 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 이 논문에서는 Linguistic Field Data Management and Analysis System (LiFE)이라는 새로운 오픈소스 웹 기반 소프트웨어에 대해 논의한다. 이 시스템은 현장에서 수집한 언어 데이터와 YouTube, Twitter, Facebook, Instagram, 블로그, 신문, 위키백과 등 다양한 웹 소스에서 크롤링한 데이터를 체계적으로 저장, 관리, 주석 달기, 분석 및 공유할 수 있게 해준다.
    2. 이 소프트웨어는 현장 언어학자의 작업 흐름과 컴퓨터 언어학자의 작업 흐름을 지원하며, 다양한 작업을 위해 데이터를 수집하고 주석을 달고 언어 기술을 개발하는 데 사용할 수 있다.
    3. 이 외에도 다중 사용자가 유연한 접근 제어와 공유 옵션을 통해 동일한 프로젝트에서 협업 작업을 수행할 수 있고, 다양한 형식으로 데이터를 내보내거나 가져오는 등의 기능을 제공한다.

###### Rumour Detection in the Wild: A Browser Extension for Twitter (https://aclanthology.org/2023.nlposs-1.15/)
- Anthology ID: 2023.nlposs-1.15 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 소셜 미디어 상에서의 소문 감지는 최근에 인기를 끌게 되었고, 기계 학습 커뮤니티에서는 이러한 플랫폼에서 소문을 자동으로 탐지하기 위한 방법을 조사하는 데 많은 기여를 하였다. 그러나 이러한 SoTA 모델은 소셜 미디어 회사에서 배포되기 때문에 일반 사용자는 자신의 소문 탐지에 이 논문의 솔루션을 활용할 수 없다.
    2. 이 문제를 해결하기 위해 우리는 사용자가 Twitter에서 소문 감지를 수행할 수 있는 새로운 브라우저 익스텐션을 제안한다. 특히, 이전에는 SoTA 아키텍처의 성능을 활용하지 않았다.
    3. 사용자 연구에서 초기 결과는이 브라우저 익스텐션이 혜택을 제공한다는 것을 확인하였다. 또한, 우리의 브라우저 익스텐션의 소문 감지 모델의 성능을 시뮬레이션 배포 환경에서 조사하였다. 결과적으로, 브라우저 익스텐션을 안정적으로 대규모의 Twitter 사용자에게 배포하기 위해 추가 인프라가 필요하다는 것을 보여주었다.

###### DeepZensols: A Deep Learning Natural Language Processing Framework for Experimentation and Reproducibility (https://aclanthology.org/2023.nlposs-1.16/)
- Anthology ID: 2023.nlposs-1.16 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 기계 학습 실험 재현의 중요성과 어려움을 고려하여 결과의 분산을 줄이는 노력이 크게 진행되고 있다.
    2. 이 논문의 기여는 일관된 결과 재현을 용이하게 하는 오픈 소스 프레임워크를 제안한다.
    3. 이 프레임워크는 기능과 임베딩의 hot-swapping을 허용하며, 데이터셋을 추가로 처리하고 재벡터화하지 않고도 자연어 처리 딥러닝 모델을 쉽게 만들고 훈련 및 평가할 수 있게 해준다.

###### Improving NER Research Workflows with SeqScore (https://aclanthology.org/2023.nlposs-1.17/)
- Anthology ID: 2023.nlposs-1.17 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. SeqScore는 명명된 개체 인식(Named Entity Recognition, NER) 데이터 작업을 위한 Python 도구로, NER 스코어링을 돕는 도구로 시작되었으나, 이제는 NER 데이터 전체 생명주기에 도움을 주는 기능을 가지고 있다.
    2. SeqScore는 주석의 유효성을 검증하고 데이터의 요약 및 상세 정보를 제공하며 실험을 지원하기 위해 주석을 수정하고 시스템 출력을 스코어링하며 오류 분석을 돕는다.
    3. SeqScore는 PyPI를 통해 배포되며(https://pypi.org/project/seqscore/), 개발은 GitHub에서 진행된다(https://github.com/bltlab/seqscore).

###### torchdistill Meets Hugging Face Libraries for Reproducible, Coding-Free Deep Learning Studies: A Case Study on NLP (https://aclanthology.org/2023.nlposs-1.18/)
- Anthology ID: 2023.nlposs-1.18 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 최근 심층학습의 발전으로 지원받는 기계학습, 자연어처리, 컴퓨터 비전 등의 연구 커뮤니티에서는 과학적인 작업의 재현성이 점점 중요해지고 있다.
    2. 이 논문에서는 초기 버전에서 주로 이미지 분류와 객체 감지 작업을 지원하던 torchdistill을 업그레이드하여 다른 태스크를 지원하는 모듈화된 코드없이 심층학습 프레임워크를 제안한다.
    3. 업그레이드된 torchdistill을 기반으로 한 스크립트를 사용하여 BERT 모델의 GLUE 벤치마크 결과를 재현하고, Hugging Face 라이브러리와 조화를 이루며 다양한 태스크를 지원할 수 있음을 보여준다.

###### Using Captum to Explain Generative Language Models (https://aclanthology.org/2023.nlposs-1.19/)
- Anthology ID: 2023.nlposs-1.19 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. Captum은 PyTorch에서 모델 설명성을 위한 포괄적인 라이브러리로, 사용자가 PyTorch 모델을 이해하는 데 도움이 되는 다양한 방법을 제공한다.
    2. 본 논문에서는 Captum에 generative language model의 동작을 분석하기 위해 특별히 설계된 새로운 기능을 소개한다.
    3. 우리는 이용 가능한 기능들과 generative language model 내에서 학습된 연관성을 이해하는 데 있어서의 잠재력을 보여주는 예시 응용 프로그램을 제공한다.

###### nerblackbox: A High-level Library for Named Entity Recognition in Python (https://aclanthology.org/2023.nlposs-1.20/)
- Anthology ID: 2023.nlposs-1.20 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. nerblackbox는 transformer 기반의 최신 모델을 사용하여 named entity recognition 작업을 쉽게 할 수 있도록 돕는 파이썬 라이브러리이다. 
    2. 다양한 소스로부터 데이터와 모델에 액세스할 수 있으며, 완전히 자동화된 모델 훈련과 평가 및 다양한 모델 추론을 위한 강력한 방법을 제공한다.
    3. 응용 프로그램 개발자와 기계 학습 전문가 및 연구자를 대상으로하며, 사용자에게는 기본적으로 숨겨진 기술적 도전 과제를 해결하면서도 세밀한 제어와 사용자 지정 가능한 기능을 제공한다.

###### News Signals: An NLP Library for Text and Time Series (https://aclanthology.org/2023.nlposs-1.21/)
- Anthology ID: 2023.nlposs-1.21 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. "우리는 입력이 텍스트 데이터 클러스터이고 출력이 하나 이상의 시계열 신호로 표현된 데이터셋을 만들고 사용할 수 있는 오픈 소스 Python 라이브러리를 제안한다.
    2. news-signals 라이브러리는 텍스트 데이터 피드를 사용하여 시계열 동작을 예측하는 다양한 데이터 과학 및 NLP 문제 설정을 지원한다. 이는 예를 들어, 뉴스 도메인에서는 특정 개체에 대한 하루 동안의 뉴스 기사에 해당하는 문서 클러스터가 입력되고, 대상은 특정 인물 또는 회사에 대한 뉴스 양 또는 특정 위키미디어 페이지의 페이지 뷰 수와 같은 실수 값 시계열과 명시적으로 연결된다.
    3. 이러한 문제 설정에 대한 많은 산업 및 연구 사용 사례가 있음에도 불구하고, News Signals는 우리의 지식으로는 자연어 입력과 시계열 대상을 사용하는 데이터 과학 및 연구 설정을 효과적으로 지원하기 위해 특별히 설계된 유일한 오픈 소스 라이브러리이다."

###### PyTAIL: An Open Source Tool for Interactive and Incremental Learning of NLP Models with Human in the Loop for Online Data (https://aclanthology.org/2023.nlposs-1.22/)
- Anthology ID: 2023.nlposs-1.22 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 온라인 데이터 스트림은 시간이 지남에 따라 분포 변화와 새로운 패턴이 발생하기 때문에 기계 학습 모델을 학습시키기 어렵다. 특히 룰과 어휘에 기반한 NLP 태스크에서는 이러한 기능을 변화하는 데이터에 적응시키는 것이 중요하다.
    2. 이 논문에서는 PyTAIL이라는 파이썬 라이브러리를 소개하며, NLP 모델을 적극적으로 훈련시키는 사람을 포함한 접근 방식을 제안한다.
    3. PyTAIL은 새로운 인스턴스를 레이블링하는 것뿐만 아니라 룰과 어휘와 같은 새로운 기능을 레이블링하기도 함께 제안하며, 훈련 중에 사용자가 룰과 어휘를 수용, 거부 또는 업데이트할 수 있는 유연성을 가지고 있다.

###### Antarlekhaka: A Comprehensive Tool for Multi-task Natural Language Annotation (https://aclanthology.org/2023.nlposs-1.23/)
- Anthology ID: 2023.nlposs-1.23 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. NLP 기술의 낮은 자원 언어(low-resource language)에 대한 발전에 있어 가장 큰 장애물 중 하나는 기계 학습 모델을 훈련 및 테스트하기 위한 주석이 달린 데이터셋 부족이다.
    2. 우리는 Antarlekhaka라는 NLP와 관련된 포괄적인 과제에 대한 수동 주석 도구를 소개한다. 이 도구는 유니코드 호환, 언어 독립적, 웹 배포 가능하며 동시에 여러 주석자들에 의해 주석을 동시에 수행할 수 있다.
    3. Antarlekhaka는 자연어 처리 작업 중 가장 중요한 작업인 문장 경계 감지와 텍스트의 시적인 형태를 위한 단어 순서 결정 등을 포함하는 8가지 유형의 작업에 대한 사용자 친화적인 인터페이스를 제공한다.

###### GPTCache: An Open-Source Semantic Cache for LLM Applications Enabling Faster Answers and Cost Savings (https://aclanthology.org/2023.nlposs-1.24/)
- Anthology ID: 2023.nlposs-1.24 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. ChatGPT와 같은 대형 언어 모델의 API를 호출하는 것은 오랜 시간이 걸릴 수 있고, peak 시간에는 응답 속도가 느려져 개발자들 사이에서 불만을 일으킬 수 있다.
    2. GPTCache는 LLM 응답을 저장하는 세마틱 캐시로, 응용 프로그램이 GPTCache와 통합되면 사용자 쿼리가 ChatGPT와 같은 LLM에 전송되기 전에 먼저 GPTCache에 보내져서 캐시에 답이 있다면 LLM에 다시 쿼리하지 않아도 빠르게 답을 제공할 수 있다.
    3. GPTCache는 API 호출 비용을 줄이고 응답 시간을 빠르게 하여 개발 비용을 절감할 수 있으며, OpenAI가 제공하는 GPT 서비스와 통합 시 응답 속도를 2-10배 향상시킬 수 있다. 또한 네트워크 변동에도 안정적인 성능을 보인다.

###### The Vault: A Comprehensive Multilingual Dataset for Advancing Code Understanding and Generation (https://aclanthology.org/2023.nlposs-1.25/)
- Anthology ID: 2023.nlposs-1.25 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 기존의 MCQ 생성 평가 방법은 교육적 가치를 고려하지 않고 데이터셋의 답과 유사성을 비교하기 때문에 한계가 있다.
    2. 본 논문에서는 MCQ의 대답 가능성을 평가하는 새로운 메트릭인 KDA를 제안하고, 이를 기반으로 자동 평가 메트릭인 KDA_disc와 KDA_cont를 개발했다.
    3. 실험 결과 KDA_disc와 KDA_cont가 실제 강의 환경에서 usability와 강한 상관관계를 가짐을 확인했다.
    
    1. 최근 NLP 모델의 정확도는 인간을 뛰어넘지만, 특정 패턴에 의존적이기 때문에 robustness에 한계가 있다.
    2. 이 논문에서는 대조학습과 대조적 augmentation을 이용하여 robustness를 향상시키는 것을 목표로 한다.
    3. 실험 결과, 본 연구는 집합적 의사 결정을 통해 각 단어의 인과관계를 robust하게 지도할 수 있었고, 이를 통해 counterfactual robustness, cross-domain generalization, scarce data로부터의 일반화에서 기존 모델보다 혁신적인 개선을 이룩할 수 있었다.

###### SEA-LION (Southeast Asian Languages In One Network): A Family of Southeast Asian Language Models (https://aclanthology.org/2023.nlposs-1.26/)
- Anthology ID: 2023.nlposs-1.26 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 기존 자동 MCQ 생성에 대한 평가 메트릭은 교육적 가치를 고려하지 않고, 단어 유사성에만 집중한다.
    2. 따라서, 우리는 지식 종속 가능성(KDA)이라는 새로운 평가 메트릭을 제안하여 MCQ의 대답 가능성과 학생의 지식을 평가한다.
    3. 실험 결과, KDA_disc와 KDA_cont는 실제 강의 환경에서의 사용성과 강한 상관관계를 보였다.
    
    1. 최근의 deep model들은 NLP 작업에서 인간을 능가하는 정확성을 보이지만, spurious pattern에 의존하기 때문에 robustness가 제한된다.
    2. 따라서, 우리는 대조 학습과 반증적 augmentation을 활용하여 robustness를 강화하려고 한다.
    3. 여러 개의 counterfactual을 생성하고 집합적 의사 결정을 통해 단어들의 인과관계를 강력하게 파악함으로써, 과제 모델의 편향을 덜 민감하게 만든다.
    
    1. 기존의 자동 MCQ 생성 평가 메트릭은 교육적 가치를 고려하지 않으며, 단어 유사성을 중점으로 한다.
    2. 본 연구에서는 새로운 KDA 평가 메트릭을 제안하여 MCQ의 대답 가능성과 대상 사실에 대한 학생의 지식을 평가한다.
    3. 실험 결과로, KDA_disc와 KDA_cont는 실제 수업에서 사용 가능하며, KDA와의 강한 상관관계를 보여준다.

###### trlX: A Framework for Large Scale Open Source RLHF (https://aclanthology.org/2023.nlposs-1.27/)
- Anthology ID: 2023.nlposs-1.27 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. 기존의 MCQ 생성 평가 메트릭은 교육적 가치를 고려하지 않고, KDA를 측정하는 새로운 자동 평가 메트릭을 제안한다.
    2. 지식 종속 가능성(KDA)을 측정하기 위해, 학생 응답을 기반으로한 사람 조사를 활용하며, KDA_disc와 KDA_cont라는 두 가지 자동 평가 메트릭을 제안한다.
    3. KDA_disc와 KDA_cont는 교사의 라벨링된 MCQ 품질 측정에 강한 예측력을 가지고 있으며, 강의실 환경에서의 사용성과 관련도가 높다는 것을 보여준다.
    
    1. 최근 deep model의 정확성이 사람을 뛰어넘으나, spurious pattern에 의존하여 robustness가 제한되는 문제를 contrastive learning과 counterfactual augmentation을 활용하여 해결하고자 한다.
    2. 기존 augmentation의 경우 데이터셋에 counterfactual을 추가하는 것이나 이미 있는 counterfactual과 유사한 것들을 자동으로 찾는 것이 필요한 반면, 이 논문에서는 "여러 개의" counterfactual을 합성하여 인과관계를 더 robust하게 파악한다.
    3. 실험 결과, collective decisions를 통한 방법은 task model의 편향과 상관없이 counterfactual robustness, cross-domain generalization, scarce data에서의 generalization에서 유의한 향상을 보인다.

###### Towards Explainable and Accessible AI (https://aclanthology.org/2023.nlposs-1.28/)
- Anthology ID: 2023.nlposs-1.28 
- Volume: Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023) 
- Summary: 
    1. MCQ 생성에 대한 기존 평가 메트릭은 교육적 가치를 고려하지 못하고, 우리는 지식 종속 가능성(KDA)이라고 불리는 새로운 평가 메트릭을 제안한다.
    2. 기존 자동화 방법과 다르게 우리의 방법은 여러 개의 수치를 통해서 각 단어들 간의 인과관계를 파악하여 더 robust한 유의미한 결과들을 얻을 수 있다.
    3. KDA_disc와 KDA_cont는 강의실에서의 사용성과 강한 상관관계를 가지고 있음을 human evaluation을 통해 입증하였다.

## Proceedings of the 2nd Workshop on Pattern-based Approaches to NLP in the Age of Deep Learning
###### Proceedings of the 2nd Workshop on Pattern-based Approaches to NLP in the Age of Deep Learning (https://aclanthology.org/2023.pandl-1.0/)
- Anthology ID: 2023.pandl-1.0 
- Volume: Proceedings of the 2nd Workshop on Pattern-based Approaches to NLP in the Age of Deep Learning 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Nearest Neighbor Search over Vectorized Lexico-Syntactic Patterns for Relation Extraction from Financial Documents (https://aclanthology.org/2023.pandl-1.1/)
- Anthology ID: 2023.pandl-1.1 
- Volume: Proceedings of the 2nd Workshop on Pattern-based Approaches to NLP in the Age of Deep Learning 
- Summary: 
    1. 기존 MCQ 생성 모델의 평가 메트릭은 교육적 가치를 고려하지 않고 단어의 유사도만 측정하는데, 이 논문은 대답 가능성(KDA)을 측정하는 새로운 평가 메트릭을 제안한다.
    2. 이 논문은 contrastive learning과 counterfactual augmentation을 이용하여 NLP 모델의 robustness를 향상시키고자 한다. Synthetic counterfactuals을 활용하여 강력한 augmentation 기법을 제안한다.
    3. 기존의 RE(관계 추출) 모델은 어려운 언어 표현과 데이터 희소성으로 인해 제약사항이 많은데, 이 논문은 lexico-syntactic patterns을 이용하여 해결하는 간단하고 효과적인 방법을 제안한다. 이를 통해 state-of-the-art 결과를 달성하였다.

###### LEAF: Linguistically Enhanced Event Temporal Relation Framework (https://aclanthology.org/2023.pandl-1.2/)
- Anthology ID: 2023.pandl-1.2 
- Volume: Proceedings of the 2nd Workshop on Pattern-based Approaches to NLP in the Age of Deep Learning 
- Summary: 
    1. 언어 구조는 이전에 탐구되지 않았던 다양한 종류의 사건 간 관계를 암시적으로 나타낼 수 있다. 이 논문에서는 대규모 말뭉치에서 사건에 대한 풍부한 시간적 지식을 습득하기 위해 Linguistically enhanced Event TemporAl relation Framework (LEAF)를 제안한다. 
    2. LEAF는 언어 모델에 다양한 시간적 지식 패턴을 사용하여 비게시된 말뭉치에서 시간 관계 지식을 자동으로 추출하여 성능을 향상시킨다.
    3. 실험 결과, LEAF는 MATRES와 TB-Dense의 두 가지 사건 관계 데이터셋에서 이전 모델들을 능가하거나 견줄만한 성능을 보여준다. 또한, 기존 방법보다 더 간단하며 복합적인 사건 관계를 식별하는 데 뛰어나다.

###### A Graph-Guided Reasoning Approach for Open-ended Commonsense Question Answering (https://aclanthology.org/2023.pandl-1.3/)
- Anthology ID: 2023.pandl-1.3 
- Volume: Proceedings of the 2nd Workshop on Pattern-based Approaches to NLP in the Age of Deep Learning 
- Summary: 
    1. 최근에는 선택형 상식 질문에 대한 end-to-end 모델이 유망한 결과를 보여주었다. 하지만 이러한 질문-답변 시스템은 선택지가 제공되지 않는 실제 상황에 직접 적용할 수 없다. 따라서 최근에 공개된 OpenCSR 도전 세트는 미리 정의된 선택지가 없는 자연과학 질문을 포함하고 있다. 
    2. 이 논문에서는 기존 연구들이 OpenCSR에서의 검색 과정을 개선하는 데에만 초점을 두었지만, 중요하고 복잡한 추론 과정은 무시되었다. 따라서 우리는 질문-의존적인 open knowledge graph를 생성하고 순차적인 서브그래프 추론 과정을 사용하여 답을 예측하는 reasoner를 제안한다. 
    3. OpenCSR 데이터셋 실험 결과, 제안된 모델이 benchmark OpenCSR 데이터셋에서 훌륭한 성능을 보이는 것을 보여준다.

###### Generating Irish Text with a Flexible Plug-and-Play Architecture (https://aclanthology.org/2023.pandl-1.4/)
- Anthology ID: 2023.pandl-1.4 
- Volume: Proceedings of the 2nd Workshop on Pattern-based Approaches to NLP in the Age of Deep Learning 
- Summary: 
    1. M-FleNS는 심볼릭 모듈과 신경망 모듈을 수용할 수 있는 다국적 유연한 플러그 앤 플레이 구조로, 아일랜드어와 같이 NLP 분야에서 소외된 언어에 대한 새로운 자원 구축에 활용된다.
    2. 아주 제한적인 자원을 사용하여, M-FleNS를 사용하여 DBpedia 온톨로지 일부를 언어로 표현하는 아일랜드어 자연어 생성 시스템을 구축하고, 풍부한 언어 주석을 가진 다중 계층 데이터셋을 만드는 방법을 제안한다.
    3. 자동 평가와 사람 평가를 통해 우리는 매우 제한된 자원을 사용하여, 유창함과 의미적 정확성이 높은 시스템을 만들 수 있음을 보여준다.

###### Symbolic Planning and Code Generation for Grounded Dialogue (https://aclanthology.org/2023.pandl-1.5/)
- Anthology ID: 2023.pandl-1.5 
- Volume: Proceedings of the 2nd Workshop on Pattern-based Approaches to NLP in the Age of Deep Learning 
- Summary: 
    1. LLMs (Large language models)은 텍스트와 코드를 처리하고 생성하는 데 우수하다. 그러나, task 목표로 직접 설계하기 어렵고 새로운 grounding을 처리하는 것에 제한이 있다.
    2. 저자들은 LLM을 심볼릭 플래너와 grounding 코드 실행과 함께 사용하여 이러한 단점을 해결하는 모듈식이고 해석 가능한 grounded dialogue 시스템을 제안한다.
    3. 이 시스템은 LLM을 사용하여 partner의 발언을 실행 가능한 코드로 변환하고, symbolic planner가 적절한 응답을 결정하는 것으로 구성되어 있다. 이 시스템은 OneCommon 대화 과제에서 이전 최고 성능을 크게 개선했다.

###### Towards Zero-Shot Frame Semantic Parsing with Task Agnostic Ontologies and Simple Labels (https://aclanthology.org/2023.pandl-1.6/)
- Anthology ID: 2023.pandl-1.6 
- Volume: Proceedings of the 2nd Workshop on Pattern-based Approaches to NLP in the Age of Deep Learning 
- Summary: 
    1. Task-oriented 대화 시스템에서 frame semantic parsing은 중요한 요소이다. 현재 모델은 사용자의 입력 발화에서 의도와 슬롯을 성공적으로 식별하기 위해 상당한 양의 훈련 데이터에 의존한다. 이는 새로운 도메인을 가상 비서 능력에 추가하는 데 상당한 장벽이 되며, 이러한 데이터를 생성하기 위해서는 고도로 전문화된 NLP 전문 지식이 필요하다.
    2. 본 논문에서는 OpenFSP라는 프레임워크를 제안한다. 이 프레임워크는 NLP 특정 지식 없이 생성할 수 있는 간단한 라벨 몇 개로 새로운 도메인을 쉽게 만들 수 있다. 우리의 접근 방식은 도메인에 무관한 슬롯 유형들 중 소규모이지만 표현이 풍부한 세트를 생성하여 새로운 도메인의 주석 작업을 용이하게 한다. 이러한 주석이 주어지면 문장 인코더에 의존하는 일치 알고리즘은 엔드 유저가 정의한 도메인에 대한 의도와 슬롯을 예측한다.
    3. TopV2 데이터셋에서의 실험 결과, 우리의 간단한 라벨로 훈련된 모델은 지도 기준과 강한 성능을 보인다.

###### Co-evolving data-driven and NLU-driven Synthesizers for Generating Code in Domain Growth and Data Scarcity (https://aclanthology.org/2023.pandl-1.7/)
- Anthology ID: 2023.pandl-1.7 
- Volume: Proceedings of the 2nd Workshop on Pattern-based Approaches to NLP in the Age of Deep Learning 
- Summary: 
    1. 자연어 프로그래밍은 사용자의 텍스트 쿼리에 기반하여 코드를 자동으로 생성한다. 그러나 기존 솔루션들은 데이터 기반 신호합성자는 많은 양의 쿼리-코드 쌍을 훈련하기 위해 필요하므로 기능과 문법을 업데이트할 수 있는 낮은 자원의 프로그래밍 언어에 적용하기 어렵다.
    2. 이 논문에서는 데이터 부족과 도메인 성장의 존재에서 높은 품질의 코드 생성을 달성하기 위해 데이터 기반 신호합성자와 NLU 기반 신호합성자를 협동적으로 진화시키는 순환 훈련 프레임워크인 Colead를 제안한다.
    3. 실험 결과, Colead는 도메인 성장과 데이터 부족의 경우 기준 성과보다 더 나은 결과를 제공하며, Colead는 데이터 기반 및 NLU 기반 신호합성자의 성능을 일관되게 향상시킨다.

###### Complementary Roles of Inference and Language Models in QA (https://aclanthology.org/2023.pandl-1.8/)
- Anthology ID: 2023.pandl-1.8 
- Volume: Proceedings of the 2nd Workshop on Pattern-based Approaches to NLP in the Age of Deep Learning 
- Summary: 
    1. 비감독 학습 방법을 통해 오픈 도메인 질문에 대한 응답을 하려는 것은 기계 독해 및 언어 모델 기반 접근 방식에 대한 도전을 야기한다.
    2. 이 논문은 이러한 접근 방식을 비교하고, 신뢰성을 갖춘 술어 함의를 활용하여 이러한 제한을 해결하기 위한 새로운 방법론을 제안한다.
    3. 결론적으로 이 논문의 결과는 술어 함의를 활용하는 것이 오픈 도메인 QA에서 추론의 중요성을 강조하고 개선할 수 있는 것을 보여준다.

###### Controlled Data Augmentation for Training Task-Oriented Dialog Systems with Low Resource Data (https://aclanthology.org/2023.pandl-1.9/)
- Anthology ID: 2023.pandl-1.9 
- Volume: Proceedings of the 2nd Workshop on Pattern-based Approaches to NLP in the Age of Deep Learning 
- Summary: 
    1. 현대 대화 시스템은 transformer 기반 모델 아키텍처를 훈련시키기 위해 딥러닝을 의존한다. 그러나 대화 데이터의 수집은 종종 지루하고 비용이 많이 드는 과정이다. 이 연구에서는 대화 주석에 기반한 제어 전략을 조사한다.
    2. 우리의 방법은 sequence-to-sequence 방식으로 대화 문장을 생성한다. 이 방법의 실용성 뿐만 아니라, 제약된 빔 서치가 생성능력에 미치는 효과도 탐구한다.
    3. 또한, 우리는 합성된 대화가 대화 시스템 훈련에 미치는 영향을 연구하여 데이터 증강의 효과를 분석한다. 여러 설정에서 실험을 수행하여 우리의 연구는 제어된 생성 접근 방법이 대화 시스템 훈련에 사용될 수 있는 태스크 지향 대화를 합성하는 데 유용하다는 것을 보여준다. 또한, 제약된 빔 서치를 사용하여 이 과정을 개선하였다.

###### A Hybrid of Rule-based and Transformer-based Approaches for Relation Extraction in Biodiversity Literature (https://aclanthology.org/2023.pandl-1.10/)
- Anthology ID: 2023.pandl-1.10 
- Volume: Proceedings of the 2nd Workshop on Pattern-based Approaches to NLP in the Age of Deep Learning 
- Summary: 
    1. Relation extraction (RE)은 다양한 NLP 응용 프로그램을 위한 중요한 작업 중 하나이다. 
    2. 이 논문에서는 특정 도메인에 대한 DL 기반 RE 시스템을 훈련시키기 위해 일반적으로 필요한 expert-labeled 데이터셋이 부족한 상황에서 pattern-based 방법과 NLI transformer 모델의 템플릿을 결합한 하이브리드 방법을 제안한다. 
    3. 생물 다양성 문헌의 어노테이션 된 관계를 사용하여 평가한 결과, 이 방법은 F1-score가 89.61%에서 96.75%로 증가하여 solely rule-based 및 transformer-based 방법보다 우수한 성능을 보였다.

## Proceedings of the 3rd Combined Workshop on Spatial Language Understanding and Grounded Communication for Robotics (SpLU-RoboNLP 2023)
###### Proceedings of the 3rd Combined Workshop on Spatial Language Understanding and Grounded Communication for Robotics (SpLU-RoboNLP 2023) (https://aclanthology.org/2023.splurobonlp-1.0/)
- Anthology ID: 2023.splurobonlp-1.0 
- Volume: Proceedings of the 3rd Combined Workshop on Spatial Language Understanding and Grounded Communication for Robotics (SpLU-RoboNLP 2023) 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Dialogue-based generation of self-driving simulation scenarios using Large Language Models (https://aclanthology.org/2023.splurobonlp-1.1/)
- Anthology ID: 2023.splurobonlp-1.1 
- Volume: Proceedings of the 3rd Combined Workshop on Spatial Language Understanding and Grounded Communication for Robotics (SpLU-RoboNLP 2023) 
- Summary: 
    1. 시뮬레이션은 자율주행차량의 컨트롤러 개발과 평가에 있어서 귀중한 도구이지만, 현재 시뮬레이션 프레임워크는 특화 언어를 사용하기 때문에 자연어 인터페이스가 사용성을 크게 향상시킬 수 있다.
    2. 이 논문에서는 확장된 다중 모달 상호작용을 지원하여 사용자가 이전 지침에 수정 또는 보완을 할 수 있도록 하는 시스템을 제안한다. 이 시스템은 대화에서 사용자의 의도를 적절히 파악하기 위해 대형 언어 모델을 사용하여 영어 발화를 도메인 특화 코드로 변환한다.
    3. 이 연구는 LLMs가 발화의 문맥을 적절히 파악하는 능력을 어느 정도 가지고 있는지를 탐구하며 사용자의 의도를 계산하는데 필요한 문맥 민감성을 탐구한다.

## Proceedings of the Seventh Widening NLP Workshop (WiNLP 2023)
###### Proceedings of the Seventh Widening NLP Workshop (WiNLP 2023) (https://aclanthology.org/2023.winlp-1.0/)
- Anthology ID: 2023.winlp-1.0 
- Volume: Proceedings of the Seventh Widening NLP Workshop (WiNLP 2023) 
- Summary: 
    요약문을 생성할 수 없습니다.

## Proceedings of the Eighth Conference on Machine Translation
###### Proceedings of the Eighth Conference on Machine Translation (https://aclanthology.org/2023.wmt-1.0/)
- Anthology ID: 2023.wmt-1.0 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    요약문을 생성할 수 없습니다.

###### Findings of the 2023 Conference on Machine Translation (WMT23): LLMs Are Here but Not Quite There Yet (https://aclanthology.org/2023.wmt-1.1/)
- Anthology ID: 2023.wmt-1.1 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 이 논문은 2023년 기계 번역 컨퍼런스(WMT) 일환으로 열린 General Machine Translation Task의 결과를 제시한다.
    2. 일반적인 기계 번역 과제에서는 참가자들에게 8개의 언어 쌍(14개의 번역 방향에 해당) 중 하나에 대해 기계 번역 시스템을 구축하라고 요청하고, 최대 네 가지 다른 도메인으로 구성된 테스트 세트에서 평가한다.
    3. 우리는 Source-based Direct Assessment와 scalar quality metric(DA+SQM)의 조합을 사용하여 전문인간 평가자들이 시스템 출력을 평가한다.

###### Findings of the WMT 2023 Biomedical Translation Shared Task: Evaluation of ChatGPT 3.5 as a Comparison System (https://aclanthology.org/2023.wmt-1.2/)
- Anthology ID: 2023.wmt-1.2 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1.  WMT23에서 진행된 Biomedical Translation Task에 대한 개요를 제공한다. 이 Task의 목표는 PubMed 데이터베이스에서 생체 의학적인 초록을 자동으로 번역하는 것이다. 
    2. 이 Task에는 프랑스어, 스페인어, 포르투갈어, 이탈리아어, 독일어, 러시아어 등 12개의 언어 방향 (영어를 기준으로 번역하거나 번역되는 방향)이 포함되었다. 
    3. ChatGPT 3.5를 기반으로 한 비교 시스템이 많은 제출작 중에서 아주 잘 수행되었다고 한다.

###### Findings of the WMT 2023 Shared Task on Discourse-Level Literary Translation: A Fresh Orb in the Cosmos of LLMs (https://aclanthology.org/2023.wmt-1.3/)
- Anthology ID: 2023.wmt-1.3 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 文학작품 번역은 기계번역에서 계속해서 어려운 도전으로 남아있고, 이 도메인에서 진전을 이끌기 위해 'Discourse-Level Literary Translation' 공유 작업을 WMT 2023에서 개최한다. 
    2. 저자들은 저작권이 있는 한영 웹 소설 말뭉치를 공개하고 사람의 평가 과정을 안내하는 산업 인증 기준을 제시한다. 
    3. 이번 작업에서는 총 7개의 학계와 산업 팀으로부터 14개의 제출을 받았고, 제출된 시스템의 성능을 측정하기 위해 자동 평가와 인간 평가를 사용했다.

###### Findings of the Second WMT Shared Task on Sign Language Translation (WMT-SLT23) (https://aclanthology.org/2023.wmt-1.4/)
- Anthology ID: 2023.wmt-1.4 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 이 논문은 자동 수화 번역을 위한 두 번째 WMT Shared Task 결과를 제시한다. 이 공유 작업은 수화와 구어 언어 간의 자동 번역에 관련되어 있다. 이미 잘 알려진 텍스트-텍스트 기계 번역의 패러다임을 넘어서 시각 정보 (비디오 프레임 또는 인간 자세 추정과 같은)를 처리하는 것이 필요하다는 점에서 이 작업은 유일하다.
    2. 이 작업은 DSGS-to-German 트랙을 포함한 네 가지 트랙이 제공된다.
    3. 이 작업은 새로운 말뭉치와 재현 가능한 베이스라인 시스템을 포함하여 다음과 같은 과학적 기여를 한다.

###### Findings of the WMT 2023 Shared Task on Parallel Data Curation (https://aclanthology.org/2023.wmt-1.5/)
- Anthology ID: 2023.wmt-1.5 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 우리는 문서 정렬 및 문장 필터링에 대한 이전 WMT 공유 태스크를 기반으로, 에스토니아-리투아니아 웹 데이터의 가능한 훈련 데이터의 최적 하위 집합을 찾는 엔드 투 엔드 데이터 정제 파이프라인의 공유 태스크를 제시했다.
    2. 참가자들은 정렬과 필터링을 포함한 데이터 정제 파이프라인의 어느 부분에 집중할 수 있었다.
    3. 우리는 결론적으로 기계 번역 품질을 기준으로 결과를 평가했으며, 강력한 기준 시스템의 다양한 중간 결과와 함께 처리된 Common Crawl 데이터를 공개하여 이에 대한 차후 연구를 가능하게 할 것이라고 생각한다.

###### Samsung R&D Institute Philippines at WMT 2023 (https://aclanthology.org/2023.wmt-1.6/)
- Anthology ID: 2023.wmt-1.6 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 삼성 R&D Institute Philippines의 제약 조건 있는 submission 시스템은 WMT 2023 일반 번역 작업에 대한 en->he와 he->en 두 방향으로 구성되어 있다.
    2. 해당 시스템은 Transformer 기반의 sequence-to-sequence 모델로, 종합적인 데이터 전처리 파이프라인, 후반환(backtranslation) 데이터의 합성, 그리고 온라인 디코딩 중 noisy channel reranking 사용 등의 다양한 방법론을 통해 학습되었다.
    3. FLORES-200 및 NTREX-128라는 두 개의 공개 벤치마크에서, 해당 모델은 mBART50 M2M 및 NLLB 200 MoE와 같은 강력한 기준 모델과 유사한 성능을 보이며, 가중치 수가 상당히 적다.

###### NAIST-NICT WMT’23 General MT Task Submission (https://aclanthology.org/2023.wmt-1.7/)
- Anthology ID: 2023.wmt-1.7 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 이 논문은 WMT'23의 영일 ↔ 일영 일반 기계 번역 작업에 대한 NAIST-NICT의 제출 시스템을 설명한다.
    2. 이 시스템은 다양한 기법을 사용하여 다양한 번역 후보를 생성하고, 두 단계의 재정렬 시스템을 사용하여 최상의 번역을 찾는다.
    3. 다양한 번역 후보를 생성하는 것이 번역 품질을 향상시키는데 도움이 되었으며, 재정렬 모델을 사용하여 최종 후보를 순위화하는 것이 성능을 향상시킨다는 것을 발견하였다.

###### CUNI at WMT23 General Translation Task: MT and a Genetic Algorithm (https://aclanthology.org/2023.wmt-1.8/)
- Anthology ID: 2023.wmt-1.8 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 이 논문은 Charles 대학의 팀이 WMT23 General 번역 과제 (영어에서 체코어 및 체코어에서 우크라이나어 번역 방향) 에 대한 기여를 소개한다.
    2. CUNI-GA는 CUNI-Transformer 및 CUNI-DocTransformer 두 개의 다른 시스템이 생성한 번역 후보에 대해 새로운 n-best list reranking 및 수정 방법을 적용하여 달성되었다.
    3. 우리의 방법은 유전 알고리즘과 MBR 디코딩을 사용하여 특정한 메트릭에 대해 최적의 번역을 탐색하고, 이는 ChrF, BLEU, COMET22-DA 및 COMET22-QE-DA의 가중 조합으로 이루어진다. 우리의 제출은 제약된 트랙에서 첫 번째이며 다양한 자동 메트릭에서 최고 수준의 제약이 없는 시스템과 경쟁력 있는 성능을 보여준다.

###### SKIM at WMT 2023 General Translation Task (https://aclanthology.org/2023.wmt-1.9/)
- Anthology ID: 2023.wmt-1.9 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. SKIM 팀은 기본 모델 훈련, 데이터 확장을 위한 역번역, 역번역 훈련 데이터를 사용하는 몇 가지 최종 모델의 재훈련을 포함한 일반적인 프로시저를 사용하여 앙상블 트랜스포머 모델을 구축했다.
    2. 각 최종 모델은 10.5B 개의 매개변수로 구성되어 있으며, 디코더에서 self-attention과 cross-sublayer를 교차+자기 어텐션 서브레이어로 대체했다.
    3. SKIM 팀은 13개의 다른 모델에서 생성된 70개의 번역 후보 중에서 가장 좋은 후보를 선택하기 위해 COMET 및 COMET-QE를 사용하는 MBR 재순위 메소드를 사용했으며, 트랜스포머 모델의 훈련 데이터에 데이터 증강 및 선택 기법을 적용했다.

###### KYB General Machine Translation Systems for WMT23 (https://aclanthology.org/2023.wmt-1.10/)
- Anthology ID: 2023.wmt-1.10 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 이 논문은 WMT 2023 일반 기계 번역 공유 작업을 위한 신경망 기계 번역 시스템 구축 방법에 대해 설명한다. 모델은 Transformer 아키텍처의 기본 설정을 기반으로 하며, 다양한 전략을 통해 성능을 최적화한다.
    2. 모델의 능력을 향상시키기 위해 미리 학습 된 모델을 확장 데이터셋으로 fine-tuning하는 전처리 기법을 사용한다. 번역 품질을 더욱 향상시키기 위해 전처리 및 후처리 기술을 사용한다.
    3. 컴팩트한 모델과 정제된 데이터의 시너지를 통해 예외적인 정확도를 달성하기 위해 효율적인 모델 훈련에 중점을 두었으며, 영어에서 일본어 및 일본어에서 영어로의 번역을 위해 N-best 랭킹에 의한 앙상블 학습도 수행하였다.

###### Yishu: Yishu at WMT2023 Translation Task (https://aclanthology.org/2023.wmt-1.11/)
- Anthology ID: 2023.wmt-1.11 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 본 논문은 WMT 2023 Universal Translation Shared Task를 위해 개발된 Dtranx AI 번역 시스템을 소개한다. 영어에서 중국어로의 번역과 중국어에서 영어로의 번역 두 가지 언어 방향으로 팀이 참여했다. 
    2. 특히 우리는 중국어에서 영어로의 모델의 효과성을 높이기 위해 이중 언어 모델을 구현하는 데 초점을 맞췄다. 데이터 코퍼스 필터링, 모델 크기 조절, sparse expert model (특히 어댑터와 Transformer 모델) 등 다양한 기술을 사용했다.
    3. 자동 평가 결과, 우리 시스템은 영어-중국어 부문에서 1위, 중국어-영어 부문에서 2위를 차지했다.

###### PROMT Systems for WMT23 Shared General Translation Task (https://aclanthology.org/2023.wmt-1.12/)
- Anthology ID: 2023.wmt-1.12 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 본 논문은 WMT23 Shared General Translation Task에 대한 PROMT의 제출 내용을 설명한다. 올해에는 영어에서 러시아어로 번역하는 방향과 러시아어에서 영어로 번역하는 방향 두 가지에 참가하였다. 
    2. 우리는 MarianNMT 툴킷을 사용하여 transformer-big 구성으로 모델을 훈련시켰고, 텍스트 인코딩을 위해 BPE를 사용하였다. 모델은 규제되지 않았고, 자동 평가 메트릭에 따라 양방향으로 경쟁력 있는 결과를 얻었다.

###### AIST AIRC Submissions to the WMT23 Shared Task (https://aclanthology.org/2023.wmt-1.13/)
- Anthology ID: 2023.wmt-1.13 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 본 논문에서는 AIST AIRC 팀이 WMT 2023 General Translation 과제에 제출한 NMT 시스템의 개발 과정을 설명한다.
    2. 우리는 영어, 독일어, 일본어 사이의 번역을 위해 constrained track 모델을 학습하였다.
    3. 최종 모델을 학습하기 전에 parallel 및 단일 언어 데이터를 걸러내고, iterative back-translation 및 parallel data distillation을 수행하여 non-autoregressive 모델 학습에 사용하였다.

###### MUNI-NLP Submission for Czech-Ukrainian Translation Task at WMT23 (https://aclanthology.org/2023.wmt-1.14/)
- Anthology ID: 2023.wmt-1.14 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 우리는 기계 번역된 텍스트, 러시아어 텍스트 및 기타 노이즈를 제거하기 위해 데이터를 철저히 정제하였다.
    2. 우리는 TorchScale 라이브러리의 DeepNorm 변형을 사용하여 18개의 인코더 레이어와 6개의 디코더 레이어를 가진 transformer 아키텍처로 시스템을 훈련시켰다.
    3. 초기 시스템에서는 HFT 토크나이저를 사용하였고, 최종 시스템에서는 HFT에서 파생된 커스텀 토크나이저를 사용하였다.

###### Exploring Prompt Engineering with GPT Language Models for Document-Level Machine Translation: Insights and Findings (https://aclanthology.org/2023.wmt-1.15/)
- Anthology ID: 2023.wmt-1.15 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 본 연구에서는 WMT 2023 General Translation 공유 작업을 위한 Lan-Bridge 번역 시스템을 설명한다. 우리는 영어-중국어 양방향으로 참가하였으며, 대용량 모델의 등장으로 문서 수준 기계 번역 분야에서 많은 변화가 있었다고 말할 수 있다.
    2. 우리는 GPT-3.5와 GPT-4와 같은 모델의 발전에 집중하여 작업했으며, 여러 prompt 기반 실험을 수행하였다. 우리의 목표는 문서 수준 기계 번역에서 최적의 인간 평가 결과를 얻는 것이며, 이를 통해 일반 트랙에서 최종 결과를 제출하였다.

###### Treating General MT Shared Task as a Multi-Domain Adaptation Problem: HW-TSC’s Submission to the WMT23 General MT Shared Task (https://aclanthology.org/2023.wmt-1.16/)
- Anthology ID: 2023.wmt-1.16 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 이 논문은 중국어-영어 동시 번역에서 Huawei Translate Services Center (HW-TSC)의 참가 결과를 보여준다. Transformer 아키텍처를 사용하여, 매개변수 크기가 큰 변형 모델을 통해 최고의 성능을 얻는다.
    2. 제공된 대규모 이중 및 단일 언어 데이터에 대해 세밀한 전처리와 필터링을 수행한다.
    3. Regularized Dropout, Bidirectional Training, Data Diversification, Forward Translation, Back Translation, Alternated Training, Curriculum Learning 및 Transductive Ensemble Learning과 같은 모델 개선 전략을 주로 사용하여 경쟁력 있는 결과를 얻었다.

###### UvA-MT’s Participation in the WMT 2023 General Translation Shared Task (https://aclanthology.org/2023.wmt-1.17/)
- Anthology ID: 2023.wmt-1.17 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 이 논문은 WMT 2023 공유 과제에 대한 UvA-MT의 제출 내용을 설명한다. 우리는 제약된 트랙에서 두 가지 방향인 영어 ↔ 히브리어로 참가했다.
    2. 우리는 한 모델을 사용하여 양방향 작업을 처리함으로써 Multilingual Machine Translation (MMT)의 최소한의 설정으로 전통적인 이중 번역과 비교 가능한 결과를 얻을 수 있다는 것을 이 대회에서 입증했다.
    3. 백 번역, 재매개 변수화된 임베딩 테이블, 과업 지향적 fine-tuning과 같은 효과적인 전략을 포함하여 영어 → 히브리어 및 히브리어 → 영어 방향 모두에서 경쟁력 있는 최종 결과를 얻었다.

###### Achieving State-of-the-Art Multilingual Translation Model with Minimal Data and Parameters (https://aclanthology.org/2023.wmt-1.18/)
- Anthology ID: 2023.wmt-1.18 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 이 논문에서는 WMT 2023 General Machine Translation Task를 위해 13개의 언어 방향으로 기계 번역 모델을 개발하였다. 다국어 데이터셋을 사용하여 디코더만을 가진 아키텍처를 채택하고, 고품질의 병렬 말뭉치를 사용하여 모델을 세밀하게 튜닝하여 번역 작업을 수행할 수 있도록 하였다.
    2. 자동 평가 메트릭에 의하면, 이 모델은 영어에서 러시아어, 독일어, 우크라이나어로의 번역 방향에서 1위를 차지하였다. 또한 영어에서 체코어, 히브리어, 히브리어에서 영어, 우크라이나어에서 영어로의 번역 방향에서 2위를 차지하였다.
    3. 13개의 번역 방향을 모두 커버하는 이 다국어 모델은 GPT-4와 비슷한 수준의 성능을 보여주고, 7개의 번역 방향에서는 GPT-4보다 높은 BLEU 점수를 기록하였다.

###### IOL Research Machine Translation Systems for WMT23 General Machine Translation Shared Task (https://aclanthology.org/2023.wmt-1.19/)
- Anthology ID: 2023.wmt-1.19 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. IOL Research 팀은 WMT23 일반 기계 번역 공유 과제에 대한 제출 시스템을 설명한다. 영어에서 중국어 및 중국어에서 영어로 두 가지 번역 방향에 참여했다. 우리의 최종 주요 제출은 제약된 시스템에 속하며, 두 번역 방향 모두에서 공식적으로 제공 된 단일 언어 및 양방향 데이터만을 사용하여 번역 시스템을 훈련시켰다.
    2. 우리의 시스템은 Transformer 아키텍처를 기반으로 하며, pre-norm 또는 deep-norm을 사용하여 더 깊은 모델을 훈련하는 데 도움이되었다. 우리는 역 번역, 데이터 다양화, 도메인 세부 조정 및 모델 앙상블과 같은 방법을 사용하여 번역 시스템을 구축했다.
    3. 특히 데이터 정제 프로세스와 데이터 확대를 위해 상당한 양의 단일 언어 데이터를 활용하는 우리의 신중한 데이터 정리 방법을 언급할만한 중요한 측면이다. 기준 시스템과 비교하여 우리의 제출은 BLEU 점수에서 큰 개선을 보였다.

###### GTCOM and DLUT’s Neural Machine Translation Systems for WMT23 (https://aclanthology.org/2023.wmt-1.20/)
- Anthology ID: 2023.wmt-1.20 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 글로벌톤 커뮤니케이션과 대련공과대학이 EMNLP의 WMT23 공유 일반 기계 번역(MT) 태스크에 대한 참가 결과를 발표한다. 영어-우크라이나어, 우크라이나어-영어, 체코-우크라이나어, 영어-히브리어, 히브리어-영어, 영어-체코어, 독일어-영어, 일본어-영어 등 8개의 언어 쌍에 참가했다. 특정 제약이나 요구사항 없이 시스템을 설계하여 기계 번역의 다양한 가능성을 탐구했다.
    2. 백번역을 우선순위로 두고, 다국어 번역 모델을 활용하며 성능을 향상시키는 세부조정 전략을 도입했다. 또한, 인간 주석을 활용하여 고품질의 훈련 데이터를 생성하는 새로운 데이터 생성 방법을 제안했고, 이로써 시스템 성능을 향상시켰다. 인공평가 결과, 우리 시스템은 우크라이나어-영어, 히브리어-영어, 영어-히브리어, 독일어-영어에서 BLEU 점수 기준으로 1위를 차지했다.
    3. (추가) 백번역(backtranslation): 목표 언어로 번역한 훈련 데이터를 다시 원래 언어로 번역하여 다양한 예문을 얻는 방법. 다양한 예문을 통해 모델의 성능을 향상시킬 수 있다.

###### RoCS-MT: Robustness Challenge Set for Machine Translation (https://aclanthology.org/2023.wmt-1.21/)
- Anthology ID: 2023.wmt-1.21 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. Robust Challenge Set for Machine Translation (MT)로 디자인된 RoCS-MT는 맞춤법 오류, 모음 삭제, 약어 등과 같은 비표준적인 특성을 가진 UGC(사용자 생성 콘텐츠)를 번역하는 MT 시스템의 능력을 테스트하기 위해 만들어졌다. 
    2. RoCS-MT는 Reddit의 비표준적인 영어 댓글들을 수작업으로 일반화하고 프로페셔널하게 다섯 가지 언어로 번역한 데이터이다.
    3. 비표준 UGC 텍스트를 처리할 때 최신 MT 모델이 직면하는 문제 유형을 분석하고, 품질 평가를 포함한 자동 메트릭을 비교하여 MT 시스템의 강건성을 평가하였다. GPT4는 가장 우수한 성능을 보이지만, RoCS의 소스 측면과 유사한 데이터에서 학습된 모델이기 때문에 일반화 능력에 대한 결론을 이끌어내는 데 주의가 필요하다.

###### Multifaceted Challenge Set for Evaluating Machine Translation Performance (https://aclanthology.org/2023.wmt-1.22/)
- Anthology ID: 2023.wmt-1.22 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 기계 번역 평가는 기계 번역 연구에 있어서 매우 중요한데, 평가 결과는 훈련 전략의 효과를 반영하기 때문이다. 그러므로 공정하고 효율적인 평가 방법이 필요하다. 
    2. 본 논문에서는 소스 문장의 난이도 수준과 평가 결과에 미치는 영향을 분석한 것은 이 논문이 처음이라고 한다. 
    3. 그들은 단어의 난이도, 길이의 난이도, 문법의 난이도, 모델 학습의 난이도 네 가지 측면에서 challenge set을 고려했으며, Zh→En 및 En→Zh를 위한 두 개의 Multifaceted Challenge Set도 공개하였다.

###### Linguistically Motivated Evaluation of the 2023 State-of-the-art Machine Translation: Can ChatGPT Outperform NMT? (https://aclanthology.org/2023.wmt-1.23/)
- Anthology ID: 2023.wmt-1.23 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 본 논문은 8회 기계 번역 학회(WMT23)에서의 공유 과제(context of the Shared Task)에서의 기계 번역 결과를 세밀한 분석한다. 이 분석은 Large Language Model과 새로운 언어 현상을 포함한 업데이트된 테스트 세트를 기반으로 한다. 
    2. GPT-4 번역 결과에 대한 첫 번째 세밀한 언어 분석이며, 독일어-영어, 영어-독일어, 영어-러시아어 언어 방향으로 평가를 진행한다. 
    3. 독일어-영어에서 가장 낮은 정확도를 보이는 현상으로는 관용구와 결과적 서술 동사가 있으며, 영어-독일어에서는 중절 수동태와 명사 형성이 포함된다. 영어-러시아어에서는 관용구와 의미론적 역할이 포함된다. GPT-4는 독일어-영어와 영어-독일어에서 최고 시스템과 동등하거나 비교 가능한 성능을 보이지만, 영어-러시아어에서는 두 번째로 중요한 군집에 속한다.

###### IIIT HYD’s Submission for WMT23 Test-suite Task (https://aclanthology.org/2023.wmt-1.24/)
- Anthology ID: 2023.wmt-1.24 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 이 논문은 영어-독일어 (en-de) 언어 쌍의 기계 번역 시스템 12개를 대상으로 한 WMT23 공유 작업의 테스트 스위트 평가 결과를 요약하고 있다.
    2. 테스트 스위트는 다섯 가지 특정 도메인 (엔터테인먼트, 환경, 건강, 과학, 법률)과 다섯 가지 서로 다른 글쓰기 스타일 (서술적, 판례, 서술적, 리포팅, 기술 글)을 다루고 있다.
    3. 도메인별 및 글쓰기 스타일별 평가에 초점을 맞춘 자동 평가 방법을 통해 결과를 분석한다.

###### Test Suites Task: Evaluation of Gender Fairness in MT with MuST-SHE and INES (https://aclanthology.org/2023.wmt-1.25/)
- Anthology ID: 2023.wmt-1.25 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. WMT-2023 "Test suites" 공유 과제의 일환으로, 이 논문에서는 MuST-SHEWMT23과 INES의 두 가지 테스트 스위트 평가 결과를 요약한다. en-de와 de-en 언어 쌍에 초점을 맞춰, 새롭게 생성된 테스트 스위트를 통해 시스템이 여성과 남성 성별을 번역하고 포괄적인 성별 포함 번역을 생성하는 능력을 조사한다.
    2. 우리는 테스트 스위트와 관련된 메트릭을 논의하고, 인간 평가를 통해 이를 검증한다. 결과는 시스템이 자연스러운 성별 현상에 대해 여성과 남성 성별 형태를 정확하게 번역하는데 합리적이고 비교 가능한 성능을 달성한다는 것을 보여준다.
    3. 그러나 포괄적인 언어 형태의 생성은 모든 평가된 기계 번역 모델에 대해 어려운 과제로 나타나며, 이를 개선하고 연구할 여지가 있다고 제시한다. MuST-SHEWMT23과 INES를 무료로 제공한다.

###### Biomedical Parallel Sentence Retrieval Using Large Language Models (https://aclanthology.org/2023.wmt-1.26/)
- Anthology ID: 2023.wmt-1.26 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 자체 도메인 코퍼스에서 평행문장 필터링 시 도메인 지식의 영향을 조사했습니다. 도메인 지식 없이 자체 도메인 코퍼스에서 문장을 채굴하여 만든 모델의 성능이 좋지 않았으며, 도메인 중심의 필터링을 추가하면 평균 2.3 BLEU 포인트 이상의 성능 향상이 있었습니다. 
    2. 유사하고 도메인에 맞는 문장을 선택하는 데에 큰 언어 모델을 사용했습니다. 초기 비교 가능 코퍼스가 도메인이 아닌 경우에도 도메인 지식의 포함은 문장 선택 방법론에 중요함을 실험적으로 보였습니다.

###### The Path to Continuous Domain Adaptation Improvements by HW-TSC for the WMT23 Biomedical Translation Shared Task (https://aclanthology.org/2023.wmt-1.27/)
- Anthology ID: 2023.wmt-1.27 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 이 논문은 화웨이 번역서비스 센터 (HW-TSC)가 WMT23 바이오의학 번역 과제의 영어↔독일어 (en↔de) 언어 쌍에서 신경망 기계 번역 (NMT) 시스템을 훈련하기 위해 도메인 적응 방법을 제시한다.  
    2. 화웨이의 NMT 시스템은 기존의 교육용 NMT 시스템을 기반으로 하고, 커리큘럼 학습, 데이터 다양화, 전방 번역, 역방향 번역 및 설명적 앙상블 학습을 활용하여 시스템 성능을 더 개선시켰다. 
    3. 전반적으로, 저자들은 공식 최종 평가에서 매우 경쟁력 있는 결과를 달성할 수 있다고 믿고 있다.

###### Investigating Techniques for a Deeper Understanding of Neural Machine Translation (NMT) Systems through Data Filtering and Fine-tuning Strategies (https://aclanthology.org/2023.wmt-1.28/)
- Anthology ID: 2023.wmt-1.28 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 생명 과학 분야에서 데이터 필터를 구현하여 훈련 데이터의 선택을 향상시켰습니다. 이를 통해 생명 과학 분야에 특화된 모델을 fine-tuning하기 위한 실용적인 전략을 개발하고, 훈련 데이터의 필터링 기준을 정의하며, 테스트 데이터에 맞춰 모델 예측 및 fine-tuning 데이터를 비교하여 신경기계번역(NMT) 시스템의 작동에 대해 깊은 통찰력을 얻고자 합니다.
    2. 텍스트메트릭 분석을 사용하여 테스트 세트 내에서 반복되는 세그먼트를 감지하고, 이를 사용하여 mBart-50 기준 모델의 fine-tuning에 사용되는 훈련 데이터를 개선합니다.
    3. 생명 과학 분야에 특화된 훈련 데이터에 대한 fine-tuning 전략을 개발하고, 테스트 세트에 따른 모델 예측 및 fine-tuning 데이터를 비교함으로써 NMT 시스템의 작동에 대한 깊은 통찰력을 얻기 위해 이러한 접근 방식을 사용합니다.

###### MAX-ISI System at WMT23 Discourse-Level Literary Translation Task (https://aclanthology.org/2023.wmt-1.29/)
- Anthology ID: 2023.wmt-1.29 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 본 논문에서는 WMT23 shared task에서 discourse-level literary translation task - constrained track에 참여한 번역 시스템에 대해 설명한다. 
    2. 기존의 Transformer 모델과 최근에 도입된 MEGA 모델을 비교 분석하여, MEGA 모델이 전통적인 Transformer에 비해 장거리 시퀀스를 모델링하는 능력이 향상되었는지 확인한다.
    3. 문학 데이터셋에서 문장을 단락으로 집계하여 언어 모델이 문서 수준의 문맥을 더 효과적으로 활용할 수 있는지 탐구하였고, 이 단락 수준의 데이터는 Transformer와 MEGA 모델 양쪽에서 활용되었다.

###### The MAKE-NMTVIZ System Description for the WMT23 Literary Task (https://aclanthology.org/2023.wmt-1.30/)
- Anthology ID: 2023.wmt-1.30 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. MAKE-NMTVIZ 시스템은 WMT 2023 Literary task를 위해 훈련된 시스템으로, mBART50 모델을 GuoFeng corpus 데이터로 fine-tuning 한다.
    2. contrastive1 submission에서는 fine-tuned concatenation transformer를 사용하여 sentence-level transformer를 구현하고, document-level에서 fine-tuning을 진행한다.
    3. contrastive2 submission에서는 sentence-level transformer model을 구현하여 general data로 훈련하고, sentence- vs document-based training의 영향을 다양한 관점에서 비교한다.

###### DUTNLP System for the WMT2023 Discourse-Level Literary Translation (https://aclanthology.org/2023.wmt-1.31/)
- Anthology ID: 2023.wmt-1.31 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. DUTNLP Lab은 문맥 수준의 중국어에서 영어 번역에 대한 WMT23 과제에 대한 사전 송부 기술을 설명한다. 
    2. 주된 방법론은 다양한 prompt 전략을 가진 대형 언어 모델을 활용하여 문맥 수준의 신경망 기계 번역의 잠재력을 탐색하는 데 있다.
    3. 실험 결과, 대형 언어 모델을 기반으로 한 적절한 prompt 전략을 선택하는 것은 전통적인 모델 학습 방법에 비해 번역 성능을 상당히 향상시킬 수 있다는 것을 보여준다.

###### HW-TSC’s Submissions to the WMT23 Discourse-Level Literary Translation Shared Task (https://aclanthology.org/2023.wmt-1.32/)
- Anthology ID: 2023.wmt-1.32 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. WMT23 Discourse-Level Literary Translation 공유 태스크에 대한 HW-TSC의 제출을 소개한다. 이 논문에서는 기본적으로 sentence-level transformer를 사용하고 domain 적응과 discourse modeling을 통해 discourse-level 기능을 향상시킨다.
    2. domain 적응을 위해 역 번역(Back-Translation), 직진 번역(Forward-Translation) 및 데이터 다양화(Data Diversification)를 사용한다.
    3. Discourse modeling을 위해 Multi-resolutional Document-to-Document Translation 및 TrAining Data Augmentation과 같은 전략을 적용한다.

###### TJUNLP:System Description for the WMT23 Literary Task in Chinese to English Translation Direction (https://aclanthology.org/2023.wmt-1.33/)
- Anthology ID: 2023.wmt-1.33 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 테스트를 위해 사용된 기본 모델은 트랜스포머(Transformer) 기반의 MOE(Mixture of Experts) 모델이며, 훈련 데이터셋이 상대적으로 작기 때문에 희소 모델을 강화하기 위해 데이터 증강 기술을 활용했다.
    2. 이를 위해 먼저 훈련 데이터셋에서 기본 트랜스포머 기반 밀집모델(dense model)을 훈련시키고, 이 모델을 사용하여 초기화된 MOE 기반 번역 모델을 구축하여 훈련시켰다.
    3. 실험 결과, 이 방법은 신경망 기계 번역 성능을 효과적으로 향상시킬 수 있음을 보여준다.

###### Machine Translation for Nko: Tools, Corpora, and Baseline Results (https://aclanthology.org/2023.wmt-1.34/)
- Anthology ID: 2023.wmt-1.34 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 현재는 수천만 명이 사용하는 서아프리카의 Nko 언어를 위한 사용 가능한 기계 번역 시스템이 없다. 이 문제를 해결하기 위해, 사용 가능한 대화형 평행 텍스트 모음을 개발하기 위한 도구, 데이터 리소스, 기준 결과를 제시한다.
    2. Fria∥el은 협업형 텍스트 가공 소프트웨어로, 품질 관리를 위해 편집기반 워크플로를 통합한다.
    3. FLoRes-200와 NLLB-Seed 코퍼스는 Nko와 함께 204개와 40개의 다른 언어와 2,009개와 6,193개의 고품질 번역으로 확장되었다.
    4. nicolingua-0005는 130,850개의 평행 문장과 300만개 이상의 Nko 단어를 포함하는 볼링귀언어와 이중 언어 코퍼스이다. 그리고 최고 모델은 FLoRes-devtest에서 영어-Nko chrF++ 30.83의 점수를 받았다.

###### TTIC’s Submission to WMT-SLT 23 (https://aclanthology.org/2023.wmt-1.35/)
- Anthology ID: 2023.wmt-1.35 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 이 논문은 스위스-독일 수화 (DSGS)에서 독일어로의 수화 번역 작업에 대한 TTIC의 참여에 대해 설명한다. 
    2. 기존의 광학 주석(gloss annotations)과 같은 비용이 많이 드는 레이블 의존적인 전통적인 방식 대신, 대규모 자가 지도 사전 학습의 이점을 수화 번역 작업에 사용하는 방법에 초점을 맞춘다.
    3. 제안된 모델은 이미지 인코딩을 위한 VideoSwin transformer와 텍스트 대신 VideoSwin 특징을 입력으로 받도록 조정된 T5 모델로 구성되어 있다.

###### KnowComp Submission for WMT23 Sign Language Translation Task (https://aclanthology.org/2023.wmt-1.36/)
- Anthology ID: 2023.wmt-1.36 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 수화 번역(Sign Language Translation, SLT)은 수화 동작을 정확하게 해석하고 이를 말이나 쓰기로 번역하는 복잡한 작업이다. 이 논문에서는 gloss-free 방법을 제안하여 텍스트 소스 문맥이 없는 SLT에서도 효율적으로 작동되는 모델을 구축한다.
    2. 기존의 방법은 수화 동작의 gloss annotation을 사용하여 동작을 구별하고 모델이 이를 학습할 수 있도록 도와준다. 그러나 다국어를 커버하기 위해 gloss로 주석을 추가하는 것은 비용이 많이 들고 현실적으로 어렵다.
    3. 이 논문에서 제안하는 시스템은 비주석 방식이며 시각 추출기와 번역 텍스트를 생성하는 생성 모델로 구성되어 있다. 또한 시각 추출기의 임베딩 공간을 생성기의 임베딩 공간과 일치시키는 임베딩 정렬 블록을 사용한다.

###### A Fast Method to Filter Noisy Parallel Data WMT2023 Shared Task on Parallel Data Curation (https://aclanthology.org/2023.wmt-1.37/)
- Anthology ID: 2023.wmt-1.37 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 기계 번역(MT) 시스템의 효과성은 훈련 데이터셋의 품질과 밀접하게 연결되어 있다. 이 논문에서는 정확한 번역을 대표하는 문장 쌍이나 문서를 찾는 것이 주요 과제라고 소개한 후, WMT2023 공유 과제에 대한 결과를 제시한다.
    2. 공유 과제에서는 MT 모델의 훈련과 평가를 위한 고품질 병렬 코포라를 만들기 위해 데이터의 정렬과 필터링을 수행하는 방법을 평가한다.
    3. 사전과 규칙 기반 방법의 조합을 활용하여 데이터의 품질과 일관성을 보장하는 접근 방식을 제안하고, 기준 시스템에 비해 가장 높은 1.6 BLEU 점수 향상을 달성하였다. 테스트 세트 전체에 일관된 향상이 보여지며, 이는 접근 방식의 효율성을 시사한다.

###### A Sentence Alignment Approach to Document Alignment and Multi-faceted Filtering for Curating Parallel Sentence Pairs from Web-crawled Data (https://aclanthology.org/2023.wmt-1.38/)
- Anthology ID: 2023.wmt-1.38 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 이 논문에서는 WMT23 공유 작업을 위한 AST의 제출 내용을 설명하여, 웹 스크랩된 텍스트로부터 데이터를 수정하는 두 가지 접근 방식에 대한 실험을 진행한다. 
    2. 문장 정렬을 사용하여 데이터에서 문서 정렬을 찾고, 정렬된 문서에서 병렬 문장 쌍을 추출한다. 다른 모든 문장들은 코사인 유사도에 기반하여 매칭하고, 다양한 필터를 적용한다. 
    3. 필터링을 위해 언어 감지, 유창성 분류, 단어 정렬, 다국어 문장 임베딩 모델 계산에 의한 코사인 거리, 그리고 Bicleaner AI를 사용한다. 최고의 모델은 네 개의 평가 세트에서 약 1.9 BLEU 포인트로 베이스라인을 능가한다.

###### Document-Level Language Models for Machine Translation (https://aclanthology.org/2023.wmt-1.39/)
- Anthology ID: 2023.wmt-1.39 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 기계 번역 시스템은 대부분 문장 단위로 작동하며 문서 수준의 메타 정보가 없어, 이러한 제한이 알려져 있음에도 불구하고 문장 수준에 연결된 병렬 훈련 데이터를 대부분 사용한다. 따라서 본문 수준의 단일언어 데이터를 사용하여 컨텍스트에 민감한 번역 시스템을 구축하는 것이 목표이다.
    2. 기존의 접근법을 개선하기 위해 최근 모델 결합 기술을 활용하는 방법을 제안하고, 시스템 결합의 유연성을 높이고 계산 오버헤드를 크게 줄이는 새로운 가중치 기술을 제안한다.
    3. 완전한 평가에서 우리는 우리의 확장이 문서를 대상으로 한 점수를 유의하게 향상시키고 계산적으로 더 효율적임을 보여준다. 그러나 대부분의 경우 다시 훈련해야하는 비용이 들지만 역번역은 더 좋은 결과를 제공하는 것으로 나타났다. 마지막으로 최근 대형 언어 모델의 발전을 고려하여 언어 모델 결합을 탐색한다.

###### ChatGPT MT: Competitive for High- (but Not Low-) Resource Languages (https://aclanthology.org/2023.wmt-1.40/)
- Anthology ID: 2023.wmt-1.40 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 대형 언어 모델 (LLM)은 기계 번역 (MT)을 포함한 다양한 언어 작업을 암묵적으로 학습한다. 하지만, 최근 LLM MT 성능이 평가되지 않은 다양한 언어가 존재한다. 이 논문은 204개 언어에 대한 첫 번째 실험적 증거를 제시하며, GPT 모델은 일부 고능사 원어민 (HRL) 언어에 대해 전통적인 MT 모델의 성능과 유사하거나 뛰어날 수 있지만, 저능사 원어민 (LRL) 언어에서는 일관되게 후퇴한다는 경향을 보인다.
    
    2. 저자들은 일부 고능사 원어민 언어(HRL)에서 GPT 모델의 기존 MT 모델 성능과 유사한 시도를 보여주었지만, 저능사 원어민 언어 (LRL)에서는 전통적인 MT보다 성능이 좋지 않음을 밝혀냈다. 
    
    3. 이 분석은 언어의 자원 수준이 ChatGPT가 해당 언어를 번역하는 상대적 능력을 결정하는 가장 중요한 요소임을 보여주며, ChatGPT는 특히 저능사 원어민 언어와 아프리카 언어에 대해 불리하게 작용한다는 것을 시사한다.

###### Large Language Models Effectively Leverage Document-level Context for Literary Translation, but Critical Errors Persist (https://aclanthology.org/2023.wmt-1.41/)
- Anthology ID: 2023.wmt-1.41 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 최근의 대형 언어 모델 (LLM)은 문장 수준의 번역 작업에 대해 최상의 성능을 보이고 있다. 그러나 문단이나 문서 수준의 번역 능력은 아직 탐구되지 않은 상태이다.
    2. 본 논문에서는 GPT-3.5 LLM을 통해 문단 전체를 한 번에 번역하는 것이 표준적인 문장 단위 번역보다 더 우수한 품질의 번역을 제공함을 인간 평가로 입증하였다.
    3. 문장 수준보다 더 많은 미번역, 문법 오류, 스타일 일관성 부재와 같은 문제가 있으나, 저자의 음성을 유지하기 위해 인간 번역가의 개입이 필요하다는 점을 알 수 있다.

###### Identifying Context-Dependent Translations for Evaluation Set Production (https://aclanthology.org/2023.wmt-1.42/)
- Anthology ID: 2023.wmt-1.42 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 문맥 기계 번역으로의 전환에 대한 큰 장애물은 좋은 평가 메트릭과 테스트 세트의 부재이다. 문맥을 바르게 번역해야 하는 문장은 테스트 세트에서 흔치 않아 COMET, BLEU와 같은 표준 코퍼스 수준의 메트릭의 유틸리티가 감소한다.
    2. 그러나 이러한 문장을 주석 달아 놓은 데이터셋은 드물고 규모가 작으며 몇 개의 언어에 한정되어 있다. 
    3. 이 논문에서는 문맥적 문장을 식별하기 위해 이전 어노테이션 파이프라인을 개선하고 확장하여 MultiPro라는 도구를 만들었다. 이 도구는 성별, 공손함, 대명사의 생물성, 동사 구문 탈락, 모호한 명사 변화 등 다섯 가지 현상을 바르게 번역하기 위해 문맥을 필요로 하는 문장을 선별한다.

###### Machine Translation with Large Language Models: Prompting, Few-shot Learning, and Fine-tuning with QLoRA (https://aclanthology.org/2023.wmt-1.43/)
- Anthology ID: 2023.wmt-1.43 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 큰 규모의 언어 모델은 자연어 생성에서 놀라운 발전을 이루고 있지만, 특히 fine-tuning을 할 때 기계 번역에서의 잠재력은 아직 탐구되지 않은 상태이다.
    2. 이 연구에서는 15개의 공개된 언어 모델을 기계 번역 과제에서 종합적으로 실험하고 성능을 평가한다.
    3. QLoRA라는 효율적인 fine-tuning 방법을 사용하여 프렌치-영어 번역에서 QLoRA fine-tuning은 few-shot learning과 모델을 처음부터 학습하는 것보다 우수한 성능을 보여준다.

###### Towards Effective Disambiguation for Machine Translation with Large Language Models (https://aclanthology.org/2023.wmt-1.44/)
- Anthology ID: 2023.wmt-1.44 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. "의미적 모호성 해결은 기계 번역 분야에서의 중요한 과제로 인식되고 있으며, 최근에는 모호한 문장에 대한 번역 성능을 벤치마킹하는 연구가 해당 분야의 전통적인 NMT 시스템의 한계를 드러냈다."
    2.  "우리는 대용량 언어 모델(LLMs)이 "모호한 문장"을 번역하는 능력을 연구하고, 이들의 명료화 능력을 향상시키기 위해 (a) 문맥 내 학습과 (b) 세련된 모호한 데이터셋에 대한 fine-tuning 두 가지 방법을 제안한다."
    3. "실험 결과, 우리의 방법들은 DeepL과 NLLB와 같은 최첨단 시스템과 비교했을 때 5 개 언어 중 4 개의 언어 방향에서 동등하거나 뛰어난 성능을 보여주었다. 우리의 연구는 기계 번역에서 LLMs를 효과적으로 개선하기 위한 가치있는 통찰력을 제공한다. 우리는 정리된 명료화 코퍼스와 자원들을 https://data.statmt.org/ambiguous-europarl 에서 공유한다."

###### A Closer Look at Transformer Attention for Multilingual Translation (https://aclanthology.org/2023.wmt-1.45/)
- Anthology ID: 2023.wmt-1.45 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 기계 번역에 대한 대표적인 모델인 Transformer는 여러 언어 쌍에 대한 번역을 학습하는 데 좋은 성과를 내었다. 이 논문에서는 다른 언어 쌍을 번역하는 데에서 multilingual Transformer 모델이 어떻게 attention을 기울이는지 조사했다.
    2. 먼저 자동 가지치기를 통해 noise가 많은 head를 제거한 후, self-attention과 cross-attention에서 남은 head의 기능과 행동을 분석했다.
    3. 다른 언어 쌍은 문법과 단어 순서가 다르더라도 같은 기능을 위해 같은 head를 사용하는 경향이 있는 것을 발견했으나, 서로 다른 언어 쌍의 특성은 기능 head에 방해를 주고 head 정확도에 영향을 준다는 것을 밝혀냈다. 또한, 깊은 레이어 cross-attention head는 다른 word 재정렬 옵션을 학습하기 위해 협력하는 것으로 나타났다.

###### Bridging the Gap between Position-Based and Content-Based Self-Attention for Neural Machine Translation (https://aclanthology.org/2023.wmt-1.46/)
- Anthology ID: 2023.wmt-1.46 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. FNet과 MLPMixer와 같은 Position-based token-mixing 접근법은 computer vision과 natural language understanding에 대한 흥미로운 attention 대안으로 알려져 있다. 
    2. rPosNet은 position-based attention을 제안하여 attention weights를 position representations에서 계산하는 multi-head attention의 변형판이다.
    3. 상대적인 위치 표현과 gating 메커니즘을 사용하여 rPosNet은 이전의 position-based 접근법보다 우수한 성능을 보이며, Transformer의 품질과 일치하면서도 학습 후 attention 파라미터를 20% 더 적게 필요로 한다.

###### Visual Prediction Improves Zero-Shot Cross-Modal Machine Translation (https://aclanthology.org/2023.wmt-1.47/)
- Anthology ID: 2023.wmt-1.47 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 최근에는 몇 가지 언어 쌍에 대해 멀티모달 기계 번역(MMT) 시스템이 성공적으로 개발되었으나, 이러한 모델을 훈련시키기 위해서는 소스 언어 텍스트, 타겟 언어 텍스트, 이미지의 튜플이 필요하다. 이 데이터를 얻기 위해서는 비용이 많이 드는 인간의 주석이 필요하므로, 텍스트만 있는 언어 쌍을 위한 모델을 개발하기가 어렵다.
    2. 우리는 새로운 번역 방향으로 기존의 멀티모달 병렬 코퍼스로부터 멀티모달 지식을 전송하는 제로샷 크로스모달 기계 번역 과제를 제안한다.
    3. 우리는 멀티모달 병렬 데이터를 기반으로 시각적 특징을 학습하고 텍스트만 있는 언어 쌍을 위해 유사 특징을 제공하는 새로운 MMT 모델을 도입한다. 이 훈련 방식으로 우리의 MMT 모델이 텍스트만 있는 대응 모델보다 더 성능이 우수함을 보여준다. 추가적인 분석을 통해 시각적 특징의 선택이 중요하며 이미지 인식 번역에서 훈련하고 비슷한 언어 쌍에 기반을 두는 것이 필수적임을 보여준다.

###### The Gender-GAP Pipeline: A Gender-Aware Polyglot Pipeline for Gender Characterisation in 55 Languages (https://aclanthology.org/2023.wmt-1.48/)
- Anthology ID: 2023.wmt-1.48 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 언어 생성 시스템의 성별 편향은 어렵게 해소할 수 있는 문제이다. 이러한 편향의 가능한 원인 중 하나는 학습 및 평가 데이터의 성별 표현 격차일 수 있다.
    2. 이 논문에서는 광범위한 데이터셋의 성별 표현을 보고하기 위한 자동 파이프라인인 Gender-Gap 파이프라인을 제안한다.
    3. 이 파이프라인은 텍스트 내의 성별화된 인칭 대명사들에 대한 다국어 어휘 사전을 활용하여 성별 표현을 계량화한다.

###### Towards Better Evaluation for Formality-Controlled English-Japanese Machine Translation (https://aclanthology.org/2023.wmt-1.49/)
- Anthology ID: 2023.wmt-1.49 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 이 논문에서는 일본어 텍스트의 정도를 자동으로 분류하는 새로운 접근 방식을 제안한다. 
    2. 기존의 자료와 일본의 하원 및 상원 웹사이트에서 스크랩한 공식 문장들을 합친 새로운 데이터셋을 소개하며, 변환기 기반의 분류 모델을 제안하여 벤치마크 데이터셋에서 최고 성능을 달성했다.
    3. 제안된 분류기를 사용하여 큰 언어 모델(Large Language Models)을 사용한 기계 번역의 정도 제어 효과를 연구하는 방법을 제안하였다. 실험 결과는 우리의 접근 방식의 강건성과 효과를 검증하며, LLM을 활용한 정도 제어가 실행 가능한 방법임을 제안한다.

###### There’s No Data like Better Data: Using QE Metrics for MT Data Filtering (https://aclanthology.org/2023.wmt-1.50/)
- Anthology ID: 2023.wmt-1.50 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. Quality Estimation(QE)는 명시적인 참조 없이 기계 번역 결과를 평가하는데 사용되는데, 웹 크롤링 데이터와 같은 많은 양의 텍스트 모음에서 오류가 있는 예제를 감지하는 것이 일반적이지만, QE 모델은 세밀한 품질 차이를 구별하는 데 사용된다.
    2. 우리는 QE 메트릭을 사용하여 훈련 데이터에서 질이 낮은 문장 쌍을 걸러내는 것의 실용성을 분석한다.
    3. 우리는 훈련 데이터에서 가장 품질이 높은 문장 쌍을 선택함으로써 번역 품질을 향상시킬 수 있고, 동시에 훈련 크기를 절반으로 줄일 수 있다는 것을 보여준다.

###### Results of WMT23 Metrics Shared Task: Metrics Might Be Guilty but References Are Not Innocent (https://aclanthology.org/2023.wmt-1.51/)
- Anthology ID: 2023.wmt-1.51 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 이 논문은 WMT23 Metrics Shared Task의 결과를 제시한다. 자동 MT 평가 metric을 제출한 참가자들은 WMT23 News Translation Task에서 경쟁하는 번역 시스템의 출력을 평가하도록 요청받았다.
    2. 작년과 유사하게 MQM을 통해 전문가 기반의 인간 평가를 기반으로 한 우리만의 인간 평가를 수행했으며, metric의 특정 유형의 번역 오류를 포착하고 벌점을 주는 능력을 평가하기 위해 대회 세트 서브태스크를 포함하였다.
    3. 결과는 신경망 기반 metric이 인간 판정과의 상관관계 수준에서 비신경망 metric보다 훨씬 우수함을 선명하게 확인하며, 나쁜 참고 번역이 metric과 인간 판단의 상관관계에 미치는 영향과 새로운 metric의 중요성에 대한 관계를 연구한다.

###### Findings of the WMT 2023 Shared Task on Quality Estimation (https://aclanthology.org/2023.wmt-1.52/)
- Anthology ID: 2023.wmt-1.52 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. WMT 2023 공유 작업에서 뉴럴 머신 번역 시스템의 출력 품질을 예측하는 도전을 하는데, 레퍼런스 번역을 사용하지 않고 단어 수준과 문장 수준에서 품질을 예측하는 것이 목표이다.
    2. 이번 대회에서는 더 세분화되고 설명 가능한 품질 예측 접근 방식을 위해 몇 가지 혁신적인 측면과 확장을 도입했다.
    3. 다양한 언어 쌍에 대해 문장 및 단어 수준의 품질 점수를 얻기 위해 다차원 품질 지표를 사용하는 업데이트된 품질 주석 체계를 도입했으며, 저자원 언어에 대한 데이터도 제공한다.

###### Findings of the Word-Level AutoCompletion Shared Task in WMT 2023 (https://aclanthology.org/2023.wmt-1.53/)
- Anthology ID: 2023.wmt-1.53 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 이 논문은 워드-레벨 자동 완성 (WLAC) 공유 과제의 개요를 제시한다. WLAC는 사람이 입력한 문자열을 포함한 번역 문맥에서 대상 단어를 자동으로 완성하는 것을 목표로 한다. 전체적으로 이전 라운드의 공유 과제 설정을 따르지만, 사람 번역가의 타이핑 과정에서 얻은 문자열을 사용하여 실제 시나리오에서 시스템 성능을 보여주고 테스트 예시를 준비한다는 점에서 두 가지 주요한 차이점이 있다.
    2. 실험 결과에서는 번역 과제가 WLAC 모델의 성능을 향상시키는 데 도움이 된다는 것을 관찰할 수 있다. 또한, 추가 분석 결과에서 의미적 오류가 모든 오류의 상당 부분을 차지하므로, 미래에 이러한 종류의 오류를 고려하는 것이 유망할 것으로 판단된다.

###### Findings of the WMT 2023 Shared Task on Machine Translation with Terminologies (https://aclanthology.org/2023.wmt-1.54/)
- Anthology ID: 2023.wmt-1.54 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. WMT 2023 Terminology Shared Task는 전문 용어를 포함한 텍스트의 기계 번역에 대한 진전 상황을 조사한다. 
    2. 팀들은 Chinese→English, English→Czech, German→English 3개의 언어 쌍에 대해 소스 텍스트와 segment-level 용어 사전을 제공받았다. 
    3. 용어 사전을 포함하는 것은 번역 품질을 향상시키지만, 참조 정보와 동일한 정보를 포함하는 것과 유사한 결과를 내는 것으로 나타났다.

###### Findings of the WMT 2023 Shared Task on Automatic Post-Editing (https://aclanthology.org/2023.wmt-1.55/)
- Anthology ID: 2023.wmt-1.55 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. WMT 공유 작업의 9번째 라운드 결과가 발표되었다. 이 작업은 black-box 기계 번역 시스템의 출력 결과를 인간의 수정을 통해 자동으로 교정하는 것을 목표로 한다. 기존 작년과 마찬가지로 영어→마라티어로 진행되었으며, 여러 도메인에서 데이터가 수집되었다. 
    2. 올해의 데이터는 예전에 비해 매우 어렵다고 판명되었다. 사실, 참가 팀 중 어느 팀도 이미 높은 수준의 초기 번역(기준 TER와 BLEU 점수가 각각 26.6과 70.66)의 품질을 향상시키지 못했다. 
    3. 팀 중 하나가 "늦은" 제출로 인정받아 기준 점수를 넘어선 자동 평가 점수를 얻었다.

###### Findings of the WMT 2023 Shared Task on Low-Resource Indic Language Translation (https://aclanthology.org/2023.wmt-1.56/)
- Anthology ID: 2023.wmt-1.56 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 2023년 WMT에서 개최된 저자가 저자가 비교적 데이터가 적은 인디아어 번역 작업에 대한 결과를 제시하였다.
    2. 참가자들은 영어와 아사메스어, 미조어, 카시어, 매니퓌리어의 4개 언어 쌍에 대한 기계 번역 시스템을 구축하는 것을 요청받았다.
    3. 이 작업을 위해 인디아어 데이터셋인 IndicNE-Corp1.0이 공개되었으며, 자동 평가 지표(BLEU, TER, RIBES, COMET, ChrF)와 인간 평가를 통해 평가가 진행될 것이다.

###### ACES: Translation Accuracy Challenge Sets at WMT 2023 (https://aclanthology.org/2023.wmt-1.57/)
- Anthology ID: 2023.wmt-1.57 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. ACES Challenge Set을 사용하여 WMT 2023에 제출된 segment-level metrics의 성능을 벤치마킹한다. 
    2. WMT 2023에 제출된 metrics 중에서는 명확한 우승자가 없으며, 2023 버전과 2022 버전의 metrics 간의 성능 변화는 매우 다양하다. 
    3. metric 개발자들은 서로 다른 디자인 패밀리의 metrics를 앙상블로 구성하고, 원본에 더 많은 주의를 기울이고 표면적인 겹치기에 덜 의존하는 metrics를 개발하며, 다국어 임베딩이 기계 번역 평가에 미치는 영향을 신중하게 결정해야 한다.

###### Challenging the State-of-the-art Machine Translation Metrics from a Linguistic Perspective (https://aclanthology.org/2023.wmt-1.58/)
- Anthology ID: 2023.wmt-1.58 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 이 연구에서는 8회 기계 번역 컨퍼런스의 Metrics Shared Task에 제출된 최신 기계 번역 메트릭을 평가하기 위해 언어학적으로 도전적인 셋을 사용한다.
    2. 이 도전 셋은 100개 이상의 문법적 현상과 14가지 범주에 걸쳐 3개의 언어 방향에서 155개의 기계 번역 시스템에서 추출한 약 21,000개의 항목을 포함하고 있다.
    3. 언어학적 분석을 기반으로 가장 우수한 성능을 가진 메트릭은 Cometoid22-wmt23(증류 기반 학습 메트릭)가 독일어-영어 및 MetricX-23-c(mT5 인코더-디코더 언어 모형에 기반한 fine-tuned 메트릭)가 영어-독일어 및 영어-러시아어에 대해 각각이다.

###### Tokengram_F, a Fast and Accurate Token-based chrF++ Derivative (https://aclanthology.org/2023.wmt-1.59/)
- Anthology ID: 2023.wmt-1.59 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. "Tokengram_F"는 chrF++에서 영감을 받은 기계 번역 평가 메트릭으로, 단어 n-gram을 토큰화 알고리즘에서 얻은 n-gram으로 대체해 단어간 유사성을 더 잘 캡처할 수 있다.
    2. 기존 평가 메트릭에 비해 더 정확한 대안으로 작용할 수 있다.
    3. Tokengram_F는 Machine Translation에서 사용되는 F-score 기반의 평가 메트릭이다.

###### Embed_Llama: Using LLM Embeddings for the Metrics Shared Task (https://aclanthology.org/2023.wmt-1.60/)
- Anthology ID: 2023.wmt-1.60 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. Embed_llama은 최근에 소개된 Llama 2 Large Language Model (LLM)의 임베딩 레이어를 활용하여 문장을 벡터 공간으로 변환하여 기하학적 및 의미적 유사성을 연결하는 언어 번역 평가 메트릭이다.
    2. Embed_llama은 언어 번역 평가에서 LLM의 임베딩 레이어를 활용하여 문장 간의 의미적 유사성을 측정함으로써 평가지표로 사용한다.
    3. Embed_llama은 기하학적 및 의미적인 접근 방식으로 문장의 유사성을 측정하여 언어 번역 평가를 수행할 수 있다.

###### eBLEU: Unexpectedly Good Machine Translation Evaluation Using Simple Word Embeddings (https://aclanthology.org/2023.wmt-1.61/)
- Anthology ID: 2023.wmt-1.61 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. BLEU 메트릭 대신 임베딩 유사성을 사용하는 eBLEU 메트릭을 제안한다. 이 메트릭은 fastText와 같은 효율적이고 비컨텍스트 단어 임베딩을 사용하여 의미적으로 유사한 단어의 n-gram을 매칭시키는데 사용한다.
    2. WMT23 데이터에서, eBLEU는 BLEU와 ChrF를 약 3.8% 시스템 수준 점수로 능가하며, BERTScore와 -0.9%의 절대적인 차이로 접근한 수치를 보여준다.
    3. WMT22 시나리오에서는 eBLEU가 f101spBLEU와 ChrF를 2.2% ~ 3.6%만큼 능가하는 MQM 점수를 기록한다. MTurk 평가에서는 eBLEU가 3.9% ~ 8.2% (f200spBLEU, COMET-22)의 성능을 보여준다. eBLEU는 전통적인 메트릭과 사전 훈련된 메트릭 사이의 흥미로운 중간지점을 제시한다.

###### Cometoid: Distilling Strong Reference-based Machine Translation Metrics into Even Stronger Quality Estimation Metrics (https://aclanthology.org/2023.wmt-1.62/)
- Anthology ID: 2023.wmt-1.62 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 지식 증류를 활용하여 작은 학생 모델을 만들고 기존의 품질 평가(reference-based metric)를 reference-free 학생 메트릭(QE)으로 증류함으로써 기계 번역 평가 메트릭을 개선한다.
    2. COMET22와 ChrF를 증류하는데 초점을 맞추며, 공식적인 WMT-22 Metrics 평가 작업에서 distilled Cometoid QE 메트릭은 모든 다른 QE 메트릭을 능가하며 reference-based teacher 메트릭과 동등하거나 능가한다.
    3. 우리의 메트릭은 인간의 참값 점수를 직접 볼 수 없으며, 오직 원래 개발자에 의해 인간의 점수에 대해 훈련된 teacher 메트릭만 학습한다. 또한, ChrFoid는 전적으로 인간의 점수가 없는 상태에서, WMT-22 작업에서 teacher 메트릭보다 7% 이상의 정확성을 가지는 것을 확인할 수 있다.

###### MetricX-23: The Google Submission to the WMT 2023 Metrics Shared Task (https://aclanthology.org/2023.wmt-1.63/)
- Anthology ID: 2023.wmt-1.63 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 이 보고서는 WMT23 Metrics Shared Task에 대한 MetricX-23 제출 내용과 어떤 메트릭스를 제출할지 결정하는데 기반이 된 실험에 대한 개요를 제공한다.
    2. 제출한 3가지 버전은 모두 학습된 회귀 기반 메트릭스로, 학습에 사용된 데이터와 초기화에 사용된 사전 훈련 언어 모델이 다양하게 다르다.
    3. 실험 결과로는 (1) 어떤 감독 학습 데이터를 사용할지, (2) 학습 레이블을 정규화하는 방식이 어떤 영향을 미치는지, (3) 합성 훈련 데이터의 양, (4) 메트릭스 성능과 모델 크기의 관계, (5) 다른 사전 훈련 언어 모델로 메트릭스를 초기화하는 효과 등에 대한 결과를 보고한다.

###### GEMBA-MQM: Detecting Translation Quality Error Spans with GPT-4 (https://aclanthology.org/2023.wmt-1.64/)
- Anthology ID: 2023.wmt-1.64 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. GEMBA-MQM는 사람의 참고 번역 없이 품질 평가 설정에서 번역 품질 오류를 감지하기 위한 GPT 기반 평가 메트릭이다.
    2. GEMBA-MQM은 LLM (large language models)의 힘을 활용하여 GPT-4 모델에 쿼리를 보내어 오류 품질 범위를 표시하는 고정된 세 개의 프롬프트 기술을 사용한다.
    3. 기존 방법들과 비교했을 때 GEMBA-MQM은 언어에 중립적인 프롬프트를 가지고 있어 새로운 언어에 대해서는 수동 프롬프트 준비가 필요 없다. 단, GPT 모델에 의존하기 때문에 학문적인 작업에서 다른 방법들과 비교해 성능 향상을 입증하는 데 주의가 필요하다.

###### Metric Score Landscape Challenge (MSLC23): Understanding Metrics’ Performance on a Wider Landscape of Translation Quality (https://aclanthology.org/2023.wmt-1.65/)
- Anthology ID: 2023.wmt-1.65 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. "The Metric Score Landscape Challenge (MSLC23)" 데이터셋은 기계번역 (MT) 품질의 넓은 범위에 대한 메트릭 점수를 이해하기 위해 고안되었다. 이 데이터셋은 WMT23 일반 과제 테스트셋에서 낮은부터 중간 품질의 MT 출력 모음을 제공한다.
    2. 이 데이터셋과 과제에 제출된 고품질 시스템을 함께 사용하여, 다양한 수준의 번역 품질에서 메트릭 점수를 더 잘 해석할 수 있다.
    3. 이 논문에서는 이보다 더 넓은 번역 품질 범위에서 메트릭의 특성을 시각화하고 분석한다.

###### MEE4 and XLsim : IIIT HYD’s Submissions’ for WMT23 Metrics Shared Task (https://aclanthology.org/2023.wmt-1.66/)
- Anthology ID: 2023.wmt-1.66 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 이 논문은 WMT2023 공유 메트릭스 작업에 대한 기여를 설명하는데, 두 가지 다른 평가 접근 방식인 (a) 비지도 기준 메트릭과 (b) 지도 기준 메트릭을 포함하고 있다. 
    2. MEE4는 단어 임베딩을 활용하여 언어적 특징을 수량화하는 비지도, reference-based 평가 메트릭이다. 
    3. 반면에 XLsim은 Siamese Architecture를 사용하여 과거 WMT 뉴스 번역 공유 작업의 직접 평가 (DA)에 대한 회귀를 수행하는 지도, reference-based 평가 메트릭이다.

###### Quality Estimation Using Minimum Bayes Risk (https://aclanthology.org/2023.wmt-1.67/)
- Anthology ID: 2023.wmt-1.67 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. MBR decoding과 BLEURT와 같은 신경망 효용 메트릭을 사용하여 고품질 기계 번역을 생성하는 것이 효과적이라는 것이 알려져 있다.
    2. 우리는 MBR 디코딩의 기술을 사용하여 레퍼런스 없는 품질 측정 메트릭을 개발한다.
    3. 우리의 방법은 evaluator 기계 번역 시스템과 레퍼런스 기반 유틸리티 메트릭을 사용하여 모델의 품질 측정 점수를 계산한다.

###### Evaluating Metrics for Document-context Evaluation in Machine Translation (https://aclanthology.org/2023.wmt-1.68/)
- Anthology ID: 2023.wmt-1.68 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. SLIDE는 WMT 2023 메트릭스 과제에 제출된 새로운 지표로, 테스트 세트에서 문서에 고정된 길이의 창을 만들어 청크를 연결하고, 한 번에 단위로 평가하는 비참조 품질 추정 메트릭이다.
    2. SLIDE는 이전의 문맥을 고려하지 않는 지표에 비해 두 개의 WMT22 평가 캠페인에서 큰 개선을 보여주었다.
    3. SLIDE는 COMET을 사용하여 점수를 매길 수 있도록 구현되었다.

###### Semantically-Informed Regressive Encoder Score (https://aclanthology.org/2023.wmt-1.69/)
- Anthology ID: 2023.wmt-1.69 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 기계 번역은 소스 텍스트를 다른 언어로 번역하는 자연어 생성(NLG) 문제로, 평가 메트릭을 필요로 한다. 
    2. 인간의 평가는 비용과 시간이 많이 드는 문제이므로, 전문가 평가와의 상관관계에서 대폭 향상된 자동 기계 번역 평가 결과를 얻기 위해 사전 훈련된 transformer 구조와 대형 언어 모델(LLM)이 등장한 지난 몇 년 동안 많은 발전이 있었다. 
    3. 우리는 MRE-Score, seMantically-informed Regression Encoder Score를 도입하여 회귀 인코더 및 대조적 사전 훈련을 기반으로 한 자동 기계 번역 평가 시스템을 구축하는 접근 방법을 제안한다.

###### Empowering a Metric with LLM-assisted Named Entity Annotation: HW-TSC’s Submission to the WMT23 Metrics Shared Task (https://aclanthology.org/2023.wmt-1.70/)
- Anthology ID: 2023.wmt-1.70 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 이 논문은 WMT23 metrics 공유 작업에 대한 Huawei 번역 서비스 센터 (HW-TSC)의 참가를 소개하고, KG-BERTScore와 HWTSC-EE-Metric 두 가지 지표를 제출한다.
    2. KG-BERTScore는 참조 없는 메트릭으로, segment-level 및 system-level 점수를 제공할 수 있다. HWTSC-EE-Metric은 참조 있는 메트릭으로, system-level 점수만 제공할 수 있다.
    3. 우리의 메트릭은 이전 연도의 metrics 과제에서 MQM 점수와 상대적으로 높은 상관관계를 보여준다. 특히 system-level 점수 과제에서 여러 언어 쌍에서 새로운 최고 성능을 달성한다.

###### Unify Word-level and Span-level Tasks: NJUNLP’s Participation for the WMT2023 Quality Estimation Shared Task (https://aclanthology.org/2023.wmt-1.71/)
- Anthology ID: 2023.wmt-1.71 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 2023 WMT Quality Estimation (QE) shared task에서 NJUNLP 팀의 제출 결과를 소개합니다. 팀은 (i) 문장 및 단어 수준의 품질 예측과 (ii) 세밀한 오류 범위 감지 두 가지 하위 과제에 대한 영어-독일어 언어 쌍의 예측을 제출했습니다.
    2. 많은 향상을 위해 pseudo data 기법을 NJUQE 프레임워크를 기반으로 한 QE에 더욱 탐구했습니다. WMT 번역 작업의 병렬 데이터를 사용하여 pseudo MQM 데이터를 생성합니다. 그 후, XLMR large 모델을 pseudo QE 데이터로 사전 훈련한 뒤, 실제 QE 데이터로 세부 조정합니다.
    3. 실험을 통해 성능 향상에 기여하는 중요한 하이퍼파라미터를 찾기 위해 실험을 수행하였습니다. 또한, 단어 수준 출력을 세밀한 오류 범위 결과로 변환하기 위한 간단한 방법을 제안합니다. 전반적으로, 우리의 모델은 단어 수준 및 세밀한 오류 범위 감지 하위 과제에서 상당한 격차로 영어-독일어에서 최고의 결과를 달성했습니다.

###### HW-TSC 2023 Submission for the Quality Estimation Shared Task (https://aclanthology.org/2023.wmt-1.72/)
- Anthology ID: 2023.wmt-1.72 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 기계 번역 품질을 참조 번역 없이 평가하는 품질 예측(QE)은 핵심 기술이다. 이 연구에서는 Huawei Translation Services Center의 Ensemble-CrossQE라는 문장 수준 QE 공유 작업에 중점을 두었다.
    2. 우리 시스템은 CrossQE를 사용하며, 다국어 기반 모델과 작업 특정 downstream 레이어로 구성되어 있다. 성능을 향상시키기 위해 XLM-R, InfoXLM, RemBERT, CometKiwi와 같은 여러 기본 모델을 finetune하고 앙상블했다.
    3. 또한, 우리는 새로운 corruption 기반 데이터 증강 방법을 도입하여 원래 번역에 삭제, 대체, 삽입 오류를 생성하고 참조 기반 QE 모델을 사용하여 가상 점수를 얻었다. 결과적으로 우리 시스템은 문장 수준 QE 테스트 세트에서 훌륭한 성능을 보여주었으며, 영어-힌디어, 영어-타밀어, 영어-텔루구어 세 언어 쌍에서 1위를 차지했다.

###### Scaling up CometKiwi: Unbabel-IST 2023 Submission for the Quality Estimation Shared Task (https://aclanthology.org/2023.wmt-1.73/)
- Anthology ID: 2023.wmt-1.73 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. Unbabel과 Instituto Superior Técnico는 WMT 2023 Shared Task on Quality Estimation (QE)에 대한 공동 기여를 제시합니다. 우리 팀은 문장 및 단어 수준의 품질 예측과 세부 오류 범위 감지에 모두 참여했습니다.
    2. 모든 작업에서 저희는 CometKiwi 모델 (rei et al., 2022)을 기반으로 구축했습니다. 저희의 다국어 접근 방식은 모든 작업에서 1위를 차지하며, 단어, 범위, 문장 수준에서 품질 예측의 최첨단 성능을 달성했습니다.
    3. 이전 최첨단 모델인 CometKiwi와 비교하여 인간 판단과의 상관관계에서 큰 개선을 보여주고 (스피어만 점수 최대 10점 이상 증가), 2위의 다국어 제출을 절대 점수로 앞서게 했습니다.

###### SurreyAI 2023 Submission for the Quality Estimation Shared Task (https://aclanthology.org/2023.wmt-1.74/)
- Anthology ID: 2023.wmt-1.74 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 레퍼런스가 없는 상황에서 번역의 품질을 평가해야 할 때, Quality Estimation (QE) 시스템은 중요하다.
    2. SurreyAI 팀은 WMT23의 Sentence-Level Direct Assessment 공유 작업에 대한 접근 방식을 설명한다.
    3. TransQuest 프레임워크를 기반으로 한 MonoTQ-InfoXLM-large 방식은 대부분의 언어 쌍에서 기준 모델을 크게 능가하며, 강력한 전략으로 나타난다.

###### MMT’s Submission for the WMT 2023 Quality Estimation Shared Task (https://aclanthology.org/2023.wmt-1.75/)
- Anthology ID: 2023.wmt-1.75 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. WMT 2023 Quality Estimation (QE) shared task 1에서 제출한 논문은 간단한 훈련 데이터 augmentation 접근 방식을 제안한다. 이를 통해 QE 모델의 예측과 사람들의 품질 평가 간의 상관관계를 개선할 수 있다.
    2. 11가지 데이터 augmentation 접근 방식과 6개의 언어 쌍을 활용하여 각 언어 쌍의 원래 훈련 세트에 각 방법을 개별적으로 적용하여 증강된 훈련 세트를 생성한다.
    3. 실험 결과, 영어-독일어, 영어-마라티어, 영어-구자라트어와 같은 언어 쌍에 대해서 Paraphrase Database (PPDB)를 통한 동의어 대체가 가장 큰 성능 향상을 가져오며, 나머지 언어 쌍에 대해서는 문맥 단어 임베딩 기반 단어 삽입, 백 번역, 직접 대치 등의 방법이 더 효과적임을 보여준다.

###### IOL Research’s Submission for WMT 2023 Quality Estimation Shared Task (https://aclanthology.org/2023.wmt-1.76/)
- Anthology ID: 2023.wmt-1.76 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 이 논문은 IOL Research가 WMT 2023 quality estimation 공유 작업에서 제출한 결과를 제시한다. 우리는 문장 수준과 단어 수준의 두 가지 Quality Estimation 작업에 참여하였다. 교차 언어적과 다중 작업 모델을 사용하여 문장 수준의 점수와 단어 수준의 태그를 예측한다. 
    2. 우리는 다양한 다국어 사전 훈련 언어 모델 (PLM)을 백본으로 사용하고 이들을 기반으로 작업 모듈을 구축하여 더 나은 예측을 이룬다. 
    3. 우리의 방법은 각 모델의 예측 결과를 통합하여 성능을 개선하며, 각 모델의 가중치는 Dev 세트의 성능에 의해 자동으로 검색 및 최적화된다. 우리의 방법은 경쟁력 있는 결과를 얻은 것을 보여준다.

###### SJTU-MTLAB’s Submission to the WMT23 Word-Level Auto Completion Task (https://aclanthology.org/2023.wmt-1.77/)
- Anthology ID: 2023.wmt-1.77 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 컴퓨터 지원 번역에서 단어 수준 자동완성(WLAC)은 중요한 역할을 한다. 이 논문에서는 SJTU-MTLAB의 WMT23 WLAC 과제 참가 결과에 대해 설명한다. 
    2. 우리는 기계 번역 작업을 WLAC 작업에 통합하는 합동 방법을 제안한다. 이 제안된 접근법은 다양한 인코더 기반 아키텍처에 적용될 수 있다.
    3. 우리의 접근법은 모델 크기를 크게 줄이면서 성능을 크게 향상시킬 수 있다는 실험 결과를 보여준다.

###### PRHLT’s Submission to WLAC 2023 (https://aclanthology.org/2023.wmt-1.78/)
- Anthology ID: 2023.wmt-1.78 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 본 논문에서는 WMT23의 Word-Level AutoCompletion 공유 작업에 대한 제출 내용을 설명한다. 저자들은 영어-독일어 및 독일어-영어 카테고리에 참여하였다. 이전 연구에서는 문맥이 없을 때의 약점을 해결하기 위해 segment-based interactive machine translation 접근법을 확장하였다. 또한, 사전 학습된 mT5 large 언어 모델을 autocompletion에 사용하기 위해 fine-tuning을 수행하였다.
    2. 영어-독일어 및 독일어-영어 Word-Level AutoCompletion 작업에 참여하여, 이전에 보완되지 못한 약점을 segment-based interactive machine translation와 사전 학습된 mT5 large 언어 모델의 fine-tuning을 통해 해결하였다.
    3. WMT23의 Word-Level AutoCompletion 공유 작업에 제출된 저자들의 방법론을 설명하고, 언어 모델의 fine-tuning을 통해 autocompletion 작업을 수행했다.

###### KnowComp Submission for WMT23 Word-Level AutoCompletion Task (https://aclanthology.org/2023.wmt-1.79/)
- Anthology ID: 2023.wmt-1.79 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 최근 자연어처리에서의 대형 언어 모델(Large Language Models, LLMs)의 성공을 보았지만, 다국어 환경에서의 단어 수준 자동 완성에 대한 LLMs의 잠재력은 아직 충분히 탐구되지 않았다. 
    2. 이 논문에서는 WMT23 단어 수준 자동 완성(WLAC) 과제에 대한 LLM 기반 시스템을 제안하고 성능을 평가한다. 
    3. 실험 결과, 우리의 시스템은 평균적으로 테스트셋에서 29.8%의 정확도를 달성하며, LLMs는 zero-shot 상황에서 WLAC에 어려움을 겪지만 추가적인 예시의 도움을 받으면 성능이 크게 향상되었다.

###### Terminology-Aware Translation with Constrained Decoding and Large Language Model Prompting (https://aclanthology.org/2023.wmt-1.80/)
- Anthology ID: 2023.wmt-1.80 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 번역 시스템에 전문 용어 제약을 주입하여 용어의 정확성을 보장하는 것은 매우 중요하다. WMT 2023 용어 번역 과제에 대한 접근 방식으로 우리는 도메인에 독립적이고 최소한의 수작업이 필요한 번역 후 개선(translate-then-refine) 방식을 채택한다.
    2. 우리는 먼저 워드 얼라인먼트로부터 얻은 가짜 용어 번역을 가진 예시를 사용해 전문 용어를 고려하는 모델을 훈련시킨다. 그리고 우리는 두 가지 후처리 방법을 탐구한다.
    3. 첫째, 우리는 용어 제약의 위반 여부를 파악하기 위해 얼라인먼트 프로세스를 사용하고, 용어 제약에 위반한 경우 해당 단어를 제약을 둔 상태로 다시 디코딩한다. 그리고 대안으로 대용량 언어 모델을 활용하여 용어 제약을 제공함으로써 가설을 개선한다. 수행 결과 우리의 용어인식 모델은 효과적으로 용어를 포함하는 것을 학습하며, 대용량 언어 모델 개선 과정은 용어 인식을 더욱 향상시킬 수 있다.

###### Lingua Custodia’s Participation at the WMT 2023 Terminology Shared Task (https://aclanthology.org/2023.wmt-1.81/)
- Anthology ID: 2023.wmt-1.81 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 기계 번역 결과의 최종 품질을 평가하는 데 기술 용어의 정확한 번역은 중요한 역할을 합니다. 이 논문은 Lingua Custodia의 WMT23 공유 작업에 제출된 용어 공유 작업 관련 제안방법을 제시합니다. 
    2. 우리는 기계 번역 시스템을 적용할 때 용어 제약을 따르려고 합니다. 우리는 비지도학습 방식으로 추출된 합성 사전을 활용하여 기계 학습 훈련 데이터에 주석을 달기로 제안합니다.
    3. 우리는 이러한 훈련 데이터로 학습한 모델을 유연하게 특정 용어로 텍스트를 번역하는 데 사용할 수 있습니다. 우리의 제출된 시스템과 함께 자동 평가 메트릭은 제안한 방법의 효과를 보여줍니다.

###### Domain Terminology Integration into Machine Translation: Leveraging Large Language Models (https://aclanthology.org/2023.wmt-1.82/)
- Anthology ID: 2023.wmt-1.82 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. WMT 2023 Terminology Shared Task에서 우리는 large language model (LLM)을 사용하여 도메인 특화 용어의 번역에 특화된 machine translation (MT) 시스템을 개발하였다. 제안된 용어를 기반으로 한 LLM은 합성된 이중 언어 용어 기반 데이터를 생성하고, MT 모델이 생성한 번역을 사전 승인된 용어를 포함시키면서 후처리하는 데 활용된다.
    2. 우리의 방법은 LLM을 사용해 합성 데이터를 생성하고 generic MT 모델을 fine-tuning한 후 번역을 생성하며, 필요한 용어를 포함하지 않은 번역에는 LLM을 활용하여 용어 제약을 가진 자동 후처리를 수행한다.
    3. 실험 결과, 우리의 접근 방법은 사전 승인된 용어를 번역에 효과적으로 통합하는 데 성공하였고, 블라인드 데이터셋의 용어 통합 수는 평균 36.67%에서 우리의 과정을 거침에 따라 평균 72.88%로 거의 두 배로 증가하였다.

###### OPUS-CAT Terminology Systems for the WMT23 Terminology Shared Task (https://aclanthology.org/2023.wmt-1.83/)
- Anthology ID: 2023.wmt-1.83 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 이 논문은 OPUS-CAT 프로젝트의 WMT 2023 용어 공유 작업에 대한 제출 내용을 설명한다. 
    2. 모든 시스템은 동일한 훈련 파이프라인과 동일한 방법을 사용하여 훈련되었다. 
    3. 훈련 데이터에서 소스 언어 용어를 해당하는 대상 언어 용어와 주석으로 지원하는 용어 지원 기능이 구현되었다.

###### VARCO-MT: NCSOFT’s WMT’23 Terminology Shared Task Submission (https://aclanthology.org/2023.wmt-1.84/)
- Anthology ID: 2023.wmt-1.84 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 최고의 성능을 보이는 신경 기계 번역 (NMT) 모델에서조차 전문적인 용어 변환의 일관성 부족은 문학, 의학 및 비디오 게임 관련용어와 같은 좁은 도메인에서 번역의 품질을 저해한다.
    2. 용어 데이터베이스 구축과 통일성 향상을 위해 종종 사전을 사용하지만, 이는 실제로 구축하고 통합하기 어렵다.
    3. 저자들은 WMT'23 Terminology Shared Task에 제출한 연구를 설명함과 동시에, 용어 인식 기계 번역의 프레임워크를 제안한다. 이 프레임워크는 낮은 지도 환경 설정에서 용어 인식 기계 번역 데이터를 구축하는 자동 용어 추출 과정과 용어 제약 조건을 가진 두 가지 모델 아키텍처로 구성된다. 이 모델들은 중국어에서 영어로 번역하는 WMT'23 Terminology Shared Task 테스트 데이터에서 용어 검출에서 각각 21.51%p와 19.36%p 성능 향상을 보였다.

###### HW-TSC’s Participation in the WMT 2023 Automatic Post Editing Shared Task (https://aclanthology.org/2023.wmt-1.85/)
- Anthology ID: 2023.wmt-1.85 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. HW-TSC는 WMT 2023 자동 후 처리 (APE) 공유 작업에서 영어-마라티어 (En-Mr) 언어 쌍을 위한 기여를 제안한다. 저자들의 방법은 몇 가지 중요한 단계를 포함하는데, APE 모델을 사전 훈련시키고 실제 APE 데이터를 활용하여 모델을 세밀 조정한다. 또한, 외부 기계 번역 (MT) 시스템에서 얻은 후보 번역을 데이터 확장에 도입한다. 이들의 실험은 사전 훈련된 APE 모델이 한정된 크기의 APE 말뭉치와 함께 세밀 조정되었을 때 효과적임을 보여주며, 외부 MT 보강으로 성능을 더 향상시킬 수 있음을 보여준다.
    2. 성능 향상을 위해 오버피팅 문제를 해결하기 위해 훈련 단계에서 R-Drop을 사용한다. APE 시스템은 '과도한 수정' 경향을 가지기 때문에, 최종 출력을 선택하기 위해 문장 단위의 품질 추정 (QE) 시스템을 사용한다.
    3. 실험 결과, HW-TSC 방법은 개발 세트에서 TER과 BLEU 점수를 각각 -2.42와 +3.76 점 향상시킨다.

###### Neural Machine Translation for English - Manipuri and English - Assamese (https://aclanthology.org/2023.wmt-1.86/)
- Anthology ID: 2023.wmt-1.86 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 영어로 작성된 가치있는 정보는 많지만, 지역 언어에 더 익숙한 사람들에게는 이러한 지식에 접근하는 것이 어려울 수 있다. 이 논문에서는 신경망 기계 번역(NMT)을 사용하여 영어와 아사미 어, 매니푸리 어간의 번역에 효과적인 방법을 제안한다.
    2. 기존의 기계 번역 방법 중 하나인 NMT 변형 모델을 사용하여 영어와 아사미어, 매니푸리어간의 번역을 수행하였으며, BLEU 점수로 성능을 평가하였다.
    3. 영어에서 매니푸리어로의 번역에서 15.02 점, 매니푸리어에서 영어로의 번역에서 18.7 점, 영어에서 아사미어로의 번역에서 5.47 점, 아사미어에서 영어로의 번역에서 8.5 점의 BLEU 점수를 달성하였다.

###### GUIT-NLP’s Submission to Shared Task: Low Resource Indic Language Translation (https://aclanthology.org/2023.wmt-1.87/)
- Anthology ID: 2023.wmt-1.87 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. GUIT-NLP 팀은 “Shared Task: Low Resource Indic Language Translation” 에 참가하여, 영어-Mizo, 영어-Khasi, 영어-Assamese와 같은 저자원 언어 쌍에 초점을 맞춘다.
    2. 이 논문에서는 제한된 데이터에 특화된 Neural Machine Translation (NMT) 기법을 깊이 있게 탐구하며 가장 효과적인 방법을 찾는다.
    3. 또한, monolingual 데이터를 활용하여 Back Translation 기법을 영어-Mizo 번역에서 혁신적으로 시스템적으로 적용하고, 이를 통해 모델의 성능을 크게 향상시킨다.

###### NICT-AI4B’s Submission to the Indic MT Shared Task in WMT 2023 (https://aclanthology.org/2023.wmt-1.88/)
- Anthology ID: 2023.wmt-1.88 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 이 논문에서는 Team NICT-AI4B가 2023 WMT Indic MT 과제에 제출한 MT 시스템에 대해 설명한다. 주요 시스템은 3단계로 구성되며, 공식적으로 승인된 단일 언어 및 병렬 말뭉치를 사용하여 공동 노이즈 제거 및 기계 번역 훈련, 역번역 및 원본 및 역번역 병렬 말뭉치를 사용한 기계 번역 훈련으로 구성된다.
    2. 역번역은 번역 품질을 4 BLEU 점까지 크게 향상시킨다는 것을 관찰했다.
    3. 또한, 우리는 무제한 설정에서 2개의 대조 시스템을 개발했으며, 첫 번째 시스템은 공식 병렬 말뭉치와 AI4Bharat et al, (2023)에서 사용된 시드 데이터에서 IndicTrans2 DA 모델을 미세 조정하는 것이고, 두 번째 시스템은 주요 시스템과 위에서 언급한 시스템의 시스템 결합을 수행한다. 
    4. 결과적으로, 우리는 주력되는 4가지 저자원 동북인도 언어에 대해 고품질 기계 번역 시스템을 구축할 수 있었다.

###### Machine Translation Advancements for Low-Resource Indian Languages in WMT23: CFILT-IITB’s Effort for Bridging the Gap (https://aclanthology.org/2023.wmt-1.89/)
- Anthology ID: 2023.wmt-1.89 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 자동 MCQ 생성 시 평가 메트릭이 교육적 가치를 고려하지 못하는 문제를 해결하기 위해 KDA라고 불리는 새로운 평가 메트릭을 제안한다.
    2. 우리의 방법은 사람의 응답을 기반으로 KDA를 측정하고, 미리 학습된 언어 모델을 활용하여 KDA_disc와 KDA_cont라는 자동 평가 메트릭을 제안한다. 
    3. KDA_disc와 KDA_cont는 실제 강의실 세팅에서 사용성과 강한 상관관계를 가지며, n-gram 기반 메트릭과 결합하면 다양한 MCQ 품질 평가를 잘 예측하는 힘이 있다.
    
    1. 최근 NLP 태스크에서 딥 모델은 사람을 뛰어넘는 정확성을 보이지만, Bias나 맞지 않는 패턴에 의존하는 한계가 있다. 
    2. 따라서 이 논문은 contrastive learning과 counterfactual augmentation을 활용하여 딥 모델의 안정성을 높이는 것을 목표로 한다.
    3. 기존의 augmentation 방법과는 달리, 우리의 방법은 "집합적 의사 결정"을 통해 딥 모델의 인과관계 학습에 robust한 지도를 제공하여 성과를 향상시킨다.
    
    1. 'WMT23 IndicMT' 공유 작업을 위해 CFILT-IITB 팀이 제출한 논문이다. 
    2. 이 논문은 작업에 대한 MT 시스템 개발 및 WMT23 IndicMT에 제출된 MT 시스템에 대해 설명하고 있다.
    3. 작은 병렬 말뭉치로 학습된 저 품질의 시스템을 전이 학습을 통해 개선하고 최종으로 제출했다.

###### Low-Resource Machine Translation Systems for Indic Languages (https://aclanthology.org/2023.wmt-1.90/)
- Anthology ID: 2023.wmt-1.90 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 이 논문에서는 영어와 Assamese, Khasi, Mizo, Manipuri 간의 번역을 위한 WMT23 공유 작업에 대한 참가 내용을 제시한다.
    2. 우리는 모든 시스템을 다중 언어 마스킹 언어 모델링 및 노이즈 제거 자동 인코딩 작업에 대해 사전 학습시켰다.
    3. 우리의 주요 시스템은 다시 네 가지 언어 방향에서의 다국어 기계 번역을 위해 사전 학습되었고, 각 언어 쌍에 대해 제한된 병렬 데이터에 대해 따로 사전 조정된다.

###### MUNI-NLP Systems for Low-resource Indic Machine Translation (https://aclanthology.org/2023.wmt-1.91/)
- Anthology ID: 2023.wmt-1.91 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. WMT 2023의 저자 한국어 번역은 대부분 경쟁력 있는 성능에 도달하지 못했으나, 데이터셋과 모델 크기 사이의 관계와 훈련 프레임워크의 영향에 대한 흥미로운 점을 발견했다. 
    2. 이전 연구와는 대조적으로, 단어 임베딩 초기화, 역 번역, 모델 깊이에 대한 몇 가지 초기 실험 결과도 있었다. 
    3. 최종 결과에서는 평가에 사용된 자동 측정 항목들 사이에 불일치가 있었다.

###### NITS-CNLP Low-Resource Neural Machine Translation Systems of English-Manipuri Language Pair (https://aclanthology.org/2023.wmt-1.92/)
- Anthology ID: 2023.wmt-1.92 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 이 논문은 NITSCNLP가 WMT 2023 공유 작업에서 제출한 저소득 지역 언어 번역 작업을 위한 transformer 기반 NMT 시스템에 대해 설명한다. 해당 모델은 영어-마니푸리어 언어 쌍에서 전체적으로 BLEU 점수 22.75 및 26.92를 달성했다.
    2. 영어에서 마니푸리어 및 마니푸리어에서 영어 모델에 대한 실험 결과로는 chrF는 각각 48.35 및 48.64, RIBES는 각각 0.61 및 0.65, TER는 각각 70.02 및 67.62, 그리고 COMET은 각각 0.70 및 0.66이 보고되었다.
    3. 이 모델은 번역 작업에서 상대적으로 좋은 성능을 보여 주며, 특히 저소득 지역 언어에 대한 자동 번역에 유용할 것으로 기대된다.

###### IACS-LRILT: Machine Translation for Low-Resource Indic Languages (https://aclanthology.org/2023.wmt-1.93/)
- Anthology ID: 2023.wmt-1.93 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 지난 10년 동안 기계 번역은 큰 발전을 이루었지만, 인디안 언어의 번역 품질은 여전히 낮아 제한된 양의 병렬 데이터 사용량과 관련이 있다.
    2. 본 논문에서는 특히 영어-마니푸리어와 아사메어-영어와 같은 인디안 언어 쌍을 위한 적은 양의 병렬 훈련 데이터 문제를 완화하기 위한 접근 방식을 제시한다.
    3. 마니푸리에서 영어로의 번역 작업에 대한 저희 주요 제출 시스템은 이 언어 쌍에 대해 최고의 점수를 받았으며, 저희는 자세한 시스템 구축과 과정에서의 발견에 대해 설명한다.

###### IOL Research Machine Translation Systems for WMT23 Low-Resource Indic Language Translation Shared Task (https://aclanthology.org/2023.wmt-1.94/)
- Anthology ID: 2023.wmt-1.94 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. IOL Research 팀은 WMT23 low-resource Indic 언어 번역 공유 작업에 대한 제출 시스템을 설명한다. 
    2. 저자들은 전이학습과 데이터 증강을 통해 목적언어 번역의 품질을 향상시킬 수 있음을 보인다. 
    3. 실험 결과에서 이 방법은 네 개 언어 쌍에 대한 번역의 BLEU 점수를 크게 향상시키는 것으로 나타났다.

###### Trained MT Metrics Learn to Cope with Machine-translated References (https://aclanthology.org/2023.wmt-1.95/)
- Anthology ID: 2023.wmt-1.95 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 인간의 MT(Machine Translation) 평가에 기반을 둔 신경 메트릭은 인간 판단과 잘 상관될 수 있지만, 그 동작 원리가 완전히 이해되지 않는다. 
    2. 이 논문에서는 기준 메트릭과 동일한 메트릭의 학습 버전을 비교 실험을 통해 분석하고, 학습된 메트릭의 경우 기계 번역된 참고 자료에 대한 강건성이 향상되는 것을 발견했다.
    3. 이는 메트릭 학습의 효과가 인간 판단과의 전반적인 상관 관계 향상 이외의 효과를 가질 수 있다는 것을 시사한다.

###### Training and Meta-Evaluating Machine Translation Evaluation Metrics at the Paragraph Level (https://aclanthology.org/2023.wmt-1.96/)
- Anthology ID: 2023.wmt-1.96 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 기계 번역 연구가 문장 이상의 텍스트 번역으로 확장됨에 따라, 자동 평가 메트릭이 더 긴 번역을 평가하는 데 효과적인지 여전히 불명확한 상태이다.
    2. 우리는 기존의 문장 수준 데이터에서 문단 수준 데이터를 만들기 위한 방법을 제안하고, 이러한 새로운 데이터를 사용하여 기존의 문장 수준 평가 메트릭과 문단 수준에서 학습된 학습 메트릭을 벤치마크로 활용하였다. 
    3. 흥미로운 결과로, 우리의 실험 결과는 문장 수준 메트릭을 사용하여 전체 문단의 점수를 매기는 것이 문단 수준 메트릭을 사용하는 것과 동일한 효과를 내는 것으로 나타났다. 이 결과는 참조 기반 평가 작업의 특성 및 문단 수준 번역에서 발생하는 모든 현상을 캡처하는 데 대한 데이터셋의 한계와 관련이 있다고 추측한다.

###### Automating Behavioral Testing in Machine Translation (https://aclanthology.org/2023.wmt-1.97/)
- Anthology ID: 2023.wmt-1.97 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. NLP에서의 행동 테스트는 입출력 행동의 분석을 통해 언어 능력을 자세하게 평가하는 기능을 제공한다. 
    2. 기계 번역에서 이러한 행동 테스트의 적용은 특정 기능과 언어에 국한되어 있으며 수작업으로 된 테스트만을 다루고 있다. 
    3. 이 논문에서는 대규모 언어 모델을 사용하여 다양한 상황에서 기계 번역 모델의 행동을 테스트하기 위한 다양한 소스 문장을 생성하고, 이를 통해 기대된 결과를 확인할 수 있다고 제안한다.

###### One Wide Feedforward Is All You Need (https://aclanthology.org/2023.wmt-1.98/)
- Anthology ID: 2023.wmt-1.98 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. Transformer 아키텍처에서는 Attention과 FFN 두 가지의 구성요소가 있다. Attention은 단어들 간의 관련성을 고려하지만 위치에 상관 없이 처리하고, FFN은 각각의 입력 토큰을 비선형으로 변환한다. 
    2. 이 논문에서는 FFN의 역할을 조사한 결과, FFN은 모델의 매개변수 중 상당 부분이 중복되었다는 것을 발견했다. 따라서 디코더 레이어에서 FFN을 제거하고 인코더 전체에서 동일한 하나의 FFN을 공유하면 매개변수 수를 크게 줄일 수 있다. 
    3. 마지막으로 FFN의 hidden 차원을 늘려서 이 아키텍처를 원래 크기로 다시 확장하면 원래 Transformer보다 정확도와 대기 시간 모두 크게 향상시킬 수 있다.

###### A Benchmark for Evaluating Machine Translation Metrics on Dialects without Standard Orthography (https://aclanthology.org/2023.wmt-1.99/)
- Anthology ID: 2023.wmt-1.99 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 자연어 처리에서 진전하기 위해서는 사용하는 평가 메트릭의 한계를 잘 알고 있어야 중요하다. 본 연구에서는 표준화되지 않은 방언이나 맞춤법이 없는 언어 변종으로 인한 철자 차이에 대한 평가 메트릭의 강건성을 평가했다.
    2. 우리는 영어에서 스위스 독일어 방언 두 가지로의 자동 번역에 대한 인간 번역 및 판단 데이터셋을 수집했다. 우리는 방언 변화에 대한 챌린지 세트를 만들고 기존 메트릭의 성능을 평가하였다. 
    3. 결과적으로, 기존의 메트릭은 스위스 독일어 텍스트 생성 출력을 신뢰할 수 없으며, 특히 세그먼트 수준에서의 평가가 어렵다는 것을 보여주었다. 우리는 표준화되지 않은 방언에 대한 강건성을 높이기 위한 초기 설계 수정사항을 제안하였다.

###### The Devil Is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation (https://aclanthology.org/2023.wmt-1.100/)
- Anthology ID: 2023.wmt-1.100 
- Volume: Proceedings of the Eighth Conference on Machine Translation 
- Summary: 
    1. 기존 평가 방법들은 세밀한 실수 분석처럼 개별 오류를 주석으로 표기하는 MQM과 같은 방법보다 상세한 정보를 제공하지 못하고 있다.
    2. 이 논문에서는 대형 언어 모델의 추론 및 문맥 학습 능력을 활용하여 번역 오류를 식별하고 분류하는 AutoMQM이라는 prompting 기법을 제안한다.
    3. AutoMQM은 PaLM-2 모델과 함께 사용되면서 점수만 추출하는 방식보다 성능을 향상시키고 (특히 큰 모델에서 큰 이득), 인간 주석과 일치하는 오류 범위를 통해 해석 가능성을 제공한다.

